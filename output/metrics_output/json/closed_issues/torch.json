{"total_count": 79, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/twitter/torch-autograd/issues/177", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/177/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/177/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/177/events", "html_url": "https://github.com/twitter/torch-autograd/issues/177", "id": 394937206, "node_id": "MDU6SXNzdWUzOTQ5MzcyMDY=", "number": 177, "title": "FloatTensor.cdata not currently supported by autograd when implementing SSIM loss", "user": {"login": "farleylai", "id": 158540, "node_id": "MDQ6VXNlcjE1ODU0MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/158540?v=4", "gravatar_id": "", "url": "https://api.github.com/users/farleylai", "html_url": "https://github.com/farleylai", "followers_url": "https://api.github.com/users/farleylai/followers", "following_url": "https://api.github.com/users/farleylai/following{/other_user}", "gists_url": "https://api.github.com/users/farleylai/gists{/gist_id}", "starred_url": "https://api.github.com/users/farleylai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/farleylai/subscriptions", "organizations_url": "https://api.github.com/users/farleylai/orgs", "repos_url": "https://api.github.com/users/farleylai/repos", "events_url": "https://api.github.com/users/farleylai/events{/privacy}", "received_events_url": "https://api.github.com/users/farleylai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-12-31T06:45:06Z", "updated_at": "2019-01-01T09:36:07Z", "closed_at": "2019-01-01T09:36:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am working on the SSIM loss with autograd. SSIM requires several Gaussian convolutions to compute the statistics. In Torch7, a simple way to do so is to utilize nn.SpatialConvolution whose weights should be viewed as constant. However, autograd is going to raise the following error when building the computation graph due to the calling to the forward() of the spatial convolution module:\r\n\r\n```\r\nstack traceback:\r\n\t[C]: in function 'error'\r\n\t...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:22: in function **'cdata'**\r\n\t...kg/torch/install/share/lua/5.1/nn/SpatialConvolution.lua:80: in function 'forward'\r\n\t./ssim.lua:58: in function 'conv2d'\r\n\t./ssim.lua:79: in function 'ssim'\r\n\tsimple.lua:30: in function 'fn'\r\n\t...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:353: in function 'protectedFn'\r\n\t...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:383: in function 'record'\r\n\t.../install/share/lua/5.1/autograd/runtime/codegen/init.lua:44: in function 'generateFn'\r\n\t.../install/share/lua/5.1/autograd/runtime/codegen/init.lua:140: in function 'df'\r\n\tsimple.lua:39: in main chunk\r\n\t[C]: in function 'dofile'\r\n\t.../pkg/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:150: in main chunk\r\n\t[C]: at 0x00405d50\r\n```\r\n\r\nssim() is the loss function and conv2d() is the helper function that calls the forward() of the spatial convolution module internally.\r\n\r\nAny ideas?\r\nWhat is the right way/alternative when the loss function uses some Torch modules?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/172", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/172/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/172/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/172/events", "html_url": "https://github.com/twitter/torch-autograd/issues/172", "id": 209048572, "node_id": "MDU6SXNzdWUyMDkwNDg1NzI=", "number": 172, "title": "mailing list for autograd", "user": {"login": "biggerlambda", "id": 17243628, "node_id": "MDQ6VXNlcjE3MjQzNjI4", "avatar_url": "https://avatars2.githubusercontent.com/u/17243628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/biggerlambda", "html_url": "https://github.com/biggerlambda", "followers_url": "https://api.github.com/users/biggerlambda/followers", "following_url": "https://api.github.com/users/biggerlambda/following{/other_user}", "gists_url": "https://api.github.com/users/biggerlambda/gists{/gist_id}", "starred_url": "https://api.github.com/users/biggerlambda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/biggerlambda/subscriptions", "organizations_url": "https://api.github.com/users/biggerlambda/orgs", "repos_url": "https://api.github.com/users/biggerlambda/repos", "events_url": "https://api.github.com/users/biggerlambda/events{/privacy}", "received_events_url": "https://api.github.com/users/biggerlambda/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-02-21T05:50:16Z", "updated_at": "2017-02-21T10:20:40Z", "closed_at": "2017-02-21T10:20:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there a mailing list for torch autograd? \r\n\r\nI was having trouble debugging my code by putting print statements in the code. I have put print statements in the function closure passed to \"grad\" but they never get printed. In theano, I remember printing values from symbolic code was not easy.\r\n\r\nCan someone point me how to print values in the function that is passed to 'grad' ? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/171", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/171/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/171/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/171/events", "html_url": "https://github.com/twitter/torch-autograd/issues/171", "id": 202969965, "node_id": "MDU6SXNzdWUyMDI5Njk5NjU=", "number": 171, "title": "Autogradient of function cannot handle batched forward-prop", "user": {"login": "NaimKabir", "id": 4506277, "node_id": "MDQ6VXNlcjQ1MDYyNzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/4506277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NaimKabir", "html_url": "https://github.com/NaimKabir", "followers_url": "https://api.github.com/users/NaimKabir/followers", "following_url": "https://api.github.com/users/NaimKabir/following{/other_user}", "gists_url": "https://api.github.com/users/NaimKabir/gists{/gist_id}", "starred_url": "https://api.github.com/users/NaimKabir/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NaimKabir/subscriptions", "organizations_url": "https://api.github.com/users/NaimKabir/orgs", "repos_url": "https://api.github.com/users/NaimKabir/repos", "events_url": "https://api.github.com/users/NaimKabir/events{/privacy}", "received_events_url": "https://api.github.com/users/NaimKabir/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-01-24T23:22:25Z", "updated_at": "2017-01-25T16:51:19Z", "closed_at": "2017-01-25T16:51:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "First of all, autograd is great. Thanks for building it! Makes convoluted nets much easier to write and understand.\r\n\r\nAnyway:\r\n\r\nTo drill down on my issue in it's simplest case:\r\n\r\nI'll create two simple neural nets below:\r\n\r\n```\r\nlookupfunc, lookuplayers = g.model.NeuralNetwork({\r\n    inputFeatures = 1,\r\n    hiddenFeatures = {64},\r\n    activations = 'Identity',\r\n    classifier = false,\r\n    dropoutProbs = {0}\r\n    })\r\n\r\npredictfunc, predictlayers = g.model.NeuralNetwork({\r\n    inputFeatures = 640,\r\n    hiddenFeatures = {1},\r\n    activations = 'Identity',\r\n    classifier = false,\r\n    dropoutProbs = {0}\r\n    })\r\n```\r\nThe first net can take in a number and map it to a 64-column Tensor.\r\nThe second net can take a 640-column Tensor and map it to a single value answer.\r\nOk.\r\n\r\nIn the function that I'll want to apply the autograd to, I want to use the 'lookupfunc' like I do in the following code block. This isn't actually what I'm doing, just the simplest case I can think of :(\r\n```\r\ninput = torch.Tensor{1,2,3,4,5,6,7,8,9,10}\r\nweights = {lookuplayers = lookuplayers, predictlayers = predictlayers}\r\ncriterion = somefunction()\r\n\r\n\r\nfunction forwardpropagation(weights, input, truth)\r\n\r\n    vec = lookupfunc(weights.lookuplayers, torch.Tensor{input}) --This is the problem area! Because I'm batching forward propagation and giving these layers 10 separate inputs at once, this thing returns a 10x64 Tensor.\r\n\r\n    vec = vec:resize(640) --just getting this into a form that can be taken in by the second net\r\n    \r\n     prediction = predictfunc(weights.predictlayers, vec) --This returns the single number answer\r\n\r\n     loss = criterion(prediction, truth)\r\n\r\n    return loss\r\nend\r\n\r\n```\r\nForward propagation works fine, and I get a loss.\r\nNow, when I try to do:\r\n\r\n```\r\ndeltas = autograd(forwardpropagation)\r\n\r\ndeltas(weights, input, truth)\r\n\r\n```\r\n\r\nIt breaks and returns this stacktrace:\r\n\r\n```\r\n        [C]: in function 'addmm'\r\n       ~ /.luarocks/share/lua/5.1/nn/Linear.lua:86: in function 'updateGradInput'\r\n        ~/.luarocks/share/lua/5.1/nn/Module.lua:31: in function 'backward'\r\n        ~/.luarocks/share/lua/5.1/autograd/nnwrapper.lua:222: in function 'nodeApply'\r\n        ~/.luarocks/share/lua/5.1/autograd/nnwrapper.lua:239: in function <~/.luarocks/share/lua/5.1/autograd/nnwrapper.lua:237>\r\n        ...cks/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:186: in function 'gradOnly'\r\n        ...cks/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:229: in function 'deltas'\r\n\r\n```\r\n\r\nWhat I noticed after printing out lines inside 'DirectTape' was that it was trying to I think compute gradients for a 10x64 matrix of weights. My hunch is that it got confused by my batch forward propagation when I did this:\r\n`\r\n    vec = lookupfunc(weights.lookuplayers, torch.Tensor{input}) --This returns a 10x64 Tensor\r\n    `\r\n\r\nAnd I confirmed that hunch by instead using a for-loop to substitute that step with this:\r\n\r\n```\r\nvec = {}\r\nfor element = 1, input:size()[1] do\r\n     table.insert(vec, lookupfunc(weights.lookuplayers, input[element]))\r\nend\r\nvec = torch.cat(vec, 2)\r\n```\r\n\r\nThis works fine and doesn't confuse AutoGrad at all. However the slowdown seems pretty significant compared to doing a batch forward prop through the layers, so it would be great to be able to fix the autograd issue.\r\n\r\nAny support with this strange problem would be appreciated! Thank you.\r\n\r\nEDIT:\r\n\r\nDigging further into where autograd fails (line 186 of DirectTape):\r\n\r\n`  local gradUpdate = (node.gradFun[iarg])(node.outgrad, node.value, table.unpack(node.argValues))`\r\n\r\nI've found that the 'node' object that's created for the result of this batch operation has \r\n\r\n- a `node.outgrad` of dimensionality that agrees with my initially defined weights, \r\n- a `node.value `that does NOT agree with the `node.outgrad` and instead has as many rows as I had batched inputs\r\n- an unpacked `node.argValues` that list the proper weights, but as an input it's listing the full list of batched inputs!\r\n\r\nI think the dimensionality disagreements between `node.outgrad` and `node.value` are the cause of the problem, since on function calls of `(node.gradFun[iarg])` where it works, those properties always agree.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/168", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/168/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/168/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/168/events", "html_url": "https://github.com/twitter/torch-autograd/issues/168", "id": 198624089, "node_id": "MDU6SXNzdWUxOTg2MjQwODk=", "number": 168, "title": "ABS still not implemented error but ABS code is actually there? ", "user": {"login": "synchro--", "id": 5878714, "node_id": "MDQ6VXNlcjU4Nzg3MTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/5878714?v=4", "gravatar_id": "", "url": "https://api.github.com/users/synchro--", "html_url": "https://github.com/synchro--", "followers_url": "https://api.github.com/users/synchro--/followers", "following_url": "https://api.github.com/users/synchro--/following{/other_user}", "gists_url": "https://api.github.com/users/synchro--/gists{/gist_id}", "starred_url": "https://api.github.com/users/synchro--/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/synchro--/subscriptions", "organizations_url": "https://api.github.com/users/synchro--/orgs", "repos_url": "https://api.github.com/users/synchro--/repos", "events_url": "https://api.github.com/users/synchro--/events{/privacy}", "received_events_url": "https://api.github.com/users/synchro--/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-01-04T03:41:13Z", "updated_at": "2017-01-07T14:04:53Z", "closed_at": "2017-01-07T14:04:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "Fixed.  \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/160", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/160/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/160/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/160/events", "html_url": "https://github.com/twitter/torch-autograd/issues/160", "id": 184489520, "node_id": "MDU6SXNzdWUxODQ0ODk1MjA=", "number": 160, "title": "Reusable AutoModule's", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-10-21T13:48:48Z", "updated_at": "2016-10-21T22:31:31Z", "closed_at": "2016-10-21T22:31:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm learning to use autograd. I tried to have a simple reusable module:\n\n``` lua\nautograd = require 'autograd'\n\nfunction pdist(embeddings)\n    local pdist = torch.mm(embeddings, embeddings:t())\n    local norm = pdist:diag():view(pdist:size(1), 1):expandAs(pdist)\n    return pdist:mul(-2.0):add(norm):add(norm:t()):sqrt()\nend\n\n\nautograd.nn.AutoModule('AutoPairwiseL2')(pdist)\nm = autograd.auto.AutoPairwiseL2() -- fails \n\ninput = torch.rand(50, 128)\nprint((pdist(input) - m:forward(input)):abs():sum())\n```\n\nIt fails with:\n\n```\nfunction: 0x40bd8900\n...wigwam/prefix/bin/luajit: ...wigwam/prefix/share/lua/5.1/autograd/auto/AutoModule.lua:22: An autograd function must be specified as input to AutoModule\nstack traceback:\n        [C]: in function 'error'\n        ...wigwam/prefix/share/lua/5.1/autograd/auto/AutoModule.lua:22: in function '__init'\n        ...a_gpu101_105/.wigwam/prefix/share/lua/5.1/torch/init.lua:91: in function <...a_gpu101_105/.wigwam/prefix/share/lua/5.1/torch/init.lua:87>\n        [C]: in function 'AutoPairwiseL2'\n        test.lua:11: in main chunk\n        [C]: in function 'dofile'\n        ...105/.wigwam/prefix/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n        [C]: at 0x00410a40\n```\n\nThe example starts working if instead I use: `m = autograd.nn.AutoModule('AutoPairwiseL2')(pdist)`. I thought that after I made the AutoModule call, the module will be registered along with its forward function for further usage, but it seems that I have to pass the forward function every time. Am I missing anything?\n\nThanks!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/159", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/159/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/159/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/159/events", "html_url": "https://github.com/twitter/torch-autograd/issues/159", "id": 184486973, "node_id": "MDU6SXNzdWUxODQ0ODY5NzM=", "number": 159, "title": "\"torch.DoubleTensor.t not currently supported\". Workarounds?", "user": {"login": "vadimkantorov", "id": 1041752, "node_id": "MDQ6VXNlcjEwNDE3NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1041752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vadimkantorov", "html_url": "https://github.com/vadimkantorov", "followers_url": "https://api.github.com/users/vadimkantorov/followers", "following_url": "https://api.github.com/users/vadimkantorov/following{/other_user}", "gists_url": "https://api.github.com/users/vadimkantorov/gists{/gist_id}", "starred_url": "https://api.github.com/users/vadimkantorov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vadimkantorov/subscriptions", "organizations_url": "https://api.github.com/users/vadimkantorov/orgs", "repos_url": "https://api.github.com/users/vadimkantorov/repos", "events_url": "https://api.github.com/users/vadimkantorov/events{/privacy}", "received_events_url": "https://api.github.com/users/vadimkantorov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-10-21T13:38:27Z", "updated_at": "2016-10-25T22:54:05Z", "closed_at": "2016-10-21T22:45:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying a toy example of auto-differentiated pairwise L2 distances module:\n\n``` lua\nrequire 'nn'\nautograd = require 'autograd'\n\nfunction pdist(embeddings)\n    local pdist = torch.mm(embeddings, embeddings:t())\n    local norm = pdist:diag():view(pdist:size(1), 1):expandAs(pdist)\n    return pdist:mul(-2.0):add(norm):add(norm:t()):sqrt()\nend\n\nm = autograd.nn.AutoModule('AutoPairwiseL2')(pdist)\n\nprint(nn.Jacobian.testJacobian(m, torch.rand(50, 128)))\n```\n\nUnfortunately it breaks:\n\n```\nfunction: 0x41b0ef00\n...fix/bin/luajit: ...fix/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:50: function torch.DoubleTensor.t not currently supported by autograd\nstack traceback:\n        [C]: in function 'error'\n        ...fix/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:50: in function 't'\n        test.lua:5: in function 'fun'\n        ...fix/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:112: in function 'funOnly'\n        ...fix/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:218: in function 'b'\n        ...wigwam/prefix/share/lua/5.1/autograd/auto/AutoModule.lua:52: in function 'updateGradInput'\n        ..._gpu101_105/.wigwam/prefix/share/lua/5.1/nn/Jacobian.lua:21: in function 'backward'\n        ..._gpu101_105/.wigwam/prefix/share/lua/5.1/nn/Jacobian.lua:235: in function 'testJacobian'\n        test.lua:12: in main chunk\n        [C]: in function 'dofile'\n        ...105/.wigwam/prefix/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n        [C]: at 0x00410a40\n```\n\nAny workarounds suggested?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/157", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/157/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/157/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/157/events", "html_url": "https://github.com/twitter/torch-autograd/issues/157", "id": 182173211, "node_id": "MDU6SXNzdWUxODIxNzMyMTE=", "number": 157, "title": "\"Failed to parse generated code\"", "user": {"login": "abdullahjamal", "id": 17014198, "node_id": "MDQ6VXNlcjE3MDE0MTk4", "avatar_url": "https://avatars0.githubusercontent.com/u/17014198?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abdullahjamal", "html_url": "https://github.com/abdullahjamal", "followers_url": "https://api.github.com/users/abdullahjamal/followers", "following_url": "https://api.github.com/users/abdullahjamal/following{/other_user}", "gists_url": "https://api.github.com/users/abdullahjamal/gists{/gist_id}", "starred_url": "https://api.github.com/users/abdullahjamal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abdullahjamal/subscriptions", "organizations_url": "https://api.github.com/users/abdullahjamal/orgs", "repos_url": "https://api.github.com/users/abdullahjamal/repos", "events_url": "https://api.github.com/users/abdullahjamal/events{/privacy}", "received_events_url": "https://api.github.com/users/abdullahjamal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-10-11T04:47:11Z", "updated_at": "2017-12-16T09:54:15Z", "closed_at": "2016-10-24T02:43:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\nI'm having problem running a loss function using torch-autograd. A snippet of the code is given below.\nLoss function is defined as \nlocal autoEntropy = grad.nn.AutoCriterion('AutoEntropy')(entropy)\nlocal autoMMD = grad.nn.AutoCriterion('AutoMMD')(mmd)\ncriterion:add(class_loss):add(autoEntropy):add(loss1)\nwhere loss1 is loss1:add(autoMMD) in the loop.  \ncriterion and loss1 are nn.ParallelCriterion() and model is defined by simple nn model.\nlocal output = model:forward({traindata,unlabeldata})\nlocal err = criterion:forward(cr_inputs,targets)\nlocal gradout = criterion:backward(cr_inputs,targets)\nlocal gradInput = model:backward({traindata,unlabeldata}, gradout)\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/153", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/153/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/153/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/153/events", "html_url": "https://github.com/twitter/torch-autograd/issues/153", "id": 175900911, "node_id": "MDU6SXNzdWUxNzU5MDA5MTE=", "number": 153, "title": "discrepency between licenses", "user": {"login": "korymath", "id": 178099, "node_id": "MDQ6VXNlcjE3ODA5OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/178099?v=4", "gravatar_id": "", "url": "https://api.github.com/users/korymath", "html_url": "https://github.com/korymath", "followers_url": "https://api.github.com/users/korymath/followers", "following_url": "https://api.github.com/users/korymath/following{/other_user}", "gists_url": "https://api.github.com/users/korymath/gists{/gist_id}", "starred_url": "https://api.github.com/users/korymath/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/korymath/subscriptions", "organizations_url": "https://api.github.com/users/korymath/orgs", "repos_url": "https://api.github.com/users/korymath/repos", "events_url": "https://api.github.com/users/korymath/events{/privacy}", "received_events_url": "https://api.github.com/users/korymath/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-09-09T00:52:14Z", "updated_at": "2016-09-10T17:56:47Z", "closed_at": "2016-09-10T17:56:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Project has an Apache 2.0 license file: https://github.com/twitter/torch-autograd/blob/master/LICENSE\n\nRockspec lists license as MIT, which shows up on the luarocks make command.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/149", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/149/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/149/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/149/events", "html_url": "https://github.com/twitter/torch-autograd/issues/149", "id": 171340965, "node_id": "MDU6SXNzdWUxNzEzNDA5NjU=", "number": 149, "title": "autograd initialization error", "user": {"login": "eladrich", "id": 7377266, "node_id": "MDQ6VXNlcjczNzcyNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/7377266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eladrich", "html_url": "https://github.com/eladrich", "followers_url": "https://api.github.com/users/eladrich/followers", "following_url": "https://api.github.com/users/eladrich/following{/other_user}", "gists_url": "https://api.github.com/users/eladrich/gists{/gist_id}", "starred_url": "https://api.github.com/users/eladrich/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eladrich/subscriptions", "organizations_url": "https://api.github.com/users/eladrich/orgs", "repos_url": "https://api.github.com/users/eladrich/repos", "events_url": "https://api.github.com/users/eladrich/events{/privacy}", "received_events_url": "https://api.github.com/users/eladrich/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-08-16T07:16:43Z", "updated_at": "2016-08-16T10:55:11Z", "closed_at": "2016-08-16T10:55:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "When trying to load autograd (require 'autograd'), the following error raises:\n\n`...ser/torch-workspace/install/share/lua/5.1/trepl/init.lua:363: ...ser/torch-workspace/install/share/lua/5.1/trepl/init.lua:363: ...-workspace/install/share/lua/5.1/autograd/optim/init.lua:27: bad argument #1 to 'pairs' (table expected, got boolean)\nstack traceback:\n    [C]: in function 'error'\n    ...ser/torch-workspace/install/share/lua/5.1/trepl/init.lua:363: in function 'require'\n    [string \"_RESULT={require 'autograd'}\"]:1: in main chunk\n    [C]: in function 'xpcall'\n    ...ser/torch-workspace/install/share/lua/5.1/trepl/init.lua:630: in function 'repl'\n    ...-workspace/install/lib/luarocks/rocks/trepl/scm-1/bin/th:185: in main chunk\n    [C]: at 0x00406240`\n\nI'm successfully working with autograd on a different machine (really awesome project!), so my guess is that I have some other package is out of date, or has changed.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/144", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/144/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/144/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/144/events", "html_url": "https://github.com/twitter/torch-autograd/issues/144", "id": 167215040, "node_id": "MDU6SXNzdWUxNjcyMTUwNDA=", "number": 144, "title": "Stop gradients", "user": {"login": "ikostrikov", "id": 1212494, "node_id": "MDQ6VXNlcjEyMTI0OTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1212494?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ikostrikov", "html_url": "https://github.com/ikostrikov", "followers_url": "https://api.github.com/users/ikostrikov/followers", "following_url": "https://api.github.com/users/ikostrikov/following{/other_user}", "gists_url": "https://api.github.com/users/ikostrikov/gists{/gist_id}", "starred_url": "https://api.github.com/users/ikostrikov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ikostrikov/subscriptions", "organizations_url": "https://api.github.com/users/ikostrikov/orgs", "repos_url": "https://api.github.com/users/ikostrikov/repos", "events_url": "https://api.github.com/users/ikostrikov/events{/privacy}", "received_events_url": "https://api.github.com/users/ikostrikov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-07-24T03:33:16Z", "updated_at": "2016-07-24T15:59:39Z", "closed_at": "2016-07-24T15:59:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thanks for this awesome library!\n\nI wonder if it is possible to stop gradients in a subgraph? I'm looking for something similar to https://www.tensorflow.org/versions/r0.9/api_docs/python/train.html#stop_gradient\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/134", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/134/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/134/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/134/events", "html_url": "https://github.com/twitter/torch-autograd/issues/134", "id": 162994184, "node_id": "MDU6SXNzdWUxNjI5OTQxODQ=", "number": 134, "title": "GPU support", "user": {"login": "Zealcui", "id": 4536739, "node_id": "MDQ6VXNlcjQ1MzY3Mzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/4536739?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zealcui", "html_url": "https://github.com/Zealcui", "followers_url": "https://api.github.com/users/Zealcui/followers", "following_url": "https://api.github.com/users/Zealcui/following{/other_user}", "gists_url": "https://api.github.com/users/Zealcui/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zealcui/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zealcui/subscriptions", "organizations_url": "https://api.github.com/users/Zealcui/orgs", "repos_url": "https://api.github.com/users/Zealcui/repos", "events_url": "https://api.github.com/users/Zealcui/events{/privacy}", "received_events_url": "https://api.github.com/users/Zealcui/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-06-29T18:26:28Z", "updated_at": "2016-06-29T19:17:36Z", "closed_at": "2016-06-29T19:17:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello folks,\n\nRecently I'm working on a project using torch-autograd. When data size becomes large, it takes a lot more time to train. I'm trying to run our code on GPU and found no information related to switch torch-autograd into GPU mode. \n\nAny ideas?\n\nThanks!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/129", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/129/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/129/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/129/events", "html_url": "https://github.com/twitter/torch-autograd/issues/129", "id": 158564534, "node_id": "MDU6SXNzdWUxNTg1NjQ1MzQ=", "number": 129, "title": "{optimize  = true} doesn't work with closures (even without updating variables)?", "user": {"login": "oal17", "id": 19672031, "node_id": "MDQ6VXNlcjE5NjcyMDMx", "avatar_url": "https://avatars3.githubusercontent.com/u/19672031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oal17", "html_url": "https://github.com/oal17", "followers_url": "https://api.github.com/users/oal17/followers", "following_url": "https://api.github.com/users/oal17/following{/other_user}", "gists_url": "https://api.github.com/users/oal17/gists{/gist_id}", "starred_url": "https://api.github.com/users/oal17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oal17/subscriptions", "organizations_url": "https://api.github.com/users/oal17/orgs", "repos_url": "https://api.github.com/users/oal17/repos", "events_url": "https://api.github.com/users/oal17/events{/privacy}", "received_events_url": "https://api.github.com/users/oal17/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-06-05T17:21:34Z", "updated_at": "2016-06-07T17:39:33Z", "closed_at": "2016-06-07T17:39:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "I see that there's some new documentation re optimized derivatives in the readme, but I don't see how it applies to examples like this one:\n\n``` lua\nlocal d = require \"autograd\"\n\nfunction test()\n    local net = nn.Sequential()\n        :add(nn.Linear(2, 1))\n        :add(nn.Sigmoid())\n\n    local netFn, netParams = d.functionalize(net) \n\n    local f = function(x)\n        return torch.sum(netFn(netParams, x))\n    end\n\n    --WORKS WITH NO OPTIMIZATION\n    local x = torch.rand(1, 2) \n    local df = d.grad(f)\n    local dx = df(x)\n\n    --WORKS WITH OPTIMIZATION AND NO CLOSURE\n    local g = function(x, ps)\n        return torch.sum(netFn(ps, x))\n    end\n    local dg = d.grad(g)\n    local dx = dg(x, netParams)\n\n    --FAILS WITH OPITMIZATION AND CLOSURE \n    local dfOptimized = d.grad(f, {optimize = true})\n    local dxOptimized = dfOptimized(x)\nend\n```\n\nWith the closure, the optimized version gives this error and generated code:\n\n```\nreturn function(locals, rlocals, vlocals, objects)\nlocal nn = require('autograd').nn\nlocal util = require('autograd.util')\nlocal util_fillInPlace = util.fillInPlace\nlocal torch_sum = torch.sum\nlocal model = model\nreturn function(p1)\n    locals[1] = objects[1].forward({ 0.4047  0.6308\n[torch.DoubleTensor of size 1x2]\n, 0.01 *\n-9.2744\n[torch.DoubleTensor of size 1]\n}, p1)\n    locals[2] = objects[1].backward((util_fillInPlace(rlocals[1], locals[1], 1)), { 0.4047  0.6308\n[torch.DoubleTensor of size 1x2]\n, 0.01 *\n-9.2744\n[torch.DoubleTensor of size 1]\n}, p1)\n    locals[3] = torch_sum(locals[1])\n    return locals[2][2], locals[3]\nend\nend\n\n[string \"return function(locals, rlocals, vlocals, obj...\"]:8: '}' expected near '0.6308'\n```\n\nNot sure if this is an inherent issue with the optimized version of  `grad`, or if there is a way around it, but thought I would check. Thanks!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/125", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/125/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/125/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/125/events", "html_url": "https://github.com/twitter/torch-autograd/issues/125", "id": 156473371, "node_id": "MDU6SXNzdWUxNTY0NzMzNzE=", "number": 125, "title": "Better documentation about optimization", "user": {"login": "mys007", "id": 5921083, "node_id": "MDQ6VXNlcjU5MjEwODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/5921083?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mys007", "html_url": "https://github.com/mys007", "followers_url": "https://api.github.com/users/mys007/followers", "following_url": "https://api.github.com/users/mys007/following{/other_user}", "gists_url": "https://api.github.com/users/mys007/gists{/gist_id}", "starred_url": "https://api.github.com/users/mys007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mys007/subscriptions", "organizations_url": "https://api.github.com/users/mys007/orgs", "repos_url": "https://api.github.com/users/mys007/repos", "events_url": "https://api.github.com/users/mys007/events{/privacy}", "received_events_url": "https://api.github.com/users/mys007/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-05-24T10:29:24Z", "updated_at": "2016-06-01T20:07:34Z", "closed_at": "2016-06-01T20:07:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "The principle of optimization and the differences to the non-optimized mode should be better documented. I think the most important is the fact that the closure of the optimized (=compiled) function seems to be sealed at the moment of optimization, so for example this:\n\n```\nlocal v = 1\nlocal f = function(params, x, y) return torch.sum(params.W[1]*v) end\n```\n\nwon't reflect later changes of `v` once `f` is compiled, although it _does_ reflect the changes if optimization is turned off. On the other hand, changes to variables passed as arguments seem to be always reflected\n\n```\nlocal f = function(params, x, y, v) return torch.sum(params.W[1]*v) end\n```\n\nMoreover, there seems to be some effect on the functionality of `nn`-modules, although I didn't have the time to isolate the cases yet.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/123", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/123/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/123/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/123/events", "html_url": "https://github.com/twitter/torch-autograd/issues/123", "id": 156180107, "node_id": "MDU6SXNzdWUxNTYxODAxMDc=", "number": 123, "title": "util.makeContiguous", "user": {"login": "mys007", "id": 5921083, "node_id": "MDQ6VXNlcjU5MjEwODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/5921083?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mys007", "html_url": "https://github.com/mys007", "followers_url": "https://api.github.com/users/mys007/followers", "following_url": "https://api.github.com/users/mys007/following{/other_user}", "gists_url": "https://api.github.com/users/mys007/gists{/gist_id}", "starred_url": "https://api.github.com/users/mys007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mys007/subscriptions", "organizations_url": "https://api.github.com/users/mys007/orgs", "repos_url": "https://api.github.com/users/mys007/repos", "events_url": "https://api.github.com/users/mys007/events{/privacy}", "received_events_url": "https://api.github.com/users/mys007/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-05-22T23:43:19Z", "updated_at": "2016-05-24T14:05:22Z", "closed_at": "2016-05-24T14:05:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am confused by the meaning of `util.makeContiguous` and its gradient being defined as `zeroGradient()`. There is also `torch.contiguous()` doing IMHO the same job, but having gradient `function(g,ans,x) return g end`. I have a strong feeling this is wrong. I have noticed this when trying to figure out why there is no backpropagation through `torch.view()`. I suggest `util.makeContiguous` get removed completely.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/120", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/120/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/120/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/120/events", "html_url": "https://github.com/twitter/torch-autograd/issues/120", "id": 153919491, "node_id": "MDU6SXNzdWUxNTM5MTk0OTE=", "number": 120, "title": "How to create a module to behave like a simple activation function?", "user": {"login": "dlmacedo", "id": 15001116, "node_id": "MDQ6VXNlcjE1MDAxMTE2", "avatar_url": "https://avatars2.githubusercontent.com/u/15001116?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dlmacedo", "html_url": "https://github.com/dlmacedo", "followers_url": "https://api.github.com/users/dlmacedo/followers", "following_url": "https://api.github.com/users/dlmacedo/following{/other_user}", "gists_url": "https://api.github.com/users/dlmacedo/gists{/gist_id}", "starred_url": "https://api.github.com/users/dlmacedo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dlmacedo/subscriptions", "organizations_url": "https://api.github.com/users/dlmacedo/orgs", "repos_url": "https://api.github.com/users/dlmacedo/repos", "events_url": "https://api.github.com/users/dlmacedo/events{/privacy}", "received_events_url": "https://api.github.com/users/dlmacedo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-05-10T04:00:42Z", "updated_at": "2016-05-12T03:11:21Z", "closed_at": "2016-05-12T03:11:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "Dear Friends,\n\nI would like to create a module with automodule to behave like just a simple activation function. No weight or bias to learn.\n\nWhat is wrong with  the code below:\n\n```\nlocal SeLU  = function(input)\n  local output \n  if input < -0.5 then\n    output = 0.5*y\n  elseif (input >= -0.5) and (input <= 0.5) then\n    output = 1.0*y\n  else\n    output = 0.5*y\n  end \n  return output\nend\n\nlocal autoSeLU = autograd.nn.AutoModule('AutoSeLU')(SeLU)\n\nlocal vgg = nn.Sequential()\n-- building block\nlocal function ConvBNReLU(nInputPlane, nOutputPlane)\n  vgg:add(nn.SpatialConvolution(nInputPlane, nOutputPlane, 3,3, 1,1, 1,1))\n  vgg:add(nn.SpatialBatchNormalization(nOutputPlane,1e-3))\n  vgg:add(autoSeLU)\n\n  return vgg\nend\n\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/119", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/119/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/119/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/119/events", "html_url": "https://github.com/twitter/torch-autograd/issues/119", "id": 153883854, "node_id": "MDU6SXNzdWUxNTM4ODM4NTQ=", "number": 119, "title": "Is it possible to use autograd.nn.AutoModule but not autograd.nn.AutoCriterion?", "user": {"login": "dlmacedo", "id": 15001116, "node_id": "MDQ6VXNlcjE1MDAxMTE2", "avatar_url": "https://avatars2.githubusercontent.com/u/15001116?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dlmacedo", "html_url": "https://github.com/dlmacedo", "followers_url": "https://api.github.com/users/dlmacedo/followers", "following_url": "https://api.github.com/users/dlmacedo/following{/other_user}", "gists_url": "https://api.github.com/users/dlmacedo/gists{/gist_id}", "starred_url": "https://api.github.com/users/dlmacedo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dlmacedo/subscriptions", "organizations_url": "https://api.github.com/users/dlmacedo/orgs", "repos_url": "https://api.github.com/users/dlmacedo/repos", "events_url": "https://api.github.com/users/dlmacedo/events{/privacy}", "received_events_url": "https://api.github.com/users/dlmacedo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-05-09T22:25:03Z", "updated_at": "2016-05-10T03:43:26Z", "closed_at": "2016-05-10T03:43:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Dear Friend,\n\nIs it possible to create a personalized model with autograd.nn.AutoModule but keeping using the standard criterions of torch, avoid using autograd.nn.AutoCriterion?\n\nThanks,\n\nDavid\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/115", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/115/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/115/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/115/events", "html_url": "https://github.com/twitter/torch-autograd/issues/115", "id": 151856727, "node_id": "MDU6SXNzdWUxNTE4NTY3Mjc=", "number": 115, "title": "sigmoid operating on tensors only", "user": {"login": "tuananhle7", "id": 15041137, "node_id": "MDQ6VXNlcjE1MDQxMTM3", "avatar_url": "https://avatars1.githubusercontent.com/u/15041137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tuananhle7", "html_url": "https://github.com/tuananhle7", "followers_url": "https://api.github.com/users/tuananhle7/followers", "following_url": "https://api.github.com/users/tuananhle7/following{/other_user}", "gists_url": "https://api.github.com/users/tuananhle7/gists{/gist_id}", "starred_url": "https://api.github.com/users/tuananhle7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tuananhle7/subscriptions", "organizations_url": "https://api.github.com/users/tuananhle7/orgs", "repos_url": "https://api.github.com/users/tuananhle7/repos", "events_url": "https://api.github.com/users/tuananhle7/events{/privacy}", "received_events_url": "https://api.github.com/users/tuananhle7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-04-29T12:40:01Z", "updated_at": "2016-04-29T15:13:52Z", "closed_at": "2016-04-29T15:13:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Running\n\n```\ngrad = require 'autograd'\nparams = {w = 1}\nf = function(params, x)\n   return torch.sigmoid(params.w * x)\nend\ndf = grad(f, {optimize = true})\ndparams, loss = df(params, 2)\n```\n\nproduces\n\n```\n/Users/tuananhle/torch/install/bin/luajit: invalid arguments: number number\nexpected arguments: [*DoubleTensor*] DoubleTensor DoubleTensor\nstack traceback:\n    [C]: at 0x0fc48540\n    [C]: in function 'fn'\n    .../install/share/lua/5.1/autograd/runtime/codegen/Node.lua:72: in function 'evaluateForward'\n    ...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:25: in function 'cmul'\n    ...nanhle/torch/install/share/lua/5.1/autograd/gradfuns.lua:554: in function <...nanhle/torch/install/share/lua/5.1/autograd/gradfuns.lua:553>\n    .../install/share/lua/5.1/autograd/runtime/codegen/Node.lua:127: in function 'evaluateBackward'\n    ...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:370: in function 'protectedFn'\n    ...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:383: in function 'record'\n    .../install/share/lua/5.1/autograd/runtime/codegen/init.lua:44: in function 'generateFn'\n    .../install/share/lua/5.1/autograd/runtime/codegen/init.lua:140: in function 'df'\n    test.lua:14: in main chunk\n    [C]: in function 'dofile'\n    ...nhle/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n    [C]: at 0x010f7debc0\n```\n\npointing to an error at [gradfuns.lua:554](https://github.com/twitter/torch-autograd/blob/master/src/gradfuns.lua#L553), while \n\n```\ngrad = require 'autograd'\nparams = {w = torch.Tensor{1}}\nf = function(params, x)\n    return torch.sigmoid(torch.cmul(params.w, x))[1]\nend\ndf = grad(f, {optimize = true})\ndparams, loss = df(params, torch.Tensor{2})\n```\n\nworks fine.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/113", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/113/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/113/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/113/events", "html_url": "https://github.com/twitter/torch-autograd/issues/113", "id": 151351751, "node_id": "MDU6SXNzdWUxNTEzNTE3NTE=", "number": 113, "title": "Wrong error message due to operation overloading", "user": {"login": "albanD", "id": 6359743, "node_id": "MDQ6VXNlcjYzNTk3NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6359743?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albanD", "html_url": "https://github.com/albanD", "followers_url": "https://api.github.com/users/albanD/followers", "following_url": "https://api.github.com/users/albanD/following{/other_user}", "gists_url": "https://api.github.com/users/albanD/gists{/gist_id}", "starred_url": "https://api.github.com/users/albanD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albanD/subscriptions", "organizations_url": "https://api.github.com/users/albanD/orgs", "repos_url": "https://api.github.com/users/albanD/repos", "events_url": "https://api.github.com/users/albanD/events{/privacy}", "received_events_url": "https://api.github.com/users/albanD/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-04-27T10:24:57Z", "updated_at": "2016-05-03T17:43:47Z", "closed_at": "2016-05-03T17:43:47Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "There is a slight unexpected behaviour in the operation overloading on numbers done [here](https://github.com/twitter/torch-autograd/blob/master/src/support.lua#L65-L87) \n\nIf we try to add (same with mul and sub) something that does not have an `__add` in its metatable to a number, we get to an infinite recursion leading to a stack overflow.\nBelow is an example using nil.\n\n``` lua\nlocal function add(a,b)\n    return a + b\nend\n\nlocal ok, res = pcall(add, nil, 2)\nprint(res)\n-- a.lua:2: attempt to perform arithmetic on local 'a' (a nil value)\n\nrequire 'autograd'\n\nlocal ok, res = pcall(add, nil, 2)\nprint(res)\n-- ...e/alban/torch/install/share/lua/5.1/autograd/support.lua:67: stack overflow\n```\n\nThis could be solve by checking whether or not the first element has the proper function in its metatable before calling `a+b` [here](https://github.com/twitter/torch-autograd/blob/master/src/support.lua#L70). Do you guys think there would be a better way to solve this? I can prepare a PR if you agree with the proposed fix.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/112", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/112/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/112/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/112/events", "html_url": "https://github.com/twitter/torch-autograd/issues/112", "id": 151334832, "node_id": "MDU6SXNzdWUxNTEzMzQ4MzI=", "number": 112, "title": "Torch.gt autograd fails", "user": {"login": "DmitryUlyanov", "id": 6727524, "node_id": "MDQ6VXNlcjY3Mjc1MjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/6727524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DmitryUlyanov", "html_url": "https://github.com/DmitryUlyanov", "followers_url": "https://api.github.com/users/DmitryUlyanov/followers", "following_url": "https://api.github.com/users/DmitryUlyanov/following{/other_user}", "gists_url": "https://api.github.com/users/DmitryUlyanov/gists{/gist_id}", "starred_url": "https://api.github.com/users/DmitryUlyanov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DmitryUlyanov/subscriptions", "organizations_url": "https://api.github.com/users/DmitryUlyanov/orgs", "repos_url": "https://api.github.com/users/DmitryUlyanov/repos", "events_url": "https://api.github.com/users/DmitryUlyanov/events{/privacy}", "received_events_url": "https://api.github.com/users/DmitryUlyanov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-04-27T09:06:52Z", "updated_at": "2016-05-23T17:10:17Z", "closed_at": "2016-05-23T17:10:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, here is the code, I try. \n\n```\nfunction Lab2RGB(input, weight, bias)\n\nlocal M,N = input:size(2),input:size(3)\n\nlocal L = torch.narrow(input, 1,1,1)\nlocal a = torch.narrow(input, 1,2,1)\nlocal b = torch.narrow(input, 1,3,1)\n\nL = L:view(1,M*N)\na = a:view(1,M*N)\nb = b:view(1,M*N)\n\nlocal T1 = 0.008856\nlocal T2 = 0.206893\n\n\n-- Compute Y\nlocal  fY = torch.pow((L + 16) / 116, 3)\nlocal  YT = torch.gt(fY, T1):double()\nfY = torch.cmul((1-YT), (L / 903.3)) + torch.cmul(YT,fY)\nY = fY\nreturn Y\nend\n```\n\nI get this error on `module:backward()`: \n\n```\n/home/lidl/torch/install/share/lua/5.1/cutorch/Tensor.lua:13: calling 'nElement' on bad self (torch.ByteTensor expected, got boolean)\n```\n\nFirst, it is very strange that the exception is at `cutorch/Tensor.lua`, I did not require 'cutorch' at all. It looks like the problem is in `torch.gt` grad. Any ways to overcome this? Thank you.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/111", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/111/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/111/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/111/events", "html_url": "https://github.com/twitter/torch-autograd/issues/111", "id": 149921019, "node_id": "MDU6SXNzdWUxNDk5MjEwMTk=", "number": 111, "title": "torch.bmm", "user": {"login": "szagoruyko", "id": 4953728, "node_id": "MDQ6VXNlcjQ5NTM3Mjg=", "avatar_url": "https://avatars3.githubusercontent.com/u/4953728?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szagoruyko", "html_url": "https://github.com/szagoruyko", "followers_url": "https://api.github.com/users/szagoruyko/followers", "following_url": "https://api.github.com/users/szagoruyko/following{/other_user}", "gists_url": "https://api.github.com/users/szagoruyko/gists{/gist_id}", "starred_url": "https://api.github.com/users/szagoruyko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szagoruyko/subscriptions", "organizations_url": "https://api.github.com/users/szagoruyko/orgs", "repos_url": "https://api.github.com/users/szagoruyko/repos", "events_url": "https://api.github.com/users/szagoruyko/events{/privacy}", "received_events_url": "https://api.github.com/users/szagoruyko/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-04-21T00:17:05Z", "updated_at": "2016-07-07T20:22:10Z", "closed_at": "2016-07-07T20:22:10Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi, I can't find bmm anywhere, is it not supported? Any plans to add it?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/110", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/110/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/110/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/110/events", "html_url": "https://github.com/twitter/torch-autograd/issues/110", "id": 149476872, "node_id": "MDU6SXNzdWUxNDk0NzY4NzI=", "number": 110, "title": "dot product in autograd", "user": {"login": "pdakwal", "id": 17278624, "node_id": "MDQ6VXNlcjE3Mjc4NjI0", "avatar_url": "https://avatars0.githubusercontent.com/u/17278624?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pdakwal", "html_url": "https://github.com/pdakwal", "followers_url": "https://api.github.com/users/pdakwal/followers", "following_url": "https://api.github.com/users/pdakwal/following{/other_user}", "gists_url": "https://api.github.com/users/pdakwal/gists{/gist_id}", "starred_url": "https://api.github.com/users/pdakwal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pdakwal/subscriptions", "organizations_url": "https://api.github.com/users/pdakwal/orgs", "repos_url": "https://api.github.com/users/pdakwal/repos", "events_url": "https://api.github.com/users/pdakwal/events{/privacy}", "received_events_url": "https://api.github.com/users/pdakwal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-04-19T14:27:01Z", "updated_at": "2016-04-19T14:32:47Z", "closed_at": "2016-04-19T14:32:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi all,\nIs dot product not yet supported by autograd. I am calling torch.dot(h1,h2) in gradient function. It gives me error 'dot product not yet supported by autograd'. If not, is there any workaround for this ?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/109", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/109/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/109/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/109/events", "html_url": "https://github.com/twitter/torch-autograd/issues/109", "id": 149426297, "node_id": "MDU6SXNzdWUxNDk0MjYyOTc=", "number": 109, "title": "attempt to call field 'nDimension' (a nil value)", "user": {"login": "tuananhle7", "id": 15041137, "node_id": "MDQ6VXNlcjE1MDQxMTM3", "avatar_url": "https://avatars1.githubusercontent.com/u/15041137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tuananhle7", "html_url": "https://github.com/tuananhle7", "followers_url": "https://api.github.com/users/tuananhle7/followers", "following_url": "https://api.github.com/users/tuananhle7/following{/other_user}", "gists_url": "https://api.github.com/users/tuananhle7/gists{/gist_id}", "starred_url": "https://api.github.com/users/tuananhle7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tuananhle7/subscriptions", "organizations_url": "https://api.github.com/users/tuananhle7/orgs", "repos_url": "https://api.github.com/users/tuananhle7/repos", "events_url": "https://api.github.com/users/tuananhle7/events{/privacy}", "received_events_url": "https://api.github.com/users/tuananhle7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-04-19T11:04:59Z", "updated_at": "2016-04-19T11:12:11Z", "closed_at": "2016-04-19T11:09:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "This happens to me when at\nhttps://github.com/twitter/torch-autograd/blob/master/src/model/RecurrentLSTMNetwork.lua#L25\n\nwhen I run\n\n```\nmodel = require 'autograd.model'\nlstm, params = model.RecurrentLSTMNetwork({\n    inputFeatures = 10,\n    hiddenFeatures =10,\n    outputType = 'all',})\nlstm(params[1], torch.rand(2, 10), {})\n```\n\nPlease let me know if this is the right place to post noob issues like these.\nPS: I just updated Torch and Torch Autograd today.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/106", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/106/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/106/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/106/events", "html_url": "https://github.com/twitter/torch-autograd/issues/106", "id": 148224739, "node_id": "MDU6SXNzdWUxNDgyMjQ3Mzk=", "number": 106, "title": "Didn't catch an unsupported torch:copy / wrong gradient computation", "user": {"login": "as1986", "id": 539843, "node_id": "MDQ6VXNlcjUzOTg0Mw==", "avatar_url": "https://avatars0.githubusercontent.com/u/539843?v=4", "gravatar_id": "", "url": "https://api.github.com/users/as1986", "html_url": "https://github.com/as1986", "followers_url": "https://api.github.com/users/as1986/followers", "following_url": "https://api.github.com/users/as1986/following{/other_user}", "gists_url": "https://api.github.com/users/as1986/gists{/gist_id}", "starred_url": "https://api.github.com/users/as1986/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/as1986/subscriptions", "organizations_url": "https://api.github.com/users/as1986/orgs", "repos_url": "https://api.github.com/users/as1986/repos", "events_url": "https://api.github.com/users/as1986/events{/privacy}", "received_events_url": "https://api.github.com/users/as1986/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-04-14T01:21:57Z", "updated_at": "2016-04-29T18:48:43Z", "closed_at": "2016-04-29T15:20:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When I do this:\n\n``` lua\nparams = {W={torch.DoubleTensor(4,2):fill(2),torch.DoubleTensor(4,2):fill(3)}}\ninp = torch.DoubleTensor(4):fill(1)\n\nmy_func = function(params, inp)\n    local s = params.W[1].new(params.W[1]:size(1), params.W[1]:size(2))\n    torch.copy(s, params.W[1])\n    return torch.sum(s) + torch.sum(params.W[2]) + torch.sum(inp)\nend\ndf = autograd(my_func, {optimize=false})\ngrad, loss =df(params, z)\n```\n\nI get grad.W[1] as a zero matrix (should be a matrix filled with 1). I think torch.copy is not yet supported but this is somehow not caught.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/104", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/104/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/104/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/104/events", "html_url": "https://github.com/twitter/torch-autograd/issues/104", "id": 146668503, "node_id": "MDU6SXNzdWUxNDY2Njg1MDM=", "number": 104, "title": "\"Failed to parse generated code\"", "user": {"login": "xq111", "id": 18042883, "node_id": "MDQ6VXNlcjE4MDQyODgz", "avatar_url": "https://avatars1.githubusercontent.com/u/18042883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xq111", "html_url": "https://github.com/xq111", "followers_url": "https://api.github.com/users/xq111/followers", "following_url": "https://api.github.com/users/xq111/following{/other_user}", "gists_url": "https://api.github.com/users/xq111/gists{/gist_id}", "starred_url": "https://api.github.com/users/xq111/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xq111/subscriptions", "organizations_url": "https://api.github.com/users/xq111/orgs", "repos_url": "https://api.github.com/users/xq111/repos", "events_url": "https://api.github.com/users/xq111/events{/privacy}", "received_events_url": "https://api.github.com/users/xq111/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-04-07T15:58:59Z", "updated_at": "2016-04-09T15:42:28Z", "closed_at": "2016-04-09T15:42:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've gotten this error a few times - is there a way to pin down what might be causing it? I've put code and generated code for a toy example that illustrates the issue below. \n\nGenerated code:\n\n```\nreturn function(locals, rlocals, vlocals)\nlocal nn = require('autograd').nn\nlocal util = require('autograd.util')\nlocal torch_pow = torch.pow\nlocal torch_sum = torch.sum\nlocal torch_t = torch.t\nlocal util_fillInPlace = util.fillInPlace\nlocal torch_mm = torch.mm\nlocal torch_transpose = torch.transpose\nreturn function(p1, p2, p3)\n    locals[1] = torch_transpose(p2[1], 1, 2)\n    torch_mm(rlocals[1], p1[1], locals[1])\n    locals[2] = torch_sum(rlocals[1])\n    locals[3] = -locals[2]\n    locals[4] = p3 + locals[3]\n    locals[5] = -1\n    locals[6] = 2 + locals[5]\n    locals[7] = torch_pow(locals[4], locals[6])\n    locals[8] = 2 * locals[7]\n    locals[9] = -locals[8]\n    util_fillInPlace(rlocals[2], rlocals[1], locals[9])\n    locals[10] = torch_t(locals[1])\n    torch_mm(rlocals[3], rlocals[2], locals[10])\n    locals[11] = locals[4]  2\n    return {\n        [1] = rlocals[3],\n    }, locals[11]\nend\nend\n```\n\nCode:\n\n```\nlocal ag = require \"autograd\"\n\nlocal params = {}\nfor i = 1,5 do\n    params[i] = torch.randn(1,2)\nend\n\nfunction mkLst(params, inp)\n    local lst = {}\n    for i = 1,#inp do\n        lst[i] = {}\n        for __, r in ipairs(params) do\n            lst[i][#lst[i] + 1] = torch.sum(r * torch.transpose(inp[i], 1, 2))\n        end\n    end\n    return lst\nend\n\nfunction computeLoss(params, inp, target)\n    local lst = mkLst(params, inp)\n    return (target - lst[1][1])^2\nend\n\nfunction test()\n    local inp = {}\n    for i = 1,10 do inp[i] = torch.rand(1, 2) end\n\n    local fwd = computeLoss(params, inp, 1)\n    print(fwd)\n    print(\"+++++++++++++++++++++++++++++++++++++++\")\n    local dLoss = ag.grad(computeLoss, {optimize = true, inline = false})\n    local dparams, loss = dLoss(params, inp, 1)\nend\ntest()\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/101", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/101/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/101/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/101/events", "html_url": "https://github.com/twitter/torch-autograd/issues/101", "id": 144067177, "node_id": "MDU6SXNzdWUxNDQwNjcxNzc=", "number": 101, "title": "Trouble with assignment", "user": {"login": "xq111", "id": 18042883, "node_id": "MDQ6VXNlcjE4MDQyODgz", "avatar_url": "https://avatars1.githubusercontent.com/u/18042883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xq111", "html_url": "https://github.com/xq111", "followers_url": "https://api.github.com/users/xq111/followers", "following_url": "https://api.github.com/users/xq111/following{/other_user}", "gists_url": "https://api.github.com/users/xq111/gists{/gist_id}", "starred_url": "https://api.github.com/users/xq111/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xq111/subscriptions", "organizations_url": "https://api.github.com/users/xq111/orgs", "repos_url": "https://api.github.com/users/xq111/repos", "events_url": "https://api.github.com/users/xq111/events{/privacy}", "received_events_url": "https://api.github.com/users/xq111/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-03-28T19:53:57Z", "updated_at": "2017-11-24T12:49:09Z", "closed_at": "2016-04-04T17:38:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm getting an error in some code involving assignment, which I would have thought the January update would have fixed. \n\nHere's a little bit of code that shows the problem\n\n```\nlocal ag = require \"autograd\"\n\nlocal params = {w1 = torch.randn(1), w2 = torch.randn(1)}\n\nfunction f(params)\n    local t = torch.zeros(2)\n    t[1] = torch.sum(params.w1)\n    t[2] = torch.sum(params.w2)\n    return ag.nn.Max(1)(t)[1]\nend\n\nfunction test()\n    local df = ag.grad(f)\n    local dParams, err = df(params)\n    print(err)\nend\n\ntest()\n```\n\nThis gives the error:\n\n```\nbad argument #3 to '?' (torch.*Tensor expected, got table)\n```\n\nAny tips for what to change? Thanks!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/100", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/100/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/100/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/100/events", "html_url": "https://github.com/twitter/torch-autograd/issues/100", "id": 143829447, "node_id": "MDU6SXNzdWUxNDM4Mjk0NDc=", "number": 100, "title": "error defining a new loss function?", "user": {"login": "cheng6076", "id": 5053575, "node_id": "MDQ6VXNlcjUwNTM1NzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/5053575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cheng6076", "html_url": "https://github.com/cheng6076", "followers_url": "https://api.github.com/users/cheng6076/followers", "following_url": "https://api.github.com/users/cheng6076/following{/other_user}", "gists_url": "https://api.github.com/users/cheng6076/gists{/gist_id}", "starred_url": "https://api.github.com/users/cheng6076/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cheng6076/subscriptions", "organizations_url": "https://api.github.com/users/cheng6076/orgs", "repos_url": "https://api.github.com/users/cheng6076/repos", "events_url": "https://api.github.com/users/cheng6076/events{/privacy}", "received_events_url": "https://api.github.com/users/cheng6076/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-03-27T17:17:01Z", "updated_at": "2016-04-03T09:56:36Z", "closed_at": "2016-04-03T09:56:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, my goal is simply to define a new error function with autograd. I tested the following example\n\n``` lua\nrequire 'nn'\ngrad = require 'autograd'\nlocal mse = function(input, target) \n    local buffer = input-target\n    return torch.sum( torch.cmul(buffer, buffer) ) / (input:dim() == 2 and input:size(1)*input:size(2) or input:size(1))\nend\nlocal autoMseCriterion = grad.nn.AutoCriterion('AutoMSE')(mse)\n```\n\nbut got the following error: \n\n> while creating metatable autograd.nn.criterion.AutMSE: bad argument #1 (autograd is an invalid module name)\n\nCan anyone help me? Thanks!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/97", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/97/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/97/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/97/events", "html_url": "https://github.com/twitter/torch-autograd/issues/97", "id": 142032000, "node_id": "MDU6SXNzdWUxNDIwMzIwMDA=", "number": 97, "title": "Binary Classifier experiment - log loss", "user": {"login": "andrewcz", "id": 2296335, "node_id": "MDQ6VXNlcjIyOTYzMzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/2296335?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrewcz", "html_url": "https://github.com/andrewcz", "followers_url": "https://api.github.com/users/andrewcz/followers", "following_url": "https://api.github.com/users/andrewcz/following{/other_user}", "gists_url": "https://api.github.com/users/andrewcz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrewcz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrewcz/subscriptions", "organizations_url": "https://api.github.com/users/andrewcz/orgs", "repos_url": "https://api.github.com/users/andrewcz/repos", "events_url": "https://api.github.com/users/andrewcz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrewcz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-03-19T06:06:53Z", "updated_at": "2016-03-21T17:58:16Z", "closed_at": "2016-03-21T17:58:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\nFantastic Library!\nI was just wondering, i am trying to use the library for a binary classifier experiment using the log loss function to train the model. This is for a university experiment around benchmarking different models. Would you have time to provide an example of how to use the library to achieve the above goal.\nAlso, with an included visualisation on how the model learns.\nMany thanks,\nBest,\nAndrew\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/95", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/95/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/95/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/95/events", "html_url": "https://github.com/twitter/torch-autograd/issues/95", "id": 140603254, "node_id": "MDU6SXNzdWUxNDA2MDMyNTQ=", "number": 95, "title": "Grad for cmin and cmax", "user": {"login": "yongfei25", "id": 1611276, "node_id": "MDQ6VXNlcjE2MTEyNzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1611276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongfei25", "html_url": "https://github.com/yongfei25", "followers_url": "https://api.github.com/users/yongfei25/followers", "following_url": "https://api.github.com/users/yongfei25/following{/other_user}", "gists_url": "https://api.github.com/users/yongfei25/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongfei25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongfei25/subscriptions", "organizations_url": "https://api.github.com/users/yongfei25/orgs", "repos_url": "https://api.github.com/users/yongfei25/repos", "events_url": "https://api.github.com/users/yongfei25/events{/privacy}", "received_events_url": "https://api.github.com/users/yongfei25/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-03-14T08:08:04Z", "updated_at": "2016-03-16T16:15:11Z", "closed_at": "2016-03-16T13:08:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\n\nCould we have `cmin` and `cmax` function supported :) ?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/94", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/94/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/94/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/94/events", "html_url": "https://github.com/twitter/torch-autograd/issues/94", "id": 139964831, "node_id": "MDU6SXNzdWUxMzk5NjQ4MzE=", "number": 94, "title": "Implementing a siamese loss function", "user": {"login": "vbalnt", "id": 3127970, "node_id": "MDQ6VXNlcjMxMjc5NzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/3127970?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vbalnt", "html_url": "https://github.com/vbalnt", "followers_url": "https://api.github.com/users/vbalnt/followers", "following_url": "https://api.github.com/users/vbalnt/following{/other_user}", "gists_url": "https://api.github.com/users/vbalnt/gists{/gist_id}", "starred_url": "https://api.github.com/users/vbalnt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vbalnt/subscriptions", "organizations_url": "https://api.github.com/users/vbalnt/orgs", "repos_url": "https://api.github.com/users/vbalnt/repos", "events_url": "https://api.github.com/users/vbalnt/events{/privacy}", "received_events_url": "https://api.github.com/users/vbalnt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-03-10T17:56:59Z", "updated_at": "2016-03-10T21:14:46Z", "closed_at": "2016-03-10T21:14:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi I have been trying to implement a Siamese kind of loss function, but I cant figure out how to compute the embeddings for two different inputs inside the autograd function\n\nHere is what I am trying to do \n\n``` lua\nt = require 'torch'\ngrad = require 'autograd'\nrequire 'cutorch'\nrequire 'cunn'\nrequire 'cudnn'\n\nlocal model = nn.Sequential()\nmodel:add(cudnn.SpatialConvolution(1, 16, 3, 3))\nmodel:add(cudnn.Tanh())\nmodel:add(nn.Reshape(16*30*30))\nmodel:add(nn.Linear(16*30*30, 128))\nmodel:add(cudnn.Tanh())\nmodel:cuda()\n\nlocal modelf, params = grad.functionalize(model)\n\nneuralNet = function(params, x)\n   local x1 = x[1]\n   local x2 = x[2]\n\n   local h = modelf(params, x1)\n   local h2 = modelf(params, x2)\n   return torch.sum(torch.abs(h-h2))\nend\n\ndneuralNet = grad(neuralNet)\n\ntt = torch.rand(1,1,32,32):cuda()\ntt2 = torch.rand(1,1,32,32):cuda()\n\ndparams, loss = dneuralNet(params, {tt,tt2})\nprint(loss)\n```\n\nThis does not work since `h==h2`, so loss comes out 0\n\nIs there any way to do something similar?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/93", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/93/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/93/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/93/events", "html_url": "https://github.com/twitter/torch-autograd/issues/93", "id": 139610697, "node_id": "MDU6SXNzdWUxMzk2MTA2OTc=", "number": 93, "title": "Failed to parse generated code", "user": {"login": "yongfei25", "id": 1611276, "node_id": "MDQ6VXNlcjE2MTEyNzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1611276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongfei25", "html_url": "https://github.com/yongfei25", "followers_url": "https://api.github.com/users/yongfei25/followers", "following_url": "https://api.github.com/users/yongfei25/following{/other_user}", "gists_url": "https://api.github.com/users/yongfei25/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongfei25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongfei25/subscriptions", "organizations_url": "https://api.github.com/users/yongfei25/orgs", "repos_url": "https://api.github.com/users/yongfei25/repos", "events_url": "https://api.github.com/users/yongfei25/events{/privacy}", "received_events_url": "https://api.github.com/users/yongfei25/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-03-09T15:36:43Z", "updated_at": "2016-03-17T17:59:14Z", "closed_at": "2016-03-17T17:59:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\n\nI'm having problem running with optimized enabled. \nI print out the error of `loadstring/load` function in `init.lua`, here's the error. \n\n```\n[string \"return function(locals, rlocals, vlocals, mod...\"]:634: function at line 38 has more than 60 upvalues  \n/home/yongfei/torch/install/bin/luajit: ...re/lua/5.1/autograd/runtime/codegen/backend/lua/init.lua:760: failed to parse generated code\n```\n\nAnd here's the generated code.\n\nhttps://gist.github.com/yongfei25/8992651ec5fd55805b7f\n\nThe error above was running on CPU, when I try on GPU, got\n\n```\n/home/ubuntu/lib/torch/install/bin/luajit: ...nstall/share/lua/5.1/autograd/runtime/codegen/Source.lua:35: invalid value (table) at index 1 in table for 'concat'\nstack traceback:\n    [C]: in function 'concat'\n    ...nstall/share/lua/5.1/autograd/runtime/codegen/Source.lua:35: in function 'symbolPath'\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/92", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/92/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/92/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/92/events", "html_url": "https://github.com/twitter/torch-autograd/issues/92", "id": 136877816, "node_id": "MDU6SXNzdWUxMzY4Nzc4MTY=", "number": 92, "title": "support to torch.FloatTensor.view", "user": {"login": "EderSantana", "id": 3902480, "node_id": "MDQ6VXNlcjM5MDI0ODA=", "avatar_url": "https://avatars3.githubusercontent.com/u/3902480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EderSantana", "html_url": "https://github.com/EderSantana", "followers_url": "https://api.github.com/users/EderSantana/followers", "following_url": "https://api.github.com/users/EderSantana/following{/other_user}", "gists_url": "https://api.github.com/users/EderSantana/gists{/gist_id}", "starred_url": "https://api.github.com/users/EderSantana/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EderSantana/subscriptions", "organizations_url": "https://api.github.com/users/EderSantana/orgs", "repos_url": "https://api.github.com/users/EderSantana/repos", "events_url": "https://api.github.com/users/EderSantana/events{/privacy}", "received_events_url": "https://api.github.com/users/EderSantana/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2016-02-27T04:33:15Z", "updated_at": "2016-03-08T00:54:47Z", "closed_at": "2016-03-07T18:39:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\n\nThanks for this really interesting module!\n\nI'd like to try a contribution to torch-autograd. `torch.FloatTensor.view` isn't supported yet but I believe it can be pretty useful. \nMy first goal was to calculate a set of pairwise distances between the rows of two matrices. In python that would be\n\n``` python\nsq = ((X[:, None, :] - Z)**2).sum(-1)\n```\n\nI was trying the same in Torch with following code:\n\n``` lua\nlocal x = X:view(X:size(1), 1, X:size(2))\n x = x:expand(X:size(1), X:size(2), X:size(2))\nlocal z = Z:view(Z:size(1), Z:size(2), 1)\nz = z:expandAs(x)\nlocal diffs = torch.sum(x - z, 3)\nlocal sq = torch.cmul(diffs, diffs)\n```\n\nBut autograd doesn't support `torch.view` yet. But I believe that `view` only reshapes the gradient, without needing any extra operations. The same should happen to `expand`. \n\nSo, my question is, could guys either tell me how I can contribute with support to `view` or suggest me another way to get the `sq` matrix above?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/91", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/91/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/91/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/91/events", "html_url": "https://github.com/twitter/torch-autograd/issues/91", "id": 135892552, "node_id": "MDU6SXNzdWUxMzU4OTI1NTI=", "number": 91, "title": "Incorrect gradfun for torch.RepeatTensor", "user": {"login": "OptimusLime", "id": 1204790, "node_id": "MDQ6VXNlcjEyMDQ3OTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1204790?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OptimusLime", "html_url": "https://github.com/OptimusLime", "followers_url": "https://api.github.com/users/OptimusLime/followers", "following_url": "https://api.github.com/users/OptimusLime/following{/other_user}", "gists_url": "https://api.github.com/users/OptimusLime/gists{/gist_id}", "starred_url": "https://api.github.com/users/OptimusLime/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OptimusLime/subscriptions", "organizations_url": "https://api.github.com/users/OptimusLime/orgs", "repos_url": "https://api.github.com/users/OptimusLime/repos", "events_url": "https://api.github.com/users/OptimusLime/events{/privacy}", "received_events_url": "https://api.github.com/users/OptimusLime/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-02-23T22:56:46Z", "updated_at": "2016-03-07T17:21:36Z", "closed_at": "2016-03-07T17:20:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "I cannot submit a pull request right now, but there is an issue using torch.RepeatTensor with non-double tensors. \n\nWithin the gradient function for torch.RepeatTensor in [gradfuns.lua](https://github.com/twitter/torch-autograd/blob/master/src/gradfuns.lua#L503), torch.cat is called but this is incorrect for non-double tensors. \n\nThe correct module should call util.cat. The new module would be: \n\n``` lua\n module.gradient(\"repeatTensor\", {\n      function(g, ans, x, ...)\n         local Dg = torch.nDimension(g)\n         local Dx = torch.nDimension(x)\n         for i=Dx,1,-1 do\n            local D = torch.nDimension(g)\n            local c = util.cat(torch.split(g,torch.size(x,i), Dg-Dx+i), D+1)\n            g = torch.squeeze(torch.sum(c,D+1))\n         end\n         for i=1,Dg-Dx do\n            g = torch.squeeze(torch.sum(g,1))\n         end\n         return g\n      end,\n      function(g, ans, ...) return nil end,\n      function(g, ans, ...) return nil end,\n      function(g, ans, ...) return nil end,\n      function(g, ans, ...) return nil end,\n      function(g, ans, ...) return nil end, -- five dimensions should be enough\n   })\n```\n\nTo expose the error, you can augment the RepeatTensor test to include a cuda tensor as input: \n\n``` lua\n   RepeatTensor = function()\n      local function f2to2(params)\n         local y = torch.repeatTensor(params.x, 2, 2)*3\n         return torch.sum(y)\n      end\n      tester:assert(gradcheck(f2to2, {x=torch.randn(3,3)}), \"Incorrect gradient\")\n\n      local function f3to3(params)\n         local y = torch.repeatTensor(params.x, 2, 2, 2)*3\n         return torch.sum(y)\n      end\n      tester:assert(gradcheck(f3to3, {x=torch.randn(3,3,3)}), \"Incorrect gradient\")\n\n      local function f2to3(params)\n         local y = torch.repeatTensor(params.x, 2, 2, 2)*3\n         return torch.sum(y)\n      end\n      tester:assert(gradcheck(f2to3, {x=torch.randn(3,3)}), \"Incorrect gradient\")\n\n      local function f3to4(params)\n         local y = torch.repeatTensor(params.x, 2, 2, 2, 2)*3\n         return torch.sum(y)\n      end\n      tester:assert(gradcheck(f3to4, {x=torch.randn(3,3,3)}), \"Incorrect gradient\")\n\n\n      local function f4to5(params)\n         local y = torch.repeatTensor(params.x, 2, 2, 2, 2)*3\n         return torch.sum(y)\n      end\n\n      tester:assert(autograd(f4to5)({x=torch.randn(3,3,3):cuda()}))\n\n\n      -- tester:assert(gradcheck(f3to4, {x=torch.randn(3,3,3):float()}), \"Incorrect gradient\")\n   end,\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/88", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/88/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/88/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/88/events", "html_url": "https://github.com/twitter/torch-autograd/issues/88", "id": 128054300, "node_id": "MDU6SXNzdWUxMjgwNTQzMDA=", "number": 88, "title": "\"expected FloatTensor in tensor array\" error", "user": {"login": "as1986", "id": 539843, "node_id": "MDQ6VXNlcjUzOTg0Mw==", "avatar_url": "https://avatars0.githubusercontent.com/u/539843?v=4", "gravatar_id": "", "url": "https://api.github.com/users/as1986", "html_url": "https://github.com/as1986", "followers_url": "https://api.github.com/users/as1986/followers", "following_url": "https://api.github.com/users/as1986/following{/other_user}", "gists_url": "https://api.github.com/users/as1986/gists{/gist_id}", "starred_url": "https://api.github.com/users/as1986/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/as1986/subscriptions", "organizations_url": "https://api.github.com/users/as1986/orgs", "repos_url": "https://api.github.com/users/as1986/repos", "events_url": "https://api.github.com/users/as1986/events{/privacy}", "received_events_url": "https://api.github.com/users/as1986/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2016-01-22T00:31:53Z", "updated_at": "2016-01-22T20:20:17Z", "closed_at": "2016-01-22T20:18:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "After pulling the latest commits I am running into the following error on the LSTM example:\n[string \"return function(locals, rlocals, vlocals, cri...\"]:254: expected FloatTensor in tensor array\nstack traceback:\n    [C]: in function 'torch_FloatTensor_cat'\n    [string \"return function(locals, rlocals, vlocals, cri...\"]:254: in function 'df'\n    train-penn-lstm.lua:183: in main chunk\n    [C]: in function 'dofile'\n    ....edu/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n    [C]: at 0x00405b50\n\nSimilar errors also occur when I changed to the CUDA backend. What has gone wrong?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/84", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/84/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/84/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/84/events", "html_url": "https://github.com/twitter/torch-autograd/issues/84", "id": 127552028, "node_id": "MDU6SXNzdWUxMjc1NTIwMjg=", "number": 84, "title": "Support assignment", "user": {"login": "alexbw", "id": 161935, "node_id": "MDQ6VXNlcjE2MTkzNQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexbw", "html_url": "https://github.com/alexbw", "followers_url": "https://api.github.com/users/alexbw/followers", "following_url": "https://api.github.com/users/alexbw/following{/other_user}", "gists_url": "https://api.github.com/users/alexbw/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexbw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexbw/subscriptions", "organizations_url": "https://api.github.com/users/alexbw/orgs", "repos_url": "https://api.github.com/users/alexbw/repos", "events_url": "https://api.github.com/users/alexbw/events{/privacy}", "received_events_url": "https://api.github.com/users/alexbw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-01-19T22:17:43Z", "updated_at": "2016-01-21T19:54:37Z", "closed_at": "2016-01-21T19:54:37Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "It's annoying to not be able to assign values to tensors. For example, we don't support any operations that look like\n\n``` lua\nx[i] = y\n```\n\nWe can easily support this via a utility, like\n\n``` lua\nx = util.set(x, i, y)\n```\n\nwhich will return a new wrapped value that we can track. However, using the built-in `__newindex` and `__index` syntax is a great deal more convenient. We have some ideas cooking up on how to support this. Just need a gradient for `__newindex`, and then some bookkeeping magic.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/81", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/81/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/81/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/81/events", "html_url": "https://github.com/twitter/torch-autograd/issues/81", "id": 126801860, "node_id": "MDU6SXNzdWUxMjY4MDE4NjA=", "number": 81, "title": "Error on Require autograd", "user": {"login": "adamw005", "id": 12405150, "node_id": "MDQ6VXNlcjEyNDA1MTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/12405150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamw005", "html_url": "https://github.com/adamw005", "followers_url": "https://api.github.com/users/adamw005/followers", "following_url": "https://api.github.com/users/adamw005/following{/other_user}", "gists_url": "https://api.github.com/users/adamw005/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamw005/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamw005/subscriptions", "organizations_url": "https://api.github.com/users/adamw005/orgs", "repos_url": "https://api.github.com/users/adamw005/repos", "events_url": "https://api.github.com/users/adamw005/events{/privacy}", "received_events_url": "https://api.github.com/users/adamw005/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2016-01-15T03:37:13Z", "updated_at": "2016-03-07T15:45:27Z", "closed_at": "2016-03-07T15:45:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm getting this error when trying to use autograd.  I used 'luarocks install autograd' to install it.\n\nSo far I've tried:\n- reinstalling with luarocks remove autograd \n- luarocks install optim\n\n```\nth> grad = require 'autograd'\n/home/ubuntu/torch/install/share/lua/5.1/trepl/init.lua:363: /home/ubuntu/torch/install/share/lua/5.1/trepl/init.lua:363: /home/ubuntu/torch/install/share/lua/5.1/trepl/init.lua:363: ...buntu/torch/install/share/lua/5.1/autograd/nnwrapper.lua:297: bad argument #1 to 'pairs' (table expected, got boolean)\nstack traceback:\n        [C]: in function 'error'\n        /home/ubuntu/torch/install/share/lua/5.1/trepl/init.lua:363: in function 'require'\n        [string \"grad = require 'autograd'\"]:1: in main chunk\n        [C]: in function 'xpcall'\n        /home/ubuntu/torch/install/share/lua/5.1/trepl/init.lua:648: in function 'repl'\n        ...untu/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:185: in main chunk\n        [C]: at 0x00406670\n```\n\nLink: [nnwrapper.lua:297](https://github.com/twitter/torch-autograd/blob/master/src/nnwrapper.lua#L297)\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/79", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/79/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/79/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/79/events", "html_url": "https://github.com/twitter/torch-autograd/issues/79", "id": 126206638, "node_id": "MDU6SXNzdWUxMjYyMDY2Mzg=", "number": 79, "title": "Error \"attempt to compare number with table\" when parameters involved in comparison", "user": {"login": "m-hahn", "id": 16668233, "node_id": "MDQ6VXNlcjE2NjY4MjMz", "avatar_url": "https://avatars3.githubusercontent.com/u/16668233?v=4", "gravatar_id": "", "url": "https://api.github.com/users/m-hahn", "html_url": "https://github.com/m-hahn", "followers_url": "https://api.github.com/users/m-hahn/followers", "following_url": "https://api.github.com/users/m-hahn/following{/other_user}", "gists_url": "https://api.github.com/users/m-hahn/gists{/gist_id}", "starred_url": "https://api.github.com/users/m-hahn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/m-hahn/subscriptions", "organizations_url": "https://api.github.com/users/m-hahn/orgs", "repos_url": "https://api.github.com/users/m-hahn/repos", "events_url": "https://api.github.com/users/m-hahn/events{/privacy}", "received_events_url": "https://api.github.com/users/m-hahn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-01-12T15:40:26Z", "updated_at": "2016-01-14T22:28:13Z", "closed_at": "2016-01-14T22:28:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I would like to differentiate functions involving Bernoulli trials whose probabilities depend on the parameters, where I would like the result of the trial to be treated as a constant by the differentiation.\nThe following code, which tries to do that, raises \"attempt to compare number with table\":\n\n```\nt = require 'torch'\ngrad = require 'autograd'\n\nparams = {\n   a = t.randn(1,1)\n}\n\nf = function(params, x)\n   local result = t.sum(x * params.a)\n\n   -- sample from Bernoulli dist\n   local bernoulli = torch.FloatTensor(1):zero()\n   if torch.uniform() < t.sum(params.a) then\n         bernoulli[1] = 1\n   end\n\n   return t.sum(bernoulli * result)\nend\n\ndf = grad(f)\n\nx = t.randn(1,1)\n\nprint(f(params, x))\n\nprint(df(params, x))\n```\n\nReplacing the `if` block by `decision[1] = t.bernoulli(t.sum(params.a))`, which should do the same thing, also raises an error. Replacing the condition by `0.5 < t.sum(params.a)` does not eliminate the error, which seems to show that the problem is not the use of random numbers.\n\nIs there a way to tell autograd not to try to differentiate through comparisons and instead treat the resulting truth values as constants (which is possible in Theano)?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/77", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/77/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/77/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/77/events", "html_url": "https://github.com/twitter/torch-autograd/issues/77", "id": 125270709, "node_id": "MDU6SXNzdWUxMjUyNzA3MDk=", "number": 77, "title": "Elementwise assignments of intermediate tensors (based on parameter-dependent values)", "user": {"login": "andreaskoepf", "id": 9976399, "node_id": "MDQ6VXNlcjk5NzYzOTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/9976399?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andreaskoepf", "html_url": "https://github.com/andreaskoepf", "followers_url": "https://api.github.com/users/andreaskoepf/followers", "following_url": "https://api.github.com/users/andreaskoepf/following{/other_user}", "gists_url": "https://api.github.com/users/andreaskoepf/gists{/gist_id}", "starred_url": "https://api.github.com/users/andreaskoepf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andreaskoepf/subscriptions", "organizations_url": "https://api.github.com/users/andreaskoepf/orgs", "repos_url": "https://api.github.com/users/andreaskoepf/repos", "events_url": "https://api.github.com/users/andreaskoepf/events{/privacy}", "received_events_url": "https://api.github.com/users/andreaskoepf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-01-06T21:46:40Z", "updated_at": "2016-01-21T15:45:12Z", "closed_at": "2016-01-15T01:50:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "I would like to calculate my scalar result based on intermediate tensors that are filled with parameter-dependent values. An example would be to generate a rotation matrix from axis and angle parameters while being interested in the gradient w.r.t. axis and angle...\n\nUnfortunately even the simplest things I try fail as soon as my input parameters are 'passed' through intermediate tensors. It seems as if autograd treats my intermediate tensors simply as constants which do not depend on the parameters but actually all of their elements are assigned from computations that are functions of the parameters...\n\nTrivial example: \n\n```\nfunction f(W)\n  local x = torch.zeros(1)\n  x[1] = torch.sin(W[1])\n  return torch.sum(torch.abs(x))\nend\ndf = grad(f)\ndparams, loss = df(torch.ones(1))\n```\n\nFails with `A node type was not returned. This is either because a gradient was not defined, or the input is independent of the output`...\n\nIs the related to https://github.com/twitter/torch-autograd/issues/3 and new-index not being implemented yet or is this deliberately not supported?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/76", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/76/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/76/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/76/events", "html_url": "https://github.com/twitter/torch-autograd/issues/76", "id": 125093652, "node_id": "MDU6SXNzdWUxMjUwOTM2NTI=", "number": 76, "title": "error when importing the library after installing it", "user": {"login": "mansimov", "id": 1727860, "node_id": "MDQ6VXNlcjE3Mjc4NjA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1727860?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mansimov", "html_url": "https://github.com/mansimov", "followers_url": "https://api.github.com/users/mansimov/followers", "following_url": "https://api.github.com/users/mansimov/following{/other_user}", "gists_url": "https://api.github.com/users/mansimov/gists{/gist_id}", "starred_url": "https://api.github.com/users/mansimov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mansimov/subscriptions", "organizations_url": "https://api.github.com/users/mansimov/orgs", "repos_url": "https://api.github.com/users/mansimov/repos", "events_url": "https://api.github.com/users/mansimov/events{/privacy}", "received_events_url": "https://api.github.com/users/mansimov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-01-06T01:59:29Z", "updated_at": "2016-01-06T03:29:57Z", "closed_at": "2016-01-06T03:29:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am getting this error when calling `require autograd` after installing it.\n\n```\ntorch/install/share/lua/5.1/trepl/init.lua:363: torch/install/share/lua/5.1/trepl/init.lua:363: ...nsim/torch/install/share/lua/5.1/autograd/optim/init.lua:27: bad argument #1 to 'pairs' (table expected, got boolean)\nstack traceback:\n    [C]: in function 'error'\n    torch/install/share/lua/5.1/trepl/init.lua:363: in function 'require'\n    [string \"_RESULT={require 'autograd'}\"]:1: in main chunk\n    [C]: in function 'xpcall'\n    torch/install/share/lua/5.1/trepl/init.lua:630: in function 'repl'\n    ...nsim/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:185: in main chunk\n    [C]: at 0x00406240\n```\n\nanyone has any idea what causes the problem ?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/74", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/74/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/74/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/74/events", "html_url": "https://github.com/twitter/torch-autograd/issues/74", "id": 124283792, "node_id": "MDU6SXNzdWUxMjQyODM3OTI=", "number": 74, "title": "A node type was not returned. This is either because a gradient was not defined, or the input is independent of the output", "user": {"login": "jarmstrong2", "id": 7797083, "node_id": "MDQ6VXNlcjc3OTcwODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/7797083?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jarmstrong2", "html_url": "https://github.com/jarmstrong2", "followers_url": "https://api.github.com/users/jarmstrong2/followers", "following_url": "https://api.github.com/users/jarmstrong2/following{/other_user}", "gists_url": "https://api.github.com/users/jarmstrong2/gists{/gist_id}", "starred_url": "https://api.github.com/users/jarmstrong2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jarmstrong2/subscriptions", "organizations_url": "https://api.github.com/users/jarmstrong2/orgs", "repos_url": "https://api.github.com/users/jarmstrong2/repos", "events_url": "https://api.github.com/users/jarmstrong2/events{/privacy}", "received_events_url": "https://api.github.com/users/jarmstrong2/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2015-12-29T23:45:57Z", "updated_at": "2016-01-06T18:16:02Z", "closed_at": "2016-01-04T18:18:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am basically mimicking your example code for autocriterion, but with my own function, but i get an error, here is the function in question:\n\n```\nautograd = require 'autograd'\n\nlocal cmd = torch.CmdLine()\n\ncmd:text()\ncmd:text('Script for training model.')\n\ncmd:option('-inputSize' , 61, 'number of input dimension')\ncmd:option('-dimSize' , 2, 'dim size for U')\ncmd:option('-batchSize' , 4, 'mini batch size')\ncmd:option('-numMixture' , 10, 'number of mixture components in output layer')\n\ncmd:text()\nopt = cmd:parse(arg)\n\nfunction logDet(matrix)\n    output = torch.zeros(opt.batchSize, 1)\n    for i = 1, opt.batchSize do\n        eig_vals = (torch.eig(matrix[i], 'N'))\n        output[i] = (torch.log(eig_vals:select(2, 1))):sum()\n    end\n    return output\nend\n\nfunction inverse(matrix)\n    output = torch.zeros(opt.batchSize, opt.inputSize, opt.inputSize)\n    for i = 1, opt.batchSize do\n        output[i] = (torch.inverse(matrix[i]))\n    end\n    return output\nend\n\nfunction getEps()\n   eps = torch.eye(opt.inputSize,opt.inputSize) * 1e-2\n   eps:resize(1,opt.inputSize,opt.inputSize)\n   fulleps = eps:clone()\n   for i = 2, opt.batchSize do\n       fulleps = torch.cat(fulleps,eps,1)\n    end\n    return fulleps\nend\n\nlocal mixtureMultvarGauss = function(input, target)\n    local sizeMeanInput = opt.inputSize * opt.numMixture\n    local sizeCovarianceInput = opt.inputSize * opt.numMixture * opt.dimSize\n\n    local piStart = 1\n    local piEnd = opt.numMixture\n    local hat_pi_t = input[{{},{piStart,piEnd}}]\n\n    local muStart = piEnd + 1\n    local muEnd = piEnd + sizeMeanInput\n    local hat_mu_t = input[{{},{muStart,muEnd}}]\n\n    local sigmaStart = muEnd + 1\n    local sigmaEnd = muEnd + sizeCovarianceInput\n    local hat_sigma_t = input[{{},{sigmaStart,sigmaEnd}}]\n\n    local mask = input[{{},{sigmaEnd + 1}}]\n\n    hat_mu_t:resize(opt.batchSize, opt.numMixture, 1, opt.inputSize)\n    hat_sigma_t:resize(opt.batchSize, opt.numMixture, opt.dimSize, opt.inputSize)\n    target:resize(opt.batchSize, 1, opt.inputSize)\n    eps = getEps()\n\n    local join_mixture_result = torch.zeros(opt.batchSize, opt.numMixture)\n\n    for i = 1, opt.numMixture do\n        local u = hat_sigma_t[{{},{i},{},{}}]:squeeze(2)\n        local mu = hat_mu_t[{{},{i},{},{}}]:squeeze(2)\n        local pi = hat_pi_t[{{},{i}}]\n        local sigma = torch.bmm(u:transpose(2,3), u)\n        sigma:add(eps)\n        local det_sigma_2_pi = logDet(sigma) + (opt.inputSize * torch.log(2 * math.pi)) \n        local sqr_det_sigma_2_pi = (det_sigma_2_pi) * -0.5\n\n        local target_mu = target - mu \n        local transpose_target_mu = target_mu:transpose(2,3)\n\n        local inv_sigma = inverse(sigma)\n        local transpose_target_mu_sigma = torch.bmm(target_mu, inv_sigma)\n\n        local transpose_target_mu_sigma_target_mu = torch.bmm(transpose_target_mu_sigma, \n            transpose_target_mu)\n\n        local exp_term = transpose_target_mu_sigma_target_mu * -0.5\n\n        local mixture_result = pi + sqr_det_sigma_2_pi + exp_term\n\n        join_mixture_result[{{},{i}}] = mixture_result\n    end\n\n    local max_mixture = torch.max(join_mixture_result, 2)\n    local max_expanded = max_mixture:expandAs(join_mixture_result) * -1\n    local norm_mixture = max_expanded + join_mixture_result\n    local norm_mixture_exp = torch.exp(norm_mixture)\n    local norm_mixture_sumexp = torch.sum(norm_mixture_exp, 2)\n    local norm_mixture_logsumexp = torch.log(norm_mixture_sumexp)\n    local norm_mixture_addlogsumexp = (max_mixture + norm_mixture_logsumexp)*-1\n\n    return torch.cmul(mask, norm_mixture_addlogsumexp)\nend \n\nlocal autoMseCriterion = autograd.nn.AutoCriterion('AutoMixGauss')(mixtureMultvarGauss)\n\npi = torch.rand(4,10)\nmask = torch.ones(4,1)\nsig = torch.rand(4, 61*2*10)\nmu = torch.rand(4, 61*10)\ninput = torch.cat(pi, mu, 2)\ninput = torch.cat(input, sig, 2)\ninput = torch.cat(input, mask, 2)\ntarget = torch.rand(4,61)\nprint(autoMseCriterion:forward(input, target))\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/73", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/73/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/73/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/73/events", "html_url": "https://github.com/twitter/torch-autograd/issues/73", "id": 124200843, "node_id": "MDU6SXNzdWUxMjQyMDA4NDM=", "number": 73, "title": "Error when loss contains scalar multiplication (eg. L2 regularization)", "user": {"login": "alex-weaver", "id": 11133789, "node_id": "MDQ6VXNlcjExMTMzNzg5", "avatar_url": "https://avatars1.githubusercontent.com/u/11133789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alex-weaver", "html_url": "https://github.com/alex-weaver", "followers_url": "https://api.github.com/users/alex-weaver/followers", "following_url": "https://api.github.com/users/alex-weaver/following{/other_user}", "gists_url": "https://api.github.com/users/alex-weaver/gists{/gist_id}", "starred_url": "https://api.github.com/users/alex-weaver/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alex-weaver/subscriptions", "organizations_url": "https://api.github.com/users/alex-weaver/orgs", "repos_url": "https://api.github.com/users/alex-weaver/repos", "events_url": "https://api.github.com/users/alex-weaver/events{/privacy}", "received_events_url": "https://api.github.com/users/alex-weaver/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2015-12-29T11:55:08Z", "updated_at": "2016-01-04T21:08:27Z", "closed_at": "2016-01-04T21:08:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I ran across an issue trying to implement a sparsity-inducing term in the cost function, and in trying to put together a minimal repro case, it turned out that the example train-mnist-autoencoder.lua fails with the following output:\n\n```\nTraining Epoch #1   \n/home/alex/torch/install/bin/luajit: invalid arguments: number \nexpected arguments: DoubleTensor | [*DoubleTensor*] DoubleTensor index\nstack traceback:\n    [C]: at 0x7f6b925e2940\n    [C]: in function 'gf'\n    ...all/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:58: in function 'gradOnly'\n    ...all/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:124: in function 'df'\n    train-mnist-autoencoder.lua:90: in main chunk\n    [C]: in function 'dofile'\n    ...alex/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n    [C]: at 0x00406670\n```\n\nnote to get this to run I had to remove the line\n    `local Value = require 'autograd.Value'`\nand change the following:\n\n``` lua\n--for i=1,Value.len(params.W) do\nfor i=1,#params.W do\n```\n\nHopefully these modifications don't break the example.\n\nThere seems to be an issue around the scalar multiplication of the summed square weights with the l2Lambda parameter. If the l2Lambda term is removed from the loss calculation, but the sum of squares of weights is left in, then the above error does not occur:\n\n``` lua\n--loss = loss + l2Lambda * torch.sum(torch.pow(params.W[i],2))\n  loss = loss + torch.sum(torch.pow(params.W[i],2))\n```\n\nThe same behaviour happens both with and without optimization enabled. If I set a debugHook, it is never triggered (presumably because this issue doesn't involve `nan` or `inf`). I've also tried rebuilding torch with Lua 5.1 instead of LuaJIT, and a similar error occurs.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/72", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/72/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/72/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/72/events", "html_url": "https://github.com/twitter/torch-autograd/issues/72", "id": 124059298, "node_id": "MDU6SXNzdWUxMjQwNTkyOTg=", "number": 72, "title": "Adding two Criterions?", "user": {"login": "yongfei25", "id": 1611276, "node_id": "MDQ6VXNlcjE2MTEyNzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1611276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongfei25", "html_url": "https://github.com/yongfei25", "followers_url": "https://api.github.com/users/yongfei25/followers", "following_url": "https://api.github.com/users/yongfei25/following{/other_user}", "gists_url": "https://api.github.com/users/yongfei25/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongfei25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongfei25/subscriptions", "organizations_url": "https://api.github.com/users/yongfei25/orgs", "repos_url": "https://api.github.com/users/yongfei25/repos", "events_url": "https://api.github.com/users/yongfei25/events{/privacy}", "received_events_url": "https://api.github.com/users/yongfei25/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-12-28T12:12:45Z", "updated_at": "2015-12-28T14:15:11Z", "closed_at": "2015-12-28T14:15:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\n\nWhat are the possible ways to return the sum of two loss? `ParallelCriterion` doesn't seem to have the `:add()` function. \n\nTried the code below, no luck too. But it did successfully sum the values.\n\n``` lua\nlocal lossf1 = d.nn.ClassNLLCriterion()\nlocal lossf2 = d.nn.ClassNLLCriterion()\nlocal loss1 = lossf1(attentionGates, attentionY)\nlocal loss2 = lossf2(predictions, y)\n\nloss = loss1 + loss2\n\nprint(loss1.value)\nprint(loss2.value)\nprint(loss.value)\n\nreturn loss\n\n-- output\n0.68027830123901    \n12.994906425476 \n13.675184726715 \n\n/torch/install/share/lua/5.1/torch/Tensor.lua:462: Wrong size for view. Input size: 2x1. Output size: 1x400004\nstack traceback:\n    [C]: in function 'error'\n    /home/yongfei/torch/install/share/lua/5.1/torch/Tensor.lua:462: in function 'gf'\n    ...all/share/lua/5.1/autograd/runtime/direct/DirectTape.lua:58: in function 'gradOnly'\n\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/71", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/71/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/71/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/71/events", "html_url": "https://github.com/twitter/torch-autograd/issues/71", "id": 123862360, "node_id": "MDU6SXNzdWUxMjM4NjIzNjA=", "number": 71, "title": "Got NaN gradients after N batches on FloatTensor.", "user": {"login": "yongfei25", "id": 1611276, "node_id": "MDQ6VXNlcjE2MTEyNzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1611276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongfei25", "html_url": "https://github.com/yongfei25", "followers_url": "https://api.github.com/users/yongfei25/followers", "following_url": "https://api.github.com/users/yongfei25/following{/other_user}", "gists_url": "https://api.github.com/users/yongfei25/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongfei25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongfei25/subscriptions", "organizations_url": "https://api.github.com/users/yongfei25/orgs", "repos_url": "https://api.github.com/users/yongfei25/repos", "events_url": "https://api.github.com/users/yongfei25/events{/privacy}", "received_events_url": "https://api.github.com/users/yongfei25/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-12-25T07:51:25Z", "updated_at": "2015-12-25T10:43:42Z", "closed_at": "2015-12-25T10:43:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\n\nOn Cuda, I'm getting NaN for all gradients after 114 batches in my model. They are fine when trained on CPU. I have tried using different learning rate (00.2, 0.0002), and they returns NaN after the same batch number.\n\nOn Cuda, if I increase the model's hidden dimension, I got out of memory error after batches 28. (Each batch has similar amount of data.)\n\nCould this be memory leak? Can you advise how should I debug this?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/70", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/70/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/70/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/70/events", "html_url": "https://github.com/twitter/torch-autograd/issues/70", "id": 123655984, "node_id": "MDU6SXNzdWUxMjM2NTU5ODQ=", "number": 70, "title": "A node type was not returned.", "user": {"login": "zw-ruan", "id": 6196170, "node_id": "MDQ6VXNlcjYxOTYxNzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/6196170?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zw-ruan", "html_url": "https://github.com/zw-ruan", "followers_url": "https://api.github.com/users/zw-ruan/followers", "following_url": "https://api.github.com/users/zw-ruan/following{/other_user}", "gists_url": "https://api.github.com/users/zw-ruan/gists{/gist_id}", "starred_url": "https://api.github.com/users/zw-ruan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zw-ruan/subscriptions", "organizations_url": "https://api.github.com/users/zw-ruan/orgs", "repos_url": "https://api.github.com/users/zw-ruan/repos", "events_url": "https://api.github.com/users/zw-ruan/events{/privacy}", "received_events_url": "https://api.github.com/users/zw-ruan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2015-12-23T12:57:59Z", "updated_at": "2015-12-25T15:23:04Z", "closed_at": "2015-12-25T15:23:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \nI write a recursive autoencoder model, but get those message :\n\n**A node type was not returned. This is either because a gradient was not defined, or the input is independent of the output.**\n\n``` lua\nrequire 'torch'\ngrad = require 'autograd'\n\n\nembeddingSize = 5\n\n-- model parameters\n-- encode parameters:\n--      encodeW1, encodeW2, encodeB1\n--\n-- decode parameters\n--      decodeW1, decodeW2, decodeB1, decodeB2\nmodel_params = {\n    W = {\n        torch.randn(embeddingSize, embeddingSize), -- encodeW1\n        torch.randn(embeddingSize, embeddingSize), -- encodeW2\n        torch.randn(embeddingSize, embeddingSize), -- decodeW1\n        torch.randn(embeddingSize, embeddingSize)  -- decodeW2\n    },\n    b = {\n        torch.randn(embeddingSize, 1), -- encodeB1\n        torch.randn(embeddingSize, 1), -- decodeB1\n        torch.randn(embeddingSize, 1)  -- decodeB2\n    }\n}\n\n\n--[[\n    parameters:\n        - input\n            sentence embedding; the i-th column as w_i's enmbedding \n--]]\n-- pass model_params to RAEModel\nRAEModel = function(params, input)\n    if input:size(2) == 1 then \n        return 0\n    end\n\n    local nodes = torch.Tensor(embeddingSize, input:size(2) * 2 - 1)\n    local candidates_index = torch.range(1, input:size(2))\n    candidates_index = candidates_index:long()\n    nodes:indexCopy(2, candidates_index, input)\n    local loss = 0.0\n    -- run (sentence length - 1) turns\n    for turn = 1, input:size(2) - 1 do\n        local candidates = nodes:index(2, candidates_index)\n\n        local C1 = candidates:narrow(2, 1, candidates:size(2) - 1) \n        local C2 = candidates:narrow(2, 2, candidates:size(2) - 1) \n\n        --     tanh(encodeW1 * C1 + encodeW2 * C2 + encodeB1)\n        local P = torch.tanh(params.W[1] * C1 + params.W[2] * C2 +\n                    torch.expand(params.b[1], C1:size(1), C1:size(2)))\n\n        -- decode\n        --      tanh(decodeW1 * P + decodeB1)\n        --      tanh(decodeW2 * P + decodeB2)\n        local C1Rec = torch.tanh(params.W[3] * P +\n                        torch.expand(params.b[2], C1:size(1), C1:size(2)))\n\n        local C2Rec = torch.tanh(params.W[4] * P +\n                        torch.expand(params.b[3], C1:size(1), C1:size(2)))\n\n        -- reconstruction error\n        local recC1Error = C1Rec - C1\n        local recC2Error = C2Rec - C2\n\n\n        local recError = torch.sum(torch.pow(recC1Error, 2) +  \n                                    torch.pow(recC2Error, 2), 1)\n\n        -- get best pos \n        local mask = torch.eq(recError, torch.min(recError))[1]\n        local index = torch.nonzero(mask)[1][1]\n        loss = loss + recError[1][index]\n\n        -- generate new candidates\n        local p = P[{{}, {index}}]\n\n        -- add p to nodes, at location input:size(2) + i\n        nodes:indexCopy(2, torch.LongTensor{input:size(2) + turn}, p)\n\n        -- Debug\n        print('============' .. turn .. '===============')\n        print('====> reconstruction error')\n        print(recError[1])\n        print('====> index: ' .. index)\n        print('====> content in candidates_index: ')\n        print(candidates_index)\n        print('====> new generate content: ')\n        print(nodes[{{}, input:size(2) + turn}])\n\n        -- get the result, then return\n        if turn == input:size(2) - 1 then\n            print('====> nodes')\n            print(nodes)\n            return loss\n        end\n\n\n        -- generat new candidates index\n        -- replace index and (index + 0) with (inputSize(2) + turn)\n        -- if there is only one candidates, we get the result\n        candidates_index[index] = input:size(2) + turn\n        if index == 1 then\n            torch.cat(candidates_index, candidates_index[{{index}}],\n                                        candidates_index[{{index+2,\n                                            candidates_index:size(1)}}])\n\n        elseif index == candidates_index:size(1) - 1 then \n            torch.cat(candidates_index, candidates_index[{{1, \n                                                            index - 1}}],\n                                        candidates_index[{{index}}])\n\n        else\n            torch.cat(candidates_index, candidates_index[{{1, \n                                                            index}}],\n                            candidates_index[{{index+2, \n                                            candidates_index:size(1)}}])\n        end\n\n    end\nend\n\n\ninput = torch.randn(5, 10)\ndmodel = grad(RAEModel)\ngrad, loss = dmodel(model_params, input)\n\nprint('=========== Result ===============')\nprint('====> loss:')\nprint(loss)\n\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/69", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/69/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/69/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/69/events", "html_url": "https://github.com/twitter/torch-autograd/issues/69", "id": 122970119, "node_id": "MDU6SXNzdWUxMjI5NzAxMTk=", "number": 69, "title": "Errors with the \"Reorganize codegen\" commit", "user": {"login": "brianzhang01", "id": 7853915, "node_id": "MDQ6VXNlcjc4NTM5MTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/7853915?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brianzhang01", "html_url": "https://github.com/brianzhang01", "followers_url": "https://api.github.com/users/brianzhang01/followers", "following_url": "https://api.github.com/users/brianzhang01/following{/other_user}", "gists_url": "https://api.github.com/users/brianzhang01/gists{/gist_id}", "starred_url": "https://api.github.com/users/brianzhang01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brianzhang01/subscriptions", "organizations_url": "https://api.github.com/users/brianzhang01/orgs", "repos_url": "https://api.github.com/users/brianzhang01/repos", "events_url": "https://api.github.com/users/brianzhang01/events{/privacy}", "received_events_url": "https://api.github.com/users/brianzhang01/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-12-18T15:38:44Z", "updated_at": "2016-01-04T21:04:46Z", "closed_at": "2016-01-04T21:04:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Commit 29a2399bca22b5fd7c52aff6757d068928e2fa1b introduced various errors that should get fixed.\n\nIn two places, the require paths were not updated correctly:\n\nIn src/gradfuns.lua, line 2 should be\nlocal DirectNode = require 'autograd.runtime.direct.DirectNode'\n\nIn src/runtime/direct/DirectTape.lua, line 3 should be\nlocal DirectNode = require 'autograd.runtime.direct.DirectNode'\n\nThe reason these were not caught by tests is because of an error that was simultaneously introduced in CMakeLists.txt. If you take a look at https://travis-ci.org/twitter/torch-autograd/jobs/96998417 you see that the files under src/runtime are getting built multiple times. This has the effect of installing the src/runtime/direct/DirectNode.lua file into autograd/direct/DirectNode.lua, an incorrect location.\n\nInstead, lines 15 - 18 of CMakeLists.txt:\n\nINSTALL(DIRECTORY \"src/runtime/direct\" DESTINATION \"${Torch_INSTALL_LUA_PATH_SUBDIR}/autograd\")\nINSTALL(DIRECTORY \"src/runtime/codegen\" DESTINATION \"${Torch_INSTALL_LUA_PATH_SUBDIR}/autograd\")\nINSTALL(DIRECTORY \"src/runtime/codegen/backend\" DESTINATION \"${Torch_INSTALL_LUA_PATH_SUBDIR}/autograd\")\nINSTALL(DIRECTORY \"src/runtime/codegen/backend/lua\" DESTINATION \"${Torch_INSTALL_LUA_PATH_SUBDIR}/autograd\")\n\nshould be removed. I wonder if there's a way to even install all the files under src/, rather than having to list out all the subfolders.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/68", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/68/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/68/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/68/events", "html_url": "https://github.com/twitter/torch-autograd/issues/68", "id": 122744006, "node_id": "MDU6SXNzdWUxMjI3NDQwMDY=", "number": 68, "title": "error using grad.nn.SpatialBatchNormalization", "user": {"login": "thouis", "id": 473043, "node_id": "MDQ6VXNlcjQ3MzA0Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/473043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thouis", "html_url": "https://github.com/thouis", "followers_url": "https://api.github.com/users/thouis/followers", "following_url": "https://api.github.com/users/thouis/following{/other_user}", "gists_url": "https://api.github.com/users/thouis/gists{/gist_id}", "starred_url": "https://api.github.com/users/thouis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thouis/subscriptions", "organizations_url": "https://api.github.com/users/thouis/orgs", "repos_url": "https://api.github.com/users/thouis/repos", "events_url": "https://api.github.com/users/thouis/events{/privacy}", "received_events_url": "https://api.github.com/users/thouis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2015-12-17T14:24:47Z", "updated_at": "2016-01-06T20:51:44Z", "closed_at": "2016-01-06T20:51:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "I get this error:\n\n```\nluajit: ...h/install/share/lua/5.1/nn/SpatialBatchNormalization.lua:119: attempt to index field 'weight' (a nil value)\nstack traceback:\n    ...h/install/share/lua/5.1/nn/SpatialBatchNormalization.lua:119: in function 'normalizer'\n    test_BN.lua:12: in function 'testbn'\n    test_BN.lua:16: in main chunk\n    [C]: in function 'dofile'\n    ...ouis/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n    [C]: at 0x01011c2bd0\n```\n\nFrom this code:\n\n```\nlocal grad = require 'autograd'\n\nlocal im = torch.FloatTensor(1, 1, 10, 10):normal()\nlocal W = torch.FloatTensor(1, 9):normal()\nlocal b = torch.FloatTensor(1):zero()\n\nlocal conv = grad.nn.SpatialConvolutionMM(1, 1, 3, 3)\nlocal normalizer = grad.nn.SpatialBatchNormalization(1)\n\nlocal testbn = function(params, input)\n   local c = conv(input, params.W, params.B)\n   local n = normalizer(c)\n   return torch.sum(n)\nend\n\nprint(testbn({W=W, B=b}, im))\ndf = grad(testbn)\ntestbn({W=W, B=b}, im)\ngrads, val = df({W=W, B=b}, im)\nprint(grads.W)\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/67", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/67/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/67/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/67/events", "html_url": "https://github.com/twitter/torch-autograd/issues/67", "id": 122265427, "node_id": "MDU6SXNzdWUxMjIyNjU0Mjc=", "number": 67, "title": "Docs or example for writing gradfuns", "user": {"login": "thouis", "id": 473043, "node_id": "MDQ6VXNlcjQ3MzA0Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/473043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thouis", "html_url": "https://github.com/thouis", "followers_url": "https://api.github.com/users/thouis/followers", "following_url": "https://api.github.com/users/thouis/following{/other_user}", "gists_url": "https://api.github.com/users/thouis/gists{/gist_id}", "starred_url": "https://api.github.com/users/thouis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thouis/subscriptions", "organizations_url": "https://api.github.com/users/thouis/orgs", "repos_url": "https://api.github.com/users/thouis/repos", "events_url": "https://api.github.com/users/thouis/events{/privacy}", "received_events_url": "https://api.github.com/users/thouis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2015-12-15T12:48:19Z", "updated_at": "2016-01-15T01:45:30Z", "closed_at": "2016-01-15T01:45:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a workaround for specific application of #50 that involves using torch.eq(A, B), but returning the same type as A or B.  I was able to hack this into my system by putting this function into the torch module, and adding an entry in autograd.lua to define gradients (zero everywhere).\n\nI'm sure there's a much cleaner way to do this, without making changes to autograd itself, but this was the easiest way I could discern.  A short example would be enough, I think.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/66", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/66/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/66/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/66/events", "html_url": "https://github.com/twitter/torch-autograd/issues/66", "id": 121867036, "node_id": "MDU6SXNzdWUxMjE4NjcwMzY=", "number": 66, "title": "Constant tensor with more than one dimension", "user": {"login": "yongfei25", "id": 1611276, "node_id": "MDQ6VXNlcjE2MTEyNzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1611276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongfei25", "html_url": "https://github.com/yongfei25", "followers_url": "https://api.github.com/users/yongfei25/followers", "following_url": "https://api.github.com/users/yongfei25/following{/other_user}", "gists_url": "https://api.github.com/users/yongfei25/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongfei25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongfei25/subscriptions", "organizations_url": "https://api.github.com/users/yongfei25/orgs", "repos_url": "https://api.github.com/users/yongfei25/repos", "events_url": "https://api.github.com/users/yongfei25/events{/privacy}", "received_events_url": "https://api.github.com/users/yongfei25/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2015-12-12T17:14:09Z", "updated_at": "2016-01-04T21:07:55Z", "closed_at": "2016-01-04T21:07:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi, been hitting into this error quite frequently. Have this error when I declare a new Tensor and pass it into a torch function.\n\n``` lua\nlocal d = require 'autograd'\nd.optimize(true)\n\nlocal lossf = d.nn.ClassNLLCriterion()\nlocal f = function(params, y)\n  local yhat = torch.Tensor(2, 400003):uniform(-0.1,0.1)\n\n  -- also, if you uncomment this block, the autograd will print out the entire tensor :\\\n  -- local t = {\n  --   torch.Tensor(400003):double():uniform(-0.1, 0.1),\n  --   torch.Tensor(400003):double():uniform(-0.1, 0.1)\n  -- }\n  -- yhat = torch.cat(t,1)\n\n  local loss = lossf(yhat, y)\n  return loss\nend\n\nlocal df = d(f)\nlocal y = torch.Tensor({9516,400003})\nlocal params = {}\n\ndf(params, y)\n\n```\n\n```\n/torch/install/bin/luajit: .../install/share/lua/5.1/autograd/runtime/codegen/Node.lua:25: constant tensor with more than one dimension. is this an upvalue that should be a function argument?\nstack traceback:\n    [C]: in function 'error'\n    .../install/share/lua/5.1/autograd/runtime/codegen/Node.lua:25: in function 'init'\n    .../install/share/lua/5.1/autograd/runtime/codegen/Node.lua:10: in function 'new'\n    ...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:19: in function 'lossf'\n    train.lua:154: in function 'fn'\n    ...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:281: in function 'protectedFn'\n    ...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:309: in function 'record'\n    .../install/share/lua/5.1/autograd/runtime/codegen/init.lua:44: in function 'generateFn'\n    .../install/share/lua/5.1/autograd/runtime/codegen/init.lua:66: in function 'df'\n    train.lua:161: in main chunk\n    [C]: in function 'dofile'\n    ...gfei/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n    [C]: at 0x00406670\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/65", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/65/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/65/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/65/events", "html_url": "https://github.com/twitter/torch-autograd/issues/65", "id": 121805674, "node_id": "MDU6SXNzdWUxMjE4MDU2NzQ=", "number": 65, "title": "non-optimizing still optimizes", "user": {"login": "ngoodman", "id": 461193, "node_id": "MDQ6VXNlcjQ2MTE5Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/461193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngoodman", "html_url": "https://github.com/ngoodman", "followers_url": "https://api.github.com/users/ngoodman/followers", "following_url": "https://api.github.com/users/ngoodman/following{/other_user}", "gists_url": "https://api.github.com/users/ngoodman/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngoodman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngoodman/subscriptions", "organizations_url": "https://api.github.com/users/ngoodman/orgs", "repos_url": "https://api.github.com/users/ngoodman/repos", "events_url": "https://api.github.com/users/ngoodman/events{/privacy}", "received_events_url": "https://api.github.com/users/ngoodman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-12-11T22:36:21Z", "updated_at": "2015-12-12T00:53:17Z", "closed_at": "2015-12-12T00:52:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "i think it's the case that somewhere around commit cd6b9e0160c8c8e41263147b8ab11be0a88aae41 optimization started happening even when not in optimization mode. main.lua says this around line 32:\n\n```\n   if optimize then\n      return RuntimeCodegen.create(fn, opt)\n   else\n      return RuntimeDirect.create(fn, opt)\n   end\n```\n\ni believe the test should be on `opt.optimize`?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/62", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/62/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/62/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/62/events", "html_url": "https://github.com/twitter/torch-autograd/issues/62", "id": 121319285, "node_id": "MDU6SXNzdWUxMjEzMTkyODU=", "number": 62, "title": "Latest commit increased memory requirements in both modes (direct and cached)", "user": {"login": "noa", "id": 139875, "node_id": "MDQ6VXNlcjEzOTg3NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/139875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noa", "html_url": "https://github.com/noa", "followers_url": "https://api.github.com/users/noa/followers", "following_url": "https://api.github.com/users/noa/following{/other_user}", "gists_url": "https://api.github.com/users/noa/gists{/gist_id}", "starred_url": "https://api.github.com/users/noa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noa/subscriptions", "organizations_url": "https://api.github.com/users/noa/orgs", "repos_url": "https://api.github.com/users/noa/repos", "events_url": "https://api.github.com/users/noa/events{/privacy}", "received_events_url": "https://api.github.com/users/noa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2015-12-09T19:22:01Z", "updated_at": "2015-12-11T00:52:22Z", "closed_at": "2015-12-11T00:52:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Just a heads up that it looks like one of the latest commits blew up memory requirements. Probably cd6b9e0. Error below; it's asking for more than 12GB, which might indicate a bug? The same trainable function was working with direct mode prior to the new commit, but I did not test it with cached mode.\n\n```\n/usr/local/bin/luajit: ...re/lua/5.1/autograd/runtime/codegen/backend/lua/init.lua:262: cuda runtime error (2) : out of memory at /tmp/luarocks_cutorch-scm-1-8457/cutorch/lib/THC/THCStorage.cu:44\nstack traceback:\n        [C]: in function 'new'\n        ...re/lua/5.1/autograd/runtime/codegen/backend/lua/init.lua:262: in function 'createSymbolTable'\n        ...re/lua/5.1/autograd/runtime/codegen/backend/lua/init.lua:413: in function 'generateCode'\n        ...re/lua/5.1/autograd/runtime/codegen/backend/lua/init.lua:574: in function 'generateFn'\n        /usr/local/share/lua/5.1/autograd/runtime/codegen/init.lua:66: in function 'd_train_net'\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/61", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/61/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/61/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/61/events", "html_url": "https://github.com/twitter/torch-autograd/issues/61", "id": 121288376, "node_id": "MDU6SXNzdWUxMjEyODgzNzY=", "number": 61, "title": "grad of grad", "user": {"login": "davidBelanger", "id": 1179562, "node_id": "MDQ6VXNlcjExNzk1NjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1179562?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidBelanger", "html_url": "https://github.com/davidBelanger", "followers_url": "https://api.github.com/users/davidBelanger/followers", "following_url": "https://api.github.com/users/davidBelanger/following{/other_user}", "gists_url": "https://api.github.com/users/davidBelanger/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidBelanger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidBelanger/subscriptions", "organizations_url": "https://api.github.com/users/davidBelanger/orgs", "repos_url": "https://api.github.com/users/davidBelanger/repos", "events_url": "https://api.github.com/users/davidBelanger/events{/privacy}", "received_events_url": "https://api.github.com/users/davidBelanger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2015-12-09T16:43:01Z", "updated_at": "2016-01-19T22:14:18Z", "closed_at": "2016-01-19T22:14:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Below I've pasted some self-contained code to test the gradient-of-gradient stuff that was added recently to the README. It's described in the comments in the code. Unfortunately, it crashes, with this error:\n\n/usr/local/torch/install/bin/luajit: .../install/share/lua/5.1/autograd/runtime/codegen/Node.lua:135: missing gradient for function util.fillSameSizeAsInPlace\nstack traceback:\n    [C]: in function 'error'\n    .../install/share/lua/5.1/autograd/runtime/codegen/Node.lua:135: in function 'evaluateBackward'\n    ...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:298: in function 'protectedFn'\n    ...install/share/lua/5.1/autograd/runtime/codegen/Graph.lua:309: in function 'record'\n    .../install/share/lua/5.1/autograd/runtime/codegen/init.lua:44: in function 'generateFn'\n    .../install/share/lua/5.1/autograd/runtime/codegen/init.lua:66: in function 'ddf'\n    testGradGrad2.lua:32: in main chunk\n\nHas anyone seen this before? \nThanks, David\n\nlocal grad = require 'autograd'\ngrad.optimize(true)\n\n--simple linear model with squared loss\nlocal params = torch.randn(100,10)\n\nlocal innerFn = function(params, x, y)\n   local yHat = x*params\n   local squaredLoss = torch.sum(torch.pow(y - yHat,2))\n   return squaredLoss\nend\n\nlocal dneuralNet = grad(innerFn)\n\n--synthetic data\nlocal x = torch.randn(1,100)\nlocal y = torch.randn(1,10) \n\nprint('first derivative size')\nprint(dneuralNet(params,x,y):size())\n\n--the outer function computes the sum of the gradient of the neural network. Therefore, differentiating this returns the diagonal of the Hessian\nlocal outerFn = function(params,x,y)\n   local grad = dneuralNet(params,x,y)\n   local sum = torch.sum(grad)\n   return sum\nend\n\nprint('outer function value')\nprint(outerFn(params,x,y))\n\nlocal ddf = grad(outerFn)\nlocal gradGrads = ddf(params,x,y)\n\nprint('second derivative')\nprint(gradGrads)\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/57", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/57/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/57/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/57/events", "html_url": "https://github.com/twitter/torch-autograd/issues/57", "id": 120798265, "node_id": "MDU6SXNzdWUxMjA3OTgyNjU=", "number": 57, "title": "Convolutional LSTM", "user": {"login": "ankurhanda", "id": 686480, "node_id": "MDQ6VXNlcjY4NjQ4MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/686480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ankurhanda", "html_url": "https://github.com/ankurhanda", "followers_url": "https://api.github.com/users/ankurhanda/followers", "following_url": "https://api.github.com/users/ankurhanda/following{/other_user}", "gists_url": "https://api.github.com/users/ankurhanda/gists{/gist_id}", "starred_url": "https://api.github.com/users/ankurhanda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ankurhanda/subscriptions", "organizations_url": "https://api.github.com/users/ankurhanda/orgs", "repos_url": "https://api.github.com/users/ankurhanda/repos", "events_url": "https://api.github.com/users/ankurhanda/events{/privacy}", "received_events_url": "https://api.github.com/users/ankurhanda/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-12-07T15:28:54Z", "updated_at": "2015-12-08T18:53:54Z", "closed_at": "2015-12-08T18:53:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm implementing convolution LSTMs with autograd - the pseudo code is here https://github.com/ankurhanda/convlstm.autograd/blob/master/RecurrentConvLSTMNetwork.lua. The code is adapted from RecurrentLSTMNetwork.lua in src/model which is very nicely structured.  However, I always get `bad argument #1 (field weight does not exist)  in function 'conv_ixinput'` when I test my RecurrentConvLSTMNetwork.lua. I wonder if nn.SpatialConvolution allows conv(x, W, b). Otherwise what's the best way to implement this while keeping the structure similar to RecurrentLSTMNetwork? \n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/56", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/56/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/56/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/56/events", "html_url": "https://github.com/twitter/torch-autograd/issues/56", "id": 120583423, "node_id": "MDU6SXNzdWUxMjA1ODM0MjM=", "number": 56, "title": "wrapping plain numbers (not tensors)", "user": {"login": "noa", "id": 139875, "node_id": "MDQ6VXNlcjEzOTg3NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/139875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noa", "html_url": "https://github.com/noa", "followers_url": "https://api.github.com/users/noa/followers", "following_url": "https://api.github.com/users/noa/following{/other_user}", "gists_url": "https://api.github.com/users/noa/gists{/gist_id}", "starred_url": "https://api.github.com/users/noa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noa/subscriptions", "organizations_url": "https://api.github.com/users/noa/orgs", "repos_url": "https://api.github.com/users/noa/repos", "events_url": "https://api.github.com/users/noa/events{/privacy}", "received_events_url": "https://api.github.com/users/noa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-12-05T19:54:55Z", "updated_at": "2015-12-07T23:15:10Z", "closed_at": "2015-12-07T23:15:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is more of a usage question than an issue: is any special handling needed for constant scaling factors? Specifically, will autograd properly handle constants which are (1) upvalues and (2) passed arguments (separate from parameters)? For instance:\n\n``` lua\nlocal loss = lossf(yhat,y) * a1 + lossf(zhat,z) * a2\n```\n\nwhere `a1` and `a2` are numbers.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/55", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/55/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/55/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/55/events", "html_url": "https://github.com/twitter/torch-autograd/issues/55", "id": 120573762, "node_id": "MDU6SXNzdWUxMjA1NzM3NjI=", "number": 55, "title": "functionalise on modules without parameters", "user": {"login": "noa", "id": 139875, "node_id": "MDQ6VXNlcjEzOTg3NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/139875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noa", "html_url": "https://github.com/noa", "followers_url": "https://api.github.com/users/noa/followers", "following_url": "https://api.github.com/users/noa/following{/other_user}", "gists_url": "https://api.github.com/users/noa/gists{/gist_id}", "starred_url": "https://api.github.com/users/noa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noa/subscriptions", "organizations_url": "https://api.github.com/users/noa/orgs", "repos_url": "https://api.github.com/users/noa/repos", "events_url": "https://api.github.com/users/noa/events{/privacy}", "received_events_url": "https://api.github.com/users/noa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2015-12-05T17:27:28Z", "updated_at": "2015-12-08T18:40:18Z", "closed_at": "2015-12-08T18:40:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "It looks like autograd.functionalize assumes the passed module has a :parameters() method, which is not true for criterions for instance. The nnwrapper correctly handles this case for packages, however.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/54", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/54/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/54/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/54/events", "html_url": "https://github.com/twitter/torch-autograd/issues/54", "id": 120544405, "node_id": "MDU6SXNzdWUxMjA1NDQ0MDU=", "number": 54, "title": "__mul function error", "user": {"login": "yongfei25", "id": 1611276, "node_id": "MDQ6VXNlcjE2MTEyNzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1611276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongfei25", "html_url": "https://github.com/yongfei25", "followers_url": "https://api.github.com/users/yongfei25/followers", "following_url": "https://api.github.com/users/yongfei25/following{/other_user}", "gists_url": "https://api.github.com/users/yongfei25/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongfei25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongfei25/subscriptions", "organizations_url": "https://api.github.com/users/yongfei25/orgs", "repos_url": "https://api.github.com/users/yongfei25/repos", "events_url": "https://api.github.com/users/yongfei25/events{/privacy}", "received_events_url": "https://api.github.com/users/yongfei25/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2015-12-05T10:00:07Z", "updated_at": "2016-01-08T15:17:20Z", "closed_at": "2016-01-08T14:05:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\n\nI have this expression below in a function within `autograd(...)`\n\n``` lua\n-- x is a table of Nodes, { Node, Node, ... }\nlocal xt = torch.view(x[1], 1, inputFeatures)\n\n-- line 77\ndots = torch.cat(xt,hp,2) * p.W + torch.expand(p.b, 1, 2*hiddenFeatures)\n```\n\nand keep getting\n\n``` lua\n/home/yongfei/torch/install/bin/luajit: bad argument #2 to '?' (number expected, got table)\nstack traceback:\n    [C]: at 0x7f3b08895ac0\n    [C]: in function '__mul'\n    /home/yongfei/codes/dmn-1/model/SimpleGRU.lua:77: in function 'episodeGRU'\n    /home/yongfei/codes/dmn-1/model/DMN.lua:184: in function 'dmn'\n    train.lua:112: in function 'fun'\n    ...rch/install/share/lua/5.1/autograd/direct/DirectTape.lua:19: in function 'funOnly'\n    ...rch/install/share/lua/5.1/autograd/direct/DirectTape.lua:114: in function 'dDmn'\n    train.lua:122: in main chunk\n    [C]: in function 'dofile'\n    ...gfei/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:133: in main chunk\n    [C]: at 0x00406670\n```\n\nHere's the values in the expression\n\n``` lua\nxt.value ~= nil \n> false \nxt:type()   \n> torch.DoubleTensor    \n\nhp.value ~= nil \n> false \nhp:type()   \n> torch.DoubleTensor    \n\np.W.value ~= nil    \n> true  \np.W.value:type()    \n> torch.DoubleTensor    \n\n(torch.cat(xt,hp,2).value) ~= nil   \n> false \n(torch.cat(xt,hp,2)):type() \n> torch.DoubleTensor    \n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/52", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/52/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/52/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/52/events", "html_url": "https://github.com/twitter/torch-autograd/issues/52", "id": 120263254, "node_id": "MDU6SXNzdWUxMjAyNjMyNTQ=", "number": 52, "title": "gradCheck test", "user": {"login": "ronanmoynihan", "id": 1719175, "node_id": "MDQ6VXNlcjE3MTkxNzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/1719175?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ronanmoynihan", "html_url": "https://github.com/ronanmoynihan", "followers_url": "https://api.github.com/users/ronanmoynihan/followers", "following_url": "https://api.github.com/users/ronanmoynihan/following{/other_user}", "gists_url": "https://api.github.com/users/ronanmoynihan/gists{/gist_id}", "starred_url": "https://api.github.com/users/ronanmoynihan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ronanmoynihan/subscriptions", "organizations_url": "https://api.github.com/users/ronanmoynihan/orgs", "repos_url": "https://api.github.com/users/ronanmoynihan/repos", "events_url": "https://api.github.com/users/ronanmoynihan/events{/privacy}", "received_events_url": "https://api.github.com/users/ronanmoynihan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2015-12-03T20:32:55Z", "updated_at": "2015-12-08T17:12:48Z", "closed_at": "2015-12-08T17:12:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\n\nI have a model which uses a normal Torch NN with an Autograd custom criterion. The gradCheck call returns true but I think I may be using it incorrectly.\n\nThe following file contains the test,\nhttps://github.com/ronanmoynihan/autograd-criterion/blob/master/gradCheck.lua\n\nIf I comment out the following lines (27-30)  then the gradCheck fails, even though the model is not referenced anywhere else in the code.\n\nlocal model = nn.Sequential()  \nmodel:add(nn.Linear(d, numhid1)) \nmodel:add(nn.Sigmoid())\nmodel:add(nn.Linear(numhid1, n_outputs))\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/50", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/50/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/50/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/50/events", "html_url": "https://github.com/twitter/torch-autograd/issues/50", "id": 119895042, "node_id": "MDU6SXNzdWUxMTk4OTUwNDI=", "number": 50, "title": "Unpooling with torch.autograd", "user": {"login": "ankurhanda", "id": 686480, "node_id": "MDQ6VXNlcjY4NjQ4MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/686480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ankurhanda", "html_url": "https://github.com/ankurhanda", "followers_url": "https://api.github.com/users/ankurhanda/followers", "following_url": "https://api.github.com/users/ankurhanda/following{/other_user}", "gists_url": "https://api.github.com/users/ankurhanda/gists{/gist_id}", "starred_url": "https://api.github.com/users/ankurhanda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ankurhanda/subscriptions", "organizations_url": "https://api.github.com/users/ankurhanda/orgs", "repos_url": "https://api.github.com/users/ankurhanda/repos", "events_url": "https://api.github.com/users/ankurhanda/events{/privacy}", "received_events_url": "https://api.github.com/users/ankurhanda/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 19, "created_at": "2015-12-02T08:54:44Z", "updated_at": "2016-01-15T01:22:19Z", "closed_at": "2016-01-15T01:22:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm max pooling and saving the indices of max values. I'd like to use these indices when I'm upsampling later in the network. However, Unpooling layer doesn't have any parameters and whenever I run the program I get this error \n\n\"A node type was not returned. This is either because a gradient was not defined, or the input is independent of the output\" \n\nCould you suggest where exactly I'd need to make changes? Here's the code \n\n```\n-- Define a standard nn model:\nrequire 'nn'\nt = require 'torch'\ngrad = require 'autograd'\n\nlocal model = nn.Sequential()\nmodel:add(nn.SpatialConvolutionMM(1, 1, 3, 3, 1, 1, 1, 1))\nlocal pool1 = nn.SpatialMaxPooling(2,2)\nlocal idx = pool1.indices\nmodel:add(pool1)\n\n-- Note that this model could have been pre-trained, and reloaded from disk.\n\n-- Functionalize the model:\nlocal modelf, params = grad.functionalize(model)\n\n-- The model can now be used as part of a regular autograd function:\nlocal loss = grad.nn.MSECriterion()\n\nfunction Unpool(h1,idx)\n\n    local pred = t.Tensor(1,4,4):zero()\n\n    D,H,W = h1:size(1),h1:size(2),h1:size(3)\n\n    for d=1,D do\n        for h=1,H do\n            for w=1,W do\n                pred[d][h*2][w*2] = h1[d][h][w]\n        ---     idx_h = math.floor(idx[d][h][w]/4)+1\n        ---     idx_w = math.fmod(idx[d][h][w],4)\n        ---     pred[d][idx_h][idx_w] = h[d][h][w]\n            end\n        end\n    end \n\n    return pred\nend\n\nneuralNet = function(params, x, y)\n   local h1 = modelf(params, x)\n   local pred= Unpool(h1,idx)\n   return loss(pred, y)\nend\n\n-- gradients:\ndneuralNet = grad(neuralNet)\n\n-- some data:\nx = t.randn(1,4,4)\ny = t.Tensor(1,4,4):zero() \n\n-- compute loss and gradients wrt all parameters in params:\ndparams, loss = dneuralNet(params,x, y)\n\nprint(loss)\n\n\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/48", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/48/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/48/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/48/events", "html_url": "https://github.com/twitter/torch-autograd/issues/48", "id": 119806916, "node_id": "MDU6SXNzdWUxMTk4MDY5MTY=", "number": 48, "title": "train-penn-lstm.lua crashes after finishing 1st epoch", "user": {"login": "jfsantos", "id": 5733, "node_id": "MDQ6VXNlcjU3MzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/5733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jfsantos", "html_url": "https://github.com/jfsantos", "followers_url": "https://api.github.com/users/jfsantos/followers", "following_url": "https://api.github.com/users/jfsantos/following{/other_user}", "gists_url": "https://api.github.com/users/jfsantos/gists{/gist_id}", "starred_url": "https://api.github.com/users/jfsantos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jfsantos/subscriptions", "organizations_url": "https://api.github.com/users/jfsantos/orgs", "repos_url": "https://api.github.com/users/jfsantos/repos", "events_url": "https://api.github.com/users/jfsantos/events{/privacy}", "received_events_url": "https://api.github.com/users/jfsantos/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2015-12-01T21:00:35Z", "updated_at": "2016-02-16T19:37:39Z", "closed_at": "2015-12-03T20:37:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Running `th train-penn-lstm.lua` without passing any parameters (processing done on CPU, default parameters) I got the following error right after the first epoch finishes training and validation/test perplexities are computed:\n\n```\nTest set [just indicative, not used for training]...\nTest set perplexity = 176.93627527427\n\nTraining Epoch #2\n/Users/jfsantos/torch/install/bin/luajit: [string \"return function(locals, rlocals, vlocals, Cla...\"]:35: attempt to perform arithmetic on local 'p4' (a table value)\nstack traceback:\n    [string \"return function(locals, rlocals, vlocals, Cla...\"]:35: in function 'df'\n    train-penn-lstm.lua:185: in main chunk\n    [C]: in function 'dofile'\n    ...ntos/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:131: in main chunk\n    [C]: at 0x010b42a320\n```\n\n`p4` seems to be an automatically generated variable inside the `df` function, but I have no clue on how I could debug that. Please let me know if I can run any specific tests to help fixing this issue.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/46", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/46/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/46/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/46/events", "html_url": "https://github.com/twitter/torch-autograd/issues/46", "id": 119678222, "node_id": "MDU6SXNzdWUxMTk2NzgyMjI=", "number": 46, "title": "repeatTensor", "user": {"login": "noa", "id": 139875, "node_id": "MDQ6VXNlcjEzOTg3NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/139875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noa", "html_url": "https://github.com/noa", "followers_url": "https://api.github.com/users/noa/followers", "following_url": "https://api.github.com/users/noa/following{/other_user}", "gists_url": "https://api.github.com/users/noa/gists{/gist_id}", "starred_url": "https://api.github.com/users/noa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noa/subscriptions", "organizations_url": "https://api.github.com/users/noa/orgs", "repos_url": "https://api.github.com/users/noa/repos", "events_url": "https://api.github.com/users/noa/events{/privacy}", "received_events_url": "https://api.github.com/users/noa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-12-01T09:42:08Z", "updated_at": "2015-12-03T18:42:20Z", "closed_at": "2015-12-03T18:42:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm seeing the error:\n\n/usr/local/share/lua/5.1/autograd/direct/DirectTape.lua:56: attempt to index field 'gradFun' (a nil value)\n\nin a test involving repeatTensor. It looks like it might just not be supported yet? \n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/44", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/44/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/44/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/44/events", "html_url": "https://github.com/twitter/torch-autograd/issues/44", "id": 119446987, "node_id": "MDU6SXNzdWUxMTk0NDY5ODc=", "number": 44, "title": "Proper use of optim with autograd", "user": {"login": "vgire", "id": 8134193, "node_id": "MDQ6VXNlcjgxMzQxOTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/8134193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vgire", "html_url": "https://github.com/vgire", "followers_url": "https://api.github.com/users/vgire/followers", "following_url": "https://api.github.com/users/vgire/following{/other_user}", "gists_url": "https://api.github.com/users/vgire/gists{/gist_id}", "starred_url": "https://api.github.com/users/vgire/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vgire/subscriptions", "organizations_url": "https://api.github.com/users/vgire/orgs", "repos_url": "https://api.github.com/users/vgire/repos", "events_url": "https://api.github.com/users/vgire/events{/privacy}", "received_events_url": "https://api.github.com/users/vgire/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2015-11-30T09:05:09Z", "updated_at": "2015-12-03T21:03:46Z", "closed_at": "2015-12-02T16:47:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Let say I have the following simple self-contained model and dataset:\n\n``` lua\nlocal autograd = require 'autograd'\ntorch.manualSeed(123)\n\nlocal params = {\n   W = {\n      torch.randn(10, 1)\n   },\n   b = {\n      torch.randn(1)\n   }\n}\n\n-- simple model\nlocal f = function(params, x, y)\n   local h1 = torch.tanh(x * params.W[1] + params.b[1])\n   return torch.sqrt(torch.sum(torch.pow(y - h1, 2)))\nend\n\nlocal df = autograd(f)\n\n-- some easy data\nlocal nData = 5000\nlocal xs = torch.randn(nData, 10)\nlocal ys = torch.Tensor(nData, 1)\nfor i=1, nData do ys[i][1] = math.tanh(xs[i]:sum()) end\n```\n\nI can train it easily with:\n\n``` lua\nlocal learningRate = 1e-3\nfor e=1, 10 do\n   local loss = 0\n   for i=1,nData  do\n      local grads, l = df(params, xs:narrow(1, i, 1), ys:narrow(1, i, 1))\n      loss = loss + l\n      params.W[1]:add(-learningRate, grads.W[1])\n      params.b[1]:add(-learningRate, grads.b[1])\n   end\n   print('epoch #' .. e .. ', loss = ' .. loss / nData)\nend\n```\n\nBut what if I need  another optimisation algorithm than SGD such as ADAM or ADADELTA ?\nThe `optim` package makes it very easy in torch but I am struggling to use it with `autograd`.\n\nThe following code does run but does not get close to the results I have with the training above and takes much more time (certainly because I flatten the grads every time).\n\n``` lua\nrequire 'nn'\nrequire 'optim'\nlocal flattenParams = nn.Module.flatten({params.W[1], params.b[1]})\nlocal state = { learningRate = 1e-3 }\nfor e=1, 10 do\n   local loss = 0\n   for i=1,nData do\n      local feval = function(x)\n         local grads, l = df(params, xs:narrow(1, i, 1), ys:narrow(1, i, 1))\n         return l, nn.Module.flatten({grads.W[1], params.b[1]}) -- ugly\n      end\n      local _, l = optim.sgd(feval, flattenParams, state)\n      loss = loss + l[1]\n   end\n   print('epoch #' .. e .. ', loss = ' .. loss / nData)\nend\n```\n\nWhat would be the good approach to use `optim` with `autograd` ?\n\nThank you for your help\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/42", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/42/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/42/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/42/events", "html_url": "https://github.com/twitter/torch-autograd/issues/42", "id": 119294684, "node_id": "MDU6SXNzdWUxMTkyOTQ2ODQ=", "number": 42, "title": "Cloning AutoModule fails", "user": {"login": "vgire", "id": 8134193, "node_id": "MDQ6VXNlcjgxMzQxOTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/8134193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vgire", "html_url": "https://github.com/vgire", "followers_url": "https://api.github.com/users/vgire/followers", "following_url": "https://api.github.com/users/vgire/following{/other_user}", "gists_url": "https://api.github.com/users/vgire/gists{/gist_id}", "starred_url": "https://api.github.com/users/vgire/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vgire/subscriptions", "organizations_url": "https://api.github.com/users/vgire/orgs", "repos_url": "https://api.github.com/users/vgire/repos", "events_url": "https://api.github.com/users/vgire/events{/privacy}", "received_events_url": "https://api.github.com/users/vgire/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2015-11-28T13:47:46Z", "updated_at": "2015-12-02T16:46:25Z", "closed_at": "2015-12-02T16:46:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "The following simple `AutoModule` fails at `module:clone()` with the error: `torch/File.lua:107: Unwritable object`\n\n``` lua\nlocal autograd = require 'autograd'\n\nlocal f = function(x, W, b)\n  return x * W + torch.expand(b, torch.size(x, 1), torch.size(b, 2))\nend\n\nlocal batchSize = 5\nlocal inputFeatures = 6\nlocal outputFeatures = 7\n\nlocal weight = torch.rand(inputFeatures, outputFeatures)\nlocal bias = torch.rand(1, outputFeatures)\nlocal module = autograd.nn.AutoModule('AutoModule')(f, weight, bias)\n\nmodule:clone()\n```\n\nIs cloning not supported or is it a bug ?\n\nThanks\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/41", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/41/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/41/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/41/events", "html_url": "https://github.com/twitter/torch-autograd/issues/41", "id": 119192200, "node_id": "MDU6SXNzdWUxMTkxOTIyMDA=", "number": 41, "title": "Remove unnecessary trepl require", "user": {"login": "brianzhang01", "id": 7853915, "node_id": "MDQ6VXNlcjc4NTM5MTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/7853915?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brianzhang01", "html_url": "https://github.com/brianzhang01", "followers_url": "https://api.github.com/users/brianzhang01/followers", "following_url": "https://api.github.com/users/brianzhang01/following{/other_user}", "gists_url": "https://api.github.com/users/brianzhang01/gists{/gist_id}", "starred_url": "https://api.github.com/users/brianzhang01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brianzhang01/subscriptions", "organizations_url": "https://api.github.com/users/brianzhang01/orgs", "repos_url": "https://api.github.com/users/brianzhang01/repos", "events_url": "https://api.github.com/users/brianzhang01/events{/privacy}", "received_events_url": "https://api.github.com/users/brianzhang01/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2015-11-27T12:57:27Z", "updated_at": "2015-12-01T19:08:35Z", "closed_at": "2015-12-01T19:08:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "Since trepl is not used in the main autograd source, only in the benchmark file, it could probably be removed as a dependency from the init.lua file. See this commit:\n\nhttps://github.com/twitter/torch-autograd/commit/762a4048191c71b739563a7b5b3b8361d246d335\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/38", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/38/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/38/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/38/events", "html_url": "https://github.com/twitter/torch-autograd/issues/38", "id": 118837569, "node_id": "MDU6SXNzdWUxMTg4Mzc1Njk=", "number": 38, "title": "Batch matrix multplication", "user": {"login": "ketranm", "id": 1192597, "node_id": "MDQ6VXNlcjExOTI1OTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1192597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ketranm", "html_url": "https://github.com/ketranm", "followers_url": "https://api.github.com/users/ketranm/followers", "following_url": "https://api.github.com/users/ketranm/following{/other_user}", "gists_url": "https://api.github.com/users/ketranm/gists{/gist_id}", "starred_url": "https://api.github.com/users/ketranm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ketranm/subscriptions", "organizations_url": "https://api.github.com/users/ketranm/orgs", "repos_url": "https://api.github.com/users/ketranm/repos", "events_url": "https://api.github.com/users/ketranm/events{/privacy}", "received_events_url": "https://api.github.com/users/ketranm/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2015-11-25T13:33:34Z", "updated_at": "2015-11-26T18:15:56Z", "closed_at": "2015-11-26T18:15:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm using nn.MM for batch matrix multiplication but it I got an error in torch-autograd. Does torch-autograd support 3D Tensor multiplication at the current state?\n\nHere's is the example code I ran\n\n``` lua\nlocal t = require 'torch'\nlocal d = require 'autograd'\n\nlocal mm = d.nn.MM(false, true)\n-- toy examples\nparams = {}\nparams.x = torch.randn(2,1,5)\nparams.y = torch.randn(2,3,5)\n\ntest = function(params)\n    local w = mm({params.x, params.y})\n    return t.sum(w)\nend\n\ndt = d(test)\ndparams, loss = dt(params)\nprint(loss)\n```\n\nAnd I got the following errors\n\n```\n/torch/install/share/lua/5.1/autograd/nnwrapper.lua:110: attempt to call method 'type' (a nil value)\nstack traceback:\n    ...etran/torch/install/share/lua/5.1/autograd/nnwrapper.lua:110: in function 'fun'\n    ...rch/install/share/lua/5.1/autograd/direct/DirectNode.lua:73: in function 'mm'\n    toy.lua:11: in function 'fun'\n    ...rch/install/share/lua/5.1/autograd/direct/DirectTape.lua:18: in function 'funOnly'\n    ...rch/install/share/lua/5.1/autograd/direct/DirectTape.lua:100: in function 'dt'\n    toy.lua:16: in main chunk\n    [C]: in function 'dofile'\n    ...tran/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n    [C]: at 0x010ec1b2d0\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/32", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/32/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/32/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/32/events", "html_url": "https://github.com/twitter/torch-autograd/issues/32", "id": 118649082, "node_id": "MDU6SXNzdWUxMTg2NDkwODI=", "number": 32, "title": "Optimized_tests failing, Direct_tests very slow", "user": {"login": "timharley", "id": 4367998, "node_id": "MDQ6VXNlcjQzNjc5OTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/4367998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/timharley", "html_url": "https://github.com/timharley", "followers_url": "https://api.github.com/users/timharley/followers", "following_url": "https://api.github.com/users/timharley/following{/other_user}", "gists_url": "https://api.github.com/users/timharley/gists{/gist_id}", "starred_url": "https://api.github.com/users/timharley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/timharley/subscriptions", "organizations_url": "https://api.github.com/users/timharley/orgs", "repos_url": "https://api.github.com/users/timharley/repos", "events_url": "https://api.github.com/users/timharley/events{/privacy}", "received_events_url": "https://api.github.com/users/timharley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2015-11-24T16:33:12Z", "updated_at": "2015-11-25T00:14:25Z", "closed_at": "2015-11-24T23:48:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there a stable version of this package yet? Currently, if running against HEAD, 24/35 of the Optimized_\\* tests fail with an error. The Direct tests pass for me, but some are very slow (>30s per test):\n- Direct_NNFunc_CNN\n- Direct_Models_SpatialNetwork\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/28", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/28/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/28/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/28/events", "html_url": "https://github.com/twitter/torch-autograd/issues/28", "id": 118266319, "node_id": "MDU6SXNzdWUxMTgyNjYzMTk=", "number": 28, "title": "'nodeApply' is nil when calling functionalized nn module", "user": {"login": "DaniloRezende", "id": 1136203, "node_id": "MDQ6VXNlcjExMzYyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1136203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DaniloRezende", "html_url": "https://github.com/DaniloRezende", "followers_url": "https://api.github.com/users/DaniloRezende/followers", "following_url": "https://api.github.com/users/DaniloRezende/following{/other_user}", "gists_url": "https://api.github.com/users/DaniloRezende/gists{/gist_id}", "starred_url": "https://api.github.com/users/DaniloRezende/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DaniloRezende/subscriptions", "organizations_url": "https://api.github.com/users/DaniloRezende/orgs", "repos_url": "https://api.github.com/users/DaniloRezende/repos", "events_url": "https://api.github.com/users/DaniloRezende/events{/privacy}", "received_events_url": "https://api.github.com/users/DaniloRezende/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2015-11-22T14:32:40Z", "updated_at": "2015-11-23T13:55:58Z", "closed_at": "2015-11-23T13:48:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I run the code below\n\n``` lua\nrequire 'env'\nlocal t = require 'torch'\nlocal ag = require 'autograd'\n\nlocal n_enc = 10\n\nlocal nn_enc = nn.Sequential()\n:add(nn.SpatialConvolutionMM(1, 16, 3, 3, 1, 1, 1, 1))\n:add(nn.Tanh())\n:add(nn.SpatialMaxPooling(2,2,2,2))\n:add(nn.SpatialConvolutionMM(16, 32, 3, 3, 1, 1, 1, 1))\n:add(nn.Tanh())\n:add(nn.Reshape(32*16*16))\n:add(nn.ConcatTable()\n    :add(nn.Linear(32*16*16, n_enc))\n    :add(nn.Linear(32*16*16, n_enc))\n    )\n\n-- quick test\nlocal x = torch.randn(10, 1, 32, 32)\nlocal y_nn = nn_enc:forward(x)\n\n-- Functionalize the model:\nlocal ag_enc, enc_params = ag.functionalize(nn_enc)\n\nlocal y_ag = ag_enc(enc_params, x)\nprint{params=params,y_ag=y_ag,y_nn=y_nn,x=x}\n```\n\nI get the error:\n\n> autograd/nnwrapper.lua:291: attempt to call upvalue 'nodeApply' (a nil value)\n> stack traceback:\n>   [C]: in function 'nodeApply'\n>   .../autograd/nnwrapper.lua:291: in function 'ag_enc'\n>   test.lua:29: in main chunk\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/24", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/24/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/24/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/24/events", "html_url": "https://github.com/twitter/torch-autograd/issues/24", "id": 117865105, "node_id": "MDU6SXNzdWUxMTc4NjUxMDU=", "number": 24, "title": "network crashes when run with CUDA (dropout-related?)", "user": {"login": "thouis", "id": 473043, "node_id": "MDQ6VXNlcjQ3MzA0Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/473043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thouis", "html_url": "https://github.com/thouis", "followers_url": "https://api.github.com/users/thouis/followers", "following_url": "https://api.github.com/users/thouis/following{/other_user}", "gists_url": "https://api.github.com/users/thouis/gists{/gist_id}", "starred_url": "https://api.github.com/users/thouis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thouis/subscriptions", "organizations_url": "https://api.github.com/users/thouis/orgs", "repos_url": "https://api.github.com/users/thouis/repos", "events_url": "https://api.github.com/users/thouis/events{/privacy}", "received_events_url": "https://api.github.com/users/thouis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2015-11-19T17:33:16Z", "updated_at": "2015-11-21T15:40:15Z", "closed_at": "2015-11-21T15:40:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "The example from #17 now works in the new release, again (thanks!).\n\nHowever, when I change it to use CUDA (on the https://github.com/thouis/denoise_cnn/tree/cuda branch), it crashes, with:\n\n```\n/Users/thouis/torch/install/bin/luajit: /Users/thouis/torch/install/share/lua/5.1/autograd/Node.lua:25: constant tensor with more than one dimension\nstack traceback:\n    [C]: in function 'error'\n    /Users/thouis/torch/install/share/lua/5.1/autograd/Node.lua:25: in function 'init'\n    /Users/thouis/torch/install/share/lua/5.1/autograd/Node.lua:10: in function 'new'\n    /Users/thouis/torch/install/share/lua/5.1/autograd/main.lua:126: in function 'bernoulli'\n    /Users/thouis/torch/install/share/lua/5.1/autograd/util.lua:60: in function 'regularize'\n    fcnnlr.lua:72: in function 'predict'\n    fcnnlr.lua:88: in function 'fn'\n    /Users/thouis/torch/install/share/lua/5.1/autograd/main.lua:403: in function 'createGraph'\n    /Users/thouis/torch/install/share/lua/5.1/autograd/main.lua:650: in function 'generateCode'\n    /Users/thouis/torch/install/share/lua/5.1/autograd/main.lua:903: in function 'df'\n    fcnnlr.lua:176: in main chunk\n    [C]: in function 'dofile'\n    ...ouis/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:145: in main chunk\n    [C]: at 0x010b90d2d0\n```\n\nRun with \n\n`th fcnnlr.lua  --type cuda z00000123_orig.png z00000123_labels.png`\n\nTo see the crash, or remove `--type cuda` to see it work.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/19", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/19/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/19/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/19/events", "html_url": "https://github.com/twitter/torch-autograd/issues/19", "id": 117486167, "node_id": "MDU6SXNzdWUxMTc0ODYxNjc=", "number": 19, "title": "Variable sized input and target tensors", "user": {"login": "noa", "id": 139875, "node_id": "MDQ6VXNlcjEzOTg3NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/139875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noa", "html_url": "https://github.com/noa", "followers_url": "https://api.github.com/users/noa/followers", "following_url": "https://api.github.com/users/noa/following{/other_user}", "gists_url": "https://api.github.com/users/noa/gists{/gist_id}", "starred_url": "https://api.github.com/users/noa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noa/subscriptions", "organizations_url": "https://api.github.com/users/noa/orgs", "repos_url": "https://api.github.com/users/noa/repos", "events_url": "https://api.github.com/users/noa/events{/privacy}", "received_events_url": "https://api.github.com/users/noa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2015-11-18T00:48:45Z", "updated_at": "2015-11-20T19:41:19Z", "closed_at": "2015-11-20T19:41:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "In some cases it's useful to have variable sized input and target tensors and batch sizes, e.g. RNNs. This was reasonably efficient before the Nov 16 overhaul but I'm now seeing extreme slowdowns after the overhaul. Any plans to introduce a flag to switch between the pre- and post-overhaul behaviors, or suggestions on how to improve performance? I assume that moving to fixed BPTT dimension and batch size would address the speed issue (to match the provided LM example), but maybe there's another way to improve performance without changing the data?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/17", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/17/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/17/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/17/events", "html_url": "https://github.com/twitter/torch-autograd/issues/17", "id": 117268974, "node_id": "MDU6SXNzdWUxMTcyNjg5NzQ=", "number": 17, "title": "Code that worked in initial release now fails with \"luajit: not enough memory\"", "user": {"login": "thouis", "id": 473043, "node_id": "MDQ6VXNlcjQ3MzA0Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/473043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thouis", "html_url": "https://github.com/thouis", "followers_url": "https://api.github.com/users/thouis/followers", "following_url": "https://api.github.com/users/thouis/following{/other_user}", "gists_url": "https://api.github.com/users/thouis/gists{/gist_id}", "starred_url": "https://api.github.com/users/thouis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thouis/subscriptions", "organizations_url": "https://api.github.com/users/thouis/orgs", "repos_url": "https://api.github.com/users/thouis/repos", "events_url": "https://api.github.com/users/thouis/events{/privacy}", "received_events_url": "https://api.github.com/users/thouis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2015-11-17T02:33:02Z", "updated_at": "2015-11-21T16:44:21Z", "closed_at": "2015-11-21T16:44:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "The example in this repository (currently at commit 6a03a4c)\n\nhttps://github.com/thouis/denoise_cnn\n\nWorked under the initial release (September 6, 2015).  After the newest release (September 16), it no longer works, getting an out of memory error when run.\n\nThis is on an 8GB macbook pro.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/16", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/16/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/16/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/16/events", "html_url": "https://github.com/twitter/torch-autograd/issues/16", "id": 116819084, "node_id": "MDU6SXNzdWUxMTY4MTkwODQ=", "number": 16, "title": "issue using functionalize", "user": {"login": "davidBelanger", "id": 1179562, "node_id": "MDQ6VXNlcjExNzk1NjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1179562?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidBelanger", "html_url": "https://github.com/davidBelanger", "followers_url": "https://api.github.com/users/davidBelanger/followers", "following_url": "https://api.github.com/users/davidBelanger/following{/other_user}", "gists_url": "https://api.github.com/users/davidBelanger/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidBelanger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidBelanger/subscriptions", "organizations_url": "https://api.github.com/users/davidBelanger/orgs", "repos_url": "https://api.github.com/users/davidBelanger/repos", "events_url": "https://api.github.com/users/davidBelanger/events{/privacy}", "received_events_url": "https://api.github.com/users/davidBelanger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-11-13T18:08:22Z", "updated_at": "2015-11-13T18:32:49Z", "closed_at": "2015-11-13T18:32:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Below is a self-contained bit of code that I think should work, but is crashing. Basically, I just took the example for autograd.functionalize in the README, but changed it to a simpler architecture, and tried to actually evaluate the function on some data. Any thoughts as to what I'm doing wrong. \n\nHere's the error:\n\ntorch/install/share/lua/5.1/nn/Threshold.lua:20: bad argument #1 (field threshold does not exist)\nstack traceback:\n    [C]: in function 'Threshold_updateOutput'\n    ...rs/belanger/torch/install/share/lua/5.1/nn/Threshold.lua:20: in function 'updateOutput'\n\nHere's the code:\n\nrequire 'nn'\nlocal autograd = require 'autograd'\n\nlocal model = nn.Sequential():add(nn.Linear(5,10)):add(nn.ReLU())\nlocal testdata = torch.Tensor(32,5)\n\nlocal modelf, params = autograd.functionalize(model)\n\nlocal x = modelf(params,testdata)\nprint(x)\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/15", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/15/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/15/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/15/events", "html_url": "https://github.com/twitter/torch-autograd/issues/15", "id": 116516561, "node_id": "MDU6SXNzdWUxMTY1MTY1NjE=", "number": 15, "title": "Error when using require autograd", "user": {"login": "bluechill52", "id": 11149853, "node_id": "MDQ6VXNlcjExMTQ5ODUz", "avatar_url": "https://avatars2.githubusercontent.com/u/11149853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bluechill52", "html_url": "https://github.com/bluechill52", "followers_url": "https://api.github.com/users/bluechill52/followers", "following_url": "https://api.github.com/users/bluechill52/following{/other_user}", "gists_url": "https://api.github.com/users/bluechill52/gists{/gist_id}", "starred_url": "https://api.github.com/users/bluechill52/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bluechill52/subscriptions", "organizations_url": "https://api.github.com/users/bluechill52/orgs", "repos_url": "https://api.github.com/users/bluechill52/repos", "events_url": "https://api.github.com/users/bluechill52/events{/privacy}", "received_events_url": "https://api.github.com/users/bluechill52/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-11-12T10:01:08Z", "updated_at": "2015-11-20T19:44:26Z", "closed_at": "2015-11-20T19:44:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I've installed torch-autograd as mentioned in the github page. After installation whenever I try to run an example code, it throws the following error:\n\n`/usr/local/share/lua/5.1/autograd/gradfuns.lua:290: table index is nil stack traceback: [C]: in function 'error' /home/monarch/torch/install/share/lua/5.1/trepl/init.lua:363: in function 'require' [string \"_RESULT={require 'autograd'}\"]:1: in main chunk [C]: in function 'xpcall' /home/monarch/torch/install/share/lua/5.1/trepl/init.lua:630: in function 'repl' ...arch/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:185: in main chunk [C]: at 0x00406670`\n\nThen I noticed that the same error pops up when I just try to simply `require 'autograd'`. Help. Thanks in advance.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/14", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/14/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/14/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/14/events", "html_url": "https://github.com/twitter/torch-autograd/issues/14", "id": 116012598, "node_id": "MDU6SXNzdWUxMTYwMTI1OTg=", "number": 14, "title": "Mac OS X install", "user": {"login": "davek44", "id": 172688, "node_id": "MDQ6VXNlcjE3MjY4OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/172688?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davek44", "html_url": "https://github.com/davek44", "followers_url": "https://api.github.com/users/davek44/followers", "following_url": "https://api.github.com/users/davek44/following{/other_user}", "gists_url": "https://api.github.com/users/davek44/gists{/gist_id}", "starred_url": "https://api.github.com/users/davek44/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davek44/subscriptions", "organizations_url": "https://api.github.com/users/davek44/orgs", "repos_url": "https://api.github.com/users/davek44/repos", "events_url": "https://api.github.com/users/davek44/events{/privacy}", "received_events_url": "https://api.github.com/users/davek44/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-11-10T02:33:00Z", "updated_at": "2015-11-10T16:36:10Z", "closed_at": "2015-11-10T16:36:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Even after updating to the latest torch-distro, I'm unable to install. The log suggests it's not happy with my gcc installation, but gcc was capable of installing torch. I'm on El Capitan.\n\n```\n[davidkelley]$ sudo luarocks make\nPassword:\ncmake -E make_directory build && cd build && cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=\"/Users/davidkelley/software/torch/install/bin/..\" -DCMAKE_INSTALL_PREFIX=\"/Users/davidkelley/software/torch/install/lib/luarocks/rocks/autograd/scm-1\" && make\n-- The C compiler identification is GNU 4.9.2\n-- The CXX compiler identification is GNU 4.9.2\n-- Checking whether C compiler has -isysroot\n-- Checking whether C compiler has -isysroot - yes\n-- Checking whether C compiler supports OSX deployment target flag\n-- Checking whether C compiler supports OSX deployment target flag - yes\n-- Check for working C compiler: /usr/local/bin/gcc-4.9\n-- Check for working C compiler: /usr/local/bin/gcc-4.9 -- broken\nCMake Error at /usr/local/Cellar/cmake/3.2.2/share/cmake/Modules/CMakeTestCCompiler.cmake:61 (message):\n  The C compiler \"/usr/local/bin/gcc-4.9\" is not able to compile a simple\n  test program.\n\n  It fails with the following output:\n\n   Change Dir: /Users/davidkelley/software/torch-autograd/build/CMakeFiles/CMakeTmp\n\n  Run Build Command:\"/usr/bin/make\" \"cmTryCompileExec384197817/fast\"\n\n  /Applications/Xcode.app/Contents/Developer/usr/bin/make -f\n  CMakeFiles/cmTryCompileExec384197817.dir/build.make\n  CMakeFiles/cmTryCompileExec384197817.dir/build\n\n  /usr/local/Cellar/cmake/3.2.2/bin/cmake -E cmake_progress_report\n  /Users/davidkelley/software/torch-autograd/build/CMakeFiles/CMakeTmp/CMakeFiles\n  1\n\n  Building C object\n  CMakeFiles/cmTryCompileExec384197817.dir/testCCompiler.c.o\n\n  /usr/local/bin/gcc-4.9 -o\n  CMakeFiles/cmTryCompileExec384197817.dir/testCCompiler.c.o -c\n  /Users/davidkelley/software/torch-autograd/build/CMakeFiles/CMakeTmp/testCCompiler.c\n\n  Linking C executable cmTryCompileExec384197817\n\n  /usr/local/Cellar/cmake/3.2.2/bin/cmake -E cmake_link_script\n  CMakeFiles/cmTryCompileExec384197817.dir/link.txt --verbose=1\n\n  /usr/local/bin/gcc-4.9 -Wl,-search_paths_first\n  -Wl,-headerpad_max_install_names\n  CMakeFiles/cmTryCompileExec384197817.dir/testCCompiler.c.o -o\n  cmTryCompileExec384197817\n\n  ld: library not found for -lSystem\n\n  collect2: error: ld returned 1 exit status\n\n  make[1]: *** [cmTryCompileExec384197817] Error 1\n\n  make: *** [cmTryCompileExec384197817/fast] Error 2\n\n  CMake will not be able to correctly generate this project.\nCall Stack (most recent call first):\n\n-- Configuring incomplete, errors occurred!\nSee also \"/Users/davidkelley/software/torch-autograd/build/CMakeFiles/CMakeOutput.log\".\nSee also \"/Users/davidkelley/software/torch-autograd/build/CMakeFiles/CMakeError.log\".\n\nError: Build error: Failed building.\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/10", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/10/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/10/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/10/events", "html_url": "https://github.com/twitter/torch-autograd/issues/10", "id": 115364865, "node_id": "MDU6SXNzdWUxMTUzNjQ4NjU=", "number": 10, "title": "Support nested parameters in gradcheck", "user": {"login": "kswersky", "id": 532290, "node_id": "MDQ6VXNlcjUzMjI5MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/532290?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kswersky", "html_url": "https://github.com/kswersky", "followers_url": "https://api.github.com/users/kswersky/followers", "following_url": "https://api.github.com/users/kswersky/following{/other_user}", "gists_url": "https://api.github.com/users/kswersky/gists{/gist_id}", "starred_url": "https://api.github.com/users/kswersky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kswersky/subscriptions", "organizations_url": "https://api.github.com/users/kswersky/orgs", "repos_url": "https://api.github.com/users/kswersky/repos", "events_url": "https://api.github.com/users/kswersky/events{/privacy}", "received_events_url": "https://api.github.com/users/kswersky/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-11-05T20:14:27Z", "updated_at": "2015-11-05T21:22:45Z", "closed_at": "2015-11-05T21:22:45Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "E.g.,\nlocal params = {\nW = {W1, W2, W3},\nB = {B1, B2, B3}\n}\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/6", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/6/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/6/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/6/events", "html_url": "https://github.com/twitter/torch-autograd/issues/6", "id": 112185698, "node_id": "MDU6SXNzdWUxMTIxODU2OTg=", "number": 6, "title": "Placing Tensors into Tables for Bookkeeping Creates Infinite Loops", "user": {"login": "alexbw", "id": 161935, "node_id": "MDQ6VXNlcjE2MTkzNQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexbw", "html_url": "https://github.com/alexbw", "followers_url": "https://api.github.com/users/alexbw/followers", "following_url": "https://api.github.com/users/alexbw/following{/other_user}", "gists_url": "https://api.github.com/users/alexbw/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexbw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexbw/subscriptions", "organizations_url": "https://api.github.com/users/alexbw/orgs", "repos_url": "https://api.github.com/users/alexbw/repos", "events_url": "https://api.github.com/users/alexbw/events{/privacy}", "received_events_url": "https://api.github.com/users/alexbw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-10-19T16:43:39Z", "updated_at": "2015-11-06T18:24:29Z", "closed_at": "2015-11-06T18:24:29Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Bookkeeping in LSTMs is made easier with tables, [but currently a hack is required](https://github.com/twitter/autograd/blob/b6e67c20018d32ea4aeaf8da78239e52548d5e55/src/model.lua#L355).\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/4", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/4/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/4/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/4/events", "html_url": "https://github.com/twitter/torch-autograd/issues/4", "id": 111196448, "node_id": "MDU6SXNzdWUxMTExOTY0NDg=", "number": 4, "title": "Tapes of tapes", "user": {"login": "alexbw", "id": 161935, "node_id": "MDQ6VXNlcjE2MTkzNQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexbw", "html_url": "https://github.com/alexbw", "followers_url": "https://api.github.com/users/alexbw/followers", "following_url": "https://api.github.com/users/alexbw/following{/other_user}", "gists_url": "https://api.github.com/users/alexbw/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexbw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexbw/subscriptions", "organizations_url": "https://api.github.com/users/alexbw/orgs", "repos_url": "https://api.github.com/users/alexbw/repos", "events_url": "https://api.github.com/users/alexbw/events{/privacy}", "received_events_url": "https://api.github.com/users/alexbw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-10-13T14:49:02Z", "updated_at": "2015-12-08T17:12:33Z", "closed_at": "2015-12-08T17:12:33Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "We need to add functionality for 2nd and higher derivatives for e.g. Hessian-vector products\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/3", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/3/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/3/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/3/events", "html_url": "https://github.com/twitter/torch-autograd/issues/3", "id": 111027248, "node_id": "MDU6SXNzdWUxMTEwMjcyNDg=", "number": 3, "title": "Grads needed", "user": {"login": "alexbw", "id": 161935, "node_id": "MDQ6VXNlcjE2MTkzNQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexbw", "html_url": "https://github.com/alexbw", "followers_url": "https://api.github.com/users/alexbw/followers", "following_url": "https://api.github.com/users/alexbw/following{/other_user}", "gists_url": "https://api.github.com/users/alexbw/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexbw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexbw/subscriptions", "organizations_url": "https://api.github.com/users/alexbw/orgs", "repos_url": "https://api.github.com/users/alexbw/repos", "events_url": "https://api.github.com/users/alexbw/events{/privacy}", "received_events_url": "https://api.github.com/users/alexbw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2015-10-12T18:15:45Z", "updated_at": "2016-01-08T13:17:13Z", "closed_at": "2016-01-08T13:17:13Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "- [ ] repeatTensor\n- [x] max\n- [x] min\n- [x] cat\n- [x] new\n- [x] fill\n- [x] index\n- [ ] __index  (operator b = a[...])\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/2", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/2/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/2/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/2/events", "html_url": "https://github.com/twitter/torch-autograd/issues/2", "id": 111027099, "node_id": "MDU6SXNzdWUxMTEwMjcwOTk=", "number": 2, "title": "Error message if trying to take a grad and node is not returned", "user": {"login": "alexbw", "id": 161935, "node_id": "MDQ6VXNlcjE2MTkzNQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexbw", "html_url": "https://github.com/alexbw", "followers_url": "https://api.github.com/users/alexbw/followers", "following_url": "https://api.github.com/users/alexbw/following{/other_user}", "gists_url": "https://api.github.com/users/alexbw/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexbw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexbw/subscriptions", "organizations_url": "https://api.github.com/users/alexbw/orgs", "repos_url": "https://api.github.com/users/alexbw/repos", "events_url": "https://api.github.com/users/alexbw/events{/privacy}", "received_events_url": "https://api.github.com/users/alexbw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-10-12T18:14:46Z", "updated_at": "2015-10-19T16:41:28Z", "closed_at": "2015-10-19T16:41:28Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/twitter/torch-autograd/issues/1", "repository_url": "https://api.github.com/repos/twitter/torch-autograd", "labels_url": "https://api.github.com/repos/twitter/torch-autograd/issues/1/labels{/name}", "comments_url": "https://api.github.com/repos/twitter/torch-autograd/issues/1/comments", "events_url": "https://api.github.com/repos/twitter/torch-autograd/issues/1/events", "html_url": "https://github.com/twitter/torch-autograd/issues/1", "id": 111027058, "node_id": "MDU6SXNzdWUxMTEwMjcwNTg=", "number": 1, "title": "Proxy class methods for torch Tensors", "user": {"login": "alexbw", "id": 161935, "node_id": "MDQ6VXNlcjE2MTkzNQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexbw", "html_url": "https://github.com/alexbw", "followers_url": "https://api.github.com/users/alexbw/followers", "following_url": "https://api.github.com/users/alexbw/following{/other_user}", "gists_url": "https://api.github.com/users/alexbw/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexbw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexbw/subscriptions", "organizations_url": "https://api.github.com/users/alexbw/orgs", "repos_url": "https://api.github.com/users/alexbw/repos", "events_url": "https://api.github.com/users/alexbw/events{/privacy}", "received_events_url": "https://api.github.com/users/alexbw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-10-12T18:14:30Z", "updated_at": "2015-11-05T21:31:23Z", "closed_at": "2015-11-05T21:31:23Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Right now, A:size() will fail if A is a Node (if it's been wrapped to track computation in the forward pass). \nHowever, getValue(A):size() will work. \nShould proxy all class functions through the Node to the tensor.\n", "performed_via_github_app": null, "score": 1.0}]}