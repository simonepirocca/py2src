{"total_count": 156, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/279", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/279/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/279/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/279/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/279", "id": 640076566, "node_id": "MDU6SXNzdWU2NDAwNzY1NjY=", "number": 279, "title": "UnicodeDecodeError: 'gbk' codec can't decode byte 0xa2 in position 885: illegal multibyte sequence", "user": {"login": "wenjuanxu", "id": 45090215, "node_id": "MDQ6VXNlcjQ1MDkwMjE1", "avatar_url": "https://avatars2.githubusercontent.com/u/45090215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wenjuanxu", "html_url": "https://github.com/wenjuanxu", "followers_url": "https://api.github.com/users/wenjuanxu/followers", "following_url": "https://api.github.com/users/wenjuanxu/following{/other_user}", "gists_url": "https://api.github.com/users/wenjuanxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/wenjuanxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wenjuanxu/subscriptions", "organizations_url": "https://api.github.com/users/wenjuanxu/orgs", "repos_url": "https://api.github.com/users/wenjuanxu/repos", "events_url": "https://api.github.com/users/wenjuanxu/events{/privacy}", "received_events_url": "https://api.github.com/users/wenjuanxu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-17T01:40:32Z", "updated_at": "2020-06-22T08:32:15Z", "closed_at": "2020-06-22T08:32:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Traceback (most recent call last):\r\n  File \"E:/\u8bfe\u9898\u7ec4\u5de5\u4f5c/\u9ad8\u94c1\u9879\u76ee/\u7a0b\u5e8f/LSTM\u591a\u5206\u7c7b/LSTM_BO_g34.py\", line 103, in <module>\r\n    trials=Trials())\r\n  File \"D:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 69, in minimize\r\n    keep_temp=keep_temp)\r\n  File \"D:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 98, in base_minimizer\r\n    model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\r\n  File \"D:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 186, in get_hyperopt_model_string\r\n    source = f.read()\r\nUnicodeDecodeError: 'gbk' codec can't decode byte 0xa2 in position 885: illegal multibyte sequence\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/278", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/278/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/278/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/278/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/278", "id": 640076418, "node_id": "MDU6SXNzdWU2NDAwNzY0MTg=", "number": 278, "title": "UnicodeDecodeError: 'gbk' codec can't decode byte 0xa2 in position 885: illegal multibyte sequence", "user": {"login": "wenjuanxu", "id": 45090215, "node_id": "MDQ6VXNlcjQ1MDkwMjE1", "avatar_url": "https://avatars2.githubusercontent.com/u/45090215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wenjuanxu", "html_url": "https://github.com/wenjuanxu", "followers_url": "https://api.github.com/users/wenjuanxu/followers", "following_url": "https://api.github.com/users/wenjuanxu/following{/other_user}", "gists_url": "https://api.github.com/users/wenjuanxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/wenjuanxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wenjuanxu/subscriptions", "organizations_url": "https://api.github.com/users/wenjuanxu/orgs", "repos_url": "https://api.github.com/users/wenjuanxu/repos", "events_url": "https://api.github.com/users/wenjuanxu/events{/privacy}", "received_events_url": "https://api.github.com/users/wenjuanxu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-17T01:40:04Z", "updated_at": "2020-06-22T08:31:48Z", "closed_at": "2020-06-22T08:31:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Traceback (most recent call last):\r\n  File \"E:/\u8bfe\u9898\u7ec4\u5de5\u4f5c/\u9ad8\u94c1\u9879\u76ee/\u7a0b\u5e8f/LSTM\u591a\u5206\u7c7b/LSTM_BO_g34.py\", line 103, in <module>\r\n    trials=Trials())\r\n  File \"D:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 69, in minimize\r\n    keep_temp=keep_temp)\r\n  File \"D:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 98, in base_minimizer\r\n    model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\r\n  File \"D:\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 186, in get_hyperopt_model_string\r\n    source = f.read()\r\nUnicodeDecodeError: 'gbk' codec can't decode byte 0xa2 in position 885: illegal multibyte sequence\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/277", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/277/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/277/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/277/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/277", "id": 640075740, "node_id": "MDU6SXNzdWU2NDAwNzU3NDA=", "number": 277, "title": "UnicodeDecodeError: 'gbk' codec can't decode byte 0xa2 in position 885: illegal multibyte sequence", "user": {"login": "wenjuanxu", "id": 45090215, "node_id": "MDQ6VXNlcjQ1MDkwMjE1", "avatar_url": "https://avatars2.githubusercontent.com/u/45090215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wenjuanxu", "html_url": "https://github.com/wenjuanxu", "followers_url": "https://api.github.com/users/wenjuanxu/followers", "following_url": "https://api.github.com/users/wenjuanxu/following{/other_user}", "gists_url": "https://api.github.com/users/wenjuanxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/wenjuanxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wenjuanxu/subscriptions", "organizations_url": "https://api.github.com/users/wenjuanxu/orgs", "repos_url": "https://api.github.com/users/wenjuanxu/repos", "events_url": "https://api.github.com/users/wenjuanxu/events{/privacy}", "received_events_url": "https://api.github.com/users/wenjuanxu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-17T01:37:53Z", "updated_at": "2020-06-22T08:31:33Z", "closed_at": "2020-06-22T08:31:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Before filing an issue, please make sure to tick the following boxes.\r\n\r\n- [ ] Make sure your issue hasn't been filed already. Use GitHub search or manually check the [existing issues](https://github.com/maxpumperla/hyperas/issues), also the closed ones. Also, make sure to check the FAQ section of our [readme](https://github.com/maxpumperla/hyperas/blob/master/README.md).\r\n\r\n- [ ] Install latest hyperas from GitHub:\r\npip install git+git://github.com/maxpumperla/hyperas.git\r\n\r\n- [ ] Install latest hyperopt from GitHub:\r\npip install git+git://github.com/hyperopt/hyperopt.git\r\n\r\n- [ ] We have continuous integration running with Travis and make sure the build stays \"green\". If, after installing test utilities with `pip install pytest pytest-cov pep8 pytest-pep8`, you can't successfully run `python -m pytest` there's very likely a problem on your side that should be addressed before creating an issue.\r\n\r\n- [ ] Create a gist containing your complete script, or a minimal version of it, that can be used to reproduce your issue. Also, add your _full stack trace_ to that gist. In many cases your error message is enough to at least give some guidance.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/274", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/274/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/274/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/274/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/274", "id": 594012012, "node_id": "MDU6SXNzdWU1OTQwMTIwMTI=", "number": 274, "title": "IndexError: list index out of range", "user": {"login": "sagarg22", "id": 23224432, "node_id": "MDQ6VXNlcjIzMjI0NDMy", "avatar_url": "https://avatars2.githubusercontent.com/u/23224432?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sagarg22", "html_url": "https://github.com/sagarg22", "followers_url": "https://api.github.com/users/sagarg22/followers", "following_url": "https://api.github.com/users/sagarg22/following{/other_user}", "gists_url": "https://api.github.com/users/sagarg22/gists{/gist_id}", "starred_url": "https://api.github.com/users/sagarg22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sagarg22/subscriptions", "organizations_url": "https://api.github.com/users/sagarg22/orgs", "repos_url": "https://api.github.com/users/sagarg22/repos", "events_url": "https://api.github.com/users/sagarg22/events{/privacy}", "received_events_url": "https://api.github.com/users/sagarg22/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-04-04T19:20:06Z", "updated_at": "2020-04-07T00:11:42Z", "closed_at": "2020-04-07T00:11:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "I keep getting the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Sagar\\Projects\\Water Quality\\model_optim.py\", line 52, in <module>\r\n    trials = Trials())\r\n  File \"C:\\Users\\Sagar-PC\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperas\\optim.py\", line 72, in minimize\r\n    data_args=data_args)\r\n  File \"C:\\Users\\Sagar-PC\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperas\\optim.py\", line 101, in base_minimizer\r\n    model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack, data_args=data_args)\r\n  File \"C:\\Users\\Sagar-PC\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperas\\optim.py\", line 194, in get_hyperopt_model_string\r\n    parts = hyperparameter_names(model_string)\r\n  File \"C:\\Users\\Sagar-PC\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperas\\optim.py\", line 267, in hyperparameter_names\r\n    parts.append(parts[-1])\r\nIndexError: list index out of range\r\n```\r\nMy code can be found at: https://gist.github.com/FieryPhoenix909/450717e374f2feff7b70e3a75a98167c\r\n\r\nI have tried deleting all the comments and installing the latest versions. In my `data()` method, `preprocess()` is a method I call that is imported from another file called `preprocess.py`. It works correctly and I have tried moving all the code from `preprocess` into the `data()` method to try without the import, but I get the same error still. Any help would be greatly appreciated!\r\n\r\n**Versions:**\r\nhyperas - 0.4.1\r\nhyperopt - 0.2.3\r\nkeras - 2.3.1", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/268", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/268/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/268/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/268/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/268", "id": 546134734, "node_id": "MDU6SXNzdWU1NDYxMzQ3MzQ=", "number": 268, "title": "ModuleNotFoundError: No module named 'tensorflow' after hyperas installation ", "user": {"login": "floriancartuta", "id": 30111494, "node_id": "MDQ6VXNlcjMwMTExNDk0", "avatar_url": "https://avatars0.githubusercontent.com/u/30111494?v=4", "gravatar_id": "", "url": "https://api.github.com/users/floriancartuta", "html_url": "https://github.com/floriancartuta", "followers_url": "https://api.github.com/users/floriancartuta/followers", "following_url": "https://api.github.com/users/floriancartuta/following{/other_user}", "gists_url": "https://api.github.com/users/floriancartuta/gists{/gist_id}", "starred_url": "https://api.github.com/users/floriancartuta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/floriancartuta/subscriptions", "organizations_url": "https://api.github.com/users/floriancartuta/orgs", "repos_url": "https://api.github.com/users/floriancartuta/repos", "events_url": "https://api.github.com/users/floriancartuta/events{/privacy}", "received_events_url": "https://api.github.com/users/floriancartuta/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-07T07:51:47Z", "updated_at": "2020-01-08T08:58:05Z", "closed_at": "2020-01-08T08:57:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "After I installed the hyperas through pip (pip install hyperas), I get the error: \r\n\r\n> ModuleNotFoundError: No module named 'tensorflow' for command: `from keras.models import Model, Sequential`\r\nBelow you can find the modules installed in the virtual environment.\r\n\r\nPlease advice how can I correct or revert.\r\n\r\n> \r\n>  pip  freeze\r\n> attrs==19.3.0\r\n> backcall==0.1.0\r\n> bleach==3.1.0\r\n> cloudpickle==1.2.2\r\n> cycler==0.10.0\r\n> Cython==0.29.13\r\n> decorator==4.4.1\r\n> defusedxml==0.6.0\r\n> entrypoints==0.3\r\n> future==0.18.2\r\n> h5py==2.10.0\r\n> hyperas==0.4.1\r\n> hyperopt==0.2.2\r\n> importlib-metadata==1.3.0\r\n> ipykernel==5.1.3\r\n> ipython==7.11.1\r\n> ipython-genutils==0.2.0\r\n> ipywidgets==7.5.1\r\n> jedi==0.15.2\r\n> Jinja2==2.10.3\r\n> joblib==0.14.0\r\n> jsonschema==3.2.0\r\n> jupyter==1.0.0\r\n> jupyter-client==5.3.4\r\n> jupyter-console==6.0.0\r\n> jupyter-core==4.6.1\r\n> Keras==2.3.1\r\n> Keras-Applications==1.0.8\r\n> Keras-Preprocessing==1.1.0\r\n> kiwisolver==1.1.0\r\n> llvmlite==0.30.0\r\n> MarkupSafe==1.1.1\r\n> matplotlib==3.1.1\r\n> mistune==0.8.4\r\n> more-itertools==8.0.2\r\n> nbconvert==5.6.1\r\n> nbformat==5.0.3\r\n> networkx==2.2\r\n> notebook==6.0.2\r\n> numba==0.46.0\r\n> numpy==1.17.3\r\n> pandas==0.25.2\r\n> pandocfilters==1.4.2\r\n> parso==0.5.2\r\n> patsy==0.5.1\r\n> pexpect==4.7.0\r\n> pickleshare==0.7.5\r\n> prometheus-client==0.7.1\r\n> prompt-toolkit==2.0.10\r\n> ptyprocess==0.6.0\r\n> Pygments==2.5.2\r\n> pyod==0.7.5\r\n> pyparsing==2.4.5\r\n> pyramid-arima==0.9.0\r\n> pyrsistent==0.15.6\r\n> python-dateutil==2.8.0\r\n> pytz==2019.3\r\n> PyYAML==5.3\r\n> pyzmq==18.1.1\r\n> qtconsole==4.6.0\r\n> scikit-learn==0.21.3\r\n> scipy==1.3.1\r\n> Send2Trash==1.5.0\r\n> six==1.12.0\r\n> statsmodels==0.10.1\r\n> terminado==0.8.3\r\n> testpath==0.4.4\r\n> tornado==6.0.3\r\n> tqdm==4.41.1\r\n> traitlets==4.3.3\r\n> wcwidth==0.1.8\r\n> webencodings==0.5.1\r\n> widgetsnbextension==3.5.1\r\n> zipp==0.6.0\r\n> ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/264", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/264/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/264/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/264/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/264", "id": 536079295, "node_id": "MDU6SXNzdWU1MzYwNzkyOTU=", "number": 264, "title": "indentation error in data()", "user": {"login": "croshong", "id": 7292758, "node_id": "MDQ6VXNlcjcyOTI3NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/7292758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/croshong", "html_url": "https://github.com/croshong", "followers_url": "https://api.github.com/users/croshong/followers", "following_url": "https://api.github.com/users/croshong/following{/other_user}", "gists_url": "https://api.github.com/users/croshong/gists{/gist_id}", "starred_url": "https://api.github.com/users/croshong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/croshong/subscriptions", "organizations_url": "https://api.github.com/users/croshong/orgs", "repos_url": "https://api.github.com/users/croshong/repos", "events_url": "https://api.github.com/users/croshong/events{/privacy}", "received_events_url": "https://api.github.com/users/croshong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-11T00:59:02Z", "updated_at": "2019-12-13T08:22:58Z", "closed_at": "2019-12-13T08:22:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi all \r\n\r\nI'm now struggling with hyperas to optimize hyperparameter in Keras.\r\n\r\nIt seems to be almost done, but another problems !!\r\n\r\nWhen I run the python code which use hyperas, it seems another temporary  python script\r\n\r\ncalled 'temp_model.py' was generated. error was from temp_model.py as shown below\r\n\r\n Unexpected error: <class 'IndentationError'>\r\nTraceback (most recent call last):\r\n  File \"gen_chem_model_v2_beta_hyperas.py\", line 154, in <module>\r\n    best_run, best_model = optim.minimize(model=build_model,data=data,algo=tpe.suggest,max_evals=15,trials=Trials(),data_args=(sam,))\r\n  File \"/lwork01/miniconda3/lib/python3.6/site-packages/hyperas/optim.py\", line 72, in minimize\r\n    data_args=data_args)\r\n  File \"/lwork01/miniconda3/lib/python3.6/site-packages/hyperas/optim.py\", line 109, in base_minimizer\r\n    from temp_model import keras_fmin_fnct, get_space\r\n  File \"/awork10-3/jhjeon/enva_re/P35968/temp_model.py\", line 143\r\n    inp = '2qu6A_857_full_rec_env_f.txt'\r\n IndentationError: unexpected indent\r\n\r\nError text itself means simply indentation error. But I couldn't figure out why this error is generated\r\n( 2qu6A_857_full_rec_env_f.txt is my input file) \r\n\r\nAttached files are my python script \r\n\r\nAny kind of suggestion or comment would be welcomed\r\n\r\nThanks\r\n\r\n[keras_hyperas.py.txt](https://github.com/maxpumperla/hyperas/files/3947872/keras_hyperas.py.txt)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/263", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/263/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/263/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/263/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/263", "id": 533840306, "node_id": "MDU6SXNzdWU1MzM4NDAzMDY=", "number": 263, "title": "data_args i optim.minimize", "user": {"login": "croshong", "id": 7292758, "node_id": "MDQ6VXNlcjcyOTI3NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/7292758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/croshong", "html_url": "https://github.com/croshong", "followers_url": "https://api.github.com/users/croshong/followers", "following_url": "https://api.github.com/users/croshong/following{/other_user}", "gists_url": "https://api.github.com/users/croshong/gists{/gist_id}", "starred_url": "https://api.github.com/users/croshong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/croshong/subscriptions", "organizations_url": "https://api.github.com/users/croshong/orgs", "repos_url": "https://api.github.com/users/croshong/repos", "events_url": "https://api.github.com/users/croshong/events{/privacy}", "received_events_url": "https://api.github.com/users/croshong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-12-06T09:19:18Z", "updated_at": "2019-12-10T05:40:10Z", "closed_at": "2019-12-10T03:57:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi all\r\n\r\n In FAQ it is written that \r\n\r\nAnd when you run your trials, pass a tuple of arguments to be substituted in as data_args:\r\n\r\nbut When I tried to use in optim.minimize\r\n\r\nThere is an error like below\r\nTypeError: minimize() got an unexpected keyword argument 'data_args'\r\n\r\nAttached files are entire code with hyperas \r\n\r\nAnd Can I have any idea about how to pass argument in data() function?\r\n\r\nAny kind of comment or suggestion would be appreciated\r\n\r\nThanks\r\n\r\n[hyperas_code.txt](https://github.com/maxpumperla/hyperas/files/3931363/hyperas_code.txt)\r\n\r\n[hyperas_code.txt](https://github.com/maxpumperla/hyperas/files/3931360/hyperas_code.txt)\r\n\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/261", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/261/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/261/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/261/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/261", "id": 528438086, "node_id": "MDU6SXNzdWU1Mjg0MzgwODY=", "number": 261, "title": "InternalError", "user": {"login": "JKoforgh", "id": 37864271, "node_id": "MDQ6VXNlcjM3ODY0Mjcx", "avatar_url": "https://avatars2.githubusercontent.com/u/37864271?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JKoforgh", "html_url": "https://github.com/JKoforgh", "followers_url": "https://api.github.com/users/JKoforgh/followers", "following_url": "https://api.github.com/users/JKoforgh/following{/other_user}", "gists_url": "https://api.github.com/users/JKoforgh/gists{/gist_id}", "starred_url": "https://api.github.com/users/JKoforgh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JKoforgh/subscriptions", "organizations_url": "https://api.github.com/users/JKoforgh/orgs", "repos_url": "https://api.github.com/users/JKoforgh/repos", "events_url": "https://api.github.com/users/JKoforgh/events{/privacy}", "received_events_url": "https://api.github.com/users/JKoforgh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-26T01:51:57Z", "updated_at": "2019-11-26T01:53:39Z", "closed_at": "2019-11-26T01:53:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Before filing an issue, please make sure to tick the following boxes.\r\n\r\n- [ ] Make sure your issue hasn't been filed already. Use GitHub search or manually check the [existing issues](https://github.com/maxpumperla/hyperas/issues), also the closed ones. Also, make sure to check the FAQ section of our [readme](https://github.com/maxpumperla/hyperas/blob/master/README.md).\r\n\r\n- [ ] Install latest hyperas from GitHub:\r\npip install git+git://github.com/maxpumperla/hyperas.git\r\n\r\n- [ ] Install latest hyperopt from GitHub:\r\npip install git+git://github.com/hyperopt/hyperopt.git\r\n\r\n- [ ] We have continuous integration running with Travis and make sure the build stays \"green\". If, after installing test utilities with `pip install pytest pytest-cov pep8 pytest-pep8`, you can't successfully run `python -m pytest` there's very likely a problem on your side that should be addressed before creating an issue.\r\n\r\n- [ ] Create a gist containing your complete script, or a minimal version of it, that can be used to reproduce your issue. Also, add your _full stack trace_ to that gist. In many cases your error message is enough to at least give some guidance.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/260", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/260/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/260/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/260/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/260", "id": 523491079, "node_id": "MDU6SXNzdWU1MjM0OTEwNzk=", "number": 260, "title": "Is it possible to pass data set to parameter-less data() function (not load from the file)", "user": {"login": "rayguang", "id": 34669744, "node_id": "MDQ6VXNlcjM0NjY5NzQ0", "avatar_url": "https://avatars0.githubusercontent.com/u/34669744?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rayguang", "html_url": "https://github.com/rayguang", "followers_url": "https://api.github.com/users/rayguang/followers", "following_url": "https://api.github.com/users/rayguang/following{/other_user}", "gists_url": "https://api.github.com/users/rayguang/gists{/gist_id}", "starred_url": "https://api.github.com/users/rayguang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rayguang/subscriptions", "organizations_url": "https://api.github.com/users/rayguang/orgs", "repos_url": "https://api.github.com/users/rayguang/repos", "events_url": "https://api.github.com/users/rayguang/events{/privacy}", "received_events_url": "https://api.github.com/users/rayguang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-11-15T14:10:25Z", "updated_at": "2019-11-18T15:17:49Z", "closed_at": "2019-11-18T15:17:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello all,\r\n\r\nThe data function is parameter-less and all the examples are loading data from disk or existing dataset. Is there anyway to pass the data set through memory variable? Is that something can be achieved via the data_args and function parameters?\r\n\r\nFor example, my data set is the output from an existing scikit learn pipeline and I would not know the details until runtime. Of course, I can dump the output to the disk and load it within the data(), but that will add a lot of I/O time considering a moderate data set size (1G+). OR equivalently, we can save the output to DB (e.g., Cassandra) and load it from DB.\r\n\r\nIs there any better approach to pass the data set to hyperas directly in memory variable without save/load to a file/DB?\r\n\r\nThanks.\r\n\r\n>     best_run, best_model = optim.minimize(model=create_model,\r\n>                                           data=data,\r\n>                                           algo=tpe.suggest,\r\n>                                           max_evals=5,\r\n>                                           trials=Trials()) ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/259", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/259/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/259/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/259/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/259", "id": 516861158, "node_id": "MDU6SXNzdWU1MTY4NjExNTg=", "number": 259, "title": "How to use keras clear_session() with hyperas?", "user": {"login": "TimZaragori", "id": 40388619, "node_id": "MDQ6VXNlcjQwMzg4NjE5", "avatar_url": "https://avatars3.githubusercontent.com/u/40388619?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TimZaragori", "html_url": "https://github.com/TimZaragori", "followers_url": "https://api.github.com/users/TimZaragori/followers", "following_url": "https://api.github.com/users/TimZaragori/following{/other_user}", "gists_url": "https://api.github.com/users/TimZaragori/gists{/gist_id}", "starred_url": "https://api.github.com/users/TimZaragori/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TimZaragori/subscriptions", "organizations_url": "https://api.github.com/users/TimZaragori/orgs", "repos_url": "https://api.github.com/users/TimZaragori/repos", "events_url": "https://api.github.com/users/TimZaragori/events{/privacy}", "received_events_url": "https://api.github.com/users/TimZaragori/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-03T17:23:45Z", "updated_at": "2019-11-10T18:02:40Z", "closed_at": "2019-11-10T18:02:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello everyone, I am trying to use hyperas to tune the hyperparameters of my model. \r\n\r\nProblem is I must use `keras.backend.tensorflow_backend.clear_session()` after each model fitted to clear GPU memory. If I don't I am getting an error when loading the model after a few iterations (I am getting the same error when I try to loop on models outside hyperas).\r\n\r\nWhen I use `clear_session()` either at the beginning or at the end of `create_model()` I have the following error, before fitting the model if at the beginning or after fitting if placed at the end : \r\n`Traceback (most recent call last):\r\n  File \"opti_mnistrot.py\", line 841, in <module>\r\n    bayesian_optimization()\r\n  File \"opti_mnistrot.py\", line 800, in bayesian_optimization\r\n    max_evals=50, trials=Trials(), rseed=111, functions=functions, keep_temp=True)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperas\\optim.py\", line 69, in minimize\r\n    keep_temp=keep_temp)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperas\\optim.py\", line 139, in base_minimizer\r\n    return_argmin=True),\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperopt\\fmin.py\", line 403, in fmin\r\n    show_progressbar=show_progressbar,\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperopt\\base.py\", line 651, in fmin\r\n    show_progressbar=show_progressbar)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperopt\\fmin.py\", line 422, in fmin\r\n    rval.exhaust()\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperopt\\fmin.py\", line 276, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperopt\\fmin.py\", line 241, in run\r\n    self.serial_evaluate()\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperopt\\fmin.py\", line 141, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\hyperopt\\base.py\", line 856, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n  File \"C:\\Users\\stage_clinique\\Desktop\\DOPA\\Code_Python\\DonutConv\\DonutConv_TF1\\temp_model.py\", line 767, in keras_fmin_fnct\r\n    callbacks=[lrate_function], verbose=1)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\keras\\engine\\training.py\", line 1418, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 40, in fit_generator\r\n    model._make_train_function()\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\keras\\engine\\training.py\", line 509, in _make_train_function\r\n    loss=self.total_loss)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\keras\\optimizers.py\", line 484, in get_updates\r\n    lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1496, in sqrt\r\n    x = tf.clip_by_value(x, zero, inf)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py\", line 67, in clip_by_value\r\n    [t, clip_value_min, clip_value_max]) as name:\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6508, in __enter__\r\n    g = _get_graph_from_inputs(self._values)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6135, in _get_graph_from_inputs\r\n    _assert_same_graph(original_graph_element, graph_element)\r\n  File \"C:\\Users\\stage_clinique\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu1.14\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6071, in _assert_same_graph\r\n    (item, original_item))\r\nValueError: Tensor(\"training/Adam/Const:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"sub:0\", shape=(), dtype=float32).`\r\n\r\nHow should I use `clear_session()` ? Or is there another mean to clear GPU memory that is  working with hyperas?\r\n\r\nHere is the code I am using : \r\n\r\n```\r\ndef create_model(x_train, y_train, x_test, y_test):\r\n    clear_session()\r\n\r\n    layer_activation = {{choice(['relu', 'sigmoid'])}}\r\n    BN_momentum = {{choice([0.01, 0.99])}}\r\n    k_reg = {{choice([None, kk.regularizers.l1(1e-5), kk.regularizers.l1(1e-9), kk.regularizers.l2(1e-5), kk.regularizers.l2(1e-9), kk.regularizers.l1_l2(1e-5, 1e-5), kk.regularizers.l1_l2(1e-9, 1e-9)])}}\r\n    b_reg = {{choice([None, kk.regularizers.l1(1e-5), kk.regularizers.l1(1e-9), kk.regularizers.l2(1e-5), kk.regularizers.l2(1e-9), kk.regularizers.l1_l2(1e-5, 1e-5), kk.regularizers.l1_l2(1e-9, 1e-9)])}}\r\n    a_reg = {{choice([None, kk.regularizers.l1(1e-5), kk.regularizers.l1(1e-9), kk.regularizers.l2(1e-5), kk.regularizers.l2(1e-9), kk.regularizers.l1_l2(1e-5, 1e-5), kk.regularizers.l1_l2(1e-9, 1e-9)])}}\r\n\r\n    conv1_filters = {{choice([128, 256, 384])}}\r\n    conv1_size = {{choice([3, 5, 7, 9])}}\r\n    conv2_filters = {{choice([128, 256, 384])}}\r\n    conv2_size = {{choice([3, 5, 7, 9])}}\r\n    conv3_filters = {{choice([256, 512, 768])}}\r\n    conv3_size = {{choice([3, 5, 7])}}\r\n    conv4_filters = {{choice([256, 512, 768])}}\r\n    conv4_size = {{choice([3, 5, 7])}}\r\n    conv5_filters = {{choice([512, 768, 1024])}}\r\n    conv5_size = {{choice([3, 5, 7])}}\r\n    conv6_filters = {{choice([512, 768, 1024])}}\r\n    conv6_size = {{choice([3, 5, 7])}}\r\n\r\n    inputs = Input(shape=(32, 32, 1))\r\n    conv1 = Conv2D(conv1_filters, conv1_size, padding='same',\r\n                           activation=layer_activation, kernel_regularizer=k_reg, bias_regularizer=b_reg,\r\n                           activity_regularizer=a_reg)(inputs)\r\n\r\n    conv2 = Conv2D(conv2_filters, conv2_size, padding='same',\r\n                           activation=layer_activation, kernel_regularizer=k_reg, bias_regularizer=b_reg,\r\n                           activity_regularizer=a_reg)(BatchNormalization(momentum=BN_momentum)(conv1))\r\n    pool1 = MaxPooling2D(pool_size=(2, 2))(BatchNormalization(momentum=BN_momentum)(conv2))\r\n\r\n    conv3 = Conv2D(conv3_filters, conv3_size, padding='same',\r\n                           activation=layer_activation, kernel_regularizer=k_reg, bias_regularizer=b_reg,\r\n                           activity_regularizer=a_reg)(BatchNormalization(momentum=BN_momentum)(pool1))\r\n\r\n    conv4 = Conv2D(conv4_filters, conv4_size, padding='same',\r\n                           activation=layer_activation, kernel_regularizer=k_reg, bias_regularizer=b_reg,\r\n                           activity_regularizer=a_reg)(BatchNormalization(momentum=BN_momentum)(conv3))\r\n    pool2 = MaxPooling2D(pool_size=(2, 2))(BatchNormalization(momentum=BN_momentum)(conv4))\r\n\r\n    conv5 = Conv2D(conv5_filters, conv5_size, padding='same',\r\n                           activation=layer_activation, kernel_regularizer=k_reg, bias_regularizer=b_reg,\r\n                           activity_regularizer=a_reg)(BatchNormalization(momentum=BN_momentum)(pool2))\r\n\r\n    conv6 = Conv2D(conv6_filters, conv6_size, padding='same',\r\n                           activation=layer_activation, kernel_regularizer=k_reg, bias_regularizer=b_reg,\r\n                           activity_regularizer=a_reg)(BatchNormalization(momentum=BN_momentum)(conv5))\r\n\r\n    n_dense_layer = {{choice([2, 3, 4])}}\r\n\r\n    neurons_activation = {{choice(['relu', 'sigmoid'])}}\r\n    dense1_neurons = {{choice([512, 1024])}}\r\n    dense1 = Dense(dense1_neurons)(Flatten()(conv6))\r\n    bn1 = BatchNormalization(momentum=BN_momentum)(dense1)\r\n    act1 = Activation(neurons_activation)(bn1)\r\n    drop1 = Dropout({{uniform(0, 1)}})(act1)\r\n\r\n    if n_dense_layer != 2:\r\n        dense2_neurons = {{choice([512, 1024])}}\r\n        dense2 = Dense(dense2_neurons)(drop1)\r\n        bn2 = BatchNormalization(momentum=BN_momentum)(dense2)\r\n        act2 = Activation(neurons_activation)(bn2)\r\n        drop2 = Dropout({{uniform(0, 1)}})(act2)\r\n\r\n        if n_dense_layer == 4:\r\n            dense3_neurons = {{choice([512, 1024])}}\r\n            dense3 = Dense(dense3_neurons)(drop2)\r\n            bn3 = BatchNormalization(momentum=BN_momentum)(dense3)\r\n            act3 = Activation(neurons_activation)(bn3)\r\n            drop3 = Dropout({{uniform(0, 1)}})(act3)\r\n            last_dense = Dense(10, activation='softmax')(drop3)\r\n\r\n        else:\r\n            last_dense = Dense(10, activation='softmax')(drop2)\r\n\r\n    else:\r\n        last_dense = Dense(10, activation='softmax')(drop1)\r\n\r\n    model = Model(inputs=inputs, outputs=last_dense)\r\n\r\n    model.compile(optimizer={{choice([Adam(), Adadelta(), Nadam()])}}, loss=\"categorical_crossentropy\",\r\n                  metrics=['categorical_accuracy'])\r\n\r\n    lrate_policy = {{choice(['clr', 'lrate'])}}\r\n\r\n    if lrate_policy == 'clr':\r\n        minLR = 1e-4\r\n        maxLR = 1e-1\r\n        lrate_function = CyclicLR(mode='triangular', base_lr=minLR, max_lr=maxLR, step_size=5 * 100)\r\n    else:\r\n        def step_decay(epoch):\r\n            if epoch > 14:\r\n                return 0.015 * 0.8 ** (epoch - 14 + 1)\r\n            else:\r\n                return 0.015\r\n        lrate_function = kk.callbacks.LearningRateScheduler(step_decay, verbose=1)\r\n\r\n    history = model.fit_generator(generator_batch_KFoldCV(50, x_train, y_train), epochs=5,\r\n                                  validation_data=generator_batch_KFoldCV(25, x_test, y_test),\r\n                                  validation_steps=80,\r\n                                  steps_per_epoch=200,\r\n                                  callbacks=[lrate_function], verbose=1)\r\n    validation_acc = np.amax(history.history['val_categorical_accuracy'])\r\n    print('Best validation acc of epoch:', validation_acc)\r\n\r\n    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\r\n```\r\n\r\n```\r\ndef bayesian_optimization():\r\n    time1 = time.time()\r\n    functions = [CyclicLR, generator_batch_KFoldCV,]\r\n    best_run, best_model = optim.minimize(model=create_model, data=data, algo=tpe.suggest,\r\n                                          max_evals=50, trials=Trials(), rseed=111, functions=functions, keep_temp=True)\r\n\r\n    test_set_path = 'E:\\\\mnist_rotation_new\\\\Test3'\r\n\r\n    cheminsTrainX = [os.path.join(test_set_path, _) for _ in os.listdir(test_set_path)]\r\n\r\n    imagesTestX = []\r\n    labelsTestY = []\r\n\r\n    print('== Preparing Test set ==')\r\n    for _ in cheminsTrainX:\r\n        if (cheminsTrainX.index(_) + 1) % 1000 == 0:\r\n            print(str(cheminsTrainX.index(_) + 1) + '/' + str(len(cheminsTrainX)))\r\n        imageTrX = np.pad(sitk.GetArrayFromImage(sitk.ReadImage(_)), 2, mode='constant')\r\n        imagesTestX.append(imageTrX.reshape(imageTrX.shape[0], imageTrX.shape[1], 1))\r\n        repY = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\r\n        repY[int(os.path.splitext(_)[0].split('Label')[-1][:-4])] = 1\r\n        labelsTestY.append(repY)\r\n\r\n    print(\"Evalutation of best performing model:\")\r\n    print(best_model.evaluate(x=np.array(imagesTestX), y=np.array(labelsTestY)))\r\n    print(\"Best performing model chosen hyper-parameters:\")\r\n    print(best_run)\r\n    print('Time: ', time.time() - time1)\r\n```\r\n\r\nThanks for your answers.\r\n\r\nPackages versions:\r\n- Keras-gpu v2.2.4\r\n- Hyperas v0.4.1\r\n- Hyperopt v0.2.2\r\n- Tensorflow v1.14.0", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/256", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/256/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/256/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/256/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/256", "id": 497744496, "node_id": "MDU6SXNzdWU0OTc3NDQ0OTY=", "number": 256, "title": "Input data is not defined for multi-input keras model", "user": {"login": "anetschka", "id": 17731067, "node_id": "MDQ6VXNlcjE3NzMxMDY3", "avatar_url": "https://avatars3.githubusercontent.com/u/17731067?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anetschka", "html_url": "https://github.com/anetschka", "followers_url": "https://api.github.com/users/anetschka/followers", "following_url": "https://api.github.com/users/anetschka/following{/other_user}", "gists_url": "https://api.github.com/users/anetschka/gists{/gist_id}", "starred_url": "https://api.github.com/users/anetschka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anetschka/subscriptions", "organizations_url": "https://api.github.com/users/anetschka/orgs", "repos_url": "https://api.github.com/users/anetschka/repos", "events_url": "https://api.github.com/users/anetschka/events{/privacy}", "received_events_url": "https://api.github.com/users/anetschka/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-09-24T14:57:53Z", "updated_at": "2019-09-27T14:20:28Z", "closed_at": "2019-09-27T14:20:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI have built a multi-input model with Keras. Hyperas (or hyperopt?) seems to hve difficulty in finding my inputs.\r\n\r\nMy data generator looks as follows (DataGetter is a custom class):\r\n![data](https://user-images.githubusercontent.com/17731067/65522710-739f2080-deeb-11e9-9a2f-0e74d3f59b76.PNG)\r\n\r\nThe signature of create_model looks like this:\r\n`def create_model(train, train_bitmap, train_start_end_bitmap, train_labels, dev, dev_bitmap, dev_start_end_bitmap, dev_labels)`\r\n\r\nAnd I call hyperas just like in the documentation:\r\n\r\n![hyperas](https://user-images.githubusercontent.com/17731067/65522883-bd880680-deeb-11e9-85c2-f86b230a5156.PNG)\r\n\r\nUnfortunately, the return statement in the data method seems to be flawed:\r\n\r\n![data_hyperas](https://user-images.githubusercontent.com/17731067/65523081-063fbf80-deec-11e9-8aff-7ca9858fe8bb.PNG)\r\n\r\nThis is my stacktrace:\r\n\r\n![stack](https://user-images.githubusercontent.com/17731067/65523154-253e5180-deec-11e9-9f91-7ceeceb88f40.PNG)\r\n\r\nAny hints on how to debug this?\r\n\r\nCheers,\r\nAnne\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/244", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/244/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/244/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/244/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/244", "id": 464503493, "node_id": "MDU6SXNzdWU0NjQ1MDM0OTM=", "number": 244, "title": "Support uniformint from hyperopt", "user": {"login": "JonnoFTW", "id": 650314, "node_id": "MDQ6VXNlcjY1MDMxNA==", "avatar_url": "https://avatars3.githubusercontent.com/u/650314?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JonnoFTW", "html_url": "https://github.com/JonnoFTW", "followers_url": "https://api.github.com/users/JonnoFTW/followers", "following_url": "https://api.github.com/users/JonnoFTW/following{/other_user}", "gists_url": "https://api.github.com/users/JonnoFTW/gists{/gist_id}", "starred_url": "https://api.github.com/users/JonnoFTW/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JonnoFTW/subscriptions", "organizations_url": "https://api.github.com/users/JonnoFTW/orgs", "repos_url": "https://api.github.com/users/JonnoFTW/repos", "events_url": "https://api.github.com/users/JonnoFTW/events{/privacy}", "received_events_url": "https://api.github.com/users/JonnoFTW/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-05T07:31:18Z", "updated_at": "2019-11-27T08:12:55Z", "closed_at": "2019-11-27T08:12:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Can we get distributions.py to include `uniformint` which was recently merged into hyperopt here: \r\n\r\nhttps://github.com/hyperopt/hyperopt/blob/762e89f14af8a6bacbcf258f8b5db063e297bcca/hyperopt/hp.py#L12\r\n\r\nI know it's bad form, but perhaps distributions.py could simply read:\r\n\r\n```python\r\nfrom hyperopt.hp import *\r\n```\r\n\r\nTo cover any future changes automatically.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/243", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/243/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/243/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/243/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/243", "id": 463807009, "node_id": "MDU6SXNzdWU0NjM4MDcwMDk=", "number": 243, "title": "Hyperas indention Error: Can't define inner functions ", "user": {"login": "Naghipourfar", "id": 16001761, "node_id": "MDQ6VXNlcjE2MDAxNzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/16001761?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Naghipourfar", "html_url": "https://github.com/Naghipourfar", "followers_url": "https://api.github.com/users/Naghipourfar/followers", "following_url": "https://api.github.com/users/Naghipourfar/following{/other_user}", "gists_url": "https://api.github.com/users/Naghipourfar/gists{/gist_id}", "starred_url": "https://api.github.com/users/Naghipourfar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Naghipourfar/subscriptions", "organizations_url": "https://api.github.com/users/Naghipourfar/orgs", "repos_url": "https://api.github.com/users/Naghipourfar/repos", "events_url": "https://api.github.com/users/Naghipourfar/events{/privacy}", "received_events_url": "https://api.github.com/users/Naghipourfar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-03T15:06:51Z", "updated_at": "2019-07-13T10:42:28Z", "closed_at": "2019-07-13T10:42:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Dear @maxpumperla, \r\n\r\nHyperas can't actually support inner functions in python and it's frustrating because when you want to write code for a single model in order to hyperopt for multiple datasets. It is impossible.  I will be very grateful if this feature can add to hyperas or if it already exists, you help me how to use it. \r\n\r\nThanks,\r\nMohsen\r\nPlease see the following code: \r\n\r\n\r\n```\r\ndef outer_data(data_name):\r\n    def inner_data():\r\n        train_data = pd.read_csv(f\"./data/{data_name}/train_{data_name}.csv\").values\r\n        valid_data = pd.read_csv(f\"./data/{data_name}/valid_{data_name}.csv\").values\r\n        return train_data, valid_data\r\n    return inner_data\r\n\r\ndef model(train_data, valid_data):\r\n    # some keras model \r\n\r\nbest_run, best_model = optim.minimize(model=model,\r\n                                      data=outer_data(\"mnist\"),\r\n                                      algo=tpe.suggest,\r\n                                      max_evals=50,\r\n                                      trials=Trials())\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/242", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/242/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/242/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/242/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/242", "id": 463274021, "node_id": "MDU6SXNzdWU0NjMyNzQwMjE=", "number": 242, "title": "choice", "user": {"login": "raymone8", "id": 17350331, "node_id": "MDQ6VXNlcjE3MzUwMzMx", "avatar_url": "https://avatars3.githubusercontent.com/u/17350331?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raymone8", "html_url": "https://github.com/raymone8", "followers_url": "https://api.github.com/users/raymone8/followers", "following_url": "https://api.github.com/users/raymone8/following{/other_user}", "gists_url": "https://api.github.com/users/raymone8/gists{/gist_id}", "starred_url": "https://api.github.com/users/raymone8/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raymone8/subscriptions", "organizations_url": "https://api.github.com/users/raymone8/orgs", "repos_url": "https://api.github.com/users/raymone8/repos", "events_url": "https://api.github.com/users/raymone8/events{/privacy}", "received_events_url": "https://api.github.com/users/raymone8/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-02T14:49:43Z", "updated_at": "2019-07-02T14:50:11Z", "closed_at": "2019-07-02T14:50:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "Before filing an issue, please make sure to tick the following boxes.\r\n\r\n- [ ] Make sure your issue hasn't been filed already. Use GitHub search or manually check the [existing issues](https://github.com/maxpumperla/hyperas/issues), also the closed ones. Also, make sure to check the FAQ section of our [readme](https://github.com/maxpumperla/hyperas/blob/master/README.md).\r\n\r\n- [ ] Install latest hyperas from GitHub:\r\npip install git+git://github.com/maxpumperla/hyperas.git\r\n\r\n- [ ] Install latest hyperopt from GitHub:\r\npip install git+git://github.com/hyperopt/hyperopt.git\r\n\r\n- [ ] We have continuous integration running with Travis and make sure the build stays \"green\". If, after installing test utilities with `pip install pytest pytest-cov pep8 pytest-pep8`, you can't successfully run `python -m pytest` there's very likely a problem on your side that should be addressed before creating an issue.\r\n\r\n- [ ] Create a gist containing your complete script, or a minimal version of it, that can be used to reproduce your issue. Also, add your _full stack trace_ to that gist. In many cases your error message is enough to at least give some guidance.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/239", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/239/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/239/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/239/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/239", "id": 456485842, "node_id": "MDU6SXNzdWU0NTY0ODU4NDI=", "number": 239, "title": "when  i introduce a customer  layer in create_model()  function ,and raise a error :name 'customer  layer' is not defined,,what shou  i do ?", "user": {"login": "cpmss521", "id": 47856948, "node_id": "MDQ6VXNlcjQ3ODU2OTQ4", "avatar_url": "https://avatars0.githubusercontent.com/u/47856948?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpmss521", "html_url": "https://github.com/cpmss521", "followers_url": "https://api.github.com/users/cpmss521/followers", "following_url": "https://api.github.com/users/cpmss521/following{/other_user}", "gists_url": "https://api.github.com/users/cpmss521/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpmss521/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpmss521/subscriptions", "organizations_url": "https://api.github.com/users/cpmss521/orgs", "repos_url": "https://api.github.com/users/cpmss521/repos", "events_url": "https://api.github.com/users/cpmss521/events{/privacy}", "received_events_url": "https://api.github.com/users/cpmss521/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-15T01:18:21Z", "updated_at": "2019-06-15T01:32:23Z", "closed_at": "2019-06-15T01:32:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Before filing an issue, please make sure to tick the following boxes.\r\n\r\n- [ ] Make sure your issue hasn't been filed already. Use GitHub search or manually check the [existing issues](https://github.com/maxpumperla/hyperas/issues), also the closed ones. Also, make sure to check the FAQ section of our [readme](https://github.com/maxpumperla/hyperas/blob/master/README.md).\r\n\r\n- [ ] Install latest hyperas from GitHub:\r\npip install git+git://github.com/maxpumperla/hyperas.git\r\n\r\n- [ ] Install latest hyperopt from GitHub:\r\npip install git+git://github.com/hyperopt/hyperopt.git\r\n\r\n- [ ] We have continuous integration running with Travis and make sure the build stays \"green\". If, after installing test utilities with `pip install pytest pytest-cov pep8 pytest-pep8`, you can't successfully run `python -m pytest` there's very likely a problem on your side that should be addressed before creating an issue.\r\n\r\n- [ ] Create a gist containing your complete script, or a minimal version of it, that can be used to reproduce your issue. Also, add your _full stack trace_ to that gist. In many cases your error message is enough to at least give some guidance.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/231", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/231/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/231/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/231/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/231", "id": 437111801, "node_id": "MDU6SXNzdWU0MzcxMTE4MDE=", "number": 231, "title": "Please give some paper or slices about the method, maybe how it works", "user": {"login": "HankerSia", "id": 32951817, "node_id": "MDQ6VXNlcjMyOTUxODE3", "avatar_url": "https://avatars0.githubusercontent.com/u/32951817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HankerSia", "html_url": "https://github.com/HankerSia", "followers_url": "https://api.github.com/users/HankerSia/followers", "following_url": "https://api.github.com/users/HankerSia/following{/other_user}", "gists_url": "https://api.github.com/users/HankerSia/gists{/gist_id}", "starred_url": "https://api.github.com/users/HankerSia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HankerSia/subscriptions", "organizations_url": "https://api.github.com/users/HankerSia/orgs", "repos_url": "https://api.github.com/users/HankerSia/repos", "events_url": "https://api.github.com/users/HankerSia/events{/privacy}", "received_events_url": "https://api.github.com/users/HankerSia/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-04-25T09:58:37Z", "updated_at": "2019-04-25T12:33:55Z", "closed_at": "2019-04-25T12:33:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using this tool, but I found little data about the principle, please give me some links or paper about how it works. Thank you very much!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/230", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/230/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/230/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/230/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/230", "id": 436674817, "node_id": "MDU6SXNzdWU0MzY2NzQ4MTc=", "number": 230, "title": "LSTM and CuDNNLSTM not working", "user": {"login": "alexv1247", "id": 46656795, "node_id": "MDQ6VXNlcjQ2NjU2Nzk1", "avatar_url": "https://avatars1.githubusercontent.com/u/46656795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexv1247", "html_url": "https://github.com/alexv1247", "followers_url": "https://api.github.com/users/alexv1247/followers", "following_url": "https://api.github.com/users/alexv1247/following{/other_user}", "gists_url": "https://api.github.com/users/alexv1247/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexv1247/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexv1247/subscriptions", "organizations_url": "https://api.github.com/users/alexv1247/orgs", "repos_url": "https://api.github.com/users/alexv1247/repos", "events_url": "https://api.github.com/users/alexv1247/events{/privacy}", "received_events_url": "https://api.github.com/users/alexv1247/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-24T12:43:34Z", "updated_at": "2019-04-24T15:09:03Z", "closed_at": "2019-04-24T15:09:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to implement bayesian optimization with hyperas for a RNN keras/tensorflow model.\r\nI followed th provided example code and got stuck with the following error:\r\n\r\n     TypeError: The added layer must be an instance of class Layer. Found: <keras.layers.recurrent.LSTM    object at 0x000001C6A74205C0>\r\n\r\nThe error occurs in : \r\n\r\n      best_run, best_model = optim.minimize(model=build_model,\r\n                                                            data=data,\r\n                                                             algo=tpe.suggest,\r\n                                                             max_evals=5,\r\n                                                             trials=Trials()) \r\n\r\nimported libraries:\r\n\r\n       from hyperas import optim\r\n       from hyperas.distributions import choice, uniform\r\n       from hyperopt import STATUS_OK, tpe, Trials\r\n       from load_data import get_preprocessed_data\r\n       from keras.layers import LSTM, Dense, Dropout, BatchNormalization \r\n\r\n\r\n\r\n\r\nI constructed the model as follows:\r\n\r\n     def build_model(x_train, y_train, x_test, y_test):\r\n         # create model\r\n          model = keras.models.Sequential()\r\n          model.add(LSTM({{choice([128, 256, 512])}}, input_shape=(x_train.shape[1:]),   return_sequences=True))\r\n          model.add(Dropout(rate={{uniform(0, 1)}}))\r\n          model.add(BatchNormalization())\r\n\r\n          model.add(LSTM({{choice([128, 256, 512])}}, return_sequences=True))\r\n          model.add(Dropout(rate={{uniform(0, 1)}}))\r\n          model.add(BatchNormalization())\r\n\r\n          model.add(LSTM({{choice([128, 256, 512])}}))\r\n          model.add(Dropout(rate={{uniform(0, 1)}}))\r\n          model.add(BatchNormalization())\r\n\r\n          model.add(Dense({{choice([16, 32, 48, 64])}}, activation='relu'))\r\n          model.add(Dropout(rate={{uniform(0, 1)}}))\r\n\r\n          model.add(Dense(2, activation='softmax'))\r\n\r\n          opt = keras.optimizers.Adam(lr=1e-3, decay=1e-6)\r\n\r\n          model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\r\n          result = model.fit(x_train, y_train,\r\n                       batch_size={{choice([64, 128])}},\r\n                       epochs=EPOCHS,\r\n                       validation_split=0.2)\r\n         validation_acc = np.amax(result.history['val_acc'])\r\n         return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\r\n\r\nI would appreciate any suggestions. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/227", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/227/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/227/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/227/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/227", "id": 432362014, "node_id": "MDU6SXNzdWU0MzIzNjIwMTQ=", "number": 227, "title": " cannot import name 'conditional' from 'hyperas.distributions'", "user": {"login": "zhang0peter", "id": 26668281, "node_id": "MDQ6VXNlcjI2NjY4Mjgx", "avatar_url": "https://avatars0.githubusercontent.com/u/26668281?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhang0peter", "html_url": "https://github.com/zhang0peter", "followers_url": "https://api.github.com/users/zhang0peter/followers", "following_url": "https://api.github.com/users/zhang0peter/following{/other_user}", "gists_url": "https://api.github.com/users/zhang0peter/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhang0peter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhang0peter/subscriptions", "organizations_url": "https://api.github.com/users/zhang0peter/orgs", "repos_url": "https://api.github.com/users/zhang0peter/repos", "events_url": "https://api.github.com/users/zhang0peter/events{/privacy}", "received_events_url": "https://api.github.com/users/zhang0peter/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-04-12T02:42:57Z", "updated_at": "2019-07-19T14:18:32Z", "closed_at": "2019-04-12T06:56:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "i use other people's code:\r\n```python\r\nfrom __future__ import print_function\r\n\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom keras.datasets import mnist\r\nfrom keras.layers.core import Dense, Dropout, Activation\r\nfrom keras.models import Sequential\r\nfrom keras.utils import np_utils\r\n\r\nfrom hyperas import optim\r\nfrom hyperas.distributions import choice, uniform, conditional\r\n```\r\nand error occured:\r\n```js\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-1-77a51f029857>\", line 10, in <module>\r\n    from hyperas.distributions import choice, uniform, conditional\r\n\r\nImportError: cannot import name 'conditional' from 'hyperas.distributions' (C:\\Users\\peter\\Anaconda3\\lib\\site-packages\\hyperas\\distributions.py)\r\n```\r\ni tryed:\r\n```js\r\npip uninstall hyperas\r\npip install git+https://github.com/maxpumperla/hyperas.git\r\npip uninstall hyperopt\r\npip install git+https://github.com/hyperopt/hyperopt.git\r\n```\r\nbut the problem is still there.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/225", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/225/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/225/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/225/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/225", "id": 419210593, "node_id": "MDU6SXNzdWU0MTkyMTA1OTM=", "number": 225, "title": "SyntaxError: invalid syntax File \"<unknown>\", line 418", "user": {"login": "naikshubham", "id": 18165547, "node_id": "MDQ6VXNlcjE4MTY1NTQ3", "avatar_url": "https://avatars3.githubusercontent.com/u/18165547?v=4", "gravatar_id": "", "url": "https://api.github.com/users/naikshubham", "html_url": "https://github.com/naikshubham", "followers_url": "https://api.github.com/users/naikshubham/followers", "following_url": "https://api.github.com/users/naikshubham/following{/other_user}", "gists_url": "https://api.github.com/users/naikshubham/gists{/gist_id}", "starred_url": "https://api.github.com/users/naikshubham/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/naikshubham/subscriptions", "organizations_url": "https://api.github.com/users/naikshubham/orgs", "repos_url": "https://api.github.com/users/naikshubham/repos", "events_url": "https://api.github.com/users/naikshubham/events{/privacy}", "received_events_url": "https://api.github.com/users/naikshubham/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-10T17:28:36Z", "updated_at": "2019-03-11T15:18:16Z", "closed_at": "2019-03-11T15:18:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Getting below error on executing the code.\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n\r\n  File \"<ipython-input-14-3eccfc64dab1>\", line 7, in <module>\r\n    notebook_name='handwritten_vs_printed_text_classifier')\r\n\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperas\\optim.py\", line 69, in minimize\r\n    keep_temp=keep_temp)\r\n\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperas\\optim.py\", line 98, in base_minimizer\r\n    model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\r\n\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperas\\optim.py\", line 189, in get_hyperopt_model_string\r\n    imports = extract_imports(cleaned_source, verbose)\r\n\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperas\\utils.py\", line 40, in extract_imports\r\n    tree = ast.parse(source)\r\n\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n\r\n  File \"<unknown>\", line 418\r\n    img = image.load_img(,grayscale=True, target_size=(img_width, img_height))\r\n                         ^\r\nSyntaxError: invalid syntax\r\n\r\n> Below is the code used\r\n\r\ndef one_hot_label(img):\r\n    label = img.split('_')[0][0]\r\n        if label == 'h':\r\n            ohl = np.array([1,0])\r\n       elif label == 'l' or 'p':\r\n           ohl = np.array([0,1])\r\n    return ohl\r\n\r\ndef train_data_with_label():\r\n    train_images = []\r\n    train_data_imgs = [file for file in os.listdir(train_data) if file.endswith(\".jpg\") or file.endswith(\".JPG\")]\r\n    for i in train_data_imgs:\r\n        path = os.path.join(train_data, i)\r\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\r\n        img = cv2.resize(img, (100, 32))\r\n        img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)[1]\r\n        train_images.append([np.array(img), one_hot_label(i)])\r\n    shuffle(train_images)\r\n    return train_images\r\n\r\ndef test_data_with_label():\r\n    test_images = []\r\n    test_data_imgs = [file for file in os.listdir(test_data) if file.endswith(\".jpg\") or file.endswith(\".JPG\")]\r\n    for i in test_data_imgs:\r\n        path = os.path.join(test_data, i)\r\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\r\n        img = cv2.resize(img, (100, 32))\r\n        img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)[1]\r\n        test_images.append([np.array(img), one_hot_label(i)])\r\n    shuffle(test_images)\r\n    return test_images`\r\n\r\ntraining_images = train_data_with_label()\r\ntesting_images = test_data_with_label()\r\n\r\ntr_img_data = np.array([i[0] for i in training_images]).reshape(-1,100,32,1)\r\ntr_lbl_data = np.array([i[1] for i in training_images])\r\n\r\ntst_img_data = np.array([i[0] for i in testing_images]).reshape(-1,100,32,1)\r\ntst_lbl_data = np.array([i[1] for i in testing_images])\r\n\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom hyperas import optim\r\nfrom hyperas.distributions import choice, uniform\r\nfrom sklearn.model_selection import train_test_split\r\n\r\ndef data():\r\n    X_train, X_val, y_train, y_val = train_test_split(tr_img_data, tr_lbl_data, test_size=0.2, random_state=12345)\r\n    X_train = X_train.reshape(-1, 100, 32, 1)\r\n    X_val = X_val.reshape(-1,100,32,1)\r\n    X_train = X_train.astype('float32')\r\n    X_val = X_val.astype('float32')\r\n    X_train /= 255\r\n    X_val /= 255\r\n    return X_train, y_train, X_val, y_val\r\n\r\n`def create_model(X_train, Y_train, X_val, Y_val):\r\n    model = Sequential()\r\n    model.add(Dense({{choice([128, 256, 512, 1024])}}, input_shape=[100, 32, 1]))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n    model.add(Dense({{choice([128, 256, 512, 1024])}}))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n    \r\n    if conditional({{choice(['two', 'three'])}}) == 'three':\r\n        model.add(Dense({{choice([128, 256, 512, 1024])}}))\r\n        model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        \r\n\r\n    model.add(Dense(10))\r\n    model.add(Activation('softmax'))\r\n\r\n    adam = keras.optimizers.Adam(lr={{choice([10**-3, 10**-2, 10**-1])}})\r\n    rmsprop = keras.optimizers.RMSprop(lr={{choice([10**-3, 10**-2, 10**-1])}})\r\n    sgd = keras.optimizers.SGD(lr={{choice([10**-3, 10**-2, 10**-1])}})\r\n   \r\n    choiceval = {{choice(['adam', 'sgd', 'rmsprop'])}}\r\n    if choiceval == 'adam':\r\n        optim = adam\r\n    elif choiceval == 'rmsprop':\r\n        optim = rmsprop\r\n    else:\r\n        optim = sgd\r\n        \r\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\r\n\r\n    model.fit(X_train, Y_train,\r\n              batch_size={{choice([100,128,256,512])}},\r\n              nb_epoch=20,\r\n              verbose=2,\r\n              validation_data=(X_val, Y_val))\r\n    score, acc = model.evaluate(X_val, Y_val, verbose=0)\r\n    print('Test accuracy:', acc)\r\n    return {'loss': -acc, 'status': STATUS_OK, 'model': model}`\r\n\r\n`if __name__ == '__main__':\r\n    best_run, best_model = optim.minimize(model=create_model,\r\n                                          data=data,\r\n                                          algo=tpe.suggest,\r\n                                          max_evals=30,\r\n                                          trials=Trials(),\r\n                                          notebook_name='handwritten_vs_printed_text_classifier')`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/223", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/223/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/223/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/223/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/223", "id": 415173303, "node_id": "MDU6SXNzdWU0MTUxNzMzMDM=", "number": 223, "title": "pip install: push new version", "user": {"login": "syzer", "id": 1989646, "node_id": "MDQ6VXNlcjE5ODk2NDY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1989646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/syzer", "html_url": "https://github.com/syzer", "followers_url": "https://api.github.com/users/syzer/followers", "following_url": "https://api.github.com/users/syzer/following{/other_user}", "gists_url": "https://api.github.com/users/syzer/gists{/gist_id}", "starred_url": "https://api.github.com/users/syzer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/syzer/subscriptions", "organizations_url": "https://api.github.com/users/syzer/orgs", "repos_url": "https://api.github.com/users/syzer/repos", "events_url": "https://api.github.com/users/syzer/events{/privacy}", "received_events_url": "https://api.github.com/users/syzer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-27T15:11:42Z", "updated_at": "2019-02-28T09:17:29Z", "closed_at": "2019-02-28T09:17:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "Currently when running mnist_distributed.py example i get error, that parameter `keep_temp` is not recognised.\r\n\r\nHad to install master branch with\r\n```bash\r\npip install  git+https://github.com/maxpumperla/hyperas.git\r\n```\r\nin order it to work\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/219", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/219/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/219/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/219/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/219", "id": 406103247, "node_id": "MDU6SXNzdWU0MDYxMDMyNDc=", "number": 219, "title": "NotImplementedError: random node already has size", "user": {"login": "datasatanic", "id": 43723188, "node_id": "MDQ6VXNlcjQzNzIzMTg4", "avatar_url": "https://avatars2.githubusercontent.com/u/43723188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/datasatanic", "html_url": "https://github.com/datasatanic", "followers_url": "https://api.github.com/users/datasatanic/followers", "following_url": "https://api.github.com/users/datasatanic/following{/other_user}", "gists_url": "https://api.github.com/users/datasatanic/gists{/gist_id}", "starred_url": "https://api.github.com/users/datasatanic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/datasatanic/subscriptions", "organizations_url": "https://api.github.com/users/datasatanic/orgs", "repos_url": "https://api.github.com/users/datasatanic/repos", "events_url": "https://api.github.com/users/datasatanic/events{/privacy}", "received_events_url": "https://api.github.com/users/datasatanic/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-03T16:09:46Z", "updated_at": "2020-03-30T14:58:55Z", "closed_at": "2020-03-30T14:58:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\n def data():\r\n    table=pd.read_csv('trainFrod.csv')    \r\n    x=scale(table.drop(columns='15'))\r\n    y=table['15']\r\n    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\r\n    sm=SMOTE()\r\n    x_train,y_train=sm.fit_resample(x_train,y_train)\r\n    x_train,y_train=shuffle(x_train,y_train)\r\n    return x_train, y_train, x_test, y_test.values\r\n```\r\n\r\n```\r\ndef model(X_train, Y_train, X_test, Y_test):\r\n\r\n    model = Sequential()\r\n    model.add(Dense(15, input_shape=(15,)))\r\n    model.add(Activation({{choice(['relu', 'sigmoid','tanh'])}}))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n    model.add(Dense({{randint(100,size=None)}}))\r\n    model.add(Activation({{choice(['relu', 'sigmoid','tanh'])}}))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n    model.add(Dense(2,activation='softmax'))\r\n    \r\n    model.name=Utils.getModelName(model)\r\n\r\n    model.compile(loss={{choice(['categorical_crossentropy','binary_crossentropy'])}},\r\n                  optimizer={{choice(['RMSprop',\r\n                                      'Adagrad',\r\n                                      'Adadelta',\r\n                                      'Adam',\r\n                                      'Adamax',\r\n                                      'Nadam'])}},\r\n                  metrics=['accuracy'])\r\n\r\n    if not os.path.exists(f\"Models/Hyperas/{model.name}\"): \r\n        os.makedirs(f\"Models/Hyperas/{model.name}\")\r\n\r\n    model.fit(X_train,\r\n              Y_train,\r\n              batch_size={{randint(100,size=None)}},\r\n              nb_epoch=20,\r\n              verbose=2,\r\n              validation_data=(X_test, Y_test),\r\n              callbacks=[\r\n                  kclb.ModelCheckpoint(filepath=f'Models/Hyperas/{model.name}/{model.name}.hdf5',save_best_only=True),\r\n                  EarlyStopping(patience=5,monitor='val_acc')\r\n              ])\r\n   \r\n    model.load_model(f'Models/Hyperas/{model.name}/{model.name}.hdf5')\r\n    pred=model.predict_classes(X_test)\r\n    cnf_matrix = confusion_matrix(Y_test,pred)\r\n    \r\n    res=cnf_matrix[0][1]+cnf_matrix[1][0]\r\n\r\n    print(f'Test accuracy:{res}')\r\n    \r\n    if (res==803):\r\n        res=1000000\r\n\r\n    return {'loss': res, 'status': STATUS_OK, 'model': model}\r\n```\r\n```\r\ntrials = Trials()\r\nbest_run, best_model = optim.minimize(model=model,\r\n                                      data=data,\r\n                                      algo=tpe.suggest,\r\n                                      max_evals=5,\r\n                                      trials=trials,\r\n                                      notebook_name='Hyperas')\r\n```\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-4-9065cd5d775c> in <module>\r\n      6                                       max_evals=5,\r\n      7                                       trials=trials,\r\n----> 8                                       notebook_name='Hyperas')\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperas\\optim.py in minimize(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\r\n     65                                      full_model_string=None,\r\n     66                                      notebook_name=notebook_name,\r\n---> 67                                      verbose=verbose)\r\n     68 \r\n     69     best_model = None\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperas\\optim.py in base_minimizer(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\r\n    131              trials=trials,\r\n    132              rstate=np.random.RandomState(rseed),\r\n--> 133              return_argmin=True),\r\n    134         get_space()\r\n    135     )\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\r\n    365             verbose=verbose,\r\n    366             catch_eval_exceptions=catch_eval_exceptions,\r\n--> 367             return_argmin=return_argmin,\r\n    368         )\r\n    369 \r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\base.py in fmin(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\r\n    633             pass_expr_memo_ctrl=pass_expr_memo_ctrl,\r\n    634             catch_eval_exceptions=catch_eval_exceptions,\r\n--> 635             return_argmin=return_argmin)\r\n    636 \r\n    637 \r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\r\n    376 \r\n    377     domain = base.Domain(fn, space,\r\n--> 378                          pass_expr_memo_ctrl=pass_expr_memo_ctrl)\r\n    379 \r\n    380     rval = FMinIter(algo, domain, trials, max_evals=max_evals,\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\base.py in __init__(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\r\n    785         # -- raises exception if expr contains cycles\r\n    786         pyll.toposort(self.expr)\r\n--> 787         vh = self.vh = VectorizeHelper(self.expr, self.s_new_ids)\r\n    788         # -- raises exception if v_expr contains cycles\r\n    789         pyll.toposort(vh.v_expr)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\vectorize.py in __init__(self, expr, expr_idxs, build)\r\n    246         self.idxs_memo = {}  # node -> union, all idxs computed\r\n    247         self.take_memo = {}  # node -> list of idxs_take retrieving node vals\r\n--> 248         self.v_expr = self.build_idxs_vals(expr, expr_idxs)\r\n    249 \r\n    250         # TODO: graph-optimization pass to remove cruft:\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\vectorize.py in build_idxs_vals(self, node, wanted_idxs)\r\n    413                 for ii, (nn, aa) in enumerate(node.named_args):\r\n    414                     all_vals.named_args.append([nn, as_apply([\r\n--> 415                         all_idxs, self.build_idxs_vals(aa, all_idxs)])])\r\n    416                     checkpoint()\r\n    417                 all_vals = vectorize_stochastic(all_vals)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\vectorize.py in build_idxs_vals(self, node, wanted_idxs)\r\n    294         if node.name == 'hyperopt_param':\r\n    295             # -- ignore, not vectorizing\r\n--> 296             return self.build_idxs_vals(node.arg['obj'], wanted_idxs)\r\n    297 \r\n    298         # -- easy exit case\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\vectorize.py in build_idxs_vals(self, node, wanted_idxs)\r\n    415                         all_idxs, self.build_idxs_vals(aa, all_idxs)])])\r\n    416                     checkpoint()\r\n--> 417                 all_vals = vectorize_stochastic(all_vals)\r\n    418 \r\n    419                 checkpoint()\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\hyperopt\\vectorize.py in vectorize_stochastic(orig)\r\n    163         n_times = scope.len(idxs)\r\n    164         if 'size' in dict(vnode.named_args):\r\n--> 165             raise NotImplementedError('random node already has size')\r\n    166         vnode.named_args.append(['size', n_times])\r\n    167         return vnode\r\n\r\nNotImplementedError: random node already has size\r\n\r\nWhen use HyperOpt I had the same problem.\r\nUse JupyterLab", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/218", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/218/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/218/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/218/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/218", "id": 404583239, "node_id": "MDU6SXNzdWU0MDQ1ODMyMzk=", "number": 218, "title": "Regarding custom loss", "user": {"login": "BenLim88", "id": 29766270, "node_id": "MDQ6VXNlcjI5NzY2Mjcw", "avatar_url": "https://avatars3.githubusercontent.com/u/29766270?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BenLim88", "html_url": "https://github.com/BenLim88", "followers_url": "https://api.github.com/users/BenLim88/followers", "following_url": "https://api.github.com/users/BenLim88/following{/other_user}", "gists_url": "https://api.github.com/users/BenLim88/gists{/gist_id}", "starred_url": "https://api.github.com/users/BenLim88/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BenLim88/subscriptions", "organizations_url": "https://api.github.com/users/BenLim88/orgs", "repos_url": "https://api.github.com/users/BenLim88/repos", "events_url": "https://api.github.com/users/BenLim88/events{/privacy}", "received_events_url": "https://api.github.com/users/BenLim88/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-01-30T03:16:08Z", "updated_at": "2019-01-30T08:55:51Z", "closed_at": "2019-01-30T08:55:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "How can I define custom loss functions in Hyperas?\r\n\r\nI am running a 4 dense layers architecture with 3 outputs. For the loss, i would like to define it as:\r\n\r\nLoss\r\n =\r\n( (Output1 Error) / max[Output1_pred, Output1_true] ) +\r\n( (Output2 Error) / max[Output2_pred, Output2_true] ) +\r\n( (Output3 Error) / max[Output3_pred, Output3_true] )\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/215", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/215/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/215/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/215/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/215", "id": 394794319, "node_id": "MDU6SXNzdWUzOTQ3OTQzMTk=", "number": 215, "title": "How to optimize number of LSTM layers using hyperas ", "user": {"login": "uttamdhakal", "id": 12582802, "node_id": "MDQ6VXNlcjEyNTgyODAy", "avatar_url": "https://avatars0.githubusercontent.com/u/12582802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/uttamdhakal", "html_url": "https://github.com/uttamdhakal", "followers_url": "https://api.github.com/users/uttamdhakal/followers", "following_url": "https://api.github.com/users/uttamdhakal/following{/other_user}", "gists_url": "https://api.github.com/users/uttamdhakal/gists{/gist_id}", "starred_url": "https://api.github.com/users/uttamdhakal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/uttamdhakal/subscriptions", "organizations_url": "https://api.github.com/users/uttamdhakal/orgs", "repos_url": "https://api.github.com/users/uttamdhakal/repos", "events_url": "https://api.github.com/users/uttamdhakal/events{/privacy}", "received_events_url": "https://api.github.com/users/uttamdhakal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-12-29T13:04:41Z", "updated_at": "2018-12-29T14:30:54Z", "closed_at": "2018-12-29T14:30:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "I think the problem lies in `return_sequences`, if I want to stack LSTM layers `return_sequences` needs to be `True` for first LSTM layers but I want to optimize the number of LSTM layers so I don't know how to get around that.\r\n\r\nI have this simple model, the program runs for certain iteration(while it checks for other parameters) but throws an error as soon as it tries to test LSTM layers. \r\n\r\n```\r\n    model = Sequential()\r\n    model.add(Embedding(max_words, embedding_dim, input_length=100))\r\n    model.add(LSTM({{choice([16,32,64,128])}}, return_sequences=True))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n    if {{choice(['three', 'four'])}} == 'four':\r\n        model.add(LSTM(100))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n    model.add(Dense(2, activation='sigmoid'))\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/214", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/214/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/214/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/214/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/214", "id": 393970821, "node_id": "MDU6SXNzdWUzOTM5NzA4MjE=", "number": 214, "title": "How can I optimize discrete hyperparameters ? Like batchsize in the range [100,1000]?", "user": {"login": "Jingfei-Liu", "id": 32126780, "node_id": "MDQ6VXNlcjMyMTI2Nzgw", "avatar_url": "https://avatars1.githubusercontent.com/u/32126780?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jingfei-Liu", "html_url": "https://github.com/Jingfei-Liu", "followers_url": "https://api.github.com/users/Jingfei-Liu/followers", "following_url": "https://api.github.com/users/Jingfei-Liu/following{/other_user}", "gists_url": "https://api.github.com/users/Jingfei-Liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jingfei-Liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jingfei-Liu/subscriptions", "organizations_url": "https://api.github.com/users/Jingfei-Liu/orgs", "repos_url": "https://api.github.com/users/Jingfei-Liu/repos", "events_url": "https://api.github.com/users/Jingfei-Liu/events{/privacy}", "received_events_url": "https://api.github.com/users/Jingfei-Liu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-12-25T06:30:00Z", "updated_at": "2019-01-30T23:09:35Z", "closed_at": "2019-01-02T08:35:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "As the title implies? Would you please help to answer this question?  \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/212", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/212/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/212/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/212/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/212", "id": 391380241, "node_id": "MDU6SXNzdWUzOTEzODAyNDE=", "number": 212, "title": "Can't use intermediate function. NameError: processing (function_name) is not defined", "user": {"login": "uttamdhakal", "id": 12582802, "node_id": "MDQ6VXNlcjEyNTgyODAy", "avatar_url": "https://avatars0.githubusercontent.com/u/12582802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/uttamdhakal", "html_url": "https://github.com/uttamdhakal", "followers_url": "https://api.github.com/users/uttamdhakal/followers", "following_url": "https://api.github.com/users/uttamdhakal/following{/other_user}", "gists_url": "https://api.github.com/users/uttamdhakal/gists{/gist_id}", "starred_url": "https://api.github.com/users/uttamdhakal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/uttamdhakal/subscriptions", "organizations_url": "https://api.github.com/users/uttamdhakal/orgs", "repos_url": "https://api.github.com/users/uttamdhakal/repos", "events_url": "https://api.github.com/users/uttamdhakal/events{/privacy}", "received_events_url": "https://api.github.com/users/uttamdhakal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-15T13:46:29Z", "updated_at": "2018-12-15T23:04:39Z", "closed_at": "2018-12-15T16:00:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to use hyperas to optimize my keras model but I keep getting `NameError: processing (function_name) is not defined.` I have already looked at [this][1] and [this][2] example from hyperas and done exactly that. It doesn't seem to work for me.\r\n\r\nThis is my code:\r\n\r\n    def processing():\r\n        df = pd.read_json('balanced_all.json')\r\n    \r\n        def label (df):\r\n            if df['rating'] < 3:\r\n                return 0\r\n            if df['rating'] > 3:\r\n                return 1\r\n    \r\n        df['label'] = df.apply (lambda df: label(df), axis=1)\r\n\r\n        df = df[['review_text', 'label']]\r\n    \r\n        maxlen = 100\r\n        max_words = 2000\r\n    \r\n        tokenizer = Tokenizer(num_words=max_words)\r\n        tokenizer.fit_on_texts(df['review_text'].values)\r\n        sequences = tokenizer.texts_to_sequences(df['review_text'].values)\r\n        word_index = tokenizer.word_index\r\n    \r\n    \r\n        sequences = pad_sequences(sequences, maxlen=maxlen)\r\n        labels = pd.get_dummies(df['label']).values\r\n    \r\n        glove_dir = '/home/uttam/Documents/Thesis/Glove'\r\n        embeddings_index = {}\r\n        f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), 'r', encoding='utf-8')\r\n        for line in f:\r\n            values = line.split()\r\n            word = values[0]\r\n            coefs = np.asarray(values[1:], dtype='float32')\r\n            embeddings_index[word] = coefs\r\n        f.close()\r\n    \r\n        embedding_dim = 100\r\n    \r\n    \r\n        embedding_matrix = np.zeros((max_words, embedding_dim))\r\n        for word, i in word_index.items():\r\n            if i < max_words:\r\n                embedding_vector = embeddings_index.get(word)\r\n                if embedding_vector is not None:\r\n                    embedding_matrix[i] = embedding_vector\r\n    \r\n        return sequences, labels, embedding_matrix\r\n    \r\n    \r\n    \r\n    def data():\r\n        sequences = processing()[0]\r\n        labels = processing()[1]\r\n        x_train, x_test, y_train, y_test = train_test_split(sequences,labels, test_size = 0.33, random_state = 42)\r\n        return x_train, y_train, x_test, y_test\r\n    \r\n    \r\n    \r\n    def create_model(x_train, y_train, x_test, y_test):\r\n        embedding_dim = 100\r\n        max_words = 2000\r\n        embedding_matrix = processing()[2]\r\n    \r\n    \r\n        model = Sequential()\r\n        model.add(Embedding(max_words, embedding_dim, input_length=100))\r\n        model.add(LSTM(128))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense(2, activation='sigmoid'))\r\n    \r\n        model.layers[0].set_weights([embedding_matrix])\r\n        model.layers[0].trainable = False\r\n    \r\n    \r\n        model.compile(optimizer={{choice(['rmsprop', 'adam', 'sgd'])}}, loss='binary_crossentropy',metrics=['acc'])\r\n        result = model.fit(x_train, y_train, epochs=20, batch_size={{choice([64, 128])}}, validation_split=0.2)\r\n        model.save('pre_trained_glove_model.h5')\r\n    \r\n    \r\n        validation_acc = np.amax(result.history['val_acc'])\r\n        print('Best validation acc of epoch:', validation_acc)\r\n        return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\r\n    \r\n    \r\n    if __name__ == '__main__':\r\n        best_run, best_model = optim.minimize(model=create_model,\r\n                                              data=data,\r\n                                              algo=tpe.suggest,\r\n                                              max_evals=5,\r\n                                              trials=Trials())\r\n        x_train, y_train, x_test, y_test = data()\r\n        print(\"Evalutation of best performing model:\")\r\n        print(best_model.evaluate(x_test, y_test))\r\n        print(\"Best performing model chosen hyper-parameters:\")\r\n        print(best_run)\r\n\r\nI don't even need the intermediate function, I had to create it because hyperas didn't find the global variable. for e.g. if I had a variable `x` outside the hyperas function say `create_model()`, It would say `NameError: x is not defined`\r\n\r\nI need this because as you can see I am using pre-trained glove embedding. I can't put everything in either `data()` or `create_model()`. For e.g. `data()`needs the variable `sequences` and `label` and `create_model` needs the variable `embedding_matrix`, so there is no way (as far as I know) to split everything in two functions.\r\n\r\nOnly way this worked for me was by putting everything in both `data()` and `create_model()` functions, which definitely is not efficient and not the way to do.\r\n\r\n\r\n\r\n  [1]: https://github.com/maxpumperla/hyperas/blob/master/examples/hyperas_in_intermediate_fns.py\r\n  [2]: https://github.com/maxpumperla/hyperas/blob/master/examples/use_intermediate_functions.py", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/206", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/206/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/206/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/206/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/206", "id": 377257961, "node_id": "MDU6SXNzdWUzNzcyNTc5NjE=", "number": 206, "title": " 'gbk' codec can't decode byte 0xae in position 48667: illegal multibyte sequence", "user": {"login": "find-happiness", "id": 1595547, "node_id": "MDQ6VXNlcjE1OTU1NDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1595547?v=4", "gravatar_id": "", "url": "https://api.github.com/users/find-happiness", "html_url": "https://github.com/find-happiness", "followers_url": "https://api.github.com/users/find-happiness/followers", "following_url": "https://api.github.com/users/find-happiness/following{/other_user}", "gists_url": "https://api.github.com/users/find-happiness/gists{/gist_id}", "starred_url": "https://api.github.com/users/find-happiness/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/find-happiness/subscriptions", "organizations_url": "https://api.github.com/users/find-happiness/orgs", "repos_url": "https://api.github.com/users/find-happiness/repos", "events_url": "https://api.github.com/users/find-happiness/events{/privacy}", "received_events_url": "https://api.github.com/users/find-happiness/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-11-05T05:42:57Z", "updated_at": "2018-11-08T10:15:20Z", "closed_at": "2018-11-08T10:15:19Z", "author_association": "NONE", "active_lock_reason": null, "body": " 'gbk' codec can't decode byte 0xae in position 48667: illegal multibyte sequence\r\n\r\ne:\\anaconda3_5_0_0\\envs\\deeplearning\\lib\\site-packages\\hyperas\\optim.py in minimize(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\r\n     65                                      full_model_string=None,\r\n     66                                      notebook_name=notebook_name,\r\n---> 67                                      verbose=verbose)\r\n     68 \r\n     69     best_model = None\r\n\r\ne:\\anaconda3_5_0_0\\envs\\deeplearning\\lib\\site-packages\\hyperas\\optim.py in base_minimizer(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\r\n     94         model_str = full_model_string\r\n     95     else:\r\n---> 96         model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\r\n     97     temp_file = './temp_model.py'\r\n     98     write_temp_files(model_str, temp_file)\r\n\r\ne:\\anaconda3_5_0_0\\envs\\deeplearning\\lib\\site-packages\\hyperas\\optim.py in get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\r\n    171         notebook_path = os.getcwd() + \"/{}.ipynb\".format(notebook_name)\r\n    172         with open(notebook_path, 'r') as f:\r\n--> 173             notebook = nbformat.reads(f.read(), nbformat.NO_CONVERT)\r\n    174             exporter = PythonExporter()\r\n    175             source, _ = exporter.from_notebook_node(notebook)\r\n\r\nUnicodeDecodeError: 'gbk' codec can't decode byte 0xae in position 48667: illegal multibyte sequence\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/204", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/204/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/204/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/204/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/204", "id": 376048349, "node_id": "MDU6SXNzdWUzNzYwNDgzNDk=", "number": 204, "title": "Number of layers", "user": {"login": "BenLim88", "id": 29766270, "node_id": "MDQ6VXNlcjI5NzY2Mjcw", "avatar_url": "https://avatars3.githubusercontent.com/u/29766270?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BenLim88", "html_url": "https://github.com/BenLim88", "followers_url": "https://api.github.com/users/BenLim88/followers", "following_url": "https://api.github.com/users/BenLim88/following{/other_user}", "gists_url": "https://api.github.com/users/BenLim88/gists{/gist_id}", "starred_url": "https://api.github.com/users/BenLim88/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BenLim88/subscriptions", "organizations_url": "https://api.github.com/users/BenLim88/orgs", "repos_url": "https://api.github.com/users/BenLim88/repos", "events_url": "https://api.github.com/users/BenLim88/events{/privacy}", "received_events_url": "https://api.github.com/users/BenLim88/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-10-31T16:22:21Z", "updated_at": "2019-08-09T08:06:22Z", "closed_at": "2018-11-05T13:17:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "We can use the following for number of layers (assuming 2 dense layers have been already defined), according to the examples:\r\n\r\n```\r\n    if conditional({{choice(['two', 'three'])}}) == 'three':\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n```\r\nIs there a way to add the number of layers by means of a number? e.g. 10 = 10 dense layers.\r\n\r\nI tried this, but in the best_run, it gives me 15 dense layers, which does not reflect the actual results\r\n\r\n```\r\n if conditional({{choice(['two', 'three','four','five','ten'])}}) == 'three':\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n    elif conditional({{choice(['two', 'three','four','five','ten'])}}) == 'four':\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n    elif conditional({{choice(['two', 'three','four','five','ten'])}}) == 'five':\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n    elif conditional({{choice(['two', 'three','four','five','ten'])}}) == 'ten':\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n        model.add(Dense({{choice([np.power(2,5),np.power(2,9),np.power(2,11)])}}))\r\n        model.add(Activation({{choice(['tanh','relu', 'sigmoid'])}}))\r\n        model.add(Dropout({{uniform(0, 1)}}))\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/203", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/203/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/203/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/203/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/203", "id": 375884377, "node_id": "MDU6SXNzdWUzNzU4ODQzNzc=", "number": 203, "title": "TypeError: object of type 'NoneType' has no len()", "user": {"login": "aojue1109", "id": 38918550, "node_id": "MDQ6VXNlcjM4OTE4NTUw", "avatar_url": "https://avatars1.githubusercontent.com/u/38918550?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aojue1109", "html_url": "https://github.com/aojue1109", "followers_url": "https://api.github.com/users/aojue1109/followers", "following_url": "https://api.github.com/users/aojue1109/following{/other_user}", "gists_url": "https://api.github.com/users/aojue1109/gists{/gist_id}", "starred_url": "https://api.github.com/users/aojue1109/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aojue1109/subscriptions", "organizations_url": "https://api.github.com/users/aojue1109/orgs", "repos_url": "https://api.github.com/users/aojue1109/repos", "events_url": "https://api.github.com/users/aojue1109/events{/privacy}", "received_events_url": "https://api.github.com/users/aojue1109/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-31T10:03:36Z", "updated_at": "2018-10-31T10:11:37Z", "closed_at": "2018-10-31T10:11:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "First time try with Hyperas. I get an error: object of type 'NoneType' has no len() at trials=Trials() in the optim.minimize(...) call. Not sure what this means. I am trying to optimize a network that takes three inputs in the form of a list X_train[], so X_train[0] has a set of input data, X_train[1] and X_train_[2] also. Not sure if that could be the cause for this error? Don't know what Hyperas can handle.\r\n\r\nHere's some code:\r\n\r\n\r\n`def create_model(base_model, train_generator,validation_generator,callbacks, steps_per_epoch, validation_steps,num_classes):\r\n    resnet50_image = Constant.resnet50_image_size\r\n    model = Sequential()\r\n    model.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:]))\r\n    model.add(Dropout({{uniform(0.1, 1)}}, name='dropout_0'))\r\n    model.add(BatchNormalization())\r\n    model.add(Dense({{choice([256, 512, 1024, 2048])}}, activation='relu',\r\n                    kernel_regularizer=regularizers.l2({{uniform(0.0001, 1)}}),\r\n                    activity_regularizer=regularizers.l1({{uniform(0.0001, 1)}})))\r\n    model.add(Dropout({{uniform(0.1, 1)}}, name='dropout_1'))\r\n    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2({{uniform(0.0001, 1)}}),\r\n                    activity_regularizer=regularizers.l1({{uniform(0.0001, 1)}})))\r\n    ## \u81ea\u52a8\u8bad\u7ec3\u7f51\u7edc\u9876\u5c42\u7ed3\u6784\uff0c\u4fdd\u5b58\u6743\u91cd\u7cfb\u6570\r\n    train_top_model(base_model=base_model,train_generator=train_generator,\r\n                    evaluate_generator=validation_generator ,num_classes=num_classes)\r\n    model.load_weights(top_model_weights_path)\r\n    model = Model(inputs=base_model.input, outputs=model(base_model.output))\r\n    for layer in model.layers[:100]:\r\n        layer.trainable = False\r\n\r\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\r\n                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\r\n\r\n    result = model.fit_generator(train_generator, epochs=200, validation_data=validation_generator,\r\n                                 steps_per_epoch=steps_per_epoch, validation_steps=validation_steps,\r\n                                 callbacks=callbacks)\r\n    validation_acc = np.amax(result.history['val_acc'])\r\n    print('Best validation acc of epoch:', validation_acc)\r\n    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/202", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/202/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/202/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/202/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/202", "id": 375880136, "node_id": "MDU6SXNzdWUzNzU4ODAxMzY=", "number": 202, "title": "TypeError: object of type 'NoneType' has no len()", "user": {"login": "aojue1109", "id": 38918550, "node_id": "MDQ6VXNlcjM4OTE4NTUw", "avatar_url": "https://avatars1.githubusercontent.com/u/38918550?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aojue1109", "html_url": "https://github.com/aojue1109", "followers_url": "https://api.github.com/users/aojue1109/followers", "following_url": "https://api.github.com/users/aojue1109/following{/other_user}", "gists_url": "https://api.github.com/users/aojue1109/gists{/gist_id}", "starred_url": "https://api.github.com/users/aojue1109/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aojue1109/subscriptions", "organizations_url": "https://api.github.com/users/aojue1109/orgs", "repos_url": "https://api.github.com/users/aojue1109/repos", "events_url": "https://api.github.com/users/aojue1109/events{/privacy}", "received_events_url": "https://api.github.com/users/aojue1109/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-31T09:53:17Z", "updated_at": "2020-01-08T04:19:19Z", "closed_at": "2018-10-31T10:00:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "I get an error: object of type 'NoneType' has no len() at trials=Trials() in the optim.minimize(...) call\r\nHere's some code:\r\n` from __future__ import print_function\r\n\r\nimport glob\r\nimport numpy as np\r\nimport time\r\n\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom keras.datasets import mnist\r\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\r\nfrom keras.models import Sequential\r\nfrom keras.utils import np_utils\r\nfrom tensorflow.keras.applications.resnet50 import ResNet50\r\nfrom hyperas import optim\r\nfrom hyperas.distributions import choice, uniform\r\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\r\nfrom tensorflow.keras.models import Model\r\nfrom keras import regularizers\r\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\r\nfrom constant import Constant\r\nfrom tensorflow.keras.preprocessing import image\r\n\r\n\r\ndef data():\r\n    \"\"\"\r\n    Data providing function:\r\n\r\n    This function is separated from create_model() so that hyperopt\r\n    won't reload data for each evaluation run.\r\n    \"\"\"\r\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n    x_train = x_train.reshape(60000, 784)\r\n    x_test = x_test.reshape(10000, 784)\r\n    x_train = x_train.astype('float32')\r\n    x_test = x_test.astype('float32')\r\n    x_train /= 255\r\n    x_test /= 255\r\n    nb_classes = 10\r\n    y_train = np_utils.to_categorical(y_train, nb_classes)\r\n    y_test = np_utils.to_categorical(y_test, nb_classes)\r\n    return x_train, y_train, x_test, y_test\r\n\r\nimport os\r\n\r\n\r\ndef get_label(path):\r\n    files = os.listdir(path)\r\n    files = files\r\n    list = []\r\n    for f in files:\r\n        list.append(f)\r\n    count = len(list)\r\n    return list, count\r\n\r\n\r\ntop_model_weights_path = 'bottleneck_fc_model.h5'\r\n\r\n\r\ndef train_top_model(base_model, train_generator, evaluate_generator,num_classes):\r\n    resnet50_image = Constant.resnet50_image_size\r\n    model = Sequential()\r\n    model.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:]))\r\n    model.add(Dropout({{uniform(0.1, 1)}}, name='dropout_0'))\r\n    model.add(BatchNormalization())\r\n    model.add(Dense({{choice([256, 512, 1024, 2048])}}, activation='relu',\r\n                    kernel_regularizer=regularizers.l2({{uniform(0.0001, 1)}}),\r\n                    activity_regularizer=regularizers.l1({{uniform(0.0001, 1)}})))\r\n    model.add(Dropout({{uniform(0.1, 1)}}, name='dropout_1'))\r\n    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2({{uniform(0.0001, 1)}}),\r\n                    activity_regularizer=regularizers.l1({{uniform(0.0001, 1)}})))\r\n\r\n    for layer in model.layers[:100]:\r\n        layer.trainable = False\r\n\r\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\r\n                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\r\n    early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=3)\r\n    model.fit_generator(train_generator,\r\n                        epochs=100, callbacks=[early_stopping],\r\n                        validation_data=evaluate_generator)\r\n    model.save_weights(top_model_weights_path)\r\n    return model\r\n\r\n\r\ndef create_model(base_model, train_generator,validation_generator,\r\n                 callbacks, steps_per_epoch, validation_steps,num_classes):\r\n\r\n    resnet50_image = Constant.resnet50_image_size\r\n\r\n    \"\"\"\r\n    Model providing function:\r\n\r\n    Create Keras model with double curly brackets dropped-in as needed.\r\n    Return value has to be a valid python dictionary with two customary keys:\r\n        - loss: Specify a numeric evaluation metric to be minimized\r\n        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n    The last one is optional, though recommended, namely:\r\n        - model: specify the model just created so that we can later use it again.\r\n    \"\"\"\r\n    model = Sequential()\r\n    model.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:]))\r\n    model.add(Dropout({{uniform(0.1, 1)}}, name='dropout_0'))\r\n    model.add(BatchNormalization())\r\n    model.add(Dense({{choice([256, 512, 1024, 2048])}}, activation='relu',\r\n                    kernel_regularizer=regularizers.l2({{uniform(0.0001, 1)}}),\r\n                    activity_regularizer=regularizers.l1({{uniform(0.0001, 1)}})))\r\n    model.add(Dropout({{uniform(0.1, 1)}}, name='dropout_1'))\r\n    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2({{uniform(0.0001, 1)}}),\r\n                    activity_regularizer=regularizers.l1({{uniform(0.0001, 1)}})))\r\n    ## \u81ea\u52a8\u8bad\u7ec3\u7f51\u7edc\u9876\u5c42\u7ed3\u6784\uff0c\u4fdd\u5b58\u6743\u91cd\u7cfb\u6570\r\n    train_top_model(base_model=base_model,train_generator=train_generator,\r\n                    evaluate_generator=validation_generator ,num_classes=num_classes)\r\n    model.load_weights(top_model_weights_path)\r\n    model = Model(inputs=base_model.input, outputs=model(base_model.output))\r\n    for layer in model.layers[:100]:\r\n        layer.trainable = False\r\n\r\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\r\n                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\r\n\r\n    result = model.fit_generator(train_generator, epochs=200, validation_data=validation_generator,\r\n                                 steps_per_epoch=steps_per_epoch, validation_steps=validation_steps,\r\n                                 callbacks=callbacks)\r\n    validation_acc = np.amax(result.history['val_acc'])\r\n    print('Best validation acc of epoch:', validation_acc)\r\n    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\r\n\r\n\r\n # \u6587\u4ef6\u5939\u540d\u5b57\u4e3a\u5206\u7c7b\u6807\u7b7e\u6570\u636e\u52a0\u8f7d\r\ndef load_data(path):\r\n    files = os.listdir(path)\r\n    images = []\r\n    labels = []\r\n    for index, f in enumerate(files):\r\n        cpath = path + f\r\n        if os.path.isfile(cpath):\r\n            img_path = cpath\r\n            img = image.load_img(img_path, target_size=())\r\n            img_array = image.img_to_array(img)\r\n            img_array = img_array.astype(np.float16)\r\n            images.append(img_array)\r\n            labels.append(index)\r\n        else:\r\n            cpath = cpath + '/'\r\n            filelist = os.listdir(cpath)\r\n            # random.shuffle(filelist)\r\n            for file in filelist:\r\n                img_path = cpath + file\r\n                img = image.load_img(img_path, target_size=(224, 224))\r\n                img_array = image.img_to_array(img)\r\n                # # \u505a\u6570\u636e\u5f52\u4e00\u5316\r\n                # img_array = img_array / 255\r\n                img_array = img_array.astype(np.float16)\r\n                images.append(img_array)\r\n                labels.append(index)\r\n    print('\u8bad\u7ec3\u6570\u636e\u91cf\uff1a%d' % len(images))\r\n    # \u628a\u6807\u7b7e\u548c\u56fe\u7247\u90fd\u653e\u5012\u4e00\u4e2a temp \u4e2d \u7136\u540e\u6253\u4e71\u987a\u5e8f\uff0c\u7136\u540e\u53d6\u51fa\u6765\r\n    temp = np.array([images, labels])\r\n    temp = temp.transpose()\r\n    # \u6253\u4e71\u987a\u5e8f\r\n    np.random.shuffle(temp)\r\n    # \u53d6\u51fa\u7b2c\u4e00\u4e2a\u5143\u7d20\u4f5c\u4e3a image \u7b2c\u4e8c\u4e2a\u5143\u7d20\u4f5c\u4e3a label\r\n    image_list = list(temp[:, 0])\r\n    label_list = list(temp[:, 1])\r\n    label_list = [int(i) for i in label_list]\r\n    image_list = np.array(image_list)\r\n    label_list = np.array(label_list)\r\n    del images, labels\r\n    print(image_list.shape)\r\n    print(label_list.shape)\r\n    # \u6570\u636e\u5f52\u4e00\u5316\u53ca\u6807\u7b7e\u5316\r\n    image_list = image_list / 255\r\n    # label_list = np_utils.to_categorical(label_list, num_classes)\r\n    return image_list, label_list\r\n # resNet50\u6a21\u578b\u8fc1\u79fb\u5b66\u4e60\r\ndef transfer_train_resNet50(train_path, evaluate_path, batch_size=64, RGB=True,\r\n                            nb_train_samples=100, nb_validation_samples=50):\r\n    image_sieze = 224\r\n    color = 3 if RGB else 1\r\n    start = time.time()\r\n    classlist, num_classes = get_label(train_path)\r\n    base_model = ResNet50(weights='imagenet', include_top=True, pooling=None,\r\n                          input_shape=(image_sieze, image_sieze, color))\r\n    base_model.summary()\r\n\r\n    train_data,train_label = load_data(train_path)\r\n    valid_data,valid_label = load_data(evaluate_path)\r\n    ## \u63d0\u53d6\u7f51\u7edc\u7279\u5f81\r\n    bottleneck_features_train = base_model.predict(\r\n        train_data,batch_size=batch_size)\r\n    np.save('bottleneck_features_train.npy', bottleneck_features_train)\r\n    bottleneck_features_validation = base_model.predict(\r\n        valid_data,batch_size=batch_size)\r\n    np.save('bottleneck_features_validation.npy', bottleneck_features_validation)\r\n    train_data = np.load('bottleneck_features_train.npy')\r\n    train_label = np_utils.to_categorical(train_label, num_classes)\r\n    validation_data = np.load('bottleneck_features_validation.npy')\r\n    validation_label = np_utils.to_categorical(valid_label, num_classes)\r\n\r\n    end = time.time()\r\n    print('\u6a21\u578b\u8bad\u7ec3\u5b8c\u6210\uff01\u8bad\u7ec3\u65f6\u95f4\uff1a%s' % ((end - start) / 60))\r\n    return train_data,train_label,validation_data,validation_label\r\n\r\ndef get_nb_files(dir):\r\n    if not os.path.exists(dir):\r\n        return 0\r\n    cnt = 0\r\n    for r, dirs, files in os.walk(dir):\r\n        for dr in dirs:\r\n            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\r\n    return cnt\r\n\r\nif __name__ == '__main__':\r\n    test_path = '/root/situ/automl_formal/static/data/test/file/'\r\n    train_path = '/root/situ/automl_formal/static/data/train/filetest/'\r\n    evaluate_path = '/root/situ/automl_formal/static/data/evaluate/filetest/'\r\n    nb_train_samples = get_nb_files(train_path)  # \u8bad\u7ec3\u6837\u672c\u4e2a\u6570\r\n    nb_classes = len(glob.glob(train_path + \"*\"))  # \u5206\u7c7b\u6570\r\n    nb_validation_samples = get_nb_files(evaluate_path)  # \u9a8c\u8bc1\u96c6\u6837\u672c\u4e2a\u6570\r\n    X_train, Y_train, X_test, Y_test = transfer_train_resNet50(train_path=train_path,\r\n                                                               evaluate_path=evaluate_path,\r\n                                                               nb_train_samples= nb_train_samples,\r\n                                                               nb_validation_samples=nb_validation_samples)\r\n    print(X_train.shape)\r\n    print(Y_train.shape)\r\n    print(X_test.shape)\r\n    print(Y_test.shape)\r\n    best_run, best_model = optim.minimize(model=create_model,\r\n                                          data=transfer_train_resNet50,\r\n                                          algo=tpe.suggest,\r\n                                          max_evals=5,\r\n                                          trials=Trials())\r\n    nb_train_samples = get_nb_files(train_path)  # \u8bad\u7ec3\u6837\u672c\u4e2a\u6570\r\n    nb_classes = len(glob.glob(train_path + \"*\"))  # \u5206\u7c7b\u6570\r\n    nb_validation_samples = get_nb_files(evaluate_path)  # \u9a8c\u8bc1\u96c6\u6837\u672c\u4e2a\u6570\r\n    X_train, Y_train, X_test, Y_test = transfer_train_resNet50(train_path=train_path,\r\n                                                               evaluate_path=evaluate_path,\r\n                                                               nb_train_samples= nb_train_samples,\r\n                                                               nb_validation_samples=nb_validation_samples)\r\n    print(\"Evalutation of best performing model:\")\r\n    print(best_model.evaluate(X_test, Y_test))\r\n    print(\"Best performing model chosen hyper-parameters:\")\r\n    print(best_run)\r\n`\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/200", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/200/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/200/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/200/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/200", "id": 371933942, "node_id": "MDU6SXNzdWUzNzE5MzM5NDI=", "number": 200, "title": "Is Cross-Validation Possible?", "user": {"login": "redraven984", "id": 13949732, "node_id": "MDQ6VXNlcjEzOTQ5NzMy", "avatar_url": "https://avatars3.githubusercontent.com/u/13949732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redraven984", "html_url": "https://github.com/redraven984", "followers_url": "https://api.github.com/users/redraven984/followers", "following_url": "https://api.github.com/users/redraven984/following{/other_user}", "gists_url": "https://api.github.com/users/redraven984/gists{/gist_id}", "starred_url": "https://api.github.com/users/redraven984/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redraven984/subscriptions", "organizations_url": "https://api.github.com/users/redraven984/orgs", "repos_url": "https://api.github.com/users/redraven984/repos", "events_url": "https://api.github.com/users/redraven984/events{/privacy}", "received_events_url": "https://api.github.com/users/redraven984/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-19T12:19:56Z", "updated_at": "2018-11-21T21:27:26Z", "closed_at": "2018-10-30T07:29:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "Before filing an issue, please make sure to tick the following boxes.\r\n\r\n- [X] Make sure your issue hasn't been filed already. Use GitHub search or manually check the [existing issues](https://github.com/maxpumperla/hyperas/issues), also the closed ones. Also, make sure to check the FAQ section of our [readme](https://github.com/maxpumperla/hyperas/blob/master/README.md).\r\n\r\n- [X] Install latest hyperas from GitHub:\r\npip install git+git://github.com/maxpumperla/hyperas.git\r\n\r\n- [X] Install latest hyperopt from GitHub:\r\npip install git+git://github.com/hyperopt/hyperopt.git\r\n\r\n- [X] We have continuous integration running with Travis and make sure the build stays \"green\". If, after installing test utilities with `pip install pytest pytest-cov pep8 pytest-pep8`, you can't successfully run `python -m pytest` there's very likely a problem on your side that should be addressed before creating an issue.\r\n\r\n- [X] Create a gist containing your complete script, or a minimal version of it, that can be used to reproduce your issue. Also, add your _full stack trace_ to that gist. In many cases your error message is enough to at least give some guidance.\r\n\r\nI have a question regarding cross-validation. The current hyperas will train parameters on a fixed set of data, but will not rotate the data sets (k-fold). Is this correct? We could of course manually force this by running K versions of hyperas script. This wouldn't be correct because we would have different parameters to reconcile at the end. Is there a way to do cross-validation in the current library? This is more to verify than to request a change. I want to make sure I'm not missing something before I try a more complex approach. Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/194", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/194/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/194/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/194/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/194", "id": 365627744, "node_id": "MDU6SXNzdWUzNjU2Mjc3NDQ=", "number": 194, "title": "EOL error : Is anyone getting this error: \"EOL while scanning string literal\"", "user": {"login": "ramazanunlu", "id": 7766694, "node_id": "MDQ6VXNlcjc3NjY2OTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/7766694?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ramazanunlu", "html_url": "https://github.com/ramazanunlu", "followers_url": "https://api.github.com/users/ramazanunlu/followers", "following_url": "https://api.github.com/users/ramazanunlu/following{/other_user}", "gists_url": "https://api.github.com/users/ramazanunlu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ramazanunlu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ramazanunlu/subscriptions", "organizations_url": "https://api.github.com/users/ramazanunlu/orgs", "repos_url": "https://api.github.com/users/ramazanunlu/repos", "events_url": "https://api.github.com/users/ramazanunlu/events{/privacy}", "received_events_url": "https://api.github.com/users/ramazanunlu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-01T20:23:28Z", "updated_at": "2018-10-02T08:06:17Z", "closed_at": "2018-10-02T08:06:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Before filing an issue, please make sure to tick the following boxes.\r\n\r\n- [ ] Make sure your issue hasn't been filed already. Use GitHub search or manually check the [existing issues](https://github.com/maxpumperla/hyperas/issues), also the closed ones. Also, make sure to check the FAQ section of our [readme](https://github.com/maxpumperla/hyperas/blob/master/README.md).\r\n\r\n- [ ] Install latest hyperas from GitHub:\r\npip install git+git://github.com/maxpumperla/hyperas.git\r\n\r\n- [ ] Install latest hyperopt from GitHub:\r\npip install git+git://github.com/hyperopt/hyperopt.git\r\n\r\n- [ ] We have continuous integration running with Travis and make sure the build stays \"green\". If, after installing test utilities with `pip install pytest pytest-cov pep8 pytest-pep8`, you can't successfully run `python -m pytest` there's very likely a problem on your side that should be addressed before creating an issue.\r\n\r\n- [ ] Create a gist containing your complete script, or a minimal version of it, that can be used to reproduce your issue. Also, add your _full stack trace_ to that gist. In many cases your error message is enough to at least give some guidance.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/193", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/193/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/193/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/193/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/193", "id": 365542964, "node_id": "MDU6SXNzdWUzNjU1NDI5NjQ=", "number": 193, "title": "Hyperparameter search and test-set", "user": {"login": "sdimi", "id": 6052419, "node_id": "MDQ6VXNlcjYwNTI0MTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/6052419?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sdimi", "html_url": "https://github.com/sdimi", "followers_url": "https://api.github.com/users/sdimi/followers", "following_url": "https://api.github.com/users/sdimi/following{/other_user}", "gists_url": "https://api.github.com/users/sdimi/gists{/gist_id}", "starred_url": "https://api.github.com/users/sdimi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sdimi/subscriptions", "organizations_url": "https://api.github.com/users/sdimi/orgs", "repos_url": "https://api.github.com/users/sdimi/repos", "events_url": "https://api.github.com/users/sdimi/events{/privacy}", "received_events_url": "https://api.github.com/users/sdimi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-01T16:32:17Z", "updated_at": "2018-10-06T14:29:40Z", "closed_at": "2018-10-06T14:29:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "A more high-level issue. In your examples it seems that you evaluate with the *test-set* in every iteration of the hyperparam-search.\r\n\r\n```python\r\nscore, acc = model.evaluate(x_test, y_test, verbose=0)\r\n```\r\n\r\nA more fair evaluation would be to consider the *validation-test* only, since by doing that you overfit to the test-set. The test-set should be seen only once in the end, when you compare it with your baselines.\r\n\r\nI'd suggest something along these lines:\r\n```python\r\nresult = model.fit(X_train....)\r\nvalidation_loss = np.amin(result.history['val_loss']) \r\nreturn {'loss': validation_loss, 'status': STATUS_OK, 'model': model}\r\n```\r\nin order to take the minimum validation loss and optimize based on that.\r\n\r\nAm I missing something obvious?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/192", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/192/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/192/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/192/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/192", "id": 365341863, "node_id": "MDU6SXNzdWUzNjUzNDE4NjM=", "number": 192, "title": "Missing 1 required positional argument when using identical distributions", "user": {"login": "JonnoFTW", "id": 650314, "node_id": "MDQ6VXNlcjY1MDMxNA==", "avatar_url": "https://avatars3.githubusercontent.com/u/650314?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JonnoFTW", "html_url": "https://github.com/JonnoFTW", "followers_url": "https://api.github.com/users/JonnoFTW/followers", "following_url": "https://api.github.com/users/JonnoFTW/following{/other_user}", "gists_url": "https://api.github.com/users/JonnoFTW/gists{/gist_id}", "starred_url": "https://api.github.com/users/JonnoFTW/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JonnoFTW/subscriptions", "organizations_url": "https://api.github.com/users/JonnoFTW/orgs", "repos_url": "https://api.github.com/users/JonnoFTW/repos", "events_url": "https://api.github.com/users/JonnoFTW/events{/privacy}", "received_events_url": "https://api.github.com/users/JonnoFTW/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-10-01T07:39:18Z", "updated_at": "2019-11-27T01:30:01Z", "closed_at": "2018-10-02T04:38:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "\r\nI'm running from the latest git (for both hyperas and hyperopt) and I get this error when running a model with multiple parameters with the same distributions:\r\n\r\n```python\r\np = {{quniform(0, 20)}}\r\nd = {{quniform(0, 3)}}\r\nq = {{quniform(0, 20)}}\r\nP = {{quniform(0, 20)}}\r\nD = {{quniform(0, 3)}}\r\nQ = {{quniform(0, 20)}}\r\ntrend = {{choice(['n', 'c', 't', 'ct'])}}\r\nL = {{choice([1440 / 5, 1440 / 5 * 7, 1440 / 5 / 24])}}\r\nuse_holidays = {{choice([True, False])}}\r\nuse_trend = {{choice([True, False])}}\r\nuse_seasonal = {{choice([True, False])}}\r\n```\r\n\r\nWhen I run the trials I get this error:\r\n\r\n```\r\n  File \"/home/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/hyperopt/tpe.py\", line 690, in build_posterior\r\n    b_post = fn(*b_args, **dict(named_args))\r\nTypeError: ap_quniform_sampler() missing 1 required positional argument: 'q'\r\n```\r\nI also get this `get_space` in my `temp_model.py`:\r\n```python\r\ndef get_space():\r\n    return {\r\n        'p': hp.quniform('p', 0, 20),\r\n        'd': hp.quniform('d', 0, 3),\r\n        'p_1': hp.quniform('p_1', 0, 20),\r\n        'p_2': hp.quniform('p_2', 0, 20),\r\n        'd_1': hp.quniform('d_1', 0, 3),\r\n        'p_3': hp.quniform('p_3', 0, 20),\r\n        'trend': hp.choice('trend', ['n', 'c', 't', 'ct']),\r\n        'L': hp.choice('L', [1440 / 5, 1440 / 5 * 7, 1440 / 5 / 24]),\r\n        'use_holidays': hp.choice('use_holidays', [True, False]),\r\n        'use_holidays_1': hp.choice('use_holidays_1', [True, False]),\r\n        'use_holidays_2': hp.choice('use_holidays_2', [True, False]),\r\n    }\r\n\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/191", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/191/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/191/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/191/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/191", "id": 365206103, "node_id": "MDU6SXNzdWUzNjUyMDYxMDM=", "number": 191, "title": "Display the current test condition", "user": {"login": "haramoz", "id": 6873268, "node_id": "MDQ6VXNlcjY4NzMyNjg=", "avatar_url": "https://avatars3.githubusercontent.com/u/6873268?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haramoz", "html_url": "https://github.com/haramoz", "followers_url": "https://api.github.com/users/haramoz/followers", "following_url": "https://api.github.com/users/haramoz/following{/other_user}", "gists_url": "https://api.github.com/users/haramoz/gists{/gist_id}", "starred_url": "https://api.github.com/users/haramoz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haramoz/subscriptions", "organizations_url": "https://api.github.com/users/haramoz/orgs", "repos_url": "https://api.github.com/users/haramoz/repos", "events_url": "https://api.github.com/users/haramoz/events{/privacy}", "received_events_url": "https://api.github.com/users/haramoz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-09-30T08:43:27Z", "updated_at": "2018-10-16T19:34:13Z", "closed_at": "2018-10-16T19:34:13Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi ,\r\n\r\nI need to ask you how to display the current test-condition for the optimization. For I am constantly bugged by cluster memory issues. My jobs run out of memory some times(working with Densenet ...) after 2 days of execution. And then all this two days worth results are just worth-less because the configs for the tests that are already done are unknown to me. \r\nOnce the best run, best model is produced I extract the details of all the run like this.\r\n        \r\n       ```for i in trials.trials:\r\n        vals = i.get('misc').get('vals')        \r\n        results = i.get('result').get('loss')\r\n        print(vals,results)```\r\nI am trying to counter that with as follows:\r\n ``` \r\n    try:\r\n         best_run, best_model = optim.minimize(...)\r\n    except:\r\n        #if exception stops the grid search\r\n        print(trials.trials)```\r\n\r\nThis is not performing that reliably, so how do I display the current test condition before/after the test starts? if this is not clear so far, I would like to get some thing like, \r\ncurrent test condition: `{'depth': [0], 'growth_rate': [1], 'nb_dense_block': [0]}` ...\r\n\r\nIs there a way for this? Please let me know. If this already exists then cool, if not, then perhaps this is more like a feature request. Thank you very much :) ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/185", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/185/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/185/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/185/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/185", "id": 352899106, "node_id": "MDU6SXNzdWUzNTI4OTkxMDY=", "number": 185, "title": "Run Hyperas with Siamese network", "user": {"login": "haramoz", "id": 6873268, "node_id": "MDQ6VXNlcjY4NzMyNjg=", "avatar_url": "https://avatars3.githubusercontent.com/u/6873268?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haramoz", "html_url": "https://github.com/haramoz", "followers_url": "https://api.github.com/users/haramoz/followers", "following_url": "https://api.github.com/users/haramoz/following{/other_user}", "gists_url": "https://api.github.com/users/haramoz/gists{/gist_id}", "starred_url": "https://api.github.com/users/haramoz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haramoz/subscriptions", "organizations_url": "https://api.github.com/users/haramoz/orgs", "repos_url": "https://api.github.com/users/haramoz/repos", "events_url": "https://api.github.com/users/haramoz/events{/privacy}", "received_events_url": "https://api.github.com/users/haramoz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2018-08-22T10:46:36Z", "updated_at": "2018-08-24T02:08:19Z", "closed_at": "2018-08-22T12:56:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I need to run the hyperas for optimizing my siamese network, But I am unable to do so. Following is my set up codes, and the error.\r\nBRANCHES OF SIAMESE:\r\n\r\ndef create_base_network(input_shape):\r\n    random_seed = 7\r\n\r\n    model = Input(shape=input_shape)\r\n    x = Conv2D(16, (3, 3), padding=\"same\",activation='relu', data_format='channels_first',\r\n               kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=random_seed),\r\n              bias_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=random_seed))(model)\r\n\r\n    x = Conv2D(16, (3, 3), padding=\"same\", activation='relu',\r\n               kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=random_seed),\r\n              bias_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=random_seed))(x)\r\n    x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\r\n\r\n    x = Conv2D(32, (3, 3), padding=\"same\", activation='relu',\r\n               kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=random_seed),\r\n              bias_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=random_seed))(x)\r\n\r\n    x = Conv2D(32, (3, 3), padding=\"same\", activation='relu',\r\n               kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=random_seed),\r\n              bias_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=random_seed))(x)\r\n\r\n    x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\r\n    x = Flatten()(x)\r\n    x = Dense({{choice([512,96,1024,2048,4096])}}, kernel_initializer=keras.initializers.he_normal(seed=random_seed),activation='relu')(x)\r\n    Dropout({{uniform(0, 1)}})\r\n    x = Dense({{choice([512,96,1024,2048,4096])}}, kernel_initializer=keras.initializers.he_normal(seed=random_seed),activation='relu')(x)\r\n    Dropout({{uniform(0, 1)}})\r\n    x = Dense({{choice([512,96,1024,2048,4096])}}, kernel_initializer=keras.initializers.he_normal(seed=random_seed),activation='relu')(x)\r\n\r\n    return Model(model,x)\r\n\r\nHOW I CREATE THE MODEL\r\ndef create_model(x_train1, x_train2, y_train,x_val1, x_val2, y_val, x_test1, x_test2, y_test):\r\n    epochs = 30\r\n    input_shape = (1,96,96)\r\n    patience_ = 1\r\n\r\n    base_network = create_base_network(input_shape)\r\n\r\n    input_a = Input(shape=input_shape)\r\n    input_b = Input(shape=input_shape)\r\n\r\n    processed_a = base_network(input_a)\r\n    processed_b = base_network(input_b)\r\n\r\n    opt = Adam(lr={{choice([1e-3,1e-4,1e-5])}})\r\n    distance = Lambda(euclidean_distance,\r\n                      output_shape=eucl_dist_output_shape)([processed_a, processed_b])\r\n    model = Model([input_a, input_b], distance)\r\n    model.compile(loss=contrastive_loss_altered, optimizer=opt, metrics=[\"accuracy\"])\r\n\r\n\r\n    es = EarlyStopping(monitor='val_acc', patience=patience_,verbose=1)\r\n    checkpointer = ModelCheckpoint(filepath='keras_weights.hdf5',\r\n                                   verbose=1,\r\n                                   save_best_only=True)\r\n    model.fit([x_train1, x_train2],y_train,\r\n          batch_size={{choice([32,64,128])}},\r\n          epochs=epochs,\r\n          validation_data=([x_val1,x_val2], y_val),\r\n          callbacks=[es],\r\n          verbose=0)\r\n\r\n    score, acc = model.evaluate([x_test1, x_test2], y_test)\r\n\r\nMAIN:\r\n\r\nif __name__ == '__main__':\r\n\r\n    x_train1, x_train2, y_train,x_val1, x_val2, y_val, x_test1, x_test2, y_test = data()\r\n\r\n    best_run, best_model = optim.minimize(model=create_model, data=data,\r\n    functions = [process_data,create_base_network,euclidean_distance,eucl_dist_output_shape,contrastive_loss_alter$\r\n    algo=tpe.suggest,max_evals=1,trials=Trials())\r\n\r\nTHEN THE ERROR I AM GETTING:\r\nError:\r\n\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"hyperas_contrastive_loss.py\", line 152, in <module>\r\n    algo=tpe.suggest,max_evals=1,trials=Trials())\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperas/optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperopt/fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperopt/fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperopt/fmin.py\", line 173, in run\r\n    self.serial_evaluate()\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperopt/base.py\", line 840, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n  File \"/home/amalli2s/thesis/keras/temp_model.py\", line 222, in keras_fmin_fnct\r\n  File \"/home/amalli2s/thesis/keras/temp_model.py\", line 192, in create_base_network\r\n  File \"/home/amalli2s/anaconda3/envs/iwin/lib/python3.6/site-packages/hyperopt/pyll_utils.py\", line 21, in wrapper\r\n    raise TypeError('require string label')\r\nTypeError: require string label\r\n\r\nThis error seems to be popular, but i don't see a specific solution or guide line to fix it yet. Can any one help me with this issue?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/180", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/180/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/180/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/180/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/180", "id": 336358583, "node_id": "MDU6SXNzdWUzMzYzNTg1ODM=", "number": 180, "title": "batch_size error", "user": {"login": "terry07", "id": 6009931, "node_id": "MDQ6VXNlcjYwMDk5MzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/6009931?v=4", "gravatar_id": "", "url": "https://api.github.com/users/terry07", "html_url": "https://github.com/terry07", "followers_url": "https://api.github.com/users/terry07/followers", "following_url": "https://api.github.com/users/terry07/following{/other_user}", "gists_url": "https://api.github.com/users/terry07/gists{/gist_id}", "starred_url": "https://api.github.com/users/terry07/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/terry07/subscriptions", "organizations_url": "https://api.github.com/users/terry07/orgs", "repos_url": "https://api.github.com/users/terry07/repos", "events_url": "https://api.github.com/users/terry07/events{/privacy}", "received_events_url": "https://api.github.com/users/terry07/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-06-27T19:31:07Z", "updated_at": "2018-06-28T09:27:09Z", "closed_at": "2018-06-28T09:26:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "i am running a similar example with the simple.py example and i am getting the following error:\r\n\r\n File \"simple_fraud.py\", line 89, in <module>\r\n    trials=Trials())\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/hyperas/optim.py\", line 132, in base_minimizer\r\n    trials=trials,\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/hyperopt/fmin.py\", line 334, in fmin\r\n    rval.exhaust()\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/hyperopt/fmin.py\", line 294, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/hyperopt/fmin.py\", line 268, in run\r\n    self.serial_evaluate()\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/hyperopt/fmin.py\", line 187, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/hyperopt/fmin.py\", line 114, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n  File \"/home/user/Seafile/kots/hyperas/temp_model.py\", line 105, in keras_fmin_fnct\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 88, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/keras/layers/core.py\", line 805, in __init__\r\n    super(Dense, self).__init__(**kwargs)\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 299, in __init__\r\n    batch_input_shape = (batch_size,) + tuple(kwargs['input_shape'])\r\nTypeError: 'int' object is not iterable\r\n\r\n\r\nCould anyone help?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/179", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/179/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/179/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/179/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/179", "id": 334765545, "node_id": "MDU6SXNzdWUzMzQ3NjU1NDU=", "number": 179, "title": "TypeError: 'generator' object is not subscriptable for the example code", "user": {"login": "DLMLPYRTRAINING", "id": 39668221, "node_id": "MDQ6VXNlcjM5NjY4MjIx", "avatar_url": "https://avatars3.githubusercontent.com/u/39668221?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DLMLPYRTRAINING", "html_url": "https://github.com/DLMLPYRTRAINING", "followers_url": "https://api.github.com/users/DLMLPYRTRAINING/followers", "following_url": "https://api.github.com/users/DLMLPYRTRAINING/following{/other_user}", "gists_url": "https://api.github.com/users/DLMLPYRTRAINING/gists{/gist_id}", "starred_url": "https://api.github.com/users/DLMLPYRTRAINING/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DLMLPYRTRAINING/subscriptions", "organizations_url": "https://api.github.com/users/DLMLPYRTRAINING/orgs", "repos_url": "https://api.github.com/users/DLMLPYRTRAINING/repos", "events_url": "https://api.github.com/users/DLMLPYRTRAINING/events{/privacy}", "received_events_url": "https://api.github.com/users/DLMLPYRTRAINING/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-06-22T06:51:09Z", "updated_at": "2020-06-18T10:51:57Z", "closed_at": "2018-06-22T07:15:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to run the example given in the readme and getting an error:\r\n\r\nPlease help.\r\n\r\nOutput and Error stack:\r\n`C:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\python.exe C:/Users/SKL/Documents/DLMLPYRTRAINING/Day6/mnist_keras_model_save_and_reload_with_hp.py\r\nC:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nUsing TensorFlow backend.\r\n>>> Imports:\r\n#coding=utf-8\r\n\r\nfrom __future__ import print_function\r\n\r\ntry:\r\n    import keras\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.datasets import mnist\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.models import Sequential, model_from_json\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.layers import Dense, Dropout, Activation\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.optimizers import RMSprop\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.utils import np_utils\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperopt import Trials, STATUS_OK, tpe\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas import optim\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas.distributions import choice, uniform, conditional\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    import datetime, os\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from matplotlib import pyplot as plt\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from random import randint\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    import numpy as np\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from PIL import Image, ImageOps\r\nexcept:\r\n    pass\r\n\r\n>>> Hyperas search space:\r\n\r\ndef get_space():\r\n    return {\r\n        'Dropout': hp.uniform('Dropout', 0, 1),\r\n        'Dense': hp.choice('Dense', [256, 512, 1024]),\r\n        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\r\n        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\r\n        'conditional': hp.choice('conditional', ['three', 'four']),\r\n        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\r\n        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\r\n        'batch_size': hp.choice('batch_size', [64, 128]),\r\n    }\r\n\r\n>>> Data\r\n  1: \r\n  2: \"\"\"\r\n  3: Data providing function:\r\n  4: \r\n  5: This function is separated from model() so that hyperopt\r\n  6: won't reload data for each evaluation run.\r\n  7: \"\"\"\r\n  8: (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n  9: x_train = x_train.reshape(60000, 784)\r\n 10: x_test = x_test.reshape(10000, 784)\r\n 11: x_train = x_train.astype('float32')\r\n 12: x_test = x_test.astype('float32')\r\n 13: x_train /= 255\r\n 14: x_test /= 255\r\n 15: nb_classes = 10\r\n 16: y_train = np_utils.to_categorical(y_train, nb_classes)\r\n 17: y_test = np_utils.to_categorical(y_test, nb_classes)\r\n 18: \r\n 19: \r\n 20: \r\n>>> Resulting replaced keras model:\r\n\r\n   1: def keras_fmin_fnct(space):\r\n   2: \r\n   3:     \"\"\"\r\n   4:     Model providing function:\r\n   5: \r\n   6:     Create Keras model with double curly brackets dropped-in as needed.\r\n   7:     Return value has to be a valid python dictionary with two customary keys:\r\n   8:         - loss: Specify a numeric evaluation metric to be minimized\r\n   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n  10:     The last one is optional, though recommended, namely:\r\n  11:         - model: specify the model just created so that we can later use it again.\r\n  12:     \"\"\"\r\n  13:     model = Sequential()\r\n  14:     model.add(Dense(512, input_shape=(784,)))\r\n  15:     model.add(Activation('relu'))\r\n  16:     model.add(Dropout(space['Dropout']))\r\n  17:     model.add(Dense(space['Dense']))\r\n  18:     model.add(Activation(space['Activation']))\r\n  19:     model.add(Dropout(space['Dropout_1']))\r\n  20: \r\n  21:     # If we choose 'four', add an additional fourth layer\r\n  22:     if conditional(space['conditional']) == 'four':\r\n  23:         model.add(Dense(100))\r\n  24: \r\n  25:         # We can also choose between complete sets of layers\r\n  26: \r\n  27:         model.add(space['add'])\r\n  28:         model.add(Activation('relu'))\r\n  29: \r\n  30:     model.add(Dense(10))\r\n  31:     model.add(Activation('softmax'))\r\n  32: \r\n  33:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\r\n  34:                   optimizer=space['optimizer'])\r\n  35: \r\n  36:     model.fit(x_train, y_train,\r\n  37:               batch_size=space['batch_size'],\r\n  38:               epochs=20,\r\n  39:               verbose=2,\r\n  40:               validation_data=(x_test, y_test))\r\n  41:     score, acc = model.evaluate(x_test, y_test, verbose=0)\r\n  42:     print('Test accuracy:', acc)\r\n  43:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\r\n  44: \r\nTraceback (most recent call last):\r\n  File \"C:/Users/SKL/Documents/DLMLPYRTRAINING/Day6/mnist_keras_model_save_and_reload_with_hp.py\", line 109, in <module>\r\n    trials=Trials())\r\n  File \"C:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"C:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperas\\optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"C:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"C:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"C:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperopt\\fmin.py\", line 314, in fmin\r\n    pass_expr_memo_ctrl=pass_expr_memo_ctrl)\r\n  File \"C:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperopt\\base.py\", line 786, in __init__\r\n    pyll.toposort(self.expr)\r\n  File \"C:\\Users\\SKL\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\hyperopt\\pyll\\base.py\", line 715, in toposort\r\n    assert order[-1] == expr\r\nTypeError: 'generator' object is not subscriptable\r\n\r\nProcess finished with exit code 1\r\n`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/172", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/172/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/172/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/172/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/172", "id": 331444203, "node_id": "MDU6SXNzdWUzMzE0NDQyMDM=", "number": 172, "title": "Import Error for Trials ", "user": {"login": "jeremiahOkai", "id": 26697852, "node_id": "MDQ6VXNlcjI2Njk3ODUy", "avatar_url": "https://avatars1.githubusercontent.com/u/26697852?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeremiahOkai", "html_url": "https://github.com/jeremiahOkai", "followers_url": "https://api.github.com/users/jeremiahOkai/followers", "following_url": "https://api.github.com/users/jeremiahOkai/following{/other_user}", "gists_url": "https://api.github.com/users/jeremiahOkai/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeremiahOkai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeremiahOkai/subscriptions", "organizations_url": "https://api.github.com/users/jeremiahOkai/orgs", "repos_url": "https://api.github.com/users/jeremiahOkai/repos", "events_url": "https://api.github.com/users/jeremiahOkai/events{/privacy}", "received_events_url": "https://api.github.com/users/jeremiahOkai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-06-12T05:40:14Z", "updated_at": "2018-06-13T07:23:36Z", "closed_at": "2018-06-13T07:23:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi guys, so after following the example on hyperas git page, I installed hyperas using pip and everything was successful but when I try executing the same example used on the git page I get this error. I have uninstalled and installed back hyperas but am still experiencing this issue. Any help will be appreaciated \r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-06b1773da367> in <module>()\r\n      1 from __future__ import print_function\r\n      2 \r\n----> 3 from hyperopt import Trials, STATUS_OK, tpe\r\n      4 from keras.datasets import mnist\r\n      5 from keras.layers.core import Dense, Dropout, Activation\r\n\r\n~/hyperopt.py in <module>()\r\n      7 \r\n      8 \r\n----> 9 from hyperopt import Trials, STATUS_OK, tpe\r\n     10 from keras.datasets import mnist\r\n     11 from keras.layers.core import Dense, Dropout, Activation\r\n\r\nImportError: cannot import name 'Trials'\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/171", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/171/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/171/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/171/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/171", "id": 330207223, "node_id": "MDU6SXNzdWUzMzAyMDcyMjM=", "number": 171, "title": "Support for keras ReduceLROnPlateau", "user": {"login": "jhmenke", "id": 25080218, "node_id": "MDQ6VXNlcjI1MDgwMjE4", "avatar_url": "https://avatars0.githubusercontent.com/u/25080218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhmenke", "html_url": "https://github.com/jhmenke", "followers_url": "https://api.github.com/users/jhmenke/followers", "following_url": "https://api.github.com/users/jhmenke/following{/other_user}", "gists_url": "https://api.github.com/users/jhmenke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhmenke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhmenke/subscriptions", "organizations_url": "https://api.github.com/users/jhmenke/orgs", "repos_url": "https://api.github.com/users/jhmenke/repos", "events_url": "https://api.github.com/users/jhmenke/events{/privacy}", "received_events_url": "https://api.github.com/users/jhmenke/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-06-07T10:15:30Z", "updated_at": "2019-04-07T11:01:37Z", "closed_at": "2018-06-13T09:35:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "If i add the ReduceLROnPlateau callback of keras into my create_model function, it results in the following error:\r\n\r\n> Traceback (most recent call last):\r\n>[...]\r\n>     return session.run(tensors, feed_dict)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n>     run_metadata_ptr)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n>     feed_dict_tensor, options, run_metadata)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n>     run_metadata)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n>     raise type(e)(node_def, op, message)\r\n> tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value Adam/lr\r\n> \t [[Node: _retval_Adam/lr_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Adam/lr)]]\r\n\r\nDid anyone encounter this before? I tried different optimizers, all with the same result.\r\nMy create_model function is pretty barebones at the moment:\r\n\r\n```\r\ndef create_model(x_train, y_train, x_test, y_test, x_validate, y_validate):\r\n    model = Sequential()\r\n    model.add(Dense(44, input_shape=(22,)))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.add(Dense(44))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.add(Dense(15))\r\n\r\n    model.compile(loss='mae', metrics=['mse'], optimizer=\"adam\")\r\n\r\n    es = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10)\r\n    rlr = ReduceLROnPlateau(factor=0.1, patience=10)\r\n    _ = model.fit(x_train, y_train, epochs=150, verbose=0, callbacks=[es, rlr],\r\n                  batch_size=24, validation_data=(x_validate, y_validate))\r\n\r\n    mae, mse = model.evaluate(x_test, y_test, verbose=0)\r\n    print('MAE:', mae)\r\n    return {'loss': mae, 'status': STATUS_OK, 'model': model}\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/170", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/170/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/170/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/170/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/170", "id": 330204817, "node_id": "MDU6SXNzdWUzMzAyMDQ4MTc=", "number": 170, "title": "Attempting to use uninitialized value Adam/lr", "user": {"login": "jhmenke", "id": 25080218, "node_id": "MDQ6VXNlcjI1MDgwMjE4", "avatar_url": "https://avatars0.githubusercontent.com/u/25080218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhmenke", "html_url": "https://github.com/jhmenke", "followers_url": "https://api.github.com/users/jhmenke/followers", "following_url": "https://api.github.com/users/jhmenke/following{/other_user}", "gists_url": "https://api.github.com/users/jhmenke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhmenke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhmenke/subscriptions", "organizations_url": "https://api.github.com/users/jhmenke/orgs", "repos_url": "https://api.github.com/users/jhmenke/repos", "events_url": "https://api.github.com/users/jhmenke/events{/privacy}", "received_events_url": "https://api.github.com/users/jhmenke/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-06-07T10:08:42Z", "updated_at": "2019-04-01T15:10:26Z", "closed_at": "2018-06-07T10:12:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nwhen trying to adapt hyperas to my problem, an unusual error appears:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"C:/Users/Jan/Desktop/PytorchSpeedTest/WindowsTest/hyperastest.py\", line 64, in <module>\r\n>     best_run, best_model = optim.minimize(model=create_model, data=data, algo=tpe.suggest, max_evals=5, trials=Trials())\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\r\n>     verbose=verbose)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperas\\optim.py\", line 133, in base_minimizer\r\n>     return_argmin=True),\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\r\n>     return_argmin=return_argmin,\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\r\n>     return_argmin=return_argmin)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\r\n>     rval.exhaust()\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\r\n>     self.run(self.max_evals - n_done, block_until_done=self.async)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\r\n>     self.serial_evaluate()\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\r\n>     result = self.domain.evaluate(spec, ctrl)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\r\n>     rval = self.fn(pyll_rval)\r\n>   File \"C:\\Users\\Jan\\Desktop\\PytorchSpeedTest\\WindowsTest\\temp_model.py\", line 93, in keras_fmin_fnct\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\keras\\models.py\", line 1002, in fit\r\n>     validation_steps=validation_steps)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1705, in fit\r\n>     validation_steps=validation_steps)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1256, in _fit_loop\r\n>     callbacks.on_epoch_end(epoch, epoch_logs)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\keras\\callbacks.py\", line 77, in on_epoch_end\r\n>     callback.on_epoch_end(epoch, logs)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\callbacks.py\", line 905, in on_epoch_end\r\n>     logs['lr'] = K.get_value(self.model.optimizer.lr)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\", line 2632, in get_value\r\n>     return x.eval(session=get_session())\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 552, in eval\r\n>     return self._variable.eval(session=session)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 710, in eval\r\n>     return _eval_using_default_session(self, feed_dict, self.graph, session)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 5180, in _eval_using_default_session\r\n>     return session.run(tensors, feed_dict)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n>     run_metadata_ptr)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n>     feed_dict_tensor, options, run_metadata)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n>     run_metadata)\r\n>   File \"C:\\Users\\Jan\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n>     raise type(e)(node_def, op, message)\r\n> tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value Adam/lr\r\n> \t [[Node: _retval_Adam/lr_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Adam/lr)]]\r\n\r\nDid anyone encounter this before? I tried different optimizers, all with the same result.\r\nMy create_model function is pretty barebones at the moment:\r\n\r\n```\r\ndef create_model(x_train, y_train, x_test, y_test, x_validate, y_validate):\r\n    model = Sequential()\r\n    model.add(Dense(44, input_shape=(22,)))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.add(Dense(44))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.add(Dense(15))\r\n\r\n    model.compile(loss='mae', metrics=['mse'], optimizer=\"adam\")\r\n\r\n    es = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10)\r\n    rlr = ReduceLROnPlateau(factor=0.1, patience=10)\r\n    _ = model.fit(x_train, y_train, epochs=150, verbose=0, callbacks=[es, rlr],\r\n                  batch_size=24, validation_data=(x_validate, y_validate))\r\n\r\n    mae, mse = model.evaluate(x_test, y_test, verbose=0)\r\n    print('MAE:', mae)\r\n    return {'loss': mae, 'status': STATUS_OK, 'model': model}\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/169", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/169/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/169/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/169/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/169", "id": 329259669, "node_id": "MDU6SXNzdWUzMjkyNTk2Njk=", "number": 169, "title": "TypeError: 'generator' object has no attribute '__getitem__'", "user": {"login": "bboynton97", "id": 6846214, "node_id": "MDQ6VXNlcjY4NDYyMTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/6846214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bboynton97", "html_url": "https://github.com/bboynton97", "followers_url": "https://api.github.com/users/bboynton97/followers", "following_url": "https://api.github.com/users/bboynton97/following{/other_user}", "gists_url": "https://api.github.com/users/bboynton97/gists{/gist_id}", "starred_url": "https://api.github.com/users/bboynton97/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bboynton97/subscriptions", "organizations_url": "https://api.github.com/users/bboynton97/orgs", "repos_url": "https://api.github.com/users/bboynton97/repos", "events_url": "https://api.github.com/users/bboynton97/events{/privacy}", "received_events_url": "https://api.github.com/users/bboynton97/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-06-05T00:19:59Z", "updated_at": "2018-06-05T17:02:34Z", "closed_at": "2018-06-05T17:02:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm running into this error when following the tutorial on my own dataset\r\n\r\n```\r\n>>> Resulting replaced keras model:\r\n\r\n   1: def keras_fmin_fnct(space):\r\n   2: \r\n   3:     model = Sequential()\r\n   4:     model.add(Dense(space['Dense'],input_dim=hm_col))\r\n   5:     model.add(Activation('relu'))\r\n   6:     model.add(Dropout(space['Dropout']))\r\n   7:     model.add(Dense(space['Dense_1']))\r\n   8:     model.add(Activation(space['Activation']))\r\n   9:     model.add(Dropout(space['Dropout_1']))\r\n  10:     \r\n  11:     if conditional(space['conditional']) == 'four':\r\n  12:         model.add(Dense(100))\r\n  13: \r\n  14:         # We can also choose between complete sets of layers\r\n  15: \r\n  16:         model.add(space['add'])\r\n  17:         model.add(Activation('relu'))\r\n  18:         \r\n  19:     model.add(Dense(10))\r\n  20:     model.add(Activation('linear'))\r\n  21: \r\n  22:     model.compile(loss='mean_absolute_error', metrics=['mae'],\r\n  23:                   optimizer=space['optimizer'])\r\n  24: \r\n  25:     model.fit(x_train, y_train,\r\n  26:               batch_size=space['batch_size'],\r\n  27:               epochs=15,\r\n  28:               verbose=2,\r\n  29:               validation_data=(x_test, y_test))\r\n  30:     \r\n  31:     mean_error = mean_absolute_error(y_true, y_scores)\r\n  32:     print('Test error:', mean_error)\r\n  33:     return {'loss': mean_error, 'status': STATUS_OK, 'model': model}\r\n  34: \r\nTraceback (most recent call last):\r\n  File \"hpo.py\", line 171, in <module>\r\n    trials=Trials())\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.py\", line 314, in fmin\r\n    pass_expr_memo_ctrl=pass_expr_memo_ctrl)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/base.py\", line 786, in __init__\r\n    pyll.toposort(self.expr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/pyll/base.py\", line 715, in toposort\r\n    assert order[-1] == expr\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/168", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/168/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/168/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/168/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/168", "id": 324077244, "node_id": "MDU6SXNzdWUzMjQwNzcyNDQ=", "number": 168, "title": "NameError: name 'x_train' is not defined", "user": {"login": "LukeDeWaal", "id": 36196737, "node_id": "MDQ6VXNlcjM2MTk2NzM3", "avatar_url": "https://avatars1.githubusercontent.com/u/36196737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LukeDeWaal", "html_url": "https://github.com/LukeDeWaal", "followers_url": "https://api.github.com/users/LukeDeWaal/followers", "following_url": "https://api.github.com/users/LukeDeWaal/following{/other_user}", "gists_url": "https://api.github.com/users/LukeDeWaal/gists{/gist_id}", "starred_url": "https://api.github.com/users/LukeDeWaal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LukeDeWaal/subscriptions", "organizations_url": "https://api.github.com/users/LukeDeWaal/orgs", "repos_url": "https://api.github.com/users/LukeDeWaal/repos", "events_url": "https://api.github.com/users/LukeDeWaal/events{/privacy}", "received_events_url": "https://api.github.com/users/LukeDeWaal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2018-05-17T15:35:37Z", "updated_at": "2019-08-23T18:49:37Z", "closed_at": "2018-05-18T17:59:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "I know a similar issue is posted in the known issues thread but it does not seem to help me. I keep getting this error no matter what I try, so perhaps I can get answers here.  My model is supposed to distinguish between 4 categories of pictures (cats, dogs, airplanes and motorbikes). \r\nI have the following code:\r\n\r\n```\r\nfrom __future__ import print_function\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport matplotlib.image as mpimg\r\nimport os\r\nfrom keras import layers, models, optimizers\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom hyperas import optim\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom hyperas.distributions import choice, uniform, conditional\r\nfrom PIL import Image as im\r\nfrom os import listdir\r\nfrom keras.datasets import mnist\r\nfrom keras.utils import np_utils\r\nfrom scipy import misc\r\n\r\nfrom keras import backend as K\r\n\r\nK.set_image_dim_ordering('tf')\r\n\r\n\r\ndef data():\r\n    \r\n    tag_dict = {'airplane':0, 'cat':1, 'dog':2, 'motorbike':3}\r\n    \r\n    base_directory      = \".\"\r\n    train_data_dir      = base_directory + \"/Train\"\r\n    validation_data_dir = base_directory + \"/Validation\"\r\n    \r\n    maxsize = (100, 100)\r\n    \r\n    trainlen = sum([len(files) for r, d, files in os.walk(train_data_dir)])\r\n    validlen = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\r\n    \r\n    train_array = np.ones((trainlen, 100, 100, 3))\r\n    train_tags  = np.ones((trainlen,))\r\n    \r\n    val_array = np.ones((validlen, 100, 100, 3))\r\n    val_tags  = np.ones((validlen,))\r\n    \r\n    itemcounter = 0\r\n    for folder in listdir(train_data_dir):\r\n        for picture in listdir(train_data_dir + \"/\" + folder):\r\n            \r\n            tempdirec = train_data_dir + \"/\" + folder + \"/\" + picture\r\n            \r\n            img = im.open(tempdirec)\r\n            img = img.resize(maxsize, im.ANTIALIAS)\r\n            \r\n            data = np.asarray(img, dtype='int32')\r\n            \r\n            if data.shape != (100, 100, 3):\r\n                \r\n                data = np.stack((data, data, data), axis=2)\r\n            \r\n            train_array[itemcounter] = data\r\n            train_tags[itemcounter] = tag_dict[folder]\r\n            \r\n            itemcounter += 1\r\n        \r\n    itemcounter = 0\r\n    for folder in listdir(validation_data_dir):\r\n        for picture in listdir(validation_data_dir + \"/\" + folder):\r\n            \r\n            tempdirec = validation_data_dir + \"/\" + folder + \"/\" + picture\r\n            \r\n            img = im.open(tempdirec)\r\n            img = img.resize(maxsize, im.ANTIALIAS)\r\n            \r\n            data = np.asarray(img, dtype='int32')\r\n            \r\n            if data.shape != (100, 100, 3):\r\n                \r\n                data = np.stack((data, data, data), axis=2)\r\n            \r\n            val_array[itemcounter] = data\r\n            val_tags[itemcounter] = tag_dict[folder]\r\n            \r\n            itemcounter += 1\r\n    \r\n    def shuffle(array, seed=16):\r\n        \r\n        np.random.seed(seed)\r\n        np.random.shuffle(array)\r\n        \r\n        return array\r\n    \r\n    nb_classes = 4\r\n    \r\n    train_array,    train_tags   = shuffle(train_array), shuffle(train_tags)\r\n    val_array,      val_tags     = shuffle(val_array),   shuffle(val_tags)  \r\n\r\n    train_tags = np_utils.to_categorical(train_tags, nb_classes)     \r\n    val_tags = np_utils.to_categorical(val_tags, nb_classes)\r\n    \r\n    return (train_array, train_tags), (val_array, val_tags)\r\n\r\n\r\n\r\n#%%\r\ndef create_model(x_train, y_train, x_test, y_test):\r\n    \r\n    shape = x_train[0].shape\r\n    \r\n    model = models.Sequential()\r\n    model.add(layers.Conv2D(16, (3, 3), activation='tanh', input_shape=shape))\r\n    model.add(layers.MaxPooling2D((2, 2)))\r\n    model.add(layers.Conv2D(32, (3, 3), activation='tanh'))\r\n    model.add(layers.MaxPooling2D((2, 2)))\r\n    model.add(layers.Conv2D(64, (3, 3), activation='tanh'))\r\n    model.add(layers.MaxPooling2D((2, 2)))\r\n    model.add(layers.Conv2D(128, (3, 3), activation='tanh'))\r\n    model.add(layers.MaxPooling2D((2, 2)))\r\n    model.add(layers.Flatten())\r\n    model.add(layers.Dropout(rate={{choice([0.2, 0.25, 0.3, 0.35, 0.4])}}))\r\n#    model.add(layers.Dropout(0.25))\r\n    model.add(layers.Dense(128, activation='relu'))\r\n    model.add(layers.Dense(64, activation='relu'))\r\n    model.add(layers.Dense(4, activation='softmax'))\r\n    \r\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(), metrics=['acc'])\r\n    \r\n    model.summary()\r\n    \r\n    train_generator, validation_generator = data()\r\n    \r\n    history = model.fit(x_train, y_train,         #history = \r\n                          batch_size = None,\r\n                          steps_per_epoch=5,\r\n                          epochs=4,\r\n                          validation_data=(x_test, y_test),\r\n                          validation_steps=5)\r\n\r\n    acc         = history.history['acc']\r\n    val_acc     = history.history['val_acc']\r\n    loss        = history.history['loss']\r\n    val_loss    = history.history['val_loss']\r\n    epochs      = range(1, len(acc) + 1)\r\n    \r\n    \r\n    plt.plot(epochs, acc, 'r-', label='Training acc')\r\n    plt.plot(epochs, val_acc, 'g-', label='Validation acc')\r\n    plt.title('Training and validation accuracy')\r\n    plt.legend()\r\n    plt.figure()\r\n    plt.plot(epochs, loss, 'r-', label='Training loss')\r\n    plt.plot(epochs, val_loss, 'g-', label='Validation loss')\r\n    plt.title('Training and validation loss')\r\n    plt.legend()\r\n    plt.pause(0.05)\r\n    plt.show()\r\n    \r\n    return {'loss': map(lambda x: x * -1.0, acc), 'status': STATUS_OK, 'model': model, 'acc': acc}\r\n\r\n\r\nif __name__ == '__main__':\r\n    \r\n    best_run, best_model = optim.minimize(model=create_model,\r\n                                          data=data,\r\n                                          algo=tpe.suggest,\r\n                                          max_evals=5,\r\n                                          trials=Trials())\r\n    (x_train, y_train), (x_test, y_test) = data()\r\n    print(\"Evalutation of best performing model:\")\r\n    print(best_model.evaluate(x_test, y_test))\r\n    print(\"Best performing model chosen hyper-parameters:\")\r\n    print(best_run)\r\n```\r\n\r\nAnd this is the error code:\r\n\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-17-df9a5e0e117e>\", line 1, in <module>\r\n    runfile('C:/Users/lucky/OneDrive/Machine Learning/Crack_Net_5.py', wdir='C:/Users/lucky/OneDrive/Machine Learning')\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 705, in runfile\r\n    execfile(filename, namespace)\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 102, in execfile\r\n    exec(compile(f.read(), filename, 'exec'), namespace)\r\n\r\n  File \"C:/Users/lucky/OneDrive/Machine Learning/Crack_Net_5.py\", line 169, in <module>\r\n    trials=Trials())\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\r\n    self.serial_evaluate()\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n\r\n  File \"C:\\Users\\lucky\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n\r\n  File \"C:\\Users\\lucky\\OneDrive\\Machine Learning\\temp_model.py\", line 160, in keras_fmin_fnct\r\n\r\nNameError: name 'x_train' is not defined\r\n```\r\n\r\nIf anyone could help me out that'd be great, I've been breaking my head over this for multiple days now.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/166", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/166/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/166/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/166/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/166", "id": 320869509, "node_id": "MDU6SXNzdWUzMjA4Njk1MDk=", "number": 166, "title": "Can I save the intermediate models and weights in different files?", "user": {"login": "LeZhengThu", "id": 18341929, "node_id": "MDQ6VXNlcjE4MzQxOTI5", "avatar_url": "https://avatars2.githubusercontent.com/u/18341929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LeZhengThu", "html_url": "https://github.com/LeZhengThu", "followers_url": "https://api.github.com/users/LeZhengThu/followers", "following_url": "https://api.github.com/users/LeZhengThu/following{/other_user}", "gists_url": "https://api.github.com/users/LeZhengThu/gists{/gist_id}", "starred_url": "https://api.github.com/users/LeZhengThu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LeZhengThu/subscriptions", "organizations_url": "https://api.github.com/users/LeZhengThu/orgs", "repos_url": "https://api.github.com/users/LeZhengThu/repos", "events_url": "https://api.github.com/users/LeZhengThu/events{/privacy}", "received_events_url": "https://api.github.com/users/LeZhengThu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-05-07T16:28:51Z", "updated_at": "2019-05-27T08:06:41Z", "closed_at": "2018-05-08T07:35:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "I can use a ModelCheckpoint to save the intermediate models and weights, but the optim funtion will overwrite it with the latest trial. But I want to save the intermediate model and weights for every trial. How can I do this? Thanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/165", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/165/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/165/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/165/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/165", "id": 319759362, "node_id": "MDU6SXNzdWUzMTk3NTkzNjI=", "number": 165, "title": "some unreasonable results when using your simple_notebook.ipynb", "user": {"login": "xuzhang5788", "id": 36318415, "node_id": "MDQ6VXNlcjM2MzE4NDE1", "avatar_url": "https://avatars0.githubusercontent.com/u/36318415?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xuzhang5788", "html_url": "https://github.com/xuzhang5788", "followers_url": "https://api.github.com/users/xuzhang5788/followers", "following_url": "https://api.github.com/users/xuzhang5788/following{/other_user}", "gists_url": "https://api.github.com/users/xuzhang5788/gists{/gist_id}", "starred_url": "https://api.github.com/users/xuzhang5788/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xuzhang5788/subscriptions", "organizations_url": "https://api.github.com/users/xuzhang5788/orgs", "repos_url": "https://api.github.com/users/xuzhang5788/repos", "events_url": "https://api.github.com/users/xuzhang5788/events{/privacy}", "received_events_url": "https://api.github.com/users/xuzhang5788/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-03T01:00:39Z", "updated_at": "2018-06-13T07:24:24Z", "closed_at": "2018-06-13T07:24:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "After running your sample_notebook.ipynb I got best_run parameters like this:\r\n{'Dense': 1, 'Dropout': 0.42522861686845626, 'Dropout_1': 0.23316134447477344, 'batch_size': 0}\r\nHowever, \r\ndef get_space():\r\n    return {\r\n        'Dropout': hp.uniform('Dropout', 0, 1),\r\n        'Dense': hp.choice('Dense', [256, 512, 1024]),\r\n        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\r\n        'batch_size': hp.choice('batch_size', [64, 128])\r\n        }\r\nWhy Dense is 1 instead of one of [256, 512, 1024], batch_size = 0?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/164", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/164/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/164/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/164/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/164", "id": 317456445, "node_id": "MDU6SXNzdWUzMTc0NTY0NDU=", "number": 164, "title": "Can I use it just with ipython?", "user": {"login": "loraince", "id": 32663994, "node_id": "MDQ6VXNlcjMyNjYzOTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/32663994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/loraince", "html_url": "https://github.com/loraince", "followers_url": "https://api.github.com/users/loraince/followers", "following_url": "https://api.github.com/users/loraince/following{/other_user}", "gists_url": "https://api.github.com/users/loraince/gists{/gist_id}", "starred_url": "https://api.github.com/users/loraince/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/loraince/subscriptions", "organizations_url": "https://api.github.com/users/loraince/orgs", "repos_url": "https://api.github.com/users/loraince/repos", "events_url": "https://api.github.com/users/loraince/events{/privacy}", "received_events_url": "https://api.github.com/users/loraince/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-25T02:15:14Z", "updated_at": "2019-03-11T23:08:54Z", "closed_at": "2018-04-26T07:42:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "I tried with win10 systems. It worked in a Jupyter notebook. However, it showed OSError in ipython with [Errno 22] Invalid argument: 'C:\\\\\\\\mywork\\\\\\\\< ipython-input-3-76977dd2255e>'\r\nThen, I tried with linux. My linux doesn't has a GUI so I can't run Jupyter notebook. When I tried the code in ipython, it showed:  FileNotFoundError: [Errno 2] No such file or directory: '/home/lxun/< ipython-input-4-545da7bd6a57 >'\r\nDoes it mean this tool can only work with Jupyter notebook?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/163", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/163/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/163/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/163/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/163", "id": 316721207, "node_id": "MDU6SXNzdWUzMTY3MjEyMDc=", "number": 163, "title": "Different evaluation results during tuning and after tuning?", "user": {"login": "Kirayue", "id": 13309212, "node_id": "MDQ6VXNlcjEzMzA5MjEy", "avatar_url": "https://avatars2.githubusercontent.com/u/13309212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kirayue", "html_url": "https://github.com/Kirayue", "followers_url": "https://api.github.com/users/Kirayue/followers", "following_url": "https://api.github.com/users/Kirayue/following{/other_user}", "gists_url": "https://api.github.com/users/Kirayue/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kirayue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kirayue/subscriptions", "organizations_url": "https://api.github.com/users/Kirayue/orgs", "repos_url": "https://api.github.com/users/Kirayue/repos", "events_url": "https://api.github.com/users/Kirayue/events{/privacy}", "received_events_url": "https://api.github.com/users/Kirayue/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-04-23T08:58:36Z", "updated_at": "2019-09-06T00:22:33Z", "closed_at": "2018-06-13T09:26:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nI randomly split data five times, and tuned the model on each split.\r\nI found that model.evaluate results are different except the first split. I print l2 value, (train_loss, train_acc), (val_loss, val_acc) and model each tuning round.\r\nAfter tuning, I use best_model that hyperas returned to evaluate the same train/val data, the results is different from turning. The model's memory location are the same. I have no idea what's happening.\r\nThank you.\r\n\r\n![image](https://user-images.githubusercontent.com/13309212/39116646-8dc6e9f6-4717-11e8-9593-eef3f4fe350b.png)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/162", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/162/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/162/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/162/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/162", "id": 314325680, "node_id": "MDU6SXNzdWUzMTQzMjU2ODA=", "number": 162, "title": "How to handle '#'", "user": {"login": "shashwattrivedi", "id": 21122257, "node_id": "MDQ6VXNlcjIxMTIyMjU3", "avatar_url": "https://avatars0.githubusercontent.com/u/21122257?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashwattrivedi", "html_url": "https://github.com/shashwattrivedi", "followers_url": "https://api.github.com/users/shashwattrivedi/followers", "following_url": "https://api.github.com/users/shashwattrivedi/following{/other_user}", "gists_url": "https://api.github.com/users/shashwattrivedi/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashwattrivedi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashwattrivedi/subscriptions", "organizations_url": "https://api.github.com/users/shashwattrivedi/orgs", "repos_url": "https://api.github.com/users/shashwattrivedi/repos", "events_url": "https://api.github.com/users/shashwattrivedi/events{/privacy}", "received_events_url": "https://api.github.com/users/shashwattrivedi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-14T12:36:24Z", "updated_at": "2018-04-16T15:42:47Z", "closed_at": "2018-04-16T15:42:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\ndef remove_hashtag(text):\r\n    if text[0]=='#':\r\n        return '<hashtag>'\r\n    else:\r\n        return text\r\n```\r\nI have to handle '#' in twitter data, but when I use \r\n```\r\nbest_run, best_model = optim.minimize(model=model_for_hyperas,\r\n                                          data=data,\r\n                                          algo=tpe.suggest,\r\n                                          max_evals=5,\r\n                                          trials=Trials()\r\n                                     ,notebook_name='<notebook_name>',)\r\n```\r\nIt shows me error\r\nFile \"<unknown>\", line 120\r\n    if text[0]=='\r\n                 ^\r\nSyntaxError: EOL while scanning string literal\r\n\r\nHow to handle this", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/161", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/161/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/161/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/161/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/161", "id": 312305835, "node_id": "MDU6SXNzdWUzMTIzMDU4MzU=", "number": 161, "title": "Strange crash(InvalidArgumentError) after few Hyperas evaluation rounds", "user": {"login": "Dahlasam", "id": 8475799, "node_id": "MDQ6VXNlcjg0NzU3OTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/8475799?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dahlasam", "html_url": "https://github.com/Dahlasam", "followers_url": "https://api.github.com/users/Dahlasam/followers", "following_url": "https://api.github.com/users/Dahlasam/following{/other_user}", "gists_url": "https://api.github.com/users/Dahlasam/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dahlasam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dahlasam/subscriptions", "organizations_url": "https://api.github.com/users/Dahlasam/orgs", "repos_url": "https://api.github.com/users/Dahlasam/repos", "events_url": "https://api.github.com/users/Dahlasam/events{/privacy}", "received_events_url": "https://api.github.com/users/Dahlasam/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-08T13:28:56Z", "updated_at": "2018-04-10T05:38:52Z", "closed_at": "2018-04-09T19:54:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "First of all thanks for the great library! \r\nHyperas has been working nicely so far related to our LSTM-net hyperparameter optimization, but after recent changes in our code some strange errors surfaced. \r\n\r\n`tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]`\r\n\r\nSo recently we have started to use argparse for getting command line parameters and then logging instead of \"print\" calls.\r\n\r\nSo first Hyperas runs fine for a couple of evaluations and then in \"create_model\" after some Keras model.fit() training call the error below pops up.\r\nWe have run the script using CPU as it seems to be faster for our small (batch_size=1) sequence training. Now I tried to start running the script in GPU again and some /CPU:0 texts are visible in the error stack below. I really can't pinpoint the root cause of the error as it's suddenly fired from Hyperas function after successful rounds.\r\n\r\nThe debug prints of normal execution are on top and then the lengthy error is shown below after that. The InvalidArgumentError from TF with missing layer data is clear, but what is causing it at the end of the epoch suddenly?\r\n\r\nHave you faced anything similar? Any suggestions are welcome! \r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nlstm_5 (LSTM)                (1, 300, 96)              41088     \r\n_________________________________________________________________\r\nlstm_6 (LSTM)                (1, 300, 96)              74112     \r\n_________________________________________________________________\r\nlstm_7 (LSTM)                (1, 300, 1024)            4591616   \r\n_________________________________________________________________\r\nlstm_8 (LSTM)                (1, 64)                   278784    \r\n_________________________________________________________________\r\ndense_2 (Dense)              (1, 5)                    325       \r\n=================================================================\r\nTotal params: 4,985,925\r\nTrainable params: 4,985,925\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nTrain on 50 samples, validate on 50 samples\r\nEpoch 1/1\r\n\r\n 1/50 [..............................] - ETA: 2:01 - loss: 1.6091 - acc: 0.0000e+00 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 1.6091\r\n 2/50 [>.............................] - ETA: 1:22 - loss: 0.8046 - acc: 0.5000 - categorical_accuracy: 0.5000 - categorical_crossentropy: 0.8046        \r\n 3/50 [>.............................] - ETA: 1:08 - loss: 0.5364 - acc: 0.6667 - categorical_accuracy: 0.6667 - categorical_crossentropy: 0.5364\r\n 4/50 [=>............................] - ETA: 1:01 - loss: 0.4023 - acc: 0.7500 - categorical_accuracy: 0.7500 - categorical_crossentropy: 0.4023\r\n 5/50 [==>...........................] - ETA: 57s - loss: 0.3218 - acc: 0.8000 - categorical_accuracy: 0.8000 - categorical_crossentropy: 0.3218 \r\n 6/50 [==>...........................] - ETA: 53s - loss: 0.2682 - acc: 0.8333 - categorical_accuracy: 0.8333 - categorical_crossentropy: 0.2682\r\n 7/50 [===>..........................] - ETA: 50s - loss: 0.2299 - acc: 0.8571 - categorical_accuracy: 0.8571 - categorical_crossentropy: 0.2299\r\n 8/50 [===>..........................] - ETA: 48s - loss: 0.2011 - acc: 0.8750 - categorical_accuracy: 0.8750 - categorical_crossentropy: 0.2011\r\n 9/50 [====>.........................] - ETA: 46s - loss: 0.1788 - acc: 0.8889 - categorical_accuracy: 0.8889 - categorical_crossentropy: 0.1788\r\n10/50 [=====>........................] - ETA: 44s - loss: 0.1609 - acc: 0.9000 - categorical_accuracy: 0.9000 - categorical_crossentropy: 0.1609\r\n11/50 [=====>........................] - ETA: 42s - loss: 0.1463 - acc: 0.9091 - categorical_accuracy: 0.9091 - categorical_crossentropy: 0.1463\r\n12/50 [======>.......................] - ETA: 41s - loss: 0.1341 - acc: 0.9167 - categorical_accuracy: 0.9167 - categorical_crossentropy: 0.1341\r\n13/50 [======>.......................] - ETA: 39s - loss: 0.1238 - acc: 0.9231 - categorical_accuracy: 0.9231 - categorical_crossentropy: 0.1238\r\n14/50 [=======>......................] - ETA: 38s - loss: 0.1149 - acc: 0.9286 - categorical_accuracy: 0.9286 - categorical_crossentropy: 0.1149\r\n15/50 [========>.....................] - ETA: 37s - loss: 0.1073 - acc: 0.9333 - categorical_accuracy: 0.9333 - categorical_crossentropy: 0.1073\r\n16/50 [========>.....................] - ETA: 36s - loss: 0.1006 - acc: 0.9375 - categorical_accuracy: 0.9375 - categorical_crossentropy: 0.1006\r\n17/50 [=========>....................] - ETA: 34s - loss: 0.0947 - acc: 0.9412 - categorical_accuracy: 0.9412 - categorical_crossentropy: 0.0947\r\n18/50 [=========>....................] - ETA: 34s - loss: 0.0894 - acc: 0.9444 - categorical_accuracy: 0.9444 - categorical_crossentropy: 0.0894\r\n19/50 [==========>...................] - ETA: 33s - loss: 0.0847 - acc: 0.9474 - categorical_accuracy: 0.9474 - categorical_crossentropy: 0.0847\r\n20/50 [===========>..................] - ETA: 32s - loss: 0.0805 - acc: 0.9500 - categorical_accuracy: 0.9500 - categorical_crossentropy: 0.0805\r\n21/50 [===========>..................] - ETA: 31s - loss: 0.0766 - acc: 0.9524 - categorical_accuracy: 0.9524 - categorical_crossentropy: 0.0766\r\n22/50 [============>.................] - ETA: 29s - loss: 0.0731 - acc: 0.9545 - categorical_accuracy: 0.9545 - categorical_crossentropy: 0.0731\r\n23/50 [============>.................] - ETA: 28s - loss: 0.0700 - acc: 0.9565 - categorical_accuracy: 0.9565 - categorical_crossentropy: 0.0700\r\n24/50 [=============>................] - ETA: 27s - loss: 0.0670 - acc: 0.9583 - categorical_accuracy: 0.9583 - categorical_crossentropy: 0.0670\r\n25/50 [==============>...............] - ETA: 26s - loss: 0.0644 - acc: 0.9600 - categorical_accuracy: 0.9600 - categorical_crossentropy: 0.0644\r\n26/50 [==============>...............] - ETA: 25s - loss: 0.0619 - acc: 0.9615 - categorical_accuracy: 0.9615 - categorical_crossentropy: 0.0619\r\n27/50 [===============>..............] - ETA: 24s - loss: 0.0596 - acc: 0.9630 - categorical_accuracy: 0.9630 - categorical_crossentropy: 0.0596\r\n28/50 [===============>..............] - ETA: 23s - loss: 0.0575 - acc: 0.9643 - categorical_accuracy: 0.9643 - categorical_crossentropy: 0.0575\r\n29/50 [================>.............] - ETA: 22s - loss: 0.0555 - acc: 0.9655 - categorical_accuracy: 0.9655 - categorical_crossentropy: 0.0555\r\n30/50 [=================>............] - ETA: 21s - loss: 0.0536 - acc: 0.9667 - categorical_accuracy: 0.9667 - categorical_crossentropy: 0.0536\r\n31/50 [=================>............] - ETA: 20s - loss: 0.0519 - acc: 0.9677 - categorical_accuracy: 0.9677 - categorical_crossentropy: 0.0519\r\n32/50 [==================>...........] - ETA: 19s - loss: 0.0503 - acc: 0.9688 - categorical_accuracy: 0.9688 - categorical_crossentropy: 0.0503\r\n33/50 [==================>...........] - ETA: 17s - loss: 0.0488 - acc: 0.9697 - categorical_accuracy: 0.9697 - categorical_crossentropy: 0.0488\r\n34/50 [===================>..........] - ETA: 16s - loss: 0.0473 - acc: 0.9706 - categorical_accuracy: 0.9706 - categorical_crossentropy: 0.0473\r\n35/50 [====================>.........] - ETA: 15s - loss: 0.0460 - acc: 0.9714 - categorical_accuracy: 0.9714 - categorical_crossentropy: 0.0460\r\n36/50 [====================>.........] - ETA: 14s - loss: 0.0447 - acc: 0.9722 - categorical_accuracy: 0.9722 - categorical_crossentropy: 0.0447\r\n37/50 [=====================>........] - ETA: 13s - loss: 0.0435 - acc: 0.9730 - categorical_accuracy: 0.9730 - categorical_crossentropy: 0.0435\r\n38/50 [=====================>........] - ETA: 12s - loss: 0.0423 - acc: 0.9737 - categorical_accuracy: 0.9737 - categorical_crossentropy: 0.0423\r\n39/50 [======================>.......] - ETA: 11s - loss: 0.0413 - acc: 0.9744 - categorical_accuracy: 0.9744 - categorical_crossentropy: 0.0413\r\n40/50 [=======================>......] - ETA: 10s - loss: 0.0402 - acc: 0.9750 - categorical_accuracy: 0.9750 - categorical_crossentropy: 0.0402\r\n41/50 [=======================>......] - ETA: 9s - loss: 0.0392 - acc: 0.9756 - categorical_accuracy: 0.9756 - categorical_crossentropy: 0.0392 \r\n42/50 [========================>.....] - ETA: 8s - loss: 0.0383 - acc: 0.9762 - categorical_accuracy: 0.9762 - categorical_crossentropy: 0.0383\r\n43/50 [========================>.....] - ETA: 7s - loss: 0.0374 - acc: 0.9767 - categorical_accuracy: 0.9767 - categorical_crossentropy: 0.0374\r\n44/50 [=========================>....] - ETA: 6s - loss: 0.0366 - acc: 0.9773 - categorical_accuracy: 0.9773 - categorical_crossentropy: 0.0366\r\n45/50 [==========================>...] - ETA: 5s - loss: 0.0358 - acc: 0.9778 - categorical_accuracy: 0.9778 - categorical_crossentropy: 0.0358\r\n46/50 [==========================>...] - ETA: 4s - loss: 0.0350 - acc: 0.9783 - categorical_accuracy: 0.9783 - categorical_crossentropy: 0.0350\r\n47/50 [===========================>..] - ETA: 3s - loss: 0.0342 - acc: 0.9787 - categorical_accuracy: 0.9787 - categorical_crossentropy: 0.0342\r\n48/50 [===========================>..] - ETA: 2s - loss: 0.0335 - acc: 0.9792 - categorical_accuracy: 0.9792 - categorical_crossentropy: 0.0335\r\n49/50 [============================>.] - ETA: 1s - loss: 0.0328 - acc: 0.9796 - categorical_accuracy: 0.9796 - categorical_crossentropy: 0.0328\r\n50/50 [==============================] - 64s 1s/step - loss: 0.0322 - acc: 0.9800 - categorical_accuracy: 0.9800 - categorical_crossentropy: 0.0322 - val_loss: 1.1921e-07 - val_acc: 1.0000 - val_categorical_accuracy: 1.0000 - val_categorical_crossentropy: 1.1921e-07\r\n2018-04-08 15:47:58.552408: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.552419: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.552453: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.552457: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.552470: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.553786: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.553813: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557405: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557454: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557490: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557529: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557640: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557668: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557705: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557754: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557772: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557817: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557838: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557870: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557916: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557946: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.557973: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559596: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559616: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559664: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559707: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559724: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559768: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559794: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559832: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559877: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559918: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559957: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.559972: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.561973: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562844: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562869: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562881: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562896: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562907: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562918: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562934: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562946: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562958: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562970: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562981: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.562997: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563010: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563022: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563034: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563045: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563057: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563068: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563079: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563090: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563102: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563113: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563128: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563139: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563276: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563310: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563322: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n2018-04-08 15:47:58.563335: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\nTraceback (most recent call last):\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1323, in _do_call\r\n    return fn(*args)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1302, in _run_fn\r\n    status, run_metadata)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\t [[Node: _arg_lstm_5_input_0_3/_622 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_33967__arg_lstm_5_input_0_3\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_lstm_5_input_0_3)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/sami/PycharmProjects/src/xxx_classifier.py\", line 1269, in <module>\r\n    main(cli_options=options)\r\n  File \"/home/sami/PycharmProjects/src/xxx_classifier.py\", line 1204, in main\r\n    eval_space=True)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperas/optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 173, in run\r\n    self.serial_evaluate()\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/base.py\", line 840, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n  File \"/home/sami/PycharmProjects/src/temp_model.py\", line 341, in keras_fmin_fnct\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/keras/models.py\", line 963, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/keras/engine/training.py\", line 1705, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/keras/engine/training.py\", line 1255, in _fit_loop\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/keras/callbacks.py\", line 77, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/keras/callbacks.py\", line 846, in on_epoch_end\r\n    result = self.sess.run([self.merged], feed_dict=feed_dict)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\t [[Node: _arg_lstm_5_input_0_3/_622 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_33967__arg_lstm_5_input_0_3\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_lstm_5_input_0_3)]]\r\n\r\nCaused by op 'dense_1_sample_weights', defined at:\r\n  File \"/home/sami/PycharmProjects/src/xxx_classifier.py\", line 1269, in <module>\r\n    main(cli_options=options)\r\n  File \"/home/sami/PycharmProjects/src/xxx_classifier.py\", line 1204, in main\r\n    eval_space=True)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperas/optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 173, in run\r\n    self.serial_evaluate()\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/hyperopt/base.py\", line 840, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n  File \"/home/sami/PycharmProjects/src/temp_model.py\", line 271, in keras_fmin_fnct\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/keras/models.py\", line 824, in compile\r\n    **kwargs)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/keras/engine/training.py\", line 802, in compile\r\n    name=name + '_sample_weights'))\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 507, in placeholder\r\n    x = tf.placeholder(dtype, shape=shape, name=name)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\r\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\r\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/home/sami/miniconda2/envs/agent/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'dense_1_sample_weights' with dtype float and shape [?]\r\n\t [[Node: dense_1_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\t [[Node: _arg_lstm_5_input_0_3/_622 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_33967__arg_lstm_5_input_0_3\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_lstm_5_input_0_3)]]\r\n\r\n\r\nProcess finished with exit code 1\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/160", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/160/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/160/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/160/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/160", "id": 310445966, "node_id": "MDU6SXNzdWUzMTA0NDU5NjY=", "number": 160, "title": "name 'x_train' is not defined", "user": {"login": "Jie-Yuan", "id": 20265321, "node_id": "MDQ6VXNlcjIwMjY1MzIx", "avatar_url": "https://avatars2.githubusercontent.com/u/20265321?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jie-Yuan", "html_url": "https://github.com/Jie-Yuan", "followers_url": "https://api.github.com/users/Jie-Yuan/followers", "following_url": "https://api.github.com/users/Jie-Yuan/following{/other_user}", "gists_url": "https://api.github.com/users/Jie-Yuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jie-Yuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jie-Yuan/subscriptions", "organizations_url": "https://api.github.com/users/Jie-Yuan/orgs", "repos_url": "https://api.github.com/users/Jie-Yuan/repos", "events_url": "https://api.github.com/users/Jie-Yuan/events{/privacy}", "received_events_url": "https://api.github.com/users/Jie-Yuan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-04-02T10:00:38Z", "updated_at": "2018-04-02T15:01:28Z", "closed_at": "2018-04-02T15:01:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "same as demo\uff1fwhy", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/159", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/159/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/159/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/159/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/159", "id": 309637590, "node_id": "MDU6SXNzdWUzMDk2Mzc1OTA=", "number": 159, "title": "Usage with multiple inputs and custom layers", "user": {"login": "pabucur", "id": 19842944, "node_id": "MDQ6VXNlcjE5ODQyOTQ0", "avatar_url": "https://avatars2.githubusercontent.com/u/19842944?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pabucur", "html_url": "https://github.com/pabucur", "followers_url": "https://api.github.com/users/pabucur/followers", "following_url": "https://api.github.com/users/pabucur/following{/other_user}", "gists_url": "https://api.github.com/users/pabucur/gists{/gist_id}", "starred_url": "https://api.github.com/users/pabucur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pabucur/subscriptions", "organizations_url": "https://api.github.com/users/pabucur/orgs", "repos_url": "https://api.github.com/users/pabucur/repos", "events_url": "https://api.github.com/users/pabucur/events{/privacy}", "received_events_url": "https://api.github.com/users/pabucur/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-03-29T06:44:52Z", "updated_at": "2018-06-13T09:37:38Z", "closed_at": "2018-06-13T09:37:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is it possible to use hyperas in the presence of models with multiple input and custom layers?\r\n\r\nIn my case, I get an exception that the custom layer is not known:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/Users/bucpau/PycharmProjects/Acoustics/Models/CanonicalCorrelationAnalysis/DCCA/DCCA_hyperparam.py\", line 305, in <module>\r\n    main()\r\n  File \"C:/Users/bucpau/PycharmProjects/Acoustics/Models/CanonicalCorrelationAnalysis/DCCA/DCCA_hyperparam.py\", line 283, in main\r\n    trials=Trials())\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperas-0.4-py3.6.egg\\hyperas\\optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperas-0.4-py3.6.egg\\hyperas\\optim.py\", line 136, in base_minimizer\r\n    return_argmin=True),\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\r\n    self.serial_evaluate()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n  File \"C:\\Users\\bucpau\\PycharmProjects\\Acoustics\\Models\\CanonicalCorrelationAnalysis\\DCCA\\temp_model.py\", line 179, in keras_fmin_fnct\r\nNameError: name 'CCA' is not defined\r\n\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/156", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/156/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/156/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/156/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/156", "id": 304904611, "node_id": "MDU6SXNzdWUzMDQ5MDQ2MTE=", "number": 156, "title": "The fundamentals of your template parsing code", "user": {"login": "ryanpeach", "id": 14838729, "node_id": "MDQ6VXNlcjE0ODM4NzI5", "avatar_url": "https://avatars1.githubusercontent.com/u/14838729?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ryanpeach", "html_url": "https://github.com/ryanpeach", "followers_url": "https://api.github.com/users/ryanpeach/followers", "following_url": "https://api.github.com/users/ryanpeach/following{/other_user}", "gists_url": "https://api.github.com/users/ryanpeach/gists{/gist_id}", "starred_url": "https://api.github.com/users/ryanpeach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ryanpeach/subscriptions", "organizations_url": "https://api.github.com/users/ryanpeach/orgs", "repos_url": "https://api.github.com/users/ryanpeach/repos", "events_url": "https://api.github.com/users/ryanpeach/events{/privacy}", "received_events_url": "https://api.github.com/users/ryanpeach/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-13T19:30:06Z", "updated_at": "2018-06-13T09:09:04Z", "closed_at": "2018-06-13T09:09:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there,\r\n\r\nI really love this projects template methodology and hyperopt's use of distributions within the template. However, for some complex reasons, I can not use hyperopt for my project. As such, I would like to fork this project and make it have a \"general purpose backend\" to where you can use any arbitrary hyper parameter optimizer with basically the same syntax as this project touts. I have identified that the main imports from hyperopt are the distributions (which I intend to replace with simple lambdas) and then the following:\r\n\r\nfmin, tpe, hp, STATUS_OK, Trials, space_eval\r\n\r\nThese all have complex IO and are often passing objects around, I wonder if you could guide me to the core of *your* code, particularly the template and string handling.\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/154", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/154/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/154/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/154/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/154", "id": 302167952, "node_id": "MDU6SXNzdWUzMDIxNjc5NTI=", "number": 154, "title": "Is search space path fixed every time?", "user": {"login": "Kirayue", "id": 13309212, "node_id": "MDQ6VXNlcjEzMzA5MjEy", "avatar_url": "https://avatars2.githubusercontent.com/u/13309212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kirayue", "html_url": "https://github.com/Kirayue", "followers_url": "https://api.github.com/users/Kirayue/followers", "following_url": "https://api.github.com/users/Kirayue/following{/other_user}", "gists_url": "https://api.github.com/users/Kirayue/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kirayue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kirayue/subscriptions", "organizations_url": "https://api.github.com/users/Kirayue/orgs", "repos_url": "https://api.github.com/users/Kirayue/repos", "events_url": "https://api.github.com/users/Kirayue/events{/privacy}", "received_events_url": "https://api.github.com/users/Kirayue/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-03-05T04:25:58Z", "updated_at": "2018-03-05T09:59:13Z", "closed_at": "2018-03-05T09:59:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, @maxpumperla \r\n\r\nI outputted the trials and found that \r\n`t = Trials()`\r\n`best_run, model = optim.minimize( model=create_model,  data=data, algo=tpe.suggest, max_evals=15, trials=t, verbose=False)`\r\n`for trial in t.trials:`                                         \r\n`     print(trial['misc']['vals'])`\r\n\r\nI got the same search space order after I changed the data split. Is this normal? \r\n\r\n![2018-03-05 12 18 51](https://user-images.githubusercontent.com/13309212/36957507-c398526e-206f-11e8-8e6a-f953efac9027.jpg)\r\n\r\n![2018-03-05 12 18 58](https://user-images.githubusercontent.com/13309212/36957514-cd91e938-206f-11e8-890e-300e12cf5fc6.jpg)\r\n\r\nBecause this is related to my research, it is very important to me. \r\n\r\nAnd thank you for this awesome repo. \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/153", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/153/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/153/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/153/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/153", "id": 301284945, "node_id": "MDU6SXNzdWUzMDEyODQ5NDU=", "number": 153, "title": "Optimize layer numbers? TypeError: 'NoneType' object is not iterable", "user": {"login": "drpx", "id": 36946052, "node_id": "MDQ6VXNlcjM2OTQ2MDUy", "avatar_url": "https://avatars1.githubusercontent.com/u/36946052?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpx", "html_url": "https://github.com/drpx", "followers_url": "https://api.github.com/users/drpx/followers", "following_url": "https://api.github.com/users/drpx/following{/other_user}", "gists_url": "https://api.github.com/users/drpx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpx/subscriptions", "organizations_url": "https://api.github.com/users/drpx/orgs", "repos_url": "https://api.github.com/users/drpx/repos", "events_url": "https://api.github.com/users/drpx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpx/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-03-01T05:43:44Z", "updated_at": "2018-03-02T03:49:23Z", "closed_at": "2018-03-02T03:49:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "I got the following error using optim.minimize which I believe is related to the model.\r\n\r\n> TypeError: 'NoneType' object is not iterable\r\n\r\nDoes hyperas not work if number of layers isn't preset? My model starts with an empty dict for layers. The following code is what causing the error  I guess.\r\n\r\n```\r\n\r\nlayer={}\r\nlayer[0] = Input(shape=(imgsize + (channels_in,)))\r\npoolloop=numpool+1\r\nfor j in range(poolloop):\r\n     for i in range(1, numcnnlayersperpool+1):\r\n          layer[i+j*numcnnlayersperpool] = Dropout({{uniform(0, .5)}})(BatchNormalization()(Conv2D(filters={{choice([32, 64, 128])}}, kernel_size=kernelsize, padding=padding, activation=cnnactivation)(layer[i+j*numcnnlayersperpool-1])))\r\n \r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/147", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/147/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/147/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/147/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/147", "id": 292144503, "node_id": "MDU6SXNzdWUyOTIxNDQ1MDM=", "number": 147, "title": "TypeError: 'function' object is not subscriptable", "user": {"login": "gaceladri", "id": 7850682, "node_id": "MDQ6VXNlcjc4NTA2ODI=", "avatar_url": "https://avatars0.githubusercontent.com/u/7850682?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaceladri", "html_url": "https://github.com/gaceladri", "followers_url": "https://api.github.com/users/gaceladri/followers", "following_url": "https://api.github.com/users/gaceladri/following{/other_user}", "gists_url": "https://api.github.com/users/gaceladri/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaceladri/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaceladri/subscriptions", "organizations_url": "https://api.github.com/users/gaceladri/orgs", "repos_url": "https://api.github.com/users/gaceladri/repos", "events_url": "https://api.github.com/users/gaceladri/events{/privacy}", "received_events_url": "https://api.github.com/users/gaceladri/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-27T19:06:55Z", "updated_at": "2018-06-13T07:40:44Z", "closed_at": "2018-06-13T07:40:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi guys,\r\n\r\nReally good job. I am having the next issue and I already installed networkx==1.11 but the issue persist.\r\n\r\n`Traceback (most recent call last):\r\n  File \"lshhyperas.py\", line 135, in <module>\r\n    trials=Trials())\r\n  File \"/home/proto/anaconda3/envs/tensorflow/lib/python3.5/site-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/home/proto/anaconda3/envs/tensorflow/lib/python3.5/site-packages/hyperas/optim.py\", line 128, in base_minimizer\r\n    space=get_space(),\r\n  File \"/home/proto/Downloads/initialnet/training_/temp_model.py\", line 223, in get_space\r\nTypeError: 'function' object is not subscriptable`\r\n\r\nAny suggestion about what is about?\r\nThanks!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/146", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/146/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/146/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/146/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/146", "id": 291841674, "node_id": "MDU6SXNzdWUyOTE4NDE2NzQ=", "number": 146, "title": "TypeError: 'generator' object has no attribute '__getitem__'", "user": {"login": "tchaton", "id": 12861981, "node_id": "MDQ6VXNlcjEyODYxOTgx", "avatar_url": "https://avatars0.githubusercontent.com/u/12861981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tchaton", "html_url": "https://github.com/tchaton", "followers_url": "https://api.github.com/users/tchaton/followers", "following_url": "https://api.github.com/users/tchaton/following{/other_user}", "gists_url": "https://api.github.com/users/tchaton/gists{/gist_id}", "starred_url": "https://api.github.com/users/tchaton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tchaton/subscriptions", "organizations_url": "https://api.github.com/users/tchaton/orgs", "repos_url": "https://api.github.com/users/tchaton/repos", "events_url": "https://api.github.com/users/tchaton/events{/privacy}", "received_events_url": "https://api.github.com/users/tchaton/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-26T09:23:10Z", "updated_at": "2018-04-04T18:38:18Z", "closed_at": "2018-04-04T18:38:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Using TensorFlow backend.\r\n>>> Imports:\r\n#coding=utf-8\r\n\r\nfrom __future__ import print_function\r\n\r\ntry:\r\n    from hyperopt import Trials, STATUS_OK, tpe\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas import optim\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas.distributions import choice, uniform, conditional\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.models import Sequential\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.layers.core import Dense, Dropout, Activation\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.datasets import mnist\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.utils import np_utils\r\nexcept:\r\n    pass\r\n\r\n>>> Hyperas search space:\r\n\r\ndef get_space():\r\n    return {\r\n        'Dropout': hp.uniform('Dropout', 0, 1),\r\n        'Dense': hp.choice('Dense', [256, 512, 1024]),\r\n        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\r\n        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\r\n        'conditional': hp.choice('conditional', ['three', 'four']),\r\n        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\r\n        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\r\n        'batch_size': hp.choice('batch_size', [64, 128]),\r\n    }\r\n\r\n>>> Data\r\n  1: \r\n  2: '''\r\n  3: Data providing function:\r\n  4: \r\n  5: This function is separated from model() so that hyperopt\r\n  6: won't reload data for each evaluation run.\r\n  7: '''\r\n  8: (X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n  9: X_train = X_train.reshape(60000, 784)\r\n 10: X_test = X_test.reshape(10000, 784)\r\n 11: X_train = X_train.astype('float32')\r\n 12: X_test = X_test.astype('float32')\r\n 13: X_train /= 255\r\n 14: X_test /= 255\r\n 15: nb_classes = 10\r\n 16: Y_train = np_utils.to_categorical(y_train, nb_classes)\r\n 17: Y_test = np_utils.to_categorical(y_test, nb_classes)\r\n 18: \r\n 19: \r\n 20: \r\n>>> Resulting replaced keras model:\r\n\r\n   1: def keras_fmin_fnct(space):\r\n   2: \r\n   3:     '''\r\n   4:     Model providing function:\r\n   5: \r\n   6:     Create Keras model with double curly brackets dropped-in as needed.\r\n   7:     Return value has to be a valid python dictionary with two customary keys:\r\n   8:         - loss: Specify a numeric evaluation metric to be minimized\r\n   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n  10:     The last one is optional, though recommended, namely:\r\n  11:         - model: specify the model just created so that we can later use it again.\r\n  12:     '''\r\n  13:     model = Sequential()\r\n  14:     model.add(Dense(512, input_shape=(784,)))\r\n  15:     model.add(Activation('relu'))\r\n  16:     model.add(Dropout(space['Dropout']))\r\n  17:     model.add(Dense(space['Dense']))\r\n  18:     model.add(Activation(space['Activation']))\r\n  19:     model.add(Dropout(space['Dropout_1']))\r\n  20: \r\n  21:     # If we choose 'four', add an additional fourth layer\r\n  22:     if conditional(space['conditional']) == 'four':\r\n  23:         model.add(Dense(100))\r\n  24:         model.add(space['add'])\r\n  25:         model.add(Activation('relu'))\r\n  26: \r\n  27:     model.add(Dense(10))\r\n  28:     model.add(Activation('softmax'))\r\n  29: \r\n  30:     model.compile(loss='categorical_crossentropy',\r\n  31:                   optimizer=space['optimizer'],\r\n  32:                   metrics=['accuracy'])\r\n  33: \r\n  34:     model.fit(X_train, Y_train,\r\n  35:               batch_size=space['batch_size'],\r\n  36:               nb_epoch=1,\r\n  37:               verbose=2,\r\n  38:               validation_data=(X_test, Y_test))\r\n  39:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\r\n  40:     print('Test accuracy:', acc)\r\n  41:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\r\n  42: \r\nTraceback (most recent call last):\r\n  File \"complex.py\", line 77, in <module>\r\n    trials=Trials())\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\", line 136, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.py\", line 314, in fmin\r\n    pass_expr_memo_ctrl=pass_expr_memo_ctrl)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/base.py\", line 786, in __init__\r\n    pyll.toposort(self.expr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/pyll/base.py\", line 715, in toposort\r\n    assert order[-1] == expr\r\nTypeError: 'generator' object has no attribute '__getitem__'\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/145", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/145/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/145/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/145/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/145", "id": 291624127, "node_id": "MDU6SXNzdWUyOTE2MjQxMjc=", "number": 145, "title": "Can you use L1 and L2 regularization as well in regression problems?", "user": {"login": "Shuyib", "id": 12908522, "node_id": "MDQ6VXNlcjEyOTA4NTIy", "avatar_url": "https://avatars1.githubusercontent.com/u/12908522?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Shuyib", "html_url": "https://github.com/Shuyib", "followers_url": "https://api.github.com/users/Shuyib/followers", "following_url": "https://api.github.com/users/Shuyib/following{/other_user}", "gists_url": "https://api.github.com/users/Shuyib/gists{/gist_id}", "starred_url": "https://api.github.com/users/Shuyib/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Shuyib/subscriptions", "organizations_url": "https://api.github.com/users/Shuyib/orgs", "repos_url": "https://api.github.com/users/Shuyib/repos", "events_url": "https://api.github.com/users/Shuyib/events{/privacy}", "received_events_url": "https://api.github.com/users/Shuyib/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-25T16:07:54Z", "updated_at": "2018-06-30T07:41:11Z", "closed_at": "2018-06-13T08:20:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI used the datasets that come along with installing Keras such as the boston housing one using the code in the README file as a template. Instead of using Dropout i used L1 and L2 regularization. I get the following error after running on the terminal (Mac) with the command `nohup python test_boston_dataset_hyper.py &` see below. Otherwise, I'm using Python 3.5.2 , Keras 2.0.8, Tensorflow 1.3.0, Theano 0.9.0, hyperas 0.4.\r\n\r\n```\r\nUsing TensorFlow backend.\r\n>>> Imports:\r\n#coding=utf-8\r\n\r\nfrom __future__ import print_function\r\n\r\ntry:\r\n    from hyperopt import Trials, STATUS_OK, tpe\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.datasets import boston_housing\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.layers.core import Dense, Dropout, Activation\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.models import Sequential\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.utils import np_utils\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras import regularizers\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    import numpy as np\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas import optim\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas.distributions import choice, uniform, conditional\r\nexcept:\r\n    pass\r\n\r\n>>> Hyperas search space:\r\n\r\ndef get_space():\r\n    return {\r\n        'Dense': hp.choice('Dense', [4, 16, 32, 64]),\r\n        'l1_l2': hp.uniform('l1_l2', 0, 1),\r\n        'l1_l2_1': hp.uniform('l1_l2_1', 0, 1),\r\n        'Activation': hp.choice('Activation', ['relu', 'tanh', 'sigmoid']),\r\n        'Dense_1': hp.choice('Dense_1', [4, 16, 32, 64]),\r\n        'l1_l2_2': hp.uniform('l1_l2_2', 0, 1),\r\n        'l1_l2_3': hp.uniform('l1_l2_3', 0, 1),\r\n        'Activation_1': hp.choice('Activation_1', ['relu', 'tanh','sigmoid']),\r\n        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\r\n        'batch_size': hp.choice('batch_size', [64, 128]),\r\n    }\r\n\r\n>>> Data\r\n  1: \r\n  2: '''loading data, scaling it and returning the data to be used throughout'''\r\n  3: (x_train, y_train), (x_test, y_test) =  boston_housing.load_data()\r\n  4: x_train = x_train.astype('float32')\r\n  5: x_test = x_test.astype('float32')\r\n  6: mean = x_train.mean(axis=0)\r\n  7: x_train -= mean\r\n  8: std = x_train.std(axis=0)\r\n  9: x_train /= std\r\n 10: x_test -= mean\r\n 11: x_test /= std\r\n 12: y_train = np.log(y_train)\r\n 13: y_test = np.log(y_test)\r\n 14: \r\n 15: \r\n 16: \r\n 17: \r\n 18: \r\n>>> Resulting replaced keras model:\r\n\r\n   1: def keras_fmin_fnct(space):\r\n   2: \r\n   3:     \"\"\"\r\n   4:     Model providing function:\r\n   5: \r\n   6:     Create Keras model with double curly brackets dropped-in as needed.\r\n   7:     Return value has to be a valid python dictionary with two customary keys:\r\n   8:         - loss: Specify a numeric evaluation metric to be minimized\r\n   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n  10:     The last one is optional, though recommended, namely:\r\n  11:         - model: specify the model just created so that we can later use it again.\r\n  12:     \"\"\"\r\n  13:     model = Sequential()\r\n  14:     model.add(Dense(space['Dense'], kernel_regularizer = regularizers.l1_l2(\r\n  15:     space['l1_l2'],space['l1_l2_1']),input_shape = (x_train.shape[1],)))\r\n  16:     model.add(Activation(space['Activation']))\r\n  17:     model.add(Dense(space['Dense_1'], regularizers.l1_l2(space['l1_l2_2'],\r\n  18:     space['l1_l2_3'])))\r\n  19:     model.add(Activation(space['Activation_1']))\r\n  20:     model.add(Dense(1))\r\n  21:     \r\n  22:     model.compile(loss='mse', metrics=['mae'],\r\n  23:                   optimizer=space['optimizer'])\r\n  24: \r\n  25:     model.fit(x_train, y_train,\r\n  26:               batch_size=space['batch_size'],\r\n  27:               epochs=1,\r\n  28:               verbose=2,\r\n  29:               validation_data=(x_test, y_test))\r\n  30:     val_mse, val_mae = model.evaluate(x_test, y_test, verbose=0)\r\n  31:     print('Test mse:', val_mse)\r\n  32:     return {'loss': -val_mse, 'status': STATUS_OK, 'model': model}\r\n```\r\n  33: \r\nTraceback (most recent call last):\r\n  File \"test_boston_housing.py\", line 69, in <module>\r\n    trials=Trials())\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperas/optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\", line 173, in run\r\n    self.serial_evaluate()\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/hyperopt/base.py\", line 840, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n  File \"/Users/../Desktop/temp_model.py\", line 85, in keras_fmin_fnct\r\n  File \"/Users/../anaconda/envs/py35/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 42, in wrapper\r\n    str(list(args[1:])))\r\nTypeError: `Dense` can accept only 1 positional arguments ('units',), but you passed the following positional arguments: [32, <keras.regularizers.L1L2 object at 0x11b74aba8>]\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/144", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/144/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/144/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/144/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/144", "id": 291126141, "node_id": "MDU6SXNzdWUyOTExMjYxNDE=", "number": 144, "title": "OSError while executing sample code", "user": {"login": "thisisashukla", "id": 20864366, "node_id": "MDQ6VXNlcjIwODY0MzY2", "avatar_url": "https://avatars3.githubusercontent.com/u/20864366?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thisisashukla", "html_url": "https://github.com/thisisashukla", "followers_url": "https://api.github.com/users/thisisashukla/followers", "following_url": "https://api.github.com/users/thisisashukla/following{/other_user}", "gists_url": "https://api.github.com/users/thisisashukla/gists{/gist_id}", "starred_url": "https://api.github.com/users/thisisashukla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thisisashukla/subscriptions", "organizations_url": "https://api.github.com/users/thisisashukla/orgs", "repos_url": "https://api.github.com/users/thisisashukla/repos", "events_url": "https://api.github.com/users/thisisashukla/events{/privacy}", "received_events_url": "https://api.github.com/users/thisisashukla/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2018-01-24T08:45:48Z", "updated_at": "2019-08-24T06:43:03Z", "closed_at": "2018-01-26T10:00:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "The sample code given on [hyperas homepage](http://maxpumperla.github.io/hyperas/) ends up in the following error stack trace:\r\n\r\n```\r\nOSError                                   Traceback (most recent call last)\r\n<ipython-input-15-871ae3941e46> in <module>()\r\n     76                                           algo=tpe.suggest,\r\n     77                                           max_evals=5,\r\n---> 78                                           trials=Trials())\r\n     79     X_train, Y_train, X_test, Y_test = data()\r\n     80     print(\"Evalutation of best performing model:\")\r\n\r\nG:\\Programs\\anaconda3\\envs\\py35\\lib\\site-packages\\hyperas\\optim.py in minimize(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\r\n     65                                      full_model_string=None,\r\n     66                                      notebook_name=notebook_name,\r\n---> 67                                      verbose=verbose)\r\n     68 \r\n     69     best_model = None\r\n\r\nG:\\Programs\\anaconda3\\envs\\py35\\lib\\site-packages\\hyperas\\optim.py in base_minimizer(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\r\n     94         model_str = full_model_string\r\n     95     else:\r\n---> 96         model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\r\n     97     temp_file = './temp_model.py'\r\n     98     write_temp_files(model_str, temp_file)\r\n\r\nG:\\Programs\\anaconda3\\envs\\py35\\lib\\site-packages\\hyperas\\optim.py in get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\r\n    176     else:\r\n    177         calling_script_file = os.path.abspath(inspect.stack()[stack][1])\r\n--> 178         with open(calling_script_file, 'r') as f:\r\n    179             source = f.read()\r\n    180 \r\n\r\nOSError: [Errno 22] Invalid argument: 'path\\\\to\\\\working\\\\directory\\\\<ipython-input-15-871ae3941e46>'\r\n```\r\n**I am now able to understand the cause of the error. I am using Python 3.5.3 (Anaconda virtual environment) on Windows 10. Please help me resolve it. If I am creating a redundant issue, I apologise for the same.**", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/142", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/142/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/142/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/142/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/142", "id": 289451975, "node_id": "MDU6SXNzdWUyODk0NTE5NzU=", "number": 142, "title": "NameError: name 'Input' is not defined", "user": {"login": "jolespin", "id": 9061708, "node_id": "MDQ6VXNlcjkwNjE3MDg=", "avatar_url": "https://avatars1.githubusercontent.com/u/9061708?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jolespin", "html_url": "https://github.com/jolespin", "followers_url": "https://api.github.com/users/jolespin/followers", "following_url": "https://api.github.com/users/jolespin/following{/other_user}", "gists_url": "https://api.github.com/users/jolespin/gists{/gist_id}", "starred_url": "https://api.github.com/users/jolespin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jolespin/subscriptions", "organizations_url": "https://api.github.com/users/jolespin/orgs", "repos_url": "https://api.github.com/users/jolespin/repos", "events_url": "https://api.github.com/users/jolespin/events{/privacy}", "received_events_url": "https://api.github.com/users/jolespin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-01-17T23:32:41Z", "updated_at": "2018-04-26T07:27:45Z", "closed_at": "2018-04-26T07:27:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was getting this same error w/ my custom neural network so I wanted to try it out on the example dataset (w/ minor edits).  I am still getting this error. \r\n```python\r\nimport keras, hyperas, hyperopt, tensorflow\r\nkeras.__version__,  hyperopt.__version__, tensorflow.__version__\r\n('2.1.2', '0.1', '1.4.0')\r\n```\r\n(btw, `hyperas` doesn't have a `__version__` I just realized) \r\n\r\n```python\r\nfrom __future__ import print_function\r\n\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom keras.datasets import mnist\r\nfrom keras.layers.core import Dense, Dropout, Activation\r\nfrom keras.models import Sequential\r\nfrom keras.utils import np_utils\r\n\r\nfrom hyperas import optim\r\nfrom hyperas.distributions import choice, uniform, conditional\r\n\r\n\r\ndef data():\r\n    \"\"\"\r\n    Data providing function:\r\n\r\n    This function is separated from create_model() so that hyperopt\r\n    won't reload data for each evaluation run.\r\n    \"\"\"\r\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n    x_train = x_train.reshape(60000, 784)\r\n    x_test = x_test.reshape(10000, 784)\r\n    x_train = x_train.astype('float32')\r\n    x_test = x_test.astype('float32')\r\n    x_train /= 255\r\n    x_test /= 255\r\n    nb_classes = 10\r\n    y_train = np_utils.to_categorical(y_train, nb_classes)\r\n    y_test = np_utils.to_categorical(y_test, nb_classes)\r\n    return x_train, y_train, x_test, y_test\r\n\r\n\r\ndef create_model(x_train, y_train, x_test, y_test):\r\n    \"\"\"\r\n    Model providing function:\r\n\r\n    Create Keras model with double curly brackets dropped-in as needed.\r\n    Return value has to be a valid python dictionary with two customary keys:\r\n        - loss: Specify a numeric evaluation metric to be minimized\r\n        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n    The last one is optional, though recommended, namely:\r\n        - model: specify the model just created so that we can later use it again.\r\n    \"\"\"\r\n    model = Sequential()\r\n    model.add(Input(784,))\r\n    model.add(Dense(512))\r\n    model.add(Activation('relu'))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n    model.add(Dense({{choice([128, 256])}}))\r\n    model.add(Activation(\"relu\"))\r\n    model.add(Dropout(0.2))\r\n\r\n    # If we choose 'four', add an additional fourth layer\r\n    if conditional({{choice(['three', 'four'])}}) == 'four':\r\n        model.add(Dense(100))\r\n\r\n        # We can also choose between complete sets of layers\r\n\r\n\r\n    model.add(Dense(10))\r\n    model.add(Activation('softmax'))\r\n\r\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\r\n                  optimizer=SGD(0.01))\r\n\r\n    model.fit(x_train, y_train,\r\n              batch_size={{choice([64, 128])}},\r\n              epochs=1,\r\n              verbose=2,\r\n              validation_data=(x_test, y_test))\r\n    score, acc = model.evaluate(x_test, y_test, verbose=0)\r\n    print('Test accuracy:', acc)\r\n    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\r\n\r\n\r\nbest_run, best_model = optim.minimize(model=create_model,\r\n                                      data=data,\r\n                                      algo=tpe.suggest,\r\n                                      max_evals=5,\r\n                                      trials=Trials(), \r\n                                      notebook_name=\"Untitled\")\r\n\r\nX_train, Y_train, X_test, Y_test = data()\r\nprint(\"Evalutation of best performing model:\")\r\nprint(best_model.evaluate(X_test, Y_test))\r\nprint(\"Best performing model chosen hyper-parameters:\")\r\nprint(best_run)\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/141", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/141/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/141/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/141/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/141", "id": 288785487, "node_id": "MDU6SXNzdWUyODg3ODU0ODc=", "number": 141, "title": "Working with non-hardcoded data", "user": {"login": "flexthink", "id": 1496671, "node_id": "MDQ6VXNlcjE0OTY2NzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1496671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flexthink", "html_url": "https://github.com/flexthink", "followers_url": "https://api.github.com/users/flexthink/followers", "following_url": "https://api.github.com/users/flexthink/following{/other_user}", "gists_url": "https://api.github.com/users/flexthink/gists{/gist_id}", "starred_url": "https://api.github.com/users/flexthink/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flexthink/subscriptions", "organizations_url": "https://api.github.com/users/flexthink/orgs", "repos_url": "https://api.github.com/users/flexthink/repos", "events_url": "https://api.github.com/users/flexthink/events{/privacy}", "received_events_url": "https://api.github.com/users/flexthink/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-01-16T04:52:09Z", "updated_at": "2019-04-24T06:29:51Z", "closed_at": "2018-06-13T09:09:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "As of now, I didn't find a way to pass parameters to the `data()` function, and it appears to ignore everything in the code except imports. This is because Hyperas creates a new Python file out of the data, the model and everything else before attempting to train, and this works well if you're training on MNIST or some other data set that came with the framework - or on random data. But what if the data-set is selected from a drop-down or retrieved from a URL? What if you want to run it out of a script that has a config file that specifies the path to the data? What if it needs to read a database? Is there a way to do this the way Hyperas is currently set up? If not, is there anything on the roadmap?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/140", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/140/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/140/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/140/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/140", "id": 282347155, "node_id": "MDU6SXNzdWUyODIzNDcxNTU=", "number": 140, "title": "For those who are struggling to find positions for many optimized parameters", "user": {"login": "mingfeisun", "id": 16696299, "node_id": "MDQ6VXNlcjE2Njk2Mjk5", "avatar_url": "https://avatars3.githubusercontent.com/u/16696299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mingfeisun", "html_url": "https://github.com/mingfeisun", "followers_url": "https://api.github.com/users/mingfeisun/followers", "following_url": "https://api.github.com/users/mingfeisun/following{/other_user}", "gists_url": "https://api.github.com/users/mingfeisun/gists{/gist_id}", "starred_url": "https://api.github.com/users/mingfeisun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mingfeisun/subscriptions", "organizations_url": "https://api.github.com/users/mingfeisun/orgs", "repos_url": "https://api.github.com/users/mingfeisun/repos", "events_url": "https://api.github.com/users/mingfeisun/events{/privacy}", "received_events_url": "https://api.github.com/users/mingfeisun/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-12-15T07:58:36Z", "updated_at": "2019-03-09T18:05:09Z", "closed_at": "2018-06-13T09:09:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "How to find the position correspondences for the random-named optimized parameters? \r\n\r\nDuring the tuning process, there are some important outputs which can help to locate. \r\n\r\nFirst, check the definition of `get_space` function in `Hypers search space` from the tuning outputs. You will find something like this:\r\n\r\n![get_space](https://user-images.githubusercontent.com/16696299/34032055-ac7914e8-e1b7-11e7-8e43-1a18d431480f.png)\r\n\r\nThis information helps us to know the naming for all parameters to be tuned. \r\n\r\nSecond, check the `Resulting replaced keras model` from the tuning outputs. Something like this:\r\n\r\n![space](https://user-images.githubusercontent.com/16696299/34032161-131d5754-e1b8-11e7-8093-9b5deed91041.png)\r\n\r\nYou will see some codes are replaced by `space['Dropout']`, `space['Dropout_1']`. This is the corresponding positions for the optimized parameters. At this point, it's easy to fill in the optimized parameters. \r\n\r\nHope this helps. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/139", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/139/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/139/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/139/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/139", "id": 282022021, "node_id": "MDU6SXNzdWUyODIwMjIwMjE=", "number": 139, "title": "Functional API not supported", "user": {"login": "GMarzinotto", "id": 5233985, "node_id": "MDQ6VXNlcjUyMzM5ODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/5233985?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GMarzinotto", "html_url": "https://github.com/GMarzinotto", "followers_url": "https://api.github.com/users/GMarzinotto/followers", "following_url": "https://api.github.com/users/GMarzinotto/following{/other_user}", "gists_url": "https://api.github.com/users/GMarzinotto/gists{/gist_id}", "starred_url": "https://api.github.com/users/GMarzinotto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GMarzinotto/subscriptions", "organizations_url": "https://api.github.com/users/GMarzinotto/orgs", "repos_url": "https://api.github.com/users/GMarzinotto/repos", "events_url": "https://api.github.com/users/GMarzinotto/events{/privacy}", "received_events_url": "https://api.github.com/users/GMarzinotto/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-12-14T08:44:43Z", "updated_at": "2018-06-13T09:09:04Z", "closed_at": "2018-06-13T09:09:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello !\r\n\r\nI have a quick question\r\nDoes Hyperas works on models built using the Functional API?\r\nI have had a hard time trying to set it up without success\r\n\r\nKind regards,\r\nGabriel M\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/138", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/138/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/138/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/138/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/138", "id": 281919026, "node_id": "MDU6SXNzdWUyODE5MTkwMjY=", "number": 138, "title": "hyperas in keras", "user": {"login": "zhangyu2ustc", "id": 7600834, "node_id": "MDQ6VXNlcjc2MDA4MzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/7600834?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangyu2ustc", "html_url": "https://github.com/zhangyu2ustc", "followers_url": "https://api.github.com/users/zhangyu2ustc/followers", "following_url": "https://api.github.com/users/zhangyu2ustc/following{/other_user}", "gists_url": "https://api.github.com/users/zhangyu2ustc/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangyu2ustc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangyu2ustc/subscriptions", "organizations_url": "https://api.github.com/users/zhangyu2ustc/orgs", "repos_url": "https://api.github.com/users/zhangyu2ustc/repos", "events_url": "https://api.github.com/users/zhangyu2ustc/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangyu2ustc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-12-13T22:28:41Z", "updated_at": "2018-06-13T08:34:42Z", "closed_at": "2018-06-13T08:34:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I am using hyperas with Keras in python3 and got the following errors. Can anyone help? thanks!\r\n\r\nHyperas search space:\r\n\r\ndef get_space():\r\n    return {\r\n        'Conv2D': hp.choice('Conv2D', [32,64]),\r\n        'Conv2D_1': hp.choice('Conv2D_1', [32,64]),\r\n        'Dense': hp.choice('Dense', [64,128,256]),\r\n    }\r\n\r\n>>> Data\r\n  1: \r\n  2: (X_train,y_train),(X_test,y_test) = mnist.load_data()\r\n  3: X_train = np.float32(X_train)/255\r\n  4: X_test = np.float32(X_test)/255\r\n  5: \r\n  6: nsamples,img_rows,img_cols = X_train.shape\r\n  7: nb_class = len(np.unique(y_train))\r\n  8: if K.image_data_format() == 'channels_first':\r\n  9:     img_shape = (1,img_rows,img_cols)\r\n 10: elif K.image_data_format() == 'channels_last':\r\n 11:     img_shape = (img_rows,img_cols,1)\r\n 12: \r\n 13: X_train = X_train.reshape((X_train.shape[0],)+img_shape)\r\n 14: X_test = X_test.reshape((X_test.shape[0],)+img_shape)\r\n 15: Y_train = np_utils.to_categorical(y_train,nb_class)\r\n 16: Y_test = np_utils.to_categorical(y_test,nb_class)\r\n 17: \r\n 18: \r\n 19: \r\n 20: \r\n>>> Resulting replaced keras model:\r\n\r\n   1: def keras_fmin_fnct(space):\r\n   2: \r\n   3:     nsamples,img_rows,img_cols = X_train.shape\r\n   4:     nb_class = len(np.unique(y_train))\r\n   5:     if K.image_data_format() == 'channels_first':\r\n   6:         img_shape = (1,img_rows,img_cols)\r\n   7:     elif K.image_data_format() == 'channels_last':\r\n   8:         img_shape = (img_rows,img_cols,1)\r\n   9:         \r\n  10:     #input_shape = np.append(np.array([None]),list(img_shape))\r\n  11:     model = Sequential()\r\n  12:     model.add(Conv2D( space['Conv2D'], (convsize,convsize), padding='same', activation='relu',input_shape=img_shape))\r\n  13:     model.add(Conv2D( space['Conv2D_1'], (convsize,convsize), padding='same', activation='relu'))\r\n  14:     model.add(MaxPooling2D((poolsize,poolsize)))\r\n  15:     model.add(Dropout(0.2))\r\n  16:         \r\n  17:     model.add(Flatten())\r\n  18:     model.add(Dense(space['Dense'],activation='relu'))\r\n  19:     model.add(Dropout(0.5))\r\n  20:     model.add(Dense(nb_class,activation='softmax'))\r\n  21:     \r\n  22:     model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n  23:     model.summary()\r\n  24:     \r\n  25:     model_history = model.fit(X_train,Y_train,batch_size=128,epochs=10,validation_split=0.05)\r\n  26:     scores = model.evaluate(X_test,Y_test)\r\n  27:     print(scores)\r\n  28:     return {'scores':scores[0],'status':STATUS_OK,'model':model}\r\n  29: \r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-27-bd58f3db5b26> in <module>()\r\n     63                                      max_evals = 5,\r\n     64                                      trials = Trials(),\r\n---> 65                                      notebook_name='tensorflow_practice_test5')\r\n     66 print(best_model.evaluate(X_test,Y_test))\r\n     67 print(best_run)\r\n\r\n/mnt/home_sq/yzhang/python_venv/tensorflow/lib/python3.5/site-packages/hyperas/optim.py in minimize(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\r\n     65                                      full_model_string=None,\r\n     66                                      notebook_name=notebook_name,\r\n---> 67                                      verbose=verbose)\r\n     68 \r\n     69     best_model = None\r\n\r\n/mnt/home_sq/yzhang/python_venv/tensorflow/lib/python3.5/site-packages/hyperas/optim.py in base_minimizer(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\r\n    126     return (\r\n    127         fmin(keras_fmin_fnct,\r\n--> 128              space=get_space(),\r\n    129              algo=algo,\r\n    130              max_evals=max_evals,\r\n\r\n/mnt/home_sq/yzhang/pylearn/temp_model.py in get_space()\r\n\r\n/mnt/home_sq/yzhang/python_venv/tensorflow/lib/python3.5/site-packages/hyperopt/pyll_utils.py in wrapper(label, *args, **kwargs)\r\n     20         if not is_real_string and not is_literal_string:\r\n     21             raise TypeError('require string label')\r\n---> 22         return f(label, *args, **kwargs)\r\n     23     return wrapper\r\n     24 \r\n\r\nTypeError: hp_choice() takes 2 positional arguments but 3 were given\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/137", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/137/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/137/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/137/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/137", "id": 276236707, "node_id": "MDU6SXNzdWUyNzYyMzY3MDc=", "number": 137, "title": "import LabelEncoder in submodule needs additional imports in functions list", "user": {"login": "kacper1095", "id": 16157910, "node_id": "MDQ6VXNlcjE2MTU3OTEw", "avatar_url": "https://avatars2.githubusercontent.com/u/16157910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kacper1095", "html_url": "https://github.com/kacper1095", "followers_url": "https://api.github.com/users/kacper1095/followers", "following_url": "https://api.github.com/users/kacper1095/following{/other_user}", "gists_url": "https://api.github.com/users/kacper1095/gists{/gist_id}", "starred_url": "https://api.github.com/users/kacper1095/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kacper1095/subscriptions", "organizations_url": "https://api.github.com/users/kacper1095/orgs", "repos_url": "https://api.github.com/users/kacper1095/repos", "events_url": "https://api.github.com/users/kacper1095/events{/privacy}", "received_events_url": "https://api.github.com/users/kacper1095/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-23T00:04:18Z", "updated_at": "2018-06-13T08:38:18Z", "closed_at": "2018-06-13T08:38:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi!\r\n\r\nI'm struggling currently with following issue. I'm trying to run optimization on model, which uses singleton class that I imported in ran script. This singleton imports and uses LabelEncoder from sklear.preprocessing. I tried successively adding to `functions` more and more classes that LabelEncoder uses (such as `column_or_1d`, and many more). But I stopped at the moment, where I had to import a property, which hyperas `minimize` didn't accept. \r\n\r\nI'm running my script from top module using command\r\n```\r\npython -m src.module.submodule.script\r\n```\r\n\r\nError I get:\r\n```\r\nNameError: name 'column_or_1d' is not defined  \r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/136", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/136/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/136/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/136/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/136", "id": 276221490, "node_id": "MDU6SXNzdWUyNzYyMjE0OTA=", "number": 136, "title": "TypeError: 'generator' object has no attribute '__getitem__'", "user": {"login": "JakSla", "id": 7399649, "node_id": "MDQ6VXNlcjczOTk2NDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/7399649?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JakSla", "html_url": "https://github.com/JakSla", "followers_url": "https://api.github.com/users/JakSla/followers", "following_url": "https://api.github.com/users/JakSla/following{/other_user}", "gists_url": "https://api.github.com/users/JakSla/gists{/gist_id}", "starred_url": "https://api.github.com/users/JakSla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JakSla/subscriptions", "organizations_url": "https://api.github.com/users/JakSla/orgs", "repos_url": "https://api.github.com/users/JakSla/repos", "events_url": "https://api.github.com/users/JakSla/events{/privacy}", "received_events_url": "https://api.github.com/users/JakSla/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-11-22T22:28:43Z", "updated_at": "2018-04-05T20:29:27Z", "closed_at": "2017-11-22T22:28:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is just for reference if someone comes across it as well to not waste his time.\r\nIt's another name for TypeError: 'generator' object is not subscriptable.\r\nissue was resolved by simply installing networkx in older version as in other case.\r\ndo\r\npip install networkx==1.11\r\n\r\nTraceback (most recent call last):\r\n  File \"bayesian_optimization.py\", line 90, in <module>\r\n    trials=Trials())\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.py\", line 314, in fmin\r\n    pass_expr_memo_ctrl=pass_expr_memo_ctrl)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/base.py\", line 786, in __init__\r\n    pyll.toposort(self.expr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/hyperopt/pyll/base.py\", line 715, in toposort\r\n    assert order[-1] == expr\r\nTypeError: 'generator' object has no attribute '__getitem__'\r\n\r\nseems like exactly the same issue, but different error message.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/135", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/135/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/135/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/135/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/135", "id": 275812940, "node_id": "MDU6SXNzdWUyNzU4MTI5NDA=", "number": 135, "title": "Error using hyperas", "user": {"login": "reversemartell", "id": 32202864, "node_id": "MDQ6VXNlcjMyMjAyODY0", "avatar_url": "https://avatars3.githubusercontent.com/u/32202864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reversemartell", "html_url": "https://github.com/reversemartell", "followers_url": "https://api.github.com/users/reversemartell/followers", "following_url": "https://api.github.com/users/reversemartell/following{/other_user}", "gists_url": "https://api.github.com/users/reversemartell/gists{/gist_id}", "starred_url": "https://api.github.com/users/reversemartell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reversemartell/subscriptions", "organizations_url": "https://api.github.com/users/reversemartell/orgs", "repos_url": "https://api.github.com/users/reversemartell/repos", "events_url": "https://api.github.com/users/reversemartell/events{/privacy}", "received_events_url": "https://api.github.com/users/reversemartell/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-21T18:21:08Z", "updated_at": "2017-12-08T18:56:01Z", "closed_at": "2017-11-22T19:36:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello! I get an error when i used the examples in github(https://github.com/maxpumperla/hyperas/tree/master/examples). I'm using w10 64 bits, Anaconda 3,Spyder 3.1.4, python 3.6.\r\n\r\nExample : \"cnn_lstm.py\".\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-1-1933c0fc7242>\", line 69, in <module>\r\n    trials=Trials())\r\n\r\n  File \"C:\\Users\\Miguel\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n\r\n  File \"C:\\Users\\Miguel\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\", line 96, in base_minimizer\r\n    model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\r\n\r\n  File \"C:\\Users\\Miguel\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\", line 178, in get_hyperopt_model_string\r\n    with open(calling_script_file, 'r') as f:\r\n\r\nOSError: [Errno 22] Invalid argument: 'C:\\\\Users\\\\Miguel\\\\<ipython-input-1-1933c0fc7242>'", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/134", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/134/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/134/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/134/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/134", "id": 270195212, "node_id": "MDU6SXNzdWUyNzAxOTUyMTI=", "number": 134, "title": "dump trials error", "user": {"login": "sparo-jack", "id": 8348554, "node_id": "MDQ6VXNlcjgzNDg1NTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/8348554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sparo-jack", "html_url": "https://github.com/sparo-jack", "followers_url": "https://api.github.com/users/sparo-jack/followers", "following_url": "https://api.github.com/users/sparo-jack/following{/other_user}", "gists_url": "https://api.github.com/users/sparo-jack/gists{/gist_id}", "starred_url": "https://api.github.com/users/sparo-jack/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sparo-jack/subscriptions", "organizations_url": "https://api.github.com/users/sparo-jack/orgs", "repos_url": "https://api.github.com/users/sparo-jack/repos", "events_url": "https://api.github.com/users/sparo-jack/events{/privacy}", "received_events_url": "https://api.github.com/users/sparo-jack/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-11-01T05:09:45Z", "updated_at": "2020-05-19T18:55:27Z", "closed_at": "2018-06-13T08:46:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "TypeError:can not pickle module", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/133", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/133/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/133/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/133/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/133", "id": 269866260, "node_id": "MDU6SXNzdWUyNjk4NjYyNjA=", "number": 133, "title": "Repeating tested hyperparameters", "user": {"login": "nd26", "id": 7026980, "node_id": "MDQ6VXNlcjcwMjY5ODA=", "avatar_url": "https://avatars3.githubusercontent.com/u/7026980?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nd26", "html_url": "https://github.com/nd26", "followers_url": "https://api.github.com/users/nd26/followers", "following_url": "https://api.github.com/users/nd26/following{/other_user}", "gists_url": "https://api.github.com/users/nd26/gists{/gist_id}", "starred_url": "https://api.github.com/users/nd26/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nd26/subscriptions", "organizations_url": "https://api.github.com/users/nd26/orgs", "repos_url": "https://api.github.com/users/nd26/repos", "events_url": "https://api.github.com/users/nd26/events{/privacy}", "received_events_url": "https://api.github.com/users/nd26/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-10-31T07:55:52Z", "updated_at": "2017-10-31T07:59:06Z", "closed_at": "2017-10-31T07:59:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "Posted by accident.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/130", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/130/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/130/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/130/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/130", "id": 269015827, "node_id": "MDU6SXNzdWUyNjkwMTU4Mjc=", "number": 130, "title": "What's the point of `conditional` ?", "user": {"login": "shadiakiki1986", "id": 8392324, "node_id": "MDQ6VXNlcjgzOTIzMjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8392324?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shadiakiki1986", "html_url": "https://github.com/shadiakiki1986", "followers_url": "https://api.github.com/users/shadiakiki1986/followers", "following_url": "https://api.github.com/users/shadiakiki1986/following{/other_user}", "gists_url": "https://api.github.com/users/shadiakiki1986/gists{/gist_id}", "starred_url": "https://api.github.com/users/shadiakiki1986/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shadiakiki1986/subscriptions", "organizations_url": "https://api.github.com/users/shadiakiki1986/orgs", "repos_url": "https://api.github.com/users/shadiakiki1986/repos", "events_url": "https://api.github.com/users/shadiakiki1986/events{/privacy}", "received_events_url": "https://api.github.com/users/shadiakiki1986/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-10-27T07:44:01Z", "updated_at": "2018-06-13T07:50:28Z", "closed_at": "2018-06-13T07:50:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "So `conditional` is just a function that passes its input. What's the point of it?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/129", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/129/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/129/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/129/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/129", "id": 269015573, "node_id": "MDU6SXNzdWUyNjkwMTU1NzM=", "number": 129, "title": "Safe-to-close issues", "user": {"login": "shadiakiki1986", "id": 8392324, "node_id": "MDQ6VXNlcjgzOTIzMjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8392324?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shadiakiki1986", "html_url": "https://github.com/shadiakiki1986", "followers_url": "https://api.github.com/users/shadiakiki1986/followers", "following_url": "https://api.github.com/users/shadiakiki1986/following{/other_user}", "gists_url": "https://api.github.com/users/shadiakiki1986/gists{/gist_id}", "starred_url": "https://api.github.com/users/shadiakiki1986/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shadiakiki1986/subscriptions", "organizations_url": "https://api.github.com/users/shadiakiki1986/orgs", "repos_url": "https://api.github.com/users/shadiakiki1986/repos", "events_url": "https://api.github.com/users/shadiakiki1986/events{/privacy}", "received_events_url": "https://api.github.com/users/shadiakiki1986/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-10-27T07:42:53Z", "updated_at": "2017-10-27T08:25:27Z", "closed_at": "2017-10-27T08:25:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I think the following issues are safe to close:\r\n- #125 \r\n- #118 \r\n- #114 \r\n- #106 \r\n- #113 \r\n\r\nEdit: Can also close\r\n- #17 \r\n- #31 ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/126", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/126/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/126/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/126/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/126", "id": 267649917, "node_id": "MDU6SXNzdWUyNjc2NDk5MTc=", "number": 126, "title": "'generator' object is not subscriptable", "user": {"login": "peachyDinosaur", "id": 11046880, "node_id": "MDQ6VXNlcjExMDQ2ODgw", "avatar_url": "https://avatars2.githubusercontent.com/u/11046880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peachyDinosaur", "html_url": "https://github.com/peachyDinosaur", "followers_url": "https://api.github.com/users/peachyDinosaur/followers", "following_url": "https://api.github.com/users/peachyDinosaur/following{/other_user}", "gists_url": "https://api.github.com/users/peachyDinosaur/gists{/gist_id}", "starred_url": "https://api.github.com/users/peachyDinosaur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peachyDinosaur/subscriptions", "organizations_url": "https://api.github.com/users/peachyDinosaur/orgs", "repos_url": "https://api.github.com/users/peachyDinosaur/repos", "events_url": "https://api.github.com/users/peachyDinosaur/events{/privacy}", "received_events_url": "https://api.github.com/users/peachyDinosaur/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-10-23T12:32:06Z", "updated_at": "2017-12-23T09:37:35Z", "closed_at": "2017-10-23T21:46:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "Just installed in a virtual enviorment with Python 3.6 and I am unable to run the basic example on the readme or any of the example in the example folder and they all give similar errors. \r\n\r\n### Code \r\n\r\n`from __future__ import print_function\r\n\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom keras.datasets import mnist\r\nfrom keras.layers.core import Dense, Dropout, Activation\r\nfrom keras.models import Sequential\r\nfrom keras.utils import np_utils\r\n\r\nfrom hyperas import optim\r\nfrom hyperas.distributions import choice, uniform, conditional\r\n\r\n\r\ndef data():\r\n    \"\"\"\r\n    Data providing function:\r\n    This function is separated from model() so that hyperopt\r\n    won't reload data for each evaluation run.\r\n    \"\"\"\r\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n    x_train = x_train.reshape(60000, 784)\r\n    x_test = x_test.reshape(10000, 784)\r\n    x_train = x_train.astype('float32')\r\n    x_test = x_test.astype('float32')\r\n    x_train /= 255\r\n    x_test /= 255\r\n    nb_classes = 10\r\n    y_train = np_utils.to_categorical(y_train, nb_classes)\r\n    y_test = np_utils.to_categorical(y_test, nb_classes)\r\n    return x_train, y_train, x_test, y_test\r\n\r\n\r\ndef model(x_train, y_train, x_test, y_test):\r\n    \"\"\"\r\n    Model providing function:\r\n    Create Keras model with double curly brackets dropped-in as needed.\r\n    Return value has to be a valid python dictionary with two customary keys:\r\n        - loss: Specify a numeric evaluation metric to be minimized\r\n        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n    The last one is optional, though recommended, namely:\r\n        - model: specify the model just created so that we can later use it again.\r\n    \"\"\"\r\n    model = Sequential()\r\n    model.add(Dense(512, input_shape=(784,)))\r\n    model.add(Activation('relu'))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n    model.add(Dense({{choice([256, 512, 1024])}}))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.add(Dropout({{uniform(0, 1)}}))\r\n\r\n    # If we choose 'four', add an additional fourth layer\r\n    if conditional({{choice(['three', 'four'])}}) == 'four':\r\n        model.add(Dense(100))\r\n\r\n        # We can also choose between complete sets of layers\r\n\r\n        model.add({{choice([Dropout(0.5), Activation('linear')])}})\r\n        model.add(Activation('relu'))\r\n\r\n    model.add(Dense(10))\r\n    model.add(Activation('softmax'))\r\n\r\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\r\n                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\r\n\r\n    model.fit(x_train, y_train,\r\n              batch_size={{choice([64, 128])}},\r\n              epochs=1,\r\n              verbose=2,\r\n              validation_data=(x_test, y_test))\r\n    score, acc = model.evaluate(x_test, y_test, verbose=0)\r\n    print('Test accuracy:', acc)\r\n    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\r\n\r\n\r\nif __name__ == '__main__':\r\n    best_run, best_model = optim.minimize(model=model,\r\n                                          data=data,\r\n                                          algo=tpe.suggest,\r\n                                          max_evals=5,\r\n                                          trials=Trials())\r\n    X_train, Y_train, X_test, Y_test = data()\r\n    print(\"Evalutation of best performing model:\")\r\n    print(best_model.evaluate(X_test, Y_test))\r\n    print(\"Best performing model chosen hyper-parameters:\")\r\nprint(best_run)`\r\n\r\n### Results in \r\n\r\n`Using TensorFlow backend.\r\n>>> Imports:\r\n#coding=utf-8\r\n\r\nfrom __future__ import print_function\r\n\r\ntry:\r\n    from hyperopt import Trials, STATUS_OK, tpe\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.datasets import mnist\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.layers.core import Dense, Dropout, Activation\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.models import Sequential\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.utils import np_utils\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas import optim\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas.distributions import choice, uniform, conditional\r\nexcept:\r\n    pass\r\n\r\n>>> Hyperas search space:\r\n\r\ndef get_space():\r\n    return {\r\n        'Dropout': hp.uniform('Dropout', 0, 1),\r\n        'Dense': hp.choice('Dense', [256, 512, 1024]),\r\n        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\r\n        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\r\n        'conditional': hp.choice('conditional', ['three', 'four']),\r\n        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\r\n        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\r\n        'batch_size': hp.choice('batch_size', [64, 128]),\r\n    }\r\n\r\n>>> Data\r\n  1: \r\n  2: \"\"\"\r\n  3: Data providing function:\r\n  4: This function is separated from model() so that hyperopt\r\n  5: won't reload data for each evaluation run.\r\n  6: \"\"\"\r\n  7: (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n  8: x_train = x_train.reshape(60000, 784)\r\n  9: x_test = x_test.reshape(10000, 784)\r\n 10: x_train = x_train.astype('float32')\r\n 11: x_test = x_test.astype('float32')\r\n 12: x_train /= 255\r\n 13: x_test /= 255\r\n 14: nb_classes = 10\r\n 15: y_train = np_utils.to_categorical(y_train, nb_classes)\r\n 16: y_test = np_utils.to_categorical(y_test, nb_classes)\r\n 17: \r\n 18: \r\n 19: \r\n>>> Resulting replaced keras model:\r\n\r\n   1: def keras_fmin_fnct(space):\r\n   2: \r\n   3:     \"\"\"\r\n   4:     Model providing function:\r\n   5:     Create Keras model with double curly brackets dropped-in as needed.\r\n   6:     Return value has to be a valid python dictionary with two customary keys:\r\n   7:         - loss: Specify a numeric evaluation metric to be minimized\r\n   8:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n   9:     The last one is optional, though recommended, namely:\r\n  10:         - model: specify the model just created so that we can later use it again.\r\n  11:     \"\"\"\r\n  12:     model = Sequential()\r\n  13:     model.add(Dense(512, input_shape=(784,)))\r\n  14:     model.add(Activation('relu'))\r\n  15:     model.add(Dropout(space['Dropout']))\r\n  16:     model.add(Dense(space['Dense']))\r\n  17:     model.add(Activation(space['Activation']))\r\n  18:     model.add(Dropout(space['Dropout_1']))\r\n  19: \r\n  20:     # If we choose 'four', add an additional fourth layer\r\n  21:     if conditional(space['conditional']) == 'four':\r\n  22:         model.add(Dense(100))\r\n  23: \r\n  24:         # We can also choose between complete sets of layers\r\n  25: \r\n  26:         model.add(space['add'])\r\n  27:         model.add(Activation('relu'))\r\n  28: \r\n  29:     model.add(Dense(10))\r\n  30:     model.add(Activation('softmax'))\r\n  31: \r\n  32:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\r\n  33:                   optimizer=space['optimizer'])\r\n  34: \r\n  35:     model.fit(x_train, y_train,\r\n  36:               batch_size=space['batch_size'],\r\n  37:               epochs=1,\r\n  38:               verbose=2,\r\n  39:               validation_data=(x_test, y_test))\r\n  40:     score, acc = model.evaluate(x_test, y_test, verbose=0)\r\n  41:     print('Test accuracy:', acc)\r\n  42:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\r\n  43: \r\nTraceback (most recent call last):\r\n  File \"hy.py\", line 80, in <module>\r\n    trials=Trials())\r\n  File \"/home/peachy/Documents/tensorflow/tf/lib/python3.6/site-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/home/peachy/Documents/tensorflow/tf/lib/python3.6/site-packages/hyperas/optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/home/peachy/Documents/tensorflow/tf/lib/python3.6/site-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/home/peachy/Documents/tensorflow/tf/lib/python3.6/site-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/home/peachy/Documents/tensorflow/tf/lib/python3.6/site-packages/hyperopt/fmin.py\", line 314, in fmin\r\n    pass_expr_memo_ctrl=pass_expr_memo_ctrl)\r\n  File \"/home/peachy/Documents/tensorflow/tf/lib/python3.6/site-packages/hyperopt/base.py\", line 786, in __init__\r\n    pyll.toposort(self.expr)\r\n  File \"/home/peachy/Documents/tensorflow/tf/lib/python3.6/site-packages/hyperopt/pyll/base.py\", line 715, in toposort\r\n    assert order[-1] == expr\r\nTypeError: 'generator' object is not subscriptable\r\n`\r\nAny help would be appreciated ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/125", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/125/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/125/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/125/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/125", "id": 267413916, "node_id": "MDU6SXNzdWUyNjc0MTM5MTY=", "number": 125, "title": "TypeError: 'generator' object is not subscriptable", "user": {"login": "brunoklein99", "id": 11358728, "node_id": "MDQ6VXNlcjExMzU4NzI4", "avatar_url": "https://avatars2.githubusercontent.com/u/11358728?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brunoklein99", "html_url": "https://github.com/brunoklein99", "followers_url": "https://api.github.com/users/brunoklein99/followers", "following_url": "https://api.github.com/users/brunoklein99/following{/other_user}", "gists_url": "https://api.github.com/users/brunoklein99/gists{/gist_id}", "starred_url": "https://api.github.com/users/brunoklein99/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brunoklein99/subscriptions", "organizations_url": "https://api.github.com/users/brunoklein99/orgs", "repos_url": "https://api.github.com/users/brunoklein99/repos", "events_url": "https://api.github.com/users/brunoklein99/events{/privacy}", "received_events_url": "https://api.github.com/users/brunoklein99/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-10-21T21:00:29Z", "updated_at": "2018-08-12T12:15:05Z", "closed_at": "2017-10-27T08:25:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nfrom hyperas import optim\r\nfrom hyperopt import Trials, tpe\r\n\r\n\r\ndef data():\r\n    return 1, 2, 3, 4\r\n\r\n\r\ndef model(a, b, c, d):\r\n    pass\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    trials = Trials()\r\n    bla = optim.minimize(model=model, data=data, algo=tpe.suggest,\r\n                         max_evals=5,\r\n                         trials=trials)\r\n\r\n```\r\n\r\n```\r\nC:\\Users\\klein-desk\\AppData\\Local\\Programs\\Python\\Python35\\python.exe G:/Source/untitled4/main.py\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n>>> Imports:\r\n  File \"G:/Source/untitled4/main.py\", line 18, in <module>\r\n#coding=utf-8\r\n    trials=trials)\r\n\r\ntry:\r\n    from hyperas import optim\r\n  File \"C:\\Users\\klein-desk\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\r\nexcept:\r\n    pass\r\n    verbose=verbose)\r\n\r\n  File \"C:\\Users\\klein-desk\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\hyperas\\optim.py\", line 133, in base_minimizer\r\ntry:\r\n    return_argmin=True),\r\n  File \"C:\\Users\\klein-desk\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\r\n    from hyperopt import Trials, tpe\r\n    return_argmin=return_argmin,\r\nexcept:\r\n  File \"C:\\Users\\klein-desk\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\r\n    pass\r\n\r\n    return_argmin=return_argmin)\r\n>>> Hyperas search space:\r\n\r\ndef get_space():\r\n  File \"C:\\Users\\klein-desk\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\hyperopt\\fmin.py\", line 314, in fmin\r\n    return {\r\n    }\r\n    pass_expr_memo_ctrl=pass_expr_memo_ctrl)\r\n\r\n  File \"C:\\Users\\klein-desk\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\hyperopt\\base.py\", line 786, in __init__\r\n>>> Data\r\n    pyll.toposort(self.expr)\r\n1: \r\n2: \r\n  File \"C:\\Users\\klein-desk\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\hyperopt\\pyll\\base.py\", line 715, in toposort\r\n3: \r\n4: \r\n    assert order[-1] == expr\r\n>>> Resulting replaced keras model:\r\nTypeError: 'generator' object is not subscriptable\r\n\r\n 1: def keras_fmin_fnct(space):\r\n 2: \r\n 3:     pass\r\n 4: \r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\nWindows\r\nPython 3.5.2", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/124", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/124/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/124/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/124/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/124", "id": 267077971, "node_id": "MDU6SXNzdWUyNjcwNzc5NzE=", "number": 124, "title": "TypeError: 'map' object is not subscriptable", "user": {"login": "YangBain", "id": 28567703, "node_id": "MDQ6VXNlcjI4NTY3NzAz", "avatar_url": "https://avatars3.githubusercontent.com/u/28567703?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YangBain", "html_url": "https://github.com/YangBain", "followers_url": "https://api.github.com/users/YangBain/followers", "following_url": "https://api.github.com/users/YangBain/following{/other_user}", "gists_url": "https://api.github.com/users/YangBain/gists{/gist_id}", "starred_url": "https://api.github.com/users/YangBain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YangBain/subscriptions", "organizations_url": "https://api.github.com/users/YangBain/orgs", "repos_url": "https://api.github.com/users/YangBain/repos", "events_url": "https://api.github.com/users/YangBain/events{/privacy}", "received_events_url": "https://api.github.com/users/YangBain/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-10-20T06:45:18Z", "updated_at": "2017-11-05T13:43:15Z", "closed_at": "2017-10-20T07:05:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Traceback (most recent call last):\r\n  File \"train.caltech.py\", line 40, in <module>\r\n    image_paths_train = np.hstack(list(map(lambda one_class: one_class[:-10], image_paths_per_label)))\r\n  File \"train.caltech.py\", line 40, in <lambda>\r\n    image_paths_train = np.hstack(list(map(lambda one_class: one_class[:-10], image_paths_per_label)))\r\nTypeError: 'map' object is not subscriptable\r\n\r\nWho know the reason, Thank you very much.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/122", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/122/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/122/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/122/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/122", "id": 263718782, "node_id": "MDU6SXNzdWUyNjM3MTg3ODI=", "number": 122, "title": "Pass arbitrary arguments to data and model function via optim.minimize", "user": {"login": "pciazynski", "id": 15675132, "node_id": "MDQ6VXNlcjE1Njc1MTMy", "avatar_url": "https://avatars1.githubusercontent.com/u/15675132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pciazynski", "html_url": "https://github.com/pciazynski", "followers_url": "https://api.github.com/users/pciazynski/followers", "following_url": "https://api.github.com/users/pciazynski/following{/other_user}", "gists_url": "https://api.github.com/users/pciazynski/gists{/gist_id}", "starred_url": "https://api.github.com/users/pciazynski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pciazynski/subscriptions", "organizations_url": "https://api.github.com/users/pciazynski/orgs", "repos_url": "https://api.github.com/users/pciazynski/repos", "events_url": "https://api.github.com/users/pciazynski/events{/privacy}", "received_events_url": "https://api.github.com/users/pciazynski/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-10-08T13:42:27Z", "updated_at": "2019-09-15T07:53:01Z", "closed_at": "2019-09-15T07:53:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi! Thank you for amazing library :)\r\n\r\nI have a question: It is possible to pass some arguments into `model` and `data` functions via `optim.minimize`? \r\n\r\nE.g. I want to pass path from command line to `data` function. I have access to command line arguments only in `__main__`, but I don't know if it possible to pass this into `data` function?\r\n\r\nIt could be like that:\r\n```python\r\nsome_variable = '/some/path'\r\nanother_variable = 10\r\nbest_run, best_model = optim.minimize(model=model, data=data, algo=tpe.suggest, max_evals=3, trials=Trials(), arguments_for_data = [some_variable, another_variable])\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/120", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/120/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/120/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/120/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/120", "id": 260322920, "node_id": "MDU6SXNzdWUyNjAzMjI5MjA=", "number": 120, "title": "possible to optimize parameters for functional API models? ", "user": {"login": "qqqqqqq007", "id": 29189488, "node_id": "MDQ6VXNlcjI5MTg5NDg4", "avatar_url": "https://avatars0.githubusercontent.com/u/29189488?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qqqqqqq007", "html_url": "https://github.com/qqqqqqq007", "followers_url": "https://api.github.com/users/qqqqqqq007/followers", "following_url": "https://api.github.com/users/qqqqqqq007/following{/other_user}", "gists_url": "https://api.github.com/users/qqqqqqq007/gists{/gist_id}", "starred_url": "https://api.github.com/users/qqqqqqq007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qqqqqqq007/subscriptions", "organizations_url": "https://api.github.com/users/qqqqqqq007/orgs", "repos_url": "https://api.github.com/users/qqqqqqq007/repos", "events_url": "https://api.github.com/users/qqqqqqq007/events{/privacy}", "received_events_url": "https://api.github.com/users/qqqqqqq007/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-09-25T15:41:16Z", "updated_at": "2018-06-13T09:36:51Z", "closed_at": "2018-06-13T09:36:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hyperas run well on sequential models, but I need to optimize the parameters for multi-input models and models with shared weights using functional api. Could anyone help? Thank you very much!  ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/118", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/118/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/118/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/118/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/118", "id": 255322073, "node_id": "MDU6SXNzdWUyNTUzMjIwNzM=", "number": 118, "title": "TypeError: require string label", "user": {"login": "kaushalshetty", "id": 6664607, "node_id": "MDQ6VXNlcjY2NjQ2MDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/6664607?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kaushalshetty", "html_url": "https://github.com/kaushalshetty", "followers_url": "https://api.github.com/users/kaushalshetty/followers", "following_url": "https://api.github.com/users/kaushalshetty/following{/other_user}", "gists_url": "https://api.github.com/users/kaushalshetty/gists{/gist_id}", "starred_url": "https://api.github.com/users/kaushalshetty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kaushalshetty/subscriptions", "organizations_url": "https://api.github.com/users/kaushalshetty/orgs", "repos_url": "https://api.github.com/users/kaushalshetty/repos", "events_url": "https://api.github.com/users/kaushalshetty/events{/privacy}", "received_events_url": "https://api.github.com/users/kaushalshetty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-05T15:42:30Z", "updated_at": "2017-10-27T08:25:56Z", "closed_at": "2017-10-27T08:25:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\ninput_tensor = Input(shape=(2001,))\r\nDense({{choice([256,512,1024])}})(input_tensor)\r\n```\r\nchoice is not working. Getting the below error for the above code.\r\n\r\n`TypeError: require string label`\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/116", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/116/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/116/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/116/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/116", "id": 254511435, "node_id": "MDU6SXNzdWUyNTQ1MTE0MzU=", "number": 116, "title": "Best hyperparameters reported are not members of get_space()", "user": {"login": "beaunorgeot", "id": 9386672, "node_id": "MDQ6VXNlcjkzODY2NzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/9386672?v=4", "gravatar_id": "", "url": "https://api.github.com/users/beaunorgeot", "html_url": "https://github.com/beaunorgeot", "followers_url": "https://api.github.com/users/beaunorgeot/followers", "following_url": "https://api.github.com/users/beaunorgeot/following{/other_user}", "gists_url": "https://api.github.com/users/beaunorgeot/gists{/gist_id}", "starred_url": "https://api.github.com/users/beaunorgeot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/beaunorgeot/subscriptions", "organizations_url": "https://api.github.com/users/beaunorgeot/orgs", "repos_url": "https://api.github.com/users/beaunorgeot/repos", "events_url": "https://api.github.com/users/beaunorgeot/events{/privacy}", "received_events_url": "https://api.github.com/users/beaunorgeot/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-01T01:25:06Z", "updated_at": "2017-09-05T16:20:55Z", "closed_at": "2017-09-05T16:20:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thanks for all the work!\r\n\r\nWhen running the lstm.py example, the best hyperparameters reported are not options within the script. For example, lstm.py has` batch_size={{choice([32, 64, 128])}}` but returns things like `'batch_size': 1`.  I'm not sure if this is a print bug or something deeper.\r\n\r\nThis seems to only be true for all {{choice[]}} arguments, not with uniform() arguments. \r\n\r\n![image](https://user-images.githubusercontent.com/9386672/29951546-3c159e66-8e78-11e7-951e-c1d488f2adff.png)\r\n\r\n![image](https://user-images.githubusercontent.com/9386672/29951558-51bcd8a6-8e78-11e7-8ce3-fad013a37afe.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/115", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/115/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/115/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/115/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/115", "id": 253115169, "node_id": "MDU6SXNzdWUyNTMxMTUxNjk=", "number": 115, "title": "Sign of non-accuracy metrics", "user": {"login": "chreman", "id": 4255751, "node_id": "MDQ6VXNlcjQyNTU3NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/4255751?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chreman", "html_url": "https://github.com/chreman", "followers_url": "https://api.github.com/users/chreman/followers", "following_url": "https://api.github.com/users/chreman/following{/other_user}", "gists_url": "https://api.github.com/users/chreman/gists{/gist_id}", "starred_url": "https://api.github.com/users/chreman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chreman/subscriptions", "organizations_url": "https://api.github.com/users/chreman/orgs", "repos_url": "https://api.github.com/users/chreman/repos", "events_url": "https://api.github.com/users/chreman/events{/privacy}", "received_events_url": "https://api.github.com/users/chreman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-26T18:45:01Z", "updated_at": "2018-06-13T09:09:04Z", "closed_at": "2018-06-13T09:09:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Sorry if I missed it in the documentation, if I compile the model with a different metric, e.g.\r\n```python\r\n    model.compile(optimizer={{choice(['rmsprop', 'adadelta'])}},\r\n                  loss='mae',\r\n                  metrics=['mae'])\r\n```\r\nand then call `score, mae = model.evaluate(...)` do I need to change the sign in \r\n`return {'loss': mae, 'status': STATUS_OK, 'model': model}`?\r\nIntuitively I did so, because with accuracy higher=better, but with mean absolute error lower=better. If this is the case, a small update to the documentation would help removing this ambiguity. Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/114", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/114/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/114/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/114/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/114", "id": 251211264, "node_id": "MDU6SXNzdWUyNTEyMTEyNjQ=", "number": 114, "title": "TypeError: require string label", "user": {"login": "gufengxiaoyuehan", "id": 9584920, "node_id": "MDQ6VXNlcjk1ODQ5MjA=", "avatar_url": "https://avatars0.githubusercontent.com/u/9584920?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gufengxiaoyuehan", "html_url": "https://github.com/gufengxiaoyuehan", "followers_url": "https://api.github.com/users/gufengxiaoyuehan/followers", "following_url": "https://api.github.com/users/gufengxiaoyuehan/following{/other_user}", "gists_url": "https://api.github.com/users/gufengxiaoyuehan/gists{/gist_id}", "starred_url": "https://api.github.com/users/gufengxiaoyuehan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gufengxiaoyuehan/subscriptions", "organizations_url": "https://api.github.com/users/gufengxiaoyuehan/orgs", "repos_url": "https://api.github.com/users/gufengxiaoyuehan/repos", "events_url": "https://api.github.com/users/gufengxiaoyuehan/events{/privacy}", "received_events_url": "https://api.github.com/users/gufengxiaoyuehan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-18T10:59:32Z", "updated_at": "2017-10-27T08:26:02Z", "closed_at": "2017-10-27T08:26:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "when flowing the example code  [https://github.com/maxpumperla/hyperas](https://github.com/maxpumperla/hyperas) I get this.\r\n\r\nno solution found after search.\r\n\r\n###################\r\n`sys.version\r\n'3.6.1 (v3.6.1:69c0db5, Mar 21 2017, 18:41:36) [MSC v.1900 64 bit (AMD64)]'\r\n`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/113", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/113/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/113/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/113/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/113", "id": 249002564, "node_id": "MDU6SXNzdWUyNDkwMDI1NjQ=", "number": 113, "title": "NameError: global name 'X_train' is not defined", "user": {"login": "drorhilman", "id": 1249605, "node_id": "MDQ6VXNlcjEyNDk2MDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/1249605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drorhilman", "html_url": "https://github.com/drorhilman", "followers_url": "https://api.github.com/users/drorhilman/followers", "following_url": "https://api.github.com/users/drorhilman/following{/other_user}", "gists_url": "https://api.github.com/users/drorhilman/gists{/gist_id}", "starred_url": "https://api.github.com/users/drorhilman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drorhilman/subscriptions", "organizations_url": "https://api.github.com/users/drorhilman/orgs", "repos_url": "https://api.github.com/users/drorhilman/repos", "events_url": "https://api.github.com/users/drorhilman/events{/privacy}", "received_events_url": "https://api.github.com/users/drorhilman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-08-09T11:39:14Z", "updated_at": "2019-04-12T12:05:41Z", "closed_at": "2017-10-27T08:26:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to optimize the architecture of a simple network with hyperas...\r\nThe code for the get_model function:\r\n\r\n```\r\ndef get_model_for_optim(x_train, y_train, x_test, y_test):\r\n\r\n    n_layers = {{choice([1, 2, 4, 8])}}\r\n    layer_width = {{choice([100, 200, 400])}}\r\n    bottleneck_width = {{choice([10, 20, 40])}}\r\n    dropout_rate = {{uniform(0, 1)}}\r\n    learning_rate = {{uniform(0.000002, 0.001)}}\r\n    \r\n    inp_size = 50    \r\n    inputs = Input(shape=(inp_size,), )\r\n    x = Dense(layer_width, activation='relu')(inputs)\r\n    for i in range(n_layers): \r\n        x = BatchNormalization()(x)   \r\n        x = Dense(layer_width, activation='relu')(x)\r\n        x = Dropout(dropout_rate)(x)\r\n\r\n    x = Dense(bottleneck_width, activation='relu')(x)\r\n\r\n    predictions = Dense(1, kernel_initializer='normal', activation='relu')(x)\r\n    model = Model(inputs=inputs, outputs=predictions)\r\n    model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate))\r\n\r\n    model.fit(x_train, y_train,\r\n              batch_size=128,\r\n              epochs=3000,\r\n              verbose=0,\r\n              validation_data=(x_test, y_test),\r\n              callbacks=[EarlyStopping(patience=200)])\r\n\r\n    score = model.evaluate(x_test, y_test, verbose=0)\r\n    return {'loss': score, 'status': STATUS_OK, 'model': model}\r\n```\r\n\r\nWhen trying to optimize it with hypers...\r\n\r\n`best_run, best_model = optim.minimize(model=get_model_for_optim, algo=tpe.suggest, max_evals=200, trials=Trials(), data=get_data)`\r\n\r\nI am getting an error...\r\n\r\n> ** in keras_fmin_fnct\r\n> NameError: global name 'x_train' is not defined**\r\n\r\nhow to solve this ? where is the error is coming from?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/111", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/111/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/111/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/111/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/111", "id": 245230756, "node_id": "MDU6SXNzdWUyNDUyMzA3NTY=", "number": 111, "title": "NameError: name 'sort_text' is not defined", "user": {"login": "abrad1212", "id": 9399948, "node_id": "MDQ6VXNlcjkzOTk5NDg=", "avatar_url": "https://avatars1.githubusercontent.com/u/9399948?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abrad1212", "html_url": "https://github.com/abrad1212", "followers_url": "https://api.github.com/users/abrad1212/followers", "following_url": "https://api.github.com/users/abrad1212/following{/other_user}", "gists_url": "https://api.github.com/users/abrad1212/gists{/gist_id}", "starred_url": "https://api.github.com/users/abrad1212/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abrad1212/subscriptions", "organizations_url": "https://api.github.com/users/abrad1212/orgs", "repos_url": "https://api.github.com/users/abrad1212/repos", "events_url": "https://api.github.com/users/abrad1212/events{/privacy}", "received_events_url": "https://api.github.com/users/abrad1212/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-07-24T22:41:55Z", "updated_at": "2017-07-24T22:44:52Z", "closed_at": "2017-07-24T22:44:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "It seems that hyperas is preventing my functions from running or something. This is just like issue #87 but I tried what was said in there and it did not work.\r\n\r\nMy code is [https://gist.github.com/abrad1212/bbca1f173f0c26a3ab344347904e43c2](here). What is going on?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/108", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/108/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/108/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/108/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/108", "id": 240261222, "node_id": "MDU6SXNzdWUyNDAyNjEyMjI=", "number": 108, "title": "TypeError: 'Sequential' object is not iterable", "user": {"login": "mrgloom", "id": 4003908, "node_id": "MDQ6VXNlcjQwMDM5MDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/4003908?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrgloom", "html_url": "https://github.com/mrgloom", "followers_url": "https://api.github.com/users/mrgloom/followers", "following_url": "https://api.github.com/users/mrgloom/following{/other_user}", "gists_url": "https://api.github.com/users/mrgloom/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrgloom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrgloom/subscriptions", "organizations_url": "https://api.github.com/users/mrgloom/orgs", "repos_url": "https://api.github.com/users/mrgloom/repos", "events_url": "https://api.github.com/users/mrgloom/events{/privacy}", "received_events_url": "https://api.github.com/users/mrgloom/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-07-03T20:41:29Z", "updated_at": "2018-01-28T00:18:24Z", "closed_at": "2017-07-05T17:32:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm using linear model on  MNIST dataset searching for optimal regularization parameters.\r\n\r\n```\r\n>>> Imports:\r\n#coding=utf-8\r\n\r\ntry:\r\n    import keras\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras import regularizers\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.models import Sequential\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from keras.layers import Dense, Dropout, Activation\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    import numpy as np\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    import pandas as pd\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from sklearn.model_selection import train_test_split\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas.distributions import uniform\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperopt import STATUS_OK\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperopt import tpe\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperopt import Trials\r\nexcept:\r\n    pass\r\n\r\ntry:\r\n    from hyperas import optim\r\nexcept:\r\n    pass\r\n\r\n>>> Hyperas search space:\r\n\r\ndef get_space():\r\n    return {\r\n        'l2': hp.uniform('l2', 0, 1),\r\n        'l2_1': hp.uniform('l2_1', 0, 1),\r\n    }\r\n\r\n>>> Data\r\n  1: \r\n  2: train_data = np.genfromtxt('MNIST/train.csv', delimiter=',', skip_header=1)\r\n  3: X= train_data[:,1:]\r\n  4: y= train_data[:,0]\r\n  5: \r\n  6: X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.20, random_state=42)\r\n  7: \r\n  8: \r\n  9: \r\n 10: \r\n>>> Resulting replaced keras model:\r\n\r\n  1: def keras_fmin_fnct(space):\r\n  2: \r\n  3: \tw=28\r\n  4: \th=28\r\n  5: \tinput_shape = (w*h,)\r\n  6: \tmodel = Sequential()\r\n  7: \r\n  8: \tmodel.add(Dense(10, init='uniform', activation='softmax',\r\n  9: \t\tkernel_regularizer=regularizers.l2(space['l2']),\r\n 10: \t\tactivity_regularizer=regularizers.l1(space['l2_1']),\r\n 11: \t\tinput_shape=input_shape))\r\n 12: \t\t\r\n 13: \tmodel.compile(loss=keras.losses.categorical_crossentropy,\r\n 14: \t\t\t\toptimizer=keras.optimizers.Adadelta(),\r\n 15: \t\t\t\tmetrics=['accuracy'])\r\n 16: \t\r\n 17: \t#print(model.summary())\r\n 18: \t\r\n 19: \treturn model\r\n 20: \r\n/home/user/deep_learning/data3/temp_model.py:83: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_regularizer=<keras.reg..., activity_regularizer=<keras.reg..., input_shape=(784,), kernel_initializer=\"uniform\")`\r\nTraceback (most recent call last):\r\n  File \"mnist_hyperas_linear.py\", line 108, in <module>\r\n    trials=Trials())\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperas/optim.py\", line 67, in minimize\r\n    verbose=verbose)\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperas/optim.py\", line 133, in base_minimizer\r\n    return_argmin=True),\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 173, in run\r\n    self.serial_evaluate()\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"/home/user/deep_learning/data3/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\", line 845, in evaluate\r\n    dict_rval = dict(rval)\r\nTypeError: 'Sequential' object is not iterable\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/107", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/107/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/107/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/107/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/107", "id": 239310511, "node_id": "MDU6SXNzdWUyMzkzMTA1MTE=", "number": 107, "title": "temp_model.py import problem", "user": {"login": "huseynlilkin", "id": 10523514, "node_id": "MDQ6VXNlcjEwNTIzNTE0", "avatar_url": "https://avatars0.githubusercontent.com/u/10523514?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huseynlilkin", "html_url": "https://github.com/huseynlilkin", "followers_url": "https://api.github.com/users/huseynlilkin/followers", "following_url": "https://api.github.com/users/huseynlilkin/following{/other_user}", "gists_url": "https://api.github.com/users/huseynlilkin/gists{/gist_id}", "starred_url": "https://api.github.com/users/huseynlilkin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huseynlilkin/subscriptions", "organizations_url": "https://api.github.com/users/huseynlilkin/orgs", "repos_url": "https://api.github.com/users/huseynlilkin/repos", "events_url": "https://api.github.com/users/huseynlilkin/events{/privacy}", "received_events_url": "https://api.github.com/users/huseynlilkin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-28T22:00:27Z", "updated_at": "2017-06-29T04:39:41Z", "closed_at": "2017-06-29T04:39:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello @maxpumperla ,\r\n\r\nThis is an awesome lib, thanks! When I try to run it a code a problem with temp_model.py. It doesn't import my functions/classses/scripts and have problem with \"as\" (when I use import `numpy as np` I got  `np is not defined` error, after deleting as np part, it worked )\r\n\r\nThanks in advance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/106", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/106/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/106/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/106/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/106", "id": 238832554, "node_id": "MDU6SXNzdWUyMzg4MzI1NTQ=", "number": 106, "title": "Unable to run example code - TypeError('require string label')", "user": {"login": "bohoro", "id": 1760441, "node_id": "MDQ6VXNlcjE3NjA0NDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1760441?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bohoro", "html_url": "https://github.com/bohoro", "followers_url": "https://api.github.com/users/bohoro/followers", "following_url": "https://api.github.com/users/bohoro/following{/other_user}", "gists_url": "https://api.github.com/users/bohoro/gists{/gist_id}", "starred_url": "https://api.github.com/users/bohoro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bohoro/subscriptions", "organizations_url": "https://api.github.com/users/bohoro/orgs", "repos_url": "https://api.github.com/users/bohoro/repos", "events_url": "https://api.github.com/users/bohoro/events{/privacy}", "received_events_url": "https://api.github.com/users/bohoro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2017-06-27T12:23:04Z", "updated_at": "2018-07-24T12:52:12Z", "closed_at": "2017-10-27T08:26:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am unable to run the first hyperas example.  Specifically this line:\r\n\r\n```\r\n>>> model.add(Dropout({{uniform(0, 1)}}))\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/brohoro/Documents/PyProjects/envs/tensorflow/lib/python2.7/site-packages/hyperopt/pyll_utils.py\", line 21, in wrapper\r\n    raise TypeError('require string label')\r\n```\r\n\r\nThe example without hyperas runs fine.\r\n\r\nHere is my env\r\n\r\nPython 2.7.13\r\nName: Keras\r\nVersion: 2.0.4\r\nName: hyperas\r\nVersion: 0.3\r\nName: hyperopt\r\nVersion: 0.1\r\n\r\nI have tried this both via Jupyter and via the python interpreter.\r\n\r\nThanks\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/105", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/105/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/105/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/105/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/105", "id": 237679355, "node_id": "MDU6SXNzdWUyMzc2NzkzNTU=", "number": 105, "title": "function cannot be pickled for mongodb", "user": {"login": "mcgibbon", "id": 12307589, "node_id": "MDQ6VXNlcjEyMzA3NTg5", "avatar_url": "https://avatars3.githubusercontent.com/u/12307589?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcgibbon", "html_url": "https://github.com/mcgibbon", "followers_url": "https://api.github.com/users/mcgibbon/followers", "following_url": "https://api.github.com/users/mcgibbon/following{/other_user}", "gists_url": "https://api.github.com/users/mcgibbon/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcgibbon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcgibbon/subscriptions", "organizations_url": "https://api.github.com/users/mcgibbon/orgs", "repos_url": "https://api.github.com/users/mcgibbon/repos", "events_url": "https://api.github.com/users/mcgibbon/events{/privacy}", "received_events_url": "https://api.github.com/users/mcgibbon/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-06-21T22:11:11Z", "updated_at": "2018-08-27T08:29:24Z", "closed_at": "2018-08-27T08:29:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "When using hyperopt.mongoexp.MongoTrials for parallelism, I am getting the same error as expressed in [this StackOverflow thread](https://stackoverflow.com/questions/41373885/hyperopt-mongotrials-issue-with-pickle-attributeerror-module-object-has-no-a). In my case, because I am using hyperas, the error says `hyperopt.mongoexp:job exception: No module named temp_model`.\r\n\r\nI believe I have made my function self-sufficient, and I have installed dill. Is there anything done to the function by hyperas that would make it temp_function impossible to pickle? Has anyone else successfully used hyperas [with mongodb](https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB)?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/103", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/103/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/103/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/103/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/103", "id": 235643975, "node_id": "MDU6SXNzdWUyMzU2NDM5NzU=", "number": 103, "title": "Error with space_eval ", "user": {"login": "caugusta", "id": 12372745, "node_id": "MDQ6VXNlcjEyMzcyNzQ1", "avatar_url": "https://avatars1.githubusercontent.com/u/12372745?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caugusta", "html_url": "https://github.com/caugusta", "followers_url": "https://api.github.com/users/caugusta/followers", "following_url": "https://api.github.com/users/caugusta/following{/other_user}", "gists_url": "https://api.github.com/users/caugusta/gists{/gist_id}", "starred_url": "https://api.github.com/users/caugusta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caugusta/subscriptions", "organizations_url": "https://api.github.com/users/caugusta/orgs", "repos_url": "https://api.github.com/users/caugusta/repos", "events_url": "https://api.github.com/users/caugusta/events{/privacy}", "received_events_url": "https://api.github.com/users/caugusta/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-06-13T18:21:56Z", "updated_at": "2017-06-16T11:47:23Z", "closed_at": "2017-06-16T11:47:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Has anyone else run into this? My model runs no problem, then chokes at the end with `space_eval`:\r\n\r\n```\r\nTrain on 5120 samples, validate on 1280 samples\r\nEpoch 1/1\r\n17s - loss: 2.0797 - acc: 0.1191 - val_loss: 2.0794 - val_acc: 0.1375\r\nFinal validation accuracy: 0.1375\r\nTrain on 5120 samples, validate on 1280 samples\r\nEpoch 1/1\r\n17s - loss: 2.0441 - acc: 0.1602 - val_loss: 1.8211 - val_acc: 0.2500\r\nFinal validation accuracy: 0.25\r\nEvalutation of best performing model:\r\n1280/1280 [==============================] - 2s     \r\n[1.8220701128244401, 0.24921874999999999]\r\nBest performing model chosen hyper-parameters:\r\n{'LSTM': 50, 'batch_size': 64}\r\nTrial 0 vals: {'LSTM': [1], 'batch_size': [0]}\r\nTraceback (most recent call last):\r\n  File \"to_stack.py\", line 87, in <module>\r\n    print(space_eval(space, vals))\r\n  File \"/.../lib/python2.7/site-packages/hyperopt/fmin.py\", line 342, in space_eval\r\n    rval = pyll.rec_eval(space, memo=memo)\r\n  File \"/.../lib/python2.7/site-packages/hyperopt/pyll/base.py\", line 870, in rec_eval\r\n    raise TypeError('switch argument was', switch_i)\r\nTypeError: ('switch argument was', [0])\r\n\r\n```\r\nFor reproducibility, I am working on Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-111-generic x86_64) with Python 2.7. I have downloaded the latest versions of keras (2.0.5) and hyperas (0.3) \r\n\r\nMy full code is below (I may import some things I don't need with this MWE). I can provide `train_pl.csv` if necessary, but for now suffice to say the final shapes of `x_train` and `x_test` returned in `data` are `(5120, 153, 1)` and `(1280, 153, 1)`, respectively, and each row of `train_pl.csv` is integer-valued.\r\n\r\n```\r\nfrom __future__ import print_function\r\nfrom hyperopt import Trials, STATUS_OK, tpe, space_eval\r\nimport keras.optimizers\r\nfrom keras.layers.core import Dense, Dropout, Activation\r\nfrom keras.layers import LSTM\r\nfrom keras.models import Sequential\r\nfrom keras.utils import np_utils\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nfrom hyperas import optim\r\nfrom hyperas.distributions import choice, uniform\r\nimport numpy\r\n\r\ndef data():\r\n    train_file='train_pl.csv'\r\n    trainset = numpy.loadtxt(train_file, delimiter=\",\")\r\n\r\n    X = trainset[:, 0:(trainset.shape[1]-2)]\r\n    Y = (trainset[:,trainset.shape[1]-1]).astype(int)\r\n\r\n    scaler = MinMaxScaler(feature_range=(0, 1))\r\n    X_scaled = scaler.fit_transform(X)\r\n\r\n    y_binary = np_utils.to_categorical(Y)\r\n\r\n    num_per_class = int(float(X.shape[0])/(float(y_binary.shape[1])))\r\n\r\n    to_take = numpy.random.choice(num_per_class, int(num_per_class*0.2), replace=False)\r\n    class_split = numpy.array_split(X_scaled, y_binary.shape[1])\r\n    val_list = [x[to_take] for x in class_split]\r\n    big_list = [item for sublist in val_list for item in sublist]\r\n    val_X = numpy.asarray(big_list)\r\n    label_set = numpy.arange(0, y_binary.shape[1])\r\n    val_Y = numpy.repeat(label_set, int(num_per_class*0.2))\r\n    val_Y = np_utils.to_categorical(val_Y)\r\n\r\n    setdiffval = set(range(num_per_class)) - set(to_take)\r\n    setdiffval = list(setdiffval)\r\n\r\n    X_train_vals = [x[setdiffval] for x in class_split]\r\n    X_train = [item for sublist in X_train_vals for item in sublist]\r\n    X_train = numpy.asarray(X_train)\r\n    Y_train = numpy.repeat(label_set, int(num_per_class*0.8))\r\n    Y_train = np_utils.to_categorical(Y_train)\r\n\r\n    x_train = X_train\r\n    x_test = val_X\r\n    y_train = Y_train\r\n    y_test = val_Y\r\n    x_train = numpy.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\r\n    x_test = numpy.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\r\n\r\n    return (x_train, y_train, x_test, y_test)\r\n\r\ndef model(x_train, y_train, x_test, y_test):\r\n    model = Sequential()\r\n    model.add(LSTM({{choice([10, 20, 50, 100])}}, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=False))\r\n    model.add(Activation('relu'))\r\n    model.add(Dense(8))\r\n    model.add(Activation('softmax'))\r\n\r\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\r\n                  optimizer='adam')\r\n\r\n    model.fit(x_train, y_train,\r\n              batch_size={{choice([64, 128])}}, epochs=1,verbose=2,validation_data=(x_test, y_test))\r\n    score, acc = model.evaluate(x_test, y_test, verbose=0)\r\n    print('Final validation accuracy:', acc)\r\n\r\n    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\r\n\r\n\r\nif __name__ == '__main__':\r\n    trials=Trials()\r\n    best_run, best_model, space = optim.minimize(model=model, data=data,algo=tpe.suggest,max_evals=2,trials=trials, eval_space=True, return_space=True)\r\n    X_train, Y_train, X_test, Y_test = data()\r\n    print(\"Evalutation of best performing model:\")\r\n    print(best_model.evaluate(X_test, Y_test))\r\n    print(\"Best performing model chosen hyper-parameters:\")\r\n    print(best_run)\r\n    for t, trial in enumerate(trials):\r\n        vals = trial.get('misc').get('vals')\r\n        print(\"Trial %s vals: %s\" % (t, vals))\r\n        print(space_eval(space, vals))](url)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/100", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/100/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/100/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/100/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/100", "id": 234759327, "node_id": "MDU6SXNzdWUyMzQ3NTkzMjc=", "number": 100, "title": "How can I set an optimizer along with a learning rate?", "user": {"login": "byshichen", "id": 19653665, "node_id": "MDQ6VXNlcjE5NjUzNjY1", "avatar_url": "https://avatars2.githubusercontent.com/u/19653665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byshichen", "html_url": "https://github.com/byshichen", "followers_url": "https://api.github.com/users/byshichen/followers", "following_url": "https://api.github.com/users/byshichen/following{/other_user}", "gists_url": "https://api.github.com/users/byshichen/gists{/gist_id}", "starred_url": "https://api.github.com/users/byshichen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byshichen/subscriptions", "organizations_url": "https://api.github.com/users/byshichen/orgs", "repos_url": "https://api.github.com/users/byshichen/repos", "events_url": "https://api.github.com/users/byshichen/events{/privacy}", "received_events_url": "https://api.github.com/users/byshichen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-09T08:40:03Z", "updated_at": "2017-06-11T12:49:09Z", "closed_at": "2017-06-11T12:49:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "just like this -> optimizers.RMSprop(lr = 1e-3, epsilon=1e-6)\r\n\r\nCheers", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/96", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/96/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/96/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/96/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/96", "id": 233921790, "node_id": "MDU6SXNzdWUyMzM5MjE3OTA=", "number": 96, "title": "Imports within the model function result in error", "user": {"login": "pkainz", "id": 6303720, "node_id": "MDQ6VXNlcjYzMDM3MjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/6303720?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pkainz", "html_url": "https://github.com/pkainz", "followers_url": "https://api.github.com/users/pkainz/followers", "following_url": "https://api.github.com/users/pkainz/following{/other_user}", "gists_url": "https://api.github.com/users/pkainz/gists{/gist_id}", "starred_url": "https://api.github.com/users/pkainz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pkainz/subscriptions", "organizations_url": "https://api.github.com/users/pkainz/orgs", "repos_url": "https://api.github.com/users/pkainz/repos", "events_url": "https://api.github.com/users/pkainz/events{/privacy}", "received_events_url": "https://api.github.com/users/pkainz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-06-06T15:00:40Z", "updated_at": "2017-06-11T13:33:19Z", "closed_at": "2017-06-11T13:33:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "If a comment `#` is present in any line before the import statement in the model function, the `remove_imports` function removes the wrong lines and occasionally causes an `IndentationError`. \r\n\r\nThis is caused by skipping the commented lines, but counting them in the `ImportParser`. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/93", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/93/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/93/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/93/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/93", "id": 232763354, "node_id": "MDU6SXNzdWUyMzI3NjMzNTQ=", "number": 93, "title": "Getting an error with a relatively complex use case ( flow in data generator) in the evaluate call", "user": {"login": "pchowdhry", "id": 2396874, "node_id": "MDQ6VXNlcjIzOTY4NzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2396874?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pchowdhry", "html_url": "https://github.com/pchowdhry", "followers_url": "https://api.github.com/users/pchowdhry/followers", "following_url": "https://api.github.com/users/pchowdhry/following{/other_user}", "gists_url": "https://api.github.com/users/pchowdhry/gists{/gist_id}", "starred_url": "https://api.github.com/users/pchowdhry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pchowdhry/subscriptions", "organizations_url": "https://api.github.com/users/pchowdhry/orgs", "repos_url": "https://api.github.com/users/pchowdhry/repos", "events_url": "https://api.github.com/users/pchowdhry/events{/privacy}", "received_events_url": "https://api.github.com/users/pchowdhry/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-01T04:32:28Z", "updated_at": "2017-06-08T22:11:44Z", "closed_at": "2017-06-08T22:11:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi Guys, I'm trying use hyperas on a project the leverages Keras' data augmentation and 'model.fit_generator'. I'm basically trying to pass in a fully built instance of datagen.flow, into hyperas. I've run the model individually and everything is working, however when I wrap in hyperas I get the error `temp_model.py\", line 120, in keras_fmin_fnct\r\nTypeError: evaluate() takes at least 3 arguments (2 given)`\r\n\r\nHere is my code, i've looked at the CNN example which used the datagen functionality, but looks like it is still using the standard numpy arrays. Thanks in advance.\r\n\r\n\r\n```\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Conv2D, MaxPooling2D\r\nfrom keras.layers import Activation, Dropout, Flatten, Dense\r\nfrom keras.callbacks import ModelCheckpoint\r\nfrom keras import backend as K\r\nfrom hyperas import optim\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom hyperas.distributions import choice, uniform, conditional\r\nimport h5py\r\n\r\ndef model(train_generator, validation_generator):\r\n    img_width, img_height = 250, 1500\r\n    input_shape = (img_width, img_height, 3)\r\n    nb_train_samples = 2000\r\n    nb_validation_samples = 800\r\n\r\n    epochs = 2\r\n    batch_size = 256\r\n    model = Sequential()\r\n    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\r\n    model.add(Activation('relu'))\r\n    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n\r\n    model.add(Conv2D(32, (3, 3)))\r\n    model.add(Activation('relu'))\r\n    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n\r\n    model.add(Conv2D({{choice([32,64,128])}}, (3, 3)))\r\n    model.add(Activation('relu'))\r\n    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n\r\n    model.add(Flatten())\r\n    model.add(Dense(64))\r\n    model.add(Activation('relu'))\r\n    model.add(Dropout(0.5))\r\n    model.add(Dense(5))\r\n    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n    model.compile(loss={{choice(['categorical_crossentropy', 'binary_crossentropy'])}},\r\n                  optimizer='adam',\r\n                  metrics=['accuracy'])\r\n\r\n    model.fit_generator(\r\n        train_generator,\r\n        steps_per_epoch=nb_train_samples // batch_size,\r\n        epochs=epochs,\r\n        validation_data=validation_generator,\r\n        validation_steps=nb_validation_samples // batch_size)\r\n\r\n    score, acc = model.evaluate(validation_generator)\r\n\r\n    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\r\n\r\ndef data():\r\n    img_width, img_height = 250, 1500\r\n    batch_size = 32\r\n    train_data_dir = 'column_data/train'\r\n    validation_data_dir = 'column_data/validation'\r\n\r\n    test_datagen = ImageDataGenerator(\r\n        rescale=None)\r\n\r\n    train_datagen = ImageDataGenerator(\r\n        rescale=None,\r\n        shear_range=0.2,\r\n        horizontal_flip=False)\r\n\r\n    train_generator = train_datagen.flow_from_directory(\r\n        train_data_dir,\r\n        target_size=(img_width, img_height),\r\n        batch_size=batch_size,\r\n        class_mode='categorical')\r\n\r\n    validation_generator = test_datagen.flow_from_directory(\r\n        validation_data_dir,\r\n        target_size=(img_width, img_height),\r\n        batch_size=batch_size,\r\n        class_mode='categorical')\r\n\r\n    return train_generator, validation_generator\r\n\r\nif __name__ == '__main__':\r\n\r\n    train_generator, validation_generator = data()\r\n\r\n    best_run, best_model = optim.minimize(model=model,\r\n                                          data=data,\r\n                                          algo=tpe.suggest,\r\n                                          max_evals=5,\r\n                                          trials=Trials())\r\n\r\n    print(\"Evaluation of best performing model:\")\r\n\r\n    print(best_model.evaluate(validation_generator))\r\n\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/90", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/90/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/90/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/90/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/90", "id": 231883400, "node_id": "MDU6SXNzdWUyMzE4ODM0MDA=", "number": 90, "title": "monitor memory", "user": {"login": "benjaminderei", "id": 12964028, "node_id": "MDQ6VXNlcjEyOTY0MDI4", "avatar_url": "https://avatars2.githubusercontent.com/u/12964028?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benjaminderei", "html_url": "https://github.com/benjaminderei", "followers_url": "https://api.github.com/users/benjaminderei/followers", "following_url": "https://api.github.com/users/benjaminderei/following{/other_user}", "gists_url": "https://api.github.com/users/benjaminderei/gists{/gist_id}", "starred_url": "https://api.github.com/users/benjaminderei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benjaminderei/subscriptions", "organizations_url": "https://api.github.com/users/benjaminderei/orgs", "repos_url": "https://api.github.com/users/benjaminderei/repos", "events_url": "https://api.github.com/users/benjaminderei/events{/privacy}", "received_events_url": "https://api.github.com/users/benjaminderei/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-28T17:48:38Z", "updated_at": "2017-06-11T13:53:21Z", "closed_at": "2017-06-11T13:53:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "Anyway to monitor the central memory and gpu memory and kill the model if it exceed certain values ?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/89", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/89/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/89/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/89/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/89", "id": 230881749, "node_id": "MDU6SXNzdWUyMzA4ODE3NDk=", "number": 89, "title": "Complete example in readme: TypeError 'module' object is not callable", "user": {"login": "caugusta", "id": 12372745, "node_id": "MDQ6VXNlcjEyMzcyNzQ1", "avatar_url": "https://avatars1.githubusercontent.com/u/12372745?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caugusta", "html_url": "https://github.com/caugusta", "followers_url": "https://api.github.com/users/caugusta/followers", "following_url": "https://api.github.com/users/caugusta/following{/other_user}", "gists_url": "https://api.github.com/users/caugusta/gists{/gist_id}", "starred_url": "https://api.github.com/users/caugusta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caugusta/subscriptions", "organizations_url": "https://api.github.com/users/caugusta/orgs", "repos_url": "https://api.github.com/users/caugusta/repos", "events_url": "https://api.github.com/users/caugusta/events{/privacy}", "received_events_url": "https://api.github.com/users/caugusta/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-23T23:53:45Z", "updated_at": "2017-06-11T13:03:20Z", "closed_at": "2017-06-11T13:03:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to run the complete example from the main page (the readme, [here](https://github.com/maxpumperla/hyperas)), and I'm getting an error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"hyperas_2.py\", line 74, in <module>\r\n    trials=t1)\r\n  File \"/user/pkgs/anaconda2/lib/python2.7/site-packages/hyperas/optim.py\", line 32, in minimize\r\n    best_run = base_minimizer(model, data, algo, max_evals, trials, rseed)\r\n  File \"/user/pkgs/anaconda2/lib/python2.7/site-packages/hyperas/optim.py\", line 120, in base_minimizer\r\n    rstate=np.random.RandomState(rseed))\r\n  File \"/user/pkgs/anaconda2/lib/python2.7/site-packages/hyperopt-0.0.4-py2.7.egg/hyperopt/fmin.py\", line 306, in fmin\r\n  File \"/user/pkgs/anaconda2/lib/python2.7/site-packages/hyperopt-0.0.4-py2.7.egg/hyperopt/base.py\", line 633, in fmin\r\nTypeError: 'module' object is not callable\r\n```\r\n\r\nI wonder if hyperopt is not playing nicely with fmin? There doesn't seem to be a problem with Trials() on its own, because I can call `t1 = Trials()` in `__main__` no problem.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/87", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/87/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/87/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/87/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/87", "id": 227855783, "node_id": "MDU6SXNzdWUyMjc4NTU3ODM=", "number": 87, "title": "NameError : name XXX(function name) is not defined", "user": {"login": "QijinYin", "id": 17307388, "node_id": "MDQ6VXNlcjE3MzA3Mzg4", "avatar_url": "https://avatars3.githubusercontent.com/u/17307388?v=4", "gravatar_id": "", "url": "https://api.github.com/users/QijinYin", "html_url": "https://github.com/QijinYin", "followers_url": "https://api.github.com/users/QijinYin/followers", "following_url": "https://api.github.com/users/QijinYin/following{/other_user}", "gists_url": "https://api.github.com/users/QijinYin/gists{/gist_id}", "starred_url": "https://api.github.com/users/QijinYin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/QijinYin/subscriptions", "organizations_url": "https://api.github.com/users/QijinYin/orgs", "repos_url": "https://api.github.com/users/QijinYin/repos", "events_url": "https://api.github.com/users/QijinYin/events{/privacy}", "received_events_url": "https://api.github.com/users/QijinYin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-11T01:41:49Z", "updated_at": "2017-06-11T12:50:31Z", "closed_at": "2017-06-11T12:50:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I use a function in data() function, it raises this wrong.\r\n\r\njust like this:\r\ndef read_train_data():\r\n   ....\r\n\r\ndef data():\r\n   train_data = read_train_data()\r\n   ...\r\n\r\nThe error message are below:\r\nUnexpected error: <type 'exceptions.NameError'>\r\nTraceback (most recent call last):\r\n  File \"31_hyper_tune.py\", line 295, in <module>\r\n    trials=Trials())\r\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/hyperas-0.3-py2.7.egg/hyperas/optim.py\", line 43, in minimize\r\n    notebook_name=notebook_name, verbose=verbose)\r\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/hyperas-0.3-py2.7.egg/hyperas/optim.py\", line 68, in base_minimizer\r\n    from temp_model import keras_fmin_fnct, get_space\r\n  File \"/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/temp_model.py\", line 135, in <module>\r\n    DData_train_ehr,DData_train_pro,DData_train_label = read_train_data(DData_train_dir)\r\nNameError: name 'read_train_data' is not defined\r\n\r\nWhat's wrong ?\r\n\r\nThanks\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/86", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/86/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/86/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/86/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/86", "id": 227596682, "node_id": "MDU6SXNzdWUyMjc1OTY2ODI=", "number": 86, "title": "./example/complex.py doesn't work", "user": {"login": "QijinYin", "id": 17307388, "node_id": "MDQ6VXNlcjE3MzA3Mzg4", "avatar_url": "https://avatars3.githubusercontent.com/u/17307388?v=4", "gravatar_id": "", "url": "https://api.github.com/users/QijinYin", "html_url": "https://github.com/QijinYin", "followers_url": "https://api.github.com/users/QijinYin/followers", "following_url": "https://api.github.com/users/QijinYin/following{/other_user}", "gists_url": "https://api.github.com/users/QijinYin/gists{/gist_id}", "starred_url": "https://api.github.com/users/QijinYin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/QijinYin/subscriptions", "organizations_url": "https://api.github.com/users/QijinYin/orgs", "repos_url": "https://api.github.com/users/QijinYin/repos", "events_url": "https://api.github.com/users/QijinYin/events{/privacy}", "received_events_url": "https://api.github.com/users/QijinYin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-10T08:00:47Z", "updated_at": "2017-06-11T13:04:20Z", "closed_at": "2017-06-11T13:04:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "when I try to run the complex.py ,there are problems as below:\r\n\r\n  File \"<unknown>\", line 36\r\n    if conditional({{choice(['three', 'four'])}}) == 'four':\r\n    ^\r\nIndentationError: unexpected indent\r\n\r\nWhat lead to this issue?\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/85", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/85/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/85/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/85/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/85", "id": 226053640, "node_id": "MDU6SXNzdWUyMjYwNTM2NDA=", "number": 85, "title": "TypeError: sequence item 1: expected string, NoneType found", "user": {"login": "lgsaber", "id": 7436364, "node_id": "MDQ6VXNlcjc0MzYzNjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/7436364?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lgsaber", "html_url": "https://github.com/lgsaber", "followers_url": "https://api.github.com/users/lgsaber/followers", "following_url": "https://api.github.com/users/lgsaber/following{/other_user}", "gists_url": "https://api.github.com/users/lgsaber/gists{/gist_id}", "starred_url": "https://api.github.com/users/lgsaber/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lgsaber/subscriptions", "organizations_url": "https://api.github.com/users/lgsaber/orgs", "repos_url": "https://api.github.com/users/lgsaber/repos", "events_url": "https://api.github.com/users/lgsaber/events{/privacy}", "received_events_url": "https://api.github.com/users/lgsaber/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-05-03T17:08:11Z", "updated_at": "2017-05-21T18:55:13Z", "closed_at": "2017-05-21T18:55:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I run into this error after pip install --upgrade to the newest master version of hyperas when running the code below:\r\n```\r\nfrom __future__ import print_function\r\nimport theano\r\nimport numpy as np,sys,h5py,cPickle,argparse,subprocess\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom hyperas import optim\r\nfrom os import system\r\nfrom os import makedirs\r\nfrom os.path import join,dirname,basename,exists\r\nfrom keras.models import model_from_json\r\n...\r\nMAX_EVAL = 30\r\nbest_run, best_model = optim.minimize(model=mymodel.model,data=mymodel.data,algo=tpe.suggest,max_evals=MAX_EVAL,trials=Trials())\r\n```\r\nComplete error message:\r\n``` \r\n File \"main.py\", line 56, in <module>\r\n    best_run, best_model = optim.minimize(model=mymodel.model,data=mymodel.data,algo=tpe.suggest,max_evals=MAX_EVAL,trials=Trials())\r\nFile \"/cluster/geliu/miniconda2/lib/python2.7/site-packages/hyperas/optim.py\", line 43, in minimize\r\n    notebook_name=notebook_name, verbose=verbose)\r\n  File \"/cluster/geliu/miniconda2/lib/python2.7/site-packages/hyperas/optim.py\", line 63, in base_minimizer\r\n    model_str = get_hyperopt_model_string(model, data,functions,notebook_name, verbose, stack)\r\n  File \"/cluster/geliu/miniconda2/lib/python2.7/site-packages/hyperas/optim.py\", line 130, in get_hyperopt_model_string\r\n    imports = extract_imports(cleaned_source, verbose)\r\n  File \"/cluster/geliu/miniconda2/lib/python2.7/site-packages/hyperas/utils.py\", line 44, in extract_imports\r\n    import_parser.visit(tree)\r\n  File \"/cluster/geliu/miniconda2/lib/python2.7/ast.py\", line 241, in visit\r\n    return visitor(node)\r\n  File \"/cluster/geliu/miniconda2/lib/python2.7/ast.py\", line 249, in generic_visit\r\n    self.visit(item)\r\n  File \"/cluster/geliu/miniconda2/lib/python2.7/ast.py\", line 241, in visit\r\n    return visitor(node)\r\n  File \"/cluster/geliu/miniconda2/lib/python2.7/site-packages/hyperas/utils.py\", line 14, in visit_Import\r\n    if (self._import_asnames(node.names)!=''):\r\n  File \"/cluster/geliu/miniconda2/lib/python2.7/site-packages/hyperas/utils.py\", line 36, in _import_asnames\r\n    return ''.join(asname)\r\nTypeError: sequence item 1: expected string, NoneType found\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/83", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/83/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/83/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/83/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/83", "id": 225821016, "node_id": "MDU6SXNzdWUyMjU4MjEwMTY=", "number": 83, "title": "\"No such file or directory\" when creating Jupyter notebook from scratch", "user": {"login": "ProgramItUp", "id": 12467188, "node_id": "MDQ6VXNlcjEyNDY3MTg4", "avatar_url": "https://avatars3.githubusercontent.com/u/12467188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ProgramItUp", "html_url": "https://github.com/ProgramItUp", "followers_url": "https://api.github.com/users/ProgramItUp/followers", "following_url": "https://api.github.com/users/ProgramItUp/following{/other_user}", "gists_url": "https://api.github.com/users/ProgramItUp/gists{/gist_id}", "starred_url": "https://api.github.com/users/ProgramItUp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ProgramItUp/subscriptions", "organizations_url": "https://api.github.com/users/ProgramItUp/orgs", "repos_url": "https://api.github.com/users/ProgramItUp/repos", "events_url": "https://api.github.com/users/ProgramItUp/events{/privacy}", "received_events_url": "https://api.github.com/users/ProgramItUp/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-05-02T21:04:29Z", "updated_at": "2020-05-19T07:37:06Z", "closed_at": "2017-06-11T13:04:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\nI'm running into a problem with a notebook I've created from scratch in Jupyter that I'm not getting with a with the included example [hyperas/examples/simple_notebook.ipynb](https://github.com/maxpumperla/hyperas/blob/master/examples/simple_notebook.ipynb).  \r\n\r\nIt appears that hyperas is looking for a temperary file that does not exist.\r\n\r\nAny thoughts about what is going wrong?\r\n\r\nSteps to recreate the error:\r\n1) Create new Jupyter notebook\r\n2) Copy the sample code from the hyperas [README](https://github.com/maxpumperla/hyperas/blob/master/README.md) and pasted it into the notebook created in 1)\r\n3) Selected \"Cell->Run All\"\r\n4) Error is thrown:  See below\r\n5) Selected \"Kernel -> Restart and Run All\"\r\n6) Error is thrown: same as 4)\r\n7) \"File -> Save and Checkpoint\", \"Kernel -> Restart and Run All\"\r\n8) Error is thrown: same as 4) and 6)\r\n\r\n```\r\nUsing TensorFlow backend.\r\n/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\r\n/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\r\n/usr/local/lib/python2.7/dist-packages/hyperas/optim.py\r\n<ipython-input-1-43ea71f3309d>\r\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\r\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\r\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\r\n/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\r\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\r\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\r\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\r\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\r\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\r\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\r\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\r\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\r\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\r\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\r\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\r\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\r\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\r\n/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\r\n/usr/lib/python2.7/runpy.py\r\n/usr/lib/python2.7/runpy.py\r\n---------------------------------------------------------------------------\r\nIOError                                   Traceback (most recent call last)\r\n<ipython-input-1-43ea71f3309d> in <module>()\r\n     80                                           algo=tpe.suggest,\r\n     81                                           max_evals=5,\r\n---> 82                                           trials=Trials())\r\n     83     X_train, Y_train, X_test, Y_test = data()\r\n     84     print(\"Evalutation of best performing model:\")\r\n\r\n/usr/local/lib/python2.7/dist-packages/hyperas/optim.pyc in minimize(model, data, algo, max_evals, trials, rseed, notebook_name, verbose)\r\n     40     best_run = base_minimizer(model=model, data=data, algo=algo, max_evals=max_evals,\r\n     41                               trials=trials, rseed=rseed, full_model_string=None,\r\n---> 42                               notebook_name=notebook_name, verbose=verbose)\r\n     43 \r\n     44     best_model = None\r\n\r\n/usr/local/lib/python2.7/dist-packages/hyperas/optim.pyc in base_minimizer(model, data, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\r\n     60         model_str = full_model_string\r\n     61     else:\r\n---> 62         model_str = get_hyperopt_model_string(model, data, notebook_name, verbose, stack)\r\n     63     temp_file = './temp_model.py'\r\n     64     write_temp_files(model_str, temp_file)\r\n\r\n/usr/local/lib/python2.7/dist-packages/hyperas/optim.pyc in get_hyperopt_model_string(model, data, notebook_name, verbose, stack)\r\n    126             print(i[1])\r\n    127         calling_script_file = os.path.abspath(inspect.stack()[stack][1])\r\n--> 128         with open(calling_script_file, 'r') as f:\r\n    129             source = f.read()\r\n    130 \r\n\r\nIOError: [Errno 2] No such file or directory: '/work/models/regression/Keras-Nonlinear-Regression/<ipython-input-1-43ea71f3309d>'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/82", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/82/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/82/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/82/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/82", "id": 225340500, "node_id": "MDU6SXNzdWUyMjUzNDA1MDA=", "number": 82, "title": "TypeError: fmin() got an unexpected keyword argument 'rseed'", "user": {"login": "jonhilgart22", "id": 8621935, "node_id": "MDQ6VXNlcjg2MjE5MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8621935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonhilgart22", "html_url": "https://github.com/jonhilgart22", "followers_url": "https://api.github.com/users/jonhilgart22/followers", "following_url": "https://api.github.com/users/jonhilgart22/following{/other_user}", "gists_url": "https://api.github.com/users/jonhilgart22/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonhilgart22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonhilgart22/subscriptions", "organizations_url": "https://api.github.com/users/jonhilgart22/orgs", "repos_url": "https://api.github.com/users/jonhilgart22/repos", "events_url": "https://api.github.com/users/jonhilgart22/events{/privacy}", "received_events_url": "https://api.github.com/users/jonhilgart22/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-04-30T17:13:40Z", "updated_at": "2017-06-10T22:50:55Z", "closed_at": "2017-04-30T19:16:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there,\r\n\r\nWhen trying to run this code, I receive the following error.\r\n\r\nfrom __future__ import print_function\r\n\r\nfrom hyperopt import Trials, STATUS_OK, tpe\r\nfrom keras.datasets import mnist\r\nfrom keras.layers.core import Dense, Dropout, Activation\r\nfrom keras.models import Sequential\r\nfrom keras.utils import np_utils\r\nimport numpy as np\r\nfrom hyperas import optim\r\nfrom keras.models import model_from_json\r\nfrom keras.models import Sequential\r\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\r\nfrom keras.layers import LSTM\r\nfrom keras.optimizers import SGD , Adam\r\nimport tensorflow as tf\r\nimport keras.backend as K\r\nfrom hyperas.distributions import choice, uniform, conditional\r\nfrom keras.layers.normalization import BatchNormalization\r\n__author__ = 'JOnathan Hilgart'\r\n\r\n\r\ndef data():\r\n    \"\"\"\r\n    Data providing function:\r\n\r\n    This function is separated from model() so that hyperopt\r\n    won't reload data for each evaluation run.\r\n    \"\"\"\r\n    import numpy as np\r\n    x = np.load('training_x')\r\n    x = x.reshape(1,50001,2)\r\n    y = np.load('training_y')\r\n    y = y.reshape(1,50001, 9)\r\n    x_train = x[:, :25000,:]\r\n    y_train = y[:, :25000,:]\r\n    x_test = x[:, 25001:,:]\r\n    y_test = y[:, 25001:,:]\r\n    return x_train, y_train, x_test, y_test\r\n\r\n\r\ndef model(x_train, y_train, x_test, y_test):\r\n    \"\"\"\r\n    Model providing function:\r\n\r\n    Create Keras model with double curly brackets dropped-in as needed.\r\n    Return value has to be a valid python dictionary with two customary keys:\r\n        - loss: Specify a numeric evaluation metric to be minimized\r\n        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\r\n    The last one is optional, though recommended, namely:\r\n        - model: specify the model just created so that we can later use it again.\r\n    \"\"\"\r\n    model_lstm = Sequential()\r\n    model_lstm .add(LSTM({{choice([64, 126, 256, 512, 1024])}}, dropout={{uniform(0, .5)}},\r\n                         batch_input_shape=(1,x_train.shape[1], 2),\r\n                     recurrent_dropout={{uniform(0, .5)}},return_sequences = True))\r\n    model_lstm.add(BatchNormalization())\r\n\r\n    if conditional({{choice(['one','two','three', 'four'])}}) == 'one':\r\n        pass\r\n    elif conditional({{choice(['one','two','three', 'four'])}}) == 'two':\r\n        model_lstm .add(LSTM({{choice([64, 126, 256, 512, 1024])}}, dropout={{uniform(0, .5)}},\r\n                     recurrent_dropout={{uniform(0, .5)}},\r\n                     return_sequences = True))\r\n        model_lstm.add(BatchNormalization())\r\n    elif conditional({{choice(['one','two','three', 'four'])}}) == 'three':\r\n        model_lstm .add(LSTM({{choice([64, 126, 256, 512, 1024])}}, dropout={{uniform(0, .5)}},\r\n                     recurrent_dropout={{uniform(0, .5)}},\r\n                     return_sequences = True))\r\n        model_lstm.add(BatchNormalization())\r\n        model_lstm.add(Dense({{choice([126, 256, 512, 1024])}},\r\n                             name='dense_one'))\r\n        model_lstm.add(BatchNormalization())\r\n        model_lstm.add(Activation('relu'))\r\n    elif conditional({{choice(['one','two','three', 'four'])}}) == 'four':\r\n        model_lstm .add(LSTM({{choice([64, 126, 256, 512, 1024])}}, dropout={{uniform(0, .5)}},\r\n                     recurrent_dropout={{uniform(0, .5)}},\r\n                     return_sequences = True))\r\n        model_lstm.add(BatchNormalization())\r\n        model_lstm.add(Dense({{choice([126, 256, 512, 1024])}},\r\n                             name='dense_one'))\r\n        model_lstm.add(BatchNormalization())\r\n        model_lstm.add(Activation('relu'))\r\n        model_lstm.add(Dense({{choice([126, 256, 512, 1024])}}, activation='relu',\r\n                             name='dense_one'))\r\n        model_lstm.add(BatchNormalization())\r\n        model_lstm.add(Activation('relu'))\r\n\r\n\r\n    model_lstm .add(Dense(9, activation='linear',name='dense_output'))\r\n    model_lstm .compile(loss='mean_squared_error', optimizer={{choice(['adam','sgd'])}})\r\n    model_lstm.summary()\r\n\r\n\r\n\r\n    model_lstm.fit(x_train, y_train,\r\n              batch_size=1,\r\n              epochs=1,\r\n              verbose=1,\r\n              validation_data=(x_test, y_test))\r\n    score, acc = model_lstm.evaluate(x_test, y_test, verbose=0)\r\n    print('Test accuracy:', acc)\r\n    return {'loss': -acc, 'status': STATUS_OK, 'model': model_mlp}\r\n\r\n\r\nif __name__ == '__main__':\r\n    import gc; gc.collect()\r\n\r\n    best_run, best_model = optim.minimize(model=model,\r\n                                          data=data,\r\n                                          algo=tpe.suggest,\r\n                                          max_evals=1,\r\n                                          trials=Trials())\r\n    X_train, Y_train, X_test, Y_test = data()\r\n    print(\"Evalutation of best performing model:\")\r\n    print(best_model.evaluate(X_test, Y_test))\r\n    print(\"Best performing model chosen hyper-parameters:\")\r\n    print(best_run)\r\n\r\n---------------------------\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperas/optim.py\", line 83, in base_minimizer\r\n    rseed=rseed)\r\nTypeError: fmin() got an unexpected keyword argument 'rseed'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"hyperparameter_optimization_lstm.py\", line 112, in <module>\r\n    trials=Trials())\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperas/optim.py\", line 42, in minimize\r\n    notebook_name=notebook_name, verbose=verbose)\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperas/optim.py\", line 90, in base_minimizer\r\n    rstate=np.random.RandomState(rseed))\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperopt/fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperopt/fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperopt/fmin.py\", line 173, in run\r\n    self.serial_evaluate()\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\r\n    result = self.domain.evaluate(spec, ctrl)\r\n  File \"/Users/jonathanhilgart/anaconda/envs/dl/lib/python3.6/site-packages/hyperopt/base.py\", line 840, in evaluate\r\n    rval = self.fn(pyll_rval)\r\n  File \"/Users/jonathanhilgart/galvanize-projects/deep_learning/src/models-DQN/temp_model.py\", line 172, in keras_fmin_fnct\r\nTypeError: 'numpy.float64' object is not iterable\r\n\r\n\r\n-----------------------------\r\n\r\nI've installed hyperas from pip and from git with no luck.\r\n\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/80", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/80/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/80/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/80/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/80", "id": 225295242, "node_id": "MDU6SXNzdWUyMjUyOTUyNDI=", "number": 80, "title": "How does it handle choices which are dimensionwise impossible?", "user": {"login": "Miail", "id": 24832675, "node_id": "MDQ6VXNlcjI0ODMyNjc1", "avatar_url": "https://avatars3.githubusercontent.com/u/24832675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Miail", "html_url": "https://github.com/Miail", "followers_url": "https://api.github.com/users/Miail/followers", "following_url": "https://api.github.com/users/Miail/following{/other_user}", "gists_url": "https://api.github.com/users/Miail/gists{/gist_id}", "starred_url": "https://api.github.com/users/Miail/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Miail/subscriptions", "organizations_url": "https://api.github.com/users/Miail/orgs", "repos_url": "https://api.github.com/users/Miail/repos", "events_url": "https://api.github.com/users/Miail/events{/privacy}", "received_events_url": "https://api.github.com/users/Miail/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-04-30T00:41:50Z", "updated_at": "2017-05-03T08:56:52Z", "closed_at": "2017-05-03T08:56:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am currently trying to optimise CNN, some of the parameter combination can result in dimension wise imposibility... how does this handle this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/79", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/79/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/79/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/79/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/79", "id": 222712838, "node_id": "MDU6SXNzdWUyMjI3MTI4Mzg=", "number": 79, "title": "TypeError: ap_uniform_sampler() takes at least 4 arguments (5 given)", "user": {"login": "ben0it8", "id": 11842615, "node_id": "MDQ6VXNlcjExODQyNjE1", "avatar_url": "https://avatars1.githubusercontent.com/u/11842615?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ben0it8", "html_url": "https://github.com/ben0it8", "followers_url": "https://api.github.com/users/ben0it8/followers", "following_url": "https://api.github.com/users/ben0it8/following{/other_user}", "gists_url": "https://api.github.com/users/ben0it8/gists{/gist_id}", "starred_url": "https://api.github.com/users/ben0it8/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ben0it8/subscriptions", "organizations_url": "https://api.github.com/users/ben0it8/orgs", "repos_url": "https://api.github.com/users/ben0it8/repos", "events_url": "https://api.github.com/users/ben0it8/events{/privacy}", "received_events_url": "https://api.github.com/users/ben0it8/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-19T11:55:04Z", "updated_at": "2017-06-11T13:22:51Z", "closed_at": "2017-06-11T13:22:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "hello, I have the above error when calling optim.minimize() with the exact same arguments as in the examples.\r\n\r\nfull traceback:\r\n\r\nTraceback (most recent call last):\r\n  File \"Untitled.py\", line 162, in <module>\r\n    trials=Trials())\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperas/optim.py\", line 42, in minimize\r\n    notebook_name=notebook_name, verbose=verbose)\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperas/optim.py\", line 92, in base_minimizer\r\n    rstate=np.random.RandomState(rseed))\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperopt/fmin.py\", line 307, in fmin\r\n    return_argmin=return_argmin,\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperopt/base.py\", line 635, in fmin\r\n    return_argmin=return_argmin)\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperopt/fmin.py\", line 320, in fmin\r\n    rval.exhaust()\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperopt/fmin.py\", line 199, in exhaust\r\n    self.run(self.max_evals - n_done, block_until_done=self.async)\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperopt/fmin.py\", line 157, in run\r\n    self.rstate.randint(2 ** 31 - 1))\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperopt/tpe.py\", line 812, in suggest\r\n    = tpe_transform(domain, prior_weight, gamma)\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperopt/tpe.py\", line 793, in tpe_transform\r\n    s_prior_weight\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperopt/tpe.py\", line 684, in build_posterior\r\n    b_post = fn(*b_args, **dict(named_args))\r\nTypeError: ap_uniform_sampler() takes at least 4 arguments (5 given)\r\n\r\nThanks in advance!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/78", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/78/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/78/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/78/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/78", "id": 222469401, "node_id": "MDU6SXNzdWUyMjI0Njk0MDE=", "number": 78, "title": "IdentationError when running optimizer", "user": {"login": "ben0it8", "id": 11842615, "node_id": "MDQ6VXNlcjExODQyNjE1", "avatar_url": "https://avatars1.githubusercontent.com/u/11842615?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ben0it8", "html_url": "https://github.com/ben0it8", "followers_url": "https://api.github.com/users/ben0it8/followers", "following_url": "https://api.github.com/users/ben0it8/following{/other_user}", "gists_url": "https://api.github.com/users/ben0it8/gists{/gist_id}", "starred_url": "https://api.github.com/users/ben0it8/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ben0it8/subscriptions", "organizations_url": "https://api.github.com/users/ben0it8/orgs", "repos_url": "https://api.github.com/users/ben0it8/repos", "events_url": "https://api.github.com/users/ben0it8/events{/privacy}", "received_events_url": "https://api.github.com/users/ben0it8/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-18T16:14:35Z", "updated_at": "2017-05-09T12:43:39Z", "closed_at": "2017-04-18T16:26:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "I get the following Traceback whenever I try to run the optimizer:\r\nUntitled.py\r\nTraceback (most recent call last):\r\n  File \"Untitled.py\", line 165, in <module>\r\n    trials=Trials())\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperas/optim.py\", line 42, in minimize\r\n    notebook_name=notebook_name, verbose=verbose)\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperas/optim.py\", line 62, in base_minimizer\r\n    model_str = get_hyperopt_model_string(model, data, notebook_name, verbose, stack)\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperas/optim.py\", line 132, in get_hyperopt_model_string\r\n    imports = extract_imports(cleaned_source, verbose)\r\n  File \"/Users/d069049/anaconda/lib/python2.7/site-packages/hyperas/utils.py\", line 31, in extract_imports\r\n    tree = ast.parse(source)\r\n  File \"/Users/d069049/anaconda/lib/python2.7/ast.py\", line 37, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 57\r\n    for lab in labels:\r\n                     ^\r\nIndentationError: unindent does not match any outer indentation level\r\n\r\nI followed the way it is advised in the examples.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/77", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/77/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/77/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/77/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/77", "id": 221438388, "node_id": "MDU6SXNzdWUyMjE0MzgzODg=", "number": 77, "title": "Ensemble models", "user": {"login": "enavarrocomes", "id": 23129773, "node_id": "MDQ6VXNlcjIzMTI5Nzcz", "avatar_url": "https://avatars3.githubusercontent.com/u/23129773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/enavarrocomes", "html_url": "https://github.com/enavarrocomes", "followers_url": "https://api.github.com/users/enavarrocomes/followers", "following_url": "https://api.github.com/users/enavarrocomes/following{/other_user}", "gists_url": "https://api.github.com/users/enavarrocomes/gists{/gist_id}", "starred_url": "https://api.github.com/users/enavarrocomes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/enavarrocomes/subscriptions", "organizations_url": "https://api.github.com/users/enavarrocomes/orgs", "repos_url": "https://api.github.com/users/enavarrocomes/repos", "events_url": "https://api.github.com/users/enavarrocomes/events{/privacy}", "received_events_url": "https://api.github.com/users/enavarrocomes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-13T02:03:21Z", "updated_at": "2017-06-11T13:14:52Z", "closed_at": "2017-06-11T13:14:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey,\r\nWhen using the best_ensemble method (for 5 models), and analyzing each one of those models returned, I find that the best one over the validation set is not the first one (in order). What models are exactly returned? Shouldn't it be the best n models over the validation set?\r\n\r\nThank you", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/maxpumperla/hyperas/issues/76", "repository_url": "https://api.github.com/repos/maxpumperla/hyperas", "labels_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/76/labels{/name}", "comments_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/76/comments", "events_url": "https://api.github.com/repos/maxpumperla/hyperas/issues/76/events", "html_url": "https://github.com/maxpumperla/hyperas/issues/76", "id": 220847918, "node_id": "MDU6SXNzdWUyMjA4NDc5MTg=", "number": 76, "title": "Get list with hyperparameters and results", "user": {"login": "enavarrocomes", "id": 23129773, "node_id": "MDQ6VXNlcjIzMTI5Nzcz", "avatar_url": "https://avatars3.githubusercontent.com/u/23129773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/enavarrocomes", "html_url": "https://github.com/enavarrocomes", "followers_url": "https://api.github.com/users/enavarrocomes/followers", "following_url": "https://api.github.com/users/enavarrocomes/following{/other_user}", "gists_url": "https://api.github.com/users/enavarrocomes/gists{/gist_id}", "starred_url": "https://api.github.com/users/enavarrocomes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/enavarrocomes/subscriptions", "organizations_url": "https://api.github.com/users/enavarrocomes/orgs", "repos_url": "https://api.github.com/users/enavarrocomes/repos", "events_url": "https://api.github.com/users/enavarrocomes/events{/privacy}", "received_events_url": "https://api.github.com/users/enavarrocomes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-11T06:03:09Z", "updated_at": "2017-06-11T13:31:06Z", "closed_at": "2017-06-11T13:31:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi!\r\nIs there a way to obtain a dictionary / list / dataframe with all the models evaluated by the algorithm and its results, instead of just getting the best one? \r\nThank you!", "performed_via_github_app": null, "score": 1.0}]}