{"total_count": 254, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/488", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/488/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/488/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/488/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/488", "id": 683069788, "node_id": "MDU6SXNzdWU2ODMwNjk3ODg=", "number": 488, "title": "Update pandas version", "user": {"login": "crypdick", "id": 5415776, "node_id": "MDQ6VXNlcjU0MTU3NzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/5415776?v=4", "gravatar_id": "", "url": "https://api.github.com/users/crypdick", "html_url": "https://github.com/crypdick", "followers_url": "https://api.github.com/users/crypdick/followers", "following_url": "https://api.github.com/users/crypdick/following{/other_user}", "gists_url": "https://api.github.com/users/crypdick/gists{/gist_id}", "starred_url": "https://api.github.com/users/crypdick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/crypdick/subscriptions", "organizations_url": "https://api.github.com/users/crypdick/orgs", "repos_url": "https://api.github.com/users/crypdick/repos", "events_url": "https://api.github.com/users/crypdick/events{/privacy}", "received_events_url": "https://api.github.com/users/crypdick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-20T20:18:18Z", "updated_at": "2020-08-21T00:27:33Z", "closed_at": "2020-08-21T00:27:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nAccording to https://github.com/quantumblacklabs/kedro/blob/master/setup.py#L41 Kedro requires `pandas>=0.24, <1.0.4` due to [this issue](https://github.com/pandas-dev/pandas/issues/34467). According to https://github.com/pandas-dev/pandas/issues/34467#issuecomment-644069002 this issue has been fixed.\r\n\r\n## Context\r\npandas 1.0.3 causes a dependency with Modin, which requires v1.0.5. This has been causing me trouble with conda environment solving, and prints ugly errors from Modin or Kedro.\r\n\r\n![2020-08-20_17-14](https://user-images.githubusercontent.com/5415776/90821073-b4283980-e308-11ea-9d51-0fe103420ca8.png)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/484", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/484/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/484/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/484/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/484", "id": 678196833, "node_id": "MDU6SXNzdWU2NzgxOTY4MzM=", "number": 484, "title": "Broken link in readthedocs", "user": {"login": "vjkr", "id": 16399079, "node_id": "MDQ6VXNlcjE2Mzk5MDc5", "avatar_url": "https://avatars2.githubusercontent.com/u/16399079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vjkr", "html_url": "https://github.com/vjkr", "followers_url": "https://api.github.com/users/vjkr/followers", "following_url": "https://api.github.com/users/vjkr/following{/other_user}", "gists_url": "https://api.github.com/users/vjkr/gists{/gist_id}", "starred_url": "https://api.github.com/users/vjkr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vjkr/subscriptions", "organizations_url": "https://api.github.com/users/vjkr/orgs", "repos_url": "https://api.github.com/users/vjkr/repos", "events_url": "https://api.github.com/users/vjkr/events{/privacy}", "received_events_url": "https://api.github.com/users/vjkr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-13T06:47:19Z", "updated_at": "2020-08-13T15:12:35Z", "closed_at": "2020-08-13T15:12:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I really do not know how to put this.\r\nBut while trying to install i found this link not working\r\nhttps://kedro.readthedocs.io/en/stable/02_getting_started/01_prerequisites.html\r\nat \r\nhttps://pypi.org/project/kedro/\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/479", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/479/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/479/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/479/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/479", "id": 675028520, "node_id": "MDU6SXNzdWU2NzUwMjg1MjA=", "number": 479, "title": "Kedro with custom execution engine? (Ray)", "user": {"login": "crypdick", "id": 5415776, "node_id": "MDQ6VXNlcjU0MTU3NzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/5415776?v=4", "gravatar_id": "", "url": "https://api.github.com/users/crypdick", "html_url": "https://github.com/crypdick", "followers_url": "https://api.github.com/users/crypdick/followers", "following_url": "https://api.github.com/users/crypdick/following{/other_user}", "gists_url": "https://api.github.com/users/crypdick/gists{/gist_id}", "starred_url": "https://api.github.com/users/crypdick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/crypdick/subscriptions", "organizations_url": "https://api.github.com/users/crypdick/orgs", "repos_url": "https://api.github.com/users/crypdick/repos", "events_url": "https://api.github.com/users/crypdick/events{/privacy}", "received_events_url": "https://api.github.com/users/crypdick/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-07T13:48:11Z", "updated_at": "2020-08-14T14:59:24Z", "closed_at": "2020-08-07T14:50:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "Potential user here. I'm interested in using Kedro, but we use Ray Distributed instead of PySpark for our execution engine. Do your pipelines support this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/474", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/474/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/474/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/474/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/474", "id": 671168758, "node_id": "MDU6SXNzdWU2NzExNjg3NTg=", "number": 474, "title": "Some broken links in README.md", "user": {"login": "jeverling", "id": 121946, "node_id": "MDQ6VXNlcjEyMTk0Ng==", "avatar_url": "https://avatars0.githubusercontent.com/u/121946?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeverling", "html_url": "https://github.com/jeverling", "followers_url": "https://api.github.com/users/jeverling/followers", "following_url": "https://api.github.com/users/jeverling/following{/other_user}", "gists_url": "https://api.github.com/users/jeverling/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeverling/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeverling/subscriptions", "organizations_url": "https://api.github.com/users/jeverling/orgs", "repos_url": "https://api.github.com/users/jeverling/repos", "events_url": "https://api.github.com/users/jeverling/events{/privacy}", "received_events_url": "https://api.github.com/users/jeverling/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-01T20:22:25Z", "updated_at": "2020-08-03T08:36:25Z", "closed_at": "2020-08-03T08:36:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nI noticed some broken links in the `README.md`. I fixed them in this PR: https://github.com/quantumblacklabs/kedro/pull/473", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/469", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/469/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/469/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/469/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/469", "id": 668503808, "node_id": "MDU6SXNzdWU2Njg1MDM4MDg=", "number": 469, "title": "FileNotFoundError occurs during `kedro jupyter convert` when `source_path / context.package_name / \"nodes\"` does not exist", "user": {"login": "kaemo", "id": 1733602, "node_id": "MDQ6VXNlcjE3MzM2MDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1733602?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kaemo", "html_url": "https://github.com/kaemo", "followers_url": "https://api.github.com/users/kaemo/followers", "following_url": "https://api.github.com/users/kaemo/following{/other_user}", "gists_url": "https://api.github.com/users/kaemo/gists{/gist_id}", "starred_url": "https://api.github.com/users/kaemo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kaemo/subscriptions", "organizations_url": "https://api.github.com/users/kaemo/orgs", "repos_url": "https://api.github.com/users/kaemo/repos", "events_url": "https://api.github.com/users/kaemo/events{/privacy}", "received_events_url": "https://api.github.com/users/kaemo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-30T08:47:10Z", "updated_at": "2020-08-07T11:22:08Z", "closed_at": "2020-08-07T11:22:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nAs per title, `FileNotFoundError` occurs during `kedro jupyter convert` when `source_path / context.package_name / \"nodes\"` does not exist. \r\n\r\n## Context\r\nI deleted the `source_path / context.package_name / \"nodes\"` directory at the beginning of the project because I wasn't using it. Later I created a notebook to try out the notebook-to-nodes conversion functionality but it failed with the aforementioned error.\r\n\r\n## Steps to Reproduce\r\n1. Remove `source_path / context.package_name / \"nodes\"` directory.\r\n2. Create a notebook and tag a cell with a function with `node`.\r\n3. Run `kedro jupyter convert notebooks/<notebook-name>.ipynb`\r\n4. Observe error.\r\n\r\n## Expected Result\r\n\r\n```\r\nConverting notebook '/Users/olszewk2/dev/pyzypad-example/notebooks/mlp.ipynb'...\r\nDone!\r\n```\r\n\r\n## Actual Result\r\n\r\n```\r\nConverting notebook '/Users/olszewk2/dev/pyzypad-example/notebooks/mlp.ipynb'...\r\nTraceback (most recent call last):\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/bin/kedro\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/kedro/framework/cli/cli.py\", line 628, in main\r\n    cli_collection()\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/click/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/kedro/framework/cli/jupyter.py\", line 237, in convert_notebook\r\n    _export_nodes(notebook, output_path)\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/site-packages/kedro/framework/cli/jupyter.py\", line 317, in _export_nodes\r\n    output_path.write_text(\"\")\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/pathlib.py\", line 1235, in write_text\r\n    with self.open(mode='w', encoding=encoding, errors=errors) as f:\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/pathlib.py\", line 1203, in open\r\n    opener=self._opener)\r\n  File \"/Users/olszewk2/miniconda3/envs/pyzypad-example-env/lib/python3.7/pathlib.py\", line 1058, in _opener\r\n    return self._accessor.open(self, flags, mode)\r\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/olszewk2/dev/pyzypad-example/src/pyzypad_example/nodes/mlp.py'\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): kedro, version 0.16.1\r\n* Python version used (`python -V`): Python 3.7.7\r\n* Operating system and version: macOS Mojave Version 10.14.6\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/465", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/465/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/465/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/465/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/465", "id": 666170183, "node_id": "MDU6SXNzdWU2NjYxNzAxODM=", "number": 465, "title": "Contributing.md - add info on running tests excluding spark related tests", "user": {"login": "sebastianbertoli", "id": 9196354, "node_id": "MDQ6VXNlcjkxOTYzNTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/9196354?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sebastianbertoli", "html_url": "https://github.com/sebastianbertoli", "followers_url": "https://api.github.com/users/sebastianbertoli/followers", "following_url": "https://api.github.com/users/sebastianbertoli/following{/other_user}", "gists_url": "https://api.github.com/users/sebastianbertoli/gists{/gist_id}", "starred_url": "https://api.github.com/users/sebastianbertoli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sebastianbertoli/subscriptions", "organizations_url": "https://api.github.com/users/sebastianbertoli/orgs", "repos_url": "https://api.github.com/users/sebastianbertoli/repos", "events_url": "https://api.github.com/users/sebastianbertoli/events{/privacy}", "received_events_url": "https://api.github.com/users/sebastianbertoli/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842395, "node_id": "MDU6TGFiZWwxMzcxODQyMzk1", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Type:%20Documentation", "name": "Type: Documentation", "color": "1D76DB", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-27T10:15:50Z", "updated_at": "2020-08-17T10:03:56Z", "closed_at": "2020-08-17T10:03:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nI would propose adding a one-liner to [First time one off](https://github.com/quantumblacklabs/kedro/blob/master/CONTRIBUTING.md#first-time-one-off) saying that if there are issues with the tests relating to the Spark functionality of Kedro one can run the test-suite excluding Spark related tests with the command `make test-no-spark`.\r\n\r\n## Context\r\nI think it would make it easier for people to get started and make new contributors aware that they could be running into issues with Spark. Furthermore, it would also save them some time. \r\n\r\n## Possible Implementation\r\nI could add a sentence to the documentation. Along the lines of:\r\n\r\n> If the Spark related tests are failing, and you are not planning to work on those features the following command will exclude them from being tested:\r\n> `make test-no-spark`\r\n\r\n## Possible Alternatives\r\nAlternatively, we could add steps to the guide / setup scripts so that those tests succeed.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/461", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/461/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/461/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/461/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/461", "id": 665747144, "node_id": "MDU6SXNzdWU2NjU3NDcxNDQ=", "number": 461, "title": "Remove quotation marks (Part 2)", "user": {"login": "yetudada", "id": 43755008, "node_id": "MDQ6VXNlcjQzNzU1MDA4", "avatar_url": "https://avatars1.githubusercontent.com/u/43755008?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yetudada", "html_url": "https://github.com/yetudada", "followers_url": "https://api.github.com/users/yetudada/followers", "following_url": "https://api.github.com/users/yetudada/following{/other_user}", "gists_url": "https://api.github.com/users/yetudada/gists{/gist_id}", "starred_url": "https://api.github.com/users/yetudada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yetudada/subscriptions", "organizations_url": "https://api.github.com/users/yetudada/orgs", "repos_url": "https://api.github.com/users/yetudada/repos", "events_url": "https://api.github.com/users/yetudada/events{/privacy}", "received_events_url": "https://api.github.com/users/yetudada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842410, "node_id": "MDU6TGFiZWwxMzcxODQyNDEw", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Difficulty:%20Starter", "name": "Difficulty: Starter", "color": "B56000", "default": false, "description": null}, {"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}, {"id": 2217699542, "node_id": "MDU6TGFiZWwyMjE3Njk5NTQy", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20EuroPython%20Sprint", "name": "Issue: EuroPython Sprint", "color": "a1e0ed", "default": false, "description": ""}, {"id": 1371842395, "node_id": "MDU6TGFiZWwxMzcxODQyMzk1", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Type:%20Documentation", "name": "Type: Documentation", "color": "1D76DB", "default": false, "description": null}, {"id": 1324784294, "node_id": "MDU6TGFiZWwxMzI0Nzg0Mjk0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": {"login": "s-mawjee", "id": 21179950, "node_id": "MDQ6VXNlcjIxMTc5OTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/21179950?v=4", "gravatar_id": "", "url": "https://api.github.com/users/s-mawjee", "html_url": "https://github.com/s-mawjee", "followers_url": "https://api.github.com/users/s-mawjee/followers", "following_url": "https://api.github.com/users/s-mawjee/following{/other_user}", "gists_url": "https://api.github.com/users/s-mawjee/gists{/gist_id}", "starred_url": "https://api.github.com/users/s-mawjee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/s-mawjee/subscriptions", "organizations_url": "https://api.github.com/users/s-mawjee/orgs", "repos_url": "https://api.github.com/users/s-mawjee/repos", "events_url": "https://api.github.com/users/s-mawjee/events{/privacy}", "received_events_url": "https://api.github.com/users/s-mawjee/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "s-mawjee", "id": 21179950, "node_id": "MDQ6VXNlcjIxMTc5OTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/21179950?v=4", "gravatar_id": "", "url": "https://api.github.com/users/s-mawjee", "html_url": "https://github.com/s-mawjee", "followers_url": "https://api.github.com/users/s-mawjee/followers", "following_url": "https://api.github.com/users/s-mawjee/following{/other_user}", "gists_url": "https://api.github.com/users/s-mawjee/gists{/gist_id}", "starred_url": "https://api.github.com/users/s-mawjee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/s-mawjee/subscriptions", "organizations_url": "https://api.github.com/users/s-mawjee/orgs", "repos_url": "https://api.github.com/users/s-mawjee/repos", "events_url": "https://api.github.com/users/s-mawjee/events{/privacy}", "received_events_url": "https://api.github.com/users/s-mawjee/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-26T09:41:05Z", "updated_at": "2020-08-03T08:38:31Z", "closed_at": "2020-08-03T08:38:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\n- We've had many authors of our documentation and this is sometimes reflected in stylistic differences\r\n- We want to move everything to the same style\r\n- For this exercise, you need to remove quotation marks from code that is documented [here](https://github.com/quantumblacklabs/kedro/blob/master/docs/source/05_data/02_kedro_io.md#partitioned-dataset-definition), you need to scroll down the page to find it in this section #460 covers working on the first code block\r\n\r\n\r\n## Actual Result\r\n\r\nHere's what the entry country looks like: \r\n```\r\n# conf/base/catalog.yml\r\n\r\nmy_partitioned_dataset:\r\n  type: \"PartitionedDataSet\"\r\n  path: \"s3://my-bucket-name/path/to/folder\"\r\n  dataset:  # full dataset config notation\r\n    type: \"pandas.CSVDataSet\"\r\n    load_args:\r\n      delimiter: \",\"\r\n    save_args:\r\n      index: false\r\n  credentials: \"my_credentials\"\r\n  load_args:\r\n    load_arg1: \"value1\"\r\n    load_arg2: \"value2\"\r\n  filepath_arg: \"filepath\"  # the argument of the dataset to pass the filepath to\r\n  filename_suffix: \".csv\"\r\n```\r\n\r\n## Expected Result\r\n\r\nHere's what we'd like it to look like, note that if the entry has some sort of punctuation then the quotation marks remain:\r\n```\r\n# conf/base/catalog.yml\r\n\r\nmy_partitioned_dataset:\r\n  type: PartitionedDataSet\r\n  path: s3://my-bucket-name/path/to/folder\r\n  dataset:  # full dataset config notation\r\n    type: pandas.CSVDataSet\r\n    load_args:\r\n      delimiter: \",\"\r\n    save_args:\r\n      index: false\r\n  credentials: my_credentials\r\n  load_args:\r\n    load_arg1: value1\r\n    load_arg2: value2\r\n  filepath_arg: filepath  # the argument of the dataset to pass the filepath to\r\n  filename_suffix: \".csv\"\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/460", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/460/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/460/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/460/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/460", "id": 665746492, "node_id": "MDU6SXNzdWU2NjU3NDY0OTI=", "number": 460, "title": "Remove quotation marks (Part 1)", "user": {"login": "yetudada", "id": 43755008, "node_id": "MDQ6VXNlcjQzNzU1MDA4", "avatar_url": "https://avatars1.githubusercontent.com/u/43755008?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yetudada", "html_url": "https://github.com/yetudada", "followers_url": "https://api.github.com/users/yetudada/followers", "following_url": "https://api.github.com/users/yetudada/following{/other_user}", "gists_url": "https://api.github.com/users/yetudada/gists{/gist_id}", "starred_url": "https://api.github.com/users/yetudada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yetudada/subscriptions", "organizations_url": "https://api.github.com/users/yetudada/orgs", "repos_url": "https://api.github.com/users/yetudada/repos", "events_url": "https://api.github.com/users/yetudada/events{/privacy}", "received_events_url": "https://api.github.com/users/yetudada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842410, "node_id": "MDU6TGFiZWwxMzcxODQyNDEw", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Difficulty:%20Starter", "name": "Difficulty: Starter", "color": "B56000", "default": false, "description": null}, {"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}, {"id": 2217699542, "node_id": "MDU6TGFiZWwyMjE3Njk5NTQy", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20EuroPython%20Sprint", "name": "Issue: EuroPython Sprint", "color": "a1e0ed", "default": false, "description": ""}, {"id": 1371842395, "node_id": "MDU6TGFiZWwxMzcxODQyMzk1", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Type:%20Documentation", "name": "Type: Documentation", "color": "1D76DB", "default": false, "description": null}, {"id": 1324784294, "node_id": "MDU6TGFiZWwxMzI0Nzg0Mjk0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": {"login": "vjkr", "id": 16399079, "node_id": "MDQ6VXNlcjE2Mzk5MDc5", "avatar_url": "https://avatars2.githubusercontent.com/u/16399079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vjkr", "html_url": "https://github.com/vjkr", "followers_url": "https://api.github.com/users/vjkr/followers", "following_url": "https://api.github.com/users/vjkr/following{/other_user}", "gists_url": "https://api.github.com/users/vjkr/gists{/gist_id}", "starred_url": "https://api.github.com/users/vjkr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vjkr/subscriptions", "organizations_url": "https://api.github.com/users/vjkr/orgs", "repos_url": "https://api.github.com/users/vjkr/repos", "events_url": "https://api.github.com/users/vjkr/events{/privacy}", "received_events_url": "https://api.github.com/users/vjkr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vjkr", "id": 16399079, "node_id": "MDQ6VXNlcjE2Mzk5MDc5", "avatar_url": "https://avatars2.githubusercontent.com/u/16399079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vjkr", "html_url": "https://github.com/vjkr", "followers_url": "https://api.github.com/users/vjkr/followers", "following_url": "https://api.github.com/users/vjkr/following{/other_user}", "gists_url": "https://api.github.com/users/vjkr/gists{/gist_id}", "starred_url": "https://api.github.com/users/vjkr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vjkr/subscriptions", "organizations_url": "https://api.github.com/users/vjkr/orgs", "repos_url": "https://api.github.com/users/vjkr/repos", "events_url": "https://api.github.com/users/vjkr/events{/privacy}", "received_events_url": "https://api.github.com/users/vjkr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-07-26T09:37:27Z", "updated_at": "2020-07-27T13:35:56Z", "closed_at": "2020-07-27T13:35:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\n- We've had many authors of our documentation and this is sometimes reflected in stylistic differences\r\n- We want to move everything to the same style\r\n- For this exercise, you need to remove quotation marks from code that is documented [here](https://github.com/quantumblacklabs/kedro/blob/master/docs/source/05_data/02_kedro_io.md#partitioned-dataset-definition)\r\n\r\n\r\n## Actual Result\r\n\r\nHere's what the entry country looks like: \r\n```\r\nmy_partitioned_dataset:\r\n  type: \"PartitionedDataSet\"\r\n  path: \"s3://my-bucket-name/path/to/folder\"  # path to the location of partitions\r\n  dataset: \"pandas.CSVDataSet\"  # shorthand notation for the dataset which will handle individual partitions\r\n  credentials: \"my_credentials\"\r\n  load_args:\r\n    load_arg1: \"value1\"\r\n    load_arg2: \"value2\"\r\n```\r\n\r\n## Expected Result\r\n\r\nHere's what we'd like it to look like:\r\n```\r\nmy_partitioned_dataset:\r\n  type: PartitionedDataSet\r\n  path: s3://my-bucket-name/path/to/folder  # path to the location of partitions\r\n  dataset: pandas.CSVDataSet  # shorthand notation for the dataset which will handle individual partitions\r\n  credentials: my_credentials\r\n  load_args:\r\n    load_arg1: value1\r\n    load_arg2: value2\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/452", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/452/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/452/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/452/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/452", "id": 665034866, "node_id": "MDU6SXNzdWU2NjUwMzQ4NjY=", "number": 452, "title": "Remove relative links from RST table", "user": {"login": "yetudada", "id": 43755008, "node_id": "MDQ6VXNlcjQzNzU1MDA4", "avatar_url": "https://avatars1.githubusercontent.com/u/43755008?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yetudada", "html_url": "https://github.com/yetudada", "followers_url": "https://api.github.com/users/yetudada/followers", "following_url": "https://api.github.com/users/yetudada/following{/other_user}", "gists_url": "https://api.github.com/users/yetudada/gists{/gist_id}", "starred_url": "https://api.github.com/users/yetudada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yetudada/subscriptions", "organizations_url": "https://api.github.com/users/yetudada/orgs", "repos_url": "https://api.github.com/users/yetudada/repos", "events_url": "https://api.github.com/users/yetudada/events{/privacy}", "received_events_url": "https://api.github.com/users/yetudada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842408, "node_id": "MDU6TGFiZWwxMzcxODQyNDA4", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Difficulty:%20Medium", "name": "Difficulty: Medium", "color": "F9D1AC", "default": false, "description": null}, {"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}, {"id": 2217699542, "node_id": "MDU6TGFiZWwyMjE3Njk5NTQy", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20EuroPython%20Sprint", "name": "Issue: EuroPython Sprint", "color": "a1e0ed", "default": false, "description": ""}, {"id": 1371842395, "node_id": "MDU6TGFiZWwxMzcxODQyMzk1", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Type:%20Documentation", "name": "Type: Documentation", "color": "1D76DB", "default": false, "description": null}, {"id": 1324784294, "node_id": "MDU6TGFiZWwxMzI0Nzg0Mjk0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-24T09:11:22Z", "updated_at": "2020-07-26T11:39:30Z", "closed_at": "2020-07-26T11:39:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n- We wanted to use relative links to take users to other places in our documentation but RST tables really don't like hyperlinks\r\n- You need to fix the hyperlinks from two places in [our documentation](https://github.com/quantumblacklabs/kedro/blob/master/docs/source/05_data/02_kedro_io.md#partitioned-dataset-definition)\r\n- This task is a \"Medium\" on difficulty because you have to understand how to create a RST table, as the layout will change\r\n- Here's more information about [links for RST tables](https://sublime-and-sphinx-guide.readthedocs.io/en/latest/references.html)\r\n\r\n## Picture of the affected area\r\n![Screenshot 2020-07-24 at 09 56 08](https://user-images.githubusercontent.com/43755008/88376417-40d8e980-cd95-11ea-953f-802ecf3fb6f4.png)\r\n\r\n## Expected Result\r\n- The two affected sentences should have hyperlinks that work", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/451", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/451/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/451/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/451/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/451", "id": 665023927, "node_id": "MDU6SXNzdWU2NjUwMjM5Mjc=", "number": 451, "title": "Add `json.JSONDataSet` to list of Versioned DataSets", "user": {"login": "yetudada", "id": 43755008, "node_id": "MDQ6VXNlcjQzNzU1MDA4", "avatar_url": "https://avatars1.githubusercontent.com/u/43755008?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yetudada", "html_url": "https://github.com/yetudada", "followers_url": "https://api.github.com/users/yetudada/followers", "following_url": "https://api.github.com/users/yetudada/following{/other_user}", "gists_url": "https://api.github.com/users/yetudada/gists{/gist_id}", "starred_url": "https://api.github.com/users/yetudada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yetudada/subscriptions", "organizations_url": "https://api.github.com/users/yetudada/orgs", "repos_url": "https://api.github.com/users/yetudada/repos", "events_url": "https://api.github.com/users/yetudada/events{/privacy}", "received_events_url": "https://api.github.com/users/yetudada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842410, "node_id": "MDU6TGFiZWwxMzcxODQyNDEw", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Difficulty:%20Starter", "name": "Difficulty: Starter", "color": "B56000", "default": false, "description": null}, {"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}, {"id": 2217699542, "node_id": "MDU6TGFiZWwyMjE3Njk5NTQy", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20EuroPython%20Sprint", "name": "Issue: EuroPython Sprint", "color": "a1e0ed", "default": false, "description": ""}, {"id": 1371842395, "node_id": "MDU6TGFiZWwxMzcxODQyMzk1", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Type:%20Documentation", "name": "Type: Documentation", "color": "1D76DB", "default": false, "description": null}, {"id": 1324784294, "node_id": "MDU6TGFiZWwxMzI0Nzg0Mjk0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": {"login": "vjkr", "id": 16399079, "node_id": "MDQ6VXNlcjE2Mzk5MDc5", "avatar_url": "https://avatars2.githubusercontent.com/u/16399079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vjkr", "html_url": "https://github.com/vjkr", "followers_url": "https://api.github.com/users/vjkr/followers", "following_url": "https://api.github.com/users/vjkr/following{/other_user}", "gists_url": "https://api.github.com/users/vjkr/gists{/gist_id}", "starred_url": "https://api.github.com/users/vjkr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vjkr/subscriptions", "organizations_url": "https://api.github.com/users/vjkr/orgs", "repos_url": "https://api.github.com/users/vjkr/repos", "events_url": "https://api.github.com/users/vjkr/events{/privacy}", "received_events_url": "https://api.github.com/users/vjkr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vjkr", "id": 16399079, "node_id": "MDQ6VXNlcjE2Mzk5MDc5", "avatar_url": "https://avatars2.githubusercontent.com/u/16399079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vjkr", "html_url": "https://github.com/vjkr", "followers_url": "https://api.github.com/users/vjkr/followers", "following_url": "https://api.github.com/users/vjkr/following{/other_user}", "gists_url": "https://api.github.com/users/vjkr/gists{/gist_id}", "starred_url": "https://api.github.com/users/vjkr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vjkr/subscriptions", "organizations_url": "https://api.github.com/users/vjkr/orgs", "repos_url": "https://api.github.com/users/vjkr/repos", "events_url": "https://api.github.com/users/vjkr/events{/privacy}", "received_events_url": "https://api.github.com/users/vjkr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-07-24T08:55:02Z", "updated_at": "2020-07-26T10:09:50Z", "closed_at": "2020-07-26T10:09:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n- We struggle to keep our list of versioned datasets up to date because manually append this list\r\n- Recently, we added a new `kedro.extras.datasets.json.JSONDataSet` \r\n- You just need to add this dataset as a new bullet to this list \r\n\r\n## Expected Result\r\n- The list of supported datasets should include `kedro.extras.datasets.json.JSONDataSet` as a new bullet", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/450", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/450/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/450/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/450/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/450", "id": 665021468, "node_id": "MDU6SXNzdWU2NjUwMjE0Njg=", "number": 450, "title": "How to let the after_node_run hook start after the output of the node is written?", "user": {"login": "widovanheemstra", "id": 8260162, "node_id": "MDQ6VXNlcjgyNjAxNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8260162?v=4", "gravatar_id": "", "url": "https://api.github.com/users/widovanheemstra", "html_url": "https://github.com/widovanheemstra", "followers_url": "https://api.github.com/users/widovanheemstra/followers", "following_url": "https://api.github.com/users/widovanheemstra/following{/other_user}", "gists_url": "https://api.github.com/users/widovanheemstra/gists{/gist_id}", "starred_url": "https://api.github.com/users/widovanheemstra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/widovanheemstra/subscriptions", "organizations_url": "https://api.github.com/users/widovanheemstra/orgs", "repos_url": "https://api.github.com/users/widovanheemstra/repos", "events_url": "https://api.github.com/users/widovanheemstra/events{/privacy}", "received_events_url": "https://api.github.com/users/widovanheemstra/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-24T08:50:29Z", "updated_at": "2020-07-25T08:35:10Z", "closed_at": "2020-07-25T08:35:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "## What are you trying to do?\r\nI have a node that creates a reporting string that will be written to txt file as output. I also have reporting hooks that start and stop mlflow runs. But I want the hook after_node_run to log  the report file as artifact but this file is then still in progress and can't be found.\r\nI assume that the hook is called as the node is stopped but that the process for storing the output is running in parallel and not part of the node run time.\r\n\r\nIn short how can I make the hook start when the output of the node is saved?\r\n\r\n## Preferred channel\r\nWe will do our best to help you with your query but in future, head to Stack Overflow for questions like this. Tag your questions with [`kedro`](https://stackoverflow.com/questions/tagged/kedro) and we'll get a notification.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/449", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/449/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/449/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/449/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/449", "id": 665021037, "node_id": "MDU6SXNzdWU2NjUwMjEwMzc=", "number": 449, "title": "Fix a typo", "user": {"login": "yetudada", "id": 43755008, "node_id": "MDQ6VXNlcjQzNzU1MDA4", "avatar_url": "https://avatars1.githubusercontent.com/u/43755008?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yetudada", "html_url": "https://github.com/yetudada", "followers_url": "https://api.github.com/users/yetudada/followers", "following_url": "https://api.github.com/users/yetudada/following{/other_user}", "gists_url": "https://api.github.com/users/yetudada/gists{/gist_id}", "starred_url": "https://api.github.com/users/yetudada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yetudada/subscriptions", "organizations_url": "https://api.github.com/users/yetudada/orgs", "repos_url": "https://api.github.com/users/yetudada/repos", "events_url": "https://api.github.com/users/yetudada/events{/privacy}", "received_events_url": "https://api.github.com/users/yetudada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842410, "node_id": "MDU6TGFiZWwxMzcxODQyNDEw", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Difficulty:%20Starter", "name": "Difficulty: Starter", "color": "B56000", "default": false, "description": null}, {"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}, {"id": 2217699542, "node_id": "MDU6TGFiZWwyMjE3Njk5NTQy", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20EuroPython%20Sprint", "name": "Issue: EuroPython Sprint", "color": "a1e0ed", "default": false, "description": ""}, {"id": 1371842395, "node_id": "MDU6TGFiZWwxMzcxODQyMzk1", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Type:%20Documentation", "name": "Type: Documentation", "color": "1D76DB", "default": false, "description": null}, {"id": 1324784294, "node_id": "MDU6TGFiZWwxMzI0Nzg0Mjk0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-24T08:49:41Z", "updated_at": "2020-07-25T19:30:29Z", "closed_at": "2020-07-25T19:30:29Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n- There's a typo in our documentation that we need your help to fix\r\n- It's in this [section of our documentation](https://github.com/quantumblacklabs/kedro/blob/master/docs/source/10_tools_integration/01_pyspark.md#use-kedros-built-in-spark-datasets-to-load-and-save-raw-data)\r\n\r\n## Picture of the affected area\r\n<img width=\"810\" alt=\"Screenshot 2020-07-24 at 09 46 34\" src=\"https://user-images.githubusercontent.com/43755008/88375001-ad061e00-cd92-11ea-88d8-354ccc0a9fc0.png\">\r\n\r\n## Expected Result\r\n`<projec-namet>/conf/base/catalog.yml` should be `<project-name>/conf/base/catalog.yml`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/448", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/448/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/448/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/448/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/448", "id": 665015104, "node_id": "MDU6SXNzdWU2NjUwMTUxMDQ=", "number": 448, "title": "Remove image description text", "user": {"login": "yetudada", "id": 43755008, "node_id": "MDQ6VXNlcjQzNzU1MDA4", "avatar_url": "https://avatars1.githubusercontent.com/u/43755008?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yetudada", "html_url": "https://github.com/yetudada", "followers_url": "https://api.github.com/users/yetudada/followers", "following_url": "https://api.github.com/users/yetudada/following{/other_user}", "gists_url": "https://api.github.com/users/yetudada/gists{/gist_id}", "starred_url": "https://api.github.com/users/yetudada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yetudada/subscriptions", "organizations_url": "https://api.github.com/users/yetudada/orgs", "repos_url": "https://api.github.com/users/yetudada/repos", "events_url": "https://api.github.com/users/yetudada/events{/privacy}", "received_events_url": "https://api.github.com/users/yetudada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842410, "node_id": "MDU6TGFiZWwxMzcxODQyNDEw", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Difficulty:%20Starter", "name": "Difficulty: Starter", "color": "B56000", "default": false, "description": null}, {"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}, {"id": 2217699542, "node_id": "MDU6TGFiZWwyMjE3Njk5NTQy", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20EuroPython%20Sprint", "name": "Issue: EuroPython Sprint", "color": "a1e0ed", "default": false, "description": ""}, {"id": 1371842395, "node_id": "MDU6TGFiZWwxMzcxODQyMzk1", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Type:%20Documentation", "name": "Type: Documentation", "color": "1D76DB", "default": false, "description": null}, {"id": 1324784294, "node_id": "MDU6TGFiZWwxMzI0Nzg0Mjk0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": {"login": "vjkr", "id": 16399079, "node_id": "MDQ6VXNlcjE2Mzk5MDc5", "avatar_url": "https://avatars2.githubusercontent.com/u/16399079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vjkr", "html_url": "https://github.com/vjkr", "followers_url": "https://api.github.com/users/vjkr/followers", "following_url": "https://api.github.com/users/vjkr/following{/other_user}", "gists_url": "https://api.github.com/users/vjkr/gists{/gist_id}", "starred_url": "https://api.github.com/users/vjkr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vjkr/subscriptions", "organizations_url": "https://api.github.com/users/vjkr/orgs", "repos_url": "https://api.github.com/users/vjkr/repos", "events_url": "https://api.github.com/users/vjkr/events{/privacy}", "received_events_url": "https://api.github.com/users/vjkr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vjkr", "id": 16399079, "node_id": "MDQ6VXNlcjE2Mzk5MDc5", "avatar_url": "https://avatars2.githubusercontent.com/u/16399079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vjkr", "html_url": "https://github.com/vjkr", "followers_url": "https://api.github.com/users/vjkr/followers", "following_url": "https://api.github.com/users/vjkr/following{/other_user}", "gists_url": "https://api.github.com/users/vjkr/gists{/gist_id}", "starred_url": "https://api.github.com/users/vjkr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vjkr/subscriptions", "organizations_url": "https://api.github.com/users/vjkr/orgs", "repos_url": "https://api.github.com/users/vjkr/repos", "events_url": "https://api.github.com/users/vjkr/events{/privacy}", "received_events_url": "https://api.github.com/users/vjkr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-07-24T08:42:33Z", "updated_at": "2020-07-25T18:35:31Z", "closed_at": "2020-07-25T18:35:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n- We struggle with how our docs render image description text and often have to include images by doing `![](/images/logo.png)` instead of `![GitHub Logo](/images/logo.png)`\r\n- You need to remove the image description text from [this](https://github.com/quantumblacklabs/kedro/blob/master/docs/source/02_get_started/02_install.md#verify-a-successful-installation) and [this](https://kedro.readthedocs.io/en/latest/03_tutorial/01_spaceflights_tutorial.html#kedro-project-development-workflow) sections in our documentation\r\n\r\n## Pictures of the affected areas \r\n### Section 1\r\n<img width=\"799\" alt=\"Screenshot 2020-07-24 at 09 38 20\" src=\"https://user-images.githubusercontent.com/43755008/88374363-8bf0fd80-cd91-11ea-9f29-f4d68fc031a1.png\">\r\n\r\n### Section 2\r\n<img width=\"792\" alt=\"Screenshot 2020-07-24 at 09 38 34\" src=\"https://user-images.githubusercontent.com/43755008/88374381-94e1cf00-cd91-11ea-92c5-d67932a4f43a.png\">", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/447", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/447/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/447/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/447/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/447", "id": 665007559, "node_id": "MDU6SXNzdWU2NjUwMDc1NTk=", "number": 447, "title": "Broken link in documentation", "user": {"login": "yetudada", "id": 43755008, "node_id": "MDQ6VXNlcjQzNzU1MDA4", "avatar_url": "https://avatars1.githubusercontent.com/u/43755008?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yetudada", "html_url": "https://github.com/yetudada", "followers_url": "https://api.github.com/users/yetudada/followers", "following_url": "https://api.github.com/users/yetudada/following{/other_user}", "gists_url": "https://api.github.com/users/yetudada/gists{/gist_id}", "starred_url": "https://api.github.com/users/yetudada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yetudada/subscriptions", "organizations_url": "https://api.github.com/users/yetudada/orgs", "repos_url": "https://api.github.com/users/yetudada/repos", "events_url": "https://api.github.com/users/yetudada/events{/privacy}", "received_events_url": "https://api.github.com/users/yetudada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842410, "node_id": "MDU6TGFiZWwxMzcxODQyNDEw", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Difficulty:%20Starter", "name": "Difficulty: Starter", "color": "B56000", "default": false, "description": null}, {"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}, {"id": 2217699542, "node_id": "MDU6TGFiZWwyMjE3Njk5NTQy", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20EuroPython%20Sprint", "name": "Issue: EuroPython Sprint", "color": "a1e0ed", "default": false, "description": ""}, {"id": 1371842395, "node_id": "MDU6TGFiZWwxMzcxODQyMzk1", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Type:%20Documentation", "name": "Type: Documentation", "color": "1D76DB", "default": false, "description": null}, {"id": 1324784294, "node_id": "MDU6TGFiZWwxMzI0Nzg0Mjk0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-24T08:33:21Z", "updated_at": "2020-07-29T11:21:37Z", "closed_at": "2020-07-29T11:21:37Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\n- We need your help with fixing a broken link in our documentation\r\n- Follow the [markdown syntax for links](https://guides.github.com/features/mastering-markdown/) to fix this problem\r\n- A picture of the affects area is below, and can be found in [this section of our docs](https://github.com/quantumblacklabs/kedro/blob/master/docs/source/01_introduction/01_introduction.md)\r\n\r\n![Screenshot 2020-07-24 at 09 28 32](https://user-images.githubusercontent.com/43755008/88373629-146e9e80-cd90-11ea-9d60-900015528405.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/442", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/442/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/442/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/442/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/442", "id": 663377723, "node_id": "MDU6SXNzdWU2NjMzNzc3MjM=", "number": 442, "title": "[KED-1876] Add support for custom queries with GBQTableDataSet", "user": {"login": "ajb7", "id": 12096029, "node_id": "MDQ6VXNlcjEyMDk2MDI5", "avatar_url": "https://avatars0.githubusercontent.com/u/12096029?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajb7", "html_url": "https://github.com/ajb7", "followers_url": "https://api.github.com/users/ajb7/followers", "following_url": "https://api.github.com/users/ajb7/following{/other_user}", "gists_url": "https://api.github.com/users/ajb7/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajb7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajb7/subscriptions", "organizations_url": "https://api.github.com/users/ajb7/orgs", "repos_url": "https://api.github.com/users/ajb7/repos", "events_url": "https://api.github.com/users/ajb7/events{/privacy}", "received_events_url": "https://api.github.com/users/ajb7/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-21T23:52:13Z", "updated_at": "2020-07-29T13:38:45Z", "closed_at": "2020-07-29T13:38:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n**Current implementation**: GBQTableDataSet loads data from Google BigQuery. It uses pandas-gbq to read from BigQuery table. In `extras/datasets/pandas/gbq_dataset.py`\r\n\r\n```\r\n    def _load(self) -> pd.DataFrame:\r\n        sql = \"select * from {}.{}\".format(self._dataset, self._table_name)  # nosec\r\n        return pd.read_gbq(\r\n            sql,\r\n            project_id=self._project_id,\r\n            credentials=self._credentials,\r\n            **self._load_args\r\n        )\r\n```\r\n\r\nThis works well when dataset is small to medium in size. However, when we have **\"Big Data\"** there is a need to get specific columns or specific rows or specific partition from the dataset; hence using custom queries with filters is required.  The `select *` implementation in many ways, violates [Best Practices](https://cloud.google.com/bigquery/docs/best-practices-costs#avoid_select_)  to fetch data from GoogleBigQuery.\r\n\r\n## Context\r\nTo comply with the [GBQ Best Practices](https://cloud.google.com/bigquery/docs/best-practices-costs#avoid_select_) in order to make the queries cost efficient as well as time efficient; GBQTableDataSet can empower developers to pass **custom queries** as arguments; instead of `select *` ;  as in the current implementation.\r\n\r\nCurrent implementation uses `pd.read_gbq()` to load data from Google Big Query. This function allows custom queries along with other arguments to be passed. The power of `read_gbq()` can be fully utilized by passing the allowed parameters of function as part of `load_args` in **GBQTableDataSet**. \r\n\r\nAs per [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_gbq.html) :\r\n\r\n```\r\npandas.read_gbq(query: str, project_id: Union[str, NoneType] = None, \r\n index_col: Union[str, NoneType] = None, col_order: Union[List[str], NoneType] = None, \r\n reauth: bool = False, auth_local_webserver: bool = False, \r\n dialect: Union[str, NoneType] = None, location: Union[str, NoneType] = None, \r\n configuration: Union[Dict[str, Any], NoneType] = None, credentials=None, \r\n use_bqstorage_api: Union[bool, NoneType] = None, private_key=None, \r\n verbose=None, progress_bar_type: Union[str, NoneType] = None) \u2192 \u2019DataFrame\u2019\r\n``` \r\n\r\nTo pass custom queries to **GBQTableDataSet**,  `catalog.yml` will look like:\r\n\r\n```\r\nmy_dataset:\r\n  type: pandas.GBQTableDataSet\r\n  dataset: gbq_dataset_name\r\n  table_name: gbq_table_name\r\n  project: gbq_project_name\r\n  load_args:\r\n    query: \"Select col1, col2, col3 from project.dataset.table_name where col4 < 100\"\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/439", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/439/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/439/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/439/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/439", "id": 663272999, "node_id": "MDU6SXNzdWU2NjMyNzI5OTk=", "number": 439, "title": "Too Many config files", "user": {"login": "WaylonWalker", "id": 22648375, "node_id": "MDQ6VXNlcjIyNjQ4Mzc1", "avatar_url": "https://avatars1.githubusercontent.com/u/22648375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaylonWalker", "html_url": "https://github.com/WaylonWalker", "followers_url": "https://api.github.com/users/WaylonWalker/followers", "following_url": "https://api.github.com/users/WaylonWalker/following{/other_user}", "gists_url": "https://api.github.com/users/WaylonWalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaylonWalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaylonWalker/subscriptions", "organizations_url": "https://api.github.com/users/WaylonWalker/orgs", "repos_url": "https://api.github.com/users/WaylonWalker/repos", "events_url": "https://api.github.com/users/WaylonWalker/events{/privacy}", "received_events_url": "https://api.github.com/users/WaylonWalker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "andrii-ivaniuk", "id": 24272541, "node_id": "MDQ6VXNlcjI0MjcyNTQx", "avatar_url": "https://avatars1.githubusercontent.com/u/24272541?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrii-ivaniuk", "html_url": "https://github.com/andrii-ivaniuk", "followers_url": "https://api.github.com/users/andrii-ivaniuk/followers", "following_url": "https://api.github.com/users/andrii-ivaniuk/following{/other_user}", "gists_url": "https://api.github.com/users/andrii-ivaniuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrii-ivaniuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrii-ivaniuk/subscriptions", "organizations_url": "https://api.github.com/users/andrii-ivaniuk/orgs", "repos_url": "https://api.github.com/users/andrii-ivaniuk/repos", "events_url": "https://api.github.com/users/andrii-ivaniuk/events{/privacy}", "received_events_url": "https://api.github.com/users/andrii-ivaniuk/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andrii-ivaniuk", "id": 24272541, "node_id": "MDQ6VXNlcjI0MjcyNTQx", "avatar_url": "https://avatars1.githubusercontent.com/u/24272541?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrii-ivaniuk", "html_url": "https://github.com/andrii-ivaniuk", "followers_url": "https://api.github.com/users/andrii-ivaniuk/followers", "following_url": "https://api.github.com/users/andrii-ivaniuk/following{/other_user}", "gists_url": "https://api.github.com/users/andrii-ivaniuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrii-ivaniuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrii-ivaniuk/subscriptions", "organizations_url": "https://api.github.com/users/andrii-ivaniuk/orgs", "repos_url": "https://api.github.com/users/andrii-ivaniuk/repos", "events_url": "https://api.github.com/users/andrii-ivaniuk/events{/privacy}", "received_events_url": "https://api.github.com/users/andrii-ivaniuk/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-21T20:02:17Z", "updated_at": "2020-08-20T14:16:51Z", "closed_at": "2020-08-20T14:10:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nKedro implements its own proprietary `.kedro.yml` config file.  This is great to have a place to configure the project, but these files can really add up.  Other python libraries/tools,  such as mypy and flake8, allow multiple config file options.  They typically set up proprietary config file locations but also allow for generic options like `setup.cfg` or `pyproject.toml` to be used to consolidate tooling config in one place.\r\n\r\n\r\n[mypy config file docs](https://mypy.readthedocs.io/en/stable/config_file.html)\r\n[flake8 config file docs](https://flake8.pycqa.org/en/latest/user/configuration.html#configuration-locations)\r\n\r\n## Possible Implementation\r\n_setup.cfg_\r\n\r\nFollow suit of other libraries for config resolution.  Look for `kedro.yml` then `.kedro.yml`, then look for a kedro key in `setup.cfg`, then look for a key in `pyproject.toml`\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/434", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/434/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/434/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/434/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/434", "id": 654454177, "node_id": "MDU6SXNzdWU2NTQ0NTQxNzc=", "number": 434, "title": "<Question> Why was JSONLocalDataSet removed?", "user": {"login": "Chtchou", "id": 27629416, "node_id": "MDQ6VXNlcjI3NjI5NDE2", "avatar_url": "https://avatars0.githubusercontent.com/u/27629416?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Chtchou", "html_url": "https://github.com/Chtchou", "followers_url": "https://api.github.com/users/Chtchou/followers", "following_url": "https://api.github.com/users/Chtchou/following{/other_user}", "gists_url": "https://api.github.com/users/Chtchou/gists{/gist_id}", "starred_url": "https://api.github.com/users/Chtchou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Chtchou/subscriptions", "organizations_url": "https://api.github.com/users/Chtchou/orgs", "repos_url": "https://api.github.com/users/Chtchou/repos", "events_url": "https://api.github.com/users/Chtchou/events{/privacy}", "received_events_url": "https://api.github.com/users/Chtchou/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-10T01:58:33Z", "updated_at": "2020-07-10T07:38:38Z", "closed_at": "2020-07-10T07:38:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "I m trying to save a JSON file in a COCO format (https://cocodataset.org/), where the arrays inside the dict have different lengths in the DataCatalog. Therefore, as the local JSONLocalDataSet doesn't exist anymore I have to recreate a custom dataset to load it. \r\nMoreover, I cannot use the JSONDataSet from pandas or geopandas as they require the length of the arrays from the dict to be of the same size.\r\n\r\nCan you please read the JSON Local DataSet in further versions, or tell me why it was deleted and if there are any other alternatives instead of rewrite your own AbstractDataset for JSON?\r\n\r\nThank you\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/433", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/433/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/433/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/433/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/433", "id": 652273383, "node_id": "MDU6SXNzdWU2NTIyNzMzODM=", "number": 433, "title": "How to pass the parameters of a function in Pipeline", "user": {"login": "adslwang4601", "id": 27870193, "node_id": "MDQ6VXNlcjI3ODcwMTkz", "avatar_url": "https://avatars1.githubusercontent.com/u/27870193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adslwang4601", "html_url": "https://github.com/adslwang4601", "followers_url": "https://api.github.com/users/adslwang4601/followers", "following_url": "https://api.github.com/users/adslwang4601/following{/other_user}", "gists_url": "https://api.github.com/users/adslwang4601/gists{/gist_id}", "starred_url": "https://api.github.com/users/adslwang4601/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adslwang4601/subscriptions", "organizations_url": "https://api.github.com/users/adslwang4601/orgs", "repos_url": "https://api.github.com/users/adslwang4601/repos", "events_url": "https://api.github.com/users/adslwang4601/events{/privacy}", "received_events_url": "https://api.github.com/users/adslwang4601/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-07T12:14:47Z", "updated_at": "2020-07-15T21:53:01Z", "closed_at": "2020-07-15T21:53:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "## What are you trying to do?\r\nI defined a function called \"split_train_test\"which is used to split a dataset into training and test datasets. \"split_train_test\" has two parameters, one is an input dataframe(defined in catalog.yml), the other one is a specific date used to split the dataset.\r\n\r\nI got a error \"ValueError: Pipeline input(s) {'201801'} not found in the DataCatalog\". It seems that in node function, we are only allowed to pass the names of datasets as parameters to our function. \r\npipeline.py\r\n```\r\nnode(\r\n                func=split_train_test,\r\n                inputs=dict(df=\"preprocessed_transactions\", test_date=\"201801\"),\r\n                outputs=[\"preprocessed_training\", \"preprocessed_test\"]\r\n            )\r\n```\r\nnodes.py\r\n```\r\ndef split_train_test(df: pd.DataFrame, test_date: int) -> pd.DataFrame:\r\n    log.info(f\"Start to split dataset into training and test datasets\")\r\n    df = train_test_split.split_data(df, test_date=int(test_date))\r\n    return df\r\n````\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/432", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/432/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/432/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/432/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/432", "id": 651665197, "node_id": "MDU6SXNzdWU2NTE2NjUxOTc=", "number": 432, "title": "Partition-wise pipeline runs", "user": {"login": "seeM", "id": 559360, "node_id": "MDQ6VXNlcjU1OTM2MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/559360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seeM", "html_url": "https://github.com/seeM", "followers_url": "https://api.github.com/users/seeM/followers", "following_url": "https://api.github.com/users/seeM/following{/other_user}", "gists_url": "https://api.github.com/users/seeM/gists{/gist_id}", "starred_url": "https://api.github.com/users/seeM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seeM/subscriptions", "organizations_url": "https://api.github.com/users/seeM/orgs", "repos_url": "https://api.github.com/users/seeM/repos", "events_url": "https://api.github.com/users/seeM/events{/privacy}", "received_events_url": "https://api.github.com/users/seeM/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-06T16:22:43Z", "updated_at": "2020-07-13T10:58:41Z", "closed_at": "2020-07-13T10:58:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nMost of my usage requires running the same pipeline independently on each of a set of partitions. For example, an ETL pipeline that selects 1 week's worth of data, applies a sequence of transformations, and writes the result to a document store or another database.\r\n\r\nI consider this a common usage pattern. The core requirement being to run pipelines \"partition-wise\" rather than \"node-wise\" (see Context for more detail), as in https://github.com/quantumblacklabs/kedro/issues/191 as well as [this stackoverflow question](https://stackoverflow.com/questions/62283931/dynamic-instance-of-pipeline-execution-based-on-dataset-partition-iterator-logic). So I would like to know:\r\n\r\n1. If this is already supported with pointers to docs and/or examples. https://github.com/quantumblacklabs/kedro/issues/191 suggests not.\r\n2. If not, is this a case that the framework could directly support or is planning to support?\r\n3. If not, what would be a good workaround?\r\n\r\nIf I'm not alone in considering this a common pattern without good support, I'd like to propose to either support this in the framework or if that's not possible to document the preferred strategy.\r\n\r\n## Context\r\nThe primary way to deal with partitions, `PartitionedDataSet`, is well documented but is kind of a red herring here. It falls short here in at least three ways, all because computation is node-wise (i.e transformations are computed for a given node across all partitions before moving to the next node, with persistence as the final step) rather than partition-wise:\r\n\r\n1. Memory inefficient: all partitions are held in memory at the same time, even though transformations are independent.\r\n2. Computation inefficient: pipelines can run two nodes in parallel, but cannot parallelise across partitions, requiring the node logic to handle that instead (via pandas, dask, spark, multiprocessing, etc). Note that node-level logic can't solve for memory inefficiency.\r\n3. Persistence is artificially delayed: Ideally you could compute all nodes and persist for the first partition, repeat for the second, etc. Not being able to do so is bad because an error at the persistence stage in one partition wastes computation, and because it makes pipelines harder to debug than if you could run a single partition at a time.\r\n\r\n## Possible Alternatives\r\nIMO the best available strategy is to parameterise the pipeline by some partition id (in the above case some identifier of the week's worth of data, like the start and end dates). Then to have a higher-level script (or perhaps another pipeline) that runs the lower-level parameterised pipelines possibly in parallel. If using a higher-level pipeline, we run into issues around unique dataset names (relates to https://github.com/quantumblacklabs/kedro/issues/162 and https://github.com/quantumblacklabs/kedro/issues/396) that I'm not sure how to solve.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/430", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/430/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/430/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/430/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/430", "id": 648826661, "node_id": "MDU6SXNzdWU2NDg4MjY2NjE=", "number": 430, "title": "pip install kedro[all] results in error with fiona: \"A GDAL API version must be specified. ...\"", "user": {"login": "eHanseJoerg", "id": 19169901, "node_id": "MDQ6VXNlcjE5MTY5OTAx", "avatar_url": "https://avatars2.githubusercontent.com/u/19169901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eHanseJoerg", "html_url": "https://github.com/eHanseJoerg", "followers_url": "https://api.github.com/users/eHanseJoerg/followers", "following_url": "https://api.github.com/users/eHanseJoerg/following{/other_user}", "gists_url": "https://api.github.com/users/eHanseJoerg/gists{/gist_id}", "starred_url": "https://api.github.com/users/eHanseJoerg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eHanseJoerg/subscriptions", "organizations_url": "https://api.github.com/users/eHanseJoerg/orgs", "repos_url": "https://api.github.com/users/eHanseJoerg/repos", "events_url": "https://api.github.com/users/eHanseJoerg/events{/privacy}", "received_events_url": "https://api.github.com/users/eHanseJoerg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-01T09:30:10Z", "updated_at": "2020-07-03T16:08:04Z", "closed_at": "2020-07-03T16:08:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nTrying to install Kedro dependencies for a fresh Kedro in a venv, the command `pip install kedro[all]` results in error as below\r\n\r\n## Context\r\nRunning Kedro in a Python venv on Windows.\r\n\r\n## Steps to Reproduce\r\n1. Create a Python Venv for kedro using Conda\r\n2. pip install kedro\r\n3. pip install kedro[all]\r\n\r\n## Expected Result\r\nNo errors with fiona\r\n\r\n## Actual Result\r\nSeems like fiona is missing the GDAL API version and exits with 0\r\n\r\n```\r\n   ERROR: Command errored out with exit status 1:\r\n     command: 'C:\\ProgramData\\Anaconda3\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\JOERGS~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fas26ji2\\\\fiona\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\JOERGS~1\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fas26ji2\\\\fiona\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\JOERGS~1\\AppData\\Local\\Temp\\pip-install-fas26ji2\\fiona\\pip-egg-info'\r\n         cwd: C:\\Users\\JOERGS~1\\AppData\\Local\\Temp\\pip-install-fas26ji2\\fiona\\\r\n    Complete output (1 lines):\r\n    A GDAL API version must be specified. Provide a path to gdal-config using a GDAL_CONFIG environment variable or use a GDAL_VERSION environment variable.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\r\n```\r\n\r\n```\r\n-- Separate them if you have more than one.\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.16.2\r\n* Python version used (`python -V`): 3.7.6\r\n* Operating system and version: Windows 10\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/428", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/428/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/428/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/428/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/428", "id": 648805208, "node_id": "MDU6SXNzdWU2NDg4MDUyMDg=", "number": 428, "title": "How to specify dtypes in catalog for pandas.CSVDataSet", "user": {"login": "widovanheemstra", "id": 8260162, "node_id": "MDQ6VXNlcjgyNjAxNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8260162?v=4", "gravatar_id": "", "url": "https://api.github.com/users/widovanheemstra", "html_url": "https://github.com/widovanheemstra", "followers_url": "https://api.github.com/users/widovanheemstra/followers", "following_url": "https://api.github.com/users/widovanheemstra/following{/other_user}", "gists_url": "https://api.github.com/users/widovanheemstra/gists{/gist_id}", "starred_url": "https://api.github.com/users/widovanheemstra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/widovanheemstra/subscriptions", "organizations_url": "https://api.github.com/users/widovanheemstra/orgs", "repos_url": "https://api.github.com/users/widovanheemstra/repos", "events_url": "https://api.github.com/users/widovanheemstra/events{/privacy}", "received_events_url": "https://api.github.com/users/widovanheemstra/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-01T09:01:47Z", "updated_at": "2020-07-07T22:42:51Z", "closed_at": "2020-07-07T22:42:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Load CSV data with forced types\r\nI have a CSV dataset with one column containing integers. They get loaded as floats. In Pandas you can specify this with the dtype parameter containing a dict. When I try this in the catalog yaml the np.int32 is not recognised and results in an error.\r\n\r\nHow can I specify the correct types for loading CSV data?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/424", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/424/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/424/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/424/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/424", "id": 646689670, "node_id": "MDU6SXNzdWU2NDY2ODk2NzA=", "number": 424, "title": "Add json as a parameter to APIDataSet to easily create json requests", "user": {"login": "dataengineerone", "id": 64087279, "node_id": "MDQ6VXNlcjY0MDg3Mjc5", "avatar_url": "https://avatars3.githubusercontent.com/u/64087279?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataengineerone", "html_url": "https://github.com/dataengineerone", "followers_url": "https://api.github.com/users/dataengineerone/followers", "following_url": "https://api.github.com/users/dataengineerone/following{/other_user}", "gists_url": "https://api.github.com/users/dataengineerone/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataengineerone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataengineerone/subscriptions", "organizations_url": "https://api.github.com/users/dataengineerone/orgs", "repos_url": "https://api.github.com/users/dataengineerone/repos", "events_url": "https://api.github.com/users/dataengineerone/events{/privacy}", "received_events_url": "https://api.github.com/users/dataengineerone/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-27T14:12:20Z", "updated_at": "2020-07-07T22:09:53Z", "closed_at": "2020-07-07T22:09:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nUsing the APIDataSet is great, but things get a little complicated if one wants to POST a JSON object.\r\nThe only way one can POST a json object is if they do the following.\r\n\r\n1. Manually add `Content-Type: application/json` to the `headers`.\r\n2. Manually stringify an object into json.\r\n\r\nThis results in a `catalog.yml` that looks something like this:\r\n\r\n```yaml\r\napi_example:\r\n  type: api.APIDataSet\r\n  url: https://jsonplaceholder.typicode.com/posts\r\n  method: 'POST'\r\n  headers:\r\n    Content-Type: application/json\r\n  data: '{\"hi\": \"there\", \"bye\": \"bear\"}'\r\n```\r\n\r\n## Context\r\n\r\nThe `requests.request` object that APIDataSet wraps Does support `json` as an argument, which would automatically stringify the python dictionary object for us, as well as change the header.\r\n\r\nThe result is that the previous `catalog.yml` entry would be much simpler to create, looking like:\r\n\r\n```yaml\r\napi_example:\r\n  type: api.APIDataSet\r\n  url: https://jsonplaceholder.typicode.com/posts\r\n  method: 'POST'\r\n  json:\r\n    hi: there\r\n    bye: bear\r\n```\r\n\r\nJSON is the lingua franca of HTTP requests, so having it more readily available in our APIDataSet I think is useful.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/423", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/423/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/423/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/423/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/423", "id": 646037511, "node_id": "MDU6SXNzdWU2NDYwMzc1MTE=", "number": 423, "title": "Memory leak with MatplotLibWriter", "user": {"login": "williamashfordQB", "id": 42339022, "node_id": "MDQ6VXNlcjQyMzM5MDIy", "avatar_url": "https://avatars0.githubusercontent.com/u/42339022?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamashfordQB", "html_url": "https://github.com/williamashfordQB", "followers_url": "https://api.github.com/users/williamashfordQB/followers", "following_url": "https://api.github.com/users/williamashfordQB/following{/other_user}", "gists_url": "https://api.github.com/users/williamashfordQB/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamashfordQB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamashfordQB/subscriptions", "organizations_url": "https://api.github.com/users/williamashfordQB/orgs", "repos_url": "https://api.github.com/users/williamashfordQB/repos", "events_url": "https://api.github.com/users/williamashfordQB/events{/privacy}", "received_events_url": "https://api.github.com/users/williamashfordQB/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-26T06:20:43Z", "updated_at": "2020-06-29T15:13:51Z", "closed_at": "2020-06-29T15:13:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nWhen saving a matplotlib figure, the writer doesn't close the figure afterwards, resulting in a memory leak for applications which write many plots. Users are prompted with the below warning:\r\n\r\n```\r\n2020-06-25 23:30:38,615 - py.warnings - WARNING - More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory\r\n. (To control this warning, see the rcParam `figure.max_open_warning`).\r\n```\r\n\r\n## Context\r\nThis bug presented itself in a Kedro project with a very large number of MatplotLib datasets used for BI/Translator interpretation. \r\n\r\n## Steps to Reproduce\r\n1. Create a kedro node that produces 20+ plots. \r\n2. Run the node\r\n\r\n## Expected Result\r\nThe MatplotLibWriter should close the figures. \r\n\r\n## Actual Result\r\nThe MatplotLibWriter doesn't close the figures. \r\n\r\n```\r\n2020-06-25 23:30:38,615 - py.warnings - WARNING - More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory\r\n. (To control this warning, see the rcParam `figure.max_open_warning`).\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.16.1\r\n* Python version used (`python -V`): 3.6.10\r\n* Operating system and version: MacOS and Debian GNU/Linux\r\n\r\n## Suggested fix\r\n\r\nAmmend the save method in the MatplotLibWriter:\r\n\r\n```\r\ndef _save(self, data: Union[figure, List[figure], Dict[str, figure]]) -> None:\r\n        save_path = self._get_save_path()\r\n\r\n        if isinstance(data, list):\r\n            for index, plot in enumerate(data):\r\n                full_key_path = get_filepath_str(\r\n                    save_path / f\"{index}.png\", self._protocol\r\n                )\r\n                self._save_to_fs(full_key_path=full_key_path, plot=plot)\r\n                plot.close()           # < ---- Closing the plot after saving should release the memory\r\n\r\n        elif isinstance(data, dict):\r\n            for plot_name, plot in data.items():\r\n                full_key_path = get_filepath_str(save_path / plot_name, self._protocol)\r\n                self._save_to_fs(full_key_path=full_key_path, plot=plot)\r\n                plot.close() \r\n\r\n        else:\r\n            full_key_path = get_filepath_str(save_path, self._protocol)\r\n            self._save_to_fs(full_key_path=full_key_path, plot=data)\r\n            data.close()\r\n\r\n        self._invalidate_cache()\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/422", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/422/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/422/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/422/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/422", "id": 645713488, "node_id": "MDU6SXNzdWU2NDU3MTM0ODg=", "number": 422, "title": "GitHub Pull Request Template has an incorrect Contributing Link", "user": {"login": "tamsanh", "id": 1330789, "node_id": "MDQ6VXNlcjEzMzA3ODk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1330789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tamsanh", "html_url": "https://github.com/tamsanh", "followers_url": "https://api.github.com/users/tamsanh/followers", "following_url": "https://api.github.com/users/tamsanh/following{/other_user}", "gists_url": "https://api.github.com/users/tamsanh/gists{/gist_id}", "starred_url": "https://api.github.com/users/tamsanh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tamsanh/subscriptions", "organizations_url": "https://api.github.com/users/tamsanh/orgs", "repos_url": "https://api.github.com/users/tamsanh/repos", "events_url": "https://api.github.com/users/tamsanh/events{/privacy}", "received_events_url": "https://api.github.com/users/tamsanh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-25T16:53:13Z", "updated_at": "2020-06-25T21:20:52Z", "closed_at": "2020-06-25T18:05:46Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nLink points to \"https://github.com/quantumblacklabs/kedro/CONTRIBUTING.md\"\r\nWhen it should point to \"https://github.com/quantumblacklabs/kedro/blob/master/CONTRIBUTING.md\" instead.\r\n\r\n## Context\r\nWas just trying to look at the contributing.md\r\n\r\n## Steps to Reproduce\r\n1. Open a pull request\r\n2. click on the 'contributing' link in \"Read the contributing guidelines\"\r\n\r\n## Expected Result\r\nShould have seen the CONTRIBUTING.md file.\r\n\r\n## Actual Result\r\nGot a \"Not Found\" error.\r\n\r\n## Your Environment\r\nWeb\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/414", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/414/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/414/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/414/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/414", "id": 640492705, "node_id": "MDU6SXNzdWU2NDA0OTI3MDU=", "number": 414, "title": "[KED-1799] Adding more than one decorator makes a pipeline be runned more than once", "user": {"login": "CharlesGaydon", "id": 11660435, "node_id": "MDQ6VXNlcjExNjYwNDM1", "avatar_url": "https://avatars3.githubusercontent.com/u/11660435?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CharlesGaydon", "html_url": "https://github.com/CharlesGaydon", "followers_url": "https://api.github.com/users/CharlesGaydon/followers", "following_url": "https://api.github.com/users/CharlesGaydon/following{/other_user}", "gists_url": "https://api.github.com/users/CharlesGaydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/CharlesGaydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CharlesGaydon/subscriptions", "organizations_url": "https://api.github.com/users/CharlesGaydon/orgs", "repos_url": "https://api.github.com/users/CharlesGaydon/repos", "events_url": "https://api.github.com/users/CharlesGaydon/events{/privacy}", "received_events_url": "https://api.github.com/users/CharlesGaydon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-17T14:33:08Z", "updated_at": "2020-06-26T12:55:09Z", "closed_at": "2020-06-26T12:55:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nAdding two decorators to a pipeline seems to make it be run again after it finished. The second time, there are issues regarding which data are used, which generated an error.\r\n\r\n## Context\r\nDoing the Spaceshift Tutorial, I started having issue [when decorators started being involved ](https://kedro.readthedocs.io/en/stable/03_tutorial/04_create_pipelines.html#using-decorators-for-nodes-and-pipelines). \r\nI wanted to add a decorator `log_time` decorator but also a `mem_profile` decorator to the `data_engineering` pipeline, as mentioned in the tutorial, which caused the error. Removing the second decorator resolves the issue.\r\n\r\n## Steps to Reproduce\r\n1. Load data and create nodes and pipelines from Kedro's Spaceshift Tutorial\r\n2. In main `pipeline.py`, add a decorator:\r\ndef create_pipelines(**kwargs) -> Dict[str, Pipeline]:\r\n```python\r\n\r\n# other imports\r\nfrom kedro.pipeline.decorators import log_time\r\nfrom kedro.extras.decorators.memory_profiler import mem_profile\r\n\r\ndef create_pipelines(**kwargs) -> Dict[str, Pipeline]:\r\n    \"\"\"Create the project's pipeline.\r\n\r\n    Args:\r\n        kwargs: Ignore any additional arguments added in the future.\r\n\r\n    Returns:\r\n        A mapping from a pipeline name to a ``Pipeline`` object.\r\n\r\n    \"\"\"\r\n\r\n    de_pipeline = de.create_pipeline().decorate(log_time).decorate(mem_profile)\r\n    # Note that the followinf line gives the same issue:\r\n    # de_pipeline = de.create_pipeline().decorate(log_time, mem_profile)\r\n    ds_pipeline = ds.create_pipeline()\r\n\r\n    return {\r\n        \"de\": de_pipeline,\r\n        \"ds\": ds_pipeline,\r\n        \"__default__\": de_pipeline + ds_pipeline,\r\n    }\r\n```\r\n3. Run the pipeline using `kedro run --pipeline de`\r\n\r\n## Expected Result\r\nThat the pipelines finishes and that runtime and max memory usage are logged.\r\n\r\n## Actual Result\r\nThe pipeline is run again (see the `Arrived here !` printed inside one of its node) after it finishes. This time causing an error because of changed data. \r\n\r\n```\r\n(kedro-tutorial-env) C:\\Users\\cgaydon\\Documents\\Working Materials\\Kedro Tutorials\\kedro-tutorial>kedro run --pipeline de\r\n2020-06-17 16:30:33,542 - root - INFO - ** Kedro project kedro-tutorial\r\nc:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\fsspec\\implementations\\local.py:33: FutureWarning: The default value of auto_mkdir=True has been deprecated and will be changed to auto_mkdir=False by default in a future release.\r\n  FutureWarning,\r\n2020-06-17 16:30:34,018 - kedro.io.data_catalog - INFO - Loading data from `shuttles` (ExcelDataSet)...\r\n2020-06-17 16:30:42,942 - kedro.pipeline.node - INFO - Running node: preprocessing_shuttles: preprocess_shuttles([shuttles]) -> [preprocessed_shuttles]\r\nArrived here !\r\n2020-06-17 16:30:43,800 - kedro.pipeline.decorators - INFO - Running 'kedro_tutorial.pipelines.data_engineering.nodes.preprocess_shuttles' took 79ms [0.079s]\r\n2020-06-17 16:30:43,800 - kedro.pipeline.decorators - INFO - Running 'kedro_tutorial.pipelines.data_engineering.nodes.preprocess_shuttles' took 79ms [0.079s]\r\nArrived here !\r\n2020-06-17 16:30:44,638 - kedro.pipeline.node - ERROR - Node `preprocessing_shuttles: preprocess_shuttles([shuttles]) -> [preprocessed_shuttles]` failed with error:\r\n'float' object has no attribute 'replace'\r\n2020-06-17 16:30:44,638 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.\r\nYou can resume the pipeline run by adding the following argument to your previous command:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\cgaydon\\AppData\\Local\\Continuum\\anaconda3\\envs\\kedro-tutorial-env\\Scripts\\kedro.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\framework\\cli\\cli.py\", line 633, in main\r\n    cli_collection()\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\click\\core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\click\\core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\click\\core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"C:\\Users\\cgaydon\\Documents\\Working Materials\\Kedro Tutorials\\kedro-tutorial\\kedro_cli.py\", line 230, in run\r\n    pipeline_name=pipeline,\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\framework\\context\\context.py\", line 699, in run\r\n    raise error\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\framework\\context\\context.py\", line 691, in run\r\n    run_result = runner.run(filtered_pipeline, catalog, run_id)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\runner\\runner.py\", line 101, in run\r\n    self._run(pipeline, catalog, run_id)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\runner\\sequential_runner.py\", line 90, in _run\r\n    run_node(node, catalog, self._is_async, run_id)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\runner\\runner.py\", line 213, in run_node\r\n    node = _run_node_sequential(node, catalog, run_id)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\runner\\runner.py\", line 238, in _run_node_sequential\r\n    raise error\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\runner\\runner.py\", line 228, in _run_node_sequential\r\n    outputs = node.run(inputs)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\pipeline\\node.py\", line 439, in run\r\n    raise exc\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\pipeline\\node.py\", line 428, in run\r\n    outputs = self._run_with_one_input(inputs, self._inputs)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\pipeline\\node.py\", line 461, in _run_with_one_input\r\n    return self._decorated_func(inputs[node_input])\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\extras\\decorators\\memory_profiler.py\", line 75, in with_memory\r\n    include_children=True,\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\memory_profiler.py\", line 343, in memory_usage\r\n    returned = f(*args, **kw)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\pipeline\\decorators.py\", line 75, in with_time\r\n    result = func(*args, **kwargs)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\kedro\\pipeline\\decorators.py\", line 75, in with_time\r\n    result = func(*args, **kwargs)\r\n  File \"C:\\Users\\cgaydon\\Documents\\Working Materials\\Kedro Tutorials\\kedro-tutorial\\src\\kedro_tutorial\\pipelines\\data_engineering\\nodes.py\", line 50, in preprocess_shuttles\r\n    shuttles[\"price\"] = shuttles[\"price\"].apply(_parse_money)\r\n  File \"c:\\users\\cgaydon\\appdata\\local\\continuum\\anaconda3\\envs\\kedro-tutorial-env\\lib\\site-packages\\pandas\\core\\series.py\", line 3848, in apply\r\n    mapped = lib.map_infer(values, f, convert=convert_dtype)\r\n  File \"pandas\\_libs\\lib.pyx\", line 2329, in pandas._libs.lib.map_infer\r\n  File \"C:\\Users\\cgaydon\\Documents\\Working Materials\\Kedro Tutorials\\kedro-tutorial\\src\\kedro_tutorial\\pipelines\\data_engineering\\nodes.py\", line 16, in _parse_money\r\n    return float(x.replace(\"$\", \"\").replace(\",\", \"\"))\r\nAttributeError: 'float' object has no attribute 'replace'```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): kedro, version 0.16.2\r\n* Python version used (`python -V`): Python 3.7.7\r\n* Operating system and version: lateste Windows\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/413", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/413/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/413/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/413/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/413", "id": 640462432, "node_id": "MDU6SXNzdWU2NDA0NjI0MzI=", "number": 413, "title": "[KED-1798] AbstractDataSet.__str__ excludes zero-valued integers", "user": {"login": "seeM", "id": 559360, "node_id": "MDQ6VXNlcjU1OTM2MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/559360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seeM", "html_url": "https://github.com/seeM", "followers_url": "https://api.github.com/users/seeM/followers", "following_url": "https://api.github.com/users/seeM/following{/other_user}", "gists_url": "https://api.github.com/users/seeM/gists{/gist_id}", "starred_url": "https://api.github.com/users/seeM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seeM/subscriptions", "organizations_url": "https://api.github.com/users/seeM/orgs", "repos_url": "https://api.github.com/users/seeM/repos", "events_url": "https://api.github.com/users/seeM/events{/privacy}", "received_events_url": "https://api.github.com/users/seeM/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-17T13:54:00Z", "updated_at": "2020-06-23T18:21:47Z", "closed_at": "2020-06-23T18:21:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "_(Apologies for deviating from the template, but this is quite straightforward and probably doesn't need all of those sections)_\r\n\r\n### Example\r\n\r\n```pycon\r\n>>> from kedro.io import AbstractDataSet\r\n>>> class MyDataSet(AbstractDataSet):\r\n...     def __init__(self, var):\r\n...         self.var = var\r\n...     def _describe(self):\r\n...         return dict(var=self.var)\r\n...     def _load(self):\r\n...         pass\r\n...     def _save(self, data):\r\n...         pass\r\n...\r\n>>> str(MyDataSet(1))\r\n'MyDataSet(var=1)'\r\n>>> str(MyDataSet(0))\r\n'MyDataSet()'\r\n```\r\n\r\n`var` isn't displayed when its value is zero, even though that could be a meaningful thing to display. This is due to the `if value` filter below:\r\n\r\nhttps://github.com/quantumblacklabs/kedro/blob/c141467739d696c1f69dfd51be33b8d02d45b501/kedro/io/core.py#L266\r\n\r\nIs falsiness an appropriate check, or should numeric values be included even when they're zero?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/412", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/412/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/412/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/412/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/412", "id": 638629186, "node_id": "MDU6SXNzdWU2Mzg2MjkxODY=", "number": 412, "title": "[KED-1796] Problems with relative paths under Windows", "user": {"login": "fdroessler", "id": 11539266, "node_id": "MDQ6VXNlcjExNTM5MjY2", "avatar_url": "https://avatars1.githubusercontent.com/u/11539266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fdroessler", "html_url": "https://github.com/fdroessler", "followers_url": "https://api.github.com/users/fdroessler/followers", "following_url": "https://api.github.com/users/fdroessler/following{/other_user}", "gists_url": "https://api.github.com/users/fdroessler/gists{/gist_id}", "starred_url": "https://api.github.com/users/fdroessler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fdroessler/subscriptions", "organizations_url": "https://api.github.com/users/fdroessler/orgs", "repos_url": "https://api.github.com/users/fdroessler/repos", "events_url": "https://api.github.com/users/fdroessler/events{/privacy}", "received_events_url": "https://api.github.com/users/fdroessler/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-15T07:56:47Z", "updated_at": "2020-06-26T13:03:13Z", "closed_at": "2020-06-26T13:03:13Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hopefully this error is not due to a change in kedro that I have missed but I had a couple of people reporting this to me.\r\n\r\n## Description\r\nSwitching from absolute paths to relative paths results in some (maybe cached) state where kedro tries to load a non-existing version of a dataset. \r\n\r\n## Context\r\nWe have developed a ML pipeline for which the data was stored in a separate partition (`D:/data`) and the kedro projekt repo was on something like `C:/code/project`. Subsequently on a different machine, a colleague cloned the repo and copied the data over into the data folder within the project repo. Now the code was in `C:/code/` and the data in `C:/code/data/` and the paths in  `catalog.yml` were adjusted to reflect the new location using relative paths. When starting IPython via the kedro command (`kedro ipython`) everything seemed ok but trying to load a versioned dataset resulted in an error. The error said that a specific version of the dataset could not be loaded from disk. Error: `VersionNotFoundError:`\r\n\r\nTrying to explicitly load a version that exists on the machine resulted in an error because for some reason a `C:/` was appended to the file URI so that it looked like this: `<path to versioned file>C:`. \r\n`01_raw/preprocessed_shuttles.csv/2020-06-15T07.44.54.647Z/C:'\r\n\r\nIf instead of relative paths `data/dataset` absolute paths are used `C:/..../kedro_project/data/dataset` everything works as expected.\r\n\r\n## Steps to Reproduce using space flight tutorial\r\n1. Catalog pointing to a different location initially.\r\n2. At this pointhttps://kedro.readthedocs.io/en/stable/03_tutorial/04_create_pipelines.html#persisting-pre-processed-data use versioned datasets\r\n3. Copy all files over to the project data directory and change catalog.yml to relative paths: `data/...`\r\n4. Start ipython using `kedro ipython` and try loading ` catalog.load(\"preprocessed_shuttles\")` or ` catalog.load(\"preprocessed_shuttles\", version='2020-06-15T07.44.54.647Z')` to see both errors.\r\n\r\n## Expected Result\r\nKedro should load the latest dataset on disk independent of absolute and relative paths.\r\n\r\n## Actual Result\r\nCopying the data and changing the yaml to relative paths results in error messages trying to load none existing versions.\r\n\r\n```\r\nVersionNotFoundError: Did not find any versions for CSVDataSet(filepath=C:\\Users\\user\\git\\space\\data\\01_raw\\preprocessed_shuttles.csv, protocol=file, save_args={'index': False}, version=Version(load=None, save='2020-06-15T07.45.43.589Z'))\r\n```\r\n\r\n```\r\nDataSetError: Failed while loading data from data set CSVDataSet(filepath=C:\\Users\\user\\git\\space\\data\\01_raw\\preprocessed_shuttles.csv, protocol=file, save_args={'index': False}, version=Version(load='2020-06-15T07.44.54.647Z', save=None)).\r\n[WinError 123] Die Syntax f\u00fcr den Dateinamen, Verzeichnisnamen oder die Datentr\u00e4gerbezeichnung ist falsch: 'C:/Users/user/git/space/data/01_raw/preprocessed_shuttles.csv/2020-06-15T07.44.54.647Z/C:'\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.16.1\r\n* Python version used (`python -V`): 3.7.7\r\n* Operating system and version: Windows 10\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/411", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/411/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/411/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/411/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/411", "id": 637716023, "node_id": "MDU6SXNzdWU2Mzc3MTYwMjM=", "number": 411, "title": "[KED-1749] `fsspec.filesystem` doesn't (reliably) expose `pathsep` property", "user": {"login": "saludes", "id": 726713, "node_id": "MDQ6VXNlcjcyNjcxMw==", "avatar_url": "https://avatars0.githubusercontent.com/u/726713?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saludes", "html_url": "https://github.com/saludes", "followers_url": "https://api.github.com/users/saludes/followers", "following_url": "https://api.github.com/users/saludes/following{/other_user}", "gists_url": "https://api.github.com/users/saludes/gists{/gist_id}", "starred_url": "https://api.github.com/users/saludes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saludes/subscriptions", "organizations_url": "https://api.github.com/users/saludes/orgs", "repos_url": "https://api.github.com/users/saludes/repos", "events_url": "https://api.github.com/users/saludes/events{/privacy}", "received_events_url": "https://api.github.com/users/saludes/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-06-12T12:29:57Z", "updated_at": "2020-06-30T13:05:45Z", "closed_at": "2020-06-30T13:05:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nCannot save a list of  figures\r\n\r\n## Steps to Reproduce\r\nOn `kedro ipython`:\r\n```\r\nfrom kedro.extras.datasets.matplotlib import MatplotlibWriter\r\nimport matplotlib.pyplot as plt\r\nlp = MatplotlibWriter(filepath='mab_list')\r\nplots = []\r\nfor i in range(5):\r\n    plots.append(plt.figure())\r\n    plt.plot([1,2,3], [4,5,6+i])\r\n    plt.close()\r\nlp.save(plots)\r\n```\r\n\r\n\r\n## Expected Result\r\nCreate a folder named *mab_list* with 5 PNG files.\r\n\r\n## Actual Result\r\n\r\n```\r\nDataSetError: Failed while saving data to data set MatplotlibWriter(filepath=mab_list, protocol=file).\r\n'LocalFileSystem' object has no attribute 'pathsep'\r\n```\r\n\r\n## Fix\r\nI just changed `.pathsep` by `.sep` in line:\r\nhttps://github.com/quantumblacklabs/kedro/blob/32180557299a196b82a7d1ad7bf93d94627e1a3e/kedro/extras/datasets/matplotlib/matplotlib_writer.py#L169\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): Version: 0.16.1\r\n* Python version used (`python -V`): Python 3.8.3\r\n* Operating system and version: mcOS Catalina 10.15.5\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/410", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/410/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/410/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/410/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/410", "id": 637074262, "node_id": "MDU6SXNzdWU2MzcwNzQyNjI=", "number": 410, "title": "Using Kedro with existing project?", "user": {"login": "ericmjl", "id": 2631566, "node_id": "MDQ6VXNlcjI2MzE1NjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/2631566?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ericmjl", "html_url": "https://github.com/ericmjl", "followers_url": "https://api.github.com/users/ericmjl/followers", "following_url": "https://api.github.com/users/ericmjl/following{/other_user}", "gists_url": "https://api.github.com/users/ericmjl/gists{/gist_id}", "starred_url": "https://api.github.com/users/ericmjl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ericmjl/subscriptions", "organizations_url": "https://api.github.com/users/ericmjl/orgs", "repos_url": "https://api.github.com/users/ericmjl/repos", "events_url": "https://api.github.com/users/ericmjl/events{/privacy}", "received_events_url": "https://api.github.com/users/ericmjl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-11T14:43:19Z", "updated_at": "2020-07-07T22:22:00Z", "closed_at": "2020-07-07T22:22:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "## What are you trying to do?\r\n\r\nI'm wondering if it's possible to use Kedro with an existing project that was not created with `kedro new`? For example, I already have a project that has a `data/` directory, a `src/` directory and more, and I'd like to start by only using the Pipelining capabilities.\r\n\r\nI've been unsuccessful on my first two attempts; I installed Kedro into the project conda environment, but the only commands available to me are `docs`, `info`, and `new`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/405", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/405/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/405/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/405/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/405", "id": 631614224, "node_id": "MDU6SXNzdWU2MzE2MTQyMjQ=", "number": 405, "title": "Pandas not reading UTF-8", "user": {"login": "widovanheemstra", "id": 8260162, "node_id": "MDQ6VXNlcjgyNjAxNjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8260162?v=4", "gravatar_id": "", "url": "https://api.github.com/users/widovanheemstra", "html_url": "https://github.com/widovanheemstra", "followers_url": "https://api.github.com/users/widovanheemstra/followers", "following_url": "https://api.github.com/users/widovanheemstra/following{/other_user}", "gists_url": "https://api.github.com/users/widovanheemstra/gists{/gist_id}", "starred_url": "https://api.github.com/users/widovanheemstra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/widovanheemstra/subscriptions", "organizations_url": "https://api.github.com/users/widovanheemstra/orgs", "repos_url": "https://api.github.com/users/widovanheemstra/repos", "events_url": "https://api.github.com/users/widovanheemstra/events{/privacy}", "received_events_url": "https://api.github.com/users/widovanheemstra/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-05T13:57:39Z", "updated_at": "2020-06-05T14:15:19Z", "closed_at": "2020-06-05T14:15:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nWhile reading a CSV file as pandas.CSVDataset an error is thrown, stating that the ascii codec can't decode a character, but utf-8 was explicitly set for decoding this file and also an escape character is defined.\r\n\r\n## Context\r\nThe raw-data file is exported from an external system and contains utf-8 characters. Although defined as utf-8 the error indicates that it assumes to read only ascii characters in the 0 - 128 range.\r\n\r\n## Steps to Reproduce\r\n1. Define a dataset containing '\u00e3', or '\u00f1' in string:\r\n```yaml\r\ntest_date:\r\n  type: pandas.CSVDataSet\r\n  filepath: data/01_raw/test_data.csv\r\n  load_args:\r\n    sep: ','\r\n    escapechar: '\\'\r\n    encoding: 'utf_8'\r\n```\r\n\r\n2. In jupyter notebook:\r\n```python\r\nfrom kedro.framework.context import load_context\r\ncontext = load_context(\"../\")\r\ncatalog = context.catalog\r\ntest_data = catalog.load(\"test_data\")\r\n```\r\n\r\n## Expected Result\r\ntest_data should be a pandas Dataframe.\r\n\r\n## Actual Result\r\nThe process stops and throws an error.\r\n\r\n```\r\nDataSetError: Failed while loading data from data set CSVDataSet(filepath=/Users/../data/01_raw/file.csv, load_args={'encoding': utf_8, 'escapechar': \\, 'sep': ,}, protocol=file, save_args={'index': False}).\r\n'ascii' codec can't decode byte 0xc3 in position 202371: ordinal not in range(128)\r\n```\r\n\r\n## Your Environment\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.16.1\r\n* Python version used (`python -V`): 3.7.3\r\n* Operating system and version: Mac OSX Catalina\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/403", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/403/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/403/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/403/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/403", "id": 629985725, "node_id": "MDU6SXNzdWU2Mjk5ODU3MjU=", "number": 403, "title": "How do I fill the credentials from environment variables", "user": {"login": "HugoPerrier", "id": 17729704, "node_id": "MDQ6VXNlcjE3NzI5NzA0", "avatar_url": "https://avatars2.githubusercontent.com/u/17729704?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HugoPerrier", "html_url": "https://github.com/HugoPerrier", "followers_url": "https://api.github.com/users/HugoPerrier/followers", "following_url": "https://api.github.com/users/HugoPerrier/following{/other_user}", "gists_url": "https://api.github.com/users/HugoPerrier/gists{/gist_id}", "starred_url": "https://api.github.com/users/HugoPerrier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HugoPerrier/subscriptions", "organizations_url": "https://api.github.com/users/HugoPerrier/orgs", "repos_url": "https://api.github.com/users/HugoPerrier/repos", "events_url": "https://api.github.com/users/HugoPerrier/events{/privacy}", "received_events_url": "https://api.github.com/users/HugoPerrier/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-03T13:15:59Z", "updated_at": "2020-06-03T14:34:20Z", "closed_at": "2020-06-03T14:34:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Issue description\r\nI would like to set placeholders in my credential files and have them filled with environment variables.\r\nExemple of **credentials.yml** file (in this case connection to a postgre database):\r\n```\r\ndev_sql:\r\n  con: \"postgresql://${USERNAME}:${PASSWORD}@${SERVERNAME}:${PORT}/${NAME}\"\r\n```\r\n\r\n## My solution (thanks DmitriiDeriabinQB and [documentation](https://kedro.readthedocs.io/en/stable/kedro.config.TemplatedConfigLoader.html#kedro.config.TemplatedConfigLoader)):\r\n\r\nEdit the run.py file to :\r\n\r\n1. Create a class inheriting from KedroContext (the default ProjectContext works fine)\r\n2. If you don't use the ProjectContext class, adapt the .kedro.yml file\r\n3. Override the KedroContext method `_create_config_loader`\r\n4. Use a TemplatedConfigLoader instead of a ConfigLoader and pass the environment variable dict as `globals_dict` argument\r\n\r\n\r\nMy run.py file looks as follows:\r\n```\r\nclass ProjectContext(KedroContext):\r\n    \"\"\"Users can override the remaining methods from the parent class here,\r\n    or create new ones (e.g. as required by plugins)\r\n    \"\"\"\r\n\r\n    project_name = \"my_project\"\r\n    project_version = \"0.16.1\"\r\n    package_name = \"my_package\"\r\n\r\n    def _get_pipelines(self) -> Dict[str, Pipeline]:\r\n        return create_pipelines()\r\n\r\n    # Get credentials from environment variables\r\n    def _create_config_loader(self, conf_paths):\r\n        return TemplatedConfigLoader(conf_paths, globals_dict=os.environ)\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n_Originally posted by @HugoPerrier in https://github.com/quantumblacklabs/kedro/issues/49#issuecomment-637656025_", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/398", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/398/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/398/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/398/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/398", "id": 629004584, "node_id": "MDU6SXNzdWU2MjkwMDQ1ODQ=", "number": 398, "title": "Kedro does not play well with Poetry", "user": {"login": "fkromer", "id": 10199742, "node_id": "MDQ6VXNlcjEwMTk5NzQy", "avatar_url": "https://avatars1.githubusercontent.com/u/10199742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fkromer", "html_url": "https://github.com/fkromer", "followers_url": "https://api.github.com/users/fkromer/followers", "following_url": "https://api.github.com/users/fkromer/following{/other_user}", "gists_url": "https://api.github.com/users/fkromer/gists{/gist_id}", "starred_url": "https://api.github.com/users/fkromer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fkromer/subscriptions", "organizations_url": "https://api.github.com/users/fkromer/orgs", "repos_url": "https://api.github.com/users/fkromer/repos", "events_url": "https://api.github.com/users/fkromer/events{/privacy}", "received_events_url": "https://api.github.com/users/fkromer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-02T08:24:50Z", "updated_at": "2020-06-02T12:46:52Z", "closed_at": "2020-06-02T10:47:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nI have created a virtual environment with Poetry into `<kedro-project-root>/.venv/` and added Kedro as development dependency. If I try to run the Kedro CLI an exception is raised.\r\n\r\n## Context\r\n\r\nThis issue implies that you cannot use Kedro with Python 3.8 if you don't want to install Kedro and Kedro project dependencies into the system or user installation of Python. Kedro-docker does not support Python 3.8 yet.\r\n\r\n## Steps to Reproduce\r\n\r\n1. Create venv: `poetry config --local virtualenvs.in-project true`, `poetry init`\r\n2. If not done automatically (e.g. in case VSCode is used), activate venv: `poetry shell`\r\n3. Add `kedro` as deve dependency: `poetry add -D kedro==0.16.1`\r\n4. Check if `kedro` is installed successfully: `poetry show | grep kedro`\r\n5. Run `kedro` CLI: `kedro -V`\r\n\r\n## Expected Result\r\nTell us what should happen.\r\n\r\n## Actual Result\r\n\r\n```\r\n$ kedro -V\r\n/home/florian/.local/lib/python3.8/site-packages/kedro/context/__init__.py:42: DeprecationWarning: All the modules in `kedro.context` have been moved to `kedro.framework.context`, and `kedro.context` will be removed in Kedro 0.17.0. Please update import paths from `kedro.context` to `kedro.framework.context` in your Kedro project.\r\n  warnings.warn(\r\n/home/florian/.local/lib/python3.8/site-packages/kedro/cli/__init__.py:40: DeprecationWarning: All the modules in `kedro.cli` have been moved to `kedro.framework.cli`, and `kedro.cli` will be removed in Kedro 0.17.0. Please update import paths from `kedro.cli` to `kedro.framework.cli` in your Kedro project.\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"/home/florian/.local/lib/python3.8/site-packages/kedro/framework/cli/cli.py\", line 619, in main\r\n    kedro_cli = importlib.import_module(\"kedro_cli\")\r\n  File \"/usr/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/florian/gitlab/<kedro-project-root/kedro_cli.py\", line 54, in <module>\r\n    from kedro.context import KEDRO_ENV_VAR, load_context\r\nImportError: cannot import name 'KEDRO_ENV_VAR' from 'kedro.context' (/home/florian/.local/lib/python3.8/site-packages/kedro/context/__init__.py)\r\n/usr/lib/python3/dist-packages/apport/report.py:13: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n  import fnmatch, glob, traceback, errno, sys, atexit, locale, imp\r\nTraceback (most recent call last):\r\n  File \"/home/florian/.local/lib/python3.8/site-packages/kedro/framework/cli/cli.py\", line 619, in main\r\n    kedro_cli = importlib.import_module(\"kedro_cli\")\r\n  File \"/usr/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/florian/gitlab/kedro-project-root/kedro_cli.py\", line 54, in <module>\r\n    from kedro.context import KEDRO_ENV_VAR, load_context\r\nImportError: cannot import name 'KEDRO_ENV_VAR' from 'kedro.context' (/home/florian/.local/lib/python3.8/site-packages/kedro/context/__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/florian/.local/bin/kedro\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/florian/.local/lib/python3.8/site-packages/kedro/framework/cli/cli.py\", line 623, in main\r\n    _handle_exception(f\"Cannot load commands from {kedro_cli_path}\")\r\n  File \"/home/florian/.local/lib/python3.8/site-packages/kedro/framework/cli/cli.py\", line 643, in _handle_exception\r\n    raise KedroCliError(msg)\r\nkedro.framework.cli.utils.KedroCliError: Cannot load commands from /home/florian/gitlab/<kedro-project-root/kedro_cli.py\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): `kedro==0.16.1`\r\n* Python version used (`python -V`): Python 3.8.2\r\n* Operating system and version: Ubuntu 20.04 LTS\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/397", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/397/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/397/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/397/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/397", "id": 628426339, "node_id": "MDU6SXNzdWU2Mjg0MjYzMzk=", "number": 397, "title": "Allow catalog in Python format in addition to YAML", "user": {"login": "Minyus", "id": 33908456, "node_id": "MDQ6VXNlcjMzOTA4NDU2", "avatar_url": "https://avatars2.githubusercontent.com/u/33908456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Minyus", "html_url": "https://github.com/Minyus", "followers_url": "https://api.github.com/users/Minyus/followers", "following_url": "https://api.github.com/users/Minyus/following{/other_user}", "gists_url": "https://api.github.com/users/Minyus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Minyus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Minyus/subscriptions", "organizations_url": "https://api.github.com/users/Minyus/orgs", "repos_url": "https://api.github.com/users/Minyus/repos", "events_url": "https://api.github.com/users/Minyus/events{/privacy}", "received_events_url": "https://api.github.com/users/Minyus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2020-06-01T13:10:03Z", "updated_at": "2020-08-19T13:52:01Z", "closed_at": "2020-07-07T22:30:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nI would suggest allowing declaring catalog datasets as a Python code in addition to YAML.\r\n\r\n## Context\r\n\r\nI personally like to use YAML, but it seems that forcing YAML format as catalog is becoming an obstacle for many Python users to start to use Kedro. \r\n\r\nHere are some examples new Kedro users suffered from YAML : \r\n\r\n- https://github.com/quantumblacklabs/kedro/issues/386\r\n- https://github.com/quantumblacklabs/kedro/issues/387\r\n- https://github.com/quantumblacklabs/kedro/issues/392\r\n\r\nIt is true that many Python users hesitate to learn YAML or Kedro's Templated Config.\r\n\r\n\r\n## Possible Implementation\r\n\r\nIn addition to `catalog.yml`, accept `catalog.py` like this:\r\n\r\n```python\r\n# written in conf/base/catalog.py\r\n\r\nfrom kedro.extras.datasets.pandas import CSVDataSet\r\n\r\ncatalog_dict = dict(\r\n  foo_dataset = CSVDataSet(filepath=\"data/foo.csv\"),\r\n  bar_dataset = CSVDataSet(filepath=\"data/bar.csv\"),\r\n)\r\n```\r\n\r\n## Possible Alternatives\r\n\r\nProvide a built-in hook to add catalog Python dict like this:\r\n\r\n```python\r\nfrom typing import Dict\r\n\r\nfrom kedro.io import AbstractDataSet, DataCatalog\r\nfrom kedro.framework.hooks import hook_impl\r\n\r\n\r\nclass AddCatalogDictHook:\r\n    \"\"\" Hook to add data sets.\r\n    \"\"\"\r\n\r\n    def __init__(\r\n        self, catalog_dict: Dict[str, AbstractDataSet],\r\n    ):\r\n        \"\"\"\r\n        Args:\r\n            catalog_dict: catalog_dict to add.\r\n        \"\"\"\r\n        assert isinstance(catalog_dict, dict), \"{} is not a dict.\".format(catalog_dict)\r\n        self._catalog_dict = catalog_dict\r\n\r\n    @hook_impl\r\n    def after_catalog_created(self, catalog: DataCatalog) -> None:\r\n        catalog.add_feed_dict(self._catalog_dict)\r\n```\r\n\r\nMy Kedro template using this hook is available at: https://github.com/Minyus/kedro_template\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/396", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/396/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/396/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/396/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/396", "id": 628388858, "node_id": "MDU6SXNzdWU2MjgzODg4NTg=", "number": 396, "title": "Running multiple pipelines in Kedro", "user": {"login": "sanjaymeena", "id": 5145685, "node_id": "MDQ6VXNlcjUxNDU2ODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/5145685?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sanjaymeena", "html_url": "https://github.com/sanjaymeena", "followers_url": "https://api.github.com/users/sanjaymeena/followers", "following_url": "https://api.github.com/users/sanjaymeena/following{/other_user}", "gists_url": "https://api.github.com/users/sanjaymeena/gists{/gist_id}", "starred_url": "https://api.github.com/users/sanjaymeena/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sanjaymeena/subscriptions", "organizations_url": "https://api.github.com/users/sanjaymeena/orgs", "repos_url": "https://api.github.com/users/sanjaymeena/repos", "events_url": "https://api.github.com/users/sanjaymeena/events{/privacy}", "received_events_url": "https://api.github.com/users/sanjaymeena/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-06-01T12:08:51Z", "updated_at": "2020-06-30T13:38:59Z", "closed_at": "2020-06-30T13:38:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, I am using Kedro for a project which I want to extend to support different countries. I want to have one pipeline for each country in the project.  Any pointers on how can I achieve this ? \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/393", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/393/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/393/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/393/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/393", "id": 627737796, "node_id": "MDU6SXNzdWU2Mjc3Mzc3OTY=", "number": 393, "title": "[KED-1834] Notify on new versions", "user": {"login": "tsanikgr", "id": 3808292, "node_id": "MDQ6VXNlcjM4MDgyOTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/3808292?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tsanikgr", "html_url": "https://github.com/tsanikgr", "followers_url": "https://api.github.com/users/tsanikgr/followers", "following_url": "https://api.github.com/users/tsanikgr/following{/other_user}", "gists_url": "https://api.github.com/users/tsanikgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/tsanikgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tsanikgr/subscriptions", "organizations_url": "https://api.github.com/users/tsanikgr/orgs", "repos_url": "https://api.github.com/users/tsanikgr/repos", "events_url": "https://api.github.com/users/tsanikgr/events{/privacy}", "received_events_url": "https://api.github.com/users/tsanikgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-30T13:58:33Z", "updated_at": "2020-08-10T13:13:23Z", "closed_at": "2020-08-10T13:13:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nThe github cli notifies on new versions as follows.\r\nWould be nice if the `kedro` cli did the same :)\r\n\r\n<img width=\"385\" alt=\"Screenshot 2020-05-30 at 16 58 21\" src=\"https://user-images.githubusercontent.com/3808292/83330308-c9a43f00-a296-11ea-8471-65411673e880.png\">\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/392", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/392/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/392/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/392/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/392", "id": 626835452, "node_id": "MDU6SXNzdWU2MjY4MzU0NTI=", "number": 392, "title": "Error trying to use \"header: None\" within catalog.yml", "user": {"login": "Burn1n9m4n", "id": 13852719, "node_id": "MDQ6VXNlcjEzODUyNzE5", "avatar_url": "https://avatars2.githubusercontent.com/u/13852719?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Burn1n9m4n", "html_url": "https://github.com/Burn1n9m4n", "followers_url": "https://api.github.com/users/Burn1n9m4n/followers", "following_url": "https://api.github.com/users/Burn1n9m4n/following{/other_user}", "gists_url": "https://api.github.com/users/Burn1n9m4n/gists{/gist_id}", "starred_url": "https://api.github.com/users/Burn1n9m4n/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Burn1n9m4n/subscriptions", "organizations_url": "https://api.github.com/users/Burn1n9m4n/orgs", "repos_url": "https://api.github.com/users/Burn1n9m4n/repos", "events_url": "https://api.github.com/users/Burn1n9m4n/events{/privacy}", "received_events_url": "https://api.github.com/users/Burn1n9m4n/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-05-28T21:43:32Z", "updated_at": "2020-05-30T01:11:17Z", "closed_at": "2020-05-29T18:52:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nTrying to read in a file from the catalog that is a text file using CSVDataSet causes the first line of data to become the header for the columns. When I try to use 'header: None', which is a valid argument, I get an error.\r\n\r\n## Context\r\nI'm basically trying to tell pandas that there is no header and that there are no names so that all the columns default to just integer labels. \r\n\r\n## Steps to Reproduce\r\n1. Place .txt file into the raw layer\r\n2. Alter catalog to read in data file using the following:\r\nraw_data:\r\n  type: pandas.CSVDataSet\r\n  filepath: data/a_raw/raw_data.txt\r\n  load_args:\r\n    sep: \"|\"\r\n    skiprows: 1\r\n    header: None\r\n    names: None\r\n    encoding: \"ISO-8859-1\"\r\n    quoting: 3\r\n3. Save catalog.yml with changes\r\n4. Run 'kedro ipython' from directory and within kedro environment\r\n5. Run following commands:\r\n x = catalog.load('raw_data')\r\n6. Code produces error\r\n## Expected Result\r\nPassing that list of arguments as load_args shouldn't cause an error. What should result is a dataframe with integers as column names and the raw data separated by '|' characters. I have done all this before using a local jupyter notebook. \r\n\r\n## Actual Result\r\nI get an error with the 'header: None' parameter specifically. \r\n\r\n```\r\nValueError: header must be integer or list of integers\r\n```\r\n```\r\nDataSetError: Failed while loading data from data set CSVDataSet(filepath=C:\\Users\\<username>\\Desktop\\kedro_tutorial\\data\\a_raw\\raw_data.txt, load_args={'encoding': ISO-8859-1, 'header': None, 'names': None, 'quoting': 3, 'sep': |, 'skiprows': 1}, protocol=file, save_args={'index': False}).\r\nheader must be integer or list of integers\r\n```\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): Version: 0.16.1\r\n* Python version used (`python -V`): Python 3.7.7\r\n* Operating system and version: Windows 10 Pro Version 10.0.17763 Build 17763\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/391", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/391/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/391/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/391/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/391", "id": 626452189, "node_id": "MDU6SXNzdWU2MjY0NTIxODk=", "number": 391, "title": "Question: Unconventional Python package dependency management", "user": {"login": "fkromer", "id": 10199742, "node_id": "MDQ6VXNlcjEwMTk5NzQy", "avatar_url": "https://avatars1.githubusercontent.com/u/10199742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fkromer", "html_url": "https://github.com/fkromer", "followers_url": "https://api.github.com/users/fkromer/followers", "following_url": "https://api.github.com/users/fkromer/following{/other_user}", "gists_url": "https://api.github.com/users/fkromer/gists{/gist_id}", "starred_url": "https://api.github.com/users/fkromer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fkromer/subscriptions", "organizations_url": "https://api.github.com/users/fkromer/orgs", "repos_url": "https://api.github.com/users/fkromer/repos", "events_url": "https://api.github.com/users/fkromer/events{/privacy}", "received_events_url": "https://api.github.com/users/fkromer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-28T12:00:23Z", "updated_at": "2020-06-01T08:36:23Z", "closed_at": "2020-06-01T08:36:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm writing a plugin for Kedro right now. In the Python world one usually uses Pipenv or Poetry for package dependency management. I've never seen a project where package dependency management has been done manually. Both tools are capable of exporting production and test dependencies into `requirements.txt` and `test_requirements.txt` respectively. Is there a reason why you don't use Pipenv or Poetry? What kind of dependency management is the recommendation for plugin contributers?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/390", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/390/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/390/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/390/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/390", "id": 625758419, "node_id": "MDU6SXNzdWU2MjU3NTg0MTk=", "number": 390, "title": "[KED-1708] Versioned datasets throw filename syntax error on Windows-latest", "user": {"login": "WaylonWalker", "id": 22648375, "node_id": "MDQ6VXNlcjIyNjQ4Mzc1", "avatar_url": "https://avatars1.githubusercontent.com/u/22648375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaylonWalker", "html_url": "https://github.com/WaylonWalker", "followers_url": "https://api.github.com/users/WaylonWalker/followers", "following_url": "https://api.github.com/users/WaylonWalker/following{/other_user}", "gists_url": "https://api.github.com/users/WaylonWalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaylonWalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaylonWalker/subscriptions", "organizations_url": "https://api.github.com/users/WaylonWalker/orgs", "repos_url": "https://api.github.com/users/WaylonWalker/repos", "events_url": "https://api.github.com/users/WaylonWalker/events{/privacy}", "received_events_url": "https://api.github.com/users/WaylonWalker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-05-27T14:42:58Z", "updated_at": "2020-07-14T08:17:30Z", "closed_at": "2020-06-26T13:04:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nWhile developing a kedro plugin I started failing matrix testing with versioned datasets due to windows path.  For now I have turned off versioning and the tests pass successfully.\r\n\r\n### Error\r\nfull traceback further down \ud83d\udc47\r\n``` python\r\n[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'C:/Users/runneradmin/AppData/Local/Temp/pytest-of-runneradmin/pytest-0/test_after_cleaned_None_None_0/raw/cars.csv/2020-05-25T21.15.02.127Z/C:'\r\n```\r\n\r\n### full report of failing test\r\nhttps://github.com/WaylonWalker/steel-toes/runs/707423172?check_suite_focus=true\r\n\r\n## Context\r\nThis is not greatly impacting me, but I wanted to raise it as an issue that I discovered. I am not able to matrix test versioned datasets. I suspect there are windows users that this would effect in a bigger way.\r\n\r\n## Steps to Reproduce\r\n1. run tests https://github.com/WaylonWalker/steel-toes/blob/master/tests/cli/context/test_context.py\r\n\r\n## Longer snippet of a single failure\r\n\r\n``` python\r\n2020-05-25T21:15:02.9888576Z c:\\hostedtoolcache\\windows\\python\\3.7.7\\x64\\lib\\os.py:223: OSError\r\n2020-05-25T21:15:02.9888752Z \r\n2020-05-25T21:15:02.9888962Z The above exception was the direct cause of the following exception:\r\n2020-05-25T21:15:02.9889130Z \r\n2020-05-25T21:15:02.9889405Z branched_dummy_context = <tests.cli.context.conftest.DummyContext object at 0x000002334A1D7048>\r\n2020-05-25T21:15:02.9889623Z dummy_dataframe =    col1  col2  col3\r\n2020-05-25T21:15:02.9889810Z 0     1     4     5\r\n2020-05-25T21:15:02.9890007Z 1     2     5     6\r\n2020-05-25T21:15:02.9890164Z \r\n2020-05-25T21:15:02.9890347Z     @pytest.fixture\r\n2020-05-25T21:15:02.9890629Z     def ready_branched_dummy_context(branched_dummy_context, dummy_dataframe):\r\n2020-05-25T21:15:02.9890919Z         \"gets dummy ready by placing a dummy dataframe at every input edge node\"\r\n2020-05-25T21:15:02.9891140Z         print(\"ready branched\")\r\n2020-05-25T21:15:02.9891354Z         for dataset in branched_dummy_context.pipeline.inputs():\r\n2020-05-25T21:15:02.9891566Z             d = getattr(branched_dummy_context.catalog.datasets, dataset)\r\n2020-05-25T21:15:02.9891780Z >           d.save(dummy_dataframe)\r\n2020-05-25T21:15:02.9891985Z \r\n2020-05-25T21:15:02.9892183Z tests\\cli\\context\\conftest.py:299: \r\n2020-05-25T21:15:02.9892381Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n2020-05-25T21:15:02.9892642Z c:\\hostedtoolcache\\windows\\python\\3.7.7\\x64\\lib\\site-packages\\kedro\\io\\core.py:625: in save\r\n2020-05-25T21:15:02.9892885Z     super().save(data)\r\n2020-05-25T21:15:02.9893516Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n2020-05-25T21:15:02.9893714Z \r\n2020-05-25T21:15:02.9894400Z self = <kedro.extras.datasets.pandas.csv_dataset.CSVDataSet object at 0x000002334A6BEE08>\r\n2020-05-25T21:15:02.9894659Z data =    col1  col2  col3\r\n2020-05-25T21:15:02.9894865Z 0     1     4     5\r\n2020-05-25T21:15:02.9895092Z 1     2     5     6\r\n2020-05-25T21:15:02.9895240Z \r\n2020-05-25T21:15:02.9895469Z     def save(self, data: Any) -> None:\r\n2020-05-25T21:15:02.9895708Z         \"\"\"Saves data by delegation to the provided save method.\r\n2020-05-25T21:15:02.9895905Z     \r\n2020-05-25T21:15:02.9896197Z         Args:\r\n2020-05-25T21:15:02.9896409Z             data: the value to be saved by provided save method.\r\n2020-05-25T21:15:02.9896643Z     \r\n2020-05-25T21:15:02.9896843Z         Raises:\r\n2020-05-25T21:15:02.9897082Z             DataSetError: when underlying save method raises error.\r\n2020-05-25T21:15:02.9897288Z     \r\n2020-05-25T21:15:02.9897522Z         \"\"\"\r\n2020-05-25T21:15:02.9897717Z     \r\n2020-05-25T21:15:02.9897916Z         if data is None:\r\n2020-05-25T21:15:02.9898170Z             raise DataSetError(\"Saving `None` to a `DataSet` is not allowed\")\r\n2020-05-25T21:15:02.9898381Z     \r\n2020-05-25T21:15:02.9898591Z         try:\r\n2020-05-25T21:15:02.9898836Z             self._logger.debug(\"Saving %s\", str(self))\r\n2020-05-25T21:15:02.9899051Z             self._save(data)\r\n2020-05-25T21:15:02.9899279Z         except DataSetError:\r\n2020-05-25T21:15:02.9899486Z             raise\r\n2020-05-25T21:15:02.9899687Z         except Exception as exc:\r\n2020-05-25T21:15:02.9899938Z             message = \"Failed while saving data to data set {}.\\n{}\".format(\r\n2020-05-25T21:15:02.9900160Z                 str(self), str(exc)\r\n2020-05-25T21:15:02.9900384Z             )\r\n2020-05-25T21:15:02.9900583Z >           raise DataSetError(message) from exc\r\n2020-05-25T21:15:02.9901990Z E           kedro.io.core.DataSetError: Failed while saving data to data set CSVDataSet(filepath=C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pytest-of-runneradmin\\pytest-0\\test_after_cleaned_None_None_0\\raw\\cars.csv, protocol=file, save_args={'index': False}, version=Version(load=None, save='2020-05-25T21.15.02.127Z')).\r\n2020-05-25T21:15:02.9902834Z E           [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'C:/Users/runneradmin/AppData/Local/Temp/pytest-of-runneradmin/pytest-0/test_after_cleaned_None_None_0/raw/cars.csv/2020-05-25T21.15.02.127Z/C:'\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\nYou can find the full workflow here https://github.com/WaylonWalker/steel-toes/blob/master/.github/workflows/test.yml\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.16.1\r\n* Python version used (`python -V`): 3.7\r\n* Operating system and version: Windows-latest\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/389", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/389/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/389/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/389/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/389", "id": 625025919, "node_id": "MDU6SXNzdWU2MjUwMjU5MTk=", "number": 389, "title": "Integration of requirement management tool", "user": {"login": "fkromer", "id": 10199742, "node_id": "MDQ6VXNlcjEwMTk5NzQy", "avatar_url": "https://avatars1.githubusercontent.com/u/10199742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fkromer", "html_url": "https://github.com/fkromer", "followers_url": "https://api.github.com/users/fkromer/followers", "following_url": "https://api.github.com/users/fkromer/following{/other_user}", "gists_url": "https://api.github.com/users/fkromer/gists{/gist_id}", "starred_url": "https://api.github.com/users/fkromer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fkromer/subscriptions", "organizations_url": "https://api.github.com/users/fkromer/orgs", "repos_url": "https://api.github.com/users/fkromer/repos", "events_url": "https://api.github.com/users/fkromer/events{/privacy}", "received_events_url": "https://api.github.com/users/fkromer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-26T16:40:19Z", "updated_at": "2020-05-27T17:39:38Z", "closed_at": "2020-05-27T17:39:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nAs a data Scientist/consultant I want to be able to deliver requirements and related tests to stakeholders/customers.\r\n\r\n## Context\r\n\r\nStakeholders/customers do not care about  API documentation. The Sphinx documentation is suboptimal as Delivery artifact. Instead they are interested in the high level functionality implemented and if there are corresponding tests.\r\n\r\n## Possible Implementation\r\n\r\ndoorstop seems to be the most feature rich package implementing requirement management right now and would play well with kedro's VCS oriented lightweight approach .\r\n\r\n## Possible Alternatives\r\n\r\n?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/387", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/387/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/387/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/387/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/387", "id": 624935626, "node_id": "MDU6SXNzdWU2MjQ5MzU2MjY=", "number": 387, "title": "Data Catalog dynamic arguments from non-local source", "user": {"login": "vonTrappG", "id": 19859712, "node_id": "MDQ6VXNlcjE5ODU5NzEy", "avatar_url": "https://avatars1.githubusercontent.com/u/19859712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vonTrappG", "html_url": "https://github.com/vonTrappG", "followers_url": "https://api.github.com/users/vonTrappG/followers", "following_url": "https://api.github.com/users/vonTrappG/following{/other_user}", "gists_url": "https://api.github.com/users/vonTrappG/gists{/gist_id}", "starred_url": "https://api.github.com/users/vonTrappG/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vonTrappG/subscriptions", "organizations_url": "https://api.github.com/users/vonTrappG/orgs", "repos_url": "https://api.github.com/users/vonTrappG/repos", "events_url": "https://api.github.com/users/vonTrappG/events{/privacy}", "received_events_url": "https://api.github.com/users/vonTrappG/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-26T14:39:20Z", "updated_at": "2020-06-02T07:21:41Z", "closed_at": "2020-06-01T12:17:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "A node in my pipeline pulls raw data from a given data source, however, the data source pull requires a dynamic input argument (e.g. an API token that expires, or a 'last-pulled' date that is updated in a remote database each time data are pulled). The dynamic input parameter values are not stored locally and need to be pulled each time the pipeline is run. In the case of a token, via an API request for new token, or in the case of the SQL query, the last date pulled which is stored in a database table that is not on the local machine executing the pipeline.\r\n\r\nExample catalog entry:\r\n\r\n```\r\nawesome_sql_query:\r\n  type: pandas.SQLQueryDataSet\r\n  credentials: secret_credentials\r\n  sql: SELECT * FROM awesome_table WHERE dates >= last_date AND dates < current_date   \r\n  load_args:\r\n    last_date: date_sql_db_data_was_last_pulled\r\n    current_date: date_of_current_sql_db_pull\r\n```\r\n\r\nMy question is: What is the best practice for implementing a service for fetching dynamic input parameters (in this example: last_date and current_date) required for pulling data from a data source?\r\n\r\nThanks! Enjoying Kedro so far!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/386", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/386/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/386/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/386/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/386", "id": 624782429, "node_id": "MDU6SXNzdWU2MjQ3ODI0Mjk=", "number": 386, "title": "How to work with long-lived refresh tokens and short-lived access tokens?", "user": {"login": "f-istvan", "id": 6824597, "node_id": "MDQ6VXNlcjY4MjQ1OTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/6824597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/f-istvan", "html_url": "https://github.com/f-istvan", "followers_url": "https://api.github.com/users/f-istvan/followers", "following_url": "https://api.github.com/users/f-istvan/following{/other_user}", "gists_url": "https://api.github.com/users/f-istvan/gists{/gist_id}", "starred_url": "https://api.github.com/users/f-istvan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/f-istvan/subscriptions", "organizations_url": "https://api.github.com/users/f-istvan/orgs", "repos_url": "https://api.github.com/users/f-istvan/repos", "events_url": "https://api.github.com/users/f-istvan/events{/privacy}", "received_events_url": "https://api.github.com/users/f-istvan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-26T10:37:15Z", "updated_at": "2020-05-27T10:37:19Z", "closed_at": "2020-05-27T10:37:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nIn my scenario I have a service that works with short-lived access tokens and long-lived refresh tokens. So I need to use the long-lived refresh token to get a short-lived token. Than I can get the data with the short-lived token. When short-lived expires I need to get a new one. \r\n\r\nI saw this example in the docs where I can pass arbitrary number of parameters to the underlying library (requests):\r\n\r\n```\r\nus_corn_yield_data:\r\n  type: api.APIDataSet\r\n  url: https://quickstats.nass.usda.gov\r\n  params:\r\n    key: SOME_TOKEN\r\n    format: JSON\r\n    commodity_desc: CORN\r\n    statisticcat_des: YIELD\r\n    agg_level_desc: STATE\r\n    year: 2000\r\n```\r\n\r\nBut in this case the `SOME_TOKEN` is the short-lived token for getting the data from the API. But what I want is to check if the short-lived token is still valid and if not request a new one with the long-lived token.\r\n\r\nThe question is: Is there a built-in support for such a use case in `api.APIDataSet` or in any other kedro Datasets?\r\n\r\nThank you!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/385", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/385/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/385/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/385/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/385", "id": 624484354, "node_id": "MDU6SXNzdWU2MjQ0ODQzNTQ=", "number": 385, "title": "Regression 0.15 -> 0.16, can no longer specify parquet engine ", "user": {"login": "philippegr", "id": 11066355, "node_id": "MDQ6VXNlcjExMDY2MzU1", "avatar_url": "https://avatars0.githubusercontent.com/u/11066355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/philippegr", "html_url": "https://github.com/philippegr", "followers_url": "https://api.github.com/users/philippegr/followers", "following_url": "https://api.github.com/users/philippegr/following{/other_user}", "gists_url": "https://api.github.com/users/philippegr/gists{/gist_id}", "starred_url": "https://api.github.com/users/philippegr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/philippegr/subscriptions", "organizations_url": "https://api.github.com/users/philippegr/orgs", "repos_url": "https://api.github.com/users/philippegr/repos", "events_url": "https://api.github.com/users/philippegr/events{/privacy}", "received_events_url": "https://api.github.com/users/philippegr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-25T21:04:53Z", "updated_at": "2020-06-30T13:31:45Z", "closed_at": "2020-06-30T13:31:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nIn version 0.15 the parquet engine used to saved Parquet files could be passed as argument, as `ParquetLocalDataSet` were saved via the pandas function:\r\nhttps://github.com/quantumblacklabs/kedro/blob/98a6c8fbecc16d3d0f0a9d810b02e123c48e8285/kedro/io/parquet_local.py#L132\r\nStarting with 0.16.0 the saving of `ParquetDataSet` is done by explicitly calling the pyarrow backend engine.\r\nhttps://github.com/quantumblacklabs/kedro/blob/d291a21bee56fdd7da4426e817fab43c9ece2302/kedro/extras/datasets/pandas/parquet_dataset.py#L172\r\nAs a direct consequence, files defined in v0.15 with ` engine: fastparquet` now raise this error\r\nhttps://github.com/quantumblacklabs/kedro/blob/ec3a325aab3e4b1a7f62ca2c3fafed1860c1b531/kedro/io/core.py#L181\r\n\r\nI don't see this being mentioned in the Release Note, thus I am assuming this is an involuntary regression. \r\n\r\nNote that the implication may be broader as pyarrow is a dependency depending on the extra requirements in the install.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/384", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/384/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/384/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/384/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/384", "id": 623694418, "node_id": "MDU6SXNzdWU2MjM2OTQ0MTg=", "number": 384, "title": "upgrading kedro_cli should be more explicit in the 0.15.* to 0.16.* migration guide", "user": {"login": "WaylonWalker", "id": 22648375, "node_id": "MDQ6VXNlcjIyNjQ4Mzc1", "avatar_url": "https://avatars1.githubusercontent.com/u/22648375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaylonWalker", "html_url": "https://github.com/WaylonWalker", "followers_url": "https://api.github.com/users/WaylonWalker/followers", "following_url": "https://api.github.com/users/WaylonWalker/following{/other_user}", "gists_url": "https://api.github.com/users/WaylonWalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaylonWalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaylonWalker/subscriptions", "organizations_url": "https://api.github.com/users/WaylonWalker/orgs", "repos_url": "https://api.github.com/users/WaylonWalker/repos", "events_url": "https://api.github.com/users/WaylonWalker/events{/privacy}", "received_events_url": "https://api.github.com/users/WaylonWalker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-23T16:28:33Z", "updated_at": "2020-05-27T12:27:11Z", "closed_at": "2020-05-27T12:27:10Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nI upgraded from a `0.15.9` project, and found that the `kedro_cli` module was quite angry.  Looking back over the migration guide, i found this note in the Migration Guide, within `Migration for kedro env environment variable`.\r\n\r\n> Note: If you haven't made significant changes to your kedro_cli.py, it may be easier to simply copy the updated kedro_cli.py .ipython/profile_default/startup/00-kedro-init.py and from GitHub or a newly generated project into your old project.\r\n\r\nI completely glossed over this section because I was not utilizing environment variables for this project.\r\n\r\n## Simple Resolution\r\n\r\nMake this note a bit more apparent inside of `release.md` by giving it its own section.   To be honest I was a bit focused on my task and did not look heavily at the diff, but it was quite different.  It definitely merits its own section of the Guide.\r\n\r\n## permanent resolution\r\n_maybe needs another issue created, or might be already under one of the framework issues_\r\n\r\nThis is a big enough module that it should just sit inside the framework, and simply be imported into kedro_cli, then users can add/overwrite commands inside this file without all of the boiler plate.\r\n\r\n\r\n## Error\r\n\r\nThis is the error I got.  Upon first inspection of the final line it doesn't lead me to initially believe that it's due to the upgrade.  I am not sure if its a feasible fix, but a better error message here would be helpful.  I believe the simple resolution highlighted above would be sufficient.\r\n\r\n```\r\n  File \"/mnt/c/temp/kedro0160/kedro_cli.py\", line 49, in <module>\r\n    from kedro.cli.pipeline import pipeline as pipeline_group\r\nModuleNotFoundError: No module named 'kedro.cli.pipeline'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/me/miniconda3/envs/kedro0160/bin/kedro\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/me/miniconda3/envs/kedro0160/lib/python3.8/site-packages/kedro/framework/cli/cli.py\", line 623, in main\r\n    _handle_exception(f\"Cannot load commands from {kedro_cli_path}\")\r\n  File \"/home/me/miniconda3/envs/kedro0160/lib/python3.8/site-packages/kedro/framework/cli/cli.py\", line 643, in _handle_exception\r\n    raise KedroCliError(msg)\r\nkedro.framework.cli.utils.KedroCliError: Cannot load commands from /mnt/c/temp/kedro0160/kedro_cli.py\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/381", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/381/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/381/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/381/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/381", "id": 623250461, "node_id": "MDU6SXNzdWU2MjMyNTA0NjE=", "number": 381, "title": "[KED-1701] Windows VM and MAX_WINDOWS_WORKERS value", "user": {"login": "kevintelford", "id": 632089, "node_id": "MDQ6VXNlcjYzMjA4OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/632089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevintelford", "html_url": "https://github.com/kevintelford", "followers_url": "https://api.github.com/users/kevintelford/followers", "following_url": "https://api.github.com/users/kevintelford/following{/other_user}", "gists_url": "https://api.github.com/users/kevintelford/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevintelford/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevintelford/subscriptions", "organizations_url": "https://api.github.com/users/kevintelford/orgs", "repos_url": "https://api.github.com/users/kevintelford/repos", "events_url": "https://api.github.com/users/kevintelford/events{/privacy}", "received_events_url": "https://api.github.com/users/kevintelford/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-22T14:31:13Z", "updated_at": "2020-07-03T08:21:00Z", "closed_at": "2020-07-03T08:21:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nWhen trying to run Kedro 0.15.9 on a Win2k12 VM on a vSphere cluster I got the error:\r\n```\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\ked\r\nro\\runner\\parallel_runner.py\", line 247, in _run\r\n    with ProcessPoolExecutor(max_workers=max_workers) as pool:\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\concurrent\\future\r\ns\\process.py\", line 523, in __init__\r\n    f\"max_workers must be <= {_MAX_WINDOWS_WORKERS}\")\r\nValueError: max_workers must be <= 61\r\nWe had an error running the pipeline - returncode=1, stderr=None, stdout=None\r\n```\r\n\r\nThis is due to how Windows and/or vSphere reports CPUs \r\n\r\n## Context\r\nCan't run on Win VM on vSphere cluster; don't really care\r\n\r\n## Steps to Reproduce\r\n1. Run on vSphere cluster\r\n\r\n## Expected Result\r\nErrors and sadness\r\n\r\n## Actual Result\r\nTell us what happens instead.\r\n\r\n```\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\runpy.py\", line 1\r\n93, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\runpy.py\", line 8\r\n5, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\kevin\\Anaconda3\\envs\\cts_distributable_37\\Scripts\\kedro.exe\\__m\r\nain__.py\", line 7, in <module>\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\ked\r\nro\\cli\\cli.py\", line 638, in main\r\n    (\"Project specific commands\", project_groups),\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\cli\r\nck\\core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\cli\r\nck\\core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\cli\r\nck\\core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\cli\r\nck\\core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\cli\r\nck\\core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"C:\\Users\\kevin\\Desktop\\cts-2.0.0\\cts-2.0.0\\kedro_cli.py\", line 278, in r\r\nun\r\n    pipeline_name=pipeline,\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\ked\r\nro\\context\\context.py\", line 487, in run\r\n    return runner.run(filtered_pipeline, catalog)\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\ked\r\nro\\runner\\runner.py\", line 82, in run\r\n    self._run(pipeline, catalog)\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\site-packages\\ked\r\nro\\runner\\parallel_runner.py\", line 247, in _run\r\n    with ProcessPoolExecutor(max_workers=max_workers) as pool:\r\n  File \"c:\\users\\kevin\\anaconda3\\envs\\cts_distributable_37\\lib\\concurrent\\future\r\ns\\process.py\", line 523, in __init__\r\n    f\"max_workers must be <= {_MAX_WINDOWS_WORKERS}\")\r\nValueError: max_workers must be <= 61\r\nWe had an error running the pipeline - returncode=1, stderr=None, stdout=None\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.15.9\r\n* Python version used (`python -V`): 3.7.7\r\n* Operating system and version: Win2k12 on vSphere cluster\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/380", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/380/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/380/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/380/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/380", "id": 622065073, "node_id": "MDU6SXNzdWU2MjIwNjUwNzM=", "number": 380, "title": "cannot import name 'KEDRO_ENV_VAR' under Kedro 0.16.0", "user": {"login": "zhangchi1", "id": 16889847, "node_id": "MDQ6VXNlcjE2ODg5ODQ3", "avatar_url": "https://avatars2.githubusercontent.com/u/16889847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangchi1", "html_url": "https://github.com/zhangchi1", "followers_url": "https://api.github.com/users/zhangchi1/followers", "following_url": "https://api.github.com/users/zhangchi1/following{/other_user}", "gists_url": "https://api.github.com/users/zhangchi1/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangchi1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangchi1/subscriptions", "organizations_url": "https://api.github.com/users/zhangchi1/orgs", "repos_url": "https://api.github.com/users/zhangchi1/repos", "events_url": "https://api.github.com/users/zhangchi1/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangchi1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-20T20:30:55Z", "updated_at": "2020-05-22T10:48:56Z", "closed_at": "2020-05-22T10:48:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nMy kedro project is created using Kedro 0.15.9. \r\nI recently upgraded kedro using `pip install kedro==0.16.0`. \r\nHowever, I got `ImportError: cannot import name 'KEDRO_ENV_VAR'` after I run `kedro info`.\r\n\r\n## Context\r\nHere is the detailed error message: \r\n\r\n```\r\n~/.pyenv/versions/3.6.6/envs/kedro-mlflow/lib/python3.6/site-packages/kedro/context/__init__.py:46: DeprecationWarning: All the modules in `kedro.context` have been moved to `kedro.framework.context`, and `kedro.context` will be removed in Kedro 0.17.0. Please update import paths from `kedro.context` to `kedro.framework.context` in your Kedro project.\r\n  DeprecationWarning,\r\n~/.pyenv/versions/3.6.6/envs/kedro-mlflow/lib/python3.6/site-packages/kedro/cli/__init__.py:44: DeprecationWarning: All the modules in `kedro.cli` have been moved to `kedro.framework.cli`, and `kedro.cli` will be removed in Kedro 0.17.0. Please update import paths from `kedro.cli` to `kedro.framework.cli` in your Kedro project.\r\n  DeprecationWarning,\r\nTraceback (most recent call last):\r\n  File \"~/.pyenv/versions/3.6.6/envs/kedro-mlflow/lib/python3.6/site-packages/kedro/framework/cli/cli.py\", line 619, in main\r\n    kedro_cli = importlib.import_module(\"kedro_cli\")\r\n  File \"~/.pyenv/versions/3.6.6/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/myProject/kedro_cli.py\", line 54, in <module>\r\n    from kedro.context import KEDRO_ENV_VAR, load_context\r\nImportError: cannot import name 'KEDRO_ENV_VAR'\r\nTraceback (most recent call last):\r\n  File \"~/.pyenv/versions/3.6.6/envs/kedro-mlflow/lib/python3.6/site-packages/kedro/framework/cli/cli.py\", line 619, in main\r\n    kedro_cli = importlib.import_module(\"kedro_cli\")\r\n  File \"~/.pyenv/versions/3.6.6/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/myProject/kedro_cli.py\", line 54, in <module>\r\n    from kedro.context import KEDRO_ENV_VAR, load_context\r\nImportError: cannot import name 'KEDRO_ENV_VAR'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"~/.pyenv/versions/3.6.6/envs/kedro-mlflow/bin/kedro\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"~/.pyenv/versions/3.6.6/envs/kedro-mlflow/lib/python3.6/site-packages/kedro/framework/cli/cli.py\", line 623, in main\r\n    _handle_exception(f\"Cannot load commands from {kedro_cli_path}\")\r\n  File \"~/.pyenv/versions/3.6.6/envs/kedro-mlflow/lib/python3.6/site-packages/kedro/framework/cli/cli.py\", line 643, in _handle_exception\r\n    raise KedroCliError(msg)\r\nkedro.framework.cli.utils.KedroCliError: Cannot load commands from /myProject/kedro_cli.py\r\n```\r\n## Questions\r\n1. Do you recommend to create a new kedro project using the new kedro version=0.16.0?\r\n2. Is there an easy way to upgrade my old kedro project (say 0.15.9) so that I can run it under the newer kedro version (say 0.16.0)? \r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): pip install kedro==0.16.0\r\n* Python version used (`python -V`): 3.6.6\r\n* Operating system and version: Mac OS\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/379", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/379/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/379/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/379/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/379", "id": 621815327, "node_id": "MDU6SXNzdWU2MjE4MTUzMjc=", "number": 379, "title": "src_prefix is not configurable", "user": {"login": "WaylonWalker", "id": 22648375, "node_id": "MDQ6VXNlcjIyNjQ4Mzc1", "avatar_url": "https://avatars1.githubusercontent.com/u/22648375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaylonWalker", "html_url": "https://github.com/WaylonWalker", "followers_url": "https://api.github.com/users/WaylonWalker/followers", "following_url": "https://api.github.com/users/WaylonWalker/following{/other_user}", "gists_url": "https://api.github.com/users/WaylonWalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaylonWalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaylonWalker/subscriptions", "organizations_url": "https://api.github.com/users/WaylonWalker/orgs", "repos_url": "https://api.github.com/users/WaylonWalker/repos", "events_url": "https://api.github.com/users/WaylonWalker/events{/privacy}", "received_events_url": "https://api.github.com/users/WaylonWalker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-20T14:37:41Z", "updated_at": "2020-05-20T14:45:37Z", "closed_at": "2020-05-20T14:45:37Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nMy project templates do not use a `src` directory.  Upgrading to `kedro==0.16.0` throws a `KedroContextError`.\r\n\r\n## Context\r\nI am not able to upgrade my projects to `kedro==0.16.0`\r\n\r\n## Steps to Reproduce\r\ncreate a project using `<project-name>/<project-name>` structure\r\n\r\n## Expected Result\r\n\r\nLoad project as it did in `kedro==0.15.9`\r\n\r\n## Actual Result\r\n\r\n```\r\nKedroContextError                         Traceback (most recent call last)\r\n\r\n~/miniconda3/envs/<my-env>/lib/python3.7/site-packages/rekonn/abstract_pipeine.py in __init__(self, parallel_runner, max_workers, context)\r\n     61 \r\n     62         if context is None:\r\n---> 63             self.context = self.get_context()\r\n     64         else:\r\n     65             self.context = context\r\n\r\n~/miniconda3/envs/<my-env>/lib/python3.7/site-packages/rekonn/abstract_pipeine.py in get_context(self)\r\n     52     def get_context(self):\r\n     53         \"\"\"returns context from self.project_path\"\"\"\r\n---> 54         return load_kedro(project_path=self.project_path,)\r\n     55 \r\n     56     def __init__(\r\n\r\n~/miniconda3/envs/<my-env>/lib/python3.7/site-packages/rekonn/load_kedro.py in load_kedro(project_path)\r\n     32         startup_error = err\r\n     33         logging.error(\"Kedro's ipython session startup script failed:\\n%s\", str(err))\r\n---> 34         raise err\r\n     35 \r\n     36     return context\r\n\r\n~/miniconda3/envs/<my-env>/lib/python3.7/site-packages/rekonn/load_kedro.py in load_kedro(project_path)\r\n     18         from kedro.context import load_context\r\n     19 \r\n---> 20         context = load_context(project_path)\r\n     21 \r\n     22         logging.info(\"** Kedro project {}\".format(context.project_name))\r\n\r\n~/miniconda3/envs/<my-env>/lib/python3.7/site-packages/kedro/context/context.py in load_context(project_path, **kwargs)\r\n    794     src_prefix = Path(kedro_yaml_content.get(\"source_dir\", \"src\")).expanduser()\r\n    795     src_path = (project_path / src_prefix).resolve()\r\n--> 796     validate_source_path(src_path, project_path)\r\n    797 \r\n    798     if str(src_path) not in sys.path:\r\n\r\n~/miniconda3/envs/<my-env>/lib/python3.7/site-packages/kedro/context/context.py in validate_source_path(source_path, project_path)\r\n    748         )\r\n    749     if not source_path.exists():\r\n--> 750         raise KedroContextError(f\"Source path '{source_path}' cannot be found.\")\r\n    751 \r\n    752 \r\n\r\nKedroContextError: Source path '<path-to-project>/src' cannot be found.\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`):\r\n   * 0.16.0\r\n* Python version used (`python -V`):\r\n   * Python 3.7.6\r\n* Operating system and version:\r\n   * Debian 9.12 stretch\r\n\r\n\r\n## Potential solution\r\n\r\nCan `src_prefix` be configured in `.kedro.yml`, or are there other things that depend on the src directory.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/375", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/375/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/375/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/375/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/375", "id": 620676550, "node_id": "MDU6SXNzdWU2MjA2NzY1NTA=", "number": 375, "title": "Save kedro pipeline image by pillow.ImageDataSet without manually launching kedro-viz server", "user": {"login": "Minyus", "id": 33908456, "node_id": "MDQ6VXNlcjMzOTA4NDU2", "avatar_url": "https://avatars2.githubusercontent.com/u/33908456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Minyus", "html_url": "https://github.com/Minyus", "followers_url": "https://api.github.com/users/Minyus/followers", "following_url": "https://api.github.com/users/Minyus/following{/other_user}", "gists_url": "https://api.github.com/users/Minyus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Minyus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Minyus/subscriptions", "organizations_url": "https://api.github.com/users/Minyus/orgs", "repos_url": "https://api.github.com/users/Minyus/repos", "events_url": "https://api.github.com/users/Minyus/events{/privacy}", "received_events_url": "https://api.github.com/users/Minyus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-19T04:54:01Z", "updated_at": "2020-06-30T13:50:24Z", "closed_at": "2020-06-30T13:50:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nCurrently we have to launch the `kedro-viz` server to see the visualized pipeline. \r\nIt will be more convenient if we can save the pipeline image by simply setting in `catalog.yml` like this:\r\n\r\n```yaml\r\n_PIPELINE_IMAGE:\r\n  type: pillow.ImageDataSet\r\n  filepath: data/_pipeline_image.png\r\n```\r\n\r\n## Context\r\nThis issue is related to #56 (moved to https://github.com/quantumblacklabs/kedro-viz/issues/31), but perhaps a more convenient feature.\r\n\r\n## Possible Implementation\r\nProvide some of the visualization code in `kedro-viz` as a Kedro hook.\r\n\r\n## Possible Alternatives\r\nPort some of the visualization code in `kedro-viz` to KedroContext.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/374", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/374/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/374/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/374/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/374", "id": 619830104, "node_id": "MDU6SXNzdWU2MTk4MzAxMDQ=", "number": 374, "title": "Kedro can't build requirements with newest pip (v20.1)", "user": {"login": "markf94", "id": 15378163, "node_id": "MDQ6VXNlcjE1Mzc4MTYz", "avatar_url": "https://avatars3.githubusercontent.com/u/15378163?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markf94", "html_url": "https://github.com/markf94", "followers_url": "https://api.github.com/users/markf94/followers", "following_url": "https://api.github.com/users/markf94/following{/other_user}", "gists_url": "https://api.github.com/users/markf94/gists{/gist_id}", "starred_url": "https://api.github.com/users/markf94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markf94/subscriptions", "organizations_url": "https://api.github.com/users/markf94/orgs", "repos_url": "https://api.github.com/users/markf94/repos", "events_url": "https://api.github.com/users/markf94/events{/privacy}", "received_events_url": "https://api.github.com/users/markf94/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-18T00:14:44Z", "updated_at": "2020-05-18T14:20:50Z", "closed_at": "2020-05-18T14:20:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n`kedro build-reqs` fails when using the newest pip version `20.1`. However, it does work fine with pip version `19.3.1` (you can easily check by running `pip install pip==19.3.1`).\r\n\r\n## Context\r\n`pip` told me I should update to version `20.1` which I did with `pip install --upgrade pip`. Afterwards, I added some new requirements to `src/requirements.in` in my `kedro` project and wanted to to build the requirements by running `kedro build-reqs`.\r\n\r\n## Steps to Reproduce\r\n1. Initialize a kedro repo\r\n2. Create a Python virtual environment within the kedro repo (`python3 -m venv .venv`)\r\n3. Activate the virtual environment (`source .venv/bin/activate`)\r\n3. Upgrade pip to `20.1` with `python -m pip install --upgrade pip`\r\n4. Add some requirements and run `kedro build-reqs`\r\n\r\n## Expected Result\r\nI expect the successful building of my `requirements.txt` file with a final output line like this:\r\n\r\n```\r\nRequirements built! Please update requirements.in if you'd like to make a change in your project's dependencies, and re-run build-reqs to generate the new requirements.txt.\r\n```\r\n\r\n## Actual Result\r\nInstead of building the requirements the command `kedro build-reqs` fails with the following traceback:\r\n\r\n```\r\n/home/markf94/.../kedro-project/.venv/bin/python -m piptools compile /home/markf94/.../kedro-project/src/requirements.in\r\nTraceback (most recent call last):\r\n  File \"/usr/lib64/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib64/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/markf94/.../kedro-project/.venv/lib/python3.7/site-packages/piptools/__main__.py\", line 17, in <module>\r\n    cli()\r\n  File \"/home/markf94/.../kedro-project/.venv/lib/python3.7/site-packages/click/core.py\", line 829, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/markf94/.../kedro-project/.venv/lib/python3.7/site-packages/click/core.py\", line 782, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/markf94/.../kedro-project/.venv/lib/python3.7/site-packages/click/core.py\", line 1259, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/home/markf94/.../kedro-project/.venv/lib/python3.7/site-packages/click/core.py\", line 1066, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/markf94.../kedro-project/.venv/lib/python3.7/site-packages/click/core.py\", line 610, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"/home/markf94/.../kedro-project/.venv/lib/python3.7/site-packages/click/decorators.py\", line 21, in new_func\r\n    return f(get_current_context(), *args, **kwargs)\r\n  File \"/home/markf94/.../kedro-project/.venv/lib/python3.7/site-packages/piptools/scripts/compile.py\", line 304, in cli\r\n    for ireq in filter(is_pinned_requirement, ireqs):\r\n  File \"/home/markf94/.../kedro-project/.venv/lib/python3.7/site-packages/piptools/utils.py\", line 122, in is_pinned_requirement\r\n    if ireq.editable:\r\nAttributeError: 'ParsedRequirement' object has no attribute 'editable'\r\n```\r\n\r\n## My Environment\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): `0.15.9`\r\n* Python version used (`python -V`): `3.7.5`\r\n* Pip version used: `20.1`\r\n* Operating system and version: Fedora 31\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/371", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/371/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/371/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/371/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/371", "id": 618426529, "node_id": "MDU6SXNzdWU2MTg0MjY1Mjk=", "number": 371, "title": "Versioning datasets in catalog.yml with flexible naming", "user": {"login": "zhangchi1", "id": 16889847, "node_id": "MDQ6VXNlcjE2ODg5ODQ3", "avatar_url": "https://avatars2.githubusercontent.com/u/16889847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangchi1", "html_url": "https://github.com/zhangchi1", "followers_url": "https://api.github.com/users/zhangchi1/followers", "following_url": "https://api.github.com/users/zhangchi1/following{/other_user}", "gists_url": "https://api.github.com/users/zhangchi1/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangchi1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangchi1/subscriptions", "organizations_url": "https://api.github.com/users/zhangchi1/orgs", "repos_url": "https://api.github.com/users/zhangchi1/repos", "events_url": "https://api.github.com/users/zhangchi1/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangchi1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-14T17:53:57Z", "updated_at": "2020-05-28T08:49:14Z", "closed_at": "2020-05-28T08:49:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI recently read this page about versioning my data sets in the data catalog yaml file: https://kedro.readthedocs.io/en/latest/04_user_guide/04_data_catalog.html#versioning-datasets-and-ml-models. \r\n```\r\nConsider the following versioned dataset defined in the catalog.yml:\r\n\r\ncars.csv:\r\n  type: pandas.CSVDataSet\r\n  filepath: data/01_raw/company/cars.csv\r\n  versioned: True\r\nThe DataCatalog will create a versioned CSVDataSet called cars.csv. The actual csv file location will look like data/01_raw/company/cars.csv/<version>/cars.csv, where <version> corresponds to a global save version string formatted as YYYY-MM-DDThh.mm.ss.sssZ.\r\n```\r\nIt seems like the folder name before the <version> mush match with the file name, which in this case is \"cars.csv\". I am wondering is it possible to get rid of the \"cars.csv\" folder before the <version> folder in the catalog yaml file?\r\n\r\n## Context\r\nLet's say I am want to upload my pandas data as a csv file to s3 bucket:\r\n```\r\nmy_data_1:\r\n  type: pandas.CSVDataSet\r\n  filepath: s3://mypath/my_data_1.csv\r\n  versioned: True\r\n```\r\nAnd I want to the actual csv file location be `s3://mypath/<version>/my_data_1.csv` instead of `s3://mypath/my_data_1.csv/<version>/my_data_1.csv`. \r\nBasically, I want to group my data sets by versions.\r\nFor example, when I have another data set that I want to upload to s3 bucket:\r\n```\r\nmy_data_2:\r\n  type: pandas.CSVDataSet\r\n  filepath: s3://mypath/my_data_2.csv\r\n  versioned: True\r\n```\r\nI want my two data sets `my_data_1` and `my_data_2` located under the same version directory: `s3://mypath/<version>/`. \r\nIn general, a versioning file path like `data/01_raw/company/cars.csv/<version>/cars.csv` is not so friendly to read. Because most of my teammates prefer the highest group level be the version, when we run the kedro pipeline. \r\n\r\n\r\n## Questions\r\nIs there a way to remove the `.csv' folder before the <version> folder? Or can we make a flexible file path in catalog yaml?\r\n\r\nThank you so much!\r\nReally enjoy using Kedro!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/370", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/370/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/370/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/370/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/370", "id": 618211529, "node_id": "MDU6SXNzdWU2MTgyMTE1Mjk=", "number": 370, "title": "How can I run my pipeline programmatically after I packaged my project?", "user": {"login": "f-istvan", "id": 6824597, "node_id": "MDQ6VXNlcjY4MjQ1OTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/6824597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/f-istvan", "html_url": "https://github.com/f-istvan", "followers_url": "https://api.github.com/users/f-istvan/followers", "following_url": "https://api.github.com/users/f-istvan/following{/other_user}", "gists_url": "https://api.github.com/users/f-istvan/gists{/gist_id}", "starred_url": "https://api.github.com/users/f-istvan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/f-istvan/subscriptions", "organizations_url": "https://api.github.com/users/f-istvan/orgs", "repos_url": "https://api.github.com/users/f-istvan/repos", "events_url": "https://api.github.com/users/f-istvan/events{/privacy}", "received_events_url": "https://api.github.com/users/f-istvan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "limdauto", "id": 2032984, "node_id": "MDQ6VXNlcjIwMzI5ODQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2032984?v=4", "gravatar_id": "", "url": "https://api.github.com/users/limdauto", "html_url": "https://github.com/limdauto", "followers_url": "https://api.github.com/users/limdauto/followers", "following_url": "https://api.github.com/users/limdauto/following{/other_user}", "gists_url": "https://api.github.com/users/limdauto/gists{/gist_id}", "starred_url": "https://api.github.com/users/limdauto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/limdauto/subscriptions", "organizations_url": "https://api.github.com/users/limdauto/orgs", "repos_url": "https://api.github.com/users/limdauto/repos", "events_url": "https://api.github.com/users/limdauto/events{/privacy}", "received_events_url": "https://api.github.com/users/limdauto/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "limdauto", "id": 2032984, "node_id": "MDQ6VXNlcjIwMzI5ODQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2032984?v=4", "gravatar_id": "", "url": "https://api.github.com/users/limdauto", "html_url": "https://github.com/limdauto", "followers_url": "https://api.github.com/users/limdauto/followers", "following_url": "https://api.github.com/users/limdauto/following{/other_user}", "gists_url": "https://api.github.com/users/limdauto/gists{/gist_id}", "starred_url": "https://api.github.com/users/limdauto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/limdauto/subscriptions", "organizations_url": "https://api.github.com/users/limdauto/orgs", "repos_url": "https://api.github.com/users/limdauto/repos", "events_url": "https://api.github.com/users/limdauto/events{/privacy}", "received_events_url": "https://api.github.com/users/limdauto/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2020-05-14T13:00:44Z", "updated_at": "2020-05-20T09:58:30Z", "closed_at": "2020-05-20T09:58:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "I ran `kedro package` and distributed my kedro project. Now, when I do a `pip install my_procejt` I get the package but the question is how can I run my pipeline from an external `.py` script. What should I import to my external python file and how can I run my pipeline?\r\n\r\nBased on the generated `kedro_cli.py` I tried this (my_external_runner_script.py):\r\n\r\n```\r\nfrom kedro.runner import SequentialRunner\r\nfrom kedro.context import load_context\r\nfrom pathlib import Path\r\n\r\ndef run(\r\n    tag=None,\r\n    env=None,\r\n    runner=SequentialRunner,\r\n    node_names=(),\r\n    to_nodes=[],\r\n    from_nodes=[],\r\n    from_inputs=[],\r\n    load_version={},\r\n    pipeline=None,\r\n    config=None,\r\n    params={},\r\n):\r\n\r\n    context = load_context(Path.cwd(), env=env, extra_params=params)\r\n    context.run(\r\n        tags=tag,\r\n        runner=runner(),\r\n        node_names=node_names,\r\n        from_nodes=from_nodes,\r\n        to_nodes=to_nodes,\r\n        from_inputs=from_inputs,\r\n        load_versions=load_version,\r\n        pipeline_name=pipeline,\r\n    )\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    run()\r\n```\r\n\r\nThe `Path.cwd()` is obviously wrong in this case. I could not find any info about this in the documentation?\r\n\r\nCould you please give me a hint how to do this?\r\n\r\nThank you,\r\nStefan", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/369", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/369/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/369/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/369/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/369", "id": 617745394, "node_id": "MDU6SXNzdWU2MTc3NDUzOTQ=", "number": 369, "title": "Versioning datasets in catalog.yml with flexible naming", "user": {"login": "zhangchi1", "id": 16889847, "node_id": "MDQ6VXNlcjE2ODg5ODQ3", "avatar_url": "https://avatars2.githubusercontent.com/u/16889847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangchi1", "html_url": "https://github.com/zhangchi1", "followers_url": "https://api.github.com/users/zhangchi1/followers", "following_url": "https://api.github.com/users/zhangchi1/following{/other_user}", "gists_url": "https://api.github.com/users/zhangchi1/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangchi1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangchi1/subscriptions", "organizations_url": "https://api.github.com/users/zhangchi1/orgs", "repos_url": "https://api.github.com/users/zhangchi1/repos", "events_url": "https://api.github.com/users/zhangchi1/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangchi1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-13T20:49:37Z", "updated_at": "2020-05-14T17:54:06Z", "closed_at": "2020-05-14T17:54:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI recently read this page about versioning my data sets in the data catalog yaml file: https://kedro.readthedocs.io/en/latest/04_user_guide/04_data_catalog.html#versioning-datasets-and-ml-models. \r\n```\r\nConsider the following versioned dataset defined in the catalog.yml:\r\n\r\ncars.csv:\r\n  type: pandas.CSVDataSet\r\n  filepath: data/01_raw/company/cars.csv\r\n  versioned: True\r\nThe DataCatalog will create a versioned CSVDataSet called cars.csv. The actual csv file location will look like data/01_raw/company/cars.csv/<version>/cars.csv, where <version> corresponds to a global save version string formatted as YYYY-MM-DDThh.mm.ss.sssZ.\r\n```\r\nIt seems like the folder name before the <version> mush match with the file name, which in this case is \"cars.csv\". I am wondering is it possible to get rid of the \"cars.csv\" folder before the <version> folder in the catalog yaml file?\r\n\r\n## Context\r\nLet's say I am want to upload my pandas data as a csv file to s3 bucket:\r\n```\r\nmy_data_1:\r\n  type: pandas.CSVDataSet\r\n  filepath: s3://mypath/my_data_1.csv\r\n  versioned: True\r\n```\r\nAnd I want to the actual csv file location be `s3://mypath/<version>/my_data_1.csv` instead of `s3://mypath/my_data_1.csv/<version>/my_data_1.csv`. \r\nBasically, I want to group my data sets by versions.\r\nFor example, when I have another data set that I want to upload to s3 bucket:\r\n```\r\nmy_data_2:\r\n  type: pandas.CSVDataSet\r\n  filepath: s3://mypath/my_data_2.csv\r\n  versioned: True\r\n```\r\nI want my two data sets `my_data_1` and `my_data_2` located under the same version directory: `s3://mypath/<version>/`. \r\nIn general, a versioning file path like `data/01_raw/company/cars.csv/<version>/cars.csv` is not so friendly to read. Because most of my teammates prefer the highest group level be the version, when we run the kedro pipeline. \r\n\r\n\r\n## Possible Implementation\r\nIs there a way to remove the `.csv' folder before the <version> folder? Or can we make a flexible file path in catalog yaml?\r\n\r\nThank you so much!\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/368", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/368/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/368/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/368/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/368", "id": 616909036, "node_id": "MDU6SXNzdWU2MTY5MDkwMzY=", "number": 368, "title": "Integrate docstring linting", "user": {"login": "fkromer", "id": 10199742, "node_id": "MDQ6VXNlcjEwMTk5NzQy", "avatar_url": "https://avatars1.githubusercontent.com/u/10199742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fkromer", "html_url": "https://github.com/fkromer", "followers_url": "https://api.github.com/users/fkromer/followers", "following_url": "https://api.github.com/users/fkromer/following{/other_user}", "gists_url": "https://api.github.com/users/fkromer/gists{/gist_id}", "starred_url": "https://api.github.com/users/fkromer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fkromer/subscriptions", "organizations_url": "https://api.github.com/users/fkromer/orgs", "repos_url": "https://api.github.com/users/fkromer/repos", "events_url": "https://api.github.com/users/fkromer/events{/privacy}", "received_events_url": "https://api.github.com/users/fkromer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-12T19:37:50Z", "updated_at": "2020-05-28T15:28:08Z", "closed_at": "2020-05-28T15:28:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nI'm always frustrated when I create the docs with `kedro build-docs` and recognize that I missed or messed docstrings up later.\r\n\r\n## Context\r\n\r\nThis feature would save a lot of time in case you want to build your docs and do not want to integrate pydocstyle yourself on every new project.\r\n\r\n## Possible Implementation\r\n\r\nIntegration of [pydocstyle](http://www.pydocstyle.org/en/5.0.1/) with `kedro lint`. pydocstyle supports [`pep257`, `numpy`, `google` style docstrings](http://www.pydocstyle.org/en/5.0.1/usage.html#cli-usage).\r\n\r\n## Possible Alternatives\r\n\r\n- [flake8-docstrings](https://pypi.org/project/flake8-docstrings/) - A simple module that adds an extension for the fantastic pydocstyle tool to flake8.\r\n\r\nComplements with:\r\n\r\n- [flake8-spellcheck](https://pypi.org/project/flake8-spellcheck/) - Spellcheck variables, comments and docstrings.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/366", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/366/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/366/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/366/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/366", "id": 615632490, "node_id": "MDU6SXNzdWU2MTU2MzI0OTA=", "number": 366, "title": "Standardize legal headers and `LICENSE.md`", "user": {"login": "deepyaman", "id": 14007150, "node_id": "MDQ6VXNlcjE0MDA3MTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/14007150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepyaman", "html_url": "https://github.com/deepyaman", "followers_url": "https://api.github.com/users/deepyaman/followers", "following_url": "https://api.github.com/users/deepyaman/following{/other_user}", "gists_url": "https://api.github.com/users/deepyaman/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepyaman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepyaman/subscriptions", "organizations_url": "https://api.github.com/users/deepyaman/orgs", "repos_url": "https://api.github.com/users/deepyaman/repos", "events_url": "https://api.github.com/users/deepyaman/events{/privacy}", "received_events_url": "https://api.github.com/users/deepyaman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-11T06:45:31Z", "updated_at": "2020-05-15T15:06:17Z", "closed_at": "2020-05-15T15:06:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n`legal_header.txt` (and the corresponding legal headers on top of source files) has nonstandard indentation on [line 22](https://github.com/quantumblacklabs/kedro/blob/d2d5ca1804d8a5b1d4ea2fe67ac09732e92956dc/legal_header.txt#L22) (middle line below):\r\n\r\n```python\r\n# Trademarks or any confusingly similar mark as a trademark for your product,\r\n#     or use the QuantumBlack Trademarks in any other manner that might cause\r\n# confusion in the marketplace, including but not limited to in advertising,\r\n```\r\n\r\nUpon further investigation, this line isn't indented in `LICENSE.md`, but the Apache link is: https://github.com/quantumblacklabs/kedro/blob/d2d5ca1804d8a5b1d4ea2fe67ac09732e92956dc/LICENSE.md#L7\r\n\r\n## Context\r\nWhy is this change important to you? How would you use it? How can it benefit other users?\r\n\r\nOther users can sleep easy at night, no longer haunted by the fact that a random line is over-indented.\r\n\r\nIssue also applies to https://github.com/quantumblacklabs/kedro-viz, https://github.com/quantumblacklabs/causalnex, etc.\r\n\r\n## Possible Implementation\r\nSee #365 \r\n\r\n## Possible Alternatives\r\nYou can still keep `legal_header.txt`, if you foresee it diverging from `LICENSE.md` in the near future. I'd prefer to add it back later, if and when necessary, though.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/364", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/364/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/364/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/364/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/364", "id": 615398821, "node_id": "MDU6SXNzdWU2MTUzOTg4MjE=", "number": 364, "title": "Support for Multiple URLs by APIDataSet", "user": {"login": "Minyus", "id": 33908456, "node_id": "MDQ6VXNlcjMzOTA4NDU2", "avatar_url": "https://avatars2.githubusercontent.com/u/33908456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Minyus", "html_url": "https://github.com/Minyus", "followers_url": "https://api.github.com/users/Minyus/followers", "following_url": "https://api.github.com/users/Minyus/following{/other_user}", "gists_url": "https://api.github.com/users/Minyus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Minyus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Minyus/subscriptions", "organizations_url": "https://api.github.com/users/Minyus/orgs", "repos_url": "https://api.github.com/users/Minyus/repos", "events_url": "https://api.github.com/users/Minyus/events{/privacy}", "received_events_url": "https://api.github.com/users/Minyus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-10T14:05:26Z", "updated_at": "2020-05-19T22:57:56Z", "closed_at": "2020-05-19T22:57:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nThe provided `APIDataSet` accepts only a single URL. \r\nI'd like to request support for multiple, potentially a lot of, URLs similar to `PartitionedDataSet` interface, without being interrupted even if errors occur for some of the URLs.\r\n\r\n## Context\r\nIt is useful to get multiple contents (e.g. json, image, video, model, zip files) through API.\r\nKedro provides `PartitionedDataSet` to support multiple datasets in a dict, but cannot be used for this purpose because:\r\n\r\n- It is possible that some of the URLs return errors while the others work fine. An option to skip errors and get contents as many as possible will make sense.\r\n\r\n- It is inefficient to configure a TCP connection for every `requests.request` call. Instead, [`requests.Session`](https://requests.readthedocs.io/en/master/user/advanced/#session-objects) allows to reuse the same TCP connection to handle multiple requests in less time.\r\n\r\n## Possible Implementation\r\n1. Accept a dict of URLs similar to `PartitionedDataSet`.\r\n2. Use [`requests.Session`](https://requests.readthedocs.io/en/master/user/advanced/#session-objects) in `__init__` method.\r\n3. Use methods of the `requests.Session` object to send requests.\r\n4. Return dict of contents using the same keys as the dict of URLs. For unsuccessful requests, return Exception/response objects without raising.\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/362", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/362/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/362/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/362/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/362", "id": 614721100, "node_id": "MDU6SXNzdWU2MTQ3MjExMDA=", "number": 362, "title": "Flexibility for APIDataSet ", "user": {"login": "Minyus", "id": 33908456, "node_id": "MDQ6VXNlcjMzOTA4NDU2", "avatar_url": "https://avatars2.githubusercontent.com/u/33908456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Minyus", "html_url": "https://github.com/Minyus", "followers_url": "https://api.github.com/users/Minyus/followers", "following_url": "https://api.github.com/users/Minyus/following{/other_user}", "gists_url": "https://api.github.com/users/Minyus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Minyus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Minyus/subscriptions", "organizations_url": "https://api.github.com/users/Minyus/orgs", "repos_url": "https://api.github.com/users/Minyus/repos", "events_url": "https://api.github.com/users/Minyus/events{/privacy}", "received_events_url": "https://api.github.com/users/Minyus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-08T12:46:05Z", "updated_at": "2020-05-15T15:47:39Z", "closed_at": "2020-05-15T15:00:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nThe provided `APIDataSet` allows to use only `text` or `json()` and does not support to get binary contents.\r\n\r\n## Context\r\nGetting binary contents such as images, models, and zip files are in demand.\r\n\r\n## Possible Implementation\r\nAllow users to specify the attribute to return.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/361", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/361/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/361/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/361/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/361", "id": 614644516, "node_id": "MDU6SXNzdWU2MTQ2NDQ1MTY=", "number": 361, "title": "Incompatible python-dateutil version with Kedro Viz", "user": {"login": "flvndh", "id": 17010377, "node_id": "MDQ6VXNlcjE3MDEwMzc3", "avatar_url": "https://avatars2.githubusercontent.com/u/17010377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flvndh", "html_url": "https://github.com/flvndh", "followers_url": "https://api.github.com/users/flvndh/followers", "following_url": "https://api.github.com/users/flvndh/following{/other_user}", "gists_url": "https://api.github.com/users/flvndh/gists{/gist_id}", "starred_url": "https://api.github.com/users/flvndh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flvndh/subscriptions", "organizations_url": "https://api.github.com/users/flvndh/orgs", "repos_url": "https://api.github.com/users/flvndh/repos", "events_url": "https://api.github.com/users/flvndh/events{/privacy}", "received_events_url": "https://api.github.com/users/flvndh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-08T10:06:00Z", "updated_at": "2020-05-11T17:31:17Z", "closed_at": "2020-05-11T17:31:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Context\r\nInitializing a new Kedro project.\r\n\r\n## Environment\r\n- Windows 10\r\n- Python 3.7.7\r\n- Conda 4.7.12\r\n- Pip 20.0.2\r\n- Kedro 0.15.9\r\n\r\n## Steps to Reproduce\r\n```\r\nconda create -n removeme python=3.7\r\nconda activate removeme\r\npip install kedro==0.15.9\r\nkedro new\r\ncd new-kedro-project\r\nkedro install\r\n````\r\n\r\n```\r\nERROR: kedro-viz 3.2.0 has requirement python-dateutil==2.8.0, but you'll have python-dateutil 2.8.1 which is incompatible.\r\n```\r\n\r\n## Side Effects\r\n\r\n```\r\nkedro activate-nbstripout\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \".miniconda3/envs/removeme/lib/python3.7/site-packages/kedro/cli/cli.py\", line 594, in load_entry_points\r\n    entry_point_commands.append(entry_point.load())\r\n  File \".miniconda3/envs/removeme/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2449, in load\r\n    self.require(*args, **kwargs)\r\n  File \".miniconda3/envs/removeme/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 2472, in require\r\n    items = working_set.resolve(reqs, env, installer, extras=self.extras)\r\n  File \".miniconda3/envs/removeme/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 792, in resolve\r\n    raise VersionConflict(dist, req).with_context(dependent_req)\r\npkg_resources.VersionConflict: (python-dateutil 2.8.1 (.miniconda3/envs/removeme/lib/python3.7/site-packages), Requirement.parse('python-dateutil==2.8.0'))\r\nError: Loading global commands from kedro-viz = kedro_viz.server:commands\r\nNotebook output cells will be automatically cleared before committing to git.\r\nnbstripout --install\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/360", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/360/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/360/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/360/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/360", "id": 614568526, "node_id": "MDU6SXNzdWU2MTQ1Njg1MjY=", "number": 360, "title": "Is Kedro a good fit for data warehousing ?", "user": {"login": "flvndh", "id": 17010377, "node_id": "MDQ6VXNlcjE3MDEwMzc3", "avatar_url": "https://avatars2.githubusercontent.com/u/17010377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flvndh", "html_url": "https://github.com/flvndh", "followers_url": "https://api.github.com/users/flvndh/followers", "following_url": "https://api.github.com/users/flvndh/following{/other_user}", "gists_url": "https://api.github.com/users/flvndh/gists{/gist_id}", "starred_url": "https://api.github.com/users/flvndh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flvndh/subscriptions", "organizations_url": "https://api.github.com/users/flvndh/orgs", "repos_url": "https://api.github.com/users/flvndh/repos", "events_url": "https://api.github.com/users/flvndh/events{/privacy}", "received_events_url": "https://api.github.com/users/flvndh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-08T07:40:31Z", "updated_at": "2020-05-27T10:23:16Z", "closed_at": "2020-05-27T10:23:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI'm in the process of evaluating the pros/cons of using Kedro to build out my data warehouse pipelines using Spark.\r\n\r\nBy reading the documentation, my first impression is that Kedro is very well suited for clearly scoped data projects. I'm wondering if it is a good fit for data warehousing as the scope can grow quite large as new processes are added.\r\n\r\nHas anyone ever used Kedro in this context ? What would you recommend ?\r\n\r\nThank you for your feedback.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/359", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/359/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/359/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/359/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/359", "id": 614564942, "node_id": "MDU6SXNzdWU2MTQ1NjQ5NDI=", "number": 359, "title": "Allow CSVLocalDataSet and CSVDataSet to accept file-like object", "user": {"login": "yxw", "id": 1821645, "node_id": "MDQ6VXNlcjE4MjE2NDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/1821645?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yxw", "html_url": "https://github.com/yxw", "followers_url": "https://api.github.com/users/yxw/followers", "following_url": "https://api.github.com/users/yxw/following{/other_user}", "gists_url": "https://api.github.com/users/yxw/gists{/gist_id}", "starred_url": "https://api.github.com/users/yxw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yxw/subscriptions", "organizations_url": "https://api.github.com/users/yxw/orgs", "repos_url": "https://api.github.com/users/yxw/repos", "events_url": "https://api.github.com/users/yxw/events{/privacy}", "received_events_url": "https://api.github.com/users/yxw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-05-08T07:33:25Z", "updated_at": "2020-06-01T08:38:04Z", "closed_at": "2020-06-01T08:38:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI got `UnicodeDecodeError` when I was trying to parse a CSV file (from an external data source) where there are columns uses inconsistent character encodings.  I tried various encodings (see below) and got `UnicodeDecodeError` no matter what encoding I passed in. \r\n\r\nRather than trying to get the data provider to use a consistent encoding (It's an external data source), I would just like to read that column and discard (swallow) the bad chars. \r\n\r\n## Context\r\n\r\nThe CSV file I was trying is showed as \"Windows-1258\" as I open it in Notepad++, the text is mostly plain ASCII, except a few the \"bad chars\". \r\n\r\nI tried with `\"ascii\"`, `\"utf-8\"`, `\"utf-8-sig\"`, `\"latin1\"`, `\"windows-1258\"`, `\"ISO-8859-1\"`, etc. (basically whatever encoding I can get from SO answers for similar questions), but none of them works for me. I don't think any single encoding works here. I got `UnicodeDecodeError` no matter what encoding I passed in.\r\n\r\nIt seems it was edited with a non-UTF8 editor (probably in Excel) and contains some character that's not in UTF8.  \r\n\r\nAs I debuged, a bad line that cause the error is something looks like this:\r\n`40|Malaysia|\"Clorox\\xe2\\x80\\x9d (home cleaning products)|NA`\r\n\r\nI believe the `\\xe2\\x80\\x9d` is the \"bad char\" that cause the error. It seems like it's a special double quote, which I guess is supposed to match the leading ASCII double quote but however the person edit it might be using a special input method.\r\n\r\nI believe this kind of mixed-encoding-text-file situation is quite common in real world. Similar \"bad character\" examples (and possible solutions) are dicussed [here ](https://www.mail-archive.com/search?l=python-list@python.org&q=subject:%22Extended+ASCII%22&o=newest&f=1)and [here](https://stackoverflow.com/questions/61407331/loading-csv-file-with-binary-data-in-pandas).\r\n\r\n## Possible Implementation\r\n\r\nThe problem is, although Pandas allows to specify encoding, it does not allow to ignore errors not to automatically replace the offending bytes. However, even if Pandas has no provision for a special error processing, but Python open function has (assuming Python3), and `Pandas.read_csv` does accept a file like object. \r\n\r\nFor example, this will help me ignore the bad chars:\r\n```python\r\nwith open(filepath, encoding='utf8', errors='ignore') as fd:\r\n    pd.read_csv(fd, ...)\r\n```\r\n\r\nHowever, the current CSVLocalDataSet calls `pandas.read_csv` **BUT** assume the filepath is only a path string (even `pandas.read_csv` does accept file-like object).  \r\n\r\nA possible implementation might be allow the `filepath` parameter be a file-like object.\r\n\r\n## Possible Alternatives\r\n(Optional) Describe any alternative solutions or features you've considered.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/358", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/358/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/358/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/358/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/358", "id": 614219480, "node_id": "MDU6SXNzdWU2MTQyMTk0ODA=", "number": 358, "title": "IncrementalDataSet partition by strings contains integers", "user": {"login": "yzhu32", "id": 35809613, "node_id": "MDQ6VXNlcjM1ODA5NjEz", "avatar_url": "https://avatars2.githubusercontent.com/u/35809613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yzhu32", "html_url": "https://github.com/yzhu32", "followers_url": "https://api.github.com/users/yzhu32/followers", "following_url": "https://api.github.com/users/yzhu32/following{/other_user}", "gists_url": "https://api.github.com/users/yzhu32/gists{/gist_id}", "starred_url": "https://api.github.com/users/yzhu32/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yzhu32/subscriptions", "organizations_url": "https://api.github.com/users/yzhu32/orgs", "repos_url": "https://api.github.com/users/yzhu32/repos", "events_url": "https://api.github.com/users/yzhu32/events{/privacy}", "received_events_url": "https://api.github.com/users/yzhu32/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-07T17:21:04Z", "updated_at": "2020-05-22T14:35:19Z", "closed_at": "2020-05-22T14:35:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nThe IncrementalDataSet feature is great. However, if the partitions are a list of strings with integers: `e.g. [\"95/\", \"950/\", \"1003/\", ]`, given the current `_list_partitions()` implementation, it returns `['1003/', '95/', '950/']`, but ideally it should return `[\"95/\", \"950/\", \"1003/\"]` and save `1003/` into the checkpoint.\r\n\r\n```\r\n@lru_cache(maxsize=None)\r\n    def _list_partitions(self) -> List[str]:\r\n        checkpoint = self._read_checkpoint()\r\n        checkpoint_path = self._filesystem._strip_protocol(  # pylint: disable=protected-access\r\n            self._checkpoint_config[self._filepath_arg]\r\n        )\r\n\r\n        def _is_valid_partition(partition) -> bool:\r\n            if not partition.endswith(self._filename_suffix):\r\n                return False\r\n            if partition == checkpoint_path:\r\n                return False\r\n            if checkpoint is None:\r\n                # nothing was processed yet\r\n                return True\r\n            partition_id = self._path_to_partition(partition)\r\n            return self._comparison_func(partition_id, checkpoint)\r\n\r\n        return sorted(\r\n            part\r\n            for part in self._filesystem.find(self._normalized_path, **self._load_args)\r\n            if _is_valid_partition(part)\r\n        )\r\n```\r\n\r\n## Context\r\nThe current implementation is great if the partitions are strings like timestamp, but not correct for cases string contains integers\r\n\r\n## Possible Implementation\r\nCan use `natsort` to solve this kind of issue\r\n\r\n## Possible Alternatives\r\n(Optional) Describe any alternative solutions or features you've considered.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/355", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/355/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/355/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/355/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/355", "id": 613405618, "node_id": "MDU6SXNzdWU2MTM0MDU2MTg=", "number": 355, "title": "How can I save a Python list/dict as a json with catalog.save function from a Jupyter notebook?", "user": {"login": "f-istvan", "id": 6824597, "node_id": "MDQ6VXNlcjY4MjQ1OTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/6824597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/f-istvan", "html_url": "https://github.com/f-istvan", "followers_url": "https://api.github.com/users/f-istvan/followers", "following_url": "https://api.github.com/users/f-istvan/following{/other_user}", "gists_url": "https://api.github.com/users/f-istvan/gists{/gist_id}", "starred_url": "https://api.github.com/users/f-istvan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/f-istvan/subscriptions", "organizations_url": "https://api.github.com/users/f-istvan/orgs", "repos_url": "https://api.github.com/users/f-istvan/repos", "events_url": "https://api.github.com/users/f-istvan/events{/privacy}", "received_events_url": "https://api.github.com/users/f-istvan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-06T15:22:33Z", "updated_at": "2020-05-14T09:48:28Z", "closed_at": "2020-05-14T09:48:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "In my Jupyter notebook I want to save the following Python list into a json file:\r\n```\r\nmy_list = [\r\n    {\r\n        'a_string': 'World!',\r\n        'a_list': [1, 2, 3]\r\n    },\r\n    {\r\n        'a_string': 'World!',\r\n        'a_list': [4, 5, 6]\r\n    }\r\n]\r\n```\r\n\r\nHere is what I have in the catalog.yml:\r\n```\r\nmy_json_data:\r\n  type: kedro.io.JSONDataSet\r\n  filepath: data/02_intermediate/extended_dataset.json \r\n```\r\nAnd this is what I'm running in my Jupyter notebook:\r\n\r\n`catalog.save(\"my_json_data\", my_list )`\r\n\r\n\r\nI got the following error message:\r\n`list' object has no attribute 'to_json`\r\n\r\nI tried to convert my list to a pandas.DataFrame since it has a to_json method but the result in the `extended_dataset.json` is an indexed pandas json instead of a normal json format with json arrays:\r\n\r\n```\r\n{\"a_string\":{\"0\":\"World!\",\"1\":\"World!\"},\"a_list\":{\"0\":[1,2,3],\"1\":[4,5,6]}}\r\n```\r\n\r\nI want this as a result in the `extended_dataset.json`:\r\n```\r\n[{\r\n\t\"a_string\": \"World!\",\r\n\t\"a_list\": [1, 2, 3]\r\n}, {\r\n\t\"a_string\": \"World!\",\r\n\t\"a_list\": [4, 5, 6]\r\n}]\r\n```\r\n\r\nCould you please help me out how to achieve this?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/352", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/352/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/352/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/352/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/352", "id": 612226300, "node_id": "MDU6SXNzdWU2MTIyMjYzMDA=", "number": 352, "title": "[KED-1642] `index` option in `pandas.ParquetDataSet`", "user": {"login": "juan-carlos-calvo", "id": 54585996, "node_id": "MDQ6VXNlcjU0NTg1OTk2", "avatar_url": "https://avatars1.githubusercontent.com/u/54585996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/juan-carlos-calvo", "html_url": "https://github.com/juan-carlos-calvo", "followers_url": "https://api.github.com/users/juan-carlos-calvo/followers", "following_url": "https://api.github.com/users/juan-carlos-calvo/following{/other_user}", "gists_url": "https://api.github.com/users/juan-carlos-calvo/gists{/gist_id}", "starred_url": "https://api.github.com/users/juan-carlos-calvo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/juan-carlos-calvo/subscriptions", "organizations_url": "https://api.github.com/users/juan-carlos-calvo/orgs", "repos_url": "https://api.github.com/users/juan-carlos-calvo/repos", "events_url": "https://api.github.com/users/juan-carlos-calvo/events{/privacy}", "received_events_url": "https://api.github.com/users/juan-carlos-calvo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-04T23:11:39Z", "updated_at": "2020-05-27T09:40:29Z", "closed_at": "2020-05-27T09:39:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n`ParquetLocalDataSet` accepts the `index` save option which specifies whether to save the index in parquet or not. `pandas.ParquetDataSet` doesn't have an equivalent option at the moment.\r\n\r\n## Context\r\nAs the datasets in `kedro.io` are going to be deprecated and moved to `kedro.extras.datasets` kedro should have backward compatibility with the `load_args` `save_args` options. Also, index is a useful option to have.\r\n\r\n## Possible Implementation\r\nat the `_save` method of `pandas.ParquetDataSet` substitute:\r\n```\r\ntable = pa.Table.from_pandas(data)\r\n```\r\nwith\r\n```\r\npreserve_index = self._save_args.pop('index', False)\r\ntable = pa.Table.from_pandas(data, preserve_index=preserve_index)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/351", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/351/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/351/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/351/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/351", "id": 612160212, "node_id": "MDU6SXNzdWU2MTIxNjAyMTI=", "number": 351, "title": "Kedro viz & kedro run --parallel don't work when working with Spark", "user": {"login": "zhangchi1", "id": 16889847, "node_id": "MDQ6VXNlcjE2ODg5ODQ3", "avatar_url": "https://avatars2.githubusercontent.com/u/16889847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangchi1", "html_url": "https://github.com/zhangchi1", "followers_url": "https://api.github.com/users/zhangchi1/followers", "following_url": "https://api.github.com/users/zhangchi1/following{/other_user}", "gists_url": "https://api.github.com/users/zhangchi1/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangchi1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangchi1/subscriptions", "organizations_url": "https://api.github.com/users/zhangchi1/orgs", "repos_url": "https://api.github.com/users/zhangchi1/repos", "events_url": "https://api.github.com/users/zhangchi1/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangchi1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-04T20:51:30Z", "updated_at": "2020-05-05T13:57:11Z", "closed_at": "2020-05-05T13:57:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nKedro viz doesn't work when I follow the [Working with PySpark\r\n](https://kedro.readthedocs.io/en/stable/04_user_guide/09_pyspark.html) tutorial\r\n\r\n## Context\r\nI'd like to use Spark session in my nodes to retrieve some data from my snowflake database. So, I followed the tutorial to initialize a SparkSession under `__init__` in `run.py`. It seems like `kedro viz` doesn't like me to initialize a SparkSession  under `__init__`. I have to comment out `self.init_spark_session()` in order to run `kedro viz`. \r\n\r\nSimilarly, when I init SparkSession under `__init__` in `run.py`, I got the same error message when I run `kedro run --parallel`.\r\n\r\nWhere should I do `init_spark_session()` except in the `__init__` under, class `ProjectContext`,in `run.py`?\r\n\r\nIn addition, I am wondering what is the best practice to pass in a SparkSession in my nodes? What I did is to add a parameter in the `create_pipelines` method: \r\n`create_pipelines(spark: SparkSession, **kwargs)`\r\n\r\n## Steps to Reproduce\r\n1. Follow the [Working with PySpark\r\n](https://kedro.readthedocs.io/en/stable/04_user_guide/09_pyspark.html) tutorial\r\n2. Run `kedro viz` under terminal\r\n\r\n## Actual Result\r\nRunning `Kedro viz` or `kedro run --parallel` will give us the error message: \r\n`Error: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.`\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.15.9\r\n* Python version used (`python -V`): 3.6.6\r\n* Operating system and version: Mac OS\r\n* Spark: 2.4.4\r\n\r\n~~ Thank you so much for the help! Kedro is an awesome ML framework!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/349", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/349/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/349/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/349/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/349", "id": 611735315, "node_id": "MDU6SXNzdWU2MTE3MzUzMTU=", "number": 349, "title": "[KED-1619] parameters.yaml configuration reference", "user": {"login": "fkromer", "id": 10199742, "node_id": "MDQ6VXNlcjEwMTk5NzQy", "avatar_url": "https://avatars1.githubusercontent.com/u/10199742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fkromer", "html_url": "https://github.com/fkromer", "followers_url": "https://api.github.com/users/fkromer/followers", "following_url": "https://api.github.com/users/fkromer/following{/other_user}", "gists_url": "https://api.github.com/users/fkromer/gists{/gist_id}", "starred_url": "https://api.github.com/users/fkromer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fkromer/subscriptions", "organizations_url": "https://api.github.com/users/fkromer/orgs", "repos_url": "https://api.github.com/users/fkromer/repos", "events_url": "https://api.github.com/users/fkromer/events{/privacy}", "received_events_url": "https://api.github.com/users/fkromer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-04T09:35:49Z", "updated_at": "2020-06-02T08:49:12Z", "closed_at": "2020-06-02T08:49:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'd like to understand what valid entries in `parameters.yaml` files are. Searching the kedro docs did not provide the info I was looking for. Is related to https://github.com/quantumblacklabs/kedro/issues/344 .", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/347", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/347/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/347/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/347/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/347", "id": 611711339, "node_id": "MDU6SXNzdWU2MTE3MTEzMzk=", "number": 347, "title": "Provide an ubuntu package", "user": {"login": "fkromer", "id": 10199742, "node_id": "MDQ6VXNlcjEwMTk5NzQy", "avatar_url": "https://avatars1.githubusercontent.com/u/10199742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fkromer", "html_url": "https://github.com/fkromer", "followers_url": "https://api.github.com/users/fkromer/followers", "following_url": "https://api.github.com/users/fkromer/following{/other_user}", "gists_url": "https://api.github.com/users/fkromer/gists{/gist_id}", "starred_url": "https://api.github.com/users/fkromer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fkromer/subscriptions", "organizations_url": "https://api.github.com/users/fkromer/orgs", "repos_url": "https://api.github.com/users/fkromer/repos", "events_url": "https://api.github.com/users/fkromer/events{/privacy}", "received_events_url": "https://api.github.com/users/fkromer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-04T08:57:21Z", "updated_at": "2020-05-05T11:30:59Z", "closed_at": "2020-05-05T11:30:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\n`kedro` allows users to encapsulate projects into `Docker` containers with `kedro-docker`. This means for running a `kedro` project `kedro` and `kedro` plugins are the only Python package dependencies in the OS, user or virtualenv (project) level.\r\n\r\n## Context\r\n\r\nIf `kedro` would be available as package for Ubuntu (snap, flatpak) users would not have to care about this Python runtime dependency at all.\r\n\r\n## Possible Implementation\r\n\r\nUbuntu: snap, flatpak\r\n\r\nI've created an [experimental snap](https://github.com/fkromer/snap-kedro) which works quite well.\r\n\r\n## Possible Alternatives\r\n\r\n?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/345", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/345/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/345/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/345/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/345", "id": 611472392, "node_id": "MDU6SXNzdWU2MTE0NzIzOTI=", "number": 345, "title": "[KED-1629] Enable caching for all datasets in the `DataCatalog`", "user": {"login": "tsanikgr", "id": 3808292, "node_id": "MDQ6VXNlcjM4MDgyOTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/3808292?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tsanikgr", "html_url": "https://github.com/tsanikgr", "followers_url": "https://api.github.com/users/tsanikgr/followers", "following_url": "https://api.github.com/users/tsanikgr/following{/other_user}", "gists_url": "https://api.github.com/users/tsanikgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/tsanikgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tsanikgr/subscriptions", "organizations_url": "https://api.github.com/users/tsanikgr/orgs", "repos_url": "https://api.github.com/users/tsanikgr/repos", "events_url": "https://api.github.com/users/tsanikgr/events{/privacy}", "received_events_url": "https://api.github.com/users/tsanikgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-03T18:10:44Z", "updated_at": "2020-06-19T08:03:56Z", "closed_at": "2020-06-19T08:03:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nThe `CachedDataset` enables caching of data on memory instead of loading from disk/network after the first load/save, and can save a lot of time if some datasets are loaded multiple times in a single run.\r\n\r\nDeclaring all datasets in the data catalog as `CachedDatasets` is very verbose, and need manual work to check what is used more than once, so I typically do this in code.\r\n\r\nIt would be nice if we could enable/disable caching on the `DataCatalog` level.\r\n\r\n## Context\r\nPerformance and less verbose code.\r\n\r\n## Possible Implementation\r\nA possible implementation is presented in #346\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/344", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/344/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/344/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/344/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/344", "id": 611144585, "node_id": "MDU6SXNzdWU2MTExNDQ1ODU=", "number": 344, "title": "[KED-1619] catalog.yaml configuration reference", "user": {"login": "fkromer", "id": 10199742, "node_id": "MDQ6VXNlcjEwMTk5NzQy", "avatar_url": "https://avatars1.githubusercontent.com/u/10199742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fkromer", "html_url": "https://github.com/fkromer", "followers_url": "https://api.github.com/users/fkromer/followers", "following_url": "https://api.github.com/users/fkromer/following{/other_user}", "gists_url": "https://api.github.com/users/fkromer/gists{/gist_id}", "starred_url": "https://api.github.com/users/fkromer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fkromer/subscriptions", "organizations_url": "https://api.github.com/users/fkromer/orgs", "repos_url": "https://api.github.com/users/fkromer/repos", "events_url": "https://api.github.com/users/fkromer/events{/privacy}", "received_events_url": "https://api.github.com/users/fkromer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-05-02T09:18:52Z", "updated_at": "2020-05-26T09:13:11Z", "closed_at": "2020-05-26T09:13:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'd like to understand what valid entries in `catalog.yaml` files are. Searching the kedro docs got me to [The Data Catalog](https://kedro.readthedocs.io/en/latest/04_user_guide/04_data_catalog.html). However the docs is an example, not really a reference. I was looking for something like e.g. [GitLab's `.gitlab-ci.yml` configuration reference](https://docs.gitlab.com/ee/ci/yaml/README.html).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/343", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/343/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/343/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/343/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/343", "id": 610871688, "node_id": "MDU6SXNzdWU2MTA4NzE2ODg=", "number": 343, "title": "Keep local-only DataSets such as CSVLocalDataSet", "user": {"login": "Minyus", "id": 33908456, "node_id": "MDQ6VXNlcjMzOTA4NDU2", "avatar_url": "https://avatars2.githubusercontent.com/u/33908456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Minyus", "html_url": "https://github.com/Minyus", "followers_url": "https://api.github.com/users/Minyus/followers", "following_url": "https://api.github.com/users/Minyus/following{/other_user}", "gists_url": "https://api.github.com/users/Minyus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Minyus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Minyus/subscriptions", "organizations_url": "https://api.github.com/users/Minyus/orgs", "repos_url": "https://api.github.com/users/Minyus/repos", "events_url": "https://api.github.com/users/Minyus/events{/privacy}", "received_events_url": "https://api.github.com/users/Minyus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-01T17:34:20Z", "updated_at": "2020-05-06T13:09:13Z", "closed_at": "2020-05-06T13:09:13Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nIn the latest `develop` branch, local-only DataSets such as `CSVLocalDataSet` were removed.\r\nAlthough the generalized DataSets in `kedro.extras.datasets` such as `CSVDataSet` support local use, I'd like to request to keep the local-only DataSets to allow avoiding to use `fsspec` package.\r\n\r\n## Context\r\nSome users do not want to or cannot use `fsspec` package due to potential bugs, performance, or security issues.\r\n\r\n## Possible Implementation\r\nKeep local-only DataSets.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/342", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/342/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/342/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/342/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/342", "id": 610745623, "node_id": "MDU6SXNzdWU2MTA3NDU2MjM=", "number": 342, "title": "pandas.CSVDataset imports unnecessary packages such as google-cloud-bigquery", "user": {"login": "Minyus", "id": 33908456, "node_id": "MDQ6VXNlcjMzOTA4NDU2", "avatar_url": "https://avatars2.githubusercontent.com/u/33908456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Minyus", "html_url": "https://github.com/Minyus", "followers_url": "https://api.github.com/users/Minyus/followers", "following_url": "https://api.github.com/users/Minyus/following{/other_user}", "gists_url": "https://api.github.com/users/Minyus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Minyus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Minyus/subscriptions", "organizations_url": "https://api.github.com/users/Minyus/orgs", "repos_url": "https://api.github.com/users/Minyus/repos", "events_url": "https://api.github.com/users/Minyus/events{/privacy}", "received_events_url": "https://api.github.com/users/Minyus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-05-01T13:17:19Z", "updated_at": "2020-05-15T15:44:04Z", "closed_at": "2020-05-15T14:10:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nImporting `pandas.CSVDataset` runs unnecessary modules such as [`kedro.extras.datasets.pandas.gbq_dataset.py`](https://github.com/quantumblacklabs/kedro/blob/develop/kedro/extras/datasets/pandas/gbq_dataset.py) in addition to [`kedro.extras.datasets.pandas.csv_dataset.py`](https://github.com/quantumblacklabs/kedro/blob/develop/kedro/extras/datasets/pandas/csv_dataset.py) due to\r\n[`kedro.extras.datasets.pandas.__init__.py`](https://github.com/quantumblacklabs/kedro/blob/develop/kedro/extras/datasets/pandas/__init__.py)\r\n\r\n## Context\r\nI'm trying to use `pandas.CSVDataset`, but I get an error in google-cloud-bigquery package which is not necessary.\r\n\r\n## Steps to Reproduce\r\n1. Import `pandas.CSVDataset`\r\n\r\n## Expected Result\r\nRun only [`kedro.extras.datasets.pandas.csv_dataset.py`](https://github.com/quantumblacklabs/kedro/blob/develop/kedro/extras/datasets/pandas/csv_dataset.py)\r\n\r\n## Actual Result\r\nI get\r\n```\r\nFile \"/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/schema.py\", line 17, in <module>\r\n    from six.moves import collections_abc\r\nImportError: cannot import name 'collections_abc'\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): The latest `develop` branch (commit e2c271be3646d6c564a67960b67fb74c6ba1ece8)\r\n* Python version used (`python -V`): 3.6.8\r\n* Operating system and version: Ubuntu 18.04.3 LTS\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/341", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/341/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/341/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/341/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/341", "id": 606783352, "node_id": "MDU6SXNzdWU2MDY3ODMzNTI=", "number": 341, "title": "[KED-1667] Chronocoding: Solving the Problem of State Tracking with Temporally Sensitive DAGs", "user": {"login": "tamsanh", "id": 1330789, "node_id": "MDQ6VXNlcjEzMzA3ODk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1330789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tamsanh", "html_url": "https://github.com/tamsanh", "followers_url": "https://api.github.com/users/tamsanh/followers", "following_url": "https://api.github.com/users/tamsanh/following{/other_user}", "gists_url": "https://api.github.com/users/tamsanh/gists{/gist_id}", "starred_url": "https://api.github.com/users/tamsanh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tamsanh/subscriptions", "organizations_url": "https://api.github.com/users/tamsanh/orgs", "repos_url": "https://api.github.com/users/tamsanh/repos", "events_url": "https://api.github.com/users/tamsanh/events{/privacy}", "received_events_url": "https://api.github.com/users/tamsanh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-25T14:41:00Z", "updated_at": "2020-07-20T11:56:11Z", "closed_at": "2020-07-20T11:56:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Introduction\r\n> A high-level, short overview of the problem(s) you are designing a solution for \r\n\r\nIn an ideal world, where limits in compute and I/O don't exist, I think kedro is the perfect framework for writing data pipeline systems. However, as a Data Engineer, I must face these problems constantly. In order to optimize this work, I require highly contextual related to a node's operation. However, I feel that kedro does not offer sufficient built-in utility to address this, and actively inhibits that effort by enforcing direct acyclic graph structures on our pipeline, whereas data I need is cyclic in nature. As a result, I spend extra engineering effort in order to hand-craft brittle compensation measures. However, I believe there is a straightforward solution to that addresses this problem, without sacrificing any of our values.\r\n\r\n## Background\r\n> Provide the reader with the context surrounding the problem(s) you are trying to solve.\r\n\r\nThe world is stateful and, whether we like it or not, kedro does, more often than not, eventually change world state. Unfortunately, kedro currently lacks the ability to directly access and react to the way it changes the state of the world around itself. Rather, it must instead recompute the nuances that it drives, from its dataset sources. This is a difficult task, and prompts developers to invest time into writing custom datasets which keep track of that world state, whilst simultaneously modifying. The problem with this is that, as far as I know, an acceptable standard to follow for how that tracking should be done is unclear. This leads to logic and code to write this world-state modification and tracking becoming cryptic and opaque, exacerbated by the fact that it is usually implemented behind the dataset `_save` and `_load` function calls, which are almost an after-thought when one thinks about a kedro pipeline. Given that the true power of kedro is its software engineering best practices applied by its framework, I believe that this aspect of data pipelines should also be addressed, and rather than letting them fester in the shadows, we can bring them in the open and care for them.\r\n\r\n## Problem\r\n\r\nWhat follows are two categories of real world problems that kedro engineers must face, currently not solved by kedro.\r\n\r\nPreservation of Past Work:\r\n1.1. There is a node that takes a lot of computation to output.\r\n1.2. There is an IO process that takes a lot of time to read.\r\n1.3. There are similar, independent, long-running, high-failure-rate operations.\r\n\r\nLimitation from Past Work:\r\n2.1. There is an API that has time-based call limits.\r\n2.2. There is an operation that must be called only once.\r\n\r\nThe theme with all of these that there exists data required to decide what operations to do next.\r\n\r\nFor the Preservation group, the data is regarding \u201cwhat work has been completed that I can take advantage of.\u201d\r\n\r\nFor the Limitation group, the data is regarding \u201cwhat work has been completed that I am not allowed to do.\"\r\n\r\nThe way that this is currently being solved is that these extra data bits are being loaded and stored as a side effect of the `_save` and `_load` functions. Obviously, we want to avoid this as much as possible.\r\n\r\n### Concrete Example\r\n\r\nLet's say I have a kedro pipeline that reads data from a JDBC connection, partitions it by dates, encodes it as parquet, and uploads it to a data lake. The connection to JDBC is slow, the connection to the data lake is highly prone to failure, and we are pressed for time. I decide to write a pipeline that downloads, encodes, and uploads in parallel, without overwriting its previous work.\r\n\r\nHow will it know when previous work is done? We cannot rely on the existence of the partition folder in the data lake, because if an upload failed midway, the folder would exist, but partitions inside the folder would be incomplete. We must instead have separate audit data that keeps track of the true, completed work.\r\n\r\nHow do we implement this audit data? This is where it gets tricky. Due to the atemporal DAG constraints in kedro, I cannot create a dataset in the catalog that I can use to save and load the marking data without creating two separate datasets pointing to the same file location. This is a clear hack, at the mercy of anyone who modifies the catalog.yml in the future, as well as the mechanics of the Pipeline topology sort itself.\r\n\r\nTo keep this separate, I must instead create a custom dataset that internally loads and saves the audit data on its own. This not only breaks DAG rules, but also contradicts the spirit of a DataSet, which should be limited to serialization.\r\n\r\nThus, by some measure, we must break kedro's framework in order to implement the marking data. I am not shy of breaking framework rules, when there are rare exceptions, but this use case has thus far been proven to be far from rare, and I encounter it in almost every pipeline I build.\r\n\r\n### What's not in scope\r\n\r\n1. How people design their state tracking\r\n2. What is being tracked in state\r\n\r\n## Design\r\n\r\n> Explain your design to the solution here. Diagrams could help.\r\n\r\n### Philosophy\r\n\r\nKedro is a framework for dealing with data, so why not instead accept our audit data as proper data to be considered? Philosophically, it\u2019s something that we seem to be against. \r\n\r\nAn implementation where data in the latter part of the pipeline affects data in the former breaks the idea of a proper Direct Acyclic Graph (DAG). I whole heartedly support DAGs, but I believe we may be making an assumption that is putting undue constraints on their flexibility.\r\n\r\nThat is: We have always thought of DAGs as atemporal, without time. However, I think that if we bring time into the equation, we can solve this problem.\r\n\r\nIf you think about it, this is similar to why we are already doing dataset transcoding:  it allows us to think about our data in different physical representation, to manipulate it as appropriate.\r\n\r\nWhat if we instead we created a method to allow us to think about our data in different temporal representations? I'd like to call it: chronocoding.\r\n\r\nImagine the following example, where there are three datasets, A, B, C, and that the output of C would directly affect A.\r\nOf course, this situation is untenable.\r\n\r\n```\r\n+---------------+\r\n|               |\r\nV               |\r\nA +---> B +---> C\r\n```\r\n\r\nHowever, when we consider the time dimension, the graph changes.\r\nBelow, A represents A at T (current run) while A\u2019 is A at T+1 (next run).\r\n\r\n```\r\nA +---> B +---> C +---> A'\r\n```\r\n\r\nNow, we are no longer arrested by a cyclic dependency; instead, the order of operations is still clear.\r\n\r\n### Practically\r\n\r\nWhat this means is that we would introduce a new representation of datasets in our pipelines. One that would indicating we are operating in a T+1 space.\r\n\r\nI propose that this be represented by a `!` at the end of a dataset's name, and only for output datasets. This way, a user knows that the `_save` function they are calling will be available for `_load` in the next run of the kedro pipeline.\r\n\r\nThe `!` was chosen as it is indicates the operation requires extra attention. The idea is similar to Ruby\u2019s \u201cbang methods,\u201d where instance methods that end in a `!` are modifying the instance directly. In the kedro case, we would be modifying the future state of the dataset.\r\n\r\n### Application\r\nThis then allows us to very cleanly solve all the problems from above, demonstrated here with pseudo code.\r\n\r\nPreservation of Past Work:\r\n1.1. There is a node that takes a lot of computation to output.\r\n1.2. There is an IO process that takes a lot of time to read.\r\n1.3. There are similar, independent, long-running, high-failure-rate operations.\r\n\r\n```\r\nnode(big_compute, inputs=[\u201cdata\u201d, \u201ccompute_history\u201d], outputs=\u201ccompute_history!\u201d)\r\n\r\ndef big_compute(data, hist):\r\n    # filter data by hist\r\n    # compute\r\n    # calculate new history\r\n    return new_hist\r\n```\r\n\r\nLimitation from Past Work:\r\n2.1. There is an API that has time-based call limits.\r\n2.2. There is an operation that must be called only once.\r\n\r\n```\r\nnode(limited_call, inputs=[\u201cpayload\u201d, \u201ccall_history\u201d], outputs=\u201ccall_history!\u201d)\r\n\r\ndef limited_call(payload, hist):\r\n    # compare history with threshold\r\n    # operate or not, based on comparison\r\n    return new_hist\r\n```\r\n\r\nThis very clearly brings our side-affecting code right out in the open, pulling them into kedro itself. The historical metadata can then take advantage of all that kedro has to offer, in terms of datasets, without requiring any additional syntax magic.\r\n\r\nThus, datasets can go back to focusing on what they do best, which is the serialization of data, and nodes can now do more of what they do best, which is the computation and operations on the data, all the while making it so much easier to test exactly what effect will the temporal state have on our computations.\r\n\r\nThus, we fully take advantage of all the benefits kedro currently celebrates, while cleanly introducing functionality to support workflows that would otherwise would be implemented sub-optimally.\r\n\r\n### Alternatives considered\r\n\r\n> Explain the trade off between different alternatives to your solution.\r\n\r\n#### IncrementalDataSet\r\n\r\nThe obvious alternative here is the `IncrementalDataSet`, which I believe is an excellent solution for addressing incrementally updated data, but not all data is incremental in nature.\r\n\r\nThis also brings up another question around whether or not the kedro team wants to address the unmentioned natures of data.\r\n\r\n#### Confirms\r\n\r\nThe other alternative is to override the `confirms` method on custom datasets. Indeed, it is an indirect way of reaching back up the pipeline, to hand off information to previous nodes in order to inform future runs.\r\n\r\nHowever, the issue is that `confirms` function ends up being removed from the actual operations we wish to track, and as a result loses the critical pieces of the context puzzle we wish to track.\r\n\r\nIt also pushes our data filtering back behind \"closed doors,\" hidden away in dataset operations, where they will eventually cause problems.\r\n\r\n#### Manual Additions to `catalog.yml`\r\n\r\nThis works well, but meticulous care must be taken to ensure sure that:\r\n\r\n1. The filepaths for chronocoded datasets are the same.\r\n2. The topology is valid.\r\n\r\nWhich doesn't seem like a lot, but even for a small pipeline, it can get tedious.\r\n\r\n## Testing\r\n\r\n> Explain the testing strategies to verify your design correctness (if possible).\r\n\r\nWe just need to test that the new syntax is picked up by the Pipeline and runners.\r\n\r\n## Rollout strategy\r\n\r\n> Is the change backward compatible? If not, what is the migration strategy?\r\n\r\nYes, fully backward compatible, as long as nobody has an `!` at the end of their datasets.\r\n\r\nWe must also continue to enforce the uniqueness of an output, i.e. two nodes may not output to the same dataset, regardless of its temporality.\r\n\r\nWe must also take into account the topological sort of this new time dimension.\r\n\r\n## Future iterations\r\n\r\n> Will there be future iterations of this design?\r\n\r\nIt\u2019s possible that chronocoded datasets will require configuration that is separate to the present dataset. We may need to implement transcoding on top of chronocoding, but I can't think of a true use case for it at this time.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/340", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/340/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/340/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/340/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/340", "id": 606383219, "node_id": "MDU6SXNzdWU2MDYzODMyMTk=", "number": 340, "title": "kedro install fails", "user": {"login": "f-istvan", "id": 6824597, "node_id": "MDQ6VXNlcjY4MjQ1OTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/6824597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/f-istvan", "html_url": "https://github.com/f-istvan", "followers_url": "https://api.github.com/users/f-istvan/followers", "following_url": "https://api.github.com/users/f-istvan/following{/other_user}", "gists_url": "https://api.github.com/users/f-istvan/gists{/gist_id}", "starred_url": "https://api.github.com/users/f-istvan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/f-istvan/subscriptions", "organizations_url": "https://api.github.com/users/f-istvan/orgs", "repos_url": "https://api.github.com/users/f-istvan/repos", "events_url": "https://api.github.com/users/f-istvan/events{/privacy}", "received_events_url": "https://api.github.com/users/f-istvan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-24T15:06:51Z", "updated_at": "2020-04-24T15:23:21Z", "closed_at": "2020-04-24T15:23:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nRunning `$ kedro install` fails with:\r\n\r\n```\r\nUsage: kedro [OPTIONS] COMMAND [ARGS]...\r\nTry 'kedro -h' for help.\r\n\r\nError: No such command 'install'.\r\n```\r\n\r\n## Environment\r\n$ python --version\r\n`Python 3.6.6`\r\n\r\n\r\n$ kedro info\r\n```\r\n _            _\r\n| | _____  __| |_ __ ___\r\n| |/ / _ \\/ _` | '__/ _ \\\r\n|   <  __/ (_| | | | (_) |\r\n|_|\\_\\___|\\__,_|_|  \\___/\r\nv0.15.9\r\n\r\nkedro allows teams to create analytics\r\nprojects. It is developed as part of\r\nthe Kedro initiative at QuantumBlack.\r\n\r\nNo plugins installed\r\n```\r\n\r\nThank you for the answers!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/338", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/338/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/338/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/338/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/338", "id": 605057979, "node_id": "MDU6SXNzdWU2MDUwNTc5Nzk=", "number": 338, "title": "[KED-1569] Documentation as PDF or ePub", "user": {"login": "jahas", "id": 27009677, "node_id": "MDQ6VXNlcjI3MDA5Njc3", "avatar_url": "https://avatars1.githubusercontent.com/u/27009677?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jahas", "html_url": "https://github.com/jahas", "followers_url": "https://api.github.com/users/jahas/followers", "following_url": "https://api.github.com/users/jahas/following{/other_user}", "gists_url": "https://api.github.com/users/jahas/gists{/gist_id}", "starred_url": "https://api.github.com/users/jahas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jahas/subscriptions", "organizations_url": "https://api.github.com/users/jahas/orgs", "repos_url": "https://api.github.com/users/jahas/repos", "events_url": "https://api.github.com/users/jahas/events{/privacy}", "received_events_url": "https://api.github.com/users/jahas/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-22T20:39:37Z", "updated_at": "2020-05-14T09:49:45Z", "closed_at": "2020-05-14T09:49:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi guys,\r\n\r\nI really appreciate your work. I will take a deep look at your work later, but now I'd like to read documentation :)\r\n\r\nCould you please activate building documentation to PDF or ePub at readthedocs ?\r\nIt would be nice, I could read it at Kindle device then.\r\n\r\nThank you in advance!\r\nAdam", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/337", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/337/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/337/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/337/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/337", "id": 604900043, "node_id": "MDU6SXNzdWU2MDQ5MDAwNDM=", "number": 337, "title": "[KED-1634] Improve DataSetNotFoundError: messages for typos (did you mean)", "user": {"login": "WaylonWalker", "id": 22648375, "node_id": "MDQ6VXNlcjIyNjQ4Mzc1", "avatar_url": "https://avatars1.githubusercontent.com/u/22648375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaylonWalker", "html_url": "https://github.com/WaylonWalker", "followers_url": "https://api.github.com/users/WaylonWalker/followers", "following_url": "https://api.github.com/users/WaylonWalker/following{/other_user}", "gists_url": "https://api.github.com/users/WaylonWalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaylonWalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaylonWalker/subscriptions", "organizations_url": "https://api.github.com/users/WaylonWalker/orgs", "repos_url": "https://api.github.com/users/WaylonWalker/repos", "events_url": "https://api.github.com/users/WaylonWalker/events{/privacy}", "received_events_url": "https://api.github.com/users/WaylonWalker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-22T16:38:23Z", "updated_at": "2020-05-06T13:00:59Z", "closed_at": "2020-05-06T11:51:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nI'm always frustrated when I get a DataSetNotFoundError: for typos. Would it be possible to look at the catalog for similarly named entries and suggest them similar to [click-didyoumean](https://github.com/click-contrib/click-didyoumean)\r\n\r\n\r\n## Context\r\nMostly when ad-hoc loading dataset its sometimes hard to remember long dataset names.  It would be helpful if kedro could suggest the correct spelling if I miss it by a few characters.\r\n\r\n## Possible Implementation\r\n(Optional) Suggest an idea for implementing the addition or change.\r\n\r\n```diff\r\n ---------------------------------------------------------------------------\r\nDataSetNotFoundError                      Traceback (most recent call last)\r\n<ipython-input-22-0b55c03ca6c5> in <module>\r\n ----> 1 catalog.load(\"raw_C\")\r\n/path/to/data_catalog.py in load(self, name, version)\r\n    347         if name not in self._data_sets:\r\n    348             raise DataSetNotFoundError(\r\n--> 349                 \"DataSet '{}' not found in the catalog\".format(name)\r\n    350             )\r\n    351\r\n- DataSetNotFoundError: DataSet 'raw_C' not found in the catalog\r\n+ DataSetNotFoundError: DataSet 'raw_C' not found in the catalog\r\n+    did you mean 'raw_c'?\r\n```\r\n## Possible Alternatives\r\nLet me know if this should be combined with #336 \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/336", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/336/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/336/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/336/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/336", "id": 604896218, "node_id": "MDU6SXNzdWU2MDQ4OTYyMTg=", "number": 336, "title": "[KED-1635] Improve DataSetNotFoundError: messages for MemoryDataSets", "user": {"login": "WaylonWalker", "id": 22648375, "node_id": "MDQ6VXNlcjIyNjQ4Mzc1", "avatar_url": "https://avatars1.githubusercontent.com/u/22648375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaylonWalker", "html_url": "https://github.com/WaylonWalker", "followers_url": "https://api.github.com/users/WaylonWalker/followers", "following_url": "https://api.github.com/users/WaylonWalker/following{/other_user}", "gists_url": "https://api.github.com/users/WaylonWalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaylonWalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaylonWalker/subscriptions", "organizations_url": "https://api.github.com/users/WaylonWalker/orgs", "repos_url": "https://api.github.com/users/WaylonWalker/repos", "events_url": "https://api.github.com/users/WaylonWalker/events{/privacy}", "received_events_url": "https://api.github.com/users/WaylonWalker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-22T16:32:46Z", "updated_at": "2020-05-27T12:43:25Z", "closed_at": "2020-05-27T09:49:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nI'm always frustrated when I get a `DataSetNotFoundError:` for MemoryDataSets.  Would it be possible to look at pipeline.all_inputs to see if the dataset is part of the pipeline, but not in the catalog, then provide instructions to get the data loaded?\r\n\r\n## Context\r\nI like chaining many small functions together and Its not always necessary to save every step along the way, but I find myself creating a catalog entry for each node so that its not confusing for others later on.\r\n\r\n## Possible Implementation\r\nI am not sure if it is possible to access the MemoryDataSet after a pipeline run.  But if the error message could find the shortest distance between a MemoryDataSet and a catalog entry then provide some instruction to get there.\r\n\r\n\r\n**potential error message**\r\n``` diff\r\n ---------------------------------------------------------------------------\r\nDataSetNotFoundError                      Traceback (most recent call last)\r\n<ipython-input-22-0b55c03ca6c5> in <module>\r\n ----> 1 catalog.load(\"C\")\r\n/path/to/data_catalog.py in load(self, name, version)\r\n    347         if name not in self._data_sets:\r\n    348             raise DataSetNotFoundError(\r\n--> 349                 \"DataSet '{}' not found in the catalog\".format(name)\r\n    350             )\r\n    351\r\n- DataSetNotFoundError: DataSet 'C' not found in the catalog\r\n+ DataSetNotFoundError: DataSet 'C' is a MemoryDatasSet\r\n+ run(pipeline.from_inputs('B') - pipeline.to_outputs('C'), keep_memory_data_set_after_run=True)\r\n+ catalog.load('C')\r\n```\r\n\r\n## Possible Alternatives\r\nLet me know your thoughts or if anything like this would be possible.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/334", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/334/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/334/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/334/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/334", "id": 604433072, "node_id": "MDU6SXNzdWU2MDQ0MzMwNzI=", "number": 334, "title": "Path of an input instead of an input dataset", "user": {"login": "Chtchou", "id": 27629416, "node_id": "MDQ6VXNlcjI3NjI5NDE2", "avatar_url": "https://avatars0.githubusercontent.com/u/27629416?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Chtchou", "html_url": "https://github.com/Chtchou", "followers_url": "https://api.github.com/users/Chtchou/followers", "following_url": "https://api.github.com/users/Chtchou/following{/other_user}", "gists_url": "https://api.github.com/users/Chtchou/gists{/gist_id}", "starred_url": "https://api.github.com/users/Chtchou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Chtchou/subscriptions", "organizations_url": "https://api.github.com/users/Chtchou/orgs", "repos_url": "https://api.github.com/users/Chtchou/repos", "events_url": "https://api.github.com/users/Chtchou/events{/privacy}", "received_events_url": "https://api.github.com/users/Chtchou/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-22T03:51:56Z", "updated_at": "2020-06-04T03:45:13Z", "closed_at": "2020-06-04T03:45:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "For a given node, is it possible to obtain a dataset file path from the catalog? By default, if we add the name of the dataset as input it will load the dataset from the path defined in the catalog.\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/329", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/329/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/329/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/329/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/329", "id": 602472557, "node_id": "MDU6SXNzdWU2MDI0NzI1NTc=", "number": 329, "title": "[KED-1581] Add on_pipeline_error and on_node_error methods to hooks", "user": {"login": "Galileo-Galilei", "id": 29451317, "node_id": "MDQ6VXNlcjI5NDUxMzE3", "avatar_url": "https://avatars1.githubusercontent.com/u/29451317?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Galileo-Galilei", "html_url": "https://github.com/Galileo-Galilei", "followers_url": "https://api.github.com/users/Galileo-Galilei/followers", "following_url": "https://api.github.com/users/Galileo-Galilei/following{/other_user}", "gists_url": "https://api.github.com/users/Galileo-Galilei/gists{/gist_id}", "starred_url": "https://api.github.com/users/Galileo-Galilei/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Galileo-Galilei/subscriptions", "organizations_url": "https://api.github.com/users/Galileo-Galilei/orgs", "repos_url": "https://api.github.com/users/Galileo-Galilei/repos", "events_url": "https://api.github.com/users/Galileo-Galilei/events{/privacy}", "received_events_url": "https://api.github.com/users/Galileo-Galilei/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-18T14:28:16Z", "updated_at": "2020-05-11T16:48:28Z", "closed_at": "2020-05-11T16:48:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI have tried the hooks implementation described which is part of #219. It works very smoothly, but I feel that it would be nice to have a method to deal with errors which may occurs during the execution between two hooks call.\r\n\r\n## Context\r\nBy now, hooks work by calling two methods (```before_WHATEVER`` and ``after_WHATEVER``) which frame the code line they should wrap. In case this code line fails, the user does not have a proper to end a behaviour that was triggered by the ``begin_WHATEVER`` function.\r\n\r\nA typical example is in #113 : if a mlflow run is started before a pipeline call, you want to be able to close it whatever even if the pipeline fails to avoid unintended side effects  (further code execution will be logged in the current mlflow runs without any user warning)\r\n\r\n## Possible Implementation\r\nAdd a hook_spec where it fits (before the following line?)\r\nhttps://github.com/quantumblacklabs/kedro/blob/e377bd5114b68caf236fa9f4c924bf58291efa9c/kedro/hooks/specs.py#L157-L158\r\n```\r\n@hook_spec\r\n    def on_pipeline_error(\r\n        self, err, other?)\r\n    )\r\n```\r\n\r\nand adjust the following call from this :\r\n\r\nhttps://github.com/quantumblacklabs/kedro/blob/8bfa0a8ce0e3bef194ba8d4ca682becf8accdc24/kedro/context/context.py#L637-L646\r\n\r\nto this:\r\n```\r\nself._hook_manager.hook.before_pipeline_run(  # pylint: disable=no-member\r\n    run_params=record_data, pipeline=filtered_pipeline, catalog=catalog\r\n )\r\ntry:\r\n    run_result = runner.run(filtered_pipeline, catalog, run_id)\r\nexcept Exception as err:\r\n    self._hook_manager.hook.on_pipeline_error(err)\r\n    raise err\r\nself._hook_manager.hook.after_pipeline_run(  # pylint: disable=no-member\r\n        run_params=record_data,\r\n        run_result=run_result,\r\n        pipeline=filtered_pipeline,\r\n        catalog=catalog,\r\n    )\r\n```\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/325", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/325/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/325/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/325/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/325", "id": 599859693, "node_id": "MDU6SXNzdWU1OTk4NTk2OTM=", "number": 325, "title": "[KED-1455] kedro run pdb flag", "user": {"login": "d-chambers", "id": 11671536, "node_id": "MDQ6VXNlcjExNjcxNTM2", "avatar_url": "https://avatars2.githubusercontent.com/u/11671536?v=4", "gravatar_id": "", "url": "https://api.github.com/users/d-chambers", "html_url": "https://github.com/d-chambers", "followers_url": "https://api.github.com/users/d-chambers/followers", "following_url": "https://api.github.com/users/d-chambers/following{/other_user}", "gists_url": "https://api.github.com/users/d-chambers/gists{/gist_id}", "starred_url": "https://api.github.com/users/d-chambers/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/d-chambers/subscriptions", "organizations_url": "https://api.github.com/users/d-chambers/orgs", "repos_url": "https://api.github.com/users/d-chambers/repos", "events_url": "https://api.github.com/users/d-chambers/events{/privacy}", "received_events_url": "https://api.github.com/users/d-chambers/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-14T21:07:23Z", "updated_at": "2020-05-27T10:14:05Z", "closed_at": "2020-05-27T10:14:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nWhen prototyping a pipeline not everything goes right the first time. I often find myself digging through tracebacks so I can determine where to drop a `breakpoint` the I run the node/pipeline again. It would be great if `kedro run` supported a pdb flag to drop the user into an interactive debugging session when an un-handled exception surfaces.\r\n\r\npytest implements [this exact feature](https://docs.pytest.org/en/latest/usage.html#dropping-to-pdb-python-debugger-on-failures).\r\n\r\nI know kedro supports pytest for testing pipelines but in some single-use workflows spending time writing tests seems overkill as the pipeline will only ever see one dataset. \r\n\r\n## Possible Implementation\r\nUsage would be as follows:\r\n```\r\nkedro run --pdb\r\n```\r\n\r\n## Possible Alternatives\r\nI am not aware of any.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/314", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/314/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/314/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/314/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/314", "id": 594645232, "node_id": "MDU6SXNzdWU1OTQ2NDUyMzI=", "number": 314, "title": "[KED-987] Current kedro_cli behaviour should be in main kedro package", "user": {"login": "seeM", "id": 559360, "node_id": "MDQ6VXNlcjU1OTM2MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/559360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seeM", "html_url": "https://github.com/seeM", "followers_url": "https://api.github.com/users/seeM/followers", "following_url": "https://api.github.com/users/seeM/following{/other_user}", "gists_url": "https://api.github.com/users/seeM/gists{/gist_id}", "starred_url": "https://api.github.com/users/seeM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seeM/subscriptions", "organizations_url": "https://api.github.com/users/seeM/orgs", "repos_url": "https://api.github.com/users/seeM/repos", "events_url": "https://api.github.com/users/seeM/events{/privacy}", "received_events_url": "https://api.github.com/users/seeM/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-04-05T21:09:35Z", "updated_at": "2020-05-27T10:51:35Z", "closed_at": "2020-05-27T10:01:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nThe current auto-generated `kedro_cli.py` should be mostly internal to the `kedro` package, and thinly wrapped in the project's `kedro_cli.py`, for example, an import and a function call.\r\n\r\n## Context\r\nOne of the main purposes of a framework is to reduce duplication and boilerplate. The `kedro_cli.py` files are ~600 lines of code that don't really have anything to do with project-specific behaviour \u2013 they are essentially boilerplate.\r\n\r\nDjango has a similar setup with its `manage.py` importing and calling the `execute_from_command_line` function.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/313", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/313/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/313/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/313/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/313", "id": 593499770, "node_id": "MDU6SXNzdWU1OTM0OTk3NzA=", "number": 313, "title": "[KED-1358] conda install kedro", "user": {"login": "marcusinthesky", "id": 26429489, "node_id": "MDQ6VXNlcjI2NDI5NDg5", "avatar_url": "https://avatars0.githubusercontent.com/u/26429489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marcusinthesky", "html_url": "https://github.com/marcusinthesky", "followers_url": "https://api.github.com/users/marcusinthesky/followers", "following_url": "https://api.github.com/users/marcusinthesky/following{/other_user}", "gists_url": "https://api.github.com/users/marcusinthesky/gists{/gist_id}", "starred_url": "https://api.github.com/users/marcusinthesky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marcusinthesky/subscriptions", "organizations_url": "https://api.github.com/users/marcusinthesky/orgs", "repos_url": "https://api.github.com/users/marcusinthesky/repos", "events_url": "https://api.github.com/users/marcusinthesky/events{/privacy}", "received_events_url": "https://api.github.com/users/marcusinthesky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-04-03T16:28:15Z", "updated_at": "2020-04-22T14:14:50Z", "closed_at": "2020-04-22T12:39:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nAnaconda is a popular package manager for many data scientists cause of its ability to resolve non-python dependencies, like Cuda.  Many tools like MLFLOW rely heavily on anaconda in order to ensure compatibility when serving model on Databricks or Azure.  \r\n\r\n## Context\r\nMany pypi packages can be automatically compiled to be install as conda packages using `conda skeleton python kedro`, `conda convert --platform all /path/to/package/` and `conda upload `path/to/package/`.  For kedro this fails, as the pypi .tar.gz does not have the test_requirements.txt. \r\n\r\nI have made a workaround by building specifically from the GitHub repo, which I have made [availible](https://anaconda.org/marcusgawronsky/kedro). \r\n\r\n## Possible Implementation\r\nChange what is uploaded to pypi to ensure the test_requirements.txt is uploaded.  \r\n\r\n## Possible Alternatives\r\nmeta.yml\r\n```\r\n{% set name = \"kedro\" %}\r\n{% set version = \"0.15.8\" %}\r\n\r\npackage:\r\n  name: \"{{ name|lower }}\"\r\n  version: \"{{ version }}\"\r\n\r\nsource:\r\n  git_rev: 0.15.8\r\n  git_url: https://github.com/quantumblacklabs/kedro.git\r\n\r\nbuild:\r\n  number: 0\r\n  script: \"{{ PYTHON }} -m pip install . --no-deps --ignore-installed -vv \"\r\n\r\nrequirements:\r\n  host:\r\n    - pip\r\n    - python\r\n  run:\r\n    - python\r\n\r\ntest:\r\n  imports:\r\n    - kedro\r\n\r\nabout:\r\n  home: \"https://kedro.readthedocs.io/\"\r\n  license: \"BSD\"\r\n  license_family: \"APACHE\"\r\n  license_file: \"LICENSE.md\"\r\n  summary: \"A Python library that implements software engineering best-practice for data and ML pipelines.\"\r\n  doc_url: \"https://kedro.readthedocs.io/\"\r\n  dev_url: \"https://github.com/quantumblacklabs/kedro/tree/develop\"\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/311", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/311/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/311/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/311/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/311", "id": 593233261, "node_id": "MDU6SXNzdWU1OTMyMzMyNjE=", "number": 311, "title": "[KED-1545] Create a Matplotlib Writer that supports versioning", "user": {"login": "TomaszKaczmarczyk", "id": 61749227, "node_id": "MDQ6VXNlcjYxNzQ5MjI3", "avatar_url": "https://avatars0.githubusercontent.com/u/61749227?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomaszKaczmarczyk", "html_url": "https://github.com/TomaszKaczmarczyk", "followers_url": "https://api.github.com/users/TomaszKaczmarczyk/followers", "following_url": "https://api.github.com/users/TomaszKaczmarczyk/following{/other_user}", "gists_url": "https://api.github.com/users/TomaszKaczmarczyk/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomaszKaczmarczyk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomaszKaczmarczyk/subscriptions", "organizations_url": "https://api.github.com/users/TomaszKaczmarczyk/orgs", "repos_url": "https://api.github.com/users/TomaszKaczmarczyk/repos", "events_url": "https://api.github.com/users/TomaszKaczmarczyk/events{/privacy}", "received_events_url": "https://api.github.com/users/TomaszKaczmarczyk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}, {"id": 1324784294, "node_id": "MDU6TGFiZWwxMzI0Nzg0Mjk0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-03T09:05:05Z", "updated_at": "2020-04-17T11:28:30Z", "closed_at": "2020-04-17T11:28:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nCurrent version of MatplotlibWriter dataset does not support versioning of datasets.\r\n\r\n## Context\r\nIt's very useful to have versioned charts when running multiple iterations of data science models.\r\n\r\n## Possible Implementation\r\nAdd support for versioning to the current MatplotlibWriter class.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/310", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/310/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/310/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/310/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/310", "id": 593189629, "node_id": "MDU6SXNzdWU1OTMxODk2Mjk=", "number": 310, "title": "[KED-1547] HoloviewsWriter Plotting Dataset", "user": {"login": "marcusinthesky", "id": 26429489, "node_id": "MDQ6VXNlcjI2NDI5NDg5", "avatar_url": "https://avatars0.githubusercontent.com/u/26429489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marcusinthesky", "html_url": "https://github.com/marcusinthesky", "followers_url": "https://api.github.com/users/marcusinthesky/followers", "following_url": "https://api.github.com/users/marcusinthesky/following{/other_user}", "gists_url": "https://api.github.com/users/marcusinthesky/gists{/gist_id}", "starred_url": "https://api.github.com/users/marcusinthesky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marcusinthesky/subscriptions", "organizations_url": "https://api.github.com/users/marcusinthesky/orgs", "repos_url": "https://api.github.com/users/marcusinthesky/repos", "events_url": "https://api.github.com/users/marcusinthesky/events{/privacy}", "received_events_url": "https://api.github.com/users/marcusinthesky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-03T07:51:20Z", "updated_at": "2020-05-29T10:09:40Z", "closed_at": "2020-05-29T10:09:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nA MatplotlibWriter-type Abstract Versioned Dataset for the Holoviews Plotting Library.  \r\n\r\n## Context\r\nHoloviews is a high-level plotting API which supports a number of plotting backends, including plotly, matplotlib and bokeh. Holoviews forms part of the [HoloViz](https://holoviz.org/) ecosystem of plotting and interactive dashboarding tools which can scale, using dask, to large distributed datasets or even GPU datasets using the Nvidia Rapids CUDF.  Holoviews has hundred of thousands of downloads on Anaconda and tens of thousands of stars on GitHub and is an exciting, growing tool for Python Developers. \r\n\r\nBeing able to version plots with your data and code is critical, as it allows one to visualize and diagnose data drift, track insights through time and evaluate the performance of different model retrains visually. \r\n\r\n## Possible Implementation\r\nI am using bokeh==1.4.0 and holoviews==1.12.7 with Python 3.7. This should not matter massively as the API has not changed dramatically and Holoviews does offer quite wide compatibility with different versions of Python. You can find out more about the different ways to persist and render holoviews plots in their [documentation](http://holoviews.org/user_guide/Plots_and_Renderers.html). \r\n\r\n```\r\nimport holoviews as hv\r\n\r\nclass HoloviewsWriter(AbstractVersionedDataSet):\r\n    DEFAULT_LOAD_ARGS = {}  # type: Dict[str, Any]\r\n    DEFAULT_SAVE_ARGS = {\"fmt\": \"png\"}  # type: Dict[str, Any]\r\n\r\n    def __init__(\r\n        self,\r\n        filepath: str,\r\n        load_args: Dict[str, Any] = None,\r\n        save_args: Dict[str, Any] = None,\r\n        version: Version = None,\r\n        credentials: Dict[str, Any] = None,\r\n        fs_args: Dict[str, Any] = None,\r\n        layer: str = None,\r\n    ) -> None:\r\n        \"\"\"\r\n        :param filepath: Filepath to a text file prefixed with a protocol like `s3://`.\r\n                If prefix is not provided, `file` protocol (local filesystem) will be used.\r\n                The prefix should be any protocol supported by ``fsspec``.\r\n                Note: `http(s)` doesn't support versioning.\r\n        :param load_args: Load arguments should be specified in accordance with\r\n                the open function of the underlying filesystem. E.g. for local file\r\n                https://docs.python.org/3/library/functions.html#open\r\n        :param save_args: Save arguments should be specified in accordance with\r\n                the open function of the underlying filesystem. E.g. for local file\r\n                https://docs.python.org/3/library/functions.html#open\r\n        :param version: If specified, should be an instance of\r\n                ``kedro.io.core.Version``. If its ``load`` attribute is\r\n                None, the latest version will be loaded. If its ``save``\r\n                attribute is None, save version will be autogenerated.\r\n        :param credentials: Credentials required to get access to the underlying filesystem.\r\n                E.g. for ``GCSFileSystem`` it should look like `{\"token\": None}`.\r\n        :param fs_args: Extra arguments to pass into underlying filesystem class.\r\n                E.g. for ``GCSFileSystem`` class: `{\"project\": \"my-project\", ...}`.\r\n        :param layer: The data layer according to the data engineering convention:\r\n                https://kedro.readthedocs.io/en/stable/06_resources/01_faq.html#what-is-data-engineering-convention\r\n        \"\"\"\r\n        _fs_args = deepcopy(fs_args) or {}\r\n        _credentials = deepcopy(credentials) or {}\r\n\r\n        protocol, path = get_protocol_and_path(filepath, version)\r\n\r\n        self._protocol = protocol\r\n        self._fs = fsspec.filesystem(self._protocol, **_credentials, **_fs_args)\r\n\r\n        super().__init__(\r\n            filepath=PurePosixPath(path),\r\n            version=version,\r\n            exists_function=self._fs.exists,\r\n            glob_function=self._fs.glob,\r\n        )\r\n\r\n        self._layer = layer\r\n\r\n        # Handle default load and save arguments\r\n        self._load_args = deepcopy(self.DEFAULT_LOAD_ARGS)\r\n        if load_args is not None:\r\n            self._load_args.update(load_args)\r\n        self._save_args = deepcopy(self.DEFAULT_SAVE_ARGS)\r\n        if save_args is not None:\r\n            self._save_args.update(save_args)\r\n\r\n    def _describe(self) -> Dict[str, Any]:\r\n        return dict(\r\n            filepath=self._filepath,\r\n            protocol=self._protocol,\r\n            load_args=self._load_args,\r\n            save_args=self._save_args,\r\n            version=self._version,\r\n            layer=self._layer,\r\n        )\r\n\r\n    def _load(self) -> str:\r\n        load_path = get_filepath_str(self._get_load_path(), self._protocol)\r\n\r\n        if str(load_path).endswith(\".png\"):\r\n            return hv.RGB.load_image(load_path, **self._load_args)\r\n        else:\r\n            raise NotImplementedError(\r\n                \"There is no way to convert from an\\\r\n                                    arbitrary saved image format to a plot.\"\r\n            )\r\n\r\n    def _save(self, plot: str) -> None:\r\n        save_path = Path(get_filepath_str(self._get_save_path(), self._protocol))\r\n        save_path.parent.mkdir(parents=True, exist_ok=True)\r\n        hv.save(plot, save_path, **self._save_args)\r\n\r\n        self._invalidate_cache()\r\n\r\n    def _exists(self) -> bool:\r\n        try:\r\n            load_path = get_filepath_str(self._get_load_path(), self._protocol)\r\n        except DataSetError:\r\n            return False\r\n\r\n        return self._fs.exists(load_path)\r\n\r\n    def _release(self) -> None:\r\n        super()._release()\r\n        self._invalidate_cache()\r\n\r\n    def _invalidate_cache(self) -> None:\r\n        \"\"\"Invalidate underlying filesystem caches.\"\"\"\r\n        filepath = get_filepath_str(self._filepath, self._protocol)\r\n        self._fs.invalidate_cache(filepath)\r\n```\r\n\r\n## Possible Alternatives\r\nI am unsure if we should allow users to load their .png plots. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/309", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/309/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/309/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/309/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/309", "id": 592107280, "node_id": "MDU6SXNzdWU1OTIxMDcyODA=", "number": 309, "title": "`credentials` param in `kedrio.io.csv_s3.CSVS3DataSet` breaks since s3fs 0.4.1.", "user": {"login": "michaelchia", "id": 16421143, "node_id": "MDQ6VXNlcjE2NDIxMTQz", "avatar_url": "https://avatars0.githubusercontent.com/u/16421143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelchia", "html_url": "https://github.com/michaelchia", "followers_url": "https://api.github.com/users/michaelchia/followers", "following_url": "https://api.github.com/users/michaelchia/following{/other_user}", "gists_url": "https://api.github.com/users/michaelchia/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelchia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelchia/subscriptions", "organizations_url": "https://api.github.com/users/michaelchia/orgs", "repos_url": "https://api.github.com/users/michaelchia/repos", "events_url": "https://api.github.com/users/michaelchia/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelchia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-01T18:10:44Z", "updated_at": "2020-06-30T21:05:27Z", "closed_at": "2020-04-06T15:22:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nUsing dict keys 'aws_access_key_id' and 'aws_secret_access_key' in the credentials param in `kedrio.io.csv_s3.CSVS3DataSet` causes errors since s3fs 0.4.1.\r\nI have made a pull request to s3fs to fix it on their side. But this report is just to let you know in case my PR is rejected or ignored. And even if the PR is accepted, since s3fs 0.4.1 & 0.4.2 are already out perhaps you'll need to be aware of this if your users report such issues and to fix your requirements.txt to avoid it. Either s3fs<=0.4.0 or hopefully >=0.4.3 if my PR gets accepted by next release.\r\n\r\n## Context\r\nI am unable to pass credentials to CSVS3DataSet as per its docstring. And would have to downgrade s3fs to get it to work.\r\n\r\n## Steps to Reproduce\r\n1. Upgrade s3fs to 0.4.1 or 0.4.2 (current latest)\r\n2. CSVS3DataSet(filepath=\"bucket/test.csv\", credentials={\"aws_access_key_id\": \"foo\", \"aws_secret_access_key\": \"bar\"})\r\n\r\n## Expected Result\r\nInstantiate dataset obj.\r\n\r\n## Actual Result\r\nRaised TypeError\r\n```\r\nTypeError: create_client() got multiple values for keyword argument 'aws_access_key_id'\r\n# from s3fs.core\r\n```\r\n\r\n## Your Environment\r\ns3fs==0.4.1\r\nkedro==0.15.8\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/308", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/308/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/308/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/308/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/308", "id": 591603911, "node_id": "MDU6SXNzdWU1OTE2MDM5MTE=", "number": 308, "title": "Sagemaker notebooks raise error for `pandas.CSVDataSet`", "user": {"login": "tjcuddihy", "id": 5057111, "node_id": "MDQ6VXNlcjUwNTcxMTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/5057111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tjcuddihy", "html_url": "https://github.com/tjcuddihy", "followers_url": "https://api.github.com/users/tjcuddihy/followers", "following_url": "https://api.github.com/users/tjcuddihy/following{/other_user}", "gists_url": "https://api.github.com/users/tjcuddihy/gists{/gist_id}", "starred_url": "https://api.github.com/users/tjcuddihy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tjcuddihy/subscriptions", "organizations_url": "https://api.github.com/users/tjcuddihy/orgs", "repos_url": "https://api.github.com/users/tjcuddihy/repos", "events_url": "https://api.github.com/users/tjcuddihy/events{/privacy}", "received_events_url": "https://api.github.com/users/tjcuddihy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-01T04:02:42Z", "updated_at": "2020-08-13T10:56:11Z", "closed_at": "2020-04-02T01:35:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nThe conda environment for python3.6 in notebooks cannot find `pandas.CSVDataSet`\r\n\r\n## Context\r\nI'm wanting to use sagemaker as my development environment. However, I cannot get kedro to run as expected in both the notebooks (for exploration and node development) and the terminal (for running pipelines).\r\n\r\n## Steps to Reproduce\r\n\r\n0. Startup a Sagemaker instance with defaults\r\n\r\nTerminal success:\r\n\r\n1. `pip install kedro` in the terminal\r\n2. `kedro new`\r\n2a. `testing` for name\r\n2b. `y` for example project\r\n3. `cd testing; kedro run` => Success!\r\n\r\nNotebook fail:\r\n1. Create a new `conda_python3` notebook in `testing/notebooks/`\r\n2. `!pip install kedro` in a notebook \r\n> The environments for the terminal and notebooks are separate by design in Sagemaker\r\n2. Load the kedro context as described [here](https://kedro.readthedocs.io/en/stable/04_user_guide/11_ipython.html#what-if-i-cannot-run-kedro-jupyter-notebook) \r\n> Note that I've started to use the code below; Without checking if `current_dir` exists, you need to restart the kernel if you want to reload the context as something in the last 2 lines of code causes the next invocation of `Path.cwd()` to point to the root dir not `notebook/`, as intended.\r\n```\r\nif \"current_dir\" not in locals():\r\n    # Check it exists first. For some reason this is not an idempotent operation?\r\n    current_dir = Path.cwd()  # this points to 'notebooks/' folder\r\nproj_path = current_dir.parent  # point back to the root of the project\r\ncontext = load_context(proj_path)\r\n```\r\n3. Run `context.catalog.list()`\r\n\r\n## Expected Result\r\nThe notebook should print:\r\n```\r\n['example_iris_data',\r\n 'parameters',\r\n 'params:example_test_data_ratio',\r\n 'params:example_num_train_iter',\r\n 'params:example_learning_rate']\r\n```\r\n\r\n## Actual Result\r\n```\r\nClass `pandas.CSVDataSet` not found.\r\n```\r\n\r\nFull trace.\r\n```\r\n---------------------------------------------------------------------------\r\nStopIteration                             Traceback (most recent call last)\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/kedro/io/core.py in parse_dataset_definition(config, load_version, save_version)\r\n    416         try:\r\n--> 417             class_obj = next(obj for obj in trials if obj is not None)\r\n    418         except StopIteration:\r\n\r\nStopIteration: \r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nDataSetError                              Traceback (most recent call last)\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/kedro/io/core.py in from_config(cls, name, config, load_version, save_version)\r\n    148             class_obj, config = parse_dataset_definition(\r\n--> 149                 config, load_version, save_version\r\n    150             )\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/kedro/io/core.py in parse_dataset_definition(config, load_version, save_version)\r\n    418         except StopIteration:\r\n--> 419             raise DataSetError(\"Class `{}` not found.\".format(class_obj))\r\n    420 \r\n\r\nDataSetError: Class `pandas.CSVDataSet` not found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nDataSetError                              Traceback (most recent call last)\r\n<ipython-input-4-5848382c8bb9> in <module>()\r\n----> 1 context.catalog.list()\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/kedro/context/context.py in catalog(self)\r\n    206 \r\n    207         \"\"\"\r\n--> 208         return self._get_catalog()\r\n    209 \r\n    210     @property\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/kedro/context/context.py in _get_catalog(self, save_version, journal, load_versions)\r\n    243         conf_creds = self._get_config_credentials()\r\n    244         catalog = self._create_catalog(\r\n--> 245             conf_catalog, conf_creds, save_version, journal, load_versions\r\n    246         )\r\n    247         catalog.add_feed_dict(self._get_feed_dict())\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/kedro/context/context.py in _create_catalog(self, conf_catalog, conf_creds, save_version, journal, load_versions)\r\n    267             save_version=save_version,\r\n    268             journal=journal,\r\n--> 269             load_versions=load_versions,\r\n    270         )\r\n    271 \r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/kedro/io/data_catalog.py in from_config(cls, catalog, credentials, load_versions, save_version, journal)\r\n    298             ds_config = _resolve_credentials(ds_config, credentials)\r\n    299             data_sets[ds_name] = AbstractDataSet.from_config(\r\n--> 300                 ds_name, ds_config, load_versions.get(ds_name), save_version\r\n    301             )\r\n    302         return cls(data_sets=data_sets, journal=journal)\r\n\r\n~/anaconda3/envs/python3/lib/python3.6/site-packages/kedro/io/core.py in from_config(cls, name, config, load_version, save_version)\r\n    152             raise DataSetError(\r\n    153                 \"An exception occurred when parsing config \"\r\n--> 154                 \"for DataSet `{}`:\\n{}\".format(name, str(ex))\r\n    155             )\r\n    156 \r\n\r\nDataSetError: An exception occurred when parsing config for DataSet `example_iris_data`:\r\nClass `pandas.CSVDataSet` not found.\r\n```\r\n\r\n## Investigations so far\r\n\r\n### `CSVLocalDataSet`\r\nUpon changing the yaml type for iris.csv from `pandas.CSVDataSet` to `CSVLocalDataSet`, we get success on both the terminal and the notebook. However, this is not my desired outcome; The transition to using `pandas.CSVDataSet` makes it easier, for me at least, to use both S3 and local datasets.\r\n\r\n### `pip install kedro` output from notebook\r\n```\r\nCollecting kedro\r\n  Downloading https://files.pythonhosted.org/packages/67/6f/4faaa0e58728a318aeabc490271a636f87f6b9165245ce1d3adc764240cf/kedro-0.15.8-py3-none-any.whl (12.5MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.5MB 4.1MB/s eta 0:00:01\r\nRequirement already satisfied: xlsxwriter<2.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kedro) (1.0.4)\r\nCollecting azure-storage-file<2.0,>=1.1.0 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/c9/33/6c611563412ffc409b2413ac50e3a063133ea235b86c137759774c77f3ad/azure_storage_file-1.4.0-py2.py3-none-any.whl\r\nCollecting fsspec<1.0,>=0.5.1 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/6e/2b/63420d49d5e5f885451429e9e0f40ad1787eed0d32b1aedd6b10f9c2719a/fsspec-0.7.1-py3-none-any.whl (66kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 33.5MB/s ta 0:00:01\r\nRequirement already satisfied: pandas<1.0,>=0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kedro) (0.24.2)\r\nCollecting s3fs<1.0,>=0.3.0 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/b8/e4/b8fc59248399d2482b39340ec9be4bb2493846ac23641b43115a7e5cd675/s3fs-0.4.2-py3-none-any.whl\r\nRequirement already satisfied: PyYAML<6.0,>=4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kedro) (5.3.1)\r\nCollecting tables<3.6,>=3.4.4 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/87/f7/bb0ec32a3f3dd74143a3108fbf737e6dcfd47f0ffd61b52af7106ab7a38a/tables-3.5.2-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.3MB 10.2MB/s ta 0:00:01\r\nRequirement already satisfied: requests<3.0,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kedro) (2.20.0)\r\nCollecting toposort<2.0,>=1.5 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\r\nRequirement already satisfied: click<8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kedro) (6.7)\r\nCollecting azure-storage-queue<2.0,>=1.1.0 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/72/94/4db044f1c155b40c5ebc037bfd9d1c24562845692c06798fbe869fe160e6/azure_storage_queue-1.4.0-py2.py3-none-any.whl\r\nCollecting cookiecutter<2.0,>=1.6.0 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/86/c9/7184edfb0e89abedc37211743d1420810f6b49ae4fa695dfc443c273470d/cookiecutter-1.7.0-py2.py3-none-any.whl (40kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40kB 24.6MB/s ta 0:00:01\r\nCollecting pandas-gbq<1.0,>=0.12.0 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/c3/74/126408f6bdb7b2cb1dcb8c6e4bd69a511a7f85792d686d1237d9825e6194/pandas_gbq-0.13.1-py3-none-any.whl\r\nCollecting pip-tools<5.0.0,>=4.0.0 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/94/8f/59495d651f3ced9b06b69545756a27296861a6edd6c5709fbe1265ed9032/pip_tools-4.5.1-py2.py3-none-any.whl (41kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 27.5MB/s ta 0:00:01\r\nCollecting azure-storage-blob<2.0,>=1.1.0 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/25/f4/a307ed89014e9abb5c5cfc8ca7f8f797d12f619f17a6059a6fd4b153b5d0/azure_storage_blob-1.5.0-py2.py3-none-any.whl (75kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81kB 35.2MB/s ta 0:00:01\r\nCollecting pyarrow<1.0.0,>=0.12.0 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/ba/10/93fad5849418eade4a4cd581f8cd27be1bbe51e18968ba1492140c887f3f/pyarrow-0.16.0-cp36-cp36m-manylinux1_x86_64.whl (62.9MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 62.9MB 779kB/s eta 0:00:01    40% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                   | 25.7MB 56.1MB/s eta 0:00:01\r\nRequirement already satisfied: SQLAlchemy<2.0,>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kedro) (1.2.11)\r\nRequirement already satisfied: xlrd<2.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kedro) (1.1.0)\r\nCollecting python-json-logger<1.0,>=0.1.9 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/80/9d/1c3393a6067716e04e6fcef95104c8426d262b4adaf18d7aa2470eab028d/python-json-logger-0.1.11.tar.gz\r\nCollecting anyconfig<1.0,>=0.9.7 (from kedro)\r\n  Downloading https://files.pythonhosted.org/packages/4c/00/cc525eb0240b6ef196b98300d505114339bbb7ddd68e3155483f1eb32050/anyconfig-0.9.10.tar.gz (103kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 112kB 34.4MB/s ta 0:00:01\r\nCollecting azure-storage-common~=1.4 (from azure-storage-file<2.0,>=1.1.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/05/6c/b2285bf3687768dbf61b6bc085b0c1be2893b6e2757a9d023263764177f3/azure_storage_common-1.4.2-py2.py3-none-any.whl (47kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 25.9MB/s ta 0:00:01\r\nCollecting azure-common>=1.1.5 (from azure-storage-file<2.0,>=1.1.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/e5/4d/d000fc3c5af601d00d55750b71da5c231fcb128f42ac95b208ed1091c2c1/azure_common-1.1.25-py2.py3-none-any.whl\r\nRequirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->kedro) (2.7.3)\r\nRequirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->kedro) (1.14.3)\r\nRequirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->kedro) (2018.4)\r\nRequirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from s3fs<1.0,>=0.3.0->kedro) (1.15.27)\r\nRequirement already satisfied: mock>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->kedro) (4.0.1)\r\nRequirement already satisfied: numexpr>=2.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->kedro) (2.6.5)\r\nRequirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->kedro) (1.11.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->kedro) (2019.11.28)\r\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->kedro) (3.0.4)\r\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->kedro) (1.23)\r\nRequirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->kedro) (2.6)\r\nCollecting whichcraft>=0.4.0 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/b5/a2/81887a0dae2e4d2adc70d9a3557fdda969f863ced51cd3c47b587d25bce5/whichcraft-0.6.1-py2.py3-none-any.whl\r\nCollecting future>=0.15.2 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 829kB 27.8MB/s ta 0:00:01\r\nCollecting poyo>=0.1.0 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/42/50/0b0820601bde2eda403f47b9a4a1f270098ed0dd4c00c443d883164bdccc/poyo-0.5.0-py2.py3-none-any.whl\r\nCollecting binaryornot>=0.2.0 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/24/7e/f7b6f453e6481d1e233540262ccbfcf89adcd43606f44a028d7f5fae5eb2/binaryornot-0.4.4-py2.py3-none-any.whl\r\nCollecting jinja2-time>=0.1.0 (from cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/6a/a1/d44fa38306ffa34a7e1af09632b158e13ec89670ce491f8a15af3ebcb4e4/jinja2_time-0.2.0-py2.py3-none-any.whl\r\nRequirement already satisfied: jinja2>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cookiecutter<2.0,>=1.6.0->kedro) (2.10)\r\nCollecting google-auth-oauthlib (from pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\r\nCollecting google-auth (from pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/05/b0/cc391ebf8ebf7855cdcfe0a9a4cdc8dcd90287c90e1ac22651d104ac6481/google_auth-1.12.0-py2.py3-none-any.whl (83kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 35.5MB/s ta 0:00:01\r\nCollecting pydata-google-auth (from pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/87/ed/9c9f410c032645632de787b8c285a78496bd89590c777385b921eb89433d/pydata_google_auth-0.3.0-py2.py3-none-any.whl\r\nRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas-gbq<1.0,>=0.12.0->kedro) (39.1.0)\r\nCollecting google-cloud-bigquery>=1.11.1 (from pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/8f/f7/b6f55e144da37f38a79552a06103f2df4a9569e2dfc6d741a7e2a63d3592/google_cloud_bigquery-1.24.0-py2.py3-none-any.whl (165kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 174kB 39.2MB/s ta 0:00:01\r\nRequirement already satisfied: cryptography in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (2.8)\r\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->kedro) (0.9.4)\r\nRequirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->kedro) (0.14)\r\nCollecting arrow (from jinja2-time>=0.1.0->cookiecutter<2.0,>=1.6.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/92/fa/f84896dede5decf284e6922134bf03fd26c90870bbf8015f4e8ee2a07bcc/arrow-0.15.5-py2.py3-none-any.whl (46kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 26.3MB/s ta 0:00:01\r\nRequirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jinja2>=2.7->cookiecutter<2.0,>=1.6.0->kedro) (1.0)\r\nCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\r\nCollecting pyasn1-modules>=0.2.1 (from google-auth->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163kB 32.5MB/s ta 0:00:01\r\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth->pandas-gbq<1.0,>=0.12.0->kedro) (3.4.2)\r\nCollecting cachetools<5.0,>=2.0.0 (from google-auth->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\r\nCollecting google-api-core<2.0dev,>=1.15.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/63/7e/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77/google_api_core-1.16.0-py2.py3-none-any.whl (70kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 29.9MB/s ta 0:00:01\r\nCollecting google-cloud-core<2.0dev,>=1.1.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\r\nRequirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro) (3.6.1)\r\nCollecting google-resumable-media<0.6dev,>=0.5.0 (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\r\nRequirement already satisfied: cffi!=1.11.3,>=1.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (1.11.5)\r\nCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 42.0MB/s ta 0:00:01\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth->pandas-gbq<1.0,>=0.12.0->kedro) (0.4.8)\r\nCollecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro)\r\n  Downloading https://files.pythonhosted.org/packages/05/46/168fd780f594a4d61122f7f3dc0561686084319ad73b4febbf02ae8b32cf/googleapis-common-protos-1.51.0.tar.gz\r\nRequirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (2.18)\r\nBuilding wheels for collected packages: python-json-logger, anyconfig, future, googleapis-common-protos\r\n  Running setup.py bdist_wheel for python-json-logger ... done\r\n  Stored in directory: /home/ec2-user/.cache/pip/wheels/97/f7/a1/752e22bb30c1cfe38194ea0070a5c66e76ef4d06ad0c7dc401\r\n  Running setup.py bdist_wheel for anyconfig ... done\r\n  Stored in directory: /home/ec2-user/.cache/pip/wheels/5a/82/0d/e374b7c77f4e4aa846a9bc2057e1d108c7f8e6b97a383befc9\r\n  Running setup.py bdist_wheel for future ... done\r\n  Stored in directory: /home/ec2-user/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\r\n  Running setup.py bdist_wheel for googleapis-common-protos ... done\r\n  Stored in directory: /home/ec2-user/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\r\nSuccessfully built python-json-logger anyconfig future googleapis-common-protos\r\ncookiecutter 1.7.0 has requirement click>=7.0, but you'll have click 6.7 which is incompatible.\r\ngoogle-auth 1.12.0 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\r\ngoogle-cloud-bigquery 1.24.0 has requirement six<2.0.0dev,>=1.13.0, but you'll have six 1.11.0 which is incompatible.\r\npip-tools 4.5.1 has requirement click>=7, but you'll have click 6.7 which is incompatible.\r\nInstalling collected packages: azure-common, azure-storage-common, azure-storage-file, fsspec, s3fs, tables, toposort, azure-storage-queue, whichcraft, future, poyo, binaryornot, arrow, jinja2-time, cookiecutter, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, pydata-google-auth, googleapis-common-protos, google-api-core, google-cloud-core, google-resumable-media, google-cloud-bigquery, pandas-gbq, pip-tools, azure-storage-blob, pyarrow, python-json-logger, anyconfig, kedro\r\n  Found existing installation: s3fs 0.1.5\r\n    Uninstalling s3fs-0.1.5:\r\n      Successfully uninstalled s3fs-0.1.5\r\n  Found existing installation: tables 3.4.3\r\n    Uninstalling tables-3.4.3:\r\n      Successfully uninstalled tables-3.4.3\r\nSuccessfully installed anyconfig-0.9.10 arrow-0.15.5 azure-common-1.1.25 azure-storage-blob-1.5.0 azure-storage-common-1.4.2 azure-storage-file-1.4.0 azure-storage-queue-1.4.0 binaryornot-0.4.4 cachetools-4.0.0 cookiecutter-1.7.0 fsspec-0.7.1 future-0.18.2 google-api-core-1.16.0 google-auth-1.12.0 google-auth-oauthlib-0.4.1 google-cloud-bigquery-1.24.0 google-cloud-core-1.3.0 google-resumable-media-0.5.0 googleapis-common-protos-1.51.0 jinja2-time-0.2.0 kedro-0.15.8 oauthlib-3.1.0 pandas-gbq-0.13.1 pip-tools-4.5.1 poyo-0.5.0 pyarrow-0.16.0 pyasn1-modules-0.2.8 pydata-google-auth-0.3.0 python-json-logger-0.1.11 requests-oauthlib-1.3.0 s3fs-0.4.2 tables-3.5.2 toposort-1.5 whichcraft-0.6.1\r\n```\r\n\r\n### `pip install kedro` output from terminal\r\n```\r\nCollecting kedro\r\n  Using cached kedro-0.15.8-py3-none-any.whl (12.5 MB)\r\nCollecting pandas<1.0,>=0.24.0\r\n  Downloading pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.4 MB 9.6 MB/s \r\nCollecting azure-storage-file<2.0,>=1.1.0\r\n  Using cached azure_storage_file-1.4.0-py2.py3-none-any.whl (30 kB)\r\nCollecting click<8.0\r\n  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 82 kB 1.7 MB/s \r\nCollecting cookiecutter<2.0,>=1.6.0\r\n  Using cached cookiecutter-1.7.0-py2.py3-none-any.whl (40 kB)\r\nCollecting SQLAlchemy<2.0,>=1.2.0\r\n  Downloading SQLAlchemy-1.3.15.tar.gz (6.1 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.1 MB 49.2 MB/s \r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n    Preparing wheel metadata ... done\r\nCollecting tables<3.6,>=3.4.4\r\n  Using cached tables-3.5.2-cp36-cp36m-manylinux1_x86_64.whl (4.3 MB)\r\nProcessing /home/ec2-user/.cache/pip/wheels/97/f7/a1/752e22bb30c1cfe38194ea0070a5c66e76ef4d06ad0c7dc401/python_json_logger-0.1.11-py2.py3-none-any.whl\r\nCollecting azure-storage-blob<2.0,>=1.1.0\r\n  Using cached azure_storage_blob-1.5.0-py2.py3-none-any.whl (75 kB)\r\nCollecting pandas-gbq<1.0,>=0.12.0\r\n  Using cached pandas_gbq-0.13.1-py3-none-any.whl (23 kB)\r\nRequirement already satisfied: fsspec<1.0,>=0.5.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from kedro) (0.6.3)\r\nCollecting xlsxwriter<2.0,>=1.0.0\r\n  Downloading XlsxWriter-1.2.8-py2.py3-none-any.whl (141 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 141 kB 65.9 MB/s \r\nCollecting pip-tools<5.0.0,>=4.0.0\r\n  Using cached pip_tools-4.5.1-py2.py3-none-any.whl (41 kB)\r\nCollecting pyarrow<1.0.0,>=0.12.0\r\n  Downloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 63.1 MB 25 kB/s \r\nCollecting xlrd<2.0,>=1.0.0\r\n  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 103 kB 66.5 MB/s \r\nRequirement already satisfied: s3fs<1.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from kedro) (0.4.0)\r\nCollecting azure-storage-queue<2.0,>=1.1.0\r\n  Using cached azure_storage_queue-1.4.0-py2.py3-none-any.whl (23 kB)\r\nProcessing /home/ec2-user/.cache/pip/wheels/5a/82/0d/e374b7c77f4e4aa846a9bc2057e1d108c7f8e6b97a383befc9/anyconfig-0.9.10-py2.py3-none-any.whl\r\nCollecting toposort<2.0,>=1.5\r\n  Using cached toposort-1.5-py2.py3-none-any.whl (7.6 kB)\r\nRequirement already satisfied: PyYAML<6.0,>=4.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from kedro) (5.3.1)\r\nRequirement already satisfied: requests<3.0,>=2.20.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from kedro) (2.23.0)\r\nRequirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->kedro) (2019.3)\r\nRequirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->kedro) (1.18.1)\r\nRequirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->kedro) (2.8.1)\r\nCollecting azure-common>=1.1.5\r\n  Using cached azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\r\nCollecting azure-storage-common~=1.4\r\n  Using cached azure_storage_common-1.4.2-py2.py3-none-any.whl (47 kB)\r\nCollecting poyo>=0.1.0\r\n  Using cached poyo-0.5.0-py2.py3-none-any.whl (10 kB)\r\nCollecting jinja2-time>=0.1.0\r\n  Using cached jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\r\nCollecting whichcraft>=0.4.0\r\n  Using cached whichcraft-0.6.1-py2.py3-none-any.whl (5.2 kB)\r\nCollecting binaryornot>=0.2.0\r\n  Using cached binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\r\nRequirement already satisfied: jinja2>=2.7 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from cookiecutter<2.0,>=1.6.0->kedro) (2.11.1)\r\nProcessing /home/ec2-user/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e/future-0.18.2-cp36-none-any.whl\r\nRequirement already satisfied: mock>=2.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->kedro) (3.0.5)\r\nCollecting numexpr>=2.6.2\r\n  Downloading numexpr-2.7.1-cp36-cp36m-manylinux1_x86_64.whl (162 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 162 kB 66.7 MB/s \r\nRequirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from tables<3.6,>=3.4.4->kedro) (1.14.0)\r\nCollecting pydata-google-auth\r\n  Using cached pydata_google_auth-0.3.0-py2.py3-none-any.whl (12 kB)\r\nCollecting google-auth-oauthlib\r\n  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\r\nCollecting google-cloud-bigquery>=1.11.1\r\n  Using cached google_cloud_bigquery-1.24.0-py2.py3-none-any.whl (165 kB)\r\nCollecting google-auth\r\n  Using cached google_auth-1.12.0-py2.py3-none-any.whl (83 kB)\r\nRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from pandas-gbq<1.0,>=0.12.0->kedro) (46.1.1.post20200323)\r\nRequirement already satisfied: boto3>=1.9.91 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from s3fs<1.0,>=0.3.0->kedro) (1.12.27)\r\nRequirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from s3fs<1.0,>=0.3.0->kedro) (1.15.27)\r\nRequirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->kedro) (2.9)\r\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->kedro) (3.0.4)\r\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->kedro) (1.22)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from requests<3.0,>=2.20.0->kedro) (2019.11.28)\r\nRequirement already satisfied: cryptography in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (2.8)\r\nCollecting arrow\r\n  Using cached arrow-0.15.5-py2.py3-none-any.whl (46 kB)\r\nRequirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from jinja2>=2.7->cookiecutter<2.0,>=1.6.0->kedro) (1.1.1)\r\nCollecting requests-oauthlib>=0.7.0\r\n  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\r\nCollecting google-resumable-media<0.6dev,>=0.5.0\r\n  Using cached google_resumable_media-0.5.0-py2.py3-none-any.whl (38 kB)\r\nCollecting google-cloud-core<2.0dev,>=1.1.0\r\n  Using cached google_cloud_core-1.3.0-py2.py3-none-any.whl (26 kB)\r\nRequirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from google-cloud-bigquery>=1.11.1->pandas-gbq<1.0,>=0.12.0->kedro) (3.11.3)\r\nCollecting google-api-core<2.0dev,>=1.15.0\r\n  Using cached google_api_core-1.16.0-py2.py3-none-any.whl (70 kB)\r\nCollecting pyasn1-modules>=0.2.1\r\n  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\r\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from google-auth->pandas-gbq<1.0,>=0.12.0->kedro) (3.4.2)\r\nCollecting cachetools<5.0,>=2.0.0\r\n  Using cached cachetools-4.0.0-py3-none-any.whl (10 kB)\r\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs<1.0,>=0.3.0->kedro) (0.3.3)\r\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs<1.0,>=0.3.0->kedro) (0.9.4)\r\nRequirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs<1.0,>=0.3.0->kedro) (0.15.2)\r\nRequirement already satisfied: cffi!=1.11.3,>=1.8 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (1.14.0)\r\nCollecting oauthlib>=3.0.0\r\n  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\r\nProcessing /home/ec2-user/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706/googleapis_common_protos-1.51.0-cp36-none-any.whl\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth->pandas-gbq<1.0,>=0.12.0->kedro) (0.4.8)\r\nRequirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=1.4->azure-storage-file<2.0,>=1.1.0->kedro) (2.20)\r\nBuilding wheels for collected packages: SQLAlchemy\r\n  Building wheel for SQLAlchemy (PEP 517) ... done\r\n  Created wheel for SQLAlchemy: filename=SQLAlchemy-1.3.15-cp36-cp36m-linux_x86_64.whl size=1215829 sha256=112167e02a19acada7f367d8aca55bbd1e0c655de9edfabebae5e9d055d9a9a6\r\n  Stored in directory: /home/ec2-user/.cache/pip/wheels/4a/1b/3a/c73044d7be48baeb47cbee343334f7803726ca1e9ba7b29095\r\nSuccessfully built SQLAlchemy\r\nInstalling collected packages: pandas, azure-common, azure-storage-common, azure-storage-file, click, poyo, arrow, jinja2-time, whichcraft, binaryornot, future, cookiecutter, SQLAlchemy, numexpr, tables, python-json-logger, azure-storage-blob, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, pydata-google-auth, google-resumable-media, googleapis-common-protos, google-api-core, google-cloud-core, google-cloud-bigquery, pandas-gbq, xlsxwriter, pip-tools, pyarrow, xlrd, azure-storage-queue, anyconfig, toposort, kedro\r\n  Attempting uninstall: pandas\r\n    Found existing installation: pandas 0.22.0\r\n    Uninstalling pandas-0.22.0:\r\n      Successfully uninstalled pandas-0.22.0\r\nSuccessfully installed SQLAlchemy-1.3.15 anyconfig-0.9.10 arrow-0.15.5 azure-common-1.1.25 azure-storage-blob-1.5.0 azure-storage-common-1.4.2 azure-storage-file-1.4.0 azure-storage-queue-1.4.0 binaryornot-0.4.4 cachetools-4.0.0 click-7.1.1 cookiecutter-1.7.0 future-0.18.2 google-api-core-1.16.0 google-auth-1.12.0 google-auth-oauthlib-0.4.1 google-cloud-bigquery-1.24.0 google-cloud-core-1.3.0 google-resumable-media-0.5.0 googleapis-common-protos-1.51.0 jinja2-time-0.2.0 kedro-0.15.8 numexpr-2.7.1 oauthlib-3.1.0 pandas-0.25.3 pandas-gbq-0.13.1 pip-tools-4.5.1 poyo-0.5.0 pyarrow-0.16.0 pyasn1-modules-0.2.8 pydata-google-auth-0.3.0 python-json-logger-0.1.11 requests-oauthlib-1.3.0 tables-3.5.2 toposort-1.5 whichcraft-0.6.1 xlrd-1.2.0 xlsxwriter-1.2.8\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n|environment | terminal | notebook|\r\n|----|----|----|\r\n|`kedro -V` | kedro, version 0.15.8 | kedro, version 0.15.8|\r\n|`python -V` | Python 3.6.10 :: Anaconda, Inc. | Python 3.6.5 :: Anaconda, Inc.|\r\n|os |  `PRETTY_NAME=\"Amazon Linux AMI 2018.03\"\"` `ID_LIKE=\"rhel fedora\"` | `PRETTY_NAME=\"Amazon Linux AMI 2018.03\"\"` `ID_LIKE=\"rhel fedora\"`|\r\n|`pip freeze` | anyconfig==0.9.10<br>arrow==0.15.5<br>asn1crypto==1.3.0<br>attrs==19.3.0<br>autovizwidget==0.12.9<br>awscli==1.18.27<br>azure-common==1.1.25<br>azure-storage-blob==1.5.0<br>azure-storage-common==1.4.2<br>azure-storage-file==1.4.0<br>azure-storage-queue==1.4.0<br>backcall==0.1.0<br>bcrypt==3.1.7<br>binaryornot==0.4.4<br>bleach==3.1.0<br>boto3==1.12.27<br>botocore==1.15.27<br>cached-property==1.5.1<br>cachetools==4.0.0<br>certifi==2019.11.28<br>cffi==1.14.0<br>chardet==3.0.4<br>click==7.1.1<br>colorama==0.4.3<br>cookiecutter==1.7.0<br>cryptography==2.8<br>decorator==4.4.2<br>defusedxml==0.6.0<br>docker==4.2.0<br>docker-compose==1.25.4<br>dockerpty==0.4.1<br>docopt==0.6.2<br>docutils==0.15.2<br>entrypoints==0.3<br>environment-kernels==1.1.1<br>fsspec==0.6.3<br>future==0.18.2<br>gitdb==4.0.2<br>GitPython==3.1.0<br>google-api-core==1.16.0<br>google-auth==1.12.0<br>google-auth-oauthlib==0.4.1<br>google-cloud-bigquery==1.24.0<br>google-cloud-core==1.3.0<br>google-resumable-media==0.5.0<br>googleapis-common-protos==1.51.0<br>hdijupyterutils==0.12.9<br>idna==2.9<br>importlib-metadata==1.5.0<br>ipykernel==5.1.4<br>ipython==7.13.0<br>ipython-genutils==0.2.0<br>ipywidgets==7.5.1<br>jedi==0.16.0<br>Jinja2==2.11.1<br>jinja2-time==0.2.0<br>jmespath==0.9.4<br>json5==0.9.3<br>jsonschema==3.2.0<br>jupyter==1.0.0<br>jupyter-client==6.0.0<br>jupyter-console==6.1.0<br>jupyter-core==4.6.1<br>jupyterlab==1.2.7<br>jupyterlab-git==0.9.0<br>jupyterlab-server==1.0.7<br>kedro==0.15.8<br>MarkupSafe==1.1.1<br>mistune==0.8.4<br>mock==3.0.5<br>nb-conda==2.2.1<br>nb-conda-kernels==2.2.3<br>nbconvert==5.6.1<br>nbdime==2.0.0<br>nbexamples==0.0.0<br>nbformat==5.0.4<br>nbserverproxy==0.3.2<br>nose==1.3.7<br>notebook==5.7.8<br>numexpr==2.7.1<br>numpy==1.18.1<br>oauthlib==3.1.0<br>packaging==20.3<br>pandas==0.25.3<br>pandas-gbq==0.13.1<br>pandocfilters==1.4.2<br>paramiko==2.7.1<br>parso==0.6.2<br>pexpect==4.8.0<br>pickleshare==0.7.5<br>pid==3.0.0<br>pip-tools==4.5.1<br>plotly==4.5.4<br>poyo==0.5.0<br>prometheus-client==0.7.1<br>prompt-toolkit==3.0.3<br>protobuf==3.11.3<br>protobuf3-to-dict==0.1.5<br>psutil==5.7.0<br>psycopg2==2.8.4<br>ptyprocess==0.6.0<br>py4j==0.10.7<br>pyarrow==0.16.0<br>pyasn1==0.4.8<br>pyasn1-modules==0.2.8<br>pycparser==2.20<br>pydata-google-auth==0.3.0<br>pygal==2.4.0<br>Pygments==2.6.1<br>pykerberos==1.1.14<br>PyNaCl==1.3.0<br>pyOpenSSL==19.1.0<br>pyparsing==2.4.6<br>pyrsistent==0.15.7<br>PySocks==1.7.1<br>pyspark==2.3.2<br>python-dateutil==2.8.1<br>python-json-logger==0.1.11<br>pytz==2019.3<br>PyYAML==5.3.1<br>pyzmq==18.1.1<br>qtconsole==4.7.1<br>QtPy==1.9.0<br>requests==2.23.0<br>requests-kerberos==0.12.0<br>requests-oauthlib==1.3.0<br>retrying==1.3.3<br>rsa==3.4.2<br>s3fs==0.4.0<br>s3transfer==0.3.3<br>sagemaker==1.51.4<br>sagemaker-experiments==0.1.10<br>sagemaker-nbi-agent==1.0<br>sagemaker-pyspark==1.2.8<br>scipy==1.4.1<br>Send2Trash==1.5.0<br>six==1.14.0<br>smdebug-rulesconfig==0.1.2<br>smmap==3.0.1<br>sparkmagic==0.15.0<br>SQLAlchemy==1.3.15<br>tables==3.5.2<br>terminado==0.8.3<br>testpath==0.4.4<br>texttable==1.6.2<br>toposort==1.5<br>tornado==6.0.4<br>traitlets==4.3.3<br>urllib3==1.22<br>wcwidth==0.1.8<br>webencodings==0.5.1<br>websocket-client==0.57.0<br>whichcraft==0.6.1<br>widgetsnbextension==3.5.1<br>xlrd==1.2.0<br>XlsxWriter==1.2.8<br>zipp==2.2.0 | alabaster==0.7.10<br>anaconda-client==1.6.14<br>anaconda-project==0.8.2<br>anyconfig==0.9.10<br>arrow==0.15.5<br>asn1crypto==0.24.0<br>astroid==1.6.3<br>astropy==3.0.2<br>attrs==18.1.0<br>Automat==0.3.0<br>autovizwidget==0.15.0<br>awscli==1.18.27<br>azure-common==1.1.25<br>azure-storage-blob==1.5.0<br>azure-storage-common==1.4.2<br>azure-storage-file==1.4.0<br>azure-storage-queue==1.4.0<br>Babel==2.5.3<br>backcall==0.1.0<br>backports.shutil-get-terminal-size==1.0.0<br>bcrypt==3.1.7<br>beautifulsoup4==4.6.0<br>binaryornot==0.4.4<br>bitarray==0.8.1<br>bkcharts==0.2<br>blaze==0.11.3<br>bleach==2.1.3<br>bokeh==1.0.4<br>boto==2.48.0<br>boto3==1.12.27<br>botocore==1.15.27<br>Bottleneck==1.2.1<br>cached-property==1.5.1<br>cachetools==4.0.0<br>certifi==2019.11.28<br>cffi==1.11.5<br>characteristic==14.3.0<br>chardet==3.0.4<br>click==6.7<br>cloudpickle==0.5.3<br>clyent==1.2.2<br>colorama==0.3.9<br>contextlib2==0.5.5<br>cookiecutter==1.7.0<br>cryptography==2.8<br>cycler==0.10.0<br>Cython==0.28.4<br>cytoolz==0.9.0.1<br>dask==0.17.5<br>datashape==0.5.4<br>decorator==4.3.0<br>defusedxml==0.6.0<br>distributed==1.21.8<br>docker==4.2.0<br>docker-compose==1.25.4<br>dockerpty==0.4.1<br>docopt==0.6.2<br>docutils==0.14<br>entrypoints==0.2.3<br>enum34==1.1.9<br>environment-kernels==1.1.1<br>et-xmlfile==1.0.1<br>fastcache==1.0.2<br>filelock==3.0.4<br>Flask==1.0.2<br>Flask-Cors==3.0.4<br>fsspec==0.7.1<br>future==0.18.2<br>gevent==1.3.0<br>glob2==0.6<br>gmpy2==2.0.8<br>google-api-core==1.16.0<br>google-auth==1.12.0<br>google-auth-oauthlib==0.4.1<br>google-cloud-bigquery==1.24.0<br>google-cloud-core==1.3.0<br>google-resumable-media==0.5.0<br>googleapis-common-protos==1.51.0<br>greenlet==0.4.13<br>h5py==2.8.0<br>hdijupyterutils==0.15.0<br>heapdict==1.0.0<br>html5lib==1.0.1<br>idna==2.6<br>imageio==2.3.0<br>imagesize==1.0.0<br>importlib-metadata==1.5.0<br>ipykernel==4.8.2<br>ipyparallel==6.2.2<br>ipython==6.4.0<br>ipython-genutils==0.2.0<br>ipywidgets==7.4.0<br>isort==4.3.4<br>itsdangerous==0.24<br>jdcal==1.4<br>jedi==0.12.0<br>Jinja2==2.10<br>jinja2-time==0.2.0<br>jmespath==0.9.4<br>jsonschema==2.6.0<br>jupyter==1.0.0<br>jupyter-client==5.2.3<br>jupyter-console==5.2.0<br>jupyter-core==4.4.0<br>jupyterlab==0.32.1<br>jupyterlab-launcher==0.10.5<br>kedro==0.15.8<br>kiwisolver==1.0.1<br>lazy-object-proxy==1.3.1<br>llvmlite==0.23.1<br>locket==0.2.0<br>lxml==4.2.1<br>MarkupSafe==1.0<br>matplotlib==3.0.3<br>mccabe==0.6.1<br>mistune==0.8.3<br>mkl-fft==1.0.0<br>mkl-random==1.0.1<br>mock==4.0.1<br>more-itertools==4.1.0<br>mpmath==1.0.0<br>msgpack==0.6.0<br>msgpack-python==0.5.6<br>multipledispatch==0.5.0<br>nb-conda==2.2.1<br>nb-conda-kernels==2.2.2<br>nbconvert==5.4.1<br>nbformat==4.4.0<br>networkx==2.1<br>nltk==3.3<br>nose==1.3.7<br>notebook==5.5.0<br>numba==0.38.0<br>numexpr==2.6.5<br>numpy==1.14.3<br>numpydoc==0.8.0<br>oauthlib==3.1.0<br>odo==0.5.1<br>olefile==0.45.1<br>opencv-python==3.4.2.17<br>openpyxl==2.5.3<br>packaging==20.1<br>pandas==0.24.2<br>pandas-gbq==0.13.1<br>pandocfilters==1.4.2<br>paramiko==2.7.1<br>parso==0.2.0<br>partd==0.3.8<br>path.py==11.0.1<br>pathlib2==2.3.2<br>patsy==0.5.0<br>pep8==1.7.1<br>pexpect==4.5.0<br>pickleshare==0.7.4<br>Pillow==5.1.0<br>pip-tools==4.5.1<br>pkginfo==1.4.2<br>plotly==4.5.2<br>pluggy==0.6.0<br>ply==3.11<br>poyo==0.5.0<br>prompt-toolkit==1.0.15<br>protobuf==3.6.1<br>protobuf3-to-dict==0.1.5<br>psutil==5.4.5<br>psycopg2==2.7.5<br>ptyprocess==0.5.2<br>py==1.5.3<br>py4j==0.10.7<br>pyarrow==0.16.0<br>pyasn1==0.4.8<br>pyasn1-modules==0.2.8<br>pycodestyle==2.4.0<br>pycosat==0.6.3<br>pycparser==2.18<br>pycrypto==2.6.1<br>pycurl==7.43.0.1<br>pydata-google-auth==0.3.0<br>pyflakes==1.6.0<br>pygal==2.4.0<br>Pygments==2.2.0<br>pykerberos==1.2.1<br>pylint==1.8.4<br>PyNaCl==1.3.0<br>pyodbc==4.0.23<br>pyOpenSSL==18.0.0<br>pyparsing==2.2.0<br>PySocks==1.6.8<br>pyspark==2.3.2<br>pytest==3.5.1<br>pytest-arraydiff==0.2<br>pytest-astropy==0.3.0<br>pytest-doctestplus==0.1.3<br>pytest-openfiles==0.3.0<br>pytest-remotedata==0.2.1<br>python-dateutil==2.7.3<br>python-json-logger==0.1.11<br>pytz==2018.4<br>PyWavelets==0.5.2<br>PyYAML==5.3.1<br>pyzmq==17.0.0<br>QtAwesome==0.4.4<br>qtconsole==4.3.1<br>QtPy==1.4.1<br>requests==2.20.0<br>requests-kerberos==0.12.0<br>requests-oauthlib==1.3.0<br>retrying==1.3.3<br>rope==0.10.7<br>rsa==3.4.2<br>ruamel-yaml==0.15.35<br>s3fs==0.4.2<br>s3transfer==0.3.3<br>sagemaker==1.51.4<br>sagemaker-pyspark==1.2.8<br>scikit-image==0.13.1<br>scikit-learn==0.20.3<br>scipy==1.1.0<br>seaborn==0.8.1<br>Send2Trash==1.5.0<br>simplegeneric==0.8.1<br>singledispatch==3.4.0.3<br>six==1.11.0<br>smdebug-rulesconfig==0.1.2<br>snowballstemmer==1.2.1<br>sortedcollections==0.6.1<br>sortedcontainers==1.5.10<br>sparkmagic==0.12.5<br>Sphinx==1.7.4<br>sphinxcontrib-websupport==1.0.1<br>spyder==3.2.8<br>SQLAlchemy==1.2.11<br>statsmodels==0.9.0<br>sympy==1.1.1<br>tables==3.5.2<br>TBB==0.1<br>tblib==1.3.2<br>terminado==0.8.1<br>testpath==0.3.1<br>texttable==1.6.2<br>toolz==0.9.0<br>toposort==1.5<br>tornado==5.0.2<br>traitlets==4.3.2<br>typing==3.6.4<br>unicodecsv==0.14.1<br>urllib3==1.23<br>wcwidth==0.1.7<br>webencodings==0.5.1<br>websocket-client==0.57.0<br>Werkzeug==0.14.1<br>whichcraft==0.6.1<br>widgetsnbextension==3.4.2<br>wrapt==1.10.11<br>xlrd==1.1.0<br>XlsxWriter==1.0.4<br>xlwt==1.3.0<br>zict==0.1.3<br>zipp==3.0.0|\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/306", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/306/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/306/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/306/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/306", "id": 589533468, "node_id": "MDU6SXNzdWU1ODk1MzM0Njg=", "number": 306, "title": "Remove cookiecutter-template tag", "user": {"login": "loleg", "id": 31819, "node_id": "MDQ6VXNlcjMxODE5", "avatar_url": "https://avatars2.githubusercontent.com/u/31819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/loleg", "html_url": "https://github.com/loleg", "followers_url": "https://api.github.com/users/loleg/followers", "following_url": "https://api.github.com/users/loleg/following{/other_user}", "gists_url": "https://api.github.com/users/loleg/gists{/gist_id}", "starred_url": "https://api.github.com/users/loleg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/loleg/subscriptions", "organizations_url": "https://api.github.com/users/loleg/orgs", "repos_url": "https://api.github.com/users/loleg/repos", "events_url": "https://api.github.com/users/loleg/events{/privacy}", "received_events_url": "https://api.github.com/users/loleg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1484450764, "node_id": "MDU6TGFiZWwxNDg0NDUwNzY0", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Thank%20You", "name": "Issue: Thank You", "color": "a82b1f", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-28T08:28:39Z", "updated_at": "2020-03-31T10:46:03Z", "closed_at": "2020-03-31T10:46:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "This project, even if originally based on a cookiecutter template, no longer supports deployment via cookiecutter. So please remove the tag in the GitHub repo to avoid confusion. Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/303", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/303/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/303/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/303/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/303", "id": 588809445, "node_id": "MDU6SXNzdWU1ODg4MDk0NDU=", "number": 303, "title": "Was dropping support for joblib in PickleDataSet intentional?", "user": {"login": "cfranklin11", "id": 10327871, "node_id": "MDQ6VXNlcjEwMzI3ODcx", "avatar_url": "https://avatars0.githubusercontent.com/u/10327871?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cfranklin11", "html_url": "https://github.com/cfranklin11", "followers_url": "https://api.github.com/users/cfranklin11/followers", "following_url": "https://api.github.com/users/cfranklin11/following{/other_user}", "gists_url": "https://api.github.com/users/cfranklin11/gists{/gist_id}", "starred_url": "https://api.github.com/users/cfranklin11/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cfranklin11/subscriptions", "organizations_url": "https://api.github.com/users/cfranklin11/orgs", "repos_url": "https://api.github.com/users/cfranklin11/repos", "events_url": "https://api.github.com/users/cfranklin11/events{/privacy}", "received_events_url": "https://api.github.com/users/cfranklin11/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-27T00:35:08Z", "updated_at": "2020-04-03T18:46:01Z", "closed_at": "2020-03-31T22:59:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## What are you trying to do?\r\nI updated Kedro from 0.15.5 to 0.15.8 and updated references to data set types in my `catalog.yml` files accordingly, but got an unknown argument error for trying to use the keyword argument `backend` for `PickleDataSet`. With the old `PickleLocalDataSet` I passed `backend='joblib'` to pickle/unpickle Scikit-learn model files.\r\n\r\nLooking through the repo, I see that references to the `backend` keyword argument are not in the documentation for `PickleDataSet`, and the code only uses the `pickle` library, but I can't find a commit or PR message explaining the removal.\r\n\r\nSo, was this change intentional? If so, is there a way to still use `joblib` in the new `PickleDataSet`, or could I open a PR to add it?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/298", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/298/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/298/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/298/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/298", "id": 585191960, "node_id": "MDU6SXNzdWU1ODUxOTE5NjA=", "number": 298, "title": "[KED-1513] PickleDataSet error in jupyter notebook", "user": {"login": "jfogelberg", "id": 30149349, "node_id": "MDQ6VXNlcjMwMTQ5MzQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/30149349?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jfogelberg", "html_url": "https://github.com/jfogelberg", "followers_url": "https://api.github.com/users/jfogelberg/followers", "following_url": "https://api.github.com/users/jfogelberg/following{/other_user}", "gists_url": "https://api.github.com/users/jfogelberg/gists{/gist_id}", "starred_url": "https://api.github.com/users/jfogelberg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jfogelberg/subscriptions", "organizations_url": "https://api.github.com/users/jfogelberg/orgs", "repos_url": "https://api.github.com/users/jfogelberg/repos", "events_url": "https://api.github.com/users/jfogelberg/events{/privacy}", "received_events_url": "https://api.github.com/users/jfogelberg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-20T16:36:51Z", "updated_at": "2020-06-03T12:28:24Z", "closed_at": "2020-06-03T12:28:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nRunning a pipeline using\r\n```python\r\ncontext.run()\r\n```\r\ninside a notebook, launched using\r\n```bash\r\nkedro jupyter notebook\r\n```\r\nraises exception when saving PickleDataSet.\r\nRunning the same pipeline in terminal works fine without any error:\r\n```bash\r\nkedro run\r\n```\r\n\r\nLoading the pickle file from inside the notebook works fine:\r\n```python\r\ncontext.io.load(\"my_data\")\r\n```\r\nThe object is a custom class containing a pandas DataFrame and some metadata.\r\n\r\n## Context\r\nCurrently I cannot run my pipeline from jupyter.\r\n\r\n## Steps to Reproduce\r\n1. Add PickleDataSet my_data  in the catalog.\r\n2. Create a pipeline that saves a custom class object to my_data\r\n3. Run pipeline from jupyter notebook using context.run()\r\n\r\n## Expected Result\r\nPipeline runs without error.\r\n\r\n## Actual Result\r\nError is raised.\r\n\r\n```\r\nDataSetError: <class 'my_custom_class'> cannot be serialized. PickleDataSet can only be used with serializable data\r\n```\r\n\r\n```\r\n _pickle.PicklingError: Can't pickle <class 'my_custom_class'>: it's not the same object as my_custom_class\r\n```\r\n\r\n## Your Environment\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.15.8\r\n* Python version used (`python -V`): 3.6.8\r\n* Operating system and version: Windows 10\r\n* Error is raised even if I run context.run() as my first cell in the notebook without having imported any other library or magic commands.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/295", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/295/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/295/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/295/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/295", "id": 583435578, "node_id": "MDU6SXNzdWU1ODM0MzU1Nzg=", "number": 295, "title": "Error: no such option: --params with Kedro run", "user": {"login": "sanjaymeena", "id": 5145685, "node_id": "MDQ6VXNlcjUxNDU2ODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/5145685?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sanjaymeena", "html_url": "https://github.com/sanjaymeena", "followers_url": "https://api.github.com/users/sanjaymeena/followers", "following_url": "https://api.github.com/users/sanjaymeena/following{/other_user}", "gists_url": "https://api.github.com/users/sanjaymeena/gists{/gist_id}", "starred_url": "https://api.github.com/users/sanjaymeena/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sanjaymeena/subscriptions", "organizations_url": "https://api.github.com/users/sanjaymeena/orgs", "repos_url": "https://api.github.com/users/sanjaymeena/repos", "events_url": "https://api.github.com/users/sanjaymeena/events{/privacy}", "received_events_url": "https://api.github.com/users/sanjaymeena/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-03-18T03:21:51Z", "updated_at": "2020-03-30T10:16:43Z", "closed_at": "2020-03-30T10:16:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI am trying to specify parameters at runtime with `kedro run` as per https://kedro.readthedocs.io/en/latest/04_user_guide/03_configuration.html#additional-configuration-environments \r\n\r\nI get following error : \r\n```\r\nUsage: kedro run [OPTIONS]\r\nTry \"kedro run -h\" for help.\r\n\r\nError: no such option: --params\r\n```\r\n\r\n## Steps to Reproduce\r\n1. kedro run --params param_key1:value1,param_key2:2.0\r\n\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.15.8 , 0.15.5\r\n* Python version used (`python -V`): 3.7.6\r\n* Operating system and version: Ubuntu\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/294", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/294/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/294/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/294/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/294", "id": 583158672, "node_id": "MDU6SXNzdWU1ODMxNTg2NzI=", "number": 294, "title": "Error: \"NameError: name 'catalog' is not defined\" in Jupyter notebook", "user": {"login": "jorge-datanalyst", "id": 60586867, "node_id": "MDQ6VXNlcjYwNTg2ODY3", "avatar_url": "https://avatars1.githubusercontent.com/u/60586867?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorge-datanalyst", "html_url": "https://github.com/jorge-datanalyst", "followers_url": "https://api.github.com/users/jorge-datanalyst/followers", "following_url": "https://api.github.com/users/jorge-datanalyst/following{/other_user}", "gists_url": "https://api.github.com/users/jorge-datanalyst/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorge-datanalyst/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorge-datanalyst/subscriptions", "organizations_url": "https://api.github.com/users/jorge-datanalyst/orgs", "repos_url": "https://api.github.com/users/jorge-datanalyst/repos", "events_url": "https://api.github.com/users/jorge-datanalyst/events{/privacy}", "received_events_url": "https://api.github.com/users/jorge-datanalyst/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-17T16:57:15Z", "updated_at": "2020-03-18T08:04:48Z", "closed_at": "2020-03-18T08:04:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, I am trying to follow the example tutorial but I am having trouble in session https://kedro.readthedocs.io/en/latest/03_tutorial/04_create_pipelines.html#working-in-a-jupyter-notebook, I am trying to run the code shown here but throws an error and although I have tried several things I can not solve the error.\r\n\r\nI opened a notebook to test the kedro notebooks session and when I run the following code:\r\n\r\npreprocessed_shuttles = catalog.load(\"preprocessed_shuttles\")\r\npreprocessed_companies = catalog.load(\"preprocessed_companies\")\r\nreviews = catalog.load(\"reviews\")\r\n\r\nmaster = create_master_table(preprocessed_shuttles, preprocessed_companies, reviews)\r\nmaster.head()\r\n\r\nand I get the following error:\r\n\r\n---------------------------------------------------------------------------\r\nNameError                                 Traceback (most recent call last)\r\n<ipython-input-1-7950015db63b> in <module>\r\n----> 1 preprocessed_shuttles = catalog.load(\"preprocessed_shuttles\")\r\n      2 preprocessed_companies = catalog.load(\"preprocessed_companies\")\r\n      3 reviews = catalog.load(\"reviews\")\r\n      4 \r\n      5 \r\n\r\nNameError: name 'catalog' is not defined\r\n\r\nI have tried to call the catalog module in various ways, but I cannot get it right. If you can guide me to a solution I thank you.\r\n\r\nSorry for my bad English\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/291", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/291/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/291/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/291/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/291", "id": 581957230, "node_id": "MDU6SXNzdWU1ODE5NTcyMzA=", "number": 291, "title": "[KED-1473] `pandas.CSVDataSet` doesn't support `encoding` parameter", "user": {"login": "deepyaman", "id": 14007150, "node_id": "MDQ6VXNlcjE0MDA3MTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/14007150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepyaman", "html_url": "https://github.com/deepyaman", "followers_url": "https://api.github.com/users/deepyaman/followers", "following_url": "https://api.github.com/users/deepyaman/following{/other_user}", "gists_url": "https://api.github.com/users/deepyaman/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepyaman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepyaman/subscriptions", "organizations_url": "https://api.github.com/users/deepyaman/orgs", "repos_url": "https://api.github.com/users/deepyaman/repos", "events_url": "https://api.github.com/users/deepyaman/events{/privacy}", "received_events_url": "https://api.github.com/users/deepyaman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2020-03-16T02:51:57Z", "updated_at": "2020-08-18T12:53:33Z", "closed_at": "2020-03-26T18:25:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nI'm unable to load a non-`utf-8`-encoded file.\r\n\r\nI know it doesn't work because of https://github.com/quantumblacklabs/kedro/blob/f03226e29b8a018a0f6edab6d3f1a0d37c1b1812/kedro/extras/datasets/pandas/csv_dataset.py#L154-L155. For it to work, `encoding` would have to be passed to `open`. However, some file systems don't support an `encoding` parameter... (e.g. `gcsfs`, I think).\r\n\r\n## Steps to Reproduce\r\nTry loading https://github.com/beoutbreakprepared/nCoV2019/blob/433628fb828f3b3b3bff7d13195af357fe42e31d/ncov_outside_hubei.csv as a `CSVDataSet`.\r\n\r\n## Expected Result\r\nI can load a `cp1252`-encoded file directly with pandas:\r\n\r\n```python3\r\npd.read_csv(\"data/01_raw/nCoV2019/ncov_outside_hubei/20200304/ncov_outside_hubei.csv\", encoding=\"cp1252\")\r\n```\r\n\r\n## Actual Result\r\nI'm unable to load a `cp1252`-encoded file using Kedro:\r\n\r\n```\r\nDataSetError: Failed while loading data from data set CSVDataSet(filepath=data/01_raw/nCoV2019/ncov_outside_hubei/20200304/ncov_outside_hubei.csv, load_args={'encoding': cp1252, 'low_memory': False}, protocol=file, save_args={'index': False}).\r\n'utf-8' codec can't decode byte 0xa0 in position 162456: invalid start byte\r\n```\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): `0.15.8`\r\n* Python version used (`python -V`): `3.7.6`\r\n* Operating system and version: macOS Mojave Version `10.14.6`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/290", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/290/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/290/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/290/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/290", "id": 581600536, "node_id": "MDU6SXNzdWU1ODE2MDA1MzY=", "number": 290, "title": "What is best practice for tests?", "user": {"login": "kirkby-ac", "id": 35689862, "node_id": "MDQ6VXNlcjM1Njg5ODYy", "avatar_url": "https://avatars0.githubusercontent.com/u/35689862?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kirkby-ac", "html_url": "https://github.com/kirkby-ac", "followers_url": "https://api.github.com/users/kirkby-ac/followers", "following_url": "https://api.github.com/users/kirkby-ac/following{/other_user}", "gists_url": "https://api.github.com/users/kirkby-ac/gists{/gist_id}", "starred_url": "https://api.github.com/users/kirkby-ac/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kirkby-ac/subscriptions", "organizations_url": "https://api.github.com/users/kirkby-ac/orgs", "repos_url": "https://api.github.com/users/kirkby-ac/repos", "events_url": "https://api.github.com/users/kirkby-ac/events{/privacy}", "received_events_url": "https://api.github.com/users/kirkby-ac/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-15T09:42:18Z", "updated_at": "2020-03-15T10:01:05Z", "closed_at": "2020-03-15T10:00:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Throughout the pipeline documentation, there are neat ways to access our conf setting i.e. referencing datasets via string names and parameters with the 'params:' prefix. This same logic doesn't seem to apply to the tests. \r\n\r\nCurrently, I am creating a pytest fixture in conftest.py to load the project context and then passing this context to each test:\r\n\r\n```python\r\n\r\n# conftest.py\r\nimport pytest\r\nfrom pathlib import Path\r\nfrom kedro.context import load_context\r\n\r\n@pytest.fixture(scope='session')\r\ndef context():\r\n    return load_context(Path.cwd())\r\n\r\n# other_test.py\r\ndef test_xyz(context):\r\n    data = context.io.load('some_test_data')\r\n    param = context.params['some_param']\r\n```\r\n\r\nJust wondering is this best practice or is there something I'm missing?\r\n\r\n*Edit: formatting", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/289", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/289/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/289/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/289/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/289", "id": 581082594, "node_id": "MDU6SXNzdWU1ODEwODI1OTQ=", "number": 289, "title": "[KED-1514] Add `--check-only` option to verify code is linted", "user": {"login": "deepyaman", "id": 14007150, "node_id": "MDQ6VXNlcjE0MDA3MTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/14007150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepyaman", "html_url": "https://github.com/deepyaman", "followers_url": "https://api.github.com/users/deepyaman/followers", "following_url": "https://api.github.com/users/deepyaman/following{/other_user}", "gists_url": "https://api.github.com/users/deepyaman/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepyaman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepyaman/subscriptions", "organizations_url": "https://api.github.com/users/deepyaman/orgs", "repos_url": "https://api.github.com/users/deepyaman/repos", "events_url": "https://api.github.com/users/deepyaman/events{/privacy}", "received_events_url": "https://api.github.com/users/deepyaman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-14T07:20:35Z", "updated_at": "2020-04-07T16:53:03Z", "closed_at": "2020-04-07T16:53:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description / Context\r\nThe way it\u2019s written, `kedro lint` does not \"work\" as part of a CI process. You run `kedro lint` as a build step, it will see incorrectly sorted imports or unblacked code and fix them then and there--on the build image--and pass the build step.\r\n\r\nIf `kedro lint` isn\u2019t intended to be used in CI processes, the current implementation is sufficient. However, I would argue that including `kedro lint` in a CI process is a common way of using it (especially at QuantumBlack, because old versions of KernelAI used it as such). In that case, my suggestion would be to have a `kedro lint --check-only` option that you can use in builds.\r\n\r\n(synthesized from a Slack conversation with @lorenabalan)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/288", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/288/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/288/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/288/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/288", "id": 580704259, "node_id": "MDU6SXNzdWU1ODA3MDQyNTk=", "number": 288, "title": "Error when Loading Compressed JSON DataSet through the Catalog", "user": {"login": "uwaisiqbal", "id": 1469206, "node_id": "MDQ6VXNlcjE0NjkyMDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/1469206?v=4", "gravatar_id": "", "url": "https://api.github.com/users/uwaisiqbal", "html_url": "https://github.com/uwaisiqbal", "followers_url": "https://api.github.com/users/uwaisiqbal/followers", "following_url": "https://api.github.com/users/uwaisiqbal/following{/other_user}", "gists_url": "https://api.github.com/users/uwaisiqbal/gists{/gist_id}", "starred_url": "https://api.github.com/users/uwaisiqbal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/uwaisiqbal/subscriptions", "organizations_url": "https://api.github.com/users/uwaisiqbal/orgs", "repos_url": "https://api.github.com/users/uwaisiqbal/repos", "events_url": "https://api.github.com/users/uwaisiqbal/events{/privacy}", "received_events_url": "https://api.github.com/users/uwaisiqbal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-13T16:14:49Z", "updated_at": "2020-03-26T18:26:52Z", "closed_at": "2020-03-26T18:26:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a dataset defined in my DataCatalog which is a gzip compressed JSON lines file that I would like to load through Kedro using a JSONDataSet. I have the following definition in my DataCatalog:\r\n\r\n```yaml\r\ntest_json:\r\n  type: JSONDataSet\r\n  filepath: \"data/01_raw/test.json.gz\"\r\n  load_args:\r\n    lines: true\r\n    compression: 'gzip'\r\n```\r\nHowever, when I try and load this dataset through a Kedro ipython session with the command:\r\n\r\n```python\r\ndf = catalog.load('test_json')\r\n```\r\n\r\nI get the following error message:\r\n\r\n```\r\nDataSetError: Failed while loading data from data set JSONDataSet(filepath=data/01_raw/test.json.gz, load_args={'compression': gzip, 'lines': True}, protocol=file).\r\n'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\r\n```\r\n\r\nI did some digging and it turns out GZIP adds an additional byte character, [see here](https://stackoverflow.com/a/44660123/1112091).\r\n\r\nThen, I decided to look under the hood of JSONDataSet's load function and I found the following in `kedro/io/json_dataset.py` lines 138-142: https://github.com/quantumblacklabs/kedro/blob/master/kedro/io/json_dataset.py#L138-L142\r\n```python\r\n    def _load(self) -> Any:\r\n        load_path = get_filepath_str(self._get_load_path(), self._protocol)\r\n\r\n        with self._fs.open(load_path, mode=\"r\") as fs_file:\r\n            return pd.read_json(fs_file, **self._load_args)\r\n```\r\n\r\nIt looks as through by forcing the file to be read initially through the filesystem, it is complaining about the startbyte. Can I ask why there is an explicit need to read the file first and then invoke pandas? Couldn't this be done directly through\r\n```python\r\nreturn pd.read_json(load_path, **self._load_args)\r\n```\r\n\r\nThat would resolve the issue I am currently having with reading the gzip compressed json file\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/287", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/287/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/287/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/287/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/287", "id": 580205355, "node_id": "MDU6SXNzdWU1ODAyMDUzNTU=", "number": 287, "title": "[KED-1474] SparkSession initialized when using parallel runner throws random errors", "user": {"login": "adengappa", "id": 10382844, "node_id": "MDQ6VXNlcjEwMzgyODQ0", "avatar_url": "https://avatars0.githubusercontent.com/u/10382844?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adengappa", "html_url": "https://github.com/adengappa", "followers_url": "https://api.github.com/users/adengappa/followers", "following_url": "https://api.github.com/users/adengappa/following{/other_user}", "gists_url": "https://api.github.com/users/adengappa/gists{/gist_id}", "starred_url": "https://api.github.com/users/adengappa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adengappa/subscriptions", "organizations_url": "https://api.github.com/users/adengappa/orgs", "repos_url": "https://api.github.com/users/adengappa/repos", "events_url": "https://api.github.com/users/adengappa/events{/privacy}", "received_events_url": "https://api.github.com/users/adengappa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-12T20:37:53Z", "updated_at": "2020-04-21T15:07:50Z", "closed_at": "2020-04-21T14:19:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI'm trying to use Kedro's parallel runner to parallelize a few independent pipelines in my set of pipelines which have only sparkDatasets as input. Unfortunately  unable to do so since parallel runner with a pre established sparkSession. or spark-submit.\r\n\r\n## Context\r\nHow has this bug affected you? What were you trying to accomplish?\r\nTrying to achieve parallelism when possible in my set of pipelines.\r\nSet of pipelines I have run as expected when I use sequentialRunner. I have used both kedro cli and spark-submit and both these ways work just fine.\r\nbut when I use parallel runner, in spite of all intermediate results being persisted - execution stops soon after loading my first dataset returning me inconsistent/random errors. \r\nThis happens specifically if sparkSession is initialized in run.py as mentioned in the documentation. \r\n\r\n\r\n## Steps to Reproduce\r\n1. setup at least 2 SparkDatasets in catalog\r\n2. Define a simple node that reads and writes(also a sparkDataset) for a pipeline that can run in parallel for 2 datasets\r\n3. Initialize sparkSession in run.py\r\n4. Execute the pipeline with parallel runner\r\n\r\n\r\n## Expected Result\r\nExecution be parallel and should complete without any issues. eg: 2 output files be created\r\n\r\n## Actual Result\r\nA random set of errors are thrown from the execution. \r\n\r\nThere errors are in no order.\r\nSame execution gives random errors in no order\r\n\r\n##############################################################################################################\r\n    return SparkSession.builder.getOrCreate()\r\n  File \"/usr/hdp/current/spark2-client/python/lib/pyspark.zip/pyspark/sql/session.py\", line 183, in getOrCreate\r\n    session._jsparkSession.sessionState().conf().setConfString(key, value)\r\nAttributeError: 'NoneType' object has no attribute 'conf'\r\n###############################################################################################################\r\nWARN FileStreamSink: Error while looking for metadata directory.\r\nconcurrent.futures.process._RemoteTraceback:\r\n\"\"\"\r\nTraceback (most recent call last):\r\n  File \"/home/user.name/.local/lib/python3.6/site-packages/kedro/io/core.py\", line 194, in load\r\n    return self._load()\r\n  File \"/home/user.name/.local/lib/python3.6/site-packages/kedro/contrib/io/pyspark/spark_data_set.py\", line 246, in _load\r\n    load_path, self._file_format, **self._load_args\r\n  File \"/home/user.name/.local/lib/python3.6/site-packages/pyspark/sql/readwriter.py\", line 166, in load\r\n    return self._df(self._jreader.load(path))\r\nAttributeError: 'NoneType' object has no attribute 'load'\r\n##################################################################################################################\r\nThe above exception was the direct cause of the following exception:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/concurrent/futures/process.py\", line 175, in _process_worker\r\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\r\n  File \"/home/user.name/.local/lib/python3.6/site-packages/kedro/runner/runner.py\", line 180, in run_node\r\n    inputs = {name: catalog.load(name) for name in node.inputs}\r\n  File \"/home/user.name/.local/lib/python3.6/site-packages/kedro/runner/runner.py\", line 180, in <dictcomp>\r\n    inputs = {name: catalog.load(name) for name in node.inputs}\r\n  File \"/home/user.name/.local/lib/python3.6/site-packages/kedro/io/data_catalog.py\", line 318, in load\r\n    result = func()\r\n  File \"/home/user.name/.local/lib/python3.6/site-packages/kedro/io/core.py\", line 560, in load\r\n    return super().load()\r\n  File \"/home/user.name/.local/lib/python3.6/site-packages/kedro/io/core.py\", line 203, in load\r\n    raise DataSetError(message) from exc\r\nkedro.io.core.DataSetError: Failed while loading data from data set SparkDataSet(file_format=parquet, filepath=s3a://abc/file/).\r\n'NoneType' object has no attribute 'load'\r\n\r\n######################################################################################################################\r\nThe above exception was the direct cause of the following exception:\r\nTraceback (most recent call last):\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/bin/kedro\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/kedro/cli/cli.py\", line 638, in main\r\n    (\"Project specific commands\", project_groups),\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/click/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/click/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/click/core.py\", line 1137, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/click/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/click/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"/Users/sriram_ravichandran/dev/odysseyDemo/kedro_cli.py\", line 274, in run\r\n    pipeline_name=pipeline,\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/kedro/context/context.py\", line 479, in run\r\n    return runner.run(filtered_pipeline, catalog)\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/kedro/runner/runner.py\", line 82, in run\r\n    self._run(pipeline, catalog)\r\n  File \"/Users/sriram_ravichandran/.virtualenvs/test/lib/python3.7/site-packages/kedro/runner/parallel_runner.py\", line 259, in _run\r\n    node = future.result()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\r\n    return self.__get_result()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\r\n    raise self._exception\r\nKeyError: 'c'\r\n\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\nenv1\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.15.5\r\n* Python version used (`python -V`): 3.6.3\r\n* Operating system and version: RHEL7\r\n* Spark : 2.3.2\r\n\r\nenv2\r\n* Kedro version used (`pip show kedro` or `kedro -V`): 0.15.5\r\n* Python version used (`python -V`): 3.7.5\r\n* Operating system and version: Mac Catalina\r\n* Spark : 2.4.5\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/283", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/283/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/283/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/283/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/283", "id": 579717713, "node_id": "MDU6SXNzdWU1Nzk3MTc3MTM=", "number": 283, "title": "[KED-1467] Create an API Dataset", "user": {"login": "ppsimatikas", "id": 10731738, "node_id": "MDQ6VXNlcjEwNzMxNzM4", "avatar_url": "https://avatars0.githubusercontent.com/u/10731738?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppsimatikas", "html_url": "https://github.com/ppsimatikas", "followers_url": "https://api.github.com/users/ppsimatikas/followers", "following_url": "https://api.github.com/users/ppsimatikas/following{/other_user}", "gists_url": "https://api.github.com/users/ppsimatikas/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppsimatikas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppsimatikas/subscriptions", "organizations_url": "https://api.github.com/users/ppsimatikas/orgs", "repos_url": "https://api.github.com/users/ppsimatikas/repos", "events_url": "https://api.github.com/users/ppsimatikas/events{/privacy}", "received_events_url": "https://api.github.com/users/ppsimatikas/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-03-12T06:16:42Z", "updated_at": "2020-04-07T15:20:32Z", "closed_at": "2020-04-07T15:20:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nI would like an API Dataset. Example:\r\n\r\nus_corn_yield_data:\r\n  type: kedro.extras.api.APIDataSet\r\n  url: https://quickstats.nass.usda.gov\r\n  params:\r\n    key: API_KEY\r\n    format: JSON\r\n    commodity_desc: CORN\r\n    statisticcat_des: YIELD\r\n    agg_level_desc: STATE\r\n    year: 2000\r\n\r\n## Context\r\nAs a data engineer I always need to fetch data from restful APIs.\r\nHaving a common dataset of doing so would be great and helpful to my current study and any future studies using kedro.\r\n\r\n## Possible Implementation\r\n(Optional) Suggest an idea for implementing the addition or change.\r\n\r\n## Possible Alternatives\r\n(Optional) Describe any alternative solutions or features you've considered.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/282", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/282/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/282/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/282/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/282", "id": 579291580, "node_id": "MDU6SXNzdWU1NzkyOTE1ODA=", "number": 282, "title": "Parameter variations during single kedro execution instance (multiple Pipeline executions with different parameters)", "user": {"login": "Mar1cX", "id": 12726926, "node_id": "MDQ6VXNlcjEyNzI2OTI2", "avatar_url": "https://avatars2.githubusercontent.com/u/12726926?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mar1cX", "html_url": "https://github.com/Mar1cX", "followers_url": "https://api.github.com/users/Mar1cX/followers", "following_url": "https://api.github.com/users/Mar1cX/following{/other_user}", "gists_url": "https://api.github.com/users/Mar1cX/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mar1cX/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mar1cX/subscriptions", "organizations_url": "https://api.github.com/users/Mar1cX/orgs", "repos_url": "https://api.github.com/users/Mar1cX/repos", "events_url": "https://api.github.com/users/Mar1cX/events{/privacy}", "received_events_url": "https://api.github.com/users/Mar1cX/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-11T14:08:24Z", "updated_at": "2020-03-20T12:51:45Z", "closed_at": "2020-03-20T12:51:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "## What are you trying to do?\r\nHello. I will start with that I'm still new at Kedro and I haven't explored every part of it yet, but I have a grasp of how things overly work. During development of Pipeline architecture it looks like that there is no clear way of making defined parameter variations. What I mean by that (in parameters.yml file) I would want to define:\r\n```\r\nparameter1: [1, 2]\r\nparameter2: [['a', 'aa'], ['b', 'bb']]\r\n```\r\nAfter that when executing `kedro run` I would have Pipeline executed four times, with those kind of parameter variations:\r\n```\r\nparameter1: 1\r\nparameter2: ['a', 'aa']\r\n\r\nparameter1: 1\r\nparameter2: ['b', 'bb']\r\n\r\nparameter1: 2\r\nparameter2: ['a', 'aa']\r\n\r\nparameter1: 2\r\nparameter2: ['b', 'bb']\r\n```\r\n\r\nThis kind of requirement happens sometimes when you try to simulate data manipulation with different parameters during multiple times of pipeline execution. Something similar as hyperparameters search which tools like sklearn GridSearch do. Also I can see small limitations with GridSearch usage for example. I might have missed the possible solutions during exploring of documentation.\r\n\r\nThanks for an answer in an advance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/279", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/279/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/279/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/279/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/279", "id": 577912394, "node_id": "MDU6SXNzdWU1Nzc5MTIzOTQ=", "number": 279, "title": "[KED-1466] SparkHiveDataSet is slow to initialize in Databricks", "user": {"login": "MigQ2", "id": 18492295, "node_id": "MDQ6VXNlcjE4NDkyMjk1", "avatar_url": "https://avatars3.githubusercontent.com/u/18492295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MigQ2", "html_url": "https://github.com/MigQ2", "followers_url": "https://api.github.com/users/MigQ2/followers", "following_url": "https://api.github.com/users/MigQ2/following{/other_user}", "gists_url": "https://api.github.com/users/MigQ2/gists{/gist_id}", "starred_url": "https://api.github.com/users/MigQ2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MigQ2/subscriptions", "organizations_url": "https://api.github.com/users/MigQ2/orgs", "repos_url": "https://api.github.com/users/MigQ2/repos", "events_url": "https://api.github.com/users/MigQ2/events{/privacy}", "received_events_url": "https://api.github.com/users/MigQ2/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-09T13:33:11Z", "updated_at": "2020-05-21T12:04:54Z", "closed_at": "2020-05-21T12:04:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI'm using `SparkHiveDataSet` to connect with some Databricks tables and I have seen that the code in **`SparkHiveDataSet.__init__()` loads the dataset to find the columns it has** and checks if the table already exists. This triggers a short spark action which takes little time (~5 seconds) for each dataset when the catalog is initialized. Therefore, if I have **hundreds of `SparkHiveDataSet`s in my catalog initializing a `kedro ipython` session takes several minutes** even if I just want to do a quick analysis with one dataset.\r\n\r\nBy reading the source code I have seen that the actions come from the following methods, which are invoked when a `SparkHiveDataSet` is initialized:\r\n\r\n* `SparkHiveDataSet._exists()`\r\n* `SparkHiveDataSet._load()`\r\n\r\n\r\n## Steps to Reproduce\r\n1. Create many `SparkHiveDataSet` in the catalog that point to tables declared in Databricks  \r\n2. Initialize the kedro catalog\r\n\r\n## Expected Result\r\nKedro context and the catalog get initialized quickly (<30 seconds)\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro 0.15.5\r\n* Python 3.7\r\n* Databricks connect 6.4\r\n* Windows 10 \r\n\r\n## Possible solution\r\nDon't trigger any spark action to inspect the schema when initializing the dataset, just when it needs to be accessed with `_load()` or `_save()`. Also caching the result could help speeding things up if the dataset is used many times in a single kedro run.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/277", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/277/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/277/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/277/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/277", "id": 576879887, "node_id": "MDU6SXNzdWU1NzY4Nzk4ODc=", "number": 277, "title": "[KED-1475] SparkDataSet fails in Windows using Databricks connect when reading from DBFS", "user": {"login": "MigQ2", "id": 18492295, "node_id": "MDQ6VXNlcjE4NDkyMjk1", "avatar_url": "https://avatars3.githubusercontent.com/u/18492295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MigQ2", "html_url": "https://github.com/MigQ2", "followers_url": "https://api.github.com/users/MigQ2/followers", "following_url": "https://api.github.com/users/MigQ2/following{/other_user}", "gists_url": "https://api.github.com/users/MigQ2/gists{/gist_id}", "starred_url": "https://api.github.com/users/MigQ2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MigQ2/subscriptions", "organizations_url": "https://api.github.com/users/MigQ2/orgs", "repos_url": "https://api.github.com/users/MigQ2/repos", "events_url": "https://api.github.com/users/MigQ2/events{/privacy}", "received_events_url": "https://api.github.com/users/MigQ2/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-06T11:46:00Z", "updated_at": "2020-04-06T11:48:00Z", "closed_at": "2020-04-06T11:45:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nUsing a Windows machine with Databricks connect to load a `SparkDataSet` in DBFS throws an Exception\r\n\r\n## Context\r\n`SparkDataSet` implementation in Windows creates the `_filepath` attribute using `Path()` in `__init__()`, except when the filepath prefix is for S3 or HDFS, in which case there is a special logic. \r\nThis way a `WindowsPath` is generated by default, but if we want to reference a DBFS filepath if fails when loading the dataset because the `WindowsPath` gets backslashes `\\` as separator when converting to a string\r\n\r\n## Steps to Reproduce\r\n1. Load a SparkDataSet where the filepath references DBFS in a Windows machine using Databricks-connect\r\n\r\n## Expected Result\r\nThe DataSet gets actually loaded\r\n\r\n## Actual Result\r\nAn Exception is raised\r\n\r\n```\r\nkedro.io.core.DataSetError: Failed while loading data from data set SparkDataSet(file_format=parquet, filepath=dbfs://mnt\\this\\is\\my\\dbfs\\path). 'Can not create a Path from an empty string' \r\n```\r\n\r\n\r\n## Your Environment\r\n\r\n* Kedro 0.15.5\r\n* Python 3.7.6\r\n* Windows 10 \r\n* Databricks-connect 6.1.0\r\n\r\n## Possible implementation to fix\r\n\r\nI can think of two ways of fixing this, but I'd like to hear your thoughts:\r\n\r\n1. Create another special case for `dbfs://` prefix in `SparkDataSet.__init__` and create a `PurePosixPath` instead of a `Path` when the prefix is specified. This would still fail when the `dbfs://` prefix is not specified, which creates an inconsistent behavior with Unix systems \r\n2. Inspect the `pyspark` module at runtime to guess whether local Spark or databricks-connect is being used and based on that decide whether to use `PurePosixPath` or `Path`. I don't know if there is an elegant way of doing this.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/275", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/275/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/275/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/275/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/275", "id": 576040155, "node_id": "MDU6SXNzdWU1NzYwNDAxNTU=", "number": 275, "title": "[KED-1458] Versioning extremely slow on DBFS", "user": {"login": "deepyaman", "id": 14007150, "node_id": "MDQ6VXNlcjE0MDA3MTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/14007150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepyaman", "html_url": "https://github.com/deepyaman", "followers_url": "https://api.github.com/users/deepyaman/followers", "following_url": "https://api.github.com/users/deepyaman/following{/other_user}", "gists_url": "https://api.github.com/users/deepyaman/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepyaman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepyaman/subscriptions", "organizations_url": "https://api.github.com/users/deepyaman/orgs", "repos_url": "https://api.github.com/users/deepyaman/repos", "events_url": "https://api.github.com/users/deepyaman/events{/privacy}", "received_events_url": "https://api.github.com/users/deepyaman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842407, "node_id": "MDU6TGFiZWwxMzcxODQyNDA3", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Bug%20Report", "name": "Issue: Bug Report", "color": "E74C3C", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-03-05T07:12:44Z", "updated_at": "2020-03-31T17:24:52Z", "closed_at": "2020-03-31T17:21:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nOur pipeline running on Azure Databricks has gotten progressively slower. Somebody noticed that running on a fresh set of paths (without so many versions) was significantly faster. Further investigation yielded that it wasn't because of the data itself; instead, it's finding the existing versions that's prohibitively slow. Specifically, underlying functions used by `iglob` (like `os.scandir`) are much slower than their DBFS-native counterparts (e.g. `dbutils.fs.ls`).\r\n\r\n## Context\r\nPipelines that should take less than 2 hours are taking 3-5 times that.\r\n\r\n## Steps to Reproduce\r\n\r\nOn a Databricks cluster:\r\n\r\n1. Save a versioned `SparkDataSet`.\r\n2. Load it back.\r\n3. Save the same dataset 500 more times.\r\n4. Load it back.\r\n\r\n## Expected Result\r\nTime taken for Step 4 should remain quite similar to that for Step 2.\r\n\r\n## Actual Result\r\nTime explodes. \ud83c\udf0b \r\n\r\n## Possible Implementation\r\n\r\nSee `DBFSDirEntry`, `_get_dbutils`, `_dbfs_scandir`, and patches below:\r\n\r\n```python3\r\n# Copyright 2020 QuantumBlack Visual Analytics Limited\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n# http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\r\n# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND\r\n# NONINFRINGEMENT. IN NO EVENT WILL THE LICENSOR OR OTHER CONTRIBUTORS\r\n# BE LIABLE FOR ANY CLAIM, DAMAGES, OR OTHER LIABILITY, WHETHER IN AN\r\n# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF, OR IN\r\n# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n#\r\n# The QuantumBlack Visual Analytics Limited (\"QuantumBlack\") name and logo\r\n# (either separately or in combination, \"QuantumBlack Trademarks\") are\r\n# trademarks of QuantumBlack. The License does not grant you any right or\r\n# license to the QuantumBlack Trademarks. You may not use the QuantumBlack\r\n# Trademarks or any confusingly similar mark as a trademark for your product,\r\n#     or use the QuantumBlack Trademarks in any other manner that might cause\r\n# confusion in the marketplace, including but not limited to in advertising,\r\n# on websites, or on software.\r\n#\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\r\n\"\"\"``AbstractDataSet`` implementation to access Spark data frames using\r\n``pyspark``\r\n\"\"\"\r\n\r\nfrom contextlib import contextmanager\r\nfrom copy import deepcopy\r\nfrom fnmatch import fnmatch\r\nfrom pathlib import Path, PurePosixPath\r\nfrom typing import Any, Dict, List, Tuple\r\nfrom unittest.mock import patch\r\nfrom warnings import warn\r\n\r\nimport IPython\r\nfrom hdfs import HdfsError, InsecureClient\r\nfrom pyspark.sql import DataFrame, SparkSession\r\nfrom pyspark.sql.utils import AnalysisException\r\nfrom s3fs import S3FileSystem\r\n\r\nfrom kedro.contrib.io import DefaultArgumentsMixIn  # isort:skip\r\nfrom kedro.io import AbstractVersionedDataSet, Version  # isort:skip\r\n\r\n\r\ndef _parse_glob_pattern(pattern: str) -> str:\r\n    special = (\"*\", \"?\", \"[\")\r\n    clean = []\r\n    for part in pattern.split(\"/\"):\r\n        if any(char in part for char in special):\r\n            break\r\n        clean.append(part)\r\n    return \"/\".join(clean)\r\n\r\n\r\ndef _split_filepath(filepath: str) -> Tuple[str, str]:\r\n    split_ = filepath.split(\"://\", 1)\r\n    if len(split_) == 2:\r\n        return split_[0] + \"://\", split_[1]\r\n    return \"\", split_[0]\r\n\r\n\r\ndef _strip_dbfs_prefix(path: str) -> str:\r\n    return path[len(\"/dbfs\") :] if path.startswith(\"/dbfs\") else path\r\n\r\n\r\nclass DBFSDirEntry:\r\n    \"\"\"Mock ``DirEntry`` object yielded by DBUtils-based ``scandir``.\"\"\"\r\n\r\n    def __init__(self, file_info):\r\n        self.name = file_info.name\r\n        self.path = file_info.path\r\n        self._is_dir = file_info.isDir()\r\n\r\n    def is_dir(self):\r\n        \"\"\"Return True if the entry is a directory.\"\"\"\r\n        return self._is_dir\r\n\r\n\r\ndef _get_dbutils():\r\n    return IPython.get_ipython().user_ns[\"dbutils\"]\r\n\r\n\r\n@contextmanager\r\ndef _dbfs_scandir(path):\r\n    yield map(DBFSDirEntry, _get_dbutils().fs.ls(_strip_dbfs_prefix(path)))\r\n\r\n\r\nclass KedroHdfsInsecureClient(InsecureClient):\r\n    \"\"\"Subclasses ``hdfs.InsecureClient`` and implements ``hdfs_exists``\r\n    and ``hdfs_glob`` methods required by ``SparkDataSet``\"\"\"\r\n\r\n    def hdfs_exists(self, hdfs_path: str) -> bool:\r\n        \"\"\"Determines whether given ``hdfs_path`` exists in HDFS.\r\n\r\n        Args:\r\n            hdfs_path: Path to check.\r\n\r\n        Returns:\r\n            True if ``hdfs_path`` exists in HDFS, False otherwise.\r\n        \"\"\"\r\n        return bool(self.status(hdfs_path, strict=False))\r\n\r\n    def hdfs_glob(self, pattern: str) -> List[str]:\r\n        \"\"\"Perform a glob search in HDFS using the provided pattern.\r\n\r\n        Args:\r\n            pattern: Glob pattern to search for.\r\n\r\n        Returns:\r\n            List of HDFS paths that satisfy the glob pattern.\r\n        \"\"\"\r\n        prefix = _parse_glob_pattern(pattern) or \"/\"\r\n        matched = set()\r\n        try:\r\n            for dpath, _, fnames in self.walk(prefix):\r\n                if fnmatch(dpath, pattern):\r\n                    matched.add(dpath)\r\n                matched |= set(\r\n                    \"{}/{}\".format(dpath, fname)\r\n                    for fname in fnames\r\n                    if fnmatch(\"{}/{}\".format(dpath, fname), pattern)\r\n                )\r\n        except HdfsError:  # pragma: no cover\r\n            # HdfsError is raised by `self.walk()` if prefix does not exist in HDFS.\r\n            # Ignore and return an empty list.\r\n            pass\r\n        return sorted(matched)\r\n\r\n\r\nclass SparkDataSet(DefaultArgumentsMixIn, AbstractVersionedDataSet):\r\n    \"\"\"``SparkDataSet`` loads and saves Spark data frames.\r\n\r\n    Example:\r\n    ::\r\n\r\n        >>> from pyspark.sql import SparkSession\r\n        >>> from pyspark.sql.types import (StructField, StringType,\r\n        >>>                                IntegerType, StructType)\r\n        >>>\r\n        >>> from kedro.contrib.io.pyspark import SparkDataSet\r\n        >>>\r\n        >>> schema = StructType([StructField(\"name\", StringType(), True),\r\n        >>>                      StructField(\"age\", IntegerType(), True)])\r\n        >>>\r\n        >>> data = [('Alex', 31), ('Bob', 12), ('Clarke', 65), ('Dave', 29)]\r\n        >>>\r\n        >>> spark_df = SparkSession.builder.getOrCreate()\\\r\n        >>>                        .createDataFrame(data, schema)\r\n        >>>\r\n        >>> data_set = SparkDataSet(filepath=\"test_data\")\r\n        >>> data_set.save(spark_df)\r\n        >>> reloaded = data_set.load()\r\n        >>>\r\n        >>> reloaded.take(4)\r\n    \"\"\"\r\n\r\n    def _describe(self) -> Dict[str, Any]:\r\n        return dict(\r\n            filepath=self._fs_prefix + str(self._filepath),\r\n            file_format=self._file_format,\r\n            load_args=self._load_args,\r\n            save_args=self._save_args,\r\n            version=self._version,\r\n        )\r\n\r\n    def __init__(  # pylint: disable=too-many-arguments\r\n        self,\r\n        filepath: str,\r\n        file_format: str = \"parquet\",\r\n        load_args: Dict[str, Any] = None,\r\n        save_args: Dict[str, Any] = None,\r\n        version: Version = None,\r\n        credentials: Dict[str, Any] = None,\r\n    ) -> None:\r\n        \"\"\"Creates a new instance of ``SparkDataSet``.\r\n\r\n        Args:\r\n            filepath: path to a Spark data frame. When using Databricks\r\n                and working with data written to mount path points,\r\n                specify ``filepath``s for (versioned) ``SparkDataSet``s\r\n                starting with ``/dbfs/mnt``.\r\n            file_format: file format used during load and save\r\n                operations. These are formats supported by the running\r\n                SparkContext include parquet, csv. For a list of supported\r\n                formats please refer to Apache Spark documentation at\r\n                https://spark.apache.org/docs/latest/sql-programming-guide.html\r\n            load_args: Load args passed to Spark DataFrameReader load method.\r\n                It is dependent on the selected file format. You can find\r\n                a list of read options for each supported format\r\n                in Spark DataFrame read documentation:\r\n                https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\r\n            save_args: Save args passed to Spark DataFrame write options.\r\n                Similar to load_args this is dependent on the selected file\r\n                format. You can pass ``mode`` and ``partitionBy`` to specify\r\n                your overwrite mode and partitioning respectively. You can find\r\n                a list of options for each format in Spark DataFrame\r\n                write documentation:\r\n                https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\r\n            version: If specified, should be an instance of\r\n                ``kedro.io.core.Version``. If its ``load`` attribute is\r\n                None, the latest version will be loaded. If its ``save``\r\n                attribute is None, save version will be autogenerated.\r\n            credentials: Credentials to access the S3 bucket, such as\r\n                ``aws_access_key_id``, ``aws_secret_access_key``, if ``filepath``\r\n                prefix is ``s3a://`` or ``s3n://``. Optional keyword arguments passed to\r\n                ``hdfs.client.InsecureClient`` if ``filepath`` prefix is ``hdfs://``.\r\n                Ignored otherwise.\r\n        \"\"\"\r\n        credentials = deepcopy(credentials) or {}\r\n        fs_prefix, filepath = _split_filepath(filepath)\r\n\r\n        if fs_prefix in (\"s3a://\", \"s3n://\"):\r\n            if fs_prefix == \"s3n://\":\r\n                warn(\r\n                    \"`s3n` filesystem has now been deprecated by Spark, \"\r\n                    \"please consider switching to `s3a`\",\r\n                    DeprecationWarning,\r\n                )\r\n            _s3 = S3FileSystem(client_kwargs=credentials)\r\n            exists_function = _s3.exists\r\n            glob_function = _s3.glob\r\n            path = PurePosixPath(filepath)\r\n\r\n        elif fs_prefix == \"hdfs://\" and version:\r\n            warn(\r\n                \"HDFS filesystem support for versioned {} is in beta and uses \"\r\n                \"`hdfs.client.InsecureClient`, please use with caution\".format(\r\n                    self.__class__.__name__\r\n                )\r\n            )\r\n\r\n            # default namenode address\r\n            credentials.setdefault(\"url\", \"http://localhost:9870\")\r\n            credentials.setdefault(\"user\", \"hadoop\")\r\n\r\n            _hdfs_client = KedroHdfsInsecureClient(**credentials)\r\n            exists_function = _hdfs_client.hdfs_exists\r\n            glob_function = _hdfs_client.hdfs_glob\r\n            path = PurePosixPath(filepath)\r\n\r\n        else:\r\n            exists_function = glob_function = None  # type: ignore\r\n            path = Path(filepath)  # type: ignore\r\n\r\n        super().__init__(\r\n            load_args=load_args,\r\n            save_args=save_args,\r\n            filepath=path,\r\n            version=version,\r\n            exists_function=exists_function,\r\n            glob_function=glob_function,\r\n        )\r\n\r\n        self._file_format = file_format\r\n        self._fs_prefix = fs_prefix\r\n\r\n    @staticmethod\r\n    def _get_spark():\r\n        return SparkSession.builder.getOrCreate()\r\n\r\n    @patch(\"os.scandir\", _dbfs_scandir)\r\n    def _load(self) -> DataFrame:\r\n        with patch(\"os.path.lexists\", return_value=True):\r\n            load_path = _strip_dbfs_prefix(self._fs_prefix + str(self._get_load_path()))\r\n        self._logger.info('`load_path = \"%s\"`', load_path)\r\n\r\n        return self._get_spark().read.load(\r\n            load_path, self._file_format, **self._load_args\r\n        )\r\n\r\n    @patch(\"os.scandir\", _dbfs_scandir)\r\n    def _save(self, data: DataFrame) -> None:\r\n        with patch(\"os.path.lexists\", return_value=True):\r\n            save_path = _strip_dbfs_prefix(self._fs_prefix + str(self._get_save_path()))\r\n        self._logger.info('`save_path = \"%s\"`', save_path)\r\n        data.write.save(save_path, self._file_format, **self._save_args)\r\n\r\n    @patch(\"os.scandir\", _dbfs_scandir)\r\n    def _exists(self) -> bool:\r\n        with patch(\"os.path.lexists\", return_value=True):\r\n            load_path = _strip_dbfs_prefix(self._fs_prefix + str(self._get_load_path()))\r\n        self._logger.info('`load_path = \"%s\"`', load_path)\r\n\r\n        try:\r\n            self._get_spark().read.load(load_path, self._file_format)\r\n        except AnalysisException as exception:\r\n            if exception.desc.startswith(\"Path does not exist:\"):\r\n                return False\r\n            raise\r\n        return True\r\n```\r\n\r\nI believe it's fine to have DBFS-specific code, as we already do. However, a few necessary enhancements:\r\n\r\n- [ ] Detect DBFS (e.g. look for `DATABRICKS_RUNTIME_VERSION` environment variable) and apply patches conditionally.\r\n- [ ] Apply to any dataset, not just `SparkDataSet`, when the filesystem is DBFS (versioning should be the same). => Actually implement this code as part of the versioning mix-in?\r\n\r\n## Possible Alternatives\r\n\r\n* Define a DBFS glob function from scratch (DBUtils doesn't provide one AFAIK).\r\n* Actually manage (archive?) versions instead of keeping hundreds. \u00af\\\\_(\u30c4)_/\u00af\r\n\r\n## Your Environment\r\nInclude as many relevant details about the environment in which you experienced the bug:\r\n\r\n* Kedro version used (`pip show kedro` or `kedro -V`): `0.15.5`\r\n* Python version used (`python -V`): Python 3.7.3\r\n* Operating system and version: Databricks Runtime Version 5.5 Conda Beta (includes Apache Spark 2.4.3, Scala 2.11)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/274", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/274/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/274/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/274/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/274", "id": 574814391, "node_id": "MDU6SXNzdWU1NzQ4MTQzOTE=", "number": 274, "title": "Getting errors Using SQL with Kedro", "user": {"login": "vincenzo-scotto001", "id": 44681272, "node_id": "MDQ6VXNlcjQ0NjgxMjcy", "avatar_url": "https://avatars1.githubusercontent.com/u/44681272?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vincenzo-scotto001", "html_url": "https://github.com/vincenzo-scotto001", "followers_url": "https://api.github.com/users/vincenzo-scotto001/followers", "following_url": "https://api.github.com/users/vincenzo-scotto001/following{/other_user}", "gists_url": "https://api.github.com/users/vincenzo-scotto001/gists{/gist_id}", "starred_url": "https://api.github.com/users/vincenzo-scotto001/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vincenzo-scotto001/subscriptions", "organizations_url": "https://api.github.com/users/vincenzo-scotto001/orgs", "repos_url": "https://api.github.com/users/vincenzo-scotto001/repos", "events_url": "https://api.github.com/users/vincenzo-scotto001/events{/privacy}", "received_events_url": "https://api.github.com/users/vincenzo-scotto001/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1837223503, "node_id": "MDU6TGFiZWwxODM3MjIzNTAz", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Question", "name": "Issue: Question", "color": "1d76db", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-03T17:09:16Z", "updated_at": "2020-03-06T19:34:07Z", "closed_at": "2020-03-06T19:34:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "What I am trying to do is pass in credentials to the catalog.yml file. The error I keep getting is: \r\n(pyodbc.InterfaceError) ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')\r\n(Background on this error at: http://sqlalche.me/e/rvf5)\r\n\r\nI checked my ODBC and tested all the drivers and all give me this error. Here is the connection string I am attempting to use:\r\n\"mssql+pyodbc://{driver}:username:password@IPaddress/dbname\"\r\n\r\nI also tried:\r\nmssql+pymssql://username:password@IPaddress/dbname\r\n\r\nThat also did not work. Any help would be appreciated!\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/273", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/273/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/273/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/273/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/273", "id": 574047578, "node_id": "MDU6SXNzdWU1NzQwNDc1Nzg=", "number": 273, "title": "request cli command - kedro list", "user": {"login": "WaylonWalker", "id": 22648375, "node_id": "MDQ6VXNlcjIyNjQ4Mzc1", "avatar_url": "https://avatars1.githubusercontent.com/u/22648375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WaylonWalker", "html_url": "https://github.com/WaylonWalker", "followers_url": "https://api.github.com/users/WaylonWalker/followers", "following_url": "https://api.github.com/users/WaylonWalker/following{/other_user}", "gists_url": "https://api.github.com/users/WaylonWalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/WaylonWalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WaylonWalker/subscriptions", "organizations_url": "https://api.github.com/users/WaylonWalker/orgs", "repos_url": "https://api.github.com/users/WaylonWalker/repos", "events_url": "https://api.github.com/users/WaylonWalker/events{/privacy}", "received_events_url": "https://api.github.com/users/WaylonWalker/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-02T15:21:26Z", "updated_at": "2020-03-02T15:28:57Z", "closed_at": "2020-03-02T15:28:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nI have some use cases where it would be nice to list things out of the command line. \r\n\r\n\r\n## Context\r\n\r\nI would like to do things such as saving all pipelines to JSON from the command line, but in order to do that, I need a way to list the pipelines.\r\n\r\n## Possible Implementation\r\n I think rather than cluttering all the top level with many list commands I think a single list command with various flags would be appropriate.\r\n\r\n``` bash\r\n\u276f kedro list --help\r\nUsage: kedro list [OPTIONS]\r\n\r\n  list things about the project\r\n\r\nOptions:\r\n  -p, --pipelines\r\n  -t, -- tags\r\n  -l, -- layers\r\n  -d, -- datasets\r\n  -n, -- nodes\r\n  -- parameters\r\n```\r\n\r\n## Possible Alternatives\r\n\r\nI am open to anything you have.\r\n\r\n\r\n# \ud83d\udc4f Thank You\r\n\r\nThank you for open sourcing everything in and around kedro, it is such an amazing project!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/272", "repository_url": "https://api.github.com/repos/quantumblacklabs/kedro", "labels_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/272/labels{/name}", "comments_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/272/comments", "events_url": "https://api.github.com/repos/quantumblacklabs/kedro/issues/272/events", "html_url": "https://github.com/quantumblacklabs/kedro/issues/272", "id": 573482247, "node_id": "MDU6SXNzdWU1NzM0ODIyNDc=", "number": 272, "title": "Installation instruction does not contain set up with Docker", "user": {"login": "iamkuldeepsingh", "id": 26478064, "node_id": "MDQ6VXNlcjI2NDc4MDY0", "avatar_url": "https://avatars3.githubusercontent.com/u/26478064?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iamkuldeepsingh", "html_url": "https://github.com/iamkuldeepsingh", "followers_url": "https://api.github.com/users/iamkuldeepsingh/followers", "following_url": "https://api.github.com/users/iamkuldeepsingh/following{/other_user}", "gists_url": "https://api.github.com/users/iamkuldeepsingh/gists{/gist_id}", "starred_url": "https://api.github.com/users/iamkuldeepsingh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iamkuldeepsingh/subscriptions", "organizations_url": "https://api.github.com/users/iamkuldeepsingh/orgs", "repos_url": "https://api.github.com/users/iamkuldeepsingh/repos", "events_url": "https://api.github.com/users/iamkuldeepsingh/events{/privacy}", "received_events_url": "https://api.github.com/users/iamkuldeepsingh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1371842409, "node_id": "MDU6TGFiZWwxMzcxODQyNDA5", "url": "https://api.github.com/repos/quantumblacklabs/kedro/labels/Issue:%20Feature%20Request", "name": "Issue: Feature Request", "color": "1D9DD3", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-01T05:10:28Z", "updated_at": "2020-03-03T07:37:34Z", "closed_at": "2020-03-03T07:37:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nMost of the developers are using python with Docker now a days and I see instructions contain only conda and pycharm. I will suggest to have the setup with Docker as well\r\n\r\n## Context\r\nI still find it difficult to setup Kedro on localsetup, however when I did with Docker it was much simpler and reproducible, hence would like to add this feature and if needed I can do that and contribute as well\r\n\r\n## Possible Implementation\r\nWe could use a base python image or a standard image loaded with other packages and extend it\r\n\r\n## Possible Alternatives\r\n\r\n", "performed_via_github_app": null, "score": 1.0}]}