{"total_count": 658, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1829", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1829/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1829/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1829/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1829", "id": 653859600, "node_id": "MDU6SXNzdWU2NTM4NTk2MDA=", "number": 1829, "title": "What is the relation of tensor2tensor version and tensorflow version?", "user": {"login": "guotong1988", "id": 4702353, "node_id": "MDQ6VXNlcjQ3MDIzNTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4702353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guotong1988", "html_url": "https://github.com/guotong1988", "followers_url": "https://api.github.com/users/guotong1988/followers", "following_url": "https://api.github.com/users/guotong1988/following{/other_user}", "gists_url": "https://api.github.com/users/guotong1988/gists{/gist_id}", "starred_url": "https://api.github.com/users/guotong1988/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guotong1988/subscriptions", "organizations_url": "https://api.github.com/users/guotong1988/orgs", "repos_url": "https://api.github.com/users/guotong1988/repos", "events_url": "https://api.github.com/users/guotong1988/events{/privacy}", "received_events_url": "https://api.github.com/users/guotong1988/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-09T08:13:05Z", "updated_at": "2020-07-09T08:15:41Z", "closed_at": "2020-07-09T08:15:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "How to know the corresponding tensorflow version for each tensor2tensor version?\r\nThank you!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1824", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1824/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1824/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1824/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1824", "id": 647798913, "node_id": "MDU6SXNzdWU2NDc3OTg5MTM=", "number": 1824, "title": "module 'tensorflow' has no attribute 'compat'", "user": {"login": "teanon", "id": 43558191, "node_id": "MDQ6VXNlcjQzNTU4MTkx", "avatar_url": "https://avatars0.githubusercontent.com/u/43558191?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teanon", "html_url": "https://github.com/teanon", "followers_url": "https://api.github.com/users/teanon/followers", "following_url": "https://api.github.com/users/teanon/following{/other_user}", "gists_url": "https://api.github.com/users/teanon/gists{/gist_id}", "starred_url": "https://api.github.com/users/teanon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teanon/subscriptions", "organizations_url": "https://api.github.com/users/teanon/orgs", "repos_url": "https://api.github.com/users/teanon/repos", "events_url": "https://api.github.com/users/teanon/events{/privacy}", "received_events_url": "https://api.github.com/users/teanon/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-30T02:19:27Z", "updated_at": "2020-06-30T02:42:01Z", "closed_at": "2020-06-30T02:42:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nWhen I ran https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/bin/t2t_datagen.py, \"import tensorflow.compat.v1 as tf \" gets error : module 'tensorflow' has no attribute 'compat'. How could I address this problem?\r\n\r\n\r\n### Environment information\r\ntensorflow-gpu 2.1\r\npython 3.7.6\r\nCUDA 10.1\r\n \r\n\r\n# Error logs:\r\nD:\\softInstallWay\\Anaconda\\envs\\tf21\\python.exe E:/\u9879\u76ee\u5b9e\u9a8c/\u5b9e\u9a8c\u5de5\u7a0b/tensor2tensor-1.15.7/tensor2tensor/bin/t2t_datagen.py\r\n2020-06-30 09:52:02.555396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\nTraceback (most recent call last):\r\n  File \"E:/\u9879\u76ee\u5b9e\u9a8c/\u5b9e\u9a8c\u5de5\u7a0b/tensor2tensor-1.15.7/tensor2tensor/bin/t2t_datagen.py\", line 39, in <module>\r\n    from tensor2tensor import problems as problems_lib  # pylint: disable=unused-import\r\n  File \"E:\\\u9879\u76ee\u5b9e\u9a8c\\\u5b9e\u9a8c\u5de5\u7a0b\\tensor2tensor-1.15.7\\tensor2tensor\\problems.py\", line 22, in <module>\r\n    from tensor2tensor.utils import registry\r\n  File \"E:\\\u9879\u76ee\u5b9e\u9a8c\\\u5b9e\u9a8c\u5de5\u7a0b\\tensor2tensor-1.15.7\\tensor2tensor\\utils\\registry.py\", line 72, in <module>\r\n    import tensorflow.compat.v1 as tf\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 46, in <module>\r\n    from . _api.v2 import compat\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 32, in <module>\r\n    from . import compat\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\", line 29, in <module>\r\n    from tensorflow._api.v2.compat.v1 import app\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 32, in <module>\r\n    from . import compat\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\", line 667, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1 import estimator\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_estimator\\__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1 import estimator\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1.estimator import experimental\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\experimental\\__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\", line 33, in <module>\r\n    from tensorflow_estimator.python.estimator import estimator\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 53, in <module>\r\n    from tensorflow_estimator.python.estimator import util as estimator_util\r\n  File \"D:\\softInstallWay\\Anaconda\\envs\\tf21\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\", line 75, in <module>\r\n    class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):\r\nAttributeError: **module 'tensorflow' has no attribute 'compat'**\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1822", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1822/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1822/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1822/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1822", "id": 637039459, "node_id": "MDU6SXNzdWU2MzcwMzk0NTk=", "number": 1822, "title": "How do underscore and punctuation are treated within a word?", "user": {"login": "andmek", "id": 16155556, "node_id": "MDQ6VXNlcjE2MTU1NTU2", "avatar_url": "https://avatars1.githubusercontent.com/u/16155556?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andmek", "html_url": "https://github.com/andmek", "followers_url": "https://api.github.com/users/andmek/followers", "following_url": "https://api.github.com/users/andmek/following{/other_user}", "gists_url": "https://api.github.com/users/andmek/gists{/gist_id}", "starred_url": "https://api.github.com/users/andmek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andmek/subscriptions", "organizations_url": "https://api.github.com/users/andmek/orgs", "repos_url": "https://api.github.com/users/andmek/repos", "events_url": "https://api.github.com/users/andmek/events{/privacy}", "received_events_url": "https://api.github.com/users/andmek/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-11T13:58:32Z", "updated_at": "2020-07-28T12:29:17Z", "closed_at": "2020-07-28T12:29:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "### How underscore and punctuation are treated within a word like in Internet addresses abc_trading.eu? \r\n\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1818", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1818/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1818/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1818/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1818", "id": 624653634, "node_id": "MDU6SXNzdWU2MjQ2NTM2MzQ=", "number": 1818, "title": "How to train a world model in other dataset?", "user": {"login": "Jthon", "id": 28537718, "node_id": "MDQ6VXNlcjI4NTM3NzE4", "avatar_url": "https://avatars0.githubusercontent.com/u/28537718?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jthon", "html_url": "https://github.com/Jthon", "followers_url": "https://api.github.com/users/Jthon/followers", "following_url": "https://api.github.com/users/Jthon/following{/other_user}", "gists_url": "https://api.github.com/users/Jthon/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jthon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jthon/subscriptions", "organizations_url": "https://api.github.com/users/Jthon/orgs", "repos_url": "https://api.github.com/users/Jthon/repos", "events_url": "https://api.github.com/users/Jthon/events{/privacy}", "received_events_url": "https://api.github.com/users/Jthon/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-26T07:15:43Z", "updated_at": "2020-06-08T11:17:33Z", "closed_at": "2020-06-08T11:17:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI was wondering if there were any possibilities to train the world model mentioned in the paper \"Model Based ReinForcement Learning For Atari\" in some other enviroments like Deepmind Lab rather than Atari? \r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1810", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1810/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1810/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1810/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1810", "id": 614240713, "node_id": "MDU6SXNzdWU2MTQyNDA3MTM=", "number": 1810, "title": "Custom Vocabulary for T2T Speech recognition model", "user": {"login": "bharat-patidar", "id": 34475219, "node_id": "MDQ6VXNlcjM0NDc1MjE5", "avatar_url": "https://avatars0.githubusercontent.com/u/34475219?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bharat-patidar", "html_url": "https://github.com/bharat-patidar", "followers_url": "https://api.github.com/users/bharat-patidar/followers", "following_url": "https://api.github.com/users/bharat-patidar/following{/other_user}", "gists_url": "https://api.github.com/users/bharat-patidar/gists{/gist_id}", "starred_url": "https://api.github.com/users/bharat-patidar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bharat-patidar/subscriptions", "organizations_url": "https://api.github.com/users/bharat-patidar/orgs", "repos_url": "https://api.github.com/users/bharat-patidar/repos", "events_url": "https://api.github.com/users/bharat-patidar/events{/privacy}", "received_events_url": "https://api.github.com/users/bharat-patidar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-05-07T17:58:29Z", "updated_at": "2020-05-16T23:05:22Z", "closed_at": "2020-05-16T23:05:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi team,\r\n\r\nIs it possible to add custom vocabulary on an already trained T2T Speech recognition model so that it can detect domain specific words?\r\n(Apologies if this question has already been asked, I couldn't locate relevant information)\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1808", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1808/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1808/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1808/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1808", "id": 611068254, "node_id": "MDU6SXNzdWU2MTEwNjgyNTQ=", "number": 1808, "title": "Output from language model is always the last character of input?", "user": {"login": "KosayJabre", "id": 20927595, "node_id": "MDQ6VXNlcjIwOTI3NTk1", "avatar_url": "https://avatars1.githubusercontent.com/u/20927595?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KosayJabre", "html_url": "https://github.com/KosayJabre", "followers_url": "https://api.github.com/users/KosayJabre/followers", "following_url": "https://api.github.com/users/KosayJabre/following{/other_user}", "gists_url": "https://api.github.com/users/KosayJabre/gists{/gist_id}", "starred_url": "https://api.github.com/users/KosayJabre/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KosayJabre/subscriptions", "organizations_url": "https://api.github.com/users/KosayJabre/orgs", "repos_url": "https://api.github.com/users/KosayJabre/repos", "events_url": "https://api.github.com/users/KosayJabre/events{/privacy}", "received_events_url": "https://api.github.com/users/KosayJabre/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-02T00:18:57Z", "updated_at": "2020-05-02T02:57:19Z", "closed_at": "2020-05-02T02:57:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, it's my first time using tensor2tensor, and I am very interested in trying out the character-level language model. However, I'm not able to find any examples or documentation on how to use the pretrained language model.\r\n\r\nI've tried to set up something on Google Colab to try and use the PTB small language model. \r\n\r\nI first do the initialization from the intro notebook:\r\n\r\n```\r\n# Imports we need.\r\nimport sys\r\nif 'google.colab' in sys.modules: # Colab-only TensorFlow version selector\r\n  %tensorflow_version 1.x\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport os\r\nimport collections\r\n\r\nfrom tensor2tensor import models\r\nfrom tensor2tensor import problems\r\nfrom tensor2tensor.layers import common_layers\r\nfrom tensor2tensor.utils import trainer_lib\r\nfrom tensor2tensor.utils import t2t_model\r\nfrom tensor2tensor.utils import registry\r\nfrom tensor2tensor.utils import metrics\r\n\r\n# Enable TF Eager execution\r\ntfe = tf.contrib.eager\r\ntfe.enable_eager_execution()\r\n\r\n# Other setup\r\nModes = tf.estimator.ModeKeys\r\n\r\n# Setup some directories\r\ndata_dir = os.path.expanduser(\"~/t2t/data\")\r\ntmp_dir = os.path.expanduser(\"~/t2t/tmp\")\r\ntrain_dir = os.path.expanduser(\"~/t2t/train\")\r\ncheckpoint_dir = os.path.expanduser(\"~/t2t/checkpoints\")\r\ntf.gfile.MakeDirs(data_dir)\r\ntf.gfile.MakeDirs(tmp_dir)\r\ntf.gfile.MakeDirs(train_dir)\r\ntf.gfile.MakeDirs(checkpoint_dir)\r\ngs_data_dir = \"gs://tensor2tensor-data\"\r\ngs_ckpt_dir = \"gs://tensor2tensor-checkpoints/\"\r\n```\r\n\r\nI define my problem, generate the data, and load a checkpoint:\r\n```\r\nproblem = problems.problem(\"languagemodel_ptb_characters\")\r\nproblem.generate_data(data_dir, tmp_dir)\r\n\r\nmodel_name = \"transformer\"\r\nhparams_set = \"transformer_small\"\r\nhparams = trainer_lib.create_hparams(hparams_set, data_dir=data_dir, problem_name=problem)\r\nlanguage_model = registry.model(model_name)(hparams, Modes.EVAL)\r\n\r\nckpt_path = tf.train.latest_checkpoint(os.path.join(data_dir, 'languagemodel_ptb_characters-train-00007-of-00010'))\r\n```\r\n\r\nThen I define my encode, decode, and predict functions:\r\n\r\n```\r\nencoders = problem.feature_encoders(data_dir)\r\n\r\ndef encode(input_str):\r\n  inputs = encoders[\"targets\"].encode(input_str)\r\n  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\r\n  return {\"inputs\": batch_inputs}\r\n\r\ndef decode(integers):\r\n  integers = list(np.squeeze(integers))\r\n  if 1 in integers:\r\n    integers = integers[:integers.index(1)]\r\n  return encoders[\"targets\"].decode(np.squeeze(integers))\r\n\r\ndef predict_next_input(inputs):\r\n  encoded_inputs = encode(inputs)\r\n  print(f\"Encoded input: {encoded_inputs}\")\r\n  with tfe.restore_variables_on_create(ckpt_path):\r\n    model_output = language_model.infer(encoded_inputs)[\"outputs\"]\r\n    print(model_output)\r\n  return decode(model_output)\r\n```\r\n\r\nHowever, when I do predict_next_input(), I always get back the last character of the input, when I expect it to predict the next character.\r\n\r\nSo for example:\r\n\r\n```\r\npredict_next_input(\"My name is Joh\")\r\n```\r\n\r\nGets:\r\n```\r\nEncoded input: {'inputs': <tf.Tensor: id=231560, shape=(1, 14, 1), dtype=int32, numpy=\r\narray([[[ 79],\r\n        [123],\r\n        [ 34],\r\n        [112],\r\n        [ 99],\r\n        [111],\r\n        [103],\r\n        [ 34],\r\n        [107],\r\n        [117],\r\n        [ 34],\r\n        [ 76],\r\n        [113],\r\n        [106]]], dtype=int32)>}\r\n\r\nOutputs: [[106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106\r\n  106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106\r\n  106 106 106 106 106 106 106 106 106 106 106 106 106 106]]\r\n\r\nDecoded outputs: 'hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh'\r\n```\r\n\r\nWhat am I doing wrong, and how can I fix this ?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1804", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1804/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1804/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1804/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1804", "id": 597682793, "node_id": "MDU6SXNzdWU1OTc2ODI3OTM=", "number": 1804, "title": "What does \"accuracy per sequence\" mean and how BLEU score is computed?", "user": {"login": "kbcao", "id": 30142877, "node_id": "MDQ6VXNlcjMwMTQyODc3", "avatar_url": "https://avatars0.githubusercontent.com/u/30142877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kbcao", "html_url": "https://github.com/kbcao", "followers_url": "https://api.github.com/users/kbcao/followers", "following_url": "https://api.github.com/users/kbcao/following{/other_user}", "gists_url": "https://api.github.com/users/kbcao/gists{/gist_id}", "starred_url": "https://api.github.com/users/kbcao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kbcao/subscriptions", "organizations_url": "https://api.github.com/users/kbcao/orgs", "repos_url": "https://api.github.com/users/kbcao/repos", "events_url": "https://api.github.com/users/kbcao/events{/privacy}", "received_events_url": "https://api.github.com/users/kbcao/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-04-10T04:06:32Z", "updated_at": "2020-04-24T04:11:55Z", "closed_at": "2020-04-24T04:11:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nHello, I have a question during my using t2t for a text2text problem.\r\nI defined a problem and used my own dataset for training, the tensorboard shows the evaluation metrics, which includes the accuracy, accuracy per sequence, and the BLEU score.\r\n\r\nMy question is\r\n1. what's the difference between \"accuracy\" and \"accuracy per sequence\"\r\n2. How is BLEU computed? (For a sequence or a token)\r\n\r\nLet's assume that my input is\r\n`input1, input2, input3`\r\nand the output is\r\n`output1, output2, output3, output4`\r\nand the ground truth is\r\n`truth1, output2, truth3`\r\n\r\nso, for this training example, what is the score of \"accuracy\" and \"accuracy per sequence\"? After reading the `metrics.py`, I think the \"accuracy\" is calculated for each token? (1/3 for this example since the output2 is predicted correctly), and \"accuracy per sequence\" is 0? (because only when the output and ground truth is completely identical (allow for the incorrect of output4) the value can be 1, and the \"accuracy per sequence\" is calculated as the `completely_matched_example`/`all_example`). Is this understanding correct?\r\n\r\nFor question 2, it is similar to question 1, when calculating the BLEU score, it is calculated for each example and calculate an average for all examples or it is calculated for each token and discard the concept of the \"examples\" (i.e. input a sentence and output a sentence).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1800", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1800/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1800/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1800/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1800", "id": 579175438, "node_id": "MDU6SXNzdWU1NzkxNzU0Mzg=", "number": 1800, "title": "Change decode hparams of an exported_model", "user": {"login": "bedapudi6788", "id": 15898654, "node_id": "MDQ6VXNlcjE1ODk4NjU0", "avatar_url": "https://avatars2.githubusercontent.com/u/15898654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bedapudi6788", "html_url": "https://github.com/bedapudi6788", "followers_url": "https://api.github.com/users/bedapudi6788/followers", "following_url": "https://api.github.com/users/bedapudi6788/following{/other_user}", "gists_url": "https://api.github.com/users/bedapudi6788/gists{/gist_id}", "starred_url": "https://api.github.com/users/bedapudi6788/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bedapudi6788/subscriptions", "organizations_url": "https://api.github.com/users/bedapudi6788/orgs", "repos_url": "https://api.github.com/users/bedapudi6788/repos", "events_url": "https://api.github.com/users/bedapudi6788/events{/privacy}", "received_events_url": "https://api.github.com/users/bedapudi6788/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-03-11T10:54:40Z", "updated_at": "2020-03-27T14:35:25Z", "closed_at": "2020-03-27T14:35:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI am experimenting with a speech-to-text model trained (by someone else) using t2t. I have access to the exported model (saved_model format) and am able to run decoding.\r\n\r\nRight now, the model only returns the top-1 ```outputs``` and  ```scores```\r\n\r\nIf I want to change decoding hparams (eg: beam width, return beams), would it possible to do just with the saved_model.\r\n\r\nI apologize if this is not the right place to ask this.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1798", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1798/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1798/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1798/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1798", "id": 578465074, "node_id": "MDU6SXNzdWU1Nzg0NjUwNzQ=", "number": 1798, "title": "Is it possible to decode with the best model?", "user": {"login": "bnr887", "id": 61744776, "node_id": "MDQ6VXNlcjYxNzQ0Nzc2", "avatar_url": "https://avatars1.githubusercontent.com/u/61744776?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bnr887", "html_url": "https://github.com/bnr887", "followers_url": "https://api.github.com/users/bnr887/followers", "following_url": "https://api.github.com/users/bnr887/following{/other_user}", "gists_url": "https://api.github.com/users/bnr887/gists{/gist_id}", "starred_url": "https://api.github.com/users/bnr887/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bnr887/subscriptions", "organizations_url": "https://api.github.com/users/bnr887/orgs", "repos_url": "https://api.github.com/users/bnr887/repos", "events_url": "https://api.github.com/users/bnr887/events{/privacy}", "received_events_url": "https://api.github.com/users/bnr887/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-10T10:04:52Z", "updated_at": "2020-05-13T04:57:03Z", "closed_at": "2020-05-13T04:57:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, I'm new to T2T and still trying to understand some concepts. I'd like to decode my input using the model which has the best loss on validation set. Is that possible? Does export_save_model do this? I found [this issue](https://github.com/tensorflow/tensor2tensor/pull/974) and \"export=FLAGS.export_saved_model\" in the t2t_trainer.py file.\r\n\r\nHowever, by using export_saved_model during my training, I couldn't observe any difference (it looks like still the latest models are saved into the train directory)?\r\n\r\nCan someone please explain me this?\r\n\r\nMany thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1795", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1795/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1795/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1795/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1795", "id": 574732880, "node_id": "MDU6SXNzdWU1NzQ3MzI4ODA=", "number": 1795, "title": "Question about Word Embeddings and Subword Encoding", "user": {"login": "bnr887", "id": 61744776, "node_id": "MDQ6VXNlcjYxNzQ0Nzc2", "avatar_url": "https://avatars1.githubusercontent.com/u/61744776?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bnr887", "html_url": "https://github.com/bnr887", "followers_url": "https://api.github.com/users/bnr887/followers", "following_url": "https://api.github.com/users/bnr887/following{/other_user}", "gists_url": "https://api.github.com/users/bnr887/gists{/gist_id}", "starred_url": "https://api.github.com/users/bnr887/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bnr887/subscriptions", "organizations_url": "https://api.github.com/users/bnr887/orgs", "repos_url": "https://api.github.com/users/bnr887/repos", "events_url": "https://api.github.com/users/bnr887/events{/privacy}", "received_events_url": "https://api.github.com/users/bnr887/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-03T15:05:57Z", "updated_at": "2020-03-03T15:42:13Z", "closed_at": "2020-03-03T15:42:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, as far as I understand, when we use subword encoding, word embeddings are initialized for each subword unit. But I couldn't understand how a word embedding is formed for a token using subword units. Are they concatenated?\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1786", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1786/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1786/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1786/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1786", "id": 563732703, "node_id": "MDU6SXNzdWU1NjM3MzI3MDM=", "number": 1786, "title": "tensor2tensor install: what is the suitable tensorflow-gpu version for tensor2tensor 1.15.4?", "user": {"login": "zide05", "id": 24726796, "node_id": "MDQ6VXNlcjI0NzI2Nzk2", "avatar_url": "https://avatars3.githubusercontent.com/u/24726796?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zide05", "html_url": "https://github.com/zide05", "followers_url": "https://api.github.com/users/zide05/followers", "following_url": "https://api.github.com/users/zide05/following{/other_user}", "gists_url": "https://api.github.com/users/zide05/gists{/gist_id}", "starred_url": "https://api.github.com/users/zide05/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zide05/subscriptions", "organizations_url": "https://api.github.com/users/zide05/orgs", "repos_url": "https://api.github.com/users/zide05/repos", "events_url": "https://api.github.com/users/zide05/events{/privacy}", "received_events_url": "https://api.github.com/users/zide05/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-12T03:50:31Z", "updated_at": "2020-02-12T06:17:11Z", "closed_at": "2020-02-12T06:17:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\ni want to install tensor2tensor using  \r\n```\r\npip install tensor2tensor[tensorflow_gpu] \r\n```\r\nbut got :\r\n\r\n```\r\nWARNING: tensor2tensor 1.15.4 does not provide the extra 'tensorflow_gpu'\r\n```\r\nis there a suitable tensorflow-gpu version for tensor2tensor 1.15.4?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1785", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1785/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1785/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1785/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1785", "id": 559599800, "node_id": "MDU6SXNzdWU1NTk1OTk4MDA=", "number": 1785, "title": "Common Voice Clean dataset giving error when using t2t-datagen", "user": {"login": "RegaliaXYZ", "id": 17549537, "node_id": "MDQ6VXNlcjE3NTQ5NTM3", "avatar_url": "https://avatars2.githubusercontent.com/u/17549537?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RegaliaXYZ", "html_url": "https://github.com/RegaliaXYZ", "followers_url": "https://api.github.com/users/RegaliaXYZ/followers", "following_url": "https://api.github.com/users/RegaliaXYZ/following{/other_user}", "gists_url": "https://api.github.com/users/RegaliaXYZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/RegaliaXYZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RegaliaXYZ/subscriptions", "organizations_url": "https://api.github.com/users/RegaliaXYZ/orgs", "repos_url": "https://api.github.com/users/RegaliaXYZ/repos", "events_url": "https://api.github.com/users/RegaliaXYZ/events{/privacy}", "received_events_url": "https://api.github.com/users/RegaliaXYZ/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-02-04T09:44:59Z", "updated_at": "2020-02-04T14:03:17Z", "closed_at": "2020-02-04T14:03:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI've been trying to generate the common voice dataset to improve the ASR checkpoint that was trained on librispeech but when using the command it downloads the file properly but seems to not find cv_corpus_v1. I think it probably doesn't extract the .tar properly\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Google Colab\r\n\r\n$ pip freeze | grep tensor\r\n\r\nmesh-tensorflow==0.1.9\r\ntensor2tensor==1.11.0\r\ntensorboard==1.14.0\r\ntensorboardcolab==0.0.22\r\ntensorflow==1.14.0\r\ntensorflow-datasets==2.0.0\r\ntensorflow-estimator==1.14.0\r\ntensorflow-gan==2.0.0\r\ntensorflow-hub==0.7.0\r\ntensorflow-metadata==0.21.1\r\ntensorflow-privacy==0.2.2\r\ntensorflow-probability==0.7.0\r\n\r\n$ python -V\r\n3.6.9\r\n\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\nuse\r\n!t2t-datagen \\\r\n  --problem=common_voice_clean \\\r\n  --data_dir=final_dir \\\r\n  --tmp_dir=tmp_dir\r\nYou should see the download happen smoothly until it finishes and get a FileNotFoundError\r\n```\r\n\r\n```\r\n# Error logs:\r\nINFO:tensorflow:Successfully downloaded cv_corpus_v1.tar.gz, 12852160484 bytes.\r\nI0204 09:30:56.961190 140237164398464 generator_utils.py:246] Successfully downloaded cv_corpus_v1.tar.gz, 12852160484 bytes.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-datagen\", line 28, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/bin/t2t-datagen\", line 23, in main\r\n    t2t_datagen.main(argv)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_datagen.py\", line 198, in main\r\n    generate_data_for_registered_problem(problem)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_datagen.py\", line 260, in generate_data_for_registered_problem\r\n    problem.generate_data(data_dir, tmp_dir, task_id)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/common_voice.py\", line 166, in generate_data\r\n    self.generator(data_dir, tmp_dir, self.TEST_DATASETS), test_paths)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/generator_utils.py\", line 165, in generate_files\r\n    for case in generator:\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/common_voice.py\", line 136, in generator\r\n    data_tuples = _collect_data(raw_data_dir)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/common_voice.py\", line 53, in _collect_data\r\n    filename for filename in os.listdir(directory)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'tmp_dir/cv_corpus_v1'\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1780", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1780/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1780/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1780/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1780", "id": 546745998, "node_id": "MDU6SXNzdWU1NDY3NDU5OTg=", "number": 1780, "title": "How to convert .ckpt file to .pb file?", "user": {"login": "StaRRk11", "id": 39273476, "node_id": "MDQ6VXNlcjM5MjczNDc2", "avatar_url": "https://avatars1.githubusercontent.com/u/39273476?v=4", "gravatar_id": "", "url": "https://api.github.com/users/StaRRk11", "html_url": "https://github.com/StaRRk11", "followers_url": "https://api.github.com/users/StaRRk11/followers", "following_url": "https://api.github.com/users/StaRRk11/following{/other_user}", "gists_url": "https://api.github.com/users/StaRRk11/gists{/gist_id}", "starred_url": "https://api.github.com/users/StaRRk11/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/StaRRk11/subscriptions", "organizations_url": "https://api.github.com/users/StaRRk11/orgs", "repos_url": "https://api.github.com/users/StaRRk11/repos", "events_url": "https://api.github.com/users/StaRRk11/events{/privacy}", "received_events_url": "https://api.github.com/users/StaRRk11/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-01-08T09:37:32Z", "updated_at": "2020-03-23T03:12:20Z", "closed_at": "2020-03-23T03:12:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nIs there a way to convert .ckpt file to .pb file? \r\nOr how can we deploy model trained by t2t without tensorflow-serving?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1774", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1774/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1774/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1774/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1774", "id": 540147778, "node_id": "MDU6SXNzdWU1NDAxNDc3Nzg=", "number": 1774, "title": "Increasing number of subwords in translation", "user": {"login": "ndvbd", "id": 845175, "node_id": "MDQ6VXNlcjg0NTE3NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/845175?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ndvbd", "html_url": "https://github.com/ndvbd", "followers_url": "https://api.github.com/users/ndvbd/followers", "following_url": "https://api.github.com/users/ndvbd/following{/other_user}", "gists_url": "https://api.github.com/users/ndvbd/gists{/gist_id}", "starred_url": "https://api.github.com/users/ndvbd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ndvbd/subscriptions", "organizations_url": "https://api.github.com/users/ndvbd/orgs", "repos_url": "https://api.github.com/users/ndvbd/repos", "events_url": "https://api.github.com/users/ndvbd/events{/privacy}", "received_events_url": "https://api.github.com/users/ndvbd/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-12-19T08:07:21Z", "updated_at": "2019-12-21T16:13:54Z", "closed_at": "2019-12-21T16:13:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\n\r\n$ python -V\r\n# your output here\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1770", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1770/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1770/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1770/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1770", "id": 537684442, "node_id": "MDU6SXNzdWU1Mzc2ODQ0NDI=", "number": 1770, "title": "Multiple GPUs are visible but not allocated and used", "user": {"login": "cgebe", "id": 9108142, "node_id": "MDQ6VXNlcjkxMDgxNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/9108142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgebe", "html_url": "https://github.com/cgebe", "followers_url": "https://api.github.com/users/cgebe/followers", "following_url": "https://api.github.com/users/cgebe/following{/other_user}", "gists_url": "https://api.github.com/users/cgebe/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgebe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgebe/subscriptions", "organizations_url": "https://api.github.com/users/cgebe/orgs", "repos_url": "https://api.github.com/users/cgebe/repos", "events_url": "https://api.github.com/users/cgebe/events{/privacy}", "received_events_url": "https://api.github.com/users/cgebe/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-13T17:51:11Z", "updated_at": "2019-12-13T18:30:23Z", "closed_at": "2019-12-13T18:29:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI am trying to start the quick start imagenet run with resnet_101 on 3 GPUs. However, the second and third GPU are not used - the model is not allocated to them. All GPUs are visible -> `$CUDA_VISIBLE_DEVICES=0,1,2` as seen in the logs.\r\n\r\n### Environment information\r\n\r\nOS: Ubuntu 18.04\r\n\r\n$ pip freeze | grep tensor\r\n```\r\nmesh-tensorflow==0.1.7\r\ntensor2tensor==1.15.2\r\ntensorboard==1.14.0\r\ntensorflow-datasets==1.3.2\r\ntensorflow-estimator==1.14.0\r\ntensorflow-gan==2.0.0\r\ntensorflow-gpu==1.14.0\r\ntensorflow-hub==0.7.0\r\ntensorflow-metadata==0.15.1\r\ntensorflow-probability==0.7.0\r\n```\r\n\r\n$ python -V\r\n```\r\nPython 3.7.5\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n\r\n```\r\nINFO:tensorflow:Transforming body output with class_label_modality_10_64.top\r\nI1213 18:41:40.599883 140097934563136 t2t_model.py:2261] Transforming body output with class_label_modality_10_64.top\r\nWARNING:tensorflow:From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/layers/modalities.py:946: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.dense instead.\r\nW1213 18:41:40.600962 140097934563136 deprecation.py:323] From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/layers/modalities.py:946: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.dense instead.\r\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6aaef45f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6aaef45f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nW1213 18:41:40.687236 140097934563136 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6aaef45f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6aaef45f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/utils/learning_rate.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nW1213 18:41:40.742912 140097934563136 deprecation_wrapper.py:119] From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/utils/learning_rate.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nINFO:tensorflow:Applying exp learning rate warmup for 100 steps\r\nI1213 18:41:40.745574 140097934563136 learning_rate.py:205] Applying exp learning rate warmup for 100 steps\r\nINFO:tensorflow:Applying learning rate decay: cosine.\r\nI1213 18:41:40.750162 140097934563136 learning_rate.py:163] Applying learning rate decay: cosine.\r\nWARNING:tensorflow:From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/utils/learning_rate.py:112: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW1213 18:41:40.756382 140097934563136 deprecation.py:323] From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/utils/learning_rate.py:112: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nINFO:tensorflow:Base learning rate: 0.400000\r\nI1213 18:41:40.756893 140097934563136 learning_rate.py:114] Base learning rate: 0.400000\r\nINFO:tensorflow:Applying weight decay, decay_rate: 0.00010\r\nI1213 18:41:40.759765 140097934563136 optimize.py:294] Applying weight decay, decay_rate: 0.00010\r\nINFO:tensorflow:Trainable Variables Total size: 42514378\r\nI1213 18:41:41.002760 140097934563136 optimize.py:335] Trainable Variables Total size: 42514378\r\nINFO:tensorflow:Non-trainable variables Total size: 105349\r\nI1213 18:41:41.004743 140097934563136 optimize.py:335] Non-trainable variables Total size: 105349\r\nINFO:tensorflow:Using optimizer Momentum\r\nI1213 18:41:41.005156 140097934563136 optimize.py:190] Using optimizer Momentum\r\nWARNING:tensorflow:From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/utils/registry.py:460: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nW1213 18:41:41.005277 140097934563136 deprecation_wrapper.py:119] From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/utils/registry.py:460: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nWARNING:tensorflow:optimizer names now keyed by snake_case names. Please update `registry.optimizer` callsite (likely due to a `HParams.optimizer` value)\r\nW1213 18:41:41.005335 140097934563136 registry.py:461] optimizer names now keyed by snake_case names. Please update `registry.optimizer` callsite (likely due to a `HParams.optimizer` value)\r\nWARNING:tensorflow:From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/utils/optimize.py:135: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\r\n\r\nW1213 18:41:41.005416 140097934563136 deprecation_wrapper.py:119] From /home/chris/envs/deep/lib/python3.7/site-packages/tensor2tensor/utils/optimize.py:135: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\r\n\r\nINFO:tensorflow:Done calling model_fn.\r\nI1213 18:41:44.708933 140097934563136 estimator.py:1147] Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nI1213 18:41:44.710017 140097934563136 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\nI1213 18:41:47.335859 140097934563136 monitored_session.py:240] Graph was finalized.\r\n2019-12-13 18:41:47.337449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:0b:00.0\r\n2019-12-13 18:41:47.337526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.338237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:41:00.0\r\n2019-12-13 18:41:47.338302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.339012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:42:00.0\r\n2019-12-13 18:41:47.339057: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\r\n2019-12-13 18:41:47.339068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\r\n2019-12-13 18:41:47.339077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\r\n2019-12-13 18:41:47.339086: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\r\n2019-12-13 18:41:47.339095: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\r\n2019-12-13 18:41:47.339104: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\r\n2019-12-13 18:41:47.339114: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-12-13 18:41:47.341557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.342539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.344254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.345240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.345944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2\r\n2019-12-13 18:41:47.346025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-12-13 18:41:47.346034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 \r\n2019-12-13 18:41:47.346041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y Y \r\n2019-12-13 18:41:47.346045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N Y \r\n2019-12-13 18:41:47.346049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   Y Y N \r\n2019-12-13 18:41:47.347136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.348120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.349842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0b:00.0, compute capability: 6.1)\r\n2019-12-13 18:41:47.349905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.350852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10481 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:41:00.0, compute capability: 6.1)\r\n2019-12-13 18:41:47.350908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-13 18:41:47.351615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10479 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\r\n2019-12-13 18:41:49.156848: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\nINFO:tensorflow:Running local_init_op.\r\nI1213 18:41:50.544704 140097934563136 session_manager.py:500] Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nI1213 18:41:50.711471 140097934563136 session_manager.py:502] Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /home/chris/output/model.ckpt.\r\nI1213 18:41:55.744890 140097934563136 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /home/chris/output/model.ckpt.\r\n2019-12-13 18:42:01.270528: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\r\n2019-12-13 18:42:04.607807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\nINFO:tensorflow:loss = 12.15226, step = 0\r\nI1213 18:42:05.817591 140097934563136 basic_session_run_hooks.py:262] loss = 12.15226, step = 0\r\nINFO:tensorflow:global_step/sec: 8.8183\r\nI1213 18:42:17.157002 140097934563136 basic_session_run_hooks.py:692] global_step/sec: 8.8183\r\nINFO:tensorflow:loss = 14.065001, step = 100 (11.341 sec)\r\nI1213 18:42:17.158270 140097934563136 basic_session_run_hooks.py:260] loss = 14.065001, step = 100 (11.341 sec)\r\nINFO:tensorflow:global_step/sec: 12.5375\r\nI1213 18:42:25.133048 140097934563136 basic_session_run_hooks.py:692] global_step/sec: 12.5375\r\nINFO:tensorflow:loss = 3.8954778, step = 200 (7.976 sec)\r\nI1213 18:42:25.134311 140097934563136 basic_session_run_hooks.py:260] loss = 3.8954778, step = 200 (7.976 sec)\r\n```\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.44       Driver Version: 440.44       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:0B:00.0 Off |                  N/A |\r\n| 40%   76C    P2   220W / 250W |  10899MiB / 11178MiB |     90%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 00000000:41:00.0 Off |                  N/A |\r\n| 32%   59C    P8    13W / 250W |    147MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 108...  Off  | 00000000:42:00.0 Off |                  N/A |\r\n| 35%   61C    P8    22W / 250W |    147MiB / 11176MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     18199      C   /home/chris/envs/deep/bin/python       10889MiB     |\r\n|    1     18199      C   /home/chris/envs/deep/bin/python         137MiB     |\r\n|    2     18199      C   /home/chris/envs/deep/bin/python         137MiB     |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\n# Steps to reproduce:\r\n\r\n```\r\nt2t-trainer \\\r\n  --generate_data \\\r\n  --data_dir=~/data \\\r\n  --output_dir=~/output \\\r\n  --problem=image_mnist \\\r\n  --model=resnet \\\r\n  --hparams_set=resnet_101 \\\r\n  --train_steps=200000 \\\r\n  --eval_steps=5000 \\\r\n  --worker-gpu=3\r\n```\r\n\r\n# Error logs:\r\nNo errors...\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1769", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1769/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1769/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1769/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1769", "id": 537393431, "node_id": "MDU6SXNzdWU1MzczOTM0MzE=", "number": 1769, "title": "Modify learning rate with multistep_optimizer", "user": {"login": "hoangcuong2011", "id": 8759715, "node_id": "MDQ6VXNlcjg3NTk3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8759715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hoangcuong2011", "html_url": "https://github.com/hoangcuong2011", "followers_url": "https://api.github.com/users/hoangcuong2011/followers", "following_url": "https://api.github.com/users/hoangcuong2011/following{/other_user}", "gists_url": "https://api.github.com/users/hoangcuong2011/gists{/gist_id}", "starred_url": "https://api.github.com/users/hoangcuong2011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hoangcuong2011/subscriptions", "organizations_url": "https://api.github.com/users/hoangcuong2011/orgs", "repos_url": "https://api.github.com/users/hoangcuong2011/repos", "events_url": "https://api.github.com/users/hoangcuong2011/events{/privacy}", "received_events_url": "https://api.github.com/users/hoangcuong2011/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-12-13T07:32:07Z", "updated_at": "2019-12-14T14:27:02Z", "closed_at": "2019-12-13T18:10:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "Greetings,\r\n\r\nI found [multistep_optimizer](https://github.com/tensorflow/tensor2tensor/blob/2330203cb267fa4efc4525ad5c7dffe0a7d2f2fc/tensor2tensor/utils/multistep_optimizer.py) is an amazing class that helps me train large batch size. I, however, have an issue with this class in the sense that I also need to change the learning rate during training, and I found it is not easy to do so. \r\n\r\nIn detail, I am trying to train the Transformer with the code I wrote from scratch. Training the model needs a good care of adapting learning rate based on the training steps. Normally with common optimizers like Adam, what I need to is just write a Callback and then modify lr as: `self.model.optimizer.lr = lrate  `. I however found this code does not work for this class (`AttributeError: 'TFOptimizer' object has no attribute 'lr'`)\r\n\r\nSo how to modify learning rate with this class?\r\nThx\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1765", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1765/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1765/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1765/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1765", "id": 534406366, "node_id": "MDU6SXNzdWU1MzQ0MDYzNjY=", "number": 1765, "title": "File Not Found: gs://tensor2tensor-data/wikisum/commoncrawl_metadata/xxx.metadata.json", "user": {"login": "chiaminchuang", "id": 9839197, "node_id": "MDQ6VXNlcjk4MzkxOTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/9839197?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chiaminchuang", "html_url": "https://github.com/chiaminchuang", "followers_url": "https://api.github.com/users/chiaminchuang/followers", "following_url": "https://api.github.com/users/chiaminchuang/following{/other_user}", "gists_url": "https://api.github.com/users/chiaminchuang/gists{/gist_id}", "starred_url": "https://api.github.com/users/chiaminchuang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chiaminchuang/subscriptions", "organizations_url": "https://api.github.com/users/chiaminchuang/orgs", "repos_url": "https://api.github.com/users/chiaminchuang/repos", "events_url": "https://api.github.com/users/chiaminchuang/events{/privacy}", "received_events_url": "https://api.github.com/users/chiaminchuang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-07T14:09:49Z", "updated_at": "2019-12-10T07:28:49Z", "closed_at": "2019-12-10T07:28:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI tried to download the **wikisum** dataset used in the paper GENERATING WIKIPEDIA BY SUMMARIZING LONG SEQUENCES and wanted to use my own computer to do it instead of GCP. I executed the following command:\r\n```\r\npython get_references_commoncrawl.py --out_dir wikisum_commoncrawl\r\n```\r\nand I got this error:\r\n```\r\ntensorflow.python.framework.errors_impl.NotFoundError: The specified path gs://tensor2tensor-data/wikisum/commoncrawl_metadata/CC-MAIN-20170919112242-20170919132242-00000.warc.wet.gz'.metadata.json was not found.\r\n```\r\nIs **wikisum** dataset still available?\r\nIs there any other way to download the full dataset instead of crawling it?\r\nThanks for your great works.\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Ubuntu 18.04.1 LST\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.1.7\r\ntensor2tensor==1.15.2\r\ntensorboard==1.14.0\r\ntensorflow==1.14.0\r\ntensorflow-datasets==1.3.2\r\ntensorflow-estimator==1.14.0\r\ntensorflow-gan==2.0.0\r\ntensorflow-hub==0.7.0\r\ntensorflow-metadata==0.15.1\r\ntensorflow-probability==0.7.0\r\n\r\n$ python -V\r\nPython 3.6.9 :: Anaconda, Inc.\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n$ git clone https://github.com/tensorflow/tensor2tensor.git\r\n$ cd tensor2tensor-master/tensor2tensor/data_generators/wikisum\r\n$ python get_references_commoncrawl.py --out_dir wikisum_commoncrawl\r\n```\r\n\r\n```\r\n# Error logs:\r\nTraceback (most recent call last):\r\n  File \"get_references_commoncrawl.py\", line 71, in <module>\r\n    tf.app.run()\r\n  File \"/home/chiamin/anaconda3/envs/wikisum/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/chiamin/anaconda3/envs/wikisum/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/chiamin/anaconda3/envs/wikisum/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"get_references_commoncrawl.py\", line 66, in main\r\n    wikisum.extract_references_from_wets(wet_files, FLAGS.metadata_dir, out_dir)\r\n  File \"/home/chiamin/.local/lib/python3.6/site-packages/tensor2tensor/data_generators/wikisum/wikisum.py\", line 521, in extract_references_from_wets\r\n    wet_metadata = json.loads(f.read())\r\n  File \"/home/chiamin/anaconda3/envs/wikisum/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 124, in read\r\n    length = self.size() - self.tell()\r\n  File \"/home/chiamin/anaconda3/envs/wikisum/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 102, in size\r\n    return stat(self.__name).length\r\n  File \"/home/chiamin/anaconda3/envs/wikisum/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 727, in stat\r\n    return stat_v2(filename)\r\n  File \"/home/chiamin/anaconda3/envs/wikisum/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 744, in stat_v2\r\n    pywrap_tensorflow.Stat(compat.as_bytes(path), file_statistics)\r\ntensorflow.python.framework.errors_impl.NotFoundError: The specified path gs://tensor2tensor-data/wikisum/commoncrawl_metadata/CC-MAIN-20170919112242-20170919132242-00000.warc.wet.gz'.metadata.json was not found.\r\n\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1759", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1759/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1759/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1759/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1759", "id": 530128378, "node_id": "MDU6SXNzdWU1MzAxMjgzNzg=", "number": 1759, "title": "Librispeech , when decoding , vocabulary is None", "user": {"login": "hl312", "id": 19568013, "node_id": "MDQ6VXNlcjE5NTY4MDEz", "avatar_url": "https://avatars0.githubusercontent.com/u/19568013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hl312", "html_url": "https://github.com/hl312", "followers_url": "https://api.github.com/users/hl312/followers", "following_url": "https://api.github.com/users/hl312/following{/other_user}", "gists_url": "https://api.github.com/users/hl312/gists{/gist_id}", "starred_url": "https://api.github.com/users/hl312/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hl312/subscriptions", "organizations_url": "https://api.github.com/users/hl312/orgs", "repos_url": "https://api.github.com/users/hl312/repos", "events_url": "https://api.github.com/users/hl312/events{/privacy}", "received_events_url": "https://api.github.com/users/hl312/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-29T02:35:48Z", "updated_at": "2019-12-03T02:53:39Z", "closed_at": "2019-12-03T02:53:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi , have you solved it ? When t2t_decode , an error comes, it says \"the location\r\nin docding:586:inputs_ids=vocabulary.encode(inputs) , 'NoneType' object has no atrribute 'encode'\" .\r\nsome question:\r\n1\u3001The content in decode_from_file is whether \"the path to real testdata file\" or \"testfile file\" ?\r\n2\u3001vocabulary is geneated in datagen process or prepared by myself ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1757", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1757/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1757/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1757/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1757", "id": 529139993, "node_id": "MDU6SXNzdWU1MjkxMzk5OTM=", "number": 1757, "title": "Log output probabilities of decoder during Beam Search", "user": {"login": "megvillanueva", "id": 4327250, "node_id": "MDQ6VXNlcjQzMjcyNTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/4327250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/megvillanueva", "html_url": "https://github.com/megvillanueva", "followers_url": "https://api.github.com/users/megvillanueva/followers", "following_url": "https://api.github.com/users/megvillanueva/following{/other_user}", "gists_url": "https://api.github.com/users/megvillanueva/gists{/gist_id}", "starred_url": "https://api.github.com/users/megvillanueva/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/megvillanueva/subscriptions", "organizations_url": "https://api.github.com/users/megvillanueva/orgs", "repos_url": "https://api.github.com/users/megvillanueva/repos", "events_url": "https://api.github.com/users/megvillanueva/events{/privacy}", "received_events_url": "https://api.github.com/users/megvillanueva/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-27T06:14:47Z", "updated_at": "2019-11-27T14:19:49Z", "closed_at": "2019-11-27T14:19:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "I want to get the output probabilities from the decoder  on every step of beam search. Can you help me log them to file?\r\n\r\nI'm currently trying to log the `flat_logits` of [utils/beam_search.py](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/beam_search.py). But I'm failing to print the value of the tensor.\r\n\r\nI'm quite new to tensorflow and I really appreciate the help. Thank you. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1756", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1756/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1756/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1756/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1756", "id": 528907294, "node_id": "MDU6SXNzdWU1Mjg5MDcyOTQ=", "number": 1756, "title": "beam_score value changes based on batch size and composition", "user": {"login": "katelynrwalker", "id": 42429344, "node_id": "MDQ6VXNlcjQyNDI5MzQ0", "avatar_url": "https://avatars2.githubusercontent.com/u/42429344?v=4", "gravatar_id": "", "url": "https://api.github.com/users/katelynrwalker", "html_url": "https://github.com/katelynrwalker", "followers_url": "https://api.github.com/users/katelynrwalker/followers", "following_url": "https://api.github.com/users/katelynrwalker/following{/other_user}", "gists_url": "https://api.github.com/users/katelynrwalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/katelynrwalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/katelynrwalker/subscriptions", "organizations_url": "https://api.github.com/users/katelynrwalker/orgs", "repos_url": "https://api.github.com/users/katelynrwalker/repos", "events_url": "https://api.github.com/users/katelynrwalker/events{/privacy}", "received_events_url": "https://api.github.com/users/katelynrwalker/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-11-26T18:44:51Z", "updated_at": "2020-01-29T22:31:43Z", "closed_at": "2020-01-29T22:31:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm getting some strange behavior when I output beam scores from the decoder using \r\n`--decode_hparams=\"beam_size=1, return_beams=True, write_beam_scores=True, extra_length=0, force_decode_length=True\"`\r\nThe beam_score that is written for a single sample changes depending on the batch size and overall number of samples (I'm presuming that second part means that the beam_score changes depending on what other items are in a particular batch, since batches are shuffled to put similar-length inputs together). The output for the sample will be the same, but the beam score changes. Any ideas what might be going on here?\r\n\r\n\r\nExamples (the score given is for a the same individual sample in each case. The decoded output is the same each time, but the score is different):\r\n\r\n108000 samples (batch size =64) \t-50.76\r\n\r\n100 samples (batch size =64) \t-62.59\r\n\r\n10 samples (batch size =64)  \t-52.70\r\n\r\n1000 samples (batch size =32) \t-51.25\r\n\r\n100 samples (batch size =32) \t-45.02\r\n\r\n1 sample (batch size =1 or 64) \t-34.40\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1755", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1755/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1755/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1755/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1755", "id": 528624749, "node_id": "MDU6SXNzdWU1Mjg2MjQ3NDk=", "number": 1755, "title": "a bug when calculating position_embedding if hparams.pos='timing'?", "user": {"login": "real-brilliant", "id": 24716125, "node_id": "MDQ6VXNlcjI0NzE2MTI1", "avatar_url": "https://avatars3.githubusercontent.com/u/24716125?v=4", "gravatar_id": "", "url": "https://api.github.com/users/real-brilliant", "html_url": "https://github.com/real-brilliant", "followers_url": "https://api.github.com/users/real-brilliant/followers", "following_url": "https://api.github.com/users/real-brilliant/following{/other_user}", "gists_url": "https://api.github.com/users/real-brilliant/gists{/gist_id}", "starred_url": "https://api.github.com/users/real-brilliant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/real-brilliant/subscriptions", "organizations_url": "https://api.github.com/users/real-brilliant/orgs", "repos_url": "https://api.github.com/users/real-brilliant/repos", "events_url": "https://api.github.com/users/real-brilliant/events{/privacy}", "received_events_url": "https://api.github.com/users/real-brilliant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-26T10:19:29Z", "updated_at": "2019-12-13T00:59:54Z", "closed_at": "2019-12-13T00:59:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\nsince,\r\n1. scaled_time is calculated by `scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(inv_timescales, 0)`, while position_idx in position will **start by 0**.\r\n2. scaled_time will be used to calculate position embedding by `signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)`\r\n\r\nThus, position_embedding of first token will always be combined with half zeros and half ones.\r\n\r\nBut the purpose of addding timing pos_embed should be helping model to learn relative and absolute position information between words by triangle relations of these words, i.e. sin(\\alpha+\\beta)=sin(\\alpha)cos(\\beta)+sin(\\beta)cos(\\alpha).\r\n\r\nObviously triangle function in first token will not be learnt\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1745", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1745/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1745/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1745/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1745", "id": 523662902, "node_id": "MDU6SXNzdWU1MjM2NjI5MDI=", "number": 1745, "title": "Using MOE utils", "user": {"login": "zack466", "id": 55601738, "node_id": "MDQ6VXNlcjU1NjAxNzM4", "avatar_url": "https://avatars2.githubusercontent.com/u/55601738?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zack466", "html_url": "https://github.com/zack466", "followers_url": "https://api.github.com/users/zack466/followers", "following_url": "https://api.github.com/users/zack466/following{/other_user}", "gists_url": "https://api.github.com/users/zack466/gists{/gist_id}", "starred_url": "https://api.github.com/users/zack466/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zack466/subscriptions", "organizations_url": "https://api.github.com/users/zack466/orgs", "repos_url": "https://api.github.com/users/zack466/repos", "events_url": "https://api.github.com/users/zack466/events{/privacy}", "received_events_url": "https://api.github.com/users/zack466/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-15T20:05:20Z", "updated_at": "2020-04-15T19:42:42Z", "closed_at": "2020-04-15T19:42:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a question about using the MOE utils. How would I integrate these utilities into my own model to create a mixture of experts model where each expert is a convolutional neural network?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1742", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1742/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1742/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1742/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1742", "id": 521943486, "node_id": "MDU6SXNzdWU1MjE5NDM0ODY=", "number": 1742, "title": "registry.list_models() returns un empty list", "user": {"login": "Hamza5", "id": 7011111, "node_id": "MDQ6VXNlcjcwMTExMTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/7011111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hamza5", "html_url": "https://github.com/Hamza5", "followers_url": "https://api.github.com/users/Hamza5/followers", "following_url": "https://api.github.com/users/Hamza5/following{/other_user}", "gists_url": "https://api.github.com/users/Hamza5/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hamza5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hamza5/subscriptions", "organizations_url": "https://api.github.com/users/Hamza5/orgs", "repos_url": "https://api.github.com/users/Hamza5/repos", "events_url": "https://api.github.com/users/Hamza5/events{/privacy}", "received_events_url": "https://api.github.com/users/Hamza5/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-13T03:55:23Z", "updated_at": "2019-11-13T11:28:18Z", "closed_at": "2019-11-13T11:28:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\nTensor2Tensor library can't find any of its predefined models! I wanted to use the Transformer but finally, I found that it contains absolutely no single model, because `registry.list_models()` returned an empty list.\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Manjaro Linux 64-bit with kernel 4.19.81 and KDE Plasma 5.17.2\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.1.4\r\ntensor2tensor==1.14.1\r\ntensorboard==1.15.0\r\ntensorflow==1.15.0\r\ntensorflow-datasets==1.3.0\r\ntensorflow-estimator==1.15.1\r\ntensorflow-gan==2.0.0\r\ntensorflow-hub==0.7.0\r\ntensorflow-metadata==0.15.0\r\ntensorflow-probability==0.7.0\r\n\r\n\r\n$ python -V\r\nPython 3.7.4\r\n\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n``` \r\n>>> from tensor2tensor.utils import registry\r\n>>> registry.list_models()\r\n[]\r\n```\r\n# Steps to reproduce:\r\nImport the `registry` module then `list_models()`:\r\n```\r\n>>> from tensor2tensor.utils import registry\r\n>>> registry.list_models()\r\n[]\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1740", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1740/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1740/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1740/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1740", "id": 519630017, "node_id": "MDU6SXNzdWU1MTk2MzAwMTc=", "number": 1740, "title": "How to test my model using my own test dataset?", "user": {"login": "1120172175", "id": 39440001, "node_id": "MDQ6VXNlcjM5NDQwMDAx", "avatar_url": "https://avatars3.githubusercontent.com/u/39440001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/1120172175", "html_url": "https://github.com/1120172175", "followers_url": "https://api.github.com/users/1120172175/followers", "following_url": "https://api.github.com/users/1120172175/following{/other_user}", "gists_url": "https://api.github.com/users/1120172175/gists{/gist_id}", "starred_url": "https://api.github.com/users/1120172175/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/1120172175/subscriptions", "organizations_url": "https://api.github.com/users/1120172175/orgs", "repos_url": "https://api.github.com/users/1120172175/repos", "events_url": "https://api.github.com/users/1120172175/events{/privacy}", "received_events_url": "https://api.github.com/users/1120172175/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-08T02:58:53Z", "updated_at": "2019-11-19T13:19:36Z", "closed_at": "2019-11-19T13:19:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI have 3 folders of data. They are train, valid and test. Now I defined my own problem and trained my model successfully. I can see the metrics-accuracy etc while training the model. **But how can I test my model on the test data set?**. I want to know some results like top-1, top-3, top-5 accuracy. \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1739", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1739/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1739/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1739/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1739", "id": 519561151, "node_id": "MDU6SXNzdWU1MTk1NjExNTE=", "number": 1739, "title": "t2t-decoder regression predictions", "user": {"login": "gabegrand", "id": 10052880, "node_id": "MDQ6VXNlcjEwMDUyODgw", "avatar_url": "https://avatars3.githubusercontent.com/u/10052880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gabegrand", "html_url": "https://github.com/gabegrand", "followers_url": "https://api.github.com/users/gabegrand/followers", "following_url": "https://api.github.com/users/gabegrand/following{/other_user}", "gists_url": "https://api.github.com/users/gabegrand/gists{/gist_id}", "starred_url": "https://api.github.com/users/gabegrand/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gabegrand/subscriptions", "organizations_url": "https://api.github.com/users/gabegrand/orgs", "repos_url": "https://api.github.com/users/gabegrand/repos", "events_url": "https://api.github.com/users/gabegrand/events{/privacy}", "received_events_url": "https://api.github.com/users/gabegrand/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-07T22:58:12Z", "updated_at": "2019-11-14T21:46:07Z", "closed_at": "2019-11-14T21:46:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nI have several regression-based tasks that involve inferring a single scalar value from a block of text. I've created a new Problem class Text2RegressionProblem that's analogous to the existing Text2ClassProblem, but for problems where the output is a single scalar. I'm able to successfully train models on this problem. However, when I run inference with trained models using t2t-decoder, I get dozens of values back.\r\n\r\nExample:\r\n```\r\nt2t-decoder \\\r\n  --t2t_usr_dir=$USR_DIR \\\r\n  --data_dir=$DATA_DIR \\\r\n  --problem=$PROBLEM \\\r\n  --model=$MODEL \\\r\n  --hparams_set=$HPARAMS \\\r\n  --output_dir=$TRAIN_DIR \\\r\n  --hparams=\"max_length=1\" \\\r\n  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA,extra_length=0\" \\\r\n  --decode_from_file=$DECODE_FILE \\\r\n  --decode_to_file=/tmp/decoded.txt \\\r\n\r\nInference results INPUT: <Some tokenized text>\r\nInference results OUTPUT: 5.3629727 5.303556 5.144407 5.17002 5.3072686 5.2574806 5.2288465 5.2287025 5.2602153 5.2170677 5.2564077 5.225711 5.1793923 5.1638227 5.2056766 5.314677 5.2889915 5.4006414 5.4020224 5.370219 5.247168 5.2442055 5.2933908 5.2927985 5.328215 5.353526 5.3514934 5.3330526 5.369112 5.3747473 5.329636 5.2914467 5.260538 5.2635546 5.2717643 5.310262 5.372777 5.3689275 5.396057 5.379212 5.338006 5.3245363 5.3512154 5.3231683 5.2917695 5.3729806 5.369797 5.3465395 5.3407426 5.370006 5.386562 5.3699274 5.3307123 5.33022 5.3411913 5.337703 5.3624287 5.389234 5.4132752 5.4185905 5.378593 5.34707 5.332845 5.335811 5.34976 5.3591514 5.3616056 5.3694997 5.387833 5.401154 5.390521 5.358708 5.3527293 5.3604765 5.359528 5.3743944 5.391922 5.407466 5.4318314\r\n```\r\n\r\n**How can I get run inference and get back a single scalar per example?**\r\n\r\nProblem definition is below:\r\n\r\n```\r\nclass Text2RegressionProblem(Text2TextProblem):\r\n    \"\"\"Base class for text regression problems.\"\"\"\r\n\r\n    def generate_samples(self, data_dir, tmp_dir, dataset_split):\r\n        \"\"\"Generate samples of text and label pairs.\r\n        Each yielded dict will be a single example. The inputs should be raw text.\r\n        The label should be a list containing a single float.\r\n        Args:\r\n          data_dir: final data directory. Typically only used in this method to copy\r\n            over user-supplied vocab files (for example, if vocab_type ==\r\n            VocabType.TOKEN).\r\n          tmp_dir: temporary directory that you can use for downloading and scratch.\r\n          dataset_split: problem.DatasetSplit, which data split to generate samples\r\n            for (for example, training and evaluation).\r\n        Yields:\r\n          {\"inputs\": text, \"label\": [float]}\r\n        \"\"\"\r\n        raise NotImplementedError()\r\n\r\n    def generate_text_for_vocab(self, data_dir, tmp_dir):\r\n        for i, sample in enumerate(\r\n                self.generate_samples(data_dir, tmp_dir, problem.DatasetSplit.TRAIN)):\r\n            yield sample[\"inputs\"]\r\n            if self.max_samples_for_vocab and (i + 1) >= self.max_samples_for_vocab:\r\n                break\r\n\r\n    def generate_encoded_samples(self, data_dir, tmp_dir, dataset_split):\r\n        generator = self.generate_samples(data_dir, tmp_dir, dataset_split)\r\n        encoder = self.get_or_create_vocab(data_dir, tmp_dir)\r\n        for sample in generator:\r\n            inputs = encoder.encode(sample[\"inputs\"])\r\n            inputs.append(text_encoder.EOS_ID)\r\n            yield {\"inputs\": inputs, \"targets\": sample[\"targets\"]}\r\n\r\n    def feature_encoders(self, data_dir):\r\n        encoder = self.get_or_create_vocab(data_dir, None, force_get=True)\r\n\r\n        return {\r\n            \"inputs\": encoder,\r\n            \"targets\": text_encoder.RealEncoder(),\r\n        }\r\n\r\n    def hparams(self, defaults, unused_model_hparams):\r\n        p = defaults\r\n        p.modality = {\r\n            \"inputs\": modalities.ModalityType.SYMBOL,\r\n            \"targets\": modalities.ModalityType.REAL_L2_LOSS,\r\n        }\r\n        p.vocab_size = {\"inputs\": self._encoders[\"inputs\"].vocab_size, \"targets\": 1}\r\n        \r\n    def max_length(self, model_hparams):\r\n        return model_hparams.batch_size\r\n\r\n    def example_reading_spec(self):\r\n        data_fields = {\r\n            \"inputs\": tf.VarLenFeature(tf.int64),\r\n            \"targets\": tf.FixedLenFeature([1], tf.float32),\r\n        }\r\n        data_items_to_decoders = None\r\n        return (data_fields, data_items_to_decoders)\r\n\r\n    def eval_metrics(self):\r\n        return [metrics.Metrics.RMSE, metrics.Metrics.PEARSON, metrics.Metrics.R2]\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1735", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1735/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1735/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1735/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1735", "id": 516912897, "node_id": "MDU6SXNzdWU1MTY5MTI4OTc=", "number": 1735, "title": "Evaluation all X steps", "user": {"login": "DevZiegler", "id": 19211664, "node_id": "MDQ6VXNlcjE5MjExNjY0", "avatar_url": "https://avatars1.githubusercontent.com/u/19211664?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DevZiegler", "html_url": "https://github.com/DevZiegler", "followers_url": "https://api.github.com/users/DevZiegler/followers", "following_url": "https://api.github.com/users/DevZiegler/following{/other_user}", "gists_url": "https://api.github.com/users/DevZiegler/gists{/gist_id}", "starred_url": "https://api.github.com/users/DevZiegler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DevZiegler/subscriptions", "organizations_url": "https://api.github.com/users/DevZiegler/orgs", "repos_url": "https://api.github.com/users/DevZiegler/repos", "events_url": "https://api.github.com/users/DevZiegler/events{/privacy}", "received_events_url": "https://api.github.com/users/DevZiegler/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-04T00:14:54Z", "updated_at": "2019-11-04T19:58:24Z", "closed_at": "2019-11-04T19:58:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nHi, I'm trying to do an evaluation of all X steps.\r\nPreferably with the best method, save the best 5 for example.\r\nI found the export_saved_model switch but it doesn't work (since loss is only present in a variable, which is currently not the problem i think i can solve it, but i want the eval test more often).\r\nCurrently I can only do one evaluation at the beginning and one at the end, not every x Steps, only the checkpoint saving.\r\n\r\nthe call looks like this:\r\nt2t_trainer.py \\\r\n  --model=transformer \\\r\n  --hparams_set=transformer_librispeech \\\r\n  --problem=librispeech_clean_small \\\r\n  --train_steps=2000 \\\r\n  --eval_steps=20 \\\r\n  --local_eval_frequency=100 \\\r\n  --data_dir=/content/t2t_records \\\r\n  --output_dir=/content/current_training4 \\\r\n  --export_saved_model=True\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Google Colab - Python3 GPU\r\n\r\n$ pip3 install -q -U tensor2tensor\r\n$ pip3 install -q matplotlib\r\n$ pip3 install -q gast==0.2.2\r\n$ apt-get install sox\r\n$ apt-get install libsox-fmt-mp3\r\n\r\n$ python -V\r\n# Python 3.6.8\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1727", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1727/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1727/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1727/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1727", "id": 509313713, "node_id": "MDU6SXNzdWU1MDkzMTM3MTM=", "number": 1727, "title": "t2t-decoder does not use GPU", "user": {"login": "gabegrand", "id": 10052880, "node_id": "MDQ6VXNlcjEwMDUyODgw", "avatar_url": "https://avatars3.githubusercontent.com/u/10052880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gabegrand", "html_url": "https://github.com/gabegrand", "followers_url": "https://api.github.com/users/gabegrand/followers", "following_url": "https://api.github.com/users/gabegrand/following{/other_user}", "gists_url": "https://api.github.com/users/gabegrand/gists{/gist_id}", "starred_url": "https://api.github.com/users/gabegrand/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gabegrand/subscriptions", "organizations_url": "https://api.github.com/users/gabegrand/orgs", "repos_url": "https://api.github.com/users/gabegrand/repos", "events_url": "https://api.github.com/users/gabegrand/events{/privacy}", "received_events_url": "https://api.github.com/users/gabegrand/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-18T21:15:13Z", "updated_at": "2019-11-05T16:44:38Z", "closed_at": "2019-11-05T16:44:37Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nAfter training a T2T model (using GPU), I noticed that t2t-decoder was running very slowly. I checked `nvidia-smi`, and it appears that t2t-decoder isn't using the GPU while decoding. Additionally, I get many warnings saying that GPU placement failed for various ops.\r\n\r\n```\r\nFailed to place the graph without changing the devices of some resources. Some of the operations (\r\nthat had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n  /job:localhost/replica:0/task:0/device:CPU:0]\r\n\r\n(See bottom of post for full error.)\r\n```\r\n\r\nI have confirmed that this model runs on GPU with `t2t-trainer`.\r\n\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Ubuntu 16.04.6 LTS\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.1.1\r\ntensor2tensor==1.14.1\r\ntensorboard==1.14.0\r\ntensorflow==1.14.0\r\ntensorflow-datasets==1.2.0\r\ntensorflow-estimator==1.14.0\r\ntensorflow-gan==1.0.0.dev0\r\ntensorflow-gpu==1.14.0\r\ntensorflow-metadata==0.15.0\r\ntensorflow-plot==0.3.2\r\ntensorflow-probability==0.7.0\r\ntensorflow-serving-api-gpu==1.13.0\r\n\r\n$ python -V\r\nPython 3.6.5\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n\r\n// I'm using a custom Text2Text problem.\r\nPROBLEM=<custom problem>\r\nMODEL=transformer\r\nHPARAMS=transformer_tiny\r\n\r\nUSR_DIR=<custom dir>\r\nDATA_DIR=$HOME/t2t_data\r\nTMP_DIR=/tmp/t2t_datagen\r\nTRAIN_DIR=$HOME/t2t_train/$PROBLEM/$MODEL-$HPARAMS\r\nmkdir -p $DATA_DIR $TMP_DIR $TRAIN_DIR\r\n\r\n// Training runs fine on GPU\r\nt2t-trainer \\\r\n  --t2t_usr_dir=$USR_DIR \\\r\n  --data_dir=$DATA_DIR \\\r\n  --problem=$PROBLEM \\\r\n  --model=$MODEL \\\r\n  --hparams_set=$HPARAMS \\\r\n  --output_dir=$TRAIN_DIR \\\r\n\r\n// Decoding runs on CPU and is very slow\r\nDECODE_FILE=$DATA_DIR/sample/src.txt\r\nBEAM_SIZE=4\r\nALPHA=0.6\r\n\r\nt2t-decoder \\\r\n  --t2t_usr_dir=$USR_DIR \\\r\n  --data_dir=$DATA_DIR \\\r\n  --problem=$PROBLEM \\\r\n  --model=$MODEL \\\r\n  --hparams_set=$HPARAMS \\\r\n  --output_dir=$TRAIN_DIR \\\r\n  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\r\n  --decode_from_file=$DECODE_FILE \\\r\n  --decode_to_file=$TRAIN_DIR/preds.txt \\\r\n  --decode_hparams=batch_size=1024 \\\r\n\r\n```\r\n# Error logs:\r\n```\r\nColocation members, user-requested devices, and framework assigned devices, if any:\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/shape (Const)\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/min (Const)\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/max (Const)\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/RandomUniform (RandomUniform)\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/sub (Sub)\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform/mul (Mul)\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Initializer/random_uniform (Add)\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel (VariableV2) /device:GPU:0\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Assign (Assign) /device:GPU:0\r\n  transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/read (Identity) /device:GPU:0\r\n  read_80/RefEnter (RefEnter) /device:GPU:0\r\n  report_uninitialized_variables/IsVariableInitialized_69 (IsVariableInitialized) /device:GPU:0\r\n  report_uninitialized_variables_1/IsVariableInitialized_69 (IsVariableInitialized) /device:GPU:0\r\n  save/Assign_34 (Assign) /device:GPU:0\r\n\r\n2019-10-18 20:54:42.053755: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (\r\nthat had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\r\n  /job:localhost/replica:0/task:0/device:CPU:0].\r\nSee below for details of this colocation group:\r\nColocation Debug Info:\r\nColocation group had the following types and supported devices:\r\nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_d\r\nevices_=[]\r\nIsVariableInitialized: CPU\r\nRefEnter: CPU\r\nAssign: CPU\r\nIdentity: CPU XLA_CPU\r\nVariableV2: CPU\r\nConst: CPU XLA_CPU\r\n```\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1719", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1719/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1719/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1719/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1719", "id": 501515909, "node_id": "MDU6SXNzdWU1MDE1MTU5MDk=", "number": 1719, "title": "How to parallelize datagen manually on Text2TextProblems?", "user": {"login": "abnf", "id": 42590463, "node_id": "MDQ6VXNlcjQyNTkwNDYz", "avatar_url": "https://avatars3.githubusercontent.com/u/42590463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abnf", "html_url": "https://github.com/abnf", "followers_url": "https://api.github.com/users/abnf/followers", "following_url": "https://api.github.com/users/abnf/following{/other_user}", "gists_url": "https://api.github.com/users/abnf/gists{/gist_id}", "starred_url": "https://api.github.com/users/abnf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abnf/subscriptions", "organizations_url": "https://api.github.com/users/abnf/orgs", "repos_url": "https://api.github.com/users/abnf/repos", "events_url": "https://api.github.com/users/abnf/events{/privacy}", "received_events_url": "https://api.github.com/users/abnf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-02T14:12:36Z", "updated_at": "2019-10-10T03:26:33Z", "closed_at": "2019-10-02T14:50:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nIs it possible to parallelize datagen manually when doing text2text problems? Because even though the data files can be concatenated, it seems likely that the vocab files (eg vocab.phrase_generator_problem.65536.subwords) cannot be concatted because the vocab files are different when running datagen on different subsets of data.\r\n\r\nQuote from @martinpopel in #914 \r\n> You can use `t2t-datagen` for generating the training data. I think recently it got support for multi-thread processing (but I am not sure, maybe you need to switch it on with some option - I'm busy now to check). You can even parallelize datagen manually (e.g. on different machines) and then just concat the TFRecords files (they have no header), or just rename the files. What is tricky is your idea of starting training before all the data is ready. You can resume training (i.e. stop and start again from the last checkpoint but with a new dataset), but does not seem user-friendly to me. I usually run `t2t-datagen` on CPU-only machines and `t2t-trainer` on GPU machines.\r\n\r\n\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: \r\nVersion: tf-cpu.1-14.m34\r\nBased on: Debian GNU/Linux 9.9 (stretch) (GNU/Linux 4.9.0-9-amd64 x86_64\\n)\r\nLinux cpu1-vm 4.9.0-9-amd64 #1 SMP Debian 4.9.168-1+deb9u5 (2019-08-11) x86_64\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\njupyter-tensorboard==0.1.10\r\nmesh-tensorflow==0.0.5\r\ntensor2tensor==1.13.4\r\ntensorboard==1.14.0\r\ntensorflow==1.14.0\r\ntensorflow-datasets==1.2.0\r\ntensorflow-estimator==1.14.0\r\ntensorflow-hub==0.5.0\r\ntensorflow-metadata==0.14.0\r\ntensorflow-probability==0.7.0rc0\r\ntensorflow-serving-api==1.13.0rc1\r\ntensorflow-transform==0.14.0\r\n\r\n$ python -V\r\n# your output here\r\nPython 2.7.13\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1705", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1705/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1705/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1705/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1705", "id": 496100791, "node_id": "MDU6SXNzdWU0OTYxMDA3OTE=", "number": 1705, "title": "training stuck after the 1st step (quite odd)", "user": {"login": "ZihengZZH", "id": 25486043, "node_id": "MDQ6VXNlcjI1NDg2MDQz", "avatar_url": "https://avatars2.githubusercontent.com/u/25486043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZihengZZH", "html_url": "https://github.com/ZihengZZH", "followers_url": "https://api.github.com/users/ZihengZZH/followers", "following_url": "https://api.github.com/users/ZihengZZH/following{/other_user}", "gists_url": "https://api.github.com/users/ZihengZZH/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZihengZZH/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZihengZZH/subscriptions", "organizations_url": "https://api.github.com/users/ZihengZZH/orgs", "repos_url": "https://api.github.com/users/ZihengZZH/repos", "events_url": "https://api.github.com/users/ZihengZZH/events{/privacy}", "received_events_url": "https://api.github.com/users/ZihengZZH/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-20T01:46:58Z", "updated_at": "2019-09-20T02:36:51Z", "closed_at": "2019-09-20T02:36:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\n...\r\nI was conducting a simple experiment on Multi30K EN2DE translation (text-only) using ```model``` transformer and ```hparams_set``` transformer_base. It went well for some time but suddenly, the training stopped after the first training step and cannot proceed.\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Ubuntu 18.04 VM\r\n\r\n$ pip freeze | grep tensor\r\ntensorboard==1.14.0\r\ntensorflow==1.14.0\r\ntensorflow-estimator==1.14.0\r\n\r\n$ python -V\r\nPython 3.7.4\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\nIt's a simple text-only translation task and it went well for a couple of days. When I tried to set the hparams ```ema``` as True and run the training, it won't proceed. So I reset ```ema``` to False and rerun the training. The following error occurred.\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\nI0920 09:36:22.023988 140220529194816 session_manager.py:500] Running local_init_op.\r\nI0920 09:36:22.339501 140220529194816 session_manager.py:502] Done running local_init_op.\r\nI0920 09:36:35.505281 140220529194816 basic_session_run_hooks.py:606] Saving checkpoints for 0 into ./t2t-output/ende/model.ckpt.\r\n2019-09-20 09:37:01.837617: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 112 of 512\r\n2019-09-20 09:37:11.833300: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 248 of 512\r\n2019-09-20 09:37:21.829728: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 369 of 512\r\n2019-09-20 09:37:31.819060: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 480 of 512\r\n2019-09-20 09:37:34.421255: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\r\nI0920 09:38:26.924503 140220529194816 basic_session_run_hooks.py:262] loss = 8.342694, step = 1\r\n<THEN NOTHING GOES ON>\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1693", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1693/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1693/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1693/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1693", "id": 490734948, "node_id": "MDU6SXNzdWU0OTA3MzQ5NDg=", "number": 1693, "title": "Does enzh nmt task support character-base vocab?", "user": {"login": "Mr-wang2016", "id": 22363893, "node_id": "MDQ6VXNlcjIyMzYzODkz", "avatar_url": "https://avatars3.githubusercontent.com/u/22363893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mr-wang2016", "html_url": "https://github.com/Mr-wang2016", "followers_url": "https://api.github.com/users/Mr-wang2016/followers", "following_url": "https://api.github.com/users/Mr-wang2016/following{/other_user}", "gists_url": "https://api.github.com/users/Mr-wang2016/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mr-wang2016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mr-wang2016/subscriptions", "organizations_url": "https://api.github.com/users/Mr-wang2016/orgs", "repos_url": "https://api.github.com/users/Mr-wang2016/repos", "events_url": "https://api.github.com/users/Mr-wang2016/events{/privacy}", "received_events_url": "https://api.github.com/users/Mr-wang2016/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-09-08T10:00:12Z", "updated_at": "2019-09-15T06:54:45Z", "closed_at": "2019-09-15T06:54:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello:\r\n\r\nI want train enzh nmt model with the script translate_enzh.py. when i run t2t-datagen script i find the default vocab type is VocabType.SUBWORD, when i change vocab_type from  SUBWORD to character in vocab_type function, it seems that translate_enzh.py still use SubwordTextEncoder other than ByteTextEncoder or other TextEncoder. Also, it seems there is no difference in generated vocab as  the vocab_type is SUBWORD.\r\n\r\nSo, does enzh Translation task support character-base vocab?\r\n\r\nDid i miss something? thanks for your reply!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1685", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1685/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1685/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1685/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1685", "id": 486663273, "node_id": "MDU6SXNzdWU0ODY2NjMyNzM=", "number": 1685, "title": "AssertionError FLAGS.output_dir in t2t-decoder (despite defining output_dir flag)", "user": {"login": "katelynrwalker", "id": 42429344, "node_id": "MDQ6VXNlcjQyNDI5MzQ0", "avatar_url": "https://avatars2.githubusercontent.com/u/42429344?v=4", "gravatar_id": "", "url": "https://api.github.com/users/katelynrwalker", "html_url": "https://github.com/katelynrwalker", "followers_url": "https://api.github.com/users/katelynrwalker/followers", "following_url": "https://api.github.com/users/katelynrwalker/following{/other_user}", "gists_url": "https://api.github.com/users/katelynrwalker/gists{/gist_id}", "starred_url": "https://api.github.com/users/katelynrwalker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/katelynrwalker/subscriptions", "organizations_url": "https://api.github.com/users/katelynrwalker/orgs", "repos_url": "https://api.github.com/users/katelynrwalker/repos", "events_url": "https://api.github.com/users/katelynrwalker/events{/privacy}", "received_events_url": "https://api.github.com/users/katelynrwalker/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-08-28T23:51:42Z", "updated_at": "2019-09-06T19:12:37Z", "closed_at": "2019-09-06T17:52:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nWhen I run t2t-decoder, it fails based on an Assertion error that there is no FLAGS.output_dir or FLAGS.checkpoint_path. However, I defined the output_dir flag when I ran the command. \r\n\r\nGoing into the t2t_trainer.py and t2t_decoder.py code and placing a few print statements showed that the FLAGS.output_dir is indeed blank.\r\n...\r\n\r\n### Environment information\r\n\r\n```              \r\ntensor2tensor            1.12.0                            \r\ntensorflow               1.12.0               \r\npython 3.7.4\r\n```\r\nAlso got same error with:   \r\n```\r\ntensor2tensor            1.14.0     \r\ntensorflow               1.14.0    \r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n### Steps to reproduce:\r\n```\r\n/home/ubuntu/anaconda3/envs/t2t/bin/t2t-decoder \\\r\n  --data_dir=/data/20190816/cu/single \\\r\n  --t2t_usr_dir=/home/ubuntu/code/ref-element-extract/trainer \\\r\n  --problem=cutag \\\r\n  --model=transformer \\\r\n  --hparams_set=transformer_big \\\r\n \u00a0--output_dir=/data/models/trained_model_with_types_20190816 \\\r\n  --decode_hparams=\"batch_size=64,beam_size=0,extra_length=0,force_decode_length=True\" \\\r\n  --decode_from_file=/data/20190816/eval/input.txt \\\r\n  --decode_to_file=/data/20190816/eval/predictions.txt\r\n```\r\n### Error logs:\r\n```\r\nINFO:tensorflow:Importing user module trainer from path /home/ubuntu/code/ref-element-extract\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/anaconda3/envs/t2t/bin/t2t-decoder\", line 17, in <module>\r\n    tf.app.run()\r\n  File \"/home/ubuntu/anaconda3/envs/t2t/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/ubuntu/anaconda3/envs/t2t/bin/t2t-decoder\", line 12, in main\r\n    t2t_decoder.main(argv)\r\n  File \"/home/ubuntu/anaconda3/envs/t2t/lib/python3.6/site-packages/tensor2tensor/bin/t2t_decoder.py\", line 188, in main\r\n    t2t_trainer.create_run_config(hp),\r\n  File \"/home/ubuntu/anaconda3/envs/t2t/lib/python3.6/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 215, in create_run_config\r\n    assert FLAGS.output_dir or FLAGS.checkpoint_path\r\nAssertionError\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1676", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1676/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1676/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1676/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1676", "id": 484848377, "node_id": "MDU6SXNzdWU0ODQ4NDgzNzc=", "number": 1676, "title": "Bad results in the inference of speech recognition", "user": {"login": "manuel3265", "id": 39747299, "node_id": "MDQ6VXNlcjM5NzQ3Mjk5", "avatar_url": "https://avatars1.githubusercontent.com/u/39747299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manuel3265", "html_url": "https://github.com/manuel3265", "followers_url": "https://api.github.com/users/manuel3265/followers", "following_url": "https://api.github.com/users/manuel3265/following{/other_user}", "gists_url": "https://api.github.com/users/manuel3265/gists{/gist_id}", "starred_url": "https://api.github.com/users/manuel3265/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manuel3265/subscriptions", "organizations_url": "https://api.github.com/users/manuel3265/orgs", "repos_url": "https://api.github.com/users/manuel3265/repos", "events_url": "https://api.github.com/users/manuel3265/events{/privacy}", "received_events_url": "https://api.github.com/users/manuel3265/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-24T18:11:24Z", "updated_at": "2020-02-17T16:17:15Z", "closed_at": "2020-02-17T16:17:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI did the voice recognition model training with my own data. I have trained with different numbers of steps: 10000, 30000, 50000, 150000 and 270000. The problem is that when putting the model into production with the flow model server tensor, we get somewhat strange results.\r\nThe results obtained are exactly the same as those of the training transcripts, for example:\r\n\r\n**TRAINING TRANSCRIPTS**\r\nI can not\r\nI'm not\r\nno, not today\r\nYes I can do it\r\nYes i am available\r\n...\r\n\r\n**INFERENCE**\r\n1)\r\n- **Audio content**: no\r\n\r\n- **result**: no, not today\r\n\r\n2)\r\n- **Audio content**: Yes\r\n\r\n- **result**: Yes i am available\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Debian 9 \r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.5\r\ntensor2tensorM==2.0.4\r\ntensorboard==1.14.0\r\ntensorflow==1.13.1\r\ntensorflow-datasets==1.0.2\r\ntensorflow-estimator==1.13.0\r\ntensorflow-hub==0.4.0\r\ntensorflow-metadata==0.13.0\r\ntensorflow-probability==0.6.0\r\ntensorflow-serving-api==1.12.0\r\n\r\n$ python -V\r\nPython 3.5.3\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1673", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1673/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1673/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1673/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1673", "id": 484412897, "node_id": "MDU6SXNzdWU0ODQ0MTI4OTc=", "number": 1673, "title": "Checkpoint specification flag during evaluation ?", "user": {"login": "ragnarlbrok", "id": 8268102, "node_id": "MDQ6VXNlcjgyNjgxMDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8268102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ragnarlbrok", "html_url": "https://github.com/ragnarlbrok", "followers_url": "https://api.github.com/users/ragnarlbrok/followers", "following_url": "https://api.github.com/users/ragnarlbrok/following{/other_user}", "gists_url": "https://api.github.com/users/ragnarlbrok/gists{/gist_id}", "starred_url": "https://api.github.com/users/ragnarlbrok/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ragnarlbrok/subscriptions", "organizations_url": "https://api.github.com/users/ragnarlbrok/orgs", "repos_url": "https://api.github.com/users/ragnarlbrok/repos", "events_url": "https://api.github.com/users/ragnarlbrok/events{/privacy}", "received_events_url": "https://api.github.com/users/ragnarlbrok/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-23T08:57:40Z", "updated_at": "2020-01-06T05:37:16Z", "closed_at": "2020-01-06T05:37:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "What flag should be used to evaluate a model on user specified checkpoint rather than latest checkpoint ?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1667", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1667/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1667/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1667/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1667", "id": 483172006, "node_id": "MDU6SXNzdWU0ODMxNzIwMDY=", "number": 1667, "title": "No preset models and hparams in tensor2tensor.utils.registry", "user": {"login": "Victor-Almeida", "id": 41767440, "node_id": "MDQ6VXNlcjQxNzY3NDQw", "avatar_url": "https://avatars0.githubusercontent.com/u/41767440?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Victor-Almeida", "html_url": "https://github.com/Victor-Almeida", "followers_url": "https://api.github.com/users/Victor-Almeida/followers", "following_url": "https://api.github.com/users/Victor-Almeida/following{/other_user}", "gists_url": "https://api.github.com/users/Victor-Almeida/gists{/gist_id}", "starred_url": "https://api.github.com/users/Victor-Almeida/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Victor-Almeida/subscriptions", "organizations_url": "https://api.github.com/users/Victor-Almeida/orgs", "repos_url": "https://api.github.com/users/Victor-Almeida/repos", "events_url": "https://api.github.com/users/Victor-Almeida/events{/privacy}", "received_events_url": "https://api.github.com/users/Victor-Almeida/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-21T02:52:12Z", "updated_at": "2019-08-21T02:56:29Z", "closed_at": "2019-08-21T02:56:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nHello. I'm using tensor2tensor on Google Colab and have stumbled upon a problem with t2t's registry's preset models and hparams. When I do \r\n```\r\n!pip3 install -q -U tensor2tensor\r\nfrom tensor2tensor.utils import registry\r\n\r\nprint(registry.list_models())\r\nprint(registry.list_hparams())\r\n```\r\nI get \r\n\r\n```\r\n[]\r\n['basic_1']\r\n```\r\nThe fun fact is that when I run t2t's notebooks all models and hparams are listed normally. Is there a way I can fetch these models and hparams or something? \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1663", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1663/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1663/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1663/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1663", "id": 481658734, "node_id": "MDU6SXNzdWU0ODE2NTg3MzQ=", "number": 1663, "title": "cannot import name 'loas2'", "user": {"login": "KyunghyunLee", "id": 6062751, "node_id": "MDQ6VXNlcjYwNjI3NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/6062751?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KyunghyunLee", "html_url": "https://github.com/KyunghyunLee", "followers_url": "https://api.github.com/users/KyunghyunLee/followers", "following_url": "https://api.github.com/users/KyunghyunLee/following{/other_user}", "gists_url": "https://api.github.com/users/KyunghyunLee/gists{/gist_id}", "starred_url": "https://api.github.com/users/KyunghyunLee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KyunghyunLee/subscriptions", "organizations_url": "https://api.github.com/users/KyunghyunLee/orgs", "repos_url": "https://api.github.com/users/KyunghyunLee/repos", "events_url": "https://api.github.com/users/KyunghyunLee/events{/privacy}", "received_events_url": "https://api.github.com/users/KyunghyunLee/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-08-16T15:17:30Z", "updated_at": "2019-08-26T18:39:01Z", "closed_at": "2019-08-26T18:08:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI am trying to run `rl/trainer_model_based.py`. \r\nI run the example command in the file and got the error at line 24 of `env/client_env.py`. \r\n`from grpc import loas2`\r\n\r\nI tried several version of grpc in case of library change, but not succeed. \r\n\r\n\r\n### Environment information\r\n\r\n```\r\nOS: ubuntu 16.04\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.5\r\n-e git+https://github.com/tensorflow/tensor2tensor@33783fd63bd0debe2138c5569698b31d9af350f6#egg=tensor2tensor\r\ntensorboard==1.14.0\r\ntensorflow-datasets==1.1.0\r\ntensorflow-estimator==1.14.0\r\ntensorflow-gpu==1.14.0\r\ntensorflow-metadata==0.14.0\r\ntensorflow-probability==0.7.0\r\n\r\n$ python -V\r\nPython 3.6.9 :: Anaconda, Inc.\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n\r\npython -m tensor2tensor.rl.trainer_model_based \\\r\n    --output_dir=$HOME/t2t/rl_v1 \\\r\n    --loop_hparams_set=rlmb_base \\\r\n    --loop_hparams='num_real_env_frames=10000,epochs=3'\r\n\r\n(same as the Example invocation in trainer_model_based.py)\r\n```\r\n```\r\n# Error logs:\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0816 23:41:59.412693 139681197864704 deprecation_wrapper.py:119] From /home/lkh/Codes/tensor2tensor/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nW0816 23:42:00.307283 139681197864704 lazy_loader.py:50] \r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nW0816 23:42:03.780892 139681197864704 deprecation_wrapper.py:119] From /home/lkh/Codes/tensor2tensor/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n\r\nW0816 23:42:03.782154 139681197864704 deprecation_wrapper.py:119] From /home/lkh/Codes/tensor2tensor/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n\r\nW0816 23:42:03.838312 139681197864704 deprecation_wrapper.py:119] From /home/lkh/anaconda3/envs/cule/lib/python3.6/site-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\r\n\r\nW0816 23:42:03.838605 139681197864704 deprecation_wrapper.py:119] From /home/lkh/anaconda3/envs/cule/lib/python3.6/site-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n\r\nW0816 23:42:03.916944 139681197864704 deprecation_wrapper.py:119] From /home/lkh/Codes/tensor2tensor/tensor2tensor/models/research/neural_stack.py:38: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/lkh/Downloads/pycharm-community-2018.2.5/helpers/pydev/pydevd.py\", line 1664, in <module>\r\n    main()\r\n  File \"/home/lkh/Downloads/pycharm-community-2018.2.5/helpers/pydev/pydevd.py\", line 1658, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/home/lkh/Downloads/pycharm-community-2018.2.5/helpers/pydev/pydevd.py\", line 1068, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/home/lkh/Downloads/pycharm-community-2018.2.5/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/home/lkh/Codes/tensor2tensor/tensor2tensor/rl/trainer_model_based.py\", line 38, in <module>\r\n    from tensor2tensor.bin import t2t_trainer  # pylint: disable=unused-import\r\n  File \"/home/lkh/Codes/tensor2tensor/tensor2tensor/bin/t2t_trainer.py\", line 24, in <module>\r\n    from tensor2tensor import models  # pylint: disable=unused-import\r\n  File \"/home/lkh/Codes/tensor2tensor/tensor2tensor/models/__init__.py\", line 61, in <module>\r\n    from tensor2tensor.models.research import rl\r\n  File \"/home/lkh/Codes/tensor2tensor/tensor2tensor/models/research/rl.py\", line 27, in <module>\r\n    from tensor2tensor.envs import tic_tac_toe_env\r\n  File \"/home/lkh/Codes/tensor2tensor/tensor2tensor/envs/__init__.py\", line 24, in <module>\r\n    from tensor2tensor.envs import client_env\r\n  File \"/home/lkh/Codes/tensor2tensor/tensor2tensor/envs/client_env.py\", line 24, in <module>\r\n    from grpc import loas2\r\nImportError: cannot import name 'loas2'\r\nWe've got an error while stopping in post-mortem: <class 'KeyboardInterrupt'>\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1660", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1660/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1660/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1660/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1660", "id": 480176083, "node_id": "MDU6SXNzdWU0ODAxNzYwODM=", "number": 1660, "title": "ERROR: (gcloud.compute.instances.create) Could not fetch resource:", "user": {"login": "SKRohit", "id": 9626333, "node_id": "MDQ6VXNlcjk2MjYzMzM=", "avatar_url": "https://avatars3.githubusercontent.com/u/9626333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SKRohit", "html_url": "https://github.com/SKRohit", "followers_url": "https://api.github.com/users/SKRohit/followers", "following_url": "https://api.github.com/users/SKRohit/following{/other_user}", "gists_url": "https://api.github.com/users/SKRohit/gists{/gist_id}", "starred_url": "https://api.github.com/users/SKRohit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SKRohit/subscriptions", "organizations_url": "https://api.github.com/users/SKRohit/orgs", "repos_url": "https://api.github.com/users/SKRohit/repos", "events_url": "https://api.github.com/users/SKRohit/events{/privacy}", "received_events_url": "https://api.github.com/users/SKRohit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-13T14:04:22Z", "updated_at": "2019-09-01T12:12:33Z", "closed_at": "2019-09-01T12:12:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI am getting this error when running the command in **Commands to generate WikisumCommonCrawl**\r\n\r\n`python -m tensor2tensor.data_generators.wikisum.parallel_launch \\\r\n  --num_instances=1000 \\\r\n  --cpu=1 --mem=2 \\\r\n  --name=wikisum-cc-refs \\\r\n  --log_dir=$BUCKET/logs \\\r\n  --setup_command=\"pip install tensor2tensor tensorflow -U -q --user\" \\\r\n  --command_prefix=\"python -m tensor2tensor.data_generators.wikisum.get_references_commoncrawl --num_tasks=1000 --out_dir=$BUCKET/wiki_references --task_id\"`\r\n\r\n```\r\n# part of output\r\nINFO:tensorflow:Creating instance wikisum-cc-refs-245\r\nINFO:tensorflow:Creating instance wikisum-cc-refs-246\r\nINFO:tensorflow:Creating instance wikisum-cc-refs-247\r\nINFO:tensorflow:Creating instance wikisum-cc-refs-248\r\nERROR: (gcloud.compute.instances.create) Could not fetch resource:\r\n - The resource 'projects/ml-images/global/images/family/tf-1-7' was not found\r\n```\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1659", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1659/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1659/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1659/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1659", "id": 480158318, "node_id": "MDU6SXNzdWU0ODAxNTgzMTg=", "number": 1659, "title": "Getting to work with MultiProblem", "user": {"login": "stefan-falk", "id": 43335432, "node_id": "MDQ6VXNlcjQzMzM1NDMy", "avatar_url": "https://avatars1.githubusercontent.com/u/43335432?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stefan-falk", "html_url": "https://github.com/stefan-falk", "followers_url": "https://api.github.com/users/stefan-falk/followers", "following_url": "https://api.github.com/users/stefan-falk/following{/other_user}", "gists_url": "https://api.github.com/users/stefan-falk/gists{/gist_id}", "starred_url": "https://api.github.com/users/stefan-falk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stefan-falk/subscriptions", "organizations_url": "https://api.github.com/users/stefan-falk/orgs", "repos_url": "https://api.github.com/users/stefan-falk/repos", "events_url": "https://api.github.com/users/stefan-falk/events{/privacy}", "received_events_url": "https://api.github.com/users/stefan-falk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-08-13T13:30:34Z", "updated_at": "2019-09-05T10:00:01Z", "closed_at": "2019-09-05T10:00:01Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "#### Please refer to https://github.com/tensorflow/tensor2tensor/issues/1687\r\n\r\n----\r\n\r\nFor training models, I have separated the data generation pipeline from t2t. For that I have implemented my own problem which, in essence, already expects a created dataset.\r\n\r\n```python\r\n@registry.register_problem\r\nclass ConfigBasedTranslationProblem(translate.TranslateProblem):\r\n\r\n    # ...\r\n\r\n    def training_filepaths(self, data_dir, num_shards, shuffled):\r\n        return glob.glob(os.path.join(data_dir, '*.train.shard'))\r\n\r\n    # ...\r\n\r\n    def filepattern(self, data_dir, split: str, shard=None):\r\n        split = 'dev' if split == 'eval' else split\r\n        return os.path.join(data_dir, '*.%s.shard' % split)\r\n\r\n    def generate_data(self, data_dir, tmp_dir, task_id=-1):\r\n        raise NotImplementedError('Data should already be generated.')\r\n\r\n    def prepare_to_generate(self, data_dir, tmp_dir):\r\n        raise NotImplementedError('Data should already be generated.')\r\n\r\n    def source_data_files(self, dataset_split):\r\n        raise NotImplementedError('Data should already be generated.')\r\n```\r\n\r\nThis works great so far but now that I discovered `MultiProblem` ([`multi_problem.md`](https://github.com/tensorflow/tensor2tensor/blob/master/docs/multi_problem.md)) I am facing some issues and questions I was hoping to be able to clarify here.\r\n\r\n### The Language Model in `MultiProblem` (?)\r\n\r\nThis is not really a question but more a suggestion for code and API changes. I would provide a PR but atm I am stuck with tensor2tensor 1.12 and until I updated to 1.13 I won't have resources for it.\r\n\r\nFrom  ([`multi_problem.md`](https://github.com/tensorflow/tensor2tensor/blob/master/docs/multi_problem.md)) and the code I can see that the first `problem` has to be a language-model problem.\r\n\r\nFrom the looks, this seems like a requirement which could be relaxed. The first task seems to be used just to create a vocabulary for all languages. In my implementation, I just merge all vocabularies from all tasks (here called `dataset`) to one and return a `SubwordEncoder`:\r\n\r\n```python\r\ndatasets = self.get_datasets()\r\nreserved_tokens = set()\r\nsubword_tokens = set()\r\nfor dataset in datasets:\r\n    encoders = dataset.feature_encoders()\r\n    for encoder in encoders.values():\r\n        encoder = cast(SubwordEncoder, encoder)\r\n        reserved_tokens.update(encoder.reserved_tokens)\r\n        subword_tokens.update(encoder.subword_tokens)\r\n\r\nfinal_subwords = list(reserved_tokens) + sorted(list(subword_tokens.difference(reserved_tokens)))\r\n# ...\r\nreturn SubwordEncoder(vocab_fp)\r\n``` \r\n\r\nThe only other occurrence of the primary task I can see is in `get_hparams()` in order to set the vocab size and modality.\r\n\r\nImho it could make sense to relax this requirement if `MultiProblem` itself provided feature encoders for inputs and targets. All that is required for this would be additional \"merge-vocab\" logic and `MultiProblem` could work without the first task having to be a language model problem.\r\n\r\n### How does `MultiProblem` training work?\r\n\r\nIn the `MultiProblem` class we find this:\r\n\r\n```python\r\ntask_dataset = task_dataset.map(\r\n  lambda x: self.add_task_id(task, x, enc, hparams, is_infer))\r\n```\r\nand `add_task_id()` takes an `example` (here `x`) in order to create\r\n\r\n```python\r\n# not is_infer \r\ninputs = example.pop(\"inputs\")\r\nconcat_list = [inputs, [task.task_id], example[\"targets\"]]\r\nexample[\"targets\"] = tf.concat(concat_list, axis=0)\r\n```\r\nin case the problem has inputs or\r\n\r\n```python\r\nconcat_list = [[task.task_id], example[\"targets\"]]\r\nexample[\"targets\"] = tf.concat(concat_list, axis=0)\r\n```\r\n\r\nin case the problem has no inputs.\r\n\r\nNow, I do not quite understand why a `MultiProblem` only works on examples which provide `targets`. I was under the impression that we still simply train a `Transformer` model which gets `inputs` and `targets` presented as usual but that these samples are drawn from a set of tasks (problems/corpora) for training (see `multiproblem_per_task_threshold`).\r\n\r\nSo in theory, I should be able to create a classic `Text2TextProblem` which contains all required samples (plus a `task_id` for each sample) and it _should_ work as well, right? Or does `MultiProblem` work totally different?\r\n\r\nThe `task_id` does not set a different \"_mode_\" or something, it's just additional context for the model, isn't it?\r\n\r\n### The Transformer in `MultiProblem`\r\n\r\nI noticed that the graph of the Transformer looks very different from why I know from single-problem training. In particular, I noticed that there are no encoder layers? The `body` only contains the `decoder` layers. Why is this the case or what am I missing here?\r\n\r\n> *Note:* It should not matter but this is from the `EvolvedTransformer` in particular\r\n\r\n![image](https://user-images.githubusercontent.com/43335432/62944531-2bb1b780-bddd-11e9-89a0-41aa84e10ef4.png)\r\n\r\nDoes this mean hparams like `num_encoder_layers` are getting ignored here?\r\n\r\n### `MultiProblem` Training Best Practice\r\n\r\nI am not at the point where I could make use of recommendations but what I was thinking of was something like the following:\r\n\r\nI want to test if (or how much) a small dataset can benefit from `MultiProblem` training. For this I would like to use a small `de_en` dataset. The main task of the `MultiProblem` would be to learn `en2de`. In addition I would like to use a `en_fr`. So the second task would be  a training on `en2fr` translation.\r\n\r\nSetting `multiproblem_per_task_threshold` to`\"95,5\"` would mean that batches should consist of 95% `en2de` and 5% `en2fr` samples, is that correct? If so, can I expect improvements for the `\"constant\"` schedule or should I rather consider the `\"pretrain\"` schedule?\r\n\r\nAny comments on that would be appreciated.\r\n\r\n----\r\n\r\nThere are some other things I do not understand. Some which are inside the code of  `MultiProblem` e.g. the following:\r\n\r\n```python\r\ndef dataset(self, ...): \r\n     # ..\r\n      if not is_training and not is_infer:\r\n        zeros = tf.zeros([self._ADDED_EVAL_COUNT, 1], dtype=tf.int64)\r\n        pad_data = tf.data.Dataset.from_tensor_slices({\r\n            \"targets\": zeros,\r\n            \"batch_prediction_key\": zeros,\r\n            \"task_id\": zeros,\r\n        })\r\n        task_dataset = task_dataset.concatenate(pad_data)\r\n    # ..\r\n```\r\n\r\nwhich I 1) do not understand why it's there and 2) breaks my pipeline. I am overriding `example_reading_spec()` in my problems because I am adding things like the `corpus`-name which I use during evaluation. \r\n\r\n```python\r\ndef example_reading_spec(self):\r\n    data_fields = {\r\n        'targets': tf.VarLenFeature(tf.int64),\r\n        'corpus': tf.VarLenFeature(tf.int64)\r\n    }\r\n    data_items_to_decoders = None\r\n    return data_fields, data_items_to_decoders\r\n```\r\n\r\nSince this padding above is hard-coded, the program crashes. I had to override `MultiProblem.dataset` and add a dummy. What is this padding good for?\r\n\r\n----\r\n\r\nI know this is a lot so thank you for any response to these questions.\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1658", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1658/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1658/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1658/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1658", "id": 480072230, "node_id": "MDU6SXNzdWU0ODAwNzIyMzA=", "number": 1658, "title": "tf serving RESTful  API  request format", "user": {"login": "Roshanson", "id": 6957133, "node_id": "MDQ6VXNlcjY5NTcxMzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6957133?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Roshanson", "html_url": "https://github.com/Roshanson", "followers_url": "https://api.github.com/users/Roshanson/followers", "following_url": "https://api.github.com/users/Roshanson/following{/other_user}", "gists_url": "https://api.github.com/users/Roshanson/gists{/gist_id}", "starred_url": "https://api.github.com/users/Roshanson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Roshanson/subscriptions", "organizations_url": "https://api.github.com/users/Roshanson/orgs", "repos_url": "https://api.github.com/users/Roshanson/repos", "events_url": "https://api.github.com/users/Roshanson/events{/privacy}", "received_events_url": "https://api.github.com/users/Roshanson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-13T10:10:20Z", "updated_at": "2020-07-07T10:23:50Z", "closed_at": "2019-08-23T07:53:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI trained a model with my own data. Then use export.py to convert the .ckpt model to saved_model.Then I started a tf serving.  The interface  in grpc format is ok.  But I need a RSETful type of interface.  I did a lot of trials and still didn't succeed...\r\n\r\nHas anyone tried to build a tf serving service with a RESTful-style interface? I can't find the correct request format\r\n\r\nwhen i send a post request\r\ncurl -d '{\"instances\": [{\"input\": {\"b64\": \"Ijg1MyI=\"}}]}' -X POST http://10.25.59.196:8501/v1/models/translate:predict\r\n\r\ni get:\r\n\r\n       {\r\n        \"error\": \"Requested more than 0 entries, but params is empty.  Params shape: \r\n         [1,4,1,1,0]\\n\\t \r\n         [[{{node transformer/while/GatherNd_1}}]]\"\r\n         }\r\n\r\nhere is the metadata:\r\n\r\n        {\r\n\t\"model_spec\": {\r\n\t\t\"name\": \"translate\",\r\n\t\t\"signature_name\": \"\",\r\n\t\t\"version\": \"1565597475\"\r\n\t},\r\n\t\"metadata\": {\r\n\t\t\"signature_def\": {\r\n\t\t\t\"signature_def\": {\r\n\t\t\t\t\"serving_default\": {\r\n\t\t\t\t\t\"inputs\": {\r\n\t\t\t\t\t\t\"input\": {\r\n\t\t\t\t\t\t\t\"dtype\": \"DT_STRING\",\r\n\t\t\t\t\t\t\t\"tensor_shape\": {\r\n\t\t\t\t\t\t\t\t\"dim\": [{\r\n\t\t\t\t\t\t\t\t\t\"size\": \"-1\",\r\n\t\t\t\t\t\t\t\t\t\"name\": \"\"\r\n\t\t\t\t\t\t\t\t}],\r\n\t\t\t\t\t\t\t\t\"unknown_rank\": false\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\"name\": \"serialized_example:0\"\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t},\r\n\t\t\t\t\t\"outputs\": {\r\n\t\t\t\t\t\t\"scores\": {\r\n\t\t\t\t\t\t\t\"dtype\": \"DT_FLOAT\",\r\n\t\t\t\t\t\t\t\"tensor_shape\": {\r\n\t\t\t\t\t\t\t\t\"dim\": [{\r\n\t\t\t\t\t\t\t\t\t\"size\": \"-1\",\r\n\t\t\t\t\t\t\t\t\t\"name\": \"\"\r\n\t\t\t\t\t\t\t\t}],\r\n\t\t\t\t\t\t\t\t\"unknown_rank\": false\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\"name\": \"transformer/strided_slice_11:0\"\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\"batch_prediction_key\": {\r\n\t\t\t\t\t\t\t\"dtype\": \"DT_INT32\",\r\n\t\t\t\t\t\t\t\"tensor_shape\": {\r\n\t\t\t\t\t\t\t\t\"dim\": [{\r\n\t\t\t\t\t\t\t\t\t\t\"size\": \"-1\",\r\n\t\t\t\t\t\t\t\t\t\t\"name\": \"\"\r\n\t\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\t\t\"size\": \"1\",\r\n\t\t\t\t\t\t\t\t\t\t\"name\": \"\"\r\n\t\t\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\t\t],\r\n\t\t\t\t\t\t\t\t\"unknown_rank\": false\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\"name\": \"DatasetToSingleElement:0\"\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\"outputs\": {\r\n\t\t\t\t\t\t\t\"dtype\": \"DT_INT32\",\r\n\t\t\t\t\t\t\t\"tensor_shape\": {\r\n\t\t\t\t\t\t\t\t\"dim\": [{\r\n\t\t\t\t\t\t\t\t\t\t\"size\": \"-1\",\r\n\t\t\t\t\t\t\t\t\t\t\"name\": \"\"\r\n\t\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\t\t\"size\": \"-1\",\r\n\t\t\t\t\t\t\t\t\t\t\"name\": \"\"\r\n\t\t\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\t\t],\r\n\t\t\t\t\t\t\t\t\"unknown_rank\": false\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\"name\": \"transformer/strided_slice_10:0\"\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t},\r\n\t\t\t\t\t\"method_name\": \"tensorflow/serving/predict\"\r\n\t\t\t \t}\r\n\t\t \t}\r\n\t \t}\r\n\t }\r\n     }\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1647", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1647/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1647/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1647/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1647", "id": 473099213, "node_id": "MDU6SXNzdWU0NzMwOTkyMTM=", "number": 1647, "title": "file fr_mono_en.txt not found", "user": {"login": "shadigit", "id": 37717852, "node_id": "MDQ6VXNlcjM3NzE3ODUy", "avatar_url": "https://avatars0.githubusercontent.com/u/37717852?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shadigit", "html_url": "https://github.com/shadigit", "followers_url": "https://api.github.com/users/shadigit/followers", "following_url": "https://api.github.com/users/shadigit/following{/other_user}", "gists_url": "https://api.github.com/users/shadigit/gists{/gist_id}", "starred_url": "https://api.github.com/users/shadigit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shadigit/subscriptions", "organizations_url": "https://api.github.com/users/shadigit/orgs", "repos_url": "https://api.github.com/users/shadigit/repos", "events_url": "https://api.github.com/users/shadigit/events{/privacy}", "received_events_url": "https://api.github.com/users/shadigit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-25T22:37:42Z", "updated_at": "2019-07-25T23:46:38Z", "closed_at": "2019-07-25T23:46:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nHi,\r\nThank you for this wonderful platform. \r\nI was trying to test problem \r\ntranslate_enfr_wmt32k_with_backtranslate_fr\r\nbut found the error of \r\nt2t_datagen/fr_mono_en.txt; No such file or directory\r\nit seems that these files are not downloaded.\r\n### Environment information\r\n\r\n```\r\nOS: Ubuntu 18.04.2 LTS\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\nbert-tensorflow==1.0.1\r\nmesh-tensorflow==0.0.5\r\ntensor2tensor==1.13.4\r\ntensorboard==1.14.0\r\ntensorflow-estimator==1.14.0\r\ntensorflow-gpu==1.14.0\r\ntensorflow-hub==0.5.0\r\ntensorflow-probability==0.7.0\r\n\r\n$ python -V\r\n# your output here\r\n```\r\nPython 2.7.15+ and Python 3.6.8\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\nsame as tutorial with the above problem\r\n```\r\n# Error logs:\r\n...\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-datagen\", line 28, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/bin/t2t-datagen\", line 23, in main\r\n    t2t_datagen.main(argv)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_datagen.py\", line 216, in main\r\n    generate_data_for_registered_problem(problem)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_datagen.py\", line 301, in generate_data_for_registered_problem\r\n    problem.generate_data(data_dir, tmp_dir, task_id)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/text_problems.py\", line 362, in generate_data\r\n    self.generate_encoded_samples(data_dir, tmp_dir, split), paths)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/generator_utils.py\", line 166, in generate_files\r\n    for case in generator:\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/text_problems.py\", line 712, in text2text_generate_encoded\r\n    for sample in sample_generator:\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/translate_enfr.py\", line 193, in generate_samples\r\n    for example in text_problems.text2text_txt_iterator(path1, path2):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/text_problems.py\", line 636, in text2text_txt_iterator\r\n    txt_line_iterator(source_txt_path), txt_line_iterator(target_txt_path)):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/text_problems.py\", line 611, in txt_line_iterator\r\n    for line in f:\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\", line 220, in __next__\r\n    return self.next()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\", line 214, in next\r\n    retval = self.readline()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\", line 178, in readline\r\n    self._preread_check()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\", line 84, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /t2t_datagen/fr_mono_en.txt; No such file or directory\r\n\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1636", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1636/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1636/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1636/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1636", "id": 471102402, "node_id": "MDU6SXNzdWU0NzExMDI0MDI=", "number": 1636, "title": "How to finetune a model with a different vocab?", "user": {"login": "SiriusKY", "id": 26294424, "node_id": "MDQ6VXNlcjI2Mjk0NDI0", "avatar_url": "https://avatars0.githubusercontent.com/u/26294424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SiriusKY", "html_url": "https://github.com/SiriusKY", "followers_url": "https://api.github.com/users/SiriusKY/followers", "following_url": "https://api.github.com/users/SiriusKY/following{/other_user}", "gists_url": "https://api.github.com/users/SiriusKY/gists{/gist_id}", "starred_url": "https://api.github.com/users/SiriusKY/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SiriusKY/subscriptions", "organizations_url": "https://api.github.com/users/SiriusKY/orgs", "repos_url": "https://api.github.com/users/SiriusKY/repos", "events_url": "https://api.github.com/users/SiriusKY/events{/privacy}", "received_events_url": "https://api.github.com/users/SiriusKY/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-22T13:41:22Z", "updated_at": "2020-05-07T14:20:31Z", "closed_at": "2019-07-28T13:18:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI have trained a universal translation model with t2t, if I get new corpus in a specific field, can I modify the vocab file and train a model based on the model I have now? Thanks!!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1631", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1631/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1631/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1631/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1631", "id": 467628166, "node_id": "MDU6SXNzdWU0Njc2MjgxNjY=", "number": 1631, "title": "Most straight forward way to train summarization on new data with simpler format than CNN/DM datasets? Make a new data_generator ?", "user": {"login": "Santosh-Gupta", "id": 5524261, "node_id": "MDQ6VXNlcjU1MjQyNjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5524261?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Santosh-Gupta", "html_url": "https://github.com/Santosh-Gupta", "followers_url": "https://api.github.com/users/Santosh-Gupta/followers", "following_url": "https://api.github.com/users/Santosh-Gupta/following{/other_user}", "gists_url": "https://api.github.com/users/Santosh-Gupta/gists{/gist_id}", "starred_url": "https://api.github.com/users/Santosh-Gupta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Santosh-Gupta/subscriptions", "organizations_url": "https://api.github.com/users/Santosh-Gupta/orgs", "repos_url": "https://api.github.com/users/Santosh-Gupta/repos", "events_url": "https://api.github.com/users/Santosh-Gupta/events{/privacy}", "received_events_url": "https://api.github.com/users/Santosh-Gupta/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-12T22:51:02Z", "updated_at": "2019-07-14T21:03:12Z", "closed_at": "2019-07-14T21:03:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI would like to train a summarizer on my own data, and I am wondering what's the most straightforward way to do this. The CNN/DailyMail datasets have a bit of an odd format which seems tricky to convert regular summarization datasets (CSVs with 1 column for source, 1 column for summary) into. \r\n\r\nSo from my analysis of the code, the easiest to for Tensor2Tensor to accept new summarization datasets is to develop new data_generators such that it will be able to training on any data formatted in CSV, one column being the source, the other column being the summary. \r\n\r\nMy plan is to use the data_generators/cnn_dailymail.py code as the base with the following alterations:\r\n\r\nFirst, replace the CNN/DailyMail google drive links with my own, here\r\n\r\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/cnn_dailymail.py#L37\r\n\r\nThen, I need to alter `def example_generator` in https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/cnn_dailymail.py#L137\r\n\r\nIn such a way that it'll take my custom data and put the source and summary in one line, seperated by story_summary_split_token ,( unless there's no sum_token )\r\n\r\nIs this it? Or is there anything else I need to take into consideration? \r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1629", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1629/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1629/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1629/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1629", "id": 466851617, "node_id": "MDU6SXNzdWU0NjY4NTE2MTc=", "number": 1629, "title": "accuracy from t2t model", "user": {"login": "radiodee1", "id": 8641916, "node_id": "MDQ6VXNlcjg2NDE5MTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/8641916?v=4", "gravatar_id": "", "url": "https://api.github.com/users/radiodee1", "html_url": "https://github.com/radiodee1", "followers_url": "https://api.github.com/users/radiodee1/followers", "following_url": "https://api.github.com/users/radiodee1/following{/other_user}", "gists_url": "https://api.github.com/users/radiodee1/gists{/gist_id}", "starred_url": "https://api.github.com/users/radiodee1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/radiodee1/subscriptions", "organizations_url": "https://api.github.com/users/radiodee1/orgs", "repos_url": "https://api.github.com/users/radiodee1/repos", "events_url": "https://api.github.com/users/radiodee1/events{/privacy}", "received_events_url": "https://api.github.com/users/radiodee1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-11T12:05:17Z", "updated_at": "2019-07-12T16:45:41Z", "closed_at": "2019-07-12T16:45:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nHi, I've got a model and dataset that I want to test. I want to measure accuracy. I want to know the percentage of times where the output of the trained model matches the target value. I am using t2t-trainer for training and t2t-decoder for evaluation. In the decoder I have set 'decode_to_file' and 'score_file' successfully. When I do this I get an output file that contains floats. Is there a way to convert those floats to something more useful? If not how do I go about getting that accuracy that I want?\r\n\r\nOS: linux\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1628", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1628/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1628/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1628/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1628", "id": 466808416, "node_id": "MDU6SXNzdWU0NjY4MDg0MTY=", "number": 1628, "title": "local_moe loss multiplied twice with loss_coefficient", "user": {"login": "davidmrau", "id": 20661461, "node_id": "MDQ6VXNlcjIwNjYxNDYx", "avatar_url": "https://avatars2.githubusercontent.com/u/20661461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidmrau", "html_url": "https://github.com/davidmrau", "followers_url": "https://api.github.com/users/davidmrau/followers", "following_url": "https://api.github.com/users/davidmrau/following{/other_user}", "gists_url": "https://api.github.com/users/davidmrau/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidmrau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidmrau/subscriptions", "organizations_url": "https://api.github.com/users/davidmrau/orgs", "repos_url": "https://api.github.com/users/davidmrau/repos", "events_url": "https://api.github.com/users/davidmrau/events{/privacy}", "received_events_url": "https://api.github.com/users/davidmrau/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-11T10:31:56Z", "updated_at": "2019-07-21T10:07:17Z", "closed_at": "2019-07-21T10:07:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nIn the case of topk gating, the loss is falsely multiplied twice by the loss coefficient. \r\nI fixed this in pull request #1627 ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1625", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1625/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1625/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1625/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1625", "id": 465031080, "node_id": "MDU6SXNzdWU0NjUwMzEwODA=", "number": 1625, "title": "Framework error when attempting mixed precision training", "user": {"login": "ekuznetsov139", "id": 12205429, "node_id": "MDQ6VXNlcjEyMjA1NDI5", "avatar_url": "https://avatars2.githubusercontent.com/u/12205429?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekuznetsov139", "html_url": "https://github.com/ekuznetsov139", "followers_url": "https://api.github.com/users/ekuznetsov139/followers", "following_url": "https://api.github.com/users/ekuznetsov139/following{/other_user}", "gists_url": "https://api.github.com/users/ekuznetsov139/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekuznetsov139/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekuznetsov139/subscriptions", "organizations_url": "https://api.github.com/users/ekuznetsov139/orgs", "repos_url": "https://api.github.com/users/ekuznetsov139/repos", "events_url": "https://api.github.com/users/ekuznetsov139/events{/privacy}", "received_events_url": "https://api.github.com/users/ekuznetsov139/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-07-08T02:52:00Z", "updated_at": "2019-07-16T23:21:18Z", "closed_at": "2019-07-16T23:21:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am attempting to use mixed precision (float16) training with transformer as described in #1362 using tensor2tensor 1.13.4. The problem is observed with tensorflow 1.13.1 and 1.14.0. Debian host with a Tesla V100 GPU.\r\n\r\nMixed precision is enabled by passing either  --hparams_set=transformer_fairseq_fp16_activation_big or explicitly --hparams weight_dtype=bfloat16,optimizer=Adafactor. \r\n\r\nIn either case, I get a wall of warnings:\r\n```\r\n\r\n<...> common_layers.py:3494] Cast for training/gradients/AddN_77:0 may induce copy from '/device:GPU:0' to ''\r\n<...>  common_layers.py:3494] Cast for training/gradients/AddN_78:0 may induce copy from '/device:GPU:0' to ''\r\n<...>  common_layers.py:3494] Cast for training/gradients/AddN_79:0 may induce copy from '/device:GPU:0' to ''\r\n<...>  common_layers.py:3494] Cast for training/gradients/AddN_80:0 may induce copy from '/device:GPU:0' to ''\r\n<...>  common_layers.py:3494] Cast for training/gradients/AddN_81:0 may induce copy from '/device:GPU:0' to ''\r\n<...>  common_layers.py:3494] Cast for training/gradients/AddN_82:0 may induce copy from '/device:GPU:0' to ''\r\n<...>  common_layers.py:3494] Cast for training/gradients/AddN_83:0 may induce copy from '/device:GPU:0' to ''\r\n```\r\n\r\nThe call trace for these goes to compute_gradients() in optimize.py\r\n, which attempts to cast e.g.\r\n`\r\nTensor(\"training/gradients/AddN_77:0\", shape=(2048, 512), dtype=float32, device=/device:GPU:0) `\r\n\r\nto type \r\n`\r\ntf.Variable 'transformer/symbol_modality_32755_512/shared/weights_0:0' shape=(2048, 512) dtype=bfloat16`\r\n\r\nI'm unclear as to whether this signifies a genuine problem or just a warning that some tensors are going to be sent onto the CPU to be cast to float16.\r\n\r\nHowever, a bit later, I get this:\r\n\r\n\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple OpKernel registrations match NodeDef 'node transformer/parallel_0_5/transformer/transformer/body/encoder/attention_bias_to_padding/Less (defined at /home/aidev/.local/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py:965) ': 'op: \"Less\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_BFLOAT16 } } }' and 'op: \"Less\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_BFLOAT16 } } }'\r\n\t [[node transformer/parallel_0_5/transformer/transformer/body/encoder/attention_bias_to_padding/Less (defined at /home/aidev/.local/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py:965) ]]\r\nCaused by op u'transformer/parallel_0_5/transformer/transformer/body/encoder/attention_bias_to_padding/Less', defined at:\r\n(snip)\r\n File \"/home/aidev/.local/lib/python2.7/site-packages/tensor2tensor/utils/expert_utils.py\", line 60, in decorated\r\n    return f(*args, **kwargs)\r\n  File \"/home/aidev/.local/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py\", line 965, in attention_bias_to_padding\r\n    return tf.squeeze(cast_fn(tf.less(attention_bias, -1)), axis=[1, 2])\r\n  File \"/home/aidev/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4622, in less\r\n    \"Less\", x=x, y=y, name=name)\r\n  File \"/home/aidev/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/aidev/.local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/aidev/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/home/aidev/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Multiple OpKernel registrations match NodeDef 'node transformer/parallel_0_5/transformer/transformer/body/encoder/attention_bias_to_padding/Less (defined at /home/aidev/.local/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py:965) ': 'op: \"Less\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_BFLOAT16 } } }' and 'op: \"Less\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_BFLOAT16 } } }'\r\n\t [[node transformer/parallel_0_5/transformer/transformer/body/encoder/attention_bias_to_padding/Less (defined at /home/aidev/.local/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py:965) ]]\r\n\r\n\r\nThis was with tensorflow 1.13.1. With 1.14.0, the error is less verbose, though equally fatal:\r\n\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple OpKernel registrations match NodeDef 'node transformer/parallel_0_5/transformer/transformer/body/encoder/attention_bias_to_padding/Less (defined at usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_attention.py:965) ': 'op: \"Less\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_BFLOAT16 } } }' and 'op: \"Less\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_BFLOAT16 } } }'\r\n         [[transformer/parallel_0_5/transformer/transformer/body/encoder/attention_bias_to_padding/Less]]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node transformer/parallel_0_5/transformer/transformer/body/encoder/attention_bias_to_padding/Less:\r\n transformer/parallel_0_5/transformer/transformer/body/Cast (defined at usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_layers.py:3486)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1617", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1617/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1617/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1617/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1617", "id": 460861930, "node_id": "MDU6SXNzdWU0NjA4NjE5MzA=", "number": 1617, "title": "Residual connections in the decoder allow cheating?", "user": {"login": "JannisBush", "id": 33023300, "node_id": "MDQ6VXNlcjMzMDIzMzAw", "avatar_url": "https://avatars1.githubusercontent.com/u/33023300?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JannisBush", "html_url": "https://github.com/JannisBush", "followers_url": "https://api.github.com/users/JannisBush/followers", "following_url": "https://api.github.com/users/JannisBush/following{/other_user}", "gists_url": "https://api.github.com/users/JannisBush/gists{/gist_id}", "starred_url": "https://api.github.com/users/JannisBush/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JannisBush/subscriptions", "organizations_url": "https://api.github.com/users/JannisBush/orgs", "repos_url": "https://api.github.com/users/JannisBush/repos", "events_url": "https://api.github.com/users/JannisBush/events{/privacy}", "received_events_url": "https://api.github.com/users/JannisBush/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-26T09:30:57Z", "updated_at": "2019-07-18T19:53:58Z", "closed_at": "2019-07-18T19:53:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "The masked-multi-head attention prevents cheating by masking out the tokens in the input sentence to the right of the current word, but the residual connections are unmasked and allow cheating? \r\n\r\nSay we have our input sequence x for the decoder and we apply the masked multi-head attention and get some representation y (Sublayer(x)) that has no access to the tokens to the right due to the masking (-inf in the softmax), but now we apply the Residual-Add & Norm step `LayerNorm(x+ Sublayer(x))`, only Sublayer(x) is masked, in x we still have information about words following our current word. In all decoder layers and sublayers there are residual connections, therefore some information from the original input sequence x can flow unmasked to the output and the network can cheat? \r\n\r\nWhere am I missing out/misunderstanding something? \r\nWhy can't the network cheat, despite these residual connections?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1615", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1615/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1615/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1615/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1615", "id": 460760787, "node_id": "MDU6SXNzdWU0NjA3NjA3ODc=", "number": 1615, "title": "Vocab not generated for user dataset", "user": {"login": "minump", "id": 22112888, "node_id": "MDQ6VXNlcjIyMTEyODg4", "avatar_url": "https://avatars1.githubusercontent.com/u/22112888?v=4", "gravatar_id": "", "url": "https://api.github.com/users/minump", "html_url": "https://github.com/minump", "followers_url": "https://api.github.com/users/minump/followers", "following_url": "https://api.github.com/users/minump/following{/other_user}", "gists_url": "https://api.github.com/users/minump/gists{/gist_id}", "starred_url": "https://api.github.com/users/minump/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/minump/subscriptions", "organizations_url": "https://api.github.com/users/minump/orgs", "repos_url": "https://api.github.com/users/minump/repos", "events_url": "https://api.github.com/users/minump/events{/privacy}", "received_events_url": "https://api.github.com/users/minump/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-26T04:58:50Z", "updated_at": "2019-07-05T17:57:35Z", "closed_at": "2019-07-05T17:57:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\ntrying out https://tensorflow.github.io/tensor2tensor/new_problem.html with data http://opus.nlpl.eu/download.php?f=ECB/v1/moses/de-en.txt.zip . The vocab is not being generated automatically. The new problem is registered correctly as it is in the output of t2t-trainer --t2t_usr_dir=\"ECB\" --registry_help\r\n translate:\r\n      * translate_ecb\r\n\r\nThe subwords file is not being generated. Am I missing anything?\r\n\r\n### Environment information\r\n\r\nOS: windows 10\r\n\r\n$ pip freeze | grep tensor\r\n1.13.1\r\n\r\n$ python -V\r\n3.7\r\n\r\n### For bugs: reproduction and error logs\r\n# Code:\r\nFile : translate_ecb.py in ECB directory\r\nfrom collections import defaultdict\r\nimport gzip\r\nimport io\r\nimport os\r\nimport random\r\nimport tarfile\r\nfrom tensor2tensor.data_generators import problem\r\nfrom tensor2tensor.data_generators import text_problems\r\nfrom tensor2tensor.data_generators import translate\r\nfrom tensor2tensor.data_generators import translate_ende\r\nfrom tensor2tensor.data_generators import text_encoder\r\nfrom tensor2tensor.data_generators import tokenizer\r\nfrom tensor2tensor.utils import registry\r\nimport tensorflow as tf\r\nimport six.moves.urllib_request as urllib  # Imports urllib on Python2, urllib.request on Python3\r\n\r\n\r\n_ECB_TRAIN_DATASETS = [\r\n        \"http://opus.nlpl.eu/download.php?f=ECB/v1/moses/de-en.txt.zip\",\r\n        (\"de-en.txt/ECB.de-en.en\",\r\n         \"de-en.txt/ECB.de-en.de\")\r\n        ]\r\n@registry.register_problem\r\nclass TranslateEcb(translate.TranslateProblem):\r\n  \r\n  @property\r\n  def approx_vocab_size(self):\r\n    return 2**15  # ~32k\r\n\r\n\r\n  @property\r\n  def dataset_splits(self):\r\n    \"\"\"Splits of data to produce and number of output shards for each.\"\"\"\r\n    # 10% evaluation data\r\n    return [{\r\n        \"split\": problem.DatasetSplit.TRAIN,\r\n        \"shards\": 9,\r\n    }, {\r\n        \"split\": problem.DatasetSplit.EVAL,\r\n        \"shards\": 1,\r\n    }]\r\n\r\n  @property\r\n  def additional_training_datasets(self):\r\n    \"\"\"Allow subclasses to add training datasets.\"\"\"\r\n    return []\r\n\r\n  def source_data_files(self, dataset_split):\r\n    train = dataset_split == problem.DatasetSplit.TRAIN\r\n    train_datasets = _ECB_TRAIN_DATASETS\r\n    print(\"source_data_files\")\r\n    return train_datasets\r\n\r\n\r\nFile : __init__.py\r\nfrom . import translate_ecb\r\n\r\n# Steps to reproduce:\r\nt2t-datagen --t2t_usr_dir=\"ECB\" --data_dir=\"ECB_corpus\" --tmp_dir=\"tmp\\\" --problem=translate_ecb\r\n# Error:\r\n File \"C:\\tensor2tensor\\bin\\t2t_datagen.py\", line 196, in main\r\n    raise ValueError(error_msg)\r\nValueError: You must specify one of the supported problems to generate data for:\r\n\r\nThis error is raised although translate_ecb is in the list of supported problems.\r\n\r\nt2t-trainer --t2t_usr_dir=\"ECB\" --data_dir=\"t2t_data\\ECB\" --output_dir=\"t2t_train\\ECB\" --problem=translate_ecb --model=transformer\r\n# Error logs:\r\nanaconda3\\lib\\site-packages\\tensor2tensor\\data_generators\\text_encoder.py\", line 939, in _load_from_file\r\n    raise ValueError(\"File %s not found\" % filename)\r\nValueError: File \\tensor2tensor\\t2t_data\\ECB\\vocab.translate_ecb.32768.subwords not found\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1612", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1612/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1612/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1612/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1612", "id": 460017488, "node_id": "MDU6SXNzdWU0NjAwMTc0ODg=", "number": 1612, "title": "Logits and Weights Wi", "user": {"login": "Styleoshin", "id": 18513759, "node_id": "MDQ6VXNlcjE4NTEzNzU5", "avatar_url": "https://avatars2.githubusercontent.com/u/18513759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Styleoshin", "html_url": "https://github.com/Styleoshin", "followers_url": "https://api.github.com/users/Styleoshin/followers", "following_url": "https://api.github.com/users/Styleoshin/following{/other_user}", "gists_url": "https://api.github.com/users/Styleoshin/gists{/gist_id}", "starred_url": "https://api.github.com/users/Styleoshin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Styleoshin/subscriptions", "organizations_url": "https://api.github.com/users/Styleoshin/orgs", "repos_url": "https://api.github.com/users/Styleoshin/repos", "events_url": "https://api.github.com/users/Styleoshin/events{/privacy}", "received_events_url": "https://api.github.com/users/Styleoshin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-24T17:49:36Z", "updated_at": "2019-07-18T19:54:46Z", "closed_at": "2019-07-18T19:54:46Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hey, i readed the code source, and i founded somes difficulties to find an anwsers.\r\n1) The weights for the Wik, Wik and Wik matrices. The matrices will be formed before the training of the model or the values \u200b\u200bwill be generated randomly and their formation will be in same time with the training of the model.\r\n2) How this matrices are trained ?\r\n3) During the training of the model (transformer), which loss function is used to determine the probability distributions in the Logits vector ? (cross entropy or kl_divergence)\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1605", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1605/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1605/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1605/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1605", "id": 457497212, "node_id": "MDU6SXNzdWU0NTc0OTcyMTI=", "number": 1605, "title": "[bug] img2img generation: likelihood error for hparams_set advised in ReadMe", "user": {"login": "Vargeel", "id": 7975891, "node_id": "MDQ6VXNlcjc5NzU4OTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/7975891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Vargeel", "html_url": "https://github.com/Vargeel", "followers_url": "https://api.github.com/users/Vargeel/followers", "following_url": "https://api.github.com/users/Vargeel/following{/other_user}", "gists_url": "https://api.github.com/users/Vargeel/gists{/gist_id}", "starred_url": "https://api.github.com/users/Vargeel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Vargeel/subscriptions", "organizations_url": "https://api.github.com/users/Vargeel/orgs", "repos_url": "https://api.github.com/users/Vargeel/repos", "events_url": "https://api.github.com/users/Vargeel/events{/privacy}", "received_events_url": "https://api.github.com/users/Vargeel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-18T13:54:38Z", "updated_at": "2019-06-20T16:48:02Z", "closed_at": "2019-06-20T16:47:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI am not able to run a training job for the img2img transformer example. \r\nI have tested it with hparams_set = \r\n      * img2img_transformer2d_base\r\n      * img2img_transformer2d_tiny\r\n      * img2img_transformer_b1\r\n      * img2img_transformer_base\r\n      * img2img_transformer_tiny\r\n\r\n### Environment information\r\n\r\n\r\nOS: Ubuntu through Docker with image FROM tensorflow/tensorflow:1.13.1-gpu\r\n\r\n```\r\n$ pip freeze | grep tensor\r\n\r\nmesh-tensorflow==0.0.5\r\ntensor2tensor==1.13.4\r\ntensorboard==1.13.1\r\ntensorflow-datasets==1.0.2\r\ntensorflow-estimator==1.13.0\r\ntensorflow-gpu==1.13.1\r\ntensorflow-metadata==0.13.0\r\ntensorflow-probability==0.6.0\r\n```\r\n\r\n```\r\n$ python -V\r\n\r\nPython 2.7.12\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n# Steps to reproduce:\r\n\r\n```\r\nt2t-trainer   --generate_data   --data_dir=~/t2t_data   --output_dir=~/transfo_celeba/first_try   --problem=img2img_celeba   --model=imagetransformer --hparams_set=img2img_transformer2d_tiny   --train_steps=100000  --eval_steps=100\r\n```\r\n\r\n# Error logs:\r\n\r\n```\r\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nINFO:tensorflow:Generating data for img2img_celeba\r\nINFO:tensorflow:Skipping generator because outputs files exists at ['/root/t2t_data/image_celeba-unshuffled-train-00000-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00001-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00002-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00003-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00004-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00005-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00006-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00007-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00008-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00009-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00010-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00011-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00012-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00013-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00014-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00015-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00016-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00017-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00018-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00019-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00020-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00021-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00022-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00023-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00024-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00025-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00026-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00027-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00028-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00029-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00030-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00031-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00032-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00033-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00034-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00035-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00036-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00037-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00038-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00039-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00040-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00041-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00042-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00043-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00044-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00045-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00046-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00047-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00048-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00049-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00050-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00051-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00052-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00053-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00054-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00055-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00056-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00057-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00058-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00059-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00060-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00061-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00062-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00063-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00064-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00065-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00066-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00067-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00068-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00069-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00070-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00071-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00072-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00073-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00074-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00075-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00076-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00077-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00078-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00079-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00080-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00081-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00082-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00083-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00084-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00085-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00086-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00087-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00088-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00089-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00090-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00091-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00092-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00093-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00094-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00095-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00096-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00097-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00098-of-00100', '/root/t2t_data/image_celeba-unshuffled-train-00099-of-00100']\r\nINFO:tensorflow:Skipping generator because outputs files exists at ['/root/t2t_data/image_celeba-unshuffled-dev-00000-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00001-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00002-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00003-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00004-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00005-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00006-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00007-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00008-of-00010', '/root/t2t_data/image_celeba-unshuffled-dev-00009-of-00010']\r\nINFO:tensorflow:Skipping generator because outputs files exists at ['/root/t2t_data/image_celeba-unshuffled-test-00000-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00001-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00002-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00003-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00004-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00005-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00006-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00007-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00008-of-00010', '/root/t2t_data/image_celeba-unshuffled-test-00009-of-00010']\r\nINFO:tensorflow:Skipping shuffle because output files exist\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:240: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nWhen switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\r\nINFO:tensorflow:Configuring DataParallelism to replicate the model.\r\nINFO:tensorflow:schedule=continuous_train_and_eval\r\nINFO:tensorflow:worker_gpu=1\r\nINFO:tensorflow:sync=False\r\nWARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\r\nINFO:tensorflow:datashard_devices: ['gpu:0']\r\nINFO:tensorflow:caching_devices: None\r\nINFO:tensorflow:ps_devices: ['gpu:0']\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4dd88b9ad0>, '_tf_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 1.0\r\n}\r\n, '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 0.95\r\n}\r\nallow_soft_placement: true\r\ngraph_options {\r\n  optimizer_options {\r\n    global_jit_level: OFF\r\n  }\r\n}\r\nisolate_session_state: true\r\n, '_model_dir': '/root/transfo_celeba/first_try', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f4dd88b9b10>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\r\nWARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7f4de2c32230>) includes params argument, but params are not passed to Estimator.\r\nWARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\r\nINFO:tensorflow:Not using Distribute Coordinator.\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nINFO:tensorflow:Reading data files from /root/t2t_data/image_celeba-train*\r\nINFO:tensorflow:partition: 0 num_data_files: 100\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/image_utils.py:94: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse eager execution and: \r\n`tf.data.TFRecordDataset(path)`\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:233: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Setting T2TModel mode to 'train'\r\nINFO:tensorflow:Using variable initializer: uniform_unit_scaling\r\nINFO:tensorflow:Transforming feature 'inputs' with identity_modality.bottom\r\nINFO:tensorflow:Transforming feature 'targets' with identity_modality.targets_bottom\r\nINFO:tensorflow:Building model body\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-trainer\", line 33, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 401, in main\r\n    execute_schedule(exp)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 356, in execute_schedule\r\n    getattr(exp, FLAGS.schedule)()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 401, in continuous_train_and_eval\r\n    self._eval_spec)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\r\n    return self.run_local()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1154, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1414, in wrapping_model_fn\r\n    use_tpu=use_tpu)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py\", line 1477, in estimator_model_fn\r\n    logits, losses_dict = model(features)  # pylint: disable=not-callable\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py\", line 323, in call\r\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py\", line 400, in model_fn_sharded\r\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__\r\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py\", line 427, in model_fn\r\n    body_out = self.body(transformed_features)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/image_transformer.py\", line 50, in body\r\n    if (hparams.likelihood == cia.DistributionType.DMOL and\r\nAttributeError: 'HParams' object has no attribute 'likelihood'\r\n\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1594", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1594/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1594/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1594/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1594", "id": 451107313, "node_id": "MDU6SXNzdWU0NTExMDczMTM=", "number": 1594, "title": "How to restore a trained model and continue training??", "user": {"login": "dreamingo", "id": 1538989, "node_id": "MDQ6VXNlcjE1Mzg5ODk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1538989?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dreamingo", "html_url": "https://github.com/dreamingo", "followers_url": "https://api.github.com/users/dreamingo/followers", "following_url": "https://api.github.com/users/dreamingo/following{/other_user}", "gists_url": "https://api.github.com/users/dreamingo/gists{/gist_id}", "starred_url": "https://api.github.com/users/dreamingo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dreamingo/subscriptions", "organizations_url": "https://api.github.com/users/dreamingo/orgs", "repos_url": "https://api.github.com/users/dreamingo/repos", "events_url": "https://api.github.com/users/dreamingo/events{/privacy}", "received_events_url": "https://api.github.com/users/dreamingo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-01T17:28:33Z", "updated_at": "2019-06-14T02:37:30Z", "closed_at": "2019-06-14T02:37:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nHow to restore from trained model and continue training in tensor2tensor??\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1593", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1593/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1593/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1593/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1593", "id": 450909799, "node_id": "MDU6SXNzdWU0NTA5MDk3OTk=", "number": 1593, "title": "AttributeError: 'NoneType' object has no attribute 'endswith'", "user": {"login": "wensdong", "id": 18463724, "node_id": "MDQ6VXNlcjE4NDYzNzI0", "avatar_url": "https://avatars0.githubusercontent.com/u/18463724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wensdong", "html_url": "https://github.com/wensdong", "followers_url": "https://api.github.com/users/wensdong/followers", "following_url": "https://api.github.com/users/wensdong/following{/other_user}", "gists_url": "https://api.github.com/users/wensdong/gists{/gist_id}", "starred_url": "https://api.github.com/users/wensdong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wensdong/subscriptions", "organizations_url": "https://api.github.com/users/wensdong/orgs", "repos_url": "https://api.github.com/users/wensdong/repos", "events_url": "https://api.github.com/users/wensdong/events{/privacy}", "received_events_url": "https://api.github.com/users/wensdong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-05-31T17:44:10Z", "updated_at": "2019-06-08T09:45:38Z", "closed_at": "2019-06-08T09:45:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nWhen following \"Train a sentiment classifier on a single Cloud TPU\"  \r\nhttps://cloud.google.com/tpu/docs/tutorials/transformer\r\n produce errors.\r\n\r\n\r\n### Environment informationg\r\n\r\ngcp with tpu\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\n\r\n$ python -V\r\n# your output here\r\nOUT_DIR=$STORAGE_BUCKET/training/transformer_sentiment_classifier\r\nwensdongcolab@wensdongcolab:~$ t2t-trainer \\\r\n>   --model=transformer_encoder \\\r\n>   --hparams_set=transformer_tiny_tpu \\\r\n>   --problem=sentiment_imdb \\\r\n>   --train_steps=10 \\\r\n>   --eval_steps=1 \\\r\n>   --data_dir=$DATA_DIR \\\r\n>   --output_dir=$OUT_DIR \\\r\n>   --use_tpu=True \\\r\n>   --cloud_tpu_name=$TPU_NAME\r\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\nIf you depend on functionality not listed there, please file an issue.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-trainer\", line 33, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 397, in main\r\n    exp = exp_fn(create_run_config(hparams), hparams)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 771, in experiment_fn\r\n    return create_experiment(run_config, hparams, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 658, in create_experiment\r\n    add_problem_hparams(hparams, problem_name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/hparams_lib.py\", line 99, in add_problem_hparams\r\n    p_hparams = problem.get_hparams(hparams)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py\", line 520, in get_hparams\r\n    self.get_feature_encoders(data_dir)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py\", line 506, in get_feature_encoders\r\n    self._encoders = self.feature_encoders(data_dir)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/text_problems.py\", line 554, in feature_encoders\r\n    encoder = self.get_or_create_vocab(data_dir, None, force_get=True)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/text_problems.py\", line 242, in get_or_create_vocab\r\n    vocab_filepath = os.path.join(data_dir, self.vocab_filename)\r\n  File \"/usr/lib/python2.7/posixpath.py\", line 70, in join\r\n    elif path == '' or path.endswith('/'):\r\nAttributeError: 'NoneType' object has no attribute 'endswith'\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1591", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1591/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1591/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1591/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1591", "id": 450381411, "node_id": "MDU6SXNzdWU0NTAzODE0MTE=", "number": 1591, "title": "Why add positional embedding instead of concatenate?", "user": {"login": "Akella17", "id": 16236287, "node_id": "MDQ6VXNlcjE2MjM2Mjg3", "avatar_url": "https://avatars3.githubusercontent.com/u/16236287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Akella17", "html_url": "https://github.com/Akella17", "followers_url": "https://api.github.com/users/Akella17/followers", "following_url": "https://api.github.com/users/Akella17/following{/other_user}", "gists_url": "https://api.github.com/users/Akella17/gists{/gist_id}", "starred_url": "https://api.github.com/users/Akella17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Akella17/subscriptions", "organizations_url": "https://api.github.com/users/Akella17/orgs", "repos_url": "https://api.github.com/users/Akella17/repos", "events_url": "https://api.github.com/users/Akella17/events{/privacy}", "received_events_url": "https://api.github.com/users/Akella17/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-05-30T16:03:02Z", "updated_at": "2020-05-28T01:08:45Z", "closed_at": "2019-06-09T20:09:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Apart from saving some memory, is there any reason we are adding the positional embeddings instead of concatenating them. It seems more intuitive concatenate useful input features, instead of adding them.\r\n\r\nFrom another perspective, how can we be sure that the Transformer network can separate the densely informative word embeddings and the position information of pos encoding?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1584", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1584/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1584/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1584/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1584", "id": 448019284, "node_id": "MDU6SXNzdWU0NDgwMTkyODQ=", "number": 1584, "title": "Error running decoder | pos=None,self_attention_type=dot_product_relative", "user": {"login": "mehmedes", "id": 21199186, "node_id": "MDQ6VXNlcjIxMTk5MTg2", "avatar_url": "https://avatars0.githubusercontent.com/u/21199186?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mehmedes", "html_url": "https://github.com/mehmedes", "followers_url": "https://api.github.com/users/mehmedes/followers", "following_url": "https://api.github.com/users/mehmedes/following{/other_user}", "gists_url": "https://api.github.com/users/mehmedes/gists{/gist_id}", "starred_url": "https://api.github.com/users/mehmedes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mehmedes/subscriptions", "organizations_url": "https://api.github.com/users/mehmedes/orgs", "repos_url": "https://api.github.com/users/mehmedes/repos", "events_url": "https://api.github.com/users/mehmedes/events{/privacy}", "received_events_url": "https://api.github.com/users/mehmedes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-05-24T07:28:06Z", "updated_at": "2019-11-27T02:02:40Z", "closed_at": "2019-05-24T09:19:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\nWhen running decoder with a model trained with ``` hparams.pos = None, \r\nhparams.self_attention_type = \"dot_product_relative\" ``` , the following error occurs:\r\n\r\n```ValueError: Cannot use 'transformer/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention_relative/attention' as input to 'Merge/MergeSummary' because 'transformer/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/dot_product_attention_relative/attention' is in a while loop.```\r\n\r\ntensor2tensor==1.13.4\r\ntensorflow-estimator==1.13.0\r\ntensorflow-gpu==1.13.1\r\n\r\nPython 2.7.15rc1\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1573", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1573/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1573/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1573/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1573", "id": 444954667, "node_id": "MDU6SXNzdWU0NDQ5NTQ2Njc=", "number": 1573, "title": "Error in speech recognition training", "user": {"login": "manuel3265", "id": 39747299, "node_id": "MDQ6VXNlcjM5NzQ3Mjk5", "avatar_url": "https://avatars1.githubusercontent.com/u/39747299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manuel3265", "html_url": "https://github.com/manuel3265", "followers_url": "https://api.github.com/users/manuel3265/followers", "following_url": "https://api.github.com/users/manuel3265/following{/other_user}", "gists_url": "https://api.github.com/users/manuel3265/gists{/gist_id}", "starred_url": "https://api.github.com/users/manuel3265/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manuel3265/subscriptions", "organizations_url": "https://api.github.com/users/manuel3265/orgs", "repos_url": "https://api.github.com/users/manuel3265/repos", "events_url": "https://api.github.com/users/manuel3265/events{/privacy}", "received_events_url": "https://api.github.com/users/manuel3265/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-16T13:25:03Z", "updated_at": "2020-03-26T03:25:55Z", "closed_at": "2020-02-17T16:16:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI do not know why this error occurs.\r\n\r\nTypeError: __init__() got an unexpected keyword argument 'experimental_export_device_assignment'\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.5\r\ntensor2tensor==1.13.4\r\ntensorboard==1.12.0\r\ntensorflow==1.13.1\r\ntensorflow-datasets==1.0.2\r\ntensorflow-estimator==1.13.0\r\ntensorflow-metadata==0.13.0\r\ntensorflow-probability==0.6.0\r\ntensorflow-serving-api==1.12.0\r\n\r\n$ python -V\r\nPython 3.5.3\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\nt2t-trainer --model=transformer --hparams_set=transformer_librispeech_tpu --problem=librispeech --train_steps=210000 --eval_steps=3 --local_eval_frequency=100 --data_dir=$DATA --output_\r\ndir=$OUT --use_tpu --cloud_tpu_name=$TPU_NAME \r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\nIf you depend on functionality not listed there, please file an issue.\r\nINFO:tensorflow:Importing user module manuel_garcia02 from path /home\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-trainer\", line 33, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 398, in main\r\n    exp = exp_fn(create_run_config(hparams), hparams)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 774, in experiment_fn\r\n    return create_experiment(run_config, hparams, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 672, in create_experiment\r\n    use_xla=use_xla)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 318, in create_estimator\r\n    experimental_export_device_assignment=True)\r\nTypeError: __init__() got an unexpected keyword argument 'experimental_export_device_assignment'\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1572", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1572/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1572/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1572/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1572", "id": 444781581, "node_id": "MDU6SXNzdWU0NDQ3ODE1ODE=", "number": 1572, "title": "ValueError: Empty generated field.", "user": {"login": "manuel3265", "id": 39747299, "node_id": "MDQ6VXNlcjM5NzQ3Mjk5", "avatar_url": "https://avatars1.githubusercontent.com/u/39747299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manuel3265", "html_url": "https://github.com/manuel3265", "followers_url": "https://api.github.com/users/manuel3265/followers", "following_url": "https://api.github.com/users/manuel3265/following{/other_user}", "gists_url": "https://api.github.com/users/manuel3265/gists{/gist_id}", "starred_url": "https://api.github.com/users/manuel3265/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manuel3265/subscriptions", "organizations_url": "https://api.github.com/users/manuel3265/orgs", "repos_url": "https://api.github.com/users/manuel3265/repos", "events_url": "https://api.github.com/users/manuel3265/events{/privacy}", "received_events_url": "https://api.github.com/users/manuel3265/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-05-16T06:47:06Z", "updated_at": "2020-02-17T16:16:30Z", "closed_at": "2020-02-17T16:16:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI'M TRYING to generate the data to train my model, I do not know why this error happens\r\n\r\nExample 1:  (Right)\r\n'waveforms'=<class 'list'>: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0518509447574615e-05, 0.0, 0.0, 0.0, -3.0518509447574615e-05, 3.0518509447574615e-05, 3.0518509447574615e-05, 3.0518509447574615e-05, 0.0, 0.0, -3.0518509447574615e-05, 0.0, 0.0, 0.0, 3.0518509447574615e-05, 3.0518509447574615e-05, 0.0, -3.0518509447574615e-05, -3.0518509447574615e-05, -6.103701889514923e-05, -3.0518509447574615e-05, 0.0, 3.0518509447574615e-05, 3.0518509447574615e-05, 3.0518509447574615e-05, 0.0, 0.0, -3.0518509447574615e-05, 0.0, 0.0, -3.0518509447574615e-05, 6.103701889514923e-05, 6.103701889514923e-05, 3.0518509447574615e-05, 0.0...\r\n'waveform_lens' =<class 'list'>: [7680]\r\n'targets' = <class 'list'>: [112, 113, 46, 34, 112, 113, 34, 115, 119, 107, 103, 116, 113, 34, 114, 99, 105, 99, 116, 1]\r\n'raw_transcript'=<class 'list'>: ['no, no quiero pagar']\r\n\r\nWith error:\r\n[]\r\n\r\nI'm not sure why it occurs. Does the size of the audio have something to do with it?\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.5\r\ntensor2tensorM==2.0.0\r\ntensorboard==1.13.1\r\ntensorflow==1.13.1\r\ntensorflow-estimator==1.13.0\r\ntensorflow-hub==0.4.0\r\ntensorflow-metadata==0.13.0\r\ntensorflow-probability==0.6.0\r\ntensorflow-serving-api==1.13.0\r\n\r\n\r\n$ python -V\r\nPython 3.7.3\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\nTraceback (most recent call last):\r\n  File \"/home/manuel/Downloads/Manuel_/apisl/tensor2tensor/tensor2tensor/bin/t2t_datagen.py\", line 311, in <module>\r\n    tf.app.run()\r\n  File \"/home/manuel/Downloads/Manuel_/apisl/tensor2tensor/venv/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/manuel/Downloads/Manuel_/apisl/tensor2tensor/tensor2tensor/bin/t2t_datagen.py\", line 221, in main\r\n    generate_data_for_registered_problem(problem)\r\n  File \"/home/manuel/Downloads/Manuel_/apisl/tensor2tensor/tensor2tensor/bin/t2t_datagen.py\", line 306, in generate_data_for_registered_problem\r\n    problem.generate_data(data_dir, tmp_dir, task_id)\r\n  File \"/home/manuel/Downloads/Manuel_/apisl/tensor2tensor/tensor2tensor/data_generators/deepspeech.py\", line 163, in generate_data\r\n    self.generator(data_dir, tmp_dir, self.TEST_DATASETS), test_paths)\r\n  File \"/home/manuel/Downloads/Manuel_/apisl/tensor2tensor/tensor2tensor/data_generators/generator_utils.py\", line 177, in generate_files\r\n    example = to_example(case)\r\n  File \"/home/manuel/Downloads/Manuel_/apisl/tensor2tensor/tensor2tensor/data_generators/generator_utils.py\", line 49, in to_example\r\n    raise ValueError(\"Empty generated field: %s\" % str((k, v)))\r\nValueError: Empty generated field: ('waveforms', [])\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1571", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1571/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1571/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1571/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1571", "id": 444672696, "node_id": "MDU6SXNzdWU0NDQ2NzI2OTY=", "number": 1571, "title": "FileNotFoundError: [Errno 2] No such file or directory: 'sox': 'sox'", "user": {"login": "Victor-Almeida", "id": 41767440, "node_id": "MDQ6VXNlcjQxNzY3NDQw", "avatar_url": "https://avatars0.githubusercontent.com/u/41767440?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Victor-Almeida", "html_url": "https://github.com/Victor-Almeida", "followers_url": "https://api.github.com/users/Victor-Almeida/followers", "following_url": "https://api.github.com/users/Victor-Almeida/following{/other_user}", "gists_url": "https://api.github.com/users/Victor-Almeida/gists{/gist_id}", "starred_url": "https://api.github.com/users/Victor-Almeida/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Victor-Almeida/subscriptions", "organizations_url": "https://api.github.com/users/Victor-Almeida/orgs", "repos_url": "https://api.github.com/users/Victor-Almeida/repos", "events_url": "https://api.github.com/users/Victor-Almeida/events{/privacy}", "received_events_url": "https://api.github.com/users/Victor-Almeida/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-15T22:26:00Z", "updated_at": "2020-07-22T09:07:43Z", "closed_at": "2019-08-21T02:15:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nWhen I try to run the librispeech problem on Google Colab I get the following error : \r\n```\r\nFileNotFoundError                         Traceback (most recent call last)\r\n\r\n<ipython-input-26-445f84cca4ca> in <module>()\r\n      1 t2t_problem = problems.problem(PROBLEM)\r\n----> 2 t2t_problem.generate_data(DATA_DIR, TMP_DIR)\r\n\r\n6 frames\r\n\r\n/usr/lib/python3.6/subprocess.py in _execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\r\n   1342                         if errno_num == errno.ENOENT:\r\n   1343                             err_msg += ': ' + repr(err_filename)\r\n-> 1344                     raise child_exception_type(errno_num, err_msg, err_filename)\r\n   1345                 raise child_exception_type(err_msg)\r\n   1346 \r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: 'sox': 'sox'\r\n```\r\n\r\nHere's the code : \r\n```\r\nfrom tensor2tensor.utils import registry\r\nfrom tensor2tensor import models\r\nfrom tensor2tensor import problems\r\n\r\nfrom google.colab import drive\r\ndrive.mount('/content/gdrive')\r\n\r\nPROBLEM = 'librispeech_clean'\r\nTMP_DIR = '/content/gdrive/My Drive/T2T tests/tmp_dir/' # Where data files from internet stored\r\nDATA_DIR = '/content/gdrive/My Drive/T2T tests/data_dir/' # Where pre-prcessed data is stored\r\nt2t_problem = problems.problem(PROBLEM)\r\nt2t_problem.generate_data(DATA_DIR, TMP_DIR) \r\n```\r\n\r\nThe error message is the same for both Python 2 and Python 3.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1569", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1569/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1569/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1569/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1569", "id": 443801934, "node_id": "MDU6SXNzdWU0NDM4MDE5MzQ=", "number": 1569, "title": "[BUG] Significant slowdown in 1.13.4", "user": {"login": "mehmedes", "id": 21199186, "node_id": "MDQ6VXNlcjIxMTk5MTg2", "avatar_url": "https://avatars0.githubusercontent.com/u/21199186?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mehmedes", "html_url": "https://github.com/mehmedes", "followers_url": "https://api.github.com/users/mehmedes/followers", "following_url": "https://api.github.com/users/mehmedes/following{/other_user}", "gists_url": "https://api.github.com/users/mehmedes/gists{/gist_id}", "starred_url": "https://api.github.com/users/mehmedes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mehmedes/subscriptions", "organizations_url": "https://api.github.com/users/mehmedes/orgs", "repos_url": "https://api.github.com/users/mehmedes/repos", "events_url": "https://api.github.com/users/mehmedes/events{/privacy}", "received_events_url": "https://api.github.com/users/mehmedes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-14T09:16:33Z", "updated_at": "2019-05-14T10:35:52Z", "closed_at": "2019-05-14T10:35:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "In 1.13.2 training speed ```for transformer_base``` was ```global_step/sec: ~7``` with ```batch_size=4096```.\r\nIn 1.13.4 trainind speed decreased to ```global_step/sec: ~1``` with same batch size.\r\nMoreover, buffer filling takes longer and mixed precision will always return NaN\r\n\r\nTested on V100, CUDA10, Nvidia Driver 410.48, Tensorflow 1.13.1.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1568", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1568/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1568/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1568/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1568", "id": 443304924, "node_id": "MDU6SXNzdWU0NDMzMDQ5MjQ=", "number": 1568, "title": "Unable to use custom problem for visualizing attention", "user": {"login": "chrismostert", "id": 15890652, "node_id": "MDQ6VXNlcjE1ODkwNjUy", "avatar_url": "https://avatars3.githubusercontent.com/u/15890652?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chrismostert", "html_url": "https://github.com/chrismostert", "followers_url": "https://api.github.com/users/chrismostert/followers", "following_url": "https://api.github.com/users/chrismostert/following{/other_user}", "gists_url": "https://api.github.com/users/chrismostert/gists{/gist_id}", "starred_url": "https://api.github.com/users/chrismostert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chrismostert/subscriptions", "organizations_url": "https://api.github.com/users/chrismostert/orgs", "repos_url": "https://api.github.com/users/chrismostert/repos", "events_url": "https://api.github.com/users/chrismostert/events{/privacy}", "received_events_url": "https://api.github.com/users/chrismostert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-13T09:49:12Z", "updated_at": "2019-06-26T16:06:13Z", "closed_at": "2019-05-13T11:22:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to run the code in the TransformerVisualization.ipynb notebook to visualize the attention on a user defined problem, however I am unable to do so. When running the following code\r\n\r\n```\r\nusr_dir.import_usr_dir('./transformer')\r\nvisualizer = visualization.AttentionVisualizer(hparams_set, model_name, data_dir, problem_name, beam_size=1)\r\n```\r\n\r\nI get the following error\r\n\r\n```\r\nINFO:tensorflow:Importing user module transformer from path /content/Deep-Learning\r\n---------------------------------------------------------------------------\r\nLookupError                               Traceback (most recent call last)\r\n<ipython-input-20-fd5211124aa0> in <module>()\r\n      1 usr_dir.import_usr_dir('./transformer')\r\n----> 2 visualizer = visualization.AttentionVisualizer(hparams_set, model_name, data_dir, problem_name, beam_size=1)\r\n\r\n4 frames\r\n/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/registry.py in problem(name)\r\n    256                   ] + all_problem_names\r\n    257     error_msg = \"\\n  * \".join(error_lines)\r\n--> 258     raise LookupError(error_msg)\r\n    259   return _PROBLEMS[base_name](was_reversed=was_reversed, was_copy=was_copy)\r\n    260 \r\n\r\nLookupError: code_transformer not in the set of supported problems:\r\n  * algorithmic_addition_binary40\r\n  * algorithmic_addition_decimal40\r\n  * algorithmic_cipher_shift200\r\n  * algorithmic_cipher_shift5\r\n  * algorithmic_cipher_vigenere200\r\n  * algorithmic_cipher_vigenere5\r\n  * algorithmic_identity_binary40\r\n  * algorithmic_identity_decimal40\r\n  * algorithmic_multiplication_binary40\r\n  * algorithmic_multiplication_decimal40\r\n  * algorithmic_reverse_binary40\r\n  * algorithmic_reverse_binary40_test\r\n  * algorithmic_reverse_decimal40\r\n  * algorithmic_reverse_nlplike32k\r\n  * algorithmic_reverse_nlplike8k\r\n  * algorithmic_shift_decimal40\r\n  * algorithmic_sort_problem\r\n  * audio_timit_characters_tune\r\n  * audio_timit_tokens8k_test\r\n  * audio_timit_tokens8k_tune\r\n  * babi_qa_concat_all_tasks_10k\r\n  * babi_qa_concat_all_tasks_1k\r\n  * babi_qa_concat_task10_10k\r\n  * babi_qa_concat_task10_1k\r\n  * babi_qa_concat_task11_10k\r\n  * babi_qa_concat_task11_1k\r\n  * babi_qa_concat_task12_10k\r\n  * babi_qa_concat_task12_1k\r\n  * babi_qa_concat_task13_10k\r\n  * babi_qa_concat_task13_1k\r\n  * babi_qa_concat_task14_10k\r\n  * babi_qa_concat_task14_1k\r\n  * babi_qa_concat_task15_10k\r\n  * babi_qa_concat_task15_1k\r\n  * babi_qa_concat_task16_10k\r\n  * babi_qa_concat_task16_1k\r\n  * babi_qa_concat_task17_10k\r\n  * babi_qa_concat_task17_1k\r\n  * babi_qa_concat_task18_10k\r\n  * babi_qa_concat_task18_1k\r\n  * babi_qa_concat_task19_10k\r\n  * babi_qa_concat_task19_1k\r\n  * babi_qa_concat_task1_10k\r\n  * babi_qa_concat_task1_1k\r\n  * babi_qa_concat_task20_10k\r\n  * babi_qa_concat_task20_1k\r\n  * babi_qa_concat_task2_10k\r\n  * babi_qa_concat_task2_1k\r\n  * babi_qa_concat_task3_10k\r\n  * babi_qa_concat_task3_1k\r\n  * babi_qa_concat_task4_10k\r\n  * babi_qa_concat_task4_1k\r\n  * babi_qa_concat_task5_10k\r\n  * babi_qa_concat_task5_1k\r\n  * babi_qa_concat_task6_10k\r\n  * babi_qa_concat_task6_1k\r\n  * babi_qa_concat_task7_10k\r\n  * babi_qa_concat_task7_1k\r\n  * babi_qa_concat_task8_10k\r\n  * babi_qa_concat_task8_1k\r\n  * babi_qa_concat_task9_10k\r\n  * babi_qa_concat_task9_1k\r\n  * cola\r\n  * cola_characters\r\n  * common_voice\r\n  * common_voice_clean\r\n  * common_voice_noisy\r\n  * common_voice_train_full_test_clean\r\n  * genomics_expression_cage10\r\n  * genomics_expression_gm12878\r\n  * genomics_expression_l262k\r\n  * github_function_docstring\r\n  * gym_air_raid-v0_random\r\n  * gym_air_raid-v4_random\r\n  * gym_air_raid_deterministic-v0_random\r\n  * gym_air_raid_deterministic-v4_random\r\n  * gym_air_raid_no_frameskip-v0_random\r\n  * gym_air_raid_no_frameskip-v4_random\r\n  * gym_alien-v0_random\r\n  * gym_alien-v4_random\r\n  * gym_alien_deterministic-v0_random\r\n  * gym_alien_deterministic-v4_random\r\n  * gym_alien_no_frameskip-v0_random\r\n  * gym_alien_no_frameskip-v4_random\r\n  * gym_amidar-v0_random\r\n  * gym_amidar-v4_random\r\n  * gym_amidar_deterministic-v0_random\r\n  * gym_amidar_deterministic-v4_random\r\n  * gym_amidar_no_frameskip-v0_random\r\n  * gym_amidar_no_frameskip-v4_random\r\n  * gym_assault-v0_random\r\n  * gym_assault-v4_random\r\n  * gym_assault_deterministic-v0_random\r\n  * gym_assault_deterministic-v4_random\r\n  * gym_assault_no_frameskip-v0_random\r\n  * gym_assault_no_frameskip-v4_random\r\n  * gym_asterix-v0_random\r\n  * gym_asterix-v4_random\r\n  * gym_asterix_deterministic-v0_random\r\n  * gym_asterix_deterministic-v4_random\r\n  * gym_asterix_no_frameskip-v0_random\r\n  * gym_asterix_no_frameskip-v4_random\r\n  * gym_asteroids-v0_random\r\n  * gym_asteroids-v4_random\r\n  * gym_asteroids_deterministic-v0_random\r\n  * gym_asteroids_deterministic-v4_random\r\n  * gym_asteroids_no_frameskip-v0_random\r\n  * gym_asteroids_no_frameskip-v4_random\r\n  * gym_atlantis-v0_random\r\n  * gym_atlantis-v4_random\r\n  * gym_atlantis_deterministic-v0_random\r\n  * gym_atlantis_deterministic-v4_random\r\n  * gym_atlantis_no_frameskip-v0_random\r\n  * gym_atlantis_no_frameskip-v4_random\r\n  * gym_bank_heist-v0_random\r\n  * gym_bank_heist-v4_random\r\n  * gym_bank_heist_deterministic-v0_random\r\n  * gym_bank_heist_deterministic-v4_random\r\n  * gym_bank_heist_no_frameskip-v0_random\r\n  * gym_bank_heist_no_frameskip-v4_random\r\n  * gym_battle_zone-v0_random\r\n  * gym_battle_zone-v4_random\r\n  * gym_battle_zone_deterministic-v0_random\r\n  * gym_battle_zone_deterministic-v4_random\r\n  * gym_battle_zone_no_frameskip-v0_random\r\n  * gym_battle_zone_no_frameskip-v4_random\r\n  * gym_beam_rider-v0_random\r\n  * gym_beam_rider-v4_random\r\n  * gym_beam_rider_deterministic-v0_random\r\n  * gym_beam_rider_deterministic-v4_random\r\n  * gym_beam_rider_no_frameskip-v0_random\r\n  * gym_beam_rider_no_frameskip-v4_random\r\n  * gym_berzerk-v0_random\r\n  * gym_berzerk-v4_random\r\n  * gym_berzerk_deterministic-v0_random\r\n  * gym_berzerk_deterministic-v4_random\r\n  * gym_berzerk_no_frameskip-v0_random\r\n  * gym_berzerk_no_frameskip-v4_random\r\n  * gym_bowling-v0_random\r\n  * gym_bowling-v4_random\r\n  * gym_bowling_deterministic-v0_random\r\n  * gym_bowling_deterministic-v4_random\r\n  * gym_bowling_no_frameskip-v0_random\r\n  * gym_bowling_no_frameskip-v4_random\r\n  * gym_boxing-v0_random\r\n  * gym_boxing-v4_random\r\n  * gym_boxing_deterministic-v0_random\r\n  * gym_boxing_deterministic-v4_random\r\n  * gym_boxing_no_frameskip-v0_random\r\n  * gym_boxing_no_frameskip-v4_random\r\n  * gym_breakout-v0_random\r\n  * gym_breakout-v4_random\r\n  * gym_breakout_deterministic-v0_random\r\n  * gym_breakout_deterministic-v4_random\r\n  * gym_breakout_no_frameskip-v0_random\r\n  * gym_breakout_no_frameskip-v4_random\r\n  * gym_carnival-v0_random\r\n  * gym_carnival-v4_random\r\n  * gym_carnival_deterministic-v0_random\r\n  * gym_carnival_deterministic-v4_random\r\n  * gym_carnival_no_frameskip-v0_random\r\n  * gym_carnival_no_frameskip-v4_random\r\n  * gym_centipede-v0_random\r\n  * gym_centipede-v4_random\r\n  * gym_centipede_deterministic-v0_random\r\n  * gym_centipede_deterministic-v4_random\r\n  * gym_centipede_no_frameskip-v0_random\r\n  * gym_centipede_no_frameskip-v4_random\r\n  * gym_chopper_command-v0_random\r\n  * gym_chopper_command-v4_random\r\n  * gym_chopper_command_deterministic-v0_random\r\n  * gym_chopper_command_deterministic-v4_random\r\n  * gym_chopper_command_no_frameskip-v0_random\r\n  * gym_chopper_command_no_frameskip-v4_random\r\n  * gym_crazy_climber-v0_random\r\n  * gym_crazy_climber-v4_random\r\n  * gym_crazy_climber_deterministic-v0_random\r\n  * gym_crazy_climber_deterministic-v4_random\r\n  * gym_crazy_climber_no_frameskip-v0_random\r\n  * gym_crazy_climber_no_frameskip-v4_random\r\n  * gym_demon_attack-v0_random\r\n  * gym_demon_attack-v4_random\r\n  * gym_demon_attack_deterministic-v0_random\r\n  * gym_demon_attack_deterministic-v4_random\r\n  * gym_demon_attack_no_frameskip-v0_random\r\n  * gym_demon_attack_no_frameskip-v4_random\r\n  * gym_double_dunk-v0_random\r\n  * gym_double_dunk-v4_random\r\n  * gym_double_dunk_deterministic-v0_random\r\n  * gym_double_dunk_deterministic-v4_random\r\n  * gym_double_dunk_no_frameskip-v0_random\r\n  * gym_double_dunk_no_frameskip-v4_random\r\n  * gym_elevator_action-v0_random\r\n  * gym_elevator_action-v4_random\r\n  * gym_elevator_action_deterministic-v0_random\r\n  * gym_elevator_action_deterministic-v4_random\r\n  * gym_elevator_action_no_frameskip-v0_random\r\n  * gym_elevator_action_no_frameskip-v4_random\r\n  * gym_enduro-v0_random\r\n  * gym_enduro-v4_random\r\n  * gym_enduro_deterministic-v0_random\r\n  * gym_enduro_deterministic-v4_random\r\n  * gym_enduro_no_frameskip-v0_random\r\n  * gym_enduro_no_frameskip-v4_random\r\n  * gym_fishing_derby-v0_random\r\n  * gym_fishing_derby-v4_random\r\n  * gym_fishing_derby_deterministic-v0_random\r\n  * gym_fishing_derby_deterministic-v4_random\r\n  * gym_fishing_derby_no_frameskip-v0_random\r\n  * gym_fishing_derby_no_frameskip-v4_random\r\n  * gym_freeway-v0_random\r\n  * gym_freeway-v4_random\r\n  * gym_freeway_deterministic-v0_random\r\n  * gym_freeway_deterministic-v4_random\r\n  * gym_freeway_no_frameskip-v0_random\r\n  * gym_freeway_no_frameskip-v4_random\r\n  * gym_frostbite-v0_random\r\n  * gym_frostbite-v4_random\r\n  * gym_frostbite_deterministic-v0_random\r\n  * gym_frostbite_deterministic-v4_random\r\n  * gym_frostbite_no_frameskip-v0_random\r\n  * gym_frostbite_no_frameskip-v4_random\r\n  * gym_gopher-v0_random\r\n  * gym_gopher-v4_random\r\n  * gym_gopher_deterministic-v0_random\r\n  * gym_gopher_deterministic-v4_random\r\n  * gym_gopher_no_frameskip-v0_random\r\n  * gym_gopher_no_frameskip-v4_random\r\n  * gym_gravitar-v0_random\r\n  * gym_gravitar-v4_random\r\n  * gym_gravitar_deterministic-v0_random\r\n  * gym_gravitar_deterministic-v4_random\r\n  * gym_gravitar_no_frameskip-v0_random\r\n  * gym_gravitar_no_frameskip-v4_random\r\n  * gym_hero-v0_random\r\n  * gym_hero-v4_random\r\n  * gym_hero_deterministic-v0_random\r\n  * gym_hero_deterministic-v4_random\r\n  * gym_hero_no_frameskip-v0_random\r\n  * gym_hero_no_frameskip-v4_random\r\n  * gym_ice_hockey-v0_random\r\n  * gym_ice_hockey-v4_random\r\n  * gym_ice_hockey_deterministic-v0_random\r\n  * gym_ice_hockey_deterministic-v4_random\r\n  * gym_ice_hockey_no_frameskip-v0_random\r\n  * gym_ice_hockey_no_frameskip-v4_random\r\n  * gym_jamesbond-v0_random\r\n  * gym_jamesbond-v4_random\r\n  * gym_jamesbond_deterministic-v0_random\r\n  * gym_jamesbond_deterministic-v4_random\r\n  * gym_jamesbond_no_frameskip-v0_random\r\n  * gym_jamesbond_no_frameskip-v4_random\r\n  * gym_journey_escape-v0_random\r\n  * gym_journey_escape-v4_random\r\n  * gym_journey_escape_deterministic-v0_random\r\n  * gym_journey_escape_deterministic-v4_random\r\n  * gym_journey_escape_no_frameskip-v0_random\r\n  * gym_journey_escape_no_frameskip-v4_random\r\n  * gym_kangaroo-v0_random\r\n  * gym_kangaroo-v4_random\r\n  * gym_kangaroo_deterministic-v0_random\r\n  * gym_kangaroo_deterministic-v4_random\r\n  * gym_kangaroo_no_frameskip-v0_random\r\n  * gym_kangaroo_no_frameskip-v4_random\r\n  * gym_krull-v0_random\r\n  * gym_krull-v4_random\r\n  * gym_krull_deterministic-v0_random\r\n  * gym_krull_deterministic-v4_random\r\n  * gym_krull_no_frameskip-v0_random\r\n  * gym_krull_no_frameskip-v4_random\r\n  * gym_kung_fu_master-v0_random\r\n  * gym_kung_fu_master-v4_random\r\n  * gym_kung_fu_master_deterministic-v0_random\r\n  * gym_kung_fu_master_deterministic-v4_random\r\n  * gym_kung_fu_master_no_frameskip-v0_random\r\n  * gym_kung_fu_master_no_frameskip-v4_random\r\n  * gym_montezuma_revenge-v0_random\r\n  * gym_montezuma_revenge-v4_random\r\n  * gym_montezuma_revenge_deterministic-v0_random\r\n  * gym_montezuma_revenge_deterministic-v4_random\r\n  * gym_montezuma_revenge_no_frameskip-v0_random\r\n  * gym_montezuma_revenge_no_frameskip-v4_random\r\n  * gym_ms_pacman-v0_random\r\n  * gym_ms_pacman-v4_random\r\n  * gym_ms_pacman_deterministic-v0_random\r\n  * gym_ms_pacman_deterministic-v4_random\r\n  * gym_ms_pacman_no_frameskip-v0_random\r\n  * gym_ms_pacman_no_frameskip-v4_random\r\n  * gym_name_this_game-v0_random\r\n  * gym_name_this_game-v4_random\r\n  * gym_name_this_game_deterministic-v0_random\r\n  * gym_name_this_game_deterministic-v4_random\r\n  * gym_name_this_game_no_frameskip-v0_random\r\n  * gym_name_this_game_no_frameskip-v4_random\r\n  * gym_phoenix-v0_random\r\n  * gym_phoenix-v4_random\r\n  * gym_phoenix_deterministic-v0_random\r\n  * gym_phoenix_deterministic-v4_random\r\n  * gym_phoenix_no_frameskip-v0_random\r\n  * gym_phoenix_no_frameskip-v4_random\r\n  * gym_pitfall-v0_random\r\n  * gym_pitfall-v4_random\r\n  * gym_pitfall_deterministic-v0_random\r\n  * gym_pitfall_deterministic-v4_random\r\n  * gym_pitfall_no_frameskip-v0_random\r\n  * gym_pitfall_no_frameskip-v4_random\r\n  * gym_pong-v0_random\r\n  * gym_pong-v4_random\r\n  * gym_pong_deterministic-v0_random\r\n  * gym_pong_deterministic-v4_random\r\n  * gym_pong_no_frameskip-v0_random\r\n  * gym_pong_no_frameskip-v4_random\r\n  * gym_pooyan-v0_random\r\n  * gym_pooyan-v4_random\r\n  * gym_pooyan_deterministic-v0_random\r\n  * gym_pooyan_deterministic-v4_random\r\n  * gym_pooyan_no_frameskip-v0_random\r\n  * gym_pooyan_no_frameskip-v4_random\r\n  * gym_private_eye-v0_random\r\n  * gym_private_eye-v4_random\r\n  * gym_private_eye_deterministic-v0_random\r\n  * gym_private_eye_deterministic-v4_random\r\n  * gym_private_eye_no_frameskip-v0_random\r\n  * gym_private_eye_no_frameskip-v4_random\r\n  * gym_qbert-v0_random\r\n  * gym_qbert-v4_random\r\n  * gym_qbert_deterministic-v0_random\r\n  * gym_qbert_deterministic-v4_random\r\n  * gym_qbert_no_frameskip-v0_random\r\n  * gym_qbert_no_frameskip-v4_random\r\n  * gym_riverraid-v0_random\r\n  * gym_riverraid-v4_random\r\n  * gym_riverraid_deterministic-v0_random\r\n  * gym_riverraid_deterministic-v4_random\r\n  * gym_riverraid_no_frameskip-v0_random\r\n  * gym_riverraid_no_frameskip-v4_random\r\n  * gym_road_runner-v0_random\r\n  * gym_road_runner-v4_random\r\n  * gym_road_runner_deterministic-v0_random\r\n  * gym_road_runner_deterministic-v4_random\r\n  * gym_road_runner_no_frameskip-v0_random\r\n  * gym_road_runner_no_frameskip-v4_random\r\n  * gym_robotank-v0_random\r\n  * gym_robotank-v4_random\r\n  * gym_robotank_deterministic-v0_random\r\n  * gym_robotank_deterministic-v4_random\r\n  * gym_robotank_no_frameskip-v0_random\r\n  * gym_robotank_no_frameskip-v4_random\r\n  * gym_seaquest-v0_random\r\n  * gym_seaquest-v4_random\r\n  * gym_seaquest_deterministic-v0_random\r\n  * gym_seaquest_deterministic-v4_random\r\n  * gym_seaquest_no_frameskip-v0_random\r\n  * gym_seaquest_no_frameskip-v4_random\r\n  * gym_skiing-v0_random\r\n  * gym_skiing-v4_random\r\n  * gym_skiing_deterministic-v0_random\r\n  * gym_skiing_deterministic-v4_random\r\n  * gym_skiing_no_frameskip-v0_random\r\n  * gym_skiing_no_frameskip-v4_random\r\n  * gym_solaris-v0_random\r\n  * gym_solaris-v4_random\r\n  * gym_solaris_deterministic-v0_random\r\n  * gym_solaris_deterministic-v4_random\r\n  * gym_solaris_no_frameskip-v0_random\r\n  * gym_solaris_no_frameskip-v4_random\r\n  * gym_space_invaders-v0_random\r\n  * gym_space_invaders-v4_random\r\n  * gym_space_invaders_deterministic-v0_random\r\n  * gym_space_invaders_deterministic-v4_random\r\n  * gym_space_invaders_no_frameskip-v0_random\r\n  * gym_space_invaders_no_frameskip-v4_random\r\n  * gym_star_gunner-v0_random\r\n  * gym_star_gunner-v4_random\r\n  * gym_star_gunner_deterministic-v0_random\r\n  * gym_star_gunner_deterministic-v4_random\r\n  * gym_star_gunner_no_frameskip-v0_random\r\n  * gym_star_gunner_no_frameskip-v4_random\r\n  * gym_tennis-v0_random\r\n  * gym_tennis-v4_random\r\n  * gym_tennis_deterministic-v0_random\r\n  * gym_tennis_deterministic-v4_random\r\n  * gym_tennis_no_frameskip-v0_random\r\n  * gym_tennis_no_frameskip-v4_random\r\n  * gym_time_pilot-v0_random\r\n  * gym_time_pilot-v4_random\r\n  * gym_time_pilot_deterministic-v0_random\r\n  * gym_time_pilot_deterministic-v4_random\r\n  * gym_time_pilot_no_frameskip-v0_random\r\n  * gym_time_pilot_no_frameskip-v4_random\r\n  * gym_tutankham-v0_random\r\n  * gym_tutankham-v4_random\r\n  * gym_tutankham_deterministic-v0_random\r\n  * gym_tutankham_deterministic-v4_random\r\n  * gym_tutankham_no_frameskip-v0_random\r\n  * gym_tutankham_no_frameskip-v4_random\r\n  * gym_up_n_down-v0_random\r\n  * gym_up_n_down-v4_random\r\n  * gym_up_n_down_deterministic-v0_random\r\n  * gym_up_n_down_deterministic-v4_random\r\n  * gym_up_n_down_no_frameskip-v0_random\r\n  * gym_up_n_down_no_frameskip-v4_random\r\n  * gym_venture-v0_random\r\n  * gym_venture-v4_random\r\n  * gym_venture_deterministic-v0_random\r\n  * gym_venture_deterministic-v4_random\r\n  * gym_venture_no_frameskip-v0_random\r\n  * gym_venture_no_frameskip-v4_random\r\n  * gym_video_pinball-v0_random\r\n  * gym_video_pinball-v4_random\r\n  * gym_video_pinball_deterministic-v0_random\r\n  * gym_video_pinball_deterministic-v4_random\r\n  * gym_video_pinball_no_frameskip-v0_random\r\n  * gym_video_pinball_no_frameskip-v4_random\r\n  * gym_wizard_of_wor-v0_random\r\n  * gym_wizard_of_wor-v4_random\r\n  * gym_wizard_of_wor_deterministic-v0_random\r\n  * gym_wizard_of_wor_deterministic-v4_random\r\n  * gym_wizard_of_wor_no_frameskip-v0_random\r\n  * gym_wizard_of_wor_no_frameskip-v4_random\r\n  * gym_yars_revenge-v0_random\r\n  * gym_yars_revenge-v4_random\r\n  * gym_yars_revenge_deterministic-v0_random\r\n  * gym_yars_revenge_deterministic-v4_random\r\n  * gym_yars_revenge_no_frameskip-v0_random\r\n  * gym_yars_revenge_no_frameskip-v4_random\r\n  * gym_zaxxon-v0_random\r\n  * gym_zaxxon-v4_random\r\n  * gym_zaxxon_deterministic-v0_random\r\n  * gym_zaxxon_deterministic-v4_random\r\n  * gym_zaxxon_no_frameskip-v0_random\r\n  * gym_zaxxon_no_frameskip-v4_random\r\n  * image_celeba\r\n  * image_celeba32\r\n  * image_celeba64\r\n  * image_celeba_multi_resolution\r\n  * image_celebahq128\r\n  * image_celebahq128_dmol\r\n  * image_celebahq256\r\n  * image_celebahq256_dmol\r\n  * image_cifar10\r\n  * image_cifar100\r\n  * image_cifar100_plain\r\n  * image_cifar100_plain8\r\n  * image_cifar100_plain_gen\r\n  * image_cifar100_tune\r\n  * image_cifar10_plain\r\n  * image_cifar10_plain8\r\n  * image_cifar10_plain_gen\r\n  * image_cifar10_plain_gen_dmol\r\n  * image_cifar10_plain_random_shift\r\n  * image_cifar10_tune\r\n  * image_cifar20\r\n  * image_cifar20_plain\r\n  * image_cifar20_plain8\r\n  * image_cifar20_plain_gen\r\n  * image_cifar20_tune\r\n  * image_fashion_mnist\r\n  * image_fsns\r\n  * image_imagenet\r\n  * image_imagenet224\r\n  * image_imagenet32\r\n  * image_imagenet32_gen\r\n  * image_imagenet32_small\r\n  * image_imagenet64\r\n  * image_imagenet64_gen\r\n  * image_imagenet_multi_resolution_gen\r\n  * image_lsun_bedrooms\r\n  * image_mnist\r\n  * image_mnist_tune\r\n  * image_ms_coco_characters\r\n  * image_ms_coco_tokens32k\r\n  * image_text_ms_coco\r\n  * image_text_ms_coco_multi_resolution\r\n  * image_vqav2_rcnn_feature_tokens10k_labels3k\r\n  * image_vqav2_tokens10k_labels3k\r\n  * img2img_allen_brain\r\n  * img2img_allen_brain_dim16to16_paint1\r\n  * img2img_allen_brain_dim48to64\r\n  * img2img_allen_brain_dim8to32\r\n  * img2img_celeba\r\n  * img2img_celeba64\r\n  * img2img_cifar10\r\n  * img2img_cifar100\r\n  * img2img_imagenet\r\n  * lambada_lm\r\n  * lambada_lm_control\r\n  * lambada_rc\r\n  * lambada_rc_control\r\n  * languagemodel_de_en_fr_ro_wiki64k\r\n  * languagemodel_de_wiki32k\r\n  * languagemodel_de_wiki64k\r\n  * languagemodel_en_wiki32k\r\n  * languagemodel_en_wiki64k\r\n  * languagemodel_en_wiki64k_shorter\r\n  * languagemodel_en_wiki_lm_multi_nli_subwords\r\n  * languagemodel_en_wiki_lm_multi_nli_subwords64k\r\n  * languagemodel_en_wiki_lm_short_multi_nli_subwords64k\r\n  * languagemodel_en_wiki_lm_summarize_cnndm_subwords\r\n  * languagemodel_en_wiki_lm_summarize_cnndm_subwords64k\r\n  * languagemodel_fr_wiki32k\r\n  * languagemodel_fr_wiki64k\r\n  * languagemodel_lm1b32k\r\n  * languagemodel_lm1b32k_packed\r\n  * languagemodel_lm1b8k\r\n  * languagemodel_lm1b8k_packed\r\n  * languagemodel_lm1b_characters\r\n  * languagemodel_lm1b_characters_packed\r\n  * languagemodel_lm1b_multi_nli\r\n  * languagemodel_lm1b_multi_nli_subwords\r\n  * languagemodel_lm1b_sentiment_imdb\r\n  * languagemodel_multi_wiki_translate_fr\r\n  * languagemodel_ptb10k\r\n  * languagemodel_ptb_characters\r\n  * languagemodel_ro_wiki32k\r\n  * languagemodel_ro_wiki64k\r\n  * languagemodel_wiki_noref_v128k_l1k\r\n  * languagemodel_wiki_noref_v32k_l16k\r\n  * languagemodel_wiki_noref_v32k_l1k\r\n  * languagemodel_wiki_noref_v8k_l16k\r\n  * languagemodel_wiki_noref_v8k_l1k\r\n  * languagemodel_wiki_scramble_l128\r\n  * languagemodel_wiki_scramble_l1k\r\n  * languagemodel_wiki_xml_v8k_l1k\r\n  * languagemodel_wiki_xml_v8k_l4k\r\n  * languagemodel_wikitext103\r\n  * languagemodel_wikitext103_characters\r\n  * librispeech\r\n  * librispeech_clean\r\n  * librispeech_clean_small\r\n  * librispeech_noisy\r\n  * librispeech_train_full_test_clean\r\n  * msr_paraphrase_corpus\r\n  * msr_paraphrase_corpus_characters\r\n  * multi_nli\r\n  * multi_nli_characters\r\n  * multi_nli_shared_vocab\r\n  * multi_nli_wiki_lm_shared_vocab\r\n  * multi_nli_wiki_lm_shared_vocab64k\r\n  * ocr_test\r\n  * paraphrase_generation_ms_coco_problem1d\r\n  * paraphrase_generation_ms_coco_problem1d_characters\r\n  * paraphrase_generation_ms_coco_problem2d\r\n  * paraphrase_generation_ms_coco_problem2d_characters\r\n  * parsing_english_ptb16k\r\n  * parsing_english_ptb8k\r\n  * parsing_icelandic16k\r\n  * program_search_algolisp\r\n  * programming_desc2code_cpp\r\n  * programming_desc2code_py\r\n  * question_nli\r\n  * question_nli_characters\r\n  * quora_question_pairs\r\n  * quora_question_pairs_characters\r\n  * rte\r\n  * rte_characters\r\n  * sci_tail\r\n  * sci_tail_characters\r\n  * sci_tail_shared_vocab\r\n  * sentiment_imdb\r\n  * sentiment_imdb_characters\r\n  * sentiment_sst_binary\r\n  * sentiment_sst_binary_characters\r\n  * squad\r\n  * squad_concat\r\n  * squad_concat_positioned\r\n  * stanford_nli\r\n  * stanford_nli_characters\r\n  * stanford_nli_shared_vocab\r\n  * stanford_nli_wiki_lm_shared_vocab\r\n  * stanford_nli_wiki_lm_shared_vocab64k\r\n  * style_transfer_modern_to_shakespeare\r\n  * style_transfer_modern_to_shakespeare_characters\r\n  * style_transfer_shakespeare_to_modern\r\n  * style_transfer_shakespeare_to_modern_characters\r\n  * summarize_cnn_dailymail32k\r\n  * summarize_cnn_dailymail_wiki_lm_shared_vocab\r\n  * summarize_cnn_dailymail_wiki_lm_shared_vocab64k\r\n  * sva_language_modeling\r\n  * sva_number_prediction\r\n  * text2text_copyable_tokens\r\n  * text2text_tmpdir\r\n  * text2text_tmpdir_tokens\r\n  * timeseries_synthetic_data_series10_samples100k\r\n  * timeseries_toy_problem\r\n  * timeseries_toy_problem_no_inputs\r\n  * tiny_algo\r\n  * translate_encs_wmt32k\r\n  * translate_encs_wmt_characters\r\n  * translate_ende_wmt32k\r\n  * translate_ende_wmt32k_packed\r\n  * translate_ende_wmt8k\r\n  * translate_ende_wmt8k_packed\r\n  * translate_ende_wmt_bpe32k\r\n  * translate_ende_wmt_characters\r\n  * translate_enet_wmt32k\r\n  * translate_enet_wmt_characters\r\n  * translate_enfr_wmt32k\r\n  * translate_enfr_wmt32k_packed\r\n  * translate_enfr_wmt32k_with_backtranslate_en\r\n  * translate_enfr_wmt32k_with_backtranslate_fr\r\n  * translate_enfr_wmt8k\r\n  * translate_enfr_wmt_characters\r\n  * translate_enfr_wmt_multi64k\r\n  * translate_enfr_wmt_small32k\r\n  * translate_enfr_wmt_small8k\r\n  * translate_enfr_wmt_small_characters\r\n  * translate_enid_iwslt32k\r\n  * translate_enmk_setimes32k\r\n  * translate_enmk_setimes_characters\r\n  * translate_envi_iwslt32k\r\n  * translate_enzh_wmt32k\r\n  * translate_enzh_wmt8k\r\n  * video_bair_robot_pushing\r\n  * video_bair_robot_pushing_with_actions\r\n  * video_google_robot_pushing\r\n  * video_stochastic_shapes10k\r\n  * video_twentybn\r\n  * wiki_revision\r\n  * wiki_revision_packed1k\r\n  * wiki_revision_packed256\r\n  * wikisum_commoncrawl\r\n  * wikisum_commoncrawl_lead_section\r\n  * wikisum_web\r\n  * wikisum_web_lead_section\r\n  * winograd_nli\r\n  * winograd_nli_characters\r\n  * wsj_parsing\r\n```\r\n\r\nTraining the model using the custom problem worked just fine by running t2t-trainer with the t2t_usr_dir flag set to my directory with the custom problem, however I am unable to properly register the problem in the notebook.\r\n\r\nAm I doing something wrong? Or is this not supported in the AttentionVIsualizer?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1549", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1549/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1549/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1549/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1549", "id": 434894073, "node_id": "MDU6SXNzdWU0MzQ4OTQwNzM=", "number": 1549, "title": "Serving pre-trained model for Speech Recognition", "user": {"login": "manuel3265", "id": 39747299, "node_id": "MDQ6VXNlcjM5NzQ3Mjk5", "avatar_url": "https://avatars1.githubusercontent.com/u/39747299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manuel3265", "html_url": "https://github.com/manuel3265", "followers_url": "https://api.github.com/users/manuel3265/followers", "following_url": "https://api.github.com/users/manuel3265/following{/other_user}", "gists_url": "https://api.github.com/users/manuel3265/gists{/gist_id}", "starred_url": "https://api.github.com/users/manuel3265/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manuel3265/subscriptions", "organizations_url": "https://api.github.com/users/manuel3265/orgs", "repos_url": "https://api.github.com/users/manuel3265/repos", "events_url": "https://api.github.com/users/manuel3265/events{/privacy}", "received_events_url": "https://api.github.com/users/manuel3265/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-04-18T18:11:37Z", "updated_at": "2020-04-08T06:39:26Z", "closed_at": "2020-02-17T16:16:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI want to put into production the pre-trained model for speech recognition, but I do not know how I should do it.\r\n\r\nI already did the part of the t2t-exporter and tensorflow_model_server. all right up there. I have to modify the query.py file, this is what I have done:\r\n\r\n```\r\n# coding=utf-8\r\n# Copyright 2019 The Tensor2Tensor Authors.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n\r\n\"\"\"Query an exported model. Py2 only. Install tensorflow-serving-api.\"\"\"\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os\r\n\r\nfrom oauth2client.client import GoogleCredentials\r\nfrom six.moves import input  # pylint: disable=redefined-builtin\r\n\r\nfrom tensor2tensor import problems as problems_lib  # pylint: disable=unused-import\r\nfrom tensor2tensor.serving import serving_utils\r\nfrom tensor2tensor.utils import registry\r\nfrom tensor2tensor.utils import usr_dir\r\nfrom tensor2tensor.utils.hparam import HParams\r\n\r\nimport tensorflow as tf\r\n\r\nflags = tf.flags\r\nFLAGS = flags.FLAGS\r\n\r\nflags.DEFINE_string(\"server\", None, \"Address to Tensorflow Serving server.\")\r\nflags.DEFINE_string(\"servable_name\", None, \"Name of served model.\")\r\nflags.DEFINE_string(\"problem\", None, \"Problem name.\")\r\nflags.DEFINE_string(\"data_dir\", None, \"Data directory, for vocab files.\")\r\nflags.DEFINE_string(\"t2t_usr_dir\", None, \"Usr dir for registrations.\")\r\nflags.DEFINE_string(\"inputs_once\", None, \"Query once with this input.\")\r\nflags.DEFINE_integer(\"timeout_secs\", 10, \"Timeout for query.\")\r\n\r\n# For Cloud ML Engine predictions.\r\nflags.DEFINE_string(\"cloud_mlengine_model_name\", None,\r\n                    \"Name of model deployed on Cloud ML Engine.\")\r\nflags.DEFINE_string(\r\n    \"cloud_mlengine_model_version\", None,\r\n    \"Version of the model to use. If None, requests will be \"\r\n    \"sent to the default version.\")\r\n\r\n\r\ndef validate_flags():\r\n  \"\"\"Validates flags are set to acceptable values.\"\"\"\r\n  if FLAGS.cloud_mlengine_model_name:\r\n    assert not FLAGS.server\r\n    assert not FLAGS.servable_name\r\n  else:\r\n    assert FLAGS.server\r\n    assert FLAGS.servable_name\r\n\r\n\r\ndef make_request_fn():\r\n  \"\"\"Returns a request function.\"\"\"\r\n  if FLAGS.cloud_mlengine_model_name:\r\n    request_fn = serving_utils.make_cloud_mlengine_request_fn(\r\n        credentials=GoogleCredentials.get_application_default(),\r\n        model_name=FLAGS.cloud_mlengine_model_name,\r\n        version=FLAGS.cloud_mlengine_model_version)\r\n  else:\r\n\r\n    request_fn = serving_utils.make_grpc_request_fn(\r\n        servable_name='servex',\r\n        server='localhost:9000',\r\n        timeout_secs=10)\r\n  return request_fn\r\n\r\n\r\ndef main(_):\r\n  tf.logging.set_verbosity(tf.logging.INFO)\r\n  # validate_flags()\r\n  usr_dir.import_usr_dir(FLAGS.t2t_usr_dir)\r\n  problem = registry.problem('librispeech_clean')\r\n  hparams = HParams(\r\n      data_dir=os.path.expanduser('/mnt/disks/mnt-dir/t2t_tmp/data/'))\r\n  problem.get_hparams(hparams)\r\n  print(FLAGS.data_dir)\r\n  print(problem.get_hparams(hparams))\r\n  print(hparams)\r\n  request_fn = make_request_fn()\r\n\r\n\r\n\r\n  while True:\r\n    inputs = '/home/manuel/Descargas/apis/audios/si.wav'\r\n    outputs = serving_utils.predict([inputs], problem, request_fn)\r\n    outputs, = outputs\r\n    output, score = outputs\r\n    if len(score.shape) > 0:  # pylint: disable=g-explicit-length-test\r\n      print_str = \"\"\"\r\nInput:\r\n{inputs}\r\nOutput (Scores [{score}]):\r\n{output}\r\n        \"\"\"\r\n      score_text = \",\".join([\"{:.3f}\".format(s) for s in score])\r\n      print(print_str.format(inputs=inputs, output=output, score=score_text))\r\n    else:\r\n      print_str = \"\"\"\r\nInput:\r\n{inputs}\r\nOutput (Score {score:.3f}):\r\n{output}\r\n        \"\"\"\r\n      print(print_str.format(inputs=inputs, output=output, score=score))\r\n\r\n    if FLAGS.inputs_once:\r\n      break\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  flags.mark_flags_as_required([\"problem\", \"data_dir\"])\r\n  tf.app.run()\r\n\r\n\r\n```\r\nleave data in a static way, to test.\r\n\r\nwhen I execute it, I receive this:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/bin/t2t-query-server\", line 17, in <module>\r\n    tf.app.run()\r\n  File \"/home/manuel/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/bin/t2t-query-server\", line 12, in main\r\n    query.main(argv)\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/serving/query.py\", line 97, in main\r\n    outputs = serving_utils.predict([inputs], problem, request_fn)\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/serving/serving_utils.py\", line 156, in predict\r\n    for inputs in inputs_list\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/serving/serving_utils.py\", line 156, in <listcomp>\r\n    for inputs in inputs_list\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/serving/serving_utils.py\", line 90, in _encode\r\n    input_ids = encoder.encode(inputs)\r\nAttributeError: 'NoneType' object has no attribute 'encode'\r\n```\r\n\r\nI think it's because of the inputs. I understand that devo decodes the audio file, but I do not know how to do it. this is correct?.\r\n\r\nPlease, I hope you can help me.\r\n\r\nI would thank you a lot.\r\n\r\n...\r\n\r\n### Environment information\r\nubuntu: 18.04 LTS\r\npython 3.6 \r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.5\r\ntensor2tensorM==1.1.12\r\ntensorboard==1.13.1\r\ntensorflow==1.13.1\r\ntensorflow-datasets==1.0.1\r\ntensorflow-estimator==1.13.0\r\ntensorflow-gpu==1.13.1\r\ntensorflow-hub==0.4.0\r\ntensorflow-metadata==0.13.0\r\ntensorflow-probability==0.6.0\r\ntensorflow-serving-api==1.13.0\r\n\r\n$ python -V\r\nPython 3.6.7\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\nTraceback (most recent call last):\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/bin/t2t-query-server\", line 17, in <module>\r\n    tf.app.run()\r\n  File \"/home/manuel/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/bin/t2t-query-server\", line 12, in main\r\n    query.main(argv)\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/serving/query.py\", line 97, in main\r\n    outputs = serving_utils.predict([inputs], problem, request_fn)\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/serving/serving_utils.py\", line 156, in predict\r\n    for inputs in inputs_list\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/serving/serving_utils.py\", line 156, in <listcomp>\r\n    for inputs in inputs_list\r\n  File \"/home/manuel/Descargas/apisl/tensor2tensor/tensor2tensor/serving/serving_utils.py\", line 90, in _encode\r\n    input_ids = encoder.encode(inputs)\r\nAttributeError: 'NoneType' object has no attribute 'encode'\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1546", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1546/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1546/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1546/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1546", "id": 434159808, "node_id": "MDU6SXNzdWU0MzQxNTk4MDg=", "number": 1546, "title": "eval_run_autoregressive doesn't work with transformer and Multi-task problems", "user": {"login": "agemagician", "id": 6087313, "node_id": "MDQ6VXNlcjYwODczMTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6087313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agemagician", "html_url": "https://github.com/agemagician", "followers_url": "https://api.github.com/users/agemagician/followers", "following_url": "https://api.github.com/users/agemagician/following{/other_user}", "gists_url": "https://api.github.com/users/agemagician/gists{/gist_id}", "starred_url": "https://api.github.com/users/agemagician/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agemagician/subscriptions", "organizations_url": "https://api.github.com/users/agemagician/orgs", "repos_url": "https://api.github.com/users/agemagician/repos", "events_url": "https://api.github.com/users/agemagician/events{/privacy}", "received_events_url": "https://api.github.com/users/agemagician/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-17T08:38:10Z", "updated_at": "2019-04-29T07:36:51Z", "closed_at": "2019-04-29T07:36:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nThe evaluation is running only when we don't use eval_run_autoregressive, however, when set it to true an error occur:\r\n```\r\nINFO:tensorflow:Cannot use 'while/transformer/parallel_0_6/transformer/transformer/languagemodel_mine_subwords8k_loss' as input to 'Merge/MergeSummary' because 'while/transformer/parallel_0_6/transfor\r\nmer/transformer/languagemodel_mine_subwords8k_loss' is in a while loop.   \r\n\r\n```\r\n### Environment information\r\n\r\n```\r\nOS: Ubuntu\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.5\r\ntensor2tensor==1.12.0\r\ntensorboard==1.13.1\r\ntensorflow-datasets==1.0.1\r\ntensorflow-estimator==1.13.0\r\ntensorflow-gpu==1.13.1\r\ntensorflow-metadata==0.13.0\r\ntensorflow-probability==0.6.0\r\n```\r\n\r\n```\r\n$ python -V\r\nPython 2.7.16 :: Anaconda, Inc.\r\n```\r\n\r\n\r\n# Error logs:\r\n```\r\nINFO:tensorflow:Cannot use 'while/transformer/parallel_0_6/transformer/transformer/languagemodel_mine_subwords8k_loss' as input to 'Merge/MergeSummary' because 'while/transformer/parallel_0_6/transfor\r\nmer/transformer/languagemodel_mine_subwords8k_loss' is in a while loop.                                                                        \r\n                                                                                                                                               \r\nMerge/MergeSummary while context: None                                                                                                                \r\nwhile/transformer/parallel_0_6/transformer/transformer/languagemodel_mine_subwords8k_loss while context: while/while_context  \r\n                                                                                                                                                                   \r\nTraceback for Merge/MergeSummary:                                                                                                     \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/bin/t2t-trainer\", line 33, in <module>                                                                            \r\n    tf.app.run()                                                                                                                                           \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run                             \r\n    _sys.exit(main(argv))                                                                                                                                      \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/bin/t2t-trainer\", line 28, in main                                                                    \r\n    t2t_trainer.main(argv)                                                                                                                                                                                        \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 393, in main                   \r\n    execute_schedule(exp)                                                                                                              \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 349, in execute_schedule                                                                       \r\n    getattr(exp, FLAGS.schedule)()                                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py\", line 438, in continuous_train_and_eval            \r\n    self._eval_spec)                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate          \r\n    return executor.run()                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\r\n    return self.run_local()                                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\r\n    saving_listeners=saving_listeners)                                           \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\r\n    saving_listeners)                                                                                                                                 \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 676, in run        \r\n    run_metadata=run_metadata)                                                                                                                 \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run        \r\n    run_metadata=run_metadata)                                                                                                                       \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run       \r\n    return self._sess.run(*args, **kwargs)          \r\nFile \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run                 \r\n    run_metadata=run_metadata))                                                                                                                           \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\r\n    if self._save(run_context.session, global_step):                                                                                                                                                              \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save    \r\n    if l.after_save(session, step):                                                                                                                                     \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate              \r\n    self._evaluator.evaluate_and_export())                                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export  \r\n    hooks=self._eval_spec.hooks)                                                                                                              \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate       \r\n    name=name)                                                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\r\n    return _evaluate()                                                                                                                                   \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\r\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\r\n    self._call_model_fn_eval(input_fn, self.config))                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\r\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)                                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)                                                                                             \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn   \r\n    use_tpu=use_tpu)                                                                                                                                 \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1483, in estimator_model_fn                                                                    \r\n    losses_dict)                                                                                                                                         \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1608, in estimator_spec_eval\r\n    summary_op=tf.summary.merge_all())                                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 404, in merge_all\r\n    return merge(summary_ops, name=name)                                                                                                                           \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 369, in merge  \r\n    val = _gen_logging_ops.merge_summary(inputs=inputs, name=name)                                                                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 503, in merge_summary           \r\n    \"MergeSummary\", inputs=inputs, name=name)                                                                                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper       \r\n    op_def=op_def)                                                                                                                                   \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func                                                                          \r\n    return func(*args, **kwargs)                                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)                                                                                                                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()                                                                                                                    \r\n                                                                    \r\nTraceback for while/transformer/parallel_0_6/transformer/transformer/languagemodel_mine_subwords8k_loss:                                                      \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/bin/t2t-trainer\", line 33, in <module>\r\n    tf.app.run()                                                                                                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))                                                                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)                                                                                                                        \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 393, in main\r\n    execute_schedule(exp)                                                                                                                                 \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 349, in execute_schedule\r\n    getattr(exp, FLAGS.schedule)()                                                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py\", line 438, in continuous_train_and_eval\r\n    self._eval_spec)                                                                                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()                                                                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\r\n    return self.run_local()                                                                                                                           \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\r\n    saving_listeners=saving_listeners)                                                                                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\r\n  loss = self._train_model(input_fn, hooks, saving_listeners)                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default                                                \r\n    saving_listeners)                                                                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\r\n    run_metadata=run_metadata)                                                                                                                                     \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\r\n    run_metadata=run_metadata)                                                                                                                                   \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\r\n    return self._sess.run(*args, **kwargs)                                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\r\n    run_metadata=run_metadata))                                                                                                                          \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\r\n    if self._save(run_context.session, global_step):                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\r\n    if l.after_save(session, step):                                                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\r\n    self._evaluator.evaluate_and_export())                                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)                                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\r\n    name=name)                                                                                                                                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\r\n    return _evaluate()                                                                                                                         \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\r\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))                                                                       \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\r\n    self._call_model_fn_eval(input_fn, self.config))                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\r\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)                                                                                             \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn        \r\n    use_tpu=use_tpu)                                                                                                                                                                                              \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1427, in estimator_model_fn    \r\n    logits, losses_dict = model.eval_autoregressive(features)                                                                          \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 730, in eval_autoregressive                                                                    \r\n    results = self._slow_greedy_infer(features, decode_length=decode_length)                                                          \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1262, in _slow_greedy_infer                    \r\n    parallel_iterations=1)                                          \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3556, in while_loop                         \r\n    return_same_structure)                                                           \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3087, in BuildLoop \r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)                                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3022, in _BuildLoop      \r\n    body_result = body(*packed_vars_for_body)                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1160, in infer_step            \r\n    samples, logits, losses = self.sample(features)                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1292, in sample                        \r\n    logits, losses = self(features)  # pylint: disable=not-callable                                                                        \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 530, in __call__                               \r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__                         \r\n    outputs = self.call(inputs, *args, **kwargs)                                                                                                              \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 295, in call                      \r\n    sharded_logits, losses = self.model_fn_sharded(sharded_features)                                                                           \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 356, in model_fn_sharded           \r\n    sharded_logits, sharded_losses = dp(self.model_fn, datashard_to_features)                                                                        \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/expert_utils.py\", line 231, in __call__               \r\n    outputs.append(fns[i](*my_args[i], **my_kwargs[i]))                                 \r\nFile \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 404, in model_fn                            \r\n    losses[\"training\"] = self.loss(logits, features)                                                                                                      \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 681, in loss                          \r\n    weights=features.get(\"targets_mask\"))                                                                                                                                                                         \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 632, in _loss_single                  \r\n    tf.summary.scalar(key, val)                                                                                                                                         \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 80, in scalar                  \r\n    val = _gen_logging_ops.scalar_summary(tags=tag, values=tensor, name=scope)                                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 727, in scalar_summary                  \r\n    \"ScalarSummary\", tags=tags, values=values, name=name)                                                                                     \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper         \r\n    op_def=op_def)                                                                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func                    \r\n    return func(*args, **kwargs)                                                                                                              \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op                  \r\n    op_def=op_def)                                                                                                                                       \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__                \r\n    self._traceback = tf_stack.extract_stack()                                                                                                       \r\n                                                                                                                                                                   \r\n                                                                                                                                                      \r\nTraceback (most recent call last):                                                                                                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/bin/t2t-trainer\", line 33, in <module>                                                                \r\n    tf.app.run()                                                                                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run                                \r\n    _sys.exit(main(argv))                                                                                                                       \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/bin/t2t-trainer\", line 28, in main                                                                    \r\n    t2t_trainer.main(argv)                                                                                                                                                                                        \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 393, in main                          \r\n    execute_schedule(exp)                                                                                                                      \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 349, in execute_schedule           \r\n    getattr(exp, FLAGS.schedule)()                                                                                                      \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py\", line 438, in continuous_train_and_eval             \r\n    self._eval_spec)                                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate   \r\n    return executor.run()                                                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run             \r\n    return self.run_local()                                                                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\r\n    saving_listeners=saving_listeners)                                                                                                                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)                                                                        \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model                                                        \r\n    return self._train_model_default(input_fn, hooks, saving_listeners)                                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\r\n    saving_listeners)                                               \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])           \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 676, in run  \r\n    run_metadata=run_metadata)                                                                                                 \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run       \r\n    run_metadata=run_metadata)                                                   \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1270, in run    \r\n    raise six.reraise(*original_exc_info)                                                                                      \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run            \r\n    return self._sess.run(*args, **kwargs)                                                                                                 \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run                    \r\n    run_metadata=run_metadata))                                                                                                                       \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run               \r\n    if self._save(run_context.session, global_step):                                                                                                          \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\r\n    if l.after_save(session, step):                                                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\r\n    self._evaluator.evaluate_and_export())                     \r\nFile \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)                                                                                                                          \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate    \r\n    name=name)                                                                                                                                                                                                    \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\r\n    return _evaluate()                                                                                                                                                  \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 493, in _evaluate\r\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1424, in _evaluate_build_graph\r\n    self._call_model_fn_eval(input_fn, self.config))                                                                                          \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1460, in _call_model_fn_eval\r\n    features, labels, model_fn_lib.ModeKeys.EVAL, config)                                                                                     \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)                                                                            \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1368, in wrapping_model_fn            \r\n    use_tpu=use_tpu)                                                                                                                                     \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1483, in estimator_model_fn        \r\n    losses_dict)                                                                                                                                     \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py\", line 1608, in estimator_spec_eval                    \r\n    summary_op=tf.summary.merge_all())                                                                                                                \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 404, in merge_all                         \r\n    return merge(summary_ops, name=name)                                                                                                             \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 369, in merge                        \r\n    val = _gen_logging_ops.merge_summary(inputs=inputs, name=name)                                                                                             \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 503, in merge_summary\r\n    \"MergeSummary\", inputs=inputs, name=name)                                                                                                        \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper                                                          \r\n    op_def=op_def)                                                                                                                                       \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func       \r\n    return func(*args, **kwargs)                                                                                                                      \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op \r\n    op_def=op_def)                                                                                                                                                 \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1838, in __init__\r\n    self._control_flow_post_processing()                                                                                                                         \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1847, in _control_flow_post_processing\r\n    control_flow_util.CheckInputFromValidContext(self, input_tensor.op)                                                                                     \r\n  File \"/home/agemagician/anaconda3/envs/t2tp2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_util.py\", line 335, in CheckInputFromValidContext\r\n    raise ValueError(error_msg + \" See info log for more details.\")                                                                                  \r\nValueError: Cannot use 'while/transformer/parallel_0_6/transformer/transformer/languagemodel_mine_subwords8k_loss' as input to 'Merge/MergeSummary' because 'while/transformer/parallel_0_6/transformer/\r\ntransformer/languagemodel_mine_subwords8k_loss' is in a while loop. See info log for more details. \r\n``` ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1544", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1544/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1544/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1544/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1544", "id": 433295873, "node_id": "MDU6SXNzdWU0MzMyOTU4NzM=", "number": 1544, "title": "Wikisum:  failing to request proper quotas", "user": {"login": "plbeaubien-eai", "id": 44006946, "node_id": "MDQ6VXNlcjQ0MDA2OTQ2", "avatar_url": "https://avatars3.githubusercontent.com/u/44006946?v=4", "gravatar_id": "", "url": "https://api.github.com/users/plbeaubien-eai", "html_url": "https://github.com/plbeaubien-eai", "followers_url": "https://api.github.com/users/plbeaubien-eai/followers", "following_url": "https://api.github.com/users/plbeaubien-eai/following{/other_user}", "gists_url": "https://api.github.com/users/plbeaubien-eai/gists{/gist_id}", "starred_url": "https://api.github.com/users/plbeaubien-eai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/plbeaubien-eai/subscriptions", "organizations_url": "https://api.github.com/users/plbeaubien-eai/orgs", "repos_url": "https://api.github.com/users/plbeaubien-eai/repos", "events_url": "https://api.github.com/users/plbeaubien-eai/events{/privacy}", "received_events_url": "https://api.github.com/users/plbeaubien-eai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-04-15T13:54:30Z", "updated_at": "2019-04-15T19:19:54Z", "closed_at": "2019-04-15T19:19:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nIn the hope of generating Wikisum, I've been asking google to modify my quotas for about 2 weeks without any luck. I'm getting daily updates saying they're working on it without getting any estimate for resolution.\r\n\r\nAny hints? Any viable alternatives? (are those files available somewhere for download?)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1538", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1538/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1538/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1538/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1538", "id": 431804809, "node_id": "MDU6SXNzdWU0MzE4MDQ4MDk=", "number": 1538, "title": "Define a Squence2Class Problem", "user": {"login": "YuTingLiu", "id": 8286904, "node_id": "MDQ6VXNlcjgyODY5MDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/8286904?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YuTingLiu", "html_url": "https://github.com/YuTingLiu", "followers_url": "https://api.github.com/users/YuTingLiu/followers", "following_url": "https://api.github.com/users/YuTingLiu/following{/other_user}", "gists_url": "https://api.github.com/users/YuTingLiu/gists{/gist_id}", "starred_url": "https://api.github.com/users/YuTingLiu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YuTingLiu/subscriptions", "organizations_url": "https://api.github.com/users/YuTingLiu/orgs", "repos_url": "https://api.github.com/users/YuTingLiu/repos", "events_url": "https://api.github.com/users/YuTingLiu/events{/privacy}", "received_events_url": "https://api.github.com/users/YuTingLiu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-11T02:46:32Z", "updated_at": "2019-04-11T02:56:24Z", "closed_at": "2019-04-11T02:55:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nModify Text2TextProblem and Text2ClassProblem for train a classify model, minor diffierence is that in my question, the input is float array.\r\n...\r\n\r\n### configration file\r\n\r\n\r\n```\r\nOS:windows \r\nENV works fine\r\n```\r\n\r\n### BUG report\r\n\r\n```\r\n# data generation works fine\r\n\r\npython datagen.py --problem=my_imu_classify --tmp_dir=./rawdata --data_dir=./ts_test_data\r\npython train.py --t2t_usr_dir=./self_script --problem=my_imu_classify --data_dir=./ts_test_data --model=transformer --output_dir=./train --hparams_set=transformer_base --train_steps=1000 --eval_steps=100\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n2019-04-11 10:35:05.253144: W tensorflow/core/framework/op_kernel.cc:1401] OP_RE\r\nQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Feature: targets\r\n (data type: int64) is required but could not be found.\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\c\r\nlient\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\c\r\nlient\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\c\r\nlient\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Feature: targets (\r\ndata type: int64) is required but could not be found.\r\n         [[{{node ParseSingleExample/ParseSingleExample}}]]\r\n         [[{{node IteratorGetNext}}]]\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1533", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1533/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1533/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1533/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1533", "id": 430256039, "node_id": "MDU6SXNzdWU0MzAyNTYwMzk=", "number": 1533, "title": "tf.session ", "user": {"login": "manuel3265", "id": 39747299, "node_id": "MDQ6VXNlcjM5NzQ3Mjk5", "avatar_url": "https://avatars1.githubusercontent.com/u/39747299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manuel3265", "html_url": "https://github.com/manuel3265", "followers_url": "https://api.github.com/users/manuel3265/followers", "following_url": "https://api.github.com/users/manuel3265/following{/other_user}", "gists_url": "https://api.github.com/users/manuel3265/gists{/gist_id}", "starred_url": "https://api.github.com/users/manuel3265/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manuel3265/subscriptions", "organizations_url": "https://api.github.com/users/manuel3265/orgs", "repos_url": "https://api.github.com/users/manuel3265/repos", "events_url": "https://api.github.com/users/manuel3265/events{/privacy}", "received_events_url": "https://api.github.com/users/manuel3265/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-08T05:01:15Z", "updated_at": "2020-02-17T16:15:34Z", "closed_at": "2020-02-17T16:15:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI would like to know, if you could tell me, in what part of the code, the session is created in the training part. that is, when executing:\r\n\r\n```\r\nt2t-trainer --model=transformer  --hparams_set=transformer_librispeech_tpu \\\r\n  --problem=librispeech_train_full_test_clean \\\r\n```\r\n\r\n, where the session (tf.session) is created. I need to do a test to change from:\r\n\r\n```with tf.Session() as sess: ``` to  ``` sess = tf.Session() ```\r\n...\r\n\r\nI would thank you a lot.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1530", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1530/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1530/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1530/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1530", "id": 428576317, "node_id": "MDU6SXNzdWU0Mjg1NzYzMTc=", "number": 1530, "title": "Is there a good example tutorial on how to use Tensor2Tensor?", "user": {"login": "zqs01", "id": 40491290, "node_id": "MDQ6VXNlcjQwNDkxMjkw", "avatar_url": "https://avatars1.githubusercontent.com/u/40491290?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zqs01", "html_url": "https://github.com/zqs01", "followers_url": "https://api.github.com/users/zqs01/followers", "following_url": "https://api.github.com/users/zqs01/following{/other_user}", "gists_url": "https://api.github.com/users/zqs01/gists{/gist_id}", "starred_url": "https://api.github.com/users/zqs01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zqs01/subscriptions", "organizations_url": "https://api.github.com/users/zqs01/orgs", "repos_url": "https://api.github.com/users/zqs01/repos", "events_url": "https://api.github.com/users/zqs01/events{/privacy}", "received_events_url": "https://api.github.com/users/zqs01/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-03T05:43:35Z", "updated_at": "2019-04-08T15:37:34Z", "closed_at": "2019-04-08T15:37:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there a good example tutorial on how to use Tensor2Tensor?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1528", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1528/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1528/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1528/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1528", "id": 427499970, "node_id": "MDU6SXNzdWU0Mjc0OTk5NzA=", "number": 1528, "title": "distributed training on multiple machine fails", "user": {"login": "batravarun125", "id": 12998020, "node_id": "MDQ6VXNlcjEyOTk4MDIw", "avatar_url": "https://avatars1.githubusercontent.com/u/12998020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/batravarun125", "html_url": "https://github.com/batravarun125", "followers_url": "https://api.github.com/users/batravarun125/followers", "following_url": "https://api.github.com/users/batravarun125/following{/other_user}", "gists_url": "https://api.github.com/users/batravarun125/gists{/gist_id}", "starred_url": "https://api.github.com/users/batravarun125/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/batravarun125/subscriptions", "organizations_url": "https://api.github.com/users/batravarun125/orgs", "repos_url": "https://api.github.com/users/batravarun125/repos", "events_url": "https://api.github.com/users/batravarun125/events{/privacy}", "received_events_url": "https://api.github.com/users/batravarun125/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-01T03:54:00Z", "updated_at": "2019-04-25T18:35:06Z", "closed_at": "2019-04-25T18:35:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI am trying to do distributed training on multiple machines with 1 GPU each. It is failing on the workers. Please look into this!\r\n...\r\n\r\n### Environment information\r\n```\r\nOS: Linux - 18\r\n\r\nOn master i run -\r\nt2t-trainer --master=grpc://10.10.1.2:2219 --ps_replicas=3 --worker_replicas=1 --worker_gpu=0 --worker_id=0 --ps_gpu=1 --sync --schedule=train --worker_job='/job:master' --model=transformer --hparams_set=transformer_base --problem=translate_ende_wmt32k --data_dir=/users/kshiteej/varunimagenet/tensor2tensor/t2t_data/ --output_dir=/users/kshiteej/\r\n\r\nOn PS-\r\n1. t2t-trainer --schedule=run_std_server \r\n2. t2t-trainer --schedule=run_std_server \r\n3. t2t-trainer --schedule=run_std_server \r\n\r\nOUTPUT of Master - \r\n..\r\n.\r\n.\r\n.\r\n13] Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nI0331 22:40:02.157696 139967148951360 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n\r\nOUTPUT of Worker - \r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-trainer\", line 33, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 413, in main\r\n    hparams = create_hparams()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 176, in create_hparams\r\n    return trainer_lib.create_hparams(FLAGS.hparams_set, FLAGS.hparams,hparams_path=hparams_path)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/hparams_lib.py\", line 48, in create_hparams\r\n    hparams = registry.hparams(hparams_set)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/registry.py\", line 254, in __getitem__\r\n    (key, self.name, display_list_by_prefix(sorted(self), 4)))\r\nKeyError: 'None never registered with registry hparams. Available:\\n     adaptive:\\n      * adaptive_universal_transformer_base\\n      * adaptive_universal_tr...\r\n..\r\n..\r\n..\r\n\r\n\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\nmesh-tensorflow==0.0.5\r\ntensor2tensor==1.13.1\r\ntensorboard==1.13.0\r\ntensorflow-datasets==1.0.1\r\ntensorflow-estimator==1.13.0\r\ntensorflow-gpu==1.13.1\r\ntensorflow-metadata==0.13.0\r\ntensorflow-probability==0.6.0\r\ntensorflow-tensorboard==0.4.0\r\n\r\n$ python -V\r\n# your output here\r\n```\r\nPython 2.7.15rc1\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1524", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1524/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1524/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1524/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1524", "id": 425014630, "node_id": "MDU6SXNzdWU0MjUwMTQ2MzA=", "number": 1524, "title": "Incompatibility with TF2.0", "user": {"login": "shkarupa-alex", "id": 1289725, "node_id": "MDQ6VXNlcjEyODk3MjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1289725?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shkarupa-alex", "html_url": "https://github.com/shkarupa-alex", "followers_url": "https://api.github.com/users/shkarupa-alex/followers", "following_url": "https://api.github.com/users/shkarupa-alex/following{/other_user}", "gists_url": "https://api.github.com/users/shkarupa-alex/gists{/gist_id}", "starred_url": "https://api.github.com/users/shkarupa-alex/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shkarupa-alex/subscriptions", "organizations_url": "https://api.github.com/users/shkarupa-alex/orgs", "repos_url": "https://api.github.com/users/shkarupa-alex/repos", "events_url": "https://api.github.com/users/shkarupa-alex/events{/privacy}", "received_events_url": "https://api.github.com/users/shkarupa-alex/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-25T17:02:20Z", "updated_at": "2019-03-25T18:23:50Z", "closed_at": "2019-03-25T18:23:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nGot an error when running t2t-trainer --registry_help with installed \"tensorflow alpha\"\r\n\r\n### Environment information\r\n\r\n```\r\nOS: MacOS X\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.5\r\ntensor2tensor==1.13.1\r\ntensorboard==1.12.0\r\ntensorflow==2.0.0a0\r\ntensorflow-datasets==1.0.1\r\ntensorflow-fold==0.0.1\r\ntensorflow-hub==0.1.1\r\ntensorflow-metadata==0.13.0\r\ntensorflow-serving-api==1.7.0\r\ntensorflow-tensorboard==1.5.1\r\ntensorflow-zero==0.0.4\r\n\r\n$ python -V\r\nPython 2.7.15\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\npip install -U --pre tensorflow\r\npip install -U tensor2tensor\r\npip uninstall tensorflow-probability\r\npip install -U tfp-nightly\r\nt2t-trainer --registry_help\r\n```\r\n\r\n```\r\n# Error logs:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-trainer\", line 23, in <module>\r\n    from tensor2tensor.bin import t2t_trainer\r\n  File \"/usr/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 25, in <module>\r\n    from tensor2tensor import models  # pylint: disable=unused-import\r\n  File \"/usr/local/lib/python2.7/site-packages/tensor2tensor/models/__init__.py\", line 25, in <module>\r\n    from tensor2tensor.layers import modalities  # pylint: disable=g-import-not-at-top\r\n  File \"/usr/local/lib/python2.7/site-packages/tensor2tensor/layers/modalities.py\", line 28, in <module>\r\n    from tensor2tensor.layers import common_attention\r\n  File \"/usr/local/lib/python2.7/site-packages/tensor2tensor/layers/common_attention.py\", line 5074, in <module>\r\n    @expert_utils.add_var_scope()\r\n  File \"/usr/local/lib/python2.7/site-packages/tensor2tensor/utils/expert_utils.py\", line 68, in add_var_scope\r\n    return add_scope(scope, scope_fn=tf.variable_scope)\r\nAttributeError: 'module' object has no attribute 'variable_scope'\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1519", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1519/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1519/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1519/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1519", "id": 424516115, "node_id": "MDU6SXNzdWU0MjQ1MTYxMTU=", "number": 1519, "title": "Image generation", "user": {"login": "riktimmondal", "id": 24415468, "node_id": "MDQ6VXNlcjI0NDE1NDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/24415468?v=4", "gravatar_id": "", "url": "https://api.github.com/users/riktimmondal", "html_url": "https://github.com/riktimmondal", "followers_url": "https://api.github.com/users/riktimmondal/followers", "following_url": "https://api.github.com/users/riktimmondal/following{/other_user}", "gists_url": "https://api.github.com/users/riktimmondal/gists{/gist_id}", "starred_url": "https://api.github.com/users/riktimmondal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/riktimmondal/subscriptions", "organizations_url": "https://api.github.com/users/riktimmondal/orgs", "repos_url": "https://api.github.com/users/riktimmondal/repos", "events_url": "https://api.github.com/users/riktimmondal/events{/privacy}", "received_events_url": "https://api.github.com/users/riktimmondal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-23T16:07:26Z", "updated_at": "2019-03-23T16:08:51Z", "closed_at": "2019-03-23T16:08:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\n\r\n$ python -V\r\n# your output here\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1515", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1515/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1515/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1515/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1515", "id": 424118379, "node_id": "MDU6SXNzdWU0MjQxMTgzNzk=", "number": 1515, "title": "The principle of LM model.", "user": {"login": "guotong1988", "id": 4702353, "node_id": "MDQ6VXNlcjQ3MDIzNTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4702353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guotong1988", "html_url": "https://github.com/guotong1988", "followers_url": "https://api.github.com/users/guotong1988/followers", "following_url": "https://api.github.com/users/guotong1988/following{/other_user}", "gists_url": "https://api.github.com/users/guotong1988/gists{/gist_id}", "starred_url": "https://api.github.com/users/guotong1988/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guotong1988/subscriptions", "organizations_url": "https://api.github.com/users/guotong1988/orgs", "repos_url": "https://api.github.com/users/guotong1988/repos", "events_url": "https://api.github.com/users/guotong1988/events{/privacy}", "received_events_url": "https://api.github.com/users/guotong1988/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-22T09:33:21Z", "updated_at": "2019-04-03T01:39:57Z", "closed_at": "2019-04-03T01:39:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Does the model need the encoder of tensor2tensor? From the ptb code I find the model do not contains the encoder.\r\n\r\nOr both with-encoder and without-encoder can do the LM task? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1512", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1512/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1512/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1512/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1512", "id": 423975962, "node_id": "MDU6SXNzdWU0MjM5NzU5NjI=", "number": 1512, "title": "logits must be 2-dimensional", "user": {"login": "alexhanna", "id": 798477, "node_id": "MDQ6VXNlcjc5ODQ3Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/798477?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexhanna", "html_url": "https://github.com/alexhanna", "followers_url": "https://api.github.com/users/alexhanna/followers", "following_url": "https://api.github.com/users/alexhanna/following{/other_user}", "gists_url": "https://api.github.com/users/alexhanna/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexhanna/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexhanna/subscriptions", "organizations_url": "https://api.github.com/users/alexhanna/orgs", "repos_url": "https://api.github.com/users/alexhanna/repos", "events_url": "https://api.github.com/users/alexhanna/events{/privacy}", "received_events_url": "https://api.github.com/users/alexhanna/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-21T22:52:45Z", "updated_at": "2019-07-19T03:05:29Z", "closed_at": "2019-03-23T01:43:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nI'm trying to perform inference with a tensor2tensor model which I trained and am hosting on Cloud ML Engine. The model takes a text sequence and is supposed to return the next line of \"poetry.\" It's based off [this lab](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/09_sequence/poetry.ipynb).\r\n\r\nI am attempting to use the tensor2tensor serving API to accept a string and perform inference within a notebook. However, I keep getting this error:\r\n\r\n     Error during model execution: AbortionError(code=StatusCode.INVALID_ARGUMENT, details=\"logits must be 2-dimensional\r\n    [[Node: transformer/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/dot_product_attention/attention_weights = Softmax[T=DT_FLOAT, _output_shapes=[[?,4,?,?]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transformer/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/dot_product_attention/add)]]\")\r\n\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Colab\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.5\r\ntensor2tensor==1.11.0\r\ntensorboard==1.13.1\r\ntensorboardcolab==0.0.22\r\ntensorflow==1.13.1\r\ntensorflow-estimator==1.13.0\r\ntensorflow-hub==0.3.0\r\ntensorflow-metadata==0.13.0\r\ntensorflow-probability==0.6.0\r\ntensorflow-serving-api==1.13.0\r\n\r\n$ python -V\r\nPython 2.7.15rc1\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1510", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1510/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1510/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1510/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1510", "id": 423665778, "node_id": "MDU6SXNzdWU0MjM2NjU3Nzg=", "number": 1510, "title": "Code question about transformer for LM problem.", "user": {"login": "guotong1988", "id": 4702353, "node_id": "MDQ6VXNlcjQ3MDIzNTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4702353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guotong1988", "html_url": "https://github.com/guotong1988", "followers_url": "https://api.github.com/users/guotong1988/followers", "following_url": "https://api.github.com/users/guotong1988/following{/other_user}", "gists_url": "https://api.github.com/users/guotong1988/gists{/gist_id}", "starred_url": "https://api.github.com/users/guotong1988/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guotong1988/subscriptions", "organizations_url": "https://api.github.com/users/guotong1988/orgs", "repos_url": "https://api.github.com/users/guotong1988/repos", "events_url": "https://api.github.com/users/guotong1988/events{/privacy}", "received_events_url": "https://api.github.com/users/guotong1988/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-21T10:40:50Z", "updated_at": "2019-03-21T14:35:24Z", "closed_at": "2019-03-21T14:34:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "LM problem only use the decoder.\r\nI find the `shift_right_3d` called in `transformer_prepare_decoder` \r\n![image](https://user-images.githubusercontent.com/4702353/54747027-b1538180-4c08-11e9-8ffc-0250b7ad0c0c.png)\r\nSo the input and target for one sequence is \r\n`target [1,2,3,4]`\r\n`input [0,1,2,3]`\r\n\r\n\r\nOK, no problem.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1508", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1508/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1508/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1508/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1508", "id": 423604163, "node_id": "MDU6SXNzdWU0MjM2MDQxNjM=", "number": 1508, "title": "Watch the exact data value which is feed into tensor2tensor and watch the exact tensor shape.", "user": {"login": "guotong1988", "id": 4702353, "node_id": "MDQ6VXNlcjQ3MDIzNTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4702353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guotong1988", "html_url": "https://github.com/guotong1988", "followers_url": "https://api.github.com/users/guotong1988/followers", "following_url": "https://api.github.com/users/guotong1988/following{/other_user}", "gists_url": "https://api.github.com/users/guotong1988/gists{/gist_id}", "starred_url": "https://api.github.com/users/guotong1988/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guotong1988/subscriptions", "organizations_url": "https://api.github.com/users/guotong1988/orgs", "repos_url": "https://api.github.com/users/guotong1988/repos", "events_url": "https://api.github.com/users/guotong1988/events{/privacy}", "received_events_url": "https://api.github.com/users/guotong1988/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-21T07:46:39Z", "updated_at": "2019-03-21T09:18:16Z", "closed_at": "2019-03-21T09:18:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "I find the code position:\r\n`Python36\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py` 's `predict` methods and `_train_with_estimator_spec` methods.\r\nBut I cannot fetch the tensor I want to print after `sess.run` it.\r\n\r\nIs there any other way to watch the data value and tensor shape, Thank you very much!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1507", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1507/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1507/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1507/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1507", "id": 423597560, "node_id": "MDU6SXNzdWU0MjM1OTc1NjA=", "number": 1507, "title": "Could not find a version that satisfies the requirement jaxlib.", "user": {"login": "KeqiH", "id": 47934222, "node_id": "MDQ6VXNlcjQ3OTM0MjIy", "avatar_url": "https://avatars3.githubusercontent.com/u/47934222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KeqiH", "html_url": "https://github.com/KeqiH", "followers_url": "https://api.github.com/users/KeqiH/followers", "following_url": "https://api.github.com/users/KeqiH/following{/other_user}", "gists_url": "https://api.github.com/users/KeqiH/gists{/gist_id}", "starred_url": "https://api.github.com/users/KeqiH/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KeqiH/subscriptions", "organizations_url": "https://api.github.com/users/KeqiH/orgs", "repos_url": "https://api.github.com/users/KeqiH/repos", "events_url": "https://api.github.com/users/KeqiH/events{/privacy}", "received_events_url": "https://api.github.com/users/KeqiH/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-03-21T07:19:44Z", "updated_at": "2019-04-08T19:12:27Z", "closed_at": "2019-04-08T19:12:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI tried to install tensor2tensor using \"pip install tensor2tensor\", but there is a problem that :\"Could not find a version that satisfies the requirement jaxlib.\"\r\n...\r\n\r\n### Environment information\r\nwin10\r\npython3.6.8 64bit\r\ntensorflow-gpu-1.4.0\r\nCUDA 8.0\r\ncudnn 6.0\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\n\r\n$ python -V\r\n# your output here\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\nCollecting jaxlib (from tensor2tensor)\r\n  Could not find a version that satisfies the requirement jaxlib (from tensor2tensor) (from versions: )\r\nNo matching distribution found for jaxlib (from tensor2tensor)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1506", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1506/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1506/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1506/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1506", "id": 423405079, "node_id": "MDU6SXNzdWU0MjM0MDUwNzk=", "number": 1506, "title": "t2t_decoder hangs when dot_product_relative_v2 is used", "user": {"login": "vidavakil", "id": 1522909, "node_id": "MDQ6VXNlcjE1MjI5MDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1522909?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vidavakil", "html_url": "https://github.com/vidavakil", "followers_url": "https://api.github.com/users/vidavakil/followers", "following_url": "https://api.github.com/users/vidavakil/following{/other_user}", "gists_url": "https://api.github.com/users/vidavakil/gists{/gist_id}", "starred_url": "https://api.github.com/users/vidavakil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vidavakil/subscriptions", "organizations_url": "https://api.github.com/users/vidavakil/orgs", "repos_url": "https://api.github.com/users/vidavakil/repos", "events_url": "https://api.github.com/users/vidavakil/events{/privacy}", "received_events_url": "https://api.github.com/users/vidavakil/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-20T18:20:27Z", "updated_at": "2019-03-22T03:03:26Z", "closed_at": "2019-03-22T03:03:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI am trying to train a custom Transformer model that has a decoder only (with a custom bottom['targets']), for sequence generation. I was able to train and generate from the model when I had not specified any other special params. However, the generated sequences frequently had a failure mode where certain tokens repeated too often. \r\n\r\nI then added the two following params and am training a new model.\r\n  hparams.self_attention_type = \"dot_product_relative_v2\"\r\n  hparams.max_relative_position = 256\r\n\r\nHowever, now when I run t2t_decoder, it hangs and does not generate any output (and it's hard to kill it with ^C, and I have to do a kill -9).\r\nI run the decoder in interactive mode, and simply press the return at the '>' prompt. \r\n\r\nt2t_decoder   --data_dir=\"${DATA_DIR}\"   --decode_hparams=\"${DECODE_HPARAMS}\"   --decode_interactive   --hparams=\"sampling_method=random\"   --hparams_set=${HPARAMS_SET}   --model=${MODEL}   --problem=${PROBLEM}   --output_dir=${TRAIN_DIR}\r\n\r\nwhere:\r\n\r\nDECODE_HPARAMS=\"alpha=0,beam_size=1,extra_length=2048\"\r\nMODEL=transformer\r\n\r\nOS: macOS, High Sierra\r\n\r\n$ pip freeze | grep tensor\r\nError [Errno 20] Not a directory: '/Users/vida_vakil/miniconda3/lib/python3.6/site-packages/magenta-1.0.2-py3.6.egg' while executing command git rev-parse\r\nException: \r\n....\r\nNotADirectoryError: [Errno 20] Not a directory: '/Users/vida_vakil/miniconda3/lib/python3.6/site-packages/magenta-1.0.2-py3.6.egg'\r\n\r\nThe model I am using is based on Score2Perf (https://github.com/tensorflow/magenta/tree/master/magenta/models/score2perf), and I have installed it using instructions from their page, and here: https://github.com/tensorflow/magenta\r\nLooks like the error has to do with the egg thing.\r\n\r\n$ python -V\r\nPython 3.6.6 :: Anaconda, Inc.\r\n\r\ntensorflow   1.12.0\r\ntensor2tensor   1.13.0\r\n\r\nThanks in advance", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1504", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1504/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1504/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1504/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1504", "id": 423114072, "node_id": "MDU6SXNzdWU0MjMxMTQwNzI=", "number": 1504, "title": "How do you fix the unavailable dependency tf-agents in pip install?", "user": {"login": "wushaobo", "id": 491264, "node_id": "MDQ6VXNlcjQ5MTI2NA==", "avatar_url": "https://avatars0.githubusercontent.com/u/491264?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wushaobo", "html_url": "https://github.com/wushaobo", "followers_url": "https://api.github.com/users/wushaobo/followers", "following_url": "https://api.github.com/users/wushaobo/following{/other_user}", "gists_url": "https://api.github.com/users/wushaobo/gists{/gist_id}", "starred_url": "https://api.github.com/users/wushaobo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wushaobo/subscriptions", "organizations_url": "https://api.github.com/users/wushaobo/orgs", "repos_url": "https://api.github.com/users/wushaobo/repos", "events_url": "https://api.github.com/users/wushaobo/events{/privacy}", "received_events_url": "https://api.github.com/users/wushaobo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-20T07:56:58Z", "updated_at": "2019-03-27T05:57:53Z", "closed_at": "2019-03-21T21:39:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "I think you have noticed that there is no release available for tf-agents pip library to install since Feb.  I notice it is still one of the dependencies in setup.py on master branch rather than the new name tf-agents-nightly.  \r\nI am really wondering how your pip install on the 1.13.0 (latest version) can complete successfully. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1502", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1502/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1502/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1502/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1502", "id": 422618141, "node_id": "MDU6SXNzdWU0MjI2MTgxNDE=", "number": 1502, "title": "May I ask a simple question: what is the difference/relation between neg_log_perplexity and perplexity?", "user": {"login": "guotong1988", "id": 4702353, "node_id": "MDQ6VXNlcjQ3MDIzNTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4702353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guotong1988", "html_url": "https://github.com/guotong1988", "followers_url": "https://api.github.com/users/guotong1988/followers", "following_url": "https://api.github.com/users/guotong1988/following{/other_user}", "gists_url": "https://api.github.com/users/guotong1988/gists{/gist_id}", "starred_url": "https://api.github.com/users/guotong1988/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guotong1988/subscriptions", "organizations_url": "https://api.github.com/users/guotong1988/orgs", "repos_url": "https://api.github.com/users/guotong1988/repos", "events_url": "https://api.github.com/users/guotong1988/events{/privacy}", "received_events_url": "https://api.github.com/users/guotong1988/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-19T09:15:10Z", "updated_at": "2019-03-24T23:06:22Z", "closed_at": "2019-03-24T23:06:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thank you very much.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1496", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1496/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1496/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1496/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1496", "id": 422003938, "node_id": "MDU6SXNzdWU0MjIwMDM5Mzg=", "number": 1496, "title": "ImportError: cannot import name 'summary_op_util'", "user": {"login": "guotong1988", "id": 4702353, "node_id": "MDQ6VXNlcjQ3MDIzNTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4702353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guotong1988", "html_url": "https://github.com/guotong1988", "followers_url": "https://api.github.com/users/guotong1988/followers", "following_url": "https://api.github.com/users/guotong1988/following{/other_user}", "gists_url": "https://api.github.com/users/guotong1988/gists{/gist_id}", "starred_url": "https://api.github.com/users/guotong1988/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guotong1988/subscriptions", "organizations_url": "https://api.github.com/users/guotong1988/orgs", "repos_url": "https://api.github.com/users/guotong1988/repos", "events_url": "https://api.github.com/users/guotong1988/events{/privacy}", "received_events_url": "https://api.github.com/users/guotong1988/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-18T01:43:55Z", "updated_at": "2019-03-27T00:50:04Z", "closed_at": "2019-03-27T00:50:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Tensorflow version\uff1a\r\n`1.13.1-cpu-windows`\r\n\r\nProject git version:\r\n`8d93b2eb65d30a36a1b14ba861fd2a3c59c56d0f`\r\n\r\nError log:\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/Users/gt/Desktop/tensor2tensor-master/tensor2tensor/bin/t2t_trainer.py\", line 25, in <module>\r\n    from tensor2tensor import models  # pylint: disable=unused-import\r\n  File \"C:\\Users\\gt\\Desktop\\tensor2tensor-master\\tensor2tensor\\models\\__init__.py\", line 58, in <module>\r\n    from tensor2tensor.models.research import rl\r\n  File \"C:\\Users\\gt\\Desktop\\tensor2tensor-master\\tensor2tensor\\models\\research\\rl.py\", line 31, in <module>\r\n    from tensor2tensor.models.video import basic_deterministic_params\r\n  File \"C:\\Users\\gt\\Desktop\\tensor2tensor-master\\tensor2tensor\\models\\video\\basic_deterministic_params.py\", line 22, in <module>\r\n    from tensor2tensor.models.video import base\r\n  File \"C:\\Users\\gt\\Desktop\\tensor2tensor-master\\tensor2tensor\\models\\video\\base.py\", line 27, in <module>\r\n    from tensor2tensor.layers import common_video\r\n  File \"C:\\Users\\gt\\Desktop\\tensor2tensor-master\\tensor2tensor\\layers\\common_video.py\", line 27, in <module>\r\n    from tensorflow.python.distribute import summary_op_util as distribute_summary_op_util  # pylint: disable=g-direct-tensorflow-import\r\nImportError: cannot import name 'summary_op_util'\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1489", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1489/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1489/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1489/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1489", "id": 421113511, "node_id": "MDU6SXNzdWU0MjExMTM1MTE=", "number": 1489, "title": "TF Serving padding issue for Transformer", "user": {"login": "oleg-yaroshevskiy", "id": 5859692, "node_id": "MDQ6VXNlcjU4NTk2OTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/5859692?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oleg-yaroshevskiy", "html_url": "https://github.com/oleg-yaroshevskiy", "followers_url": "https://api.github.com/users/oleg-yaroshevskiy/followers", "following_url": "https://api.github.com/users/oleg-yaroshevskiy/following{/other_user}", "gists_url": "https://api.github.com/users/oleg-yaroshevskiy/gists{/gist_id}", "starred_url": "https://api.github.com/users/oleg-yaroshevskiy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oleg-yaroshevskiy/subscriptions", "organizations_url": "https://api.github.com/users/oleg-yaroshevskiy/orgs", "repos_url": "https://api.github.com/users/oleg-yaroshevskiy/repos", "events_url": "https://api.github.com/users/oleg-yaroshevskiy/events{/privacy}", "received_events_url": "https://api.github.com/users/oleg-yaroshevskiy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-14T16:13:37Z", "updated_at": "2020-04-10T03:27:48Z", "closed_at": "2019-03-16T10:25:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \r\nFor long time I'm trying to solve problem with tf serving for transformer nmt model inference. So let's assume I create simple signature: \r\n\r\n```\r\ninputs = tf.placeholder(dtype=tf.int64, shape=[None, None], name=\"input_logits\")\r\nfeatures = {\"inputs\": standardize_shapes(inputs)}\r\n\r\n        return tf.estimator.export.ServingInputReceiver(\r\n            features=features, receiver_tensors=inputs)\r\n\r\n```\r\nand everything works well.\r\nThen I want to enable batching and due to different sequence lengths I set \r\n`pad_variable_length_inputs: true ` in batching.config file.\r\nThats where the problem starts. Serving returns garbage for short sequences f.e:\r\n```\r\nfirst (1, 18) {'instances': [{'inputs': [336, 201, 506, 26, 1902, 2339, 6677, 13748, 14, 55, 11864, 3258, 7380, 1368, 2770, 26172, 662, 1]}]} enfr {\r\n    \"predictions\": [\r\n        {\r\n            \"outputs\": [367, 169, 1306, 2, 37, 10043, 301, 19606, 4, 19005, 151, 85, 15888, 11427, 20653, 5131, 21936, 16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\r\n            \"scores\": -9.25369\r\n        }\r\n    ]\r\n}\r\n\r\nsecond (1, 3) {'instances': [{'inputs': [1544, 657, 1]}]} enfr {\r\n    \"predictions\": [\r\n        {\r\n            \"outputs\": [2865, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 1141, 2865, 2865, 2865, 2865, 2865, 2865, 2865, 2865, 2865, 2865, 2865, 2865, 2865, 1],\r\n            \"scores\": -28.8886\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\nas we can see a longer one was predicted well and for short one it messed up with repeated tokens. This can't be reproduced for single element inference or out of tf serving env.\r\n\r\nExample after decoding:\r\n```\r\n['Made from steel']->['MadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeM\r\nadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMadeMa\r\ndeMadeMadeMadeMadeMademade.']\r\n```\r\n\r\nAny idea? Is it related to tf-serving padding? Or not the best input signature?\r\nGive me a clue,\r\nthanks.\r\n\r\n### Environment information\r\ntf serving 1.13.0\r\ntensor2tensor==1.6.6", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1488", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1488/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1488/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1488/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1488", "id": 420876731, "node_id": "MDU6SXNzdWU0MjA4NzY3MzE=", "number": 1488, "title": "Can t2t-decoder read a pb file for predict?", "user": {"login": "Mr-wang2016", "id": 22363893, "node_id": "MDQ6VXNlcjIyMzYzODkz", "avatar_url": "https://avatars3.githubusercontent.com/u/22363893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mr-wang2016", "html_url": "https://github.com/Mr-wang2016", "followers_url": "https://api.github.com/users/Mr-wang2016/followers", "following_url": "https://api.github.com/users/Mr-wang2016/following{/other_user}", "gists_url": "https://api.github.com/users/Mr-wang2016/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mr-wang2016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mr-wang2016/subscriptions", "organizations_url": "https://api.github.com/users/Mr-wang2016/orgs", "repos_url": "https://api.github.com/users/Mr-wang2016/repos", "events_url": "https://api.github.com/users/Mr-wang2016/events{/privacy}", "received_events_url": "https://api.github.com/users/Mr-wang2016/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-14T07:55:58Z", "updated_at": "2019-04-28T01:40:37Z", "closed_at": "2019-04-28T01:40:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi\uff1a\r\nt2t version: 1.11\r\nAs far as i know, now t2t-decoder read checkpoint file with Estimator.predict. the code is 'saver.restore(sess, checkpoint_filename_with_path)', i want a smaller model file so i turn checkpoint file to a pb file use t2t-exporter, pb file size smaller 2/3 then checkpoint file. I can't use tensorflow serving with pb now, so can t2t-decoder read pb file?\r\nthanks so much !!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1483", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1483/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1483/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1483/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1483", "id": 420138395, "node_id": "MDU6SXNzdWU0MjAxMzgzOTU=", "number": 1483, "title": "code for \"Model-Based Reinforcement Learning for Atari\"", "user": {"login": "daiwk", "id": 4243530, "node_id": "MDQ6VXNlcjQyNDM1MzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/4243530?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daiwk", "html_url": "https://github.com/daiwk", "followers_url": "https://api.github.com/users/daiwk/followers", "following_url": "https://api.github.com/users/daiwk/following{/other_user}", "gists_url": "https://api.github.com/users/daiwk/gists{/gist_id}", "starred_url": "https://api.github.com/users/daiwk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daiwk/subscriptions", "organizations_url": "https://api.github.com/users/daiwk/orgs", "repos_url": "https://api.github.com/users/daiwk/repos", "events_url": "https://api.github.com/users/daiwk/events{/privacy}", "received_events_url": "https://api.github.com/users/daiwk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-12T18:20:57Z", "updated_at": "2019-03-13T17:25:22Z", "closed_at": "2019-03-12T18:25:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "where can i find the code for \"Model-Based Reinforcement Learning for Atari\" https://arxiv.org/pdf/1903.00374.pdf\r\nwhich said the code is in https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/rl\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1482", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1482/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1482/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1482/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1482", "id": 419980884, "node_id": "MDU6SXNzdWU0MTk5ODA4ODQ=", "number": 1482, "title": "reduce t2t nmt model size", "user": {"login": "Mr-wang2016", "id": 22363893, "node_id": "MDQ6VXNlcjIyMzYzODkz", "avatar_url": "https://avatars3.githubusercontent.com/u/22363893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mr-wang2016", "html_url": "https://github.com/Mr-wang2016", "followers_url": "https://api.github.com/users/Mr-wang2016/followers", "following_url": "https://api.github.com/users/Mr-wang2016/following{/other_user}", "gists_url": "https://api.github.com/users/Mr-wang2016/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mr-wang2016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mr-wang2016/subscriptions", "organizations_url": "https://api.github.com/users/Mr-wang2016/orgs", "repos_url": "https://api.github.com/users/Mr-wang2016/repos", "events_url": "https://api.github.com/users/Mr-wang2016/events{/privacy}", "received_events_url": "https://api.github.com/users/Mr-wang2016/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-03-12T13:17:38Z", "updated_at": "2019-03-13T12:52:13Z", "closed_at": "2019-03-13T12:52:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi:\r\n\r\n   I trained a nmt model use t2t  with vocab size 32000, the nmt model size is about 1.2G, I think it is a little big, so how can i reduce the size of my model with little loss about blue? Any Suggestions would be appreciated, thanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1477", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1477/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1477/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1477/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1477", "id": 418092339, "node_id": "MDU6SXNzdWU0MTgwOTIzMzk=", "number": 1477, "title": "RFC: What do you think about TRAX? How do we make the next T2T really good?", "user": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-07T01:57:11Z", "updated_at": "2019-03-07T01:57:22Z", "closed_at": "2019-03-07T01:57:22Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "### Description\r\n\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\n\r\n$ python -V\r\n# your output here\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1472", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1472/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1472/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1472/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1472", "id": 414868439, "node_id": "MDU6SXNzdWU0MTQ4Njg0Mzk=", "number": 1472, "title": "Dependency mismatch for Cloud ML Engine runtime 1.12", "user": {"login": "jvmncs", "id": 7891333, "node_id": "MDQ6VXNlcjc4OTEzMzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/7891333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jvmncs", "html_url": "https://github.com/jvmncs", "followers_url": "https://api.github.com/users/jvmncs/followers", "following_url": "https://api.github.com/users/jvmncs/following{/other_user}", "gists_url": "https://api.github.com/users/jvmncs/gists{/gist_id}", "starred_url": "https://api.github.com/users/jvmncs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jvmncs/subscriptions", "organizations_url": "https://api.github.com/users/jvmncs/orgs", "repos_url": "https://api.github.com/users/jvmncs/repos", "events_url": "https://api.github.com/users/jvmncs/events{/privacy}", "received_events_url": "https://api.github.com/users/jvmncs/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-02-26T23:21:49Z", "updated_at": "2020-03-19T06:50:33Z", "closed_at": "2019-03-21T21:16:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nTensorFlow Probability has just released 0.6.0 to PyPI, which expects TF 1.13.1.  The current Runtime Version on Cloud ML Engine comes with TF 1.12.0.  Without either:\r\n1. upgrading the default tensorflow version to 1.13.1 on ML Engine, or\r\n2. downgrading the version of tensorflow-probability to 0.5.0,\r\njobs cannot currently be submitted to ML Engine.\r\n\r\nFWIW, I already tried specifying both of these in the requirements.txt file of my t2t_usr_dir package with no change in error output, so I'm assuming these requirements.txt are superseded by the versions imposed by PyPI.\r\n\r\n### Environment information\r\nCloud ML Engine Runtime Version 1.12\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n#### Steps to reproduce:\r\nSubmit any `t2t-trainer` job to Cloud ML Engine.\r\n\r\n#### Error logs:\r\n```\r\nThe replica master 0 exited with a non-zero status of 1. \r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/root/.local/lib/python3.5/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 24, in <module>\r\n    from tensor2tensor import models  # pylint: disable=unused-import\r\n  File \"/root/.local/lib/python3.5/site-packages/tensor2tensor/models/__init__.py\", line 25, in <module>\r\n    from tensor2tensor.layers import modalities  # pylint: disable=g-import-not-at-top\r\n  File \"/root/.local/lib/python3.5/site-packages/tensor2tensor/layers/modalities.py\", line 22, in <module>\r\n    from tensor2tensor.layers import common_attention\r\n  File \"/root/.local/lib/python3.5/site-packages/tensor2tensor/layers/common_attention.py\", line 31, in <module>\r\n    from tensor2tensor.layers import common_layers\r\n  File \"/root/.local/lib/python3.5/site-packages/tensor2tensor/layers/common_layers.py\", line 30, in <module>\r\n    import tensorflow_probability as tfp\r\n  File \"/root/.local/lib/python3.5/site-packages/tensorflow_probability/__init__.py\", line 68, in <module>\r\n    _ensure_tf_install()\r\n  File \"/root/.local/lib/python3.5/site-packages/tensorflow_probability/__init__.py\", line 65, in _ensure_tf_install\r\n    present=tf.__version__))\r\nImportError: This version of TensorFlow Probability requires TensorFlow version >= 1.13.1; Detected an installation of version 1.12.0. Please upgrade TensorFlow to proceed.\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1467", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1467/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1467/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1467/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1467", "id": 413812347, "node_id": "MDU6SXNzdWU0MTM4MTIzNDc=", "number": 1467, "title": "The scores of beam search are negative? ", "user": {"login": "111xumengze", "id": 28833644, "node_id": "MDQ6VXNlcjI4ODMzNjQ0", "avatar_url": "https://avatars0.githubusercontent.com/u/28833644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/111xumengze", "html_url": "https://github.com/111xumengze", "followers_url": "https://api.github.com/users/111xumengze/followers", "following_url": "https://api.github.com/users/111xumengze/following{/other_user}", "gists_url": "https://api.github.com/users/111xumengze/gists{/gist_id}", "starred_url": "https://api.github.com/users/111xumengze/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/111xumengze/subscriptions", "organizations_url": "https://api.github.com/users/111xumengze/orgs", "repos_url": "https://api.github.com/users/111xumengze/repos", "events_url": "https://api.github.com/users/111xumengze/events{/privacy}", "received_events_url": "https://api.github.com/users/111xumengze/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-24T11:40:46Z", "updated_at": "2019-02-24T12:38:14Z", "closed_at": "2019-02-24T12:38:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\n\r\n$ python -V\r\n# your output here\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1450", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1450/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1450/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1450/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1450", "id": 409752624, "node_id": "MDU6SXNzdWU0MDk3NTI2MjQ=", "number": 1450, "title": "Appending extra words to source vocabulary does not affect translation?", "user": {"login": "lkluo", "id": 26020832, "node_id": "MDQ6VXNlcjI2MDIwODMy", "avatar_url": "https://avatars3.githubusercontent.com/u/26020832?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lkluo", "html_url": "https://github.com/lkluo", "followers_url": "https://api.github.com/users/lkluo/followers", "following_url": "https://api.github.com/users/lkluo/following{/other_user}", "gists_url": "https://api.github.com/users/lkluo/gists{/gist_id}", "starred_url": "https://api.github.com/users/lkluo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lkluo/subscriptions", "organizations_url": "https://api.github.com/users/lkluo/orgs", "repos_url": "https://api.github.com/users/lkluo/repos", "events_url": "https://api.github.com/users/lkluo/events{/privacy}", "received_events_url": "https://api.github.com/users/lkluo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-13T11:13:54Z", "updated_at": "2019-02-18T04:14:14Z", "closed_at": "2019-02-18T04:14:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "Suppose the vocabulary is built based on train data, and t2t model is also trained with them. Now I append some words at the tail of source vocabulary (the total units are below a size threshold and the extra words are independent from each other), it should not affect the translation results, right? (My experiments supposed this, but I just want to double confirm).if so, then t2t must generate a fixed size word vector for embedding look up, right?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1449", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1449/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1449/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1449/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1449", "id": 409687347, "node_id": "MDU6SXNzdWU0MDk2ODczNDc=", "number": 1449, "title": "ImportError: No module named 'mesh_tensorflow.transformer'", "user": {"login": "stefan-falk", "id": 43335432, "node_id": "MDQ6VXNlcjQzMzM1NDMy", "avatar_url": "https://avatars1.githubusercontent.com/u/43335432?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stefan-falk", "html_url": "https://github.com/stefan-falk", "followers_url": "https://api.github.com/users/stefan-falk/followers", "following_url": "https://api.github.com/users/stefan-falk/following{/other_user}", "gists_url": "https://api.github.com/users/stefan-falk/gists{/gist_id}", "starred_url": "https://api.github.com/users/stefan-falk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stefan-falk/subscriptions", "organizations_url": "https://api.github.com/users/stefan-falk/orgs", "repos_url": "https://api.github.com/users/stefan-falk/repos", "events_url": "https://api.github.com/users/stefan-falk/events{/privacy}", "received_events_url": "https://api.github.com/users/stefan-falk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-13T08:41:16Z", "updated_at": "2019-02-13T08:45:50Z", "closed_at": "2019-02-13T08:45:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### Description\r\n\r\nImporting `t2t_trainer` is not working in `1.12.0`.\r\n\r\nI have just updated my t2t version to `1.12.0` and noticed that I cannot import `t2t_trainer` anymor as I am getting\r\n\r\n> `ImportError: No module named 'mesh_tensorflow.transformer'`\r\n\r\nwhich was not the case in `1.11.0`.\r\n...\r\n\r\n### Reproduce\r\n\r\n```python\r\nfrom tensor2tensor.bin import t2t_trainer\r\n\r\nif __name__ == '__main__':\r\n    t2t_trainer.main(None)\r\n```\r\n\r\n### Stack trace\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/sfalk/tmp/pycharm_project_265/asr/punctuation/test.py\", line 1, in <module>\r\n    from tensor2tensor.bin import t2t_trainer\r\n  File \"/home/sfalk/miniconda3/envs/t2t/lib/python3.5/site-packages/tensor2tensor/bin/t2t_trainer.py\", line 24, in <module>\r\n    from tensor2tensor import models  # pylint: disable=unused-import\r\n  File \"/home/sfalk/miniconda3/envs/t2t/lib/python3.5/site-packages/tensor2tensor/models/__init__.py\", line 35, in <module>\r\n    from tensor2tensor.models import mtf_transformer2\r\n  File \"/home/sfalk/miniconda3/envs/t2t/lib/python3.5/site-packages/tensor2tensor/models/mtf_transformer2.py\", line 23, in <module>\r\n    from mesh_tensorflow.transformer import moe\r\nImportError: No module named 'mesh_tensorflow.transformer'\r\n```\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Linux 4.15.0-45-generic #48~16.04.1-Ubuntu SMP Tue Jan 29 18:03:48 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.4\r\ntensor2tensor==1.12.0\r\ntensorboard==1.12.0\r\ntensorflow-gpu==1.12.0\r\ntensorflow-metadata==0.9.0\r\ntensorflow-probability==0.5.0\r\n\r\n$ python -V\r\nPython 3.5.6 :: Anaconda, Inc.\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1437", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1437/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1437/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1437/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1437", "id": 406753567, "node_id": "MDU6SXNzdWU0MDY3NTM1Njc=", "number": 1437, "title": "Tensor2tensor transformer division by zero error", "user": {"login": "Erra-Ernesto", "id": 46380181, "node_id": "MDQ6VXNlcjQ2MzgwMTgx", "avatar_url": "https://avatars2.githubusercontent.com/u/46380181?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Erra-Ernesto", "html_url": "https://github.com/Erra-Ernesto", "followers_url": "https://api.github.com/users/Erra-Ernesto/followers", "following_url": "https://api.github.com/users/Erra-Ernesto/following{/other_user}", "gists_url": "https://api.github.com/users/Erra-Ernesto/gists{/gist_id}", "starred_url": "https://api.github.com/users/Erra-Ernesto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Erra-Ernesto/subscriptions", "organizations_url": "https://api.github.com/users/Erra-Ernesto/orgs", "repos_url": "https://api.github.com/users/Erra-Ernesto/repos", "events_url": "https://api.github.com/users/Erra-Ernesto/events{/privacy}", "received_events_url": "https://api.github.com/users/Erra-Ernesto/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-05T12:09:59Z", "updated_at": "2020-01-16T07:14:59Z", "closed_at": "2019-02-05T16:36:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm very new to Tensor2Tensor and am trying to use Transformer model to decode a english text in italian text. For now i have training the model on Google Colab. Now i want translate a file in my local machine (with Windows 7) with checkpoints that i have obtained on Colab e I have download in local machine. I have execute on cmd prompt the follow code\r\n\r\nC:\\Users\\My-name>python /Users/My-name/TranslatorApp/t2t_app/tensor2tensor/bin/t\r\n2t-decoder --t2t_usr_dir=/Users/My-name/TranslatorApp/t2t_app/usrdir --data_dir=\r\n/Users/My-name/TranslatorApp/t2t_data_enit32k --problem=translate_enit_wmt32k --\r\nmodel=transformer --hparams_set=transformer_base_single_gpu --output_dir=/Users/\r\nMy-name/TranslatorApp/checkpoint/model_checkpoint --decode_hparams=\"beam_size=4,\r\nalpha=0.6\" --decode_from_file=/Users/My-name/da_tradurre.en --decode_to_file=/Us\r\ners/My-name/tradotto.it\r\n\r\nAnd I have how response an error of division by zero, as shown below:\r\n\r\nINFO:tensorflow:Importing user module usrdir from path C:\\Users\\My-name\\Translat\r\norApp\\t2t_app\r\nWARNING:tensorflow:From C:\\Users\\My-name\\Anaconda3\\lib\\site-packages\\tensor2tens\r\nor\\utils\\trainer_lib.py:198: RunConfig.__init__ (from tensorflow.contrib.learn.p\r\nython.learn.estimators.run_config) is deprecated and will be removed in a future\r\n version.\r\nInstructions for updating:\r\nWhen switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\r\nINFO:tensorflow:schedule=continuous_train_and_eval\r\nINFO:tensorflow:worker_gpu=1\r\nINFO:tensorflow:sync=False\r\nWARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is\r\n running on a single machine.\r\nINFO:tensorflow:datashard_devices: ['gpu:0']\r\nINFO:tensorflow:caching_devices: None\r\nINFO:tensorflow:ps_devices: ['gpu:0']\r\nINFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec\r\n': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000001D3E5B\r\nA8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environm\r\nent': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute':\r\n None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\r\n\r\n  per_process_gpu_memory_fraction: 1.0\r\n}\r\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs':\r\n None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_o\r\nptions {\r\n  per_process_gpu_memory_fraction: 0.95\r\n}\r\nallow_soft_placement: true\r\ngraph_options {\r\n  optimizer_options {\r\n  }\r\n}\r\n, '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint\r\n_every_n_hours': 10000, '_model_dir': '/Users/My-name/TranslatorApp/checkpoint/m\r\nodel_checkpoint', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}\r\n, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x\r\n000000001D3E5C18>}\r\nWARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model\r\n_fn.<locals>.wrapping_model_fn at 0x00000000190E6840>) includes params argument,\r\n but params are not passed to Estimator.\r\nINFO:tensorflow:decode_hp.batch_size not specified; default=32\r\nINFO:tensorflow:Performing decoding from a file.\r\nINFO:tensorflow:Getting sorted inputs\r\nINFO:tensorflow: batch 0\r\nINFO:tensorflow:Elapsed Time: 0.06900\r\nTraceback (most recent call last):\r\n  File \"/Users/My-name/TranslatorApp/t2t_app/tensor2tensor/bin/t2t-decoder\", lin\r\ne 17, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\My-name\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\\r\napp.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/Users/My-name/TranslatorApp/t2t_app/tensor2tensor/bin/t2t-decoder\", lin\r\ne 12, in main\r\n    t2t_decoder.main(argv)\r\n  File \"C:\\Users\\My-name\\Anaconda3\\lib\\site-packages\\tensor2tensor\\bin\\t2t_decod\r\ner.py\", line 190, in main\r\n    decode(estimator, hp, decode_hp)\r\n  File \"C:\\Users\\My-name\\Anaconda3\\lib\\site-packages\\tensor2tensor\\bin\\t2t_decod\r\ner.py\", line 90, in decode\r\n    checkpoint_path=FLAGS.checkpoint_path)\r\n  File \"C:\\Users\\My-name\\Anaconda3\\lib\\site-packages\\tensor2tensor\\utils\\decodin\r\ng.py\", line 412, in decode_from_file\r\n    (total_time_per_step / total_cnt))\r\nZeroDivisionError: division by zero\r\n\r\nPlease can you help me to solve this error?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1434", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1434/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1434/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1434/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1434", "id": 406181033, "node_id": "MDU6SXNzdWU0MDYxODEwMzM=", "number": 1434, "title": "Regarding tflops/sec", "user": {"login": "Raviteja1996", "id": 17984785, "node_id": "MDQ6VXNlcjE3OTg0Nzg1", "avatar_url": "https://avatars3.githubusercontent.com/u/17984785?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Raviteja1996", "html_url": "https://github.com/Raviteja1996", "followers_url": "https://api.github.com/users/Raviteja1996/followers", "following_url": "https://api.github.com/users/Raviteja1996/following{/other_user}", "gists_url": "https://api.github.com/users/Raviteja1996/gists{/gist_id}", "starred_url": "https://api.github.com/users/Raviteja1996/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Raviteja1996/subscriptions", "organizations_url": "https://api.github.com/users/Raviteja1996/orgs", "repos_url": "https://api.github.com/users/Raviteja1996/repos", "events_url": "https://api.github.com/users/Raviteja1996/events{/privacy}", "received_events_url": "https://api.github.com/users/Raviteja1996/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-04T04:51:13Z", "updated_at": "2019-02-05T08:57:51Z", "closed_at": "2019-02-05T08:57:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am new to this and don't know much about it. So, can anyone help me how to calculate \"Tflops/sec\" in tensor2tensor.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1433", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1433/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1433/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1433/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1433", "id": 406163028, "node_id": "MDU6SXNzdWU0MDYxNjMwMjg=", "number": 1433, "title": "assertionerror", "user": {"login": "woonsangcho", "id": 21053926, "node_id": "MDQ6VXNlcjIxMDUzOTI2", "avatar_url": "https://avatars3.githubusercontent.com/u/21053926?v=4", "gravatar_id": "", "url": "https://api.github.com/users/woonsangcho", "html_url": "https://github.com/woonsangcho", "followers_url": "https://api.github.com/users/woonsangcho/followers", "following_url": "https://api.github.com/users/woonsangcho/following{/other_user}", "gists_url": "https://api.github.com/users/woonsangcho/gists{/gist_id}", "starred_url": "https://api.github.com/users/woonsangcho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/woonsangcho/subscriptions", "organizations_url": "https://api.github.com/users/woonsangcho/orgs", "repos_url": "https://api.github.com/users/woonsangcho/repos", "events_url": "https://api.github.com/users/woonsangcho/events{/privacy}", "received_events_url": "https://api.github.com/users/woonsangcho/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-04T02:33:30Z", "updated_at": "2019-02-04T03:32:01Z", "closed_at": "2019-02-04T03:32:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1429", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1429/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1429/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1429/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1429", "id": 405969350, "node_id": "MDU6SXNzdWU0MDU5NjkzNTA=", "number": 1429, "title": "Change hparams hidden_size dimension", "user": {"login": "Eugen2525", "id": 13747115, "node_id": "MDQ6VXNlcjEzNzQ3MTE1", "avatar_url": "https://avatars3.githubusercontent.com/u/13747115?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Eugen2525", "html_url": "https://github.com/Eugen2525", "followers_url": "https://api.github.com/users/Eugen2525/followers", "following_url": "https://api.github.com/users/Eugen2525/following{/other_user}", "gists_url": "https://api.github.com/users/Eugen2525/gists{/gist_id}", "starred_url": "https://api.github.com/users/Eugen2525/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Eugen2525/subscriptions", "organizations_url": "https://api.github.com/users/Eugen2525/orgs", "repos_url": "https://api.github.com/users/Eugen2525/repos", "events_url": "https://api.github.com/users/Eugen2525/events{/privacy}", "received_events_url": "https://api.github.com/users/Eugen2525/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-02-02T10:10:50Z", "updated_at": "2019-02-02T10:54:19Z", "closed_at": "2019-02-02T10:54:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nSo l want to change the 'hidden_size' of the hparam after I initialize it with the below code: \r\n\r\n```\r\nfrom tensor2tensor.models import transformer\r\nimport tensorflow as tf\r\n\r\nhparams = transformer.transformer_base()\r\n\r\n```\r\nHow can this be done?\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor \r\n# your output here\r\ntensorboard==1.12.2\r\ntensorflow-gpu==1.12.0\r\n$ python -V\r\n# your output here\r\n```\r\nPython 2.7.15 :: Anaconda, Inc.\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1427", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1427/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1427/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1427/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1427", "id": 405936573, "node_id": "MDU6SXNzdWU0MDU5MzY1NzM=", "number": 1427, "title": "output the n-best translation  ", "user": {"login": "shiny1022", "id": 45384372, "node_id": "MDQ6VXNlcjQ1Mzg0Mzcy", "avatar_url": "https://avatars1.githubusercontent.com/u/45384372?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shiny1022", "html_url": "https://github.com/shiny1022", "followers_url": "https://api.github.com/users/shiny1022/followers", "following_url": "https://api.github.com/users/shiny1022/following{/other_user}", "gists_url": "https://api.github.com/users/shiny1022/gists{/gist_id}", "starred_url": "https://api.github.com/users/shiny1022/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shiny1022/subscriptions", "organizations_url": "https://api.github.com/users/shiny1022/orgs", "repos_url": "https://api.github.com/users/shiny1022/repos", "events_url": "https://api.github.com/users/shiny1022/events{/privacy}", "received_events_url": "https://api.github.com/users/shiny1022/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-02-02T02:09:07Z", "updated_at": "2019-09-26T06:06:38Z", "closed_at": "2019-03-08T03:12:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI use the universal transformer to train the EN-DE translation system. Now I want to output the n-best translation result.  How should I set the decoding parameters?\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1408", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1408/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1408/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1408/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1408", "id": 402741560, "node_id": "MDU6SXNzdWU0MDI3NDE1NjA=", "number": 1408, "title": "{BUG} High Validation Accuracy but rubbish decoding", "user": {"login": "agemagician", "id": 6087313, "node_id": "MDQ6VXNlcjYwODczMTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6087313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agemagician", "html_url": "https://github.com/agemagician", "followers_url": "https://api.github.com/users/agemagician/followers", "following_url": "https://api.github.com/users/agemagician/following{/other_user}", "gists_url": "https://api.github.com/users/agemagician/gists{/gist_id}", "starred_url": "https://api.github.com/users/agemagician/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agemagician/subscriptions", "organizations_url": "https://api.github.com/users/agemagician/orgs", "repos_url": "https://api.github.com/users/agemagician/repos", "events_url": "https://api.github.com/users/agemagician/events{/privacy}", "received_events_url": "https://api.github.com/users/agemagician/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 22, "created_at": "2019-01-24T14:48:46Z", "updated_at": "2020-02-04T18:09:36Z", "closed_at": "2019-04-29T07:39:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI implemented a new problem and while training I get high accuracy more than 80%, but during decoding I got rubbish. Is there a bug in decoding ?\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Ubuntu\r\n\r\n$ pip freeze | grep tensor\r\nmesh-tensorflow==0.0.4\r\ntensor2tensor==1.11.0\r\ntensorboard==1.12.0\r\ntensorflow==1.12.0\r\ntensorflow-metadata==0.9.0\r\ntensorflow-probability==0.5.0\r\n\r\n$ python -V\r\nPython 2.7.15 :: Anaconda, Inc.\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n# Steps to reproduce:\r\n```\r\n@registry.register_hparams\r\ndef transformer_base_single_gpu_protein():\r\n  \"\"\"HParams for transformer base model for single GPU.\"\"\"\r\n  hparams = transformer_base()\r\n  hparams.batch_size = 256\r\n  hparams.max_length = 4096\r\n  hparams.learning_rate_warmup_steps = 16000\r\n  return hparams\r\n```\r\n```\r\n@registry.register_problem\r\nclass TranslateAminoProtinTokensSharedVocab(text_problems.Text2TextProblem):\r\n\r\n  @property\r\n  def approx_vocab_size(self):\r\n    return 2**13  # 8192\r\n\r\n  @property\r\n  def is_generate_per_split(self):\r\n    return False\r\n\r\n  @property\r\n  def dataset_splits(self):\r\n    return [{\r\n        \"split\": problem.DatasetSplit.TRAIN,\r\n        \"shards\": 9,\r\n    }, {\r\n        \"split\": problem.DatasetSplit.EVAL,\r\n        \"shards\": 1,\r\n    }]\r\n\r\n  def eval_metrics(self):\r\n    return [\r\n        metrics.Metrics.ACC,\r\n        metrics.Metrics.ACC_TOP5,\r\n        metrics.Metrics.ACC_PER_SEQ,\r\n        metrics.Metrics.NEG_LOG_PERPLEXITY,\r\n        metrics.Metrics.ROUGE_L_F,\r\n        metrics.Metrics.APPROX_BLEU,\r\n        metrics.Metrics.APPROX_Q3\r\n    ]\r\n\r\n  def generate_samples(self, data_dir, tmp_dir, dataset_split):\r\n       datasetdf = pd.read_csv(tmp_dir + '/complete_train_dataset_seperated.csv')\r\n       for index, row in datasetdf.iterrows():\r\n         yield {\r\n         \"inputs\": row['input'],\r\n         \"targets\": row['output'],\r\n         }\r\n```\r\n```\r\nimport numpy as np\r\nfrom sklearn.metrics import accuracy_score\r\nimport tensorflow as tf\r\n\r\ndef computeQ3ApproxAccuracy(targets, predictions):\r\n    accs = []\r\n    for (references, translations) in zip(targets, predictions):\r\n        \r\n        referencesLength = len(references)\r\n        translationsLength = len(translations)\r\n        if (referencesLength > translationsLength):\r\n            translations += [-1] * (referencesLength - translationsLength)\r\n        \r\n        if (translationsLength > referencesLength):\r\n            references += [-1] * (translationsLength - referencesLength)\r\n        \r\n        accs.append(accuracy_score(references, translations))\r\n    return np.float32(np.mean(accs))\r\n\r\n\r\ndef q3_score(predictions, labels, **unused_kwargs):\r\n  outputs = tf.to_int32(tf.argmax(predictions, axis=-1))\r\n  # Convert the outputs and labels to a [batch_size, input_length] tensor.\r\n  outputs = tf.squeeze(outputs, axis=[-1, -2])\r\n  labels = tf.squeeze(labels, axis=[-1, -2])\r\n\r\n  q3 = tf.py_func(computeQ3ApproxAccuracy, (labels, outputs), tf.float32)\r\n  return q3, tf.constant(1.0)\r\n```\r\n\r\n\r\n```\r\nt2t-trainer   --data_dir=$DATA_DIR   --problem=$PROBLEM   --model=$MODEL   --hparams_set=$HPARAMS   --output_dir=$TRAIN_DIR\r\n\r\nt2t-decoder   --data_dir=$DATA_DIR   --problem=$PROBLEM   --model=$MODEL   --hparams_set=$HPARAMS   --output_dir=$TRAIN_DIR   --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \r\n```\r\n# Error logs:\r\n```\r\nTraining results:\r\nINFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 0.6671654, metrics-translate_amino_protin_tokens_shared_vocab/targets/accuracy = 0.81997406, metrics-translate_amino_protin_tokens_shared_vocab/targets/accuracy_per_sequence = 0.0, metrics-translate_a\r\nmino_protin_tokens_shared_vocab/targets/accuracy_top5 = 0.9993136, metrics-translate_amino_protin_tokens_shared_vocab/targets/approx_bleu_score = 0.97672814, metrics-translate_amino_protin_tokens_shared_vocab/targets/approx_q3_accuracy = 0.818279, metrics-translate_amino_protin_\r\ntokens_shared_vocab/targets/neg_log_perplexity = -0.66406167, metrics-translate_amino_protin_tokens_shared_vocab/targets/rouge_L_fscore = 0.9852302\r\n```\r\n\r\n```\r\nDecoding results:\r\nINFO:tensorflow:Inference results INPUT: G D D N N A A E V D R Q V A Q D S A E P K T G E N A A A G D S S S T N K N A E K I V A V D I S A E T E K T Y L T H V A N D M V I P A Y A D A A K Q S D L L H D L A Q K H C Q K A P V S G D E L Q A L R D Q W L V L A Q A W A S A E M V N F G P A T A S M S N L Y I N Y Y P D E R G L V H G G V A D L I T A N P A L T A E Q L A N E S A V V Q G I P G L E E A L Y A N D S L D A G Q C A Y V M S A S S A L G T R L K D I E K N W Q Q N A I K L L A I D K T A E S D Q G L N Q W F N S L L S L V E T M K S N A I E Q P L G L S G K A K G H L P A A T A G Q S R A I I N A K L A T L N K A M T D P V L T A I L G S N N E N T V A D T L S T A L A D T T A L L A Q M P E D L A T A D K A T Q Q E L Y D H L T N I T R L I K S Q L I P T L G I R V G F N S T D G D\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nX X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X C C C C C C C H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H C C E C H H H H H H H H H H H H H H H H H H H H H C C C C C H H H H H H H H\r\nH H H H C C C C C C C C H H H H H H H H H H H H C C C C C C H H H H H C C H H H C H H H H H H H H H H C C C C E C H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H C C H H H C C C C C H H H H H H H H H H H H H H H H H H H H H H H H H H C C C C C C C C C C C C C C C C C H H H H\r\nH H H H H H H H H H H H C C H H H H H H H C C C C C H H H H H H H H H H H H H H H H H H H C C C C C H H H C C H H H H H H H H H H H H H H H H H H H H H H H H H C C C C C C C X X X X X X\r\nINFO:tensorflow:Inference results INPUT: G H M V S L T L Q V E N D L K H Q L S I G A L K P G A R L I T K N L A E Q L G M S I T P V R E A L L R L V S V N A L S V A P A Q A F T V P E V G K R Q L D E I N R I R Y E L E L M A V A L A V E N L T P Q D L A E L Q E L L E K L Q Q A Q E K G D M E Q I I N V N R L F R L A I Y H R S N M P I L C E M I E Q L W V R M G P G L H Y L Y E A I N P A E L R E H I E N Y H L L L A A L K A K D K E G C R H C L A E I M Q Q N I A I L Y Q Q Y N R\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: X X C C C H H H H H H H H H H H H H H C C C C C C C C E Y Y Y H H H H H H H C C C H H H H H H H H H H H H H C C C C E E Y C C C Y E E C C C C C H H H H H H H H H H H H H H H H H H H H H H H C C C C H H H H H H H H H H H H H H H H H H H H C C H H H H\r\nH H H H H H H H H H H H H C C C C H H H H H H H H H H H H H H H H H H H H H H H H C C H H H H H H H H H H H H H H H H H H H C C C H H H H H H H H H H H H H H H H H H H H Y Y Y C X\r\nINFO:tensorflow:Inference results INPUT: G S S G S S G E K I T K V Y E L G N E P E R K L W V D R Y L T F M E E R G S P V S S L P A V G K K P L D L F R L Y V C V K E I G G L A Q V N K N K K W R E L A T N L N V G T S S S A A S S L K K Q Y I Q Y L F A F E C K I E R G E E P P P E V F S T G D T\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: X X X X X X C C E C C H H H H C C C C C C H H H H H H H H H H H H H H C C C C C C E C C E E C C E E C C H H H H H H H H H H H C C H H H H H H H C C H H H H H H H C C C C C C H H H H H H H H H H H H H H C H H H H H H H H H C C C C C C C C C X X X X X\r\nINFO:tensorflow:Inference results INPUT: N T I E L F Y M P S D E E L T A N P N A L Q E A S F T E E D I N G L K G V D G V K Q V V A S A V K S M T A R Y H E E D T D I T L N G I N S G Y M D V K K L D V Q D G R T F T D N D F L S G K R A G I I S K K M A E K L F G K T S P L G K I V W A G G Q P V E V I G V L K E E S G F L S L G L S E M Y V P F N M L K T S F G T N D Y S N V S V Q T E S A D Q I K S T G K E A A R L L N D N H G T K E A Y Q V M N\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: C E E E E E E C C C H H H H C C C C X X X X X C C E C H H H H H H H H C C C C E E E E E E E E E E E E E E E E C C E E E E E E E E E E C H H H H H H C C C C E E E E C C C C H H H H H H C C C E E E E C H H H H H H H H C C C C C C C C E E E E C C E E E\r\nE E E E E E C C X X X X X X X C C C E E E E E H H H H H H H C C C C C E C E E E E E E C C H H H H H H H H H H H H H H H H H H H C C C C C E E C C C\r\nINFO:tensorflow:Inference results INPUT: M G S S H H H H H H S S G L V P R G S H M A L G S G V V P F E N L Q I E E G I I T D A E V A R F D N I R Q G L D F G Y G P D P L A F V R W H Y D K R K N R I Y A I D E L V D H K V S L K R T A D F V R K N K Y E S A R I I A D S S E P R S I D A L K L E H G I N R I E G A K K G P D S V E H G E R W L D E L D A I V I D P L R T P N I A R E F E N I D Y Q T D K N G D P I P R L E D K D N H T I D A T R Y A F E R D M K K G G V S L W G\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: X X X X X X X X X X X X X X X X X X X X X X X X X X C C C C C C E E E C C C C C C H H H H H H C C C E E E E E E C C E C C E C E E E E E E E E E C C C C E E E E E E E E E E C C C C H H H H H H H H H H C C C C C C C E E E C C C C H H H H H H H H H H C\r\nC C C C E E E C C C C H H H H H H H H H H H H C C C E E E E C C C C C H H H H H H H H H C C E E E C C C C C E E E E E C C C C C H H H H H H H H H C H H H C C X X X X X X X X\r\nINFO:tensorflow:Inference results INPUT: M R V M I T D K L R R D S E Q I W K K I F E H P F V V Q L Y S G T L P L E K F K F Y V L Q D F N Y L V G L T R A L A V I S S K A E Y P L M A E L I E L A R D E V T V E V E N Y V K L L K E L D L T L E D A I K T E P T L V N S A Y M D F M L A T A Y K G N I I E G L T A L L P C F W S Y A E I A E Y H K D K L R D N P I K I Y R E W G K V Y L S N E Y L N L V G R L R K I I D S S G H S G Y D R L R R I F I T G S K F E L A F W E M A W R G G D V F L E H H H H H H\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: C C C C H H H H H H H Y C H H H H H H H H C C H H H H H H H H C C C C H H H H H H H H H H H H H H H H H H H H H H H H H H H H C C C C H H H H H H H H H H H H Y C H H H H H H H H H H H H C C C C H H H H H H C C C C H H H H H H H H H H H H H H H H C C\r\nH H H H H H H H H H H H H H H H H H H H H C H H H H Y Y C C C H H H H H H H H H H H C H H H H H H H H H H H H H H H C C C C C C H H H H H H H H H H H H H H H H H H H H H H H H C C X X X X X X X X X X X\r\nINFO:tensorflow:Inference results INPUT: M T A F R Q R P L R L G H R G A P L K A K E N T L E S F R L A L E A G L D G V E L D V W P T R D G V F A V R H D P D T P L G P V F Q V D Y A D L K A Q E P D L P R L E E V L A L K E A F P Q A V F N V E L K S F P G L G E E A A R R L A A L L R G R E G V W V S S F D P L A L L A L R K A A P G L P L G F L M A E D H S A L L P C L G V E A V H P H H A L V T E E A V A G W R K R G L F V V A W T V N E E G E A R R L L A L G L D G L I G D R P E V L L P L G G\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: X X X X X X X C E E E E E C C C C C C C C C C C H H H H H H H H H C C C C E E E E E E E E C C C C C E E E C C C C E E C C E E H H H C C H H H H H H H C C C C C E H H H H H H H H H C C C C C E E E E E E C C C C C C H H H H H H H H H H H C C C C C C E\r\nE E E E C C H H H H H H H H H H C C C C C E E E E E C C C C H H H H H H C C C C E E E E E H H H C C H H H H H H H H H C C C E E E E E C C C C H H H H H H H H H C C C C E E E E C C H H H H C C C C C\r\nINFO:tensorflow:Inference results INPUT: A E L V S D K A L E S A P T V G W A S Q N G F T T G G A A A T S D N I Y I V T N I S E F T S A L S A G A E A K I I Q I K G T I D I S G G T P Y T D F A D Q K A R S Q I N I P A N T T V I G L G T D A K F I N G S L I I D G T D G T N N V I I R N V Y I Q T P I D V E P H Y E K G D G W N A E W D A M N I T N G A H H V W I D H V T I S D G N F T D D M Y T T K D G E T Y V Q H D G A L D I K R G S D Y V T I S N S L I D Q H D K T M L I G H S D S N G S Q D K G K L H V T L F N N V F N R V T E R A P R V R Y G S I H S F N N V F K G D A K D P V Y R Y Q Y S F G I G T S G S V L S E G N S F T I A N L S A S K A C K V V K K F N G S I F S D N G S V L N G S A V D L S G C G F S A Y T S K I P Y I Y D V Q P M T T E L A Q S I T D N A G S G K L\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nX X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: C C C C C Y Y Y Y C C C C C C C H H H C C C C C C C C C C C C H H H E E E E C C H H H H H H H H C C C C C C E E E E E C C E E E C C C C C C C C C H H H H H H H Y E E E C C C C E E E E E C C C C C E E E C C E E E E E H H H C C E E E E E E C C E E E C\r\nC C C C C C E E E C C C E E E C C C C C E E E E C C C E E E E E E C C E E E C C C C C H H H C C E E C C E E C C C C C C C E E E C C C C E E E E E E C C E E E E E E E C E E E C C C Y Y Y H H H H C C C C E E E E E C C E E E E E E E C C C E E C C C E E E E E C C E E E E E C C C C C C C C C C C\r\nE E E C C C C E E E E E C C E E E E E C C C H H H H H H H E E E C C C C E E E E E C C E E C C E E C C C C C C C C E C C C C C C C C C C C C C C C C H H H H H H H H H H C C C C C C\r\nINFO:tensorflow:Inference results INPUT: V M N T I Q Q L M M I L N S A S D Q P S E N L I S Y F N N C T V N P K E S I L K R V K D I G Y I F K E K F A K A V G Q G C V E I G S Q R Y K L G V R L Y Y R V M E S M L K S E E E R L S I Q N F S K L L N D N I F H M S L L A C A L E V V M A T Y S R S T S Q N L D S G T D L S F P W I L N V L N L K A F D F Y K V I E S F I K A E G N L T R E M I K H L E R C E H R I M E S L A\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: C C C C C C H H H H H H H C C C C C C C H H H H H H H H C C C C C C H H H H H H H H H H H H H H H H H H H H H H H C C C C H H H H H H H H H H H H H H H H H H H H H H H H H H H H H H C C C C C H H H H C C H H H H H H H H H H H H H H H H H H C C C C C\r\nC C C C C C C C C C C C C H H H H H H C C C H H H H H H H H H H H H H H C C C C C H H H H H H H H H H H H H H H H C C C\r\nINFO:tensorflow:Inference results INPUT: M N E A L D D I D R I L V R E L A A D G R A T L S E L A T R A G L S V S A V Q S R V R R L E S R G V V Q G Y S A R I N P E A V G H L L S A F V A I T P L D P S Q P D D A P A R L E H I E E V E S C Y S V A G E A S Y V L L V R V A S A R A L E D L L Q R I R T T A N V R T R S T I I L N T F Y S D R Q H I P\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: X X X C C C Y Y H H H H H H H H H H C C C C C H H H H H H H H C C C H H H H H H H H H H H H H C C C E E E E E E E E C C Y Y Y C C C E E E E E E E E E C C C C C C C C H H H H Y C C C C C E E E E E E E Y C C C C E E E E E E E C C H H H H H H H H H H H H H H Y C E E E E E E E E E E E E E C C C C C C C\r\nINFO:tensorflow:Inference results INPUT: M T D D S A V E S K Q K K S K I R K G H W I P V V A G F L R K D G K I L V G Q R P E N N S L A G Q W E F P G G K I E N G E T P E E A L A R E L N E E L G I E A E V G E L K L A C T H S Y G D V G I L I L F Y E I L Y W K G E P R A K H H M M L E W I H P E E L K H R N I P E A N R K I L H K I Y K A L G L E W R K\r\nINFO:tensorflow:Inference results OUTPUT: X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X\r\nINFO:tensorflow:Inference results TARGET: X X X X X X X X X X X X X X X X X C C C E E E E E E E E E E E C C E E E E E E C C C C C C C C C C E E C C E E E C C C C C C H H H H H H H H H H H H H C C E E E C C C E E E E E E E E Y C C Y E E E E E E E E E C E E E C C C C C C C C C E E E E E C H H H H H H C C C C H H H H C C H H H H H H H C C C C C X X\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1407", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1407/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1407/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1407/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1407", "id": 402666896, "node_id": "MDU6SXNzdWU0MDI2NjY4OTY=", "number": 1407, "title": "install", "user": {"login": "zira-wang", "id": 17594438, "node_id": "MDQ6VXNlcjE3NTk0NDM4", "avatar_url": "https://avatars1.githubusercontent.com/u/17594438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zira-wang", "html_url": "https://github.com/zira-wang", "followers_url": "https://api.github.com/users/zira-wang/followers", "following_url": "https://api.github.com/users/zira-wang/following{/other_user}", "gists_url": "https://api.github.com/users/zira-wang/gists{/gist_id}", "starred_url": "https://api.github.com/users/zira-wang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zira-wang/subscriptions", "organizations_url": "https://api.github.com/users/zira-wang/orgs", "repos_url": "https://api.github.com/users/zira-wang/repos", "events_url": "https://api.github.com/users/zira-wang/events{/privacy}", "received_events_url": "https://api.github.com/users/zira-wang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-01-24T11:37:54Z", "updated_at": "2019-01-24T11:38:21Z", "closed_at": "2019-01-24T11:38:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\n...\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\n\r\n$ python -V\r\n# your output here\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1394", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1394/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1394/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1394/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1394", "id": 401545106, "node_id": "MDU6SXNzdWU0MDE1NDUxMDY=", "number": 1394, "title": "Propose to contribute documentation on use and design of MultiProblem", "user": {"login": "cwbeitel", "id": 2348401, "node_id": "MDQ6VXNlcjIzNDg0MDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/2348401?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cwbeitel", "html_url": "https://github.com/cwbeitel", "followers_url": "https://api.github.com/users/cwbeitel/followers", "following_url": "https://api.github.com/users/cwbeitel/following{/other_user}", "gists_url": "https://api.github.com/users/cwbeitel/gists{/gist_id}", "starred_url": "https://api.github.com/users/cwbeitel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cwbeitel/subscriptions", "organizations_url": "https://api.github.com/users/cwbeitel/orgs", "repos_url": "https://api.github.com/users/cwbeitel/repos", "events_url": "https://api.github.com/users/cwbeitel/events{/privacy}", "received_events_url": "https://api.github.com/users/cwbeitel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-01-21T23:41:56Z", "updated_at": "2019-01-24T19:19:56Z", "closed_at": "2019-01-24T19:19:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The new MultiProblem class and instances are really cool!!\r\n\r\nI'm interested in writing some documentation on MultiProblem both regarding use and design. In my case towards understanding how to extend it to support multiple input modalities (audio and video).\r\n\r\nChecking whether this isn't something the authors would prefer to do themselves.\r\n\r\n/cc @rsepassi @lukaszkaiser", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1384", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1384/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1384/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1384/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1384", "id": 400982845, "node_id": "MDU6SXNzdWU0MDA5ODI4NDU=", "number": 1384, "title": "problem about translateEnZhWmt8k , i exported trained model and deploy it on tensorflow model server , the effiency is very bad ;  my client is same as t2t-query . who can help me ? thanks very much !!", "user": {"login": "alchemistlee", "id": 3377447, "node_id": "MDQ6VXNlcjMzNzc0NDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/3377447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alchemistlee", "html_url": "https://github.com/alchemistlee", "followers_url": "https://api.github.com/users/alchemistlee/followers", "following_url": "https://api.github.com/users/alchemistlee/following{/other_user}", "gists_url": "https://api.github.com/users/alchemistlee/gists{/gist_id}", "starred_url": "https://api.github.com/users/alchemistlee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alchemistlee/subscriptions", "organizations_url": "https://api.github.com/users/alchemistlee/orgs", "repos_url": "https://api.github.com/users/alchemistlee/repos", "events_url": "https://api.github.com/users/alchemistlee/events{/privacy}", "received_events_url": "https://api.github.com/users/alchemistlee/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-01-19T10:28:55Z", "updated_at": "2019-09-19T01:40:48Z", "closed_at": "2019-01-31T00:59:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nproblem about translateEnZhWmt8k , i exported trained model and deploy it on tensorflow model server , the effiency is very bad ;  my client is same as t2t-query . who can help me ? thanks very much !!\r\n\r\n### Environment information\r\n\r\n```\r\nOS: <your answer here>\r\n\r\n$ pip freeze | grep tensor\r\n# your output here\r\n\r\n$ python -V\r\n# your output here\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\n...\r\n```\r\n\r\n```\r\n# Error logs:\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1382", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1382/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1382/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1382/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1382", "id": 400892205, "node_id": "MDU6SXNzdWU0MDA4OTIyMDU=", "number": 1382, "title": "Getting out of hbm memory error on TPU", "user": {"login": "ranjeethks", "id": 32025394, "node_id": "MDQ6VXNlcjMyMDI1Mzk0", "avatar_url": "https://avatars2.githubusercontent.com/u/32025394?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ranjeethks", "html_url": "https://github.com/ranjeethks", "followers_url": "https://api.github.com/users/ranjeethks/followers", "following_url": "https://api.github.com/users/ranjeethks/following{/other_user}", "gists_url": "https://api.github.com/users/ranjeethks/gists{/gist_id}", "starred_url": "https://api.github.com/users/ranjeethks/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ranjeethks/subscriptions", "organizations_url": "https://api.github.com/users/ranjeethks/orgs", "repos_url": "https://api.github.com/users/ranjeethks/repos", "events_url": "https://api.github.com/users/ranjeethks/events{/privacy}", "received_events_url": "https://api.github.com/users/ranjeethks/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2019-01-18T21:17:41Z", "updated_at": "2020-05-31T22:53:14Z", "closed_at": "2019-04-24T14:42:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nTrying to train a language model - \r\n\r\nt2t-trainer --model=lstm_seq2seq --hparams_set=lstm_seq2seq --problem=languagemodel_lm1b8k_packed --train_steps=250000 --eval_steps=8 --data_dir=$DATA_DIR --output_dir=$OUT_DIR --use_tpu=True --cloud_tpu_name=$TPU_NAME --hparams='optimizer=Adafactor, weight_dtype=bfloat16, hidden_size=1024, batch_size=1024'\r\n\r\nGetting the following error (copied imp stuffs only)\r\nI tried to change the batch number. But no success. This is relatively a smaller model, 2 layer LSTM, 1024 hidden, 8k vocab (arguments take on 64 MB). But program takes more than 8 GB. Why is it so? Is there anyway I can use more than 1 TPU?\r\n\r\n```\r\n\r\nINFO:tensorflow:Error recorded from training_loop: Compilation failure: Ran out of memory in memory space hbm. Used 8.83G of 8.00G hbm. Exceeded hbm capacity by 848.88M.\r\n\r\nTotal hbm usage >= 8.83G:\r\n    reserved        528.00M\r\n    program           8.25G\r\n    arguments        64.32M (99.9% utilization)\r\n\r\nOutput size 64.32M (99.9% utilization); shares 64.25M with arguments.\r\n\r\nProgram hbm requirement 8.25G:\r\n    reserved           4.0K\r\n    global            65.0K\r\n    HLO temp          8.25G (100.0% utilization, 0.0% fragmentation (1.01M))\r\n\r\n  Largest program allocations in hbm:\r\n\r\n  1. Size: 4.00G\r\n     Operator: op_name=\"XLA_Args\"\r\n     Shape: bf16[256,2048,4096]{2,1,0}\r\n     Unpadded size: 4.00G\r\n     XLA label: %arg_tuple.1996.1402 = (s32[], s32[], f32[], f32[4,1024]{1,0}, bf16[4,1024]{1,0}, f32[4,1024]{1,0}, bf16[4,1024]{1,0}, s32[4]{0}, s32[], s32[], f32[4,1024]{1,0}, f32[], bf16[], bf16[], s32[], bf16[2048,4096]{1,0}, bf16[4096]{0}, bf16[2048,4096]{1,0}, bf16[...\r\n     Allocation type: HLO temp\r\n     ==========================\r\n\r\n  2. Size: 4.00G\r\n     Shape: bf16[256,2048,4096]{2,1,0}\r\n     Unpadded size: 4.00G\r\n     XLA label: %arg_tuple.3500.0 = (s32[], f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, s32[], f32[4,1024]{1,0}, f32[4,1024]{1,0}, f32[4,1024]{1,0}, f32[4,1024]{1,0}, bf16[], bf16[], bf16[], bf16[], (pred[256,4]{1,0}, s32[]), (bf16[256,4,1024]{2,...\r\n     Allocation type: HLO temp\r\n     ==========================\r\n\r\n  3. Size: 32.06M\r\n     Operator: op_type=\"Reshape\" op_name=\"lstm_seq2seq/parallel_0_6/lstm_seq2seq/lstm_seq2seq/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_1\"\r\n     Shape: f32[1024,8201]{0,1}\r\n     Unpadded size: 32.04M\r\n     Extra memory due to padding: 28.0K (1.0x expansion)\r\n     XLA label: %reshape.101.remat4 = f32[1024,8201]{0,1} reshape(f32[4,256,1,1,8201]{1,0,4,2,3} %fusion.250.remat4), sharding={maximal device=0}, metadata={op_type=\"Reshape\" op_name=\"lstm_seq2seq/parallel_0_6/lstm_seq2seq/lstm_seq2seq/padded_cross_entropy/smoothing_cross...\r\n     Allocation type: HLO temp\r\n     ==========================\r\n\r\n  4. Size: 32.06M\r\n     Operator: op_type=\"SoftmaxCrossEntropyWithLogits\" op_name=\"lstm_seq2seq/parallel_0_6/lstm_seq2seq/lstm_seq2seq/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits\"\r\n     Shape: f32[1024,8201]{0,1}\r\n     Unpadded size: 32.04M\r\n     Extra memory due to padding: 28.0K (1.0x expansion)\r\n     XLA label: %fusion.247 = (f32[1024]{0}, f32[1024,8201]{0,1}) fusion(f32[1024]{0} %log.remat2, f32[1024,8201]{0,1} %reshape.101.remat4, f32[1024]{0} %reduce.5, bf16[1024,1024]{1,0} %bitcast.45, bf16[8201,1024]{1,0} %get-tuple-element.1637), kind=kOutput, calls=%fused_...\r\nAllocation type: HLO temp\r\n     ==========================\r\n\r\n  5. Size: 32.06M\r\n     Operator: op_type=\"MatMul\" op_name=\"lstm_seq2seq/parallel_0_6/lstm_seq2seq/lstm_seq2seq/symbol_modality_8201_1024_1/softmax/MatMul\"\r\n     Shape: f32[1024,8201]{0,1}\r\n     Unpadded size: 32.04M\r\n     Extra memory due to padding: 28.0K (1.0x expansion)\r\n     XLA label: %fusion.213.remat4.1.remat3 = f32[1024,8201]{0,1} fusion(bf16[1024,1024]{1,0} %bitcast.45, bf16[8201,1024]{1,0} %get-tuple-element.1637), kind=kOutput, calls=%fused_computation.200.clone.clone.clone.clone.1.clone.clone.clone, sharding={maximal device=0}, m...\r\n     Allocation type: HLO temp\r\n     ==========================\r\n\r\n\r\n        TPU compilation failed\r\n         [[{{node tpu_compile_succeeded_assert/_4879872842451564100/_21}} = TPUCompileSucceededAssert[_device=\"/job:worker/replica:0/task:0/device:CPU:0\"](TPUReplicate/_compile/_14987246518586785693/_20)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node tpu_compile_succeeded_assert/_4879872842451564100/_21_G306}} = _Recv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/device:TPU:7\", send_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device_incarnation=-5499342681075470468, tensor_name=\"edge_226_tpu_compile_succeeded_assert/_4879872842451564100/_21\", tensor_type=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/device:TPU:7\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\nINFO:tensorflow:training_loop marked as finished\r\nWARNING:tensorflow:Reraising captured error\r\nTraceback (most recent call last):\r\nFile \"/usr/local/bin/t2t-trainer\", line 33, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 393, in main\r\n    execute_schedule(exp)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 349, in execute_schedule\r\n    getattr(exp, FLAGS.schedule)()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 438, in continuous_train_and_eval\r\n    self._eval_spec)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 637, in run\r\n    getattr(self, task_to_run)()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 647, in run_worker\r\n    return self._start_distributed_training()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 788, in _start_distributed_training\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2409, in train\r\n    rendezvous.raise_errors()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/error_handling.py\", line 128, in raise_errors\r\n    six.reraise(typ, value, traceback)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2403, in train\r\n    saving_listeners=saving_listeners\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1207, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1241, in _train_model_default\r\n    saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1471, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 671, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1156, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1240, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1312, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1076, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Compilation failure: Ran out of memory in memory space hbm. Used 8.83G of 8.00G hbm. Exceeded hbm capacity by 848.88M.\r\n\r\nTotal hbm usage >= 8.83G:\r\n    reserved        528.00M\r\n    program           8.25G\r\n    arguments        64.32M (99.9% utilization)\r\n\r\nOutput size 64.32M (99.9% utilization); shares 64.25M with arguments.\r\n\r\nProgram hbm requirement 8.25G:\r\n    reserved           4.0K\r\n    global            65.0K\r\n    HLO temp          8.25G (100.0% utilization, 0.0% fragmentation (1.01M))\r\n\r\n  Largest program allocations in hbm:\r\n\r\n  1. Size: 4.00G\r\n     Operator: op_name=\"XLA_Args\"\r\n     Shape: bf16[256,2048,4096]{2,1,0}\r\n     Unpadded size: 4.00G\r\n     XLA label: %arg_tuple.1996.1402 = (s32[], s32[], f32[], f32[4,1024]{1,0}, bf16[4,1024]{1,0}, f32[4,1024]{1,0}, bf16[4,1024]{1,0}, s32[4]{0}, s32[], s32[], f32[4,1024]{1,0}, f32[], bf16[], bf16[], s32[], bf16[2048,4096]{1,0}, bf16[4096]{0}, bf16[2048,4096]{1,0}, bf16[...\r\n     Allocation type: HLO temp\r\n     ==========================\r\n\r\n  2. Size: 4.00G\r\n     Shape: bf16[256,2048,4096]{2,1,0}\r\n     Unpadded size: 4.00G\r\n     XLA label: %arg_tuple.3500.0 = (s32[], f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, s32[], f32[4,1024]{1,0}, f32[4,1024]{1,0}, f32[4,1024]{1,0}, f32[4,1024]{1,0}, bf16[], bf16[], bf16[], bf16[], (pred[256,4]{1,0}, s32[]), (bf16[256,4,1024]{2,...\r\n     Allocation type: HLO temp\r\n     ==========================\r\n\r\n  3. Size: 32.06M\r\n     Operator: op_type=\"Reshape\" op_name=\"lstm_seq2seq/parallel_0_6/lstm_seq2seq/lstm_seq2seq/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits/Reshape_1\"\r\n     Shape: f32[1024,8201]{0,1}\r\n     Unpadded size: 32.04M\r\n     Extra memory due to padding: 28.0K (1.0x expansion)\r\n     XLA label: %reshape.101.remat4 = f32[1024,8201]{0,1} reshape(f32[4,256,1,1,8201]{1,0,4,2,3} %fusion.250.remat4), sharding={maximal device=0}, metadata={op_type=\"Reshape\" op_name=\"lstm_seq2seq/parallel_0_6/lstm_seq2seq/lstm_seq2seq/padded_cross_entropy/smoothing_cross...\r\n     Allocation type: HLO temp\r\n ==========================\r\n\r\n  4. Size: 32.06M\r\n     Operator: op_type=\"SoftmaxCrossEntropyWithLogits\" op_name=\"lstm_seq2seq/parallel_0_6/lstm_seq2seq/lstm_seq2seq/padded_cross_entropy/smoothing_cross_entropy/softmax_cross_entropy_with_logits\"\r\n     Shape: f32[1024,8201]{0,1}\r\n     Unpadded size: 32.04M\r\n     Extra memory due to padding: 28.0K (1.0x expansion)\r\n     XLA label: %fusion.247 = (f32[1024]{0}, f32[1024,8201]{0,1}) fusion(f32[1024]{0} %log.remat2, f32[1024,8201]{0,1} %reshape.101.remat4, f32[1024]{0} %reduce.5, bf16[1024,1024]{1,0} %bitcast.45, bf16[8201,1024]{1,0} %get-tuple-element.1637), kind=kOutput, calls=%fused_...\r\n     Allocation type: HLO temp\r\n     ==========================\r\n\r\n  5. Size: 32.06M\r\n     Operator: op_type=\"MatMul\" op_name=\"lstm_seq2seq/parallel_0_6/lstm_seq2seq/lstm_seq2seq/symbol_modality_8201_1024_1/softmax/MatMul\"\r\n     Shape: f32[1024,8201]{0,1}\r\n     Unpadded size: 32.04M\r\n     Extra memory due to padding: 28.0K (1.0x expansion)\r\n     XLA label: %fusion.213.remat4.1.remat3 = f32[1024,8201]{0,1} fusion(bf16[1024,1024]{1,0} %bitcast.45, bf16[8201,1024]{1,0} %get-tuple-element.1637), kind=kOutput, calls=%fused_computation.200.clone.clone.clone.clone.1.clone.clone.clone, sharding={maximal device=0}, m...\r\n     Allocation type: HLO temp\r\n     ==========================\r\n\r\n\r\n        TPU compilation failed\r\n         [[{{node tpu_compile_succeeded_assert/_4879872842451564100/_21}} = TPUCompileSucceededAssert[_device=\"/job:worker/replica:0/task:0/device:CPU:0\"](TPUReplicate/_compile/_14987246518586785693/_20)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node tpu_compile_succeeded_assert/_4879872842451564100/_21_G306}} = _Recv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/device:TPU:7\", send_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device_incarnation=-5499342681075470468, tensor_name=\"edge_226_tpu_compile_succeeded_assert/_4879872842451564100/_21\", tensor_type=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/device:TPU:7\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n```\r\n### Environment information\r\n\r\n```\r\nOS: <Linux version 4.9.0-8-amd64 running on gcloud>\r\n\r\n$ pip freeze | grep tensor\r\n# mesh-tensorflow==0.0.5\r\ntensor2tensor==1.12.0\r\ntensorboard==1.12.0\r\ntensorflow==1.12.0\r\ntensorflow-metadata==0.9.0\r\ntensorflow-probability==0.5.0\r\n\r\n$ python -V\r\n# Python 2.7.13\r\n```\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1379", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1379/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1379/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1379/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1379", "id": 400288456, "node_id": "MDU6SXNzdWU0MDAyODg0NTY=", "number": 1379, "title": "Defining a new Multi-Task Problem", "user": {"login": "agemagician", "id": 6087313, "node_id": "MDQ6VXNlcjYwODczMTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6087313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agemagician", "html_url": "https://github.com/agemagician", "followers_url": "https://api.github.com/users/agemagician/followers", "following_url": "https://api.github.com/users/agemagician/following{/other_user}", "gists_url": "https://api.github.com/users/agemagician/gists{/gist_id}", "starred_url": "https://api.github.com/users/agemagician/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agemagician/subscriptions", "organizations_url": "https://api.github.com/users/agemagician/orgs", "repos_url": "https://api.github.com/users/agemagician/repos", "events_url": "https://api.github.com/users/agemagician/events{/privacy}", "received_events_url": "https://api.github.com/users/agemagician/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-17T13:57:13Z", "updated_at": "2019-08-13T09:39:44Z", "closed_at": "2019-08-13T09:37:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI am trying to define a new multi-task problem that predict the secondary structure protein from amino acids. I am using the transformer base model.\r\n\r\nI am facing several problems/questions:\r\n\r\n1) After training, when I change the decoding problem id, I get the same result for both problems. The output doesn't change. Is there a bug in the multi-task decoding ?\r\n2) How I can force the decoder to always produce the same length as the input ?\r\n3) With the current code I can find a lot of the input vocabulary in the output vocabulary. It extremely reduces the accuracy. How can I force the model not to share vocabulary?\r\n4) The accuracy is really low compared to a simple CNN that I made in pytorch. Is there something wrong in the Code bellow ?\r\n\r\nThis is my code unlabelled data \"like language modelling\":\r\n```\r\n@registry.register_problem\r\nclass LanguagemodelUniref50C8k(text_problems.Text2SelfProblem):\r\n\r\n  @property\r\n  def approx_vocab_size(self):\r\n    return 2**13  # 8192\r\n\r\n  def is_generate_per_split(self):\r\n    return False\r\n\r\n  @property\r\n  def dataset_splits(self):\r\n    return [{\r\n        \"split\": problem.DatasetSplit.TRAIN,\r\n        \"shards\": 99,\r\n    }, {\r\n        \"split\": problem.DatasetSplit.EVAL,\r\n        \"shards\": 1,\r\n    }]\r\n\r\n  def generate_samples(self, data_dir, tmp_dir, dataset_split):\r\n    filepath = tmp_dir + '/uniref50_protein_unlabeled.txt'\r\n    for line in tf.gfile.Open(filepath):\r\n        yield {\"targets\": line}\r\n```\r\n\r\nThis is my code to the labeled dataset:\r\n\r\n```\r\n@registry.register_problem\r\nclass TranslateAminoProtinTokensSharedVocab(text_problems.Text2TextProblem):\r\n\r\n  @property\r\n  def approx_vocab_size(self):\r\n    return 2**13  # 8192\r\n\r\n  @property\r\n  def is_generate_per_split(self):\r\n    return False\r\n\r\n  @property\r\n  def dataset_splits(self):\r\n    return [{\r\n        \"split\": problem.DatasetSplit.TRAIN,\r\n        \"shards\": 9,\r\n    }, {\r\n        \"split\": problem.DatasetSplit.EVAL,\r\n        \"shards\": 1,\r\n    }]\r\n\r\n  def generate_samples(self, data_dir, tmp_dir, dataset_split):\r\n       datasetdf = pd.read_csv(tmp_dir + '/complete_train_dataset_seperated.csv')\r\n       for index, row in datasetdf.iterrows():\r\n         yield {\r\n         \"inputs\": row['input'],\r\n         \"targets\": row['output'],\r\n         }\r\n```\r\n\r\nThis is my code for the Multi-task:\r\n```\r\n@registry.register_problem\r\nclass MultiUniref50C8kTranslateAminoProtin(multi_problem.MultiProblem):\r\n\r\n  def __init__(self, was_reversed=False, was_copy=False):\r\n    super(MultiUniref50C8kTranslateAminoProtin, self).__init__(was_reversed, was_copy)\r\n    self.task_list.append(uniref.LanguagemodelUniref50C8k())\r\n    self.task_list.append(translate_amino_protin.TranslateAminoProtinTokensSharedVocab())\r\n\r\n  @property\r\n  def vocab_type(self):\r\n    return text_problems.VocabType.SUBWORD\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1376", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1376/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1376/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1376/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1376", "id": 399896607, "node_id": "MDU6SXNzdWUzOTk4OTY2MDc=", "number": 1376, "title": "Pip install broken due to tensorflow-metadata dependency in tfds-nightly", "user": {"login": "ykl7", "id": 4996184, "node_id": "MDQ6VXNlcjQ5OTYxODQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4996184?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ykl7", "html_url": "https://github.com/ykl7", "followers_url": "https://api.github.com/users/ykl7/followers", "following_url": "https://api.github.com/users/ykl7/following{/other_user}", "gists_url": "https://api.github.com/users/ykl7/gists{/gist_id}", "starred_url": "https://api.github.com/users/ykl7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ykl7/subscriptions", "organizations_url": "https://api.github.com/users/ykl7/orgs", "repos_url": "https://api.github.com/users/ykl7/repos", "events_url": "https://api.github.com/users/ykl7/events{/privacy}", "received_events_url": "https://api.github.com/users/ykl7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-01-16T16:41:26Z", "updated_at": "2019-01-16T18:02:37Z", "closed_at": "2019-01-16T18:02:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nPip install doesn't run since no matching distributions for tensorflow-metadata found in tfds-nightly\r\n\r\n### Environment information\r\n\r\n```\r\nOS: Debian GNU/Linux 9\r\nUsing conda\r\n\r\n$ python -V\r\nPython 3.7.2\r\n```\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\npip install tensor2tensor --force-reinstall\r\n```\r\n\r\n```\r\n# Error logs:\r\nCollecting tensor2tensor\r\n  Using cached https://files.pythonhosted.org/packages/e1/3a/2e85ecf08a66819ed623bc8dafcc2fe22aea80f1f56b9aa723d4197e96f4/tensor2tensor-1.12.0-py2.py3-none-any.whl\r\nCollecting six (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\r\nCollecting gym (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/d4/22/4ff09745ade385ffe707fb5f053548f0f6a6e7d5e98a2b9d6c07f5b931a7/gym-0.10.9.tar.gz\r\nCollecting dopamine-rl (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/5b/72/fcd254a6dfbce2bf4090f992b62bf4dc1126f28520932c5e83217c03514b/dopamine_rl-1.0.5-py3-none-any.whl\r\nCollecting numpy (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/3d/10/62224c551acfd3a3583ad16d1e0f1c9e9c333e74479dc51977c31836119c/numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl\r\nCollecting tfds-nightly (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/b6/65/94f42e48ea6f8398d128d48ac3df629687acfcbfaeccc867d3e85cbcdb38/tfds_nightly-0.0.2.dev201901160014-py3-none-any.whl\r\nCollecting sympy (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/dd/f6/ed485ff22efdd7b371d0dbbf6d77ad61c3b3b7e0815a83c89cbb38ce35de/sympy-1.3.tar.gz\r\nCollecting gunicorn (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/8c/da/b8dd8deb741bff556db53902d4706774c8e1e67265f69528c14c003644e6/gunicorn-19.9.0-py2.py3-none-any.whl\r\nCollecting scipy (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/80/39/066ecde98f373430bf7a39a02d91c7075b01ef4fc928456e8e31577342d6/scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl\r\nCollecting google-api-python-client (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/d7/47/940908e52487440f61fb93ad55cbbe3a28235d3bb143b26affb17b37dd28/google_api_python_client-1.7.7-py2.py3-none-any.whl\r\nCollecting opencv-python (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/45/bd/e0a4391ac105ecf73a6e14372174b05774634c7c6454e49c38750d516eee/opencv_python-4.0.0.21-cp37-cp37m-manylinux1_x86_64.whl\r\nCollecting bz2file (from tensor2tensor)\r\nCollecting tf-agents (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/33/3a/134af64155edfe930b0e8561df0b3d2188693a86c2fe40d6eb9df94777da/tf_agents-0.2.0rc1-py2.py3-none-any.whl\r\nCollecting future (from tensor2tensor)\r\nCollecting tqdm (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/ed/d6/3458d39cf4978f4ece846295e83daf5ece710ab0a4106774f7f7b3a68697/tqdm-4.29.1-py2.py3-none-any.whl\r\nCollecting h5py (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/8e/fd/2ca5c4f4ed33ac4178f9c4d551e3946ab480866e3cd67a65a67a4bb35367/h5py-2.9.0-cp37-cp37m-manylinux1_x86_64.whl\r\nCollecting oauth2client (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/95/a9/4f25a14d23f0786b64875b91784607c2277eff25d48f915e39ff0cff505a/oauth2client-4.1.3-py2.py3-none-any.whl\r\nCollecting mesh-tensorflow (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/90/f3/07fe1c894490156d0d423b95fc375fcf09371413234b94500bfcd61ab6d7/mesh_tensorflow-0.0.5-py2.py3-none-any.whl\r\nCollecting requests (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl\r\nCollecting gevent (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/d4/89/57b63d6d7967d8763b913172bf6831afb01951b9ed9da127f2938a365585/gevent-1.4.0-cp37-cp37m-manylinux1_x86_64.whl\r\nCollecting flask (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/7f/e7/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b/Flask-1.0.2-py2.py3-none-any.whl\r\nCollecting tensorflow-probability (from tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/a1/ca/6f213618b5f7d0bf6139e6ec928d412a5ca14e4776adfd41a59c74a34021/tensorflow_probability-0.5.0-py2.py3-none-any.whl\r\nCollecting pyglet>=1.2.0 (from gym->tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl\r\nCollecting absl-py>=0.2.2 (from dopamine-rl->tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/31/bc/ab68120d1d89ae23b694a55fe2aece2f91194313b71f9b05a80b32d3c24b/absl-py-0.7.0.tar.gz\r\nCollecting gin-config>=0.1.1 (from dopamine-rl->tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/c9/f3/c02c3b040ab701ca0d9b2b7b071e78c8035dc62affb0ad5ba15c4226a16c/gin-config-0.1.2.tar.gz\r\nCollecting wrapt (from tfds-nightly->tensor2tensor)\r\n  Using cached https://files.pythonhosted.org/packages/78/4d/c3f9bd791683bd61b7799e465872bf5f4495fe3abb6c4f119419b9f606eb/wrapt-1.11.0.tar.gz\r\nCollecting tensorflow-metadata (from tfds-nightly->tensor2tensor)\r\n  Could not find a version that satisfies the requirement tensorflow-metadata (from tfds-nightly->tensor2tensor) (from versions: )\r\nNo matching distribution found for tensorflow-metadata (from tfds-nightly->tensor2tensor)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1366", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1366/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1366/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1366/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1366", "id": 398629619, "node_id": "MDU6SXNzdWUzOTg2Mjk2MTk=", "number": 1366, "title": "cifar datagen using cPickle not compatible with python3", "user": {"login": "eyaler", "id": 4436747, "node_id": "MDQ6VXNlcjQ0MzY3NDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4436747?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eyaler", "html_url": "https://github.com/eyaler", "followers_url": "https://api.github.com/users/eyaler/followers", "following_url": "https://api.github.com/users/eyaler/following{/other_user}", "gists_url": "https://api.github.com/users/eyaler/gists{/gist_id}", "starred_url": "https://api.github.com/users/eyaler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eyaler/subscriptions", "organizations_url": "https://api.github.com/users/eyaler/orgs", "repos_url": "https://api.github.com/users/eyaler/repos", "events_url": "https://api.github.com/users/eyaler/events{/privacy}", "received_events_url": "https://api.github.com/users/eyaler/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-13T08:06:23Z", "updated_at": "2019-01-13T12:37:30Z", "closed_at": "2019-01-13T12:37:30Z", "author_association": "NONE", "active_lock_reason": null, "body": " File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"c:/anaconda3/scripts/t2t-datagen\", line 23, in main\r\n    t2t_datagen.main(argv)\r\n  File \"C:\\anaconda3\\lib\\site-packages\\tensor2tensor\\bin\\t2t_datagen.py\", line 182, in main\r\n    generate_data_for_registered_problem(problem)\r\n  File \"C:\\anaconda3\\lib\\site-packages\\tensor2tensor\\bin\\t2t_datagen.py\", line 232, in generate_data_for_registered_problem\r\n    problem.generate_data(data_dir, tmp_dir, task_id)\r\n  File \"C:\\anaconda3\\lib\\site-packages\\tensor2tensor\\data_generators\\image_utils.py\", line 190, in generate_data\r\n    self.generator(data_dir, tmp_dir, True),\r\n  File \"C:\\anaconda3\\lib\\site-packages\\tensor2tensor\\data_generators\\cifar.py\", line 146, in generator\r\n    return cifar_generator(\"cifar10\", tmp_dir, True, 50000)\r\n  File \"C:\\anaconda3\\lib\\site-packages\\tensor2tensor\\data_generators\\cifar.py\", line 95, in cifar_generator\r\n    data = cPickle.load(f)\r\nUnicodeDecodeError: 'ascii' codec can't decode byte 0x8b in position 6: ordinal not in range(128)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1353", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1353/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1353/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1353/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1353", "id": 397387035, "node_id": "MDU6SXNzdWUzOTczODcwMzU=", "number": 1353, "title": "Universal_transformer._beam_decode lost 1 parameter", "user": {"login": "bigzt", "id": 19234454, "node_id": "MDQ6VXNlcjE5MjM0NDU0", "avatar_url": "https://avatars0.githubusercontent.com/u/19234454?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bigzt", "html_url": "https://github.com/bigzt", "followers_url": "https://api.github.com/users/bigzt/followers", "following_url": "https://api.github.com/users/bigzt/following{/other_user}", "gists_url": "https://api.github.com/users/bigzt/gists{/gist_id}", "starred_url": "https://api.github.com/users/bigzt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bigzt/subscriptions", "organizations_url": "https://api.github.com/users/bigzt/orgs", "repos_url": "https://api.github.com/users/bigzt/repos", "events_url": "https://api.github.com/users/bigzt/events{/privacy}", "received_events_url": "https://api.github.com/users/bigzt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-01-09T14:08:10Z", "updated_at": "2019-01-14T18:12:49Z", "closed_at": "2019-01-14T18:12:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\n\r\nHi, there. The universal_transformer._beam_decode lost 1 parameter: use_tpu. When using T2T-decoder, it will cause TypeError: _beam_decode() takes 6 positional arguments but 7 were given.\r\n\r\n### For bugs: reproduction and error logs\r\n\r\n```\r\n# Steps to reproduce:\r\nUse T2T-decoder to predict a universal transformer model.\r\n```\r\n\r\n```\r\n# Error logs:\r\nINFO:tensorflow:Setting hparams.dropout to 0.0\r\nINFO:tensorflow:Setting hparams.label_smoothing to 0.0\r\nINFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\r\nINFO:tensorflow:Setting hparams.symbol_dropout to 0.0\r\nINFO:tensorflow:Setting hparams.attention_dropout to 0.0\r\nINFO:tensorflow:Setting hparams.relu_dropout to 0.0\r\nINFO:tensorflow:Beam Decoding with beam size 4\r\nTraceback (most recent call last):\r\n  File \"F:/tensorflow/project/huiming/t2t_decode.py\", line 203, in <module>\r\n    tf.app.run()\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"F:/tensorflow/project/huiming/t2t_decode.py\", line 198, in main\r\n    decode(estimator, hp, decode_hp)\r\n  File \"F:/tensorflow/project/huiming/t2t_decode.py\", line 98, in decode\r\n    checkpoint_path=FLAGS.checkpoint_path)\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensor2tensor\\utils\\decoding.py\", line 393, in decode_from_file\r\n    for elapsed_time, result in timer(result_iter):\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensor2tensor\\utils\\decoding.py\", line 387, in timer\r\n    item = next(gen)\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 577, in predict\r\n    features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1195, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensor2tensor\\utils\\t2t_model.py\", line 1264, in wrapping_model_fn\r\n    use_tpu=use_tpu)\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensor2tensor\\utils\\t2t_model.py\", line 1319, in estimator_model_fn\r\n    return model.estimator_spec_predict(features, use_tpu=use_tpu)\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensor2tensor\\utils\\t2t_model.py\", line 1521, in estimator_spec_predict\r\n    use_tpu=use_tpu)\r\n  File \"F:\\tensorflow\\tf_env\\lib\\site-packages\\tensor2tensor\\utils\\t2t_model.py\", line 691, in infer\r\n    top_beams, alpha, use_tpu)\r\nTypeError: _beam_decode() takes 6 positional arguments but 7 were given\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1337", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1337/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1337/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1337/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1337", "id": 395143919, "node_id": "MDU6SXNzdWUzOTUxNDM5MTk=", "number": 1337, "title": "state update in universal_transformer_act_basic", "user": {"login": "rouniuyizu", "id": 7133753, "node_id": "MDQ6VXNlcjcxMzM3NTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/7133753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rouniuyizu", "html_url": "https://github.com/rouniuyizu", "followers_url": "https://api.github.com/users/rouniuyizu/followers", "following_url": "https://api.github.com/users/rouniuyizu/following{/other_user}", "gists_url": "https://api.github.com/users/rouniuyizu/gists{/gist_id}", "starred_url": "https://api.github.com/users/rouniuyizu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rouniuyizu/subscriptions", "organizations_url": "https://api.github.com/users/rouniuyizu/orgs", "repos_url": "https://api.github.com/users/rouniuyizu/repos", "events_url": "https://api.github.com/users/rouniuyizu/events{/privacy}", "received_events_url": "https://api.github.com/users/rouniuyizu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-02T03:54:57Z", "updated_at": "2019-01-16T01:29:38Z", "closed_at": "2019-01-16T01:29:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm new to this but I failed to find the reference: \"Implementations of all act models are based on craffel@'s cl/160711592.\" All I got was from Alex Graves: \"https://arxiv.org/abs/1603.08983\"\r\n\r\nQuestion on \"universal_transformer_util.py#L1176\": \r\nnew_state = ((transformed_state * update_weights) + (previous_state * (1 - update_weights)))\r\n\r\nShouldn't it be: \"new_state = (transformed_state * update_weights) + previous_state\" ?\r\n\r\nFrom AG's paper we suppose to sum up all the states according to p at various steps.\r\n\r\nAny hints appreciated.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1334", "repository_url": "https://api.github.com/repos/tensorflow/tensor2tensor", "labels_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1334/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1334/comments", "events_url": "https://api.github.com/repos/tensorflow/tensor2tensor/issues/1334/events", "html_url": "https://github.com/tensorflow/tensor2tensor/issues/1334", "id": 394945754, "node_id": "MDU6SXNzdWUzOTQ5NDU3NTQ=", "number": 1334, "title": "Multiple beams in exported model", "user": {"login": "Stercator", "id": 19503908, "node_id": "MDQ6VXNlcjE5NTAzOTA4", "avatar_url": "https://avatars3.githubusercontent.com/u/19503908?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Stercator", "html_url": "https://github.com/Stercator", "followers_url": "https://api.github.com/users/Stercator/followers", "following_url": "https://api.github.com/users/Stercator/following{/other_user}", "gists_url": "https://api.github.com/users/Stercator/gists{/gist_id}", "starred_url": "https://api.github.com/users/Stercator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Stercator/subscriptions", "organizations_url": "https://api.github.com/users/Stercator/orgs", "repos_url": "https://api.github.com/users/Stercator/repos", "events_url": "https://api.github.com/users/Stercator/events{/privacy}", "received_events_url": "https://api.github.com/users/Stercator/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-31T08:24:20Z", "updated_at": "2019-02-18T07:58:33Z", "closed_at": "2019-02-18T07:58:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "How can I get multiple beams (outputs and scores) in an **exported** model?", "performed_via_github_app": null, "score": 1.0}]}