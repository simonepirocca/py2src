{"total_count": 834, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/pytorch/vision/issues/2599", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2599/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2599/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2599/events", "html_url": "https://github.com/pytorch/vision/issues/2599", "id": 683261086, "node_id": "MDU6SXNzdWU2ODMyNjEwODY=", "number": 2599, "title": "resnext101 backbone faster rcnn train occur loss is Nan", "user": {"login": "juyunsang", "id": 13113520, "node_id": "MDQ6VXNlcjEzMTEzNTIw", "avatar_url": "https://avatars0.githubusercontent.com/u/13113520?v=4", "gravatar_id": "", "url": "https://api.github.com/users/juyunsang", "html_url": "https://github.com/juyunsang", "followers_url": "https://api.github.com/users/juyunsang/followers", "following_url": "https://api.github.com/users/juyunsang/following{/other_user}", "gists_url": "https://api.github.com/users/juyunsang/gists{/gist_id}", "starred_url": "https://api.github.com/users/juyunsang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/juyunsang/subscriptions", "organizations_url": "https://api.github.com/users/juyunsang/orgs", "repos_url": "https://api.github.com/users/juyunsang/repos", "events_url": "https://api.github.com/users/juyunsang/events{/privacy}", "received_events_url": "https://api.github.com/users/juyunsang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-21T04:56:22Z", "updated_at": "2020-08-21T12:12:36Z", "closed_at": "2020-08-21T05:19:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\nHello\r\nLoss is nan error occurs when I learn fast rcnn with resnext101 backbone\r\nMy code is as follows\r\n```python\r\nbackbone = resnet_fpn_backbone('resnext101_32x8d', pretrained=True)\r\nmodel = FasterRCNN(backbone, num_classes)\r\nin_features = model.roi_heads.box_predictor.cls_score.in_features\r\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\r\n```\r\n\r\nerror message\r\n```\r\nEpoch: [0]  [   0/7208]  eta: 1:27:42  lr: 0.000040  loss: 40613806080.0000 (40613806080.0000)  loss_box_reg: 7979147264.0000 (7979147264.0000)  loss_classifier: 11993160704.0000 (11993160704.0000)  loss_objectness: 9486380032.0000 (9486380032.0000)  loss_rpn_box_reg: 11155118080.0000 (11155118080.0000)  time: 0.7301  data: 0.4106  max mem: 1241\r\nLoss is nan, stopping training\r\n```\r\n\r\nWhen i change the backbone to resnet50 and resnet152, no error occrus.\r\n### Please note that this issue tracker is not a help form and this issue will be closed.\r\n\r\nWe have a set of [listed resources available on the website](https://pytorch.org/resources). Our primary means of support is our discussion forum:\r\n\r\n- [Discussion Forum](https://discuss.pytorch.org/)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2580", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2580/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2580/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2580/events", "html_url": "https://github.com/pytorch/vision/issues/2580", "id": 677481795, "node_id": "MDU6SXNzdWU2Nzc0ODE3OTU=", "number": 2580, "title": "Why the supoort inputs of torchvision.transforms.functional.crop() and resize () on Windows is different from docs on website?", "user": {"login": "dongning-ac", "id": 67568009, "node_id": "MDQ6VXNlcjY3NTY4MDA5", "avatar_url": "https://avatars1.githubusercontent.com/u/67568009?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dongning-ac", "html_url": "https://github.com/dongning-ac", "followers_url": "https://api.github.com/users/dongning-ac/followers", "following_url": "https://api.github.com/users/dongning-ac/following{/other_user}", "gists_url": "https://api.github.com/users/dongning-ac/gists{/gist_id}", "starred_url": "https://api.github.com/users/dongning-ac/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dongning-ac/subscriptions", "organizations_url": "https://api.github.com/users/dongning-ac/orgs", "repos_url": "https://api.github.com/users/dongning-ac/repos", "events_url": "https://api.github.com/users/dongning-ac/events{/privacy}", "received_events_url": "https://api.github.com/users/dongning-ac/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619883, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODM=", "url": "https://api.github.com/repos/pytorch/vision/labels/duplicate", "name": "duplicate", "color": "cccccc", "default": true, "description": null}, {"id": 1391938214, "node_id": "MDU6TGFiZWwxMzkxOTM4MjE0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20documentation", "name": "module: documentation", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-12T07:57:55Z", "updated_at": "2020-08-12T10:31:59Z", "closed_at": "2020-08-12T10:31:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n\r\nWindows 10:\r\nCUDA version :10.1\r\ntorchvision.__version__ is 0.7.0\r\npython: 3.7\r\n\r\nThe docs on the website: [torchvision.transforms.functional.resize()](https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=resize#torchvision.transforms.functional.resize) and  [torchvision.transforms.functional.crop()](https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=resize#torchvision.transforms.functional.crop) are written that the two functions support both **PIL and tensor** as inputs. \r\n\r\nBut when I use the two functions on Windows, I found that it still only support PIL as inputs. I'd like to use tensor as inputs. Some of the source code in functional.py  is:\r\n```python\r\ndef resize(img, size, interpolation=Image.BILINEAR):\r\n    r\"\"\"Resize the input PIL Image to the given size.\r\n\r\n    Args:\r\n        img (PIL Image): Image to be resized.\r\n        size (sequence or int): Desired output size. If size is a sequence like\r\n            (h, w), the output size will be matched to this. If size is an int,\r\n            the smaller edge of the image will be matched to this number maintaining\r\n            the aspect ratio. i.e, if height > width, then image will be rescaled to\r\n            :math:`\\left(\\text{size} \\times \\frac{\\text{height}}{\\text{width}}, \\text{size}\\right)`\r\n        interpolation (int, optional): Desired interpolation. Default is\r\n            ``PIL.Image.BILINEAR``\r\n\r\n    Returns:\r\n        PIL Image: Resized image.\r\n    \"\"\"\r\n    if not _is_pil_image(img):\r\n        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\r\n    if not (isinstance(size, int) or (isinstance(size, Iterable) and len(size) == 2)):\r\n        raise TypeError('Got inappropriate size arg: {}'.format(size))\r\n\r\n    if isinstance(size, int):\r\n        w, h = img.size\r\n        if (w <= h and w == size) or (h <= w and h == size):\r\n            return img\r\n        if w < h:\r\n            ow = size\r\n            oh = int(size * h / w)\r\n            return img.resize((ow, oh), interpolation)\r\n        else:\r\n            oh = size\r\n            ow = int(size * w / h)\r\n            return img.resize((ow, oh), interpolation)\r\n    else:\r\n        return img.resize(size[::-1], interpolation)\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2578", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2578/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2578/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2578/events", "html_url": "https://github.com/pytorch/vision/issues/2578", "id": 677240554, "node_id": "MDU6SXNzdWU2NzcyNDA1NTQ=", "number": 2578, "title": "Calculate Training Accuracy on resnet152", "user": {"login": "FrostByteGER", "id": 3531645, "node_id": "MDQ6VXNlcjM1MzE2NDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/3531645?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FrostByteGER", "html_url": "https://github.com/FrostByteGER", "followers_url": "https://api.github.com/users/FrostByteGER/followers", "following_url": "https://api.github.com/users/FrostByteGER/following{/other_user}", "gists_url": "https://api.github.com/users/FrostByteGER/gists{/gist_id}", "starred_url": "https://api.github.com/users/FrostByteGER/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FrostByteGER/subscriptions", "organizations_url": "https://api.github.com/users/FrostByteGER/orgs", "repos_url": "https://api.github.com/users/FrostByteGER/repos", "events_url": "https://api.github.com/users/FrostByteGER/events{/privacy}", "received_events_url": "https://api.github.com/users/FrostByteGER/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-11T22:30:00Z", "updated_at": "2020-08-21T14:11:44Z", "closed_at": "2020-08-12T05:45:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to calculate training accuracy on resnet152, however\r\n`loss_dict = model(images, targets)`\r\nonly contains loss values. \r\n\r\nUsually the model accepts only the images and the outputs are then passed to a loss function as well as used to calculate the accuracy. Calling it without the targets parameter results in:\r\n`ValueError: In training mode, targets should be passed`\r\n\r\nSorry if this is the wrong place, I'm still quite a beginner.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2575", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2575/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2575/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2575/events", "html_url": "https://github.com/pytorch/vision/issues/2575", "id": 676801071, "node_id": "MDU6SXNzdWU2NzY4MDEwNzE=", "number": 2575, "title": "NMS not available with CUDA backend in 0.7.0", "user": {"login": "vcarpani", "id": 38493091, "node_id": "MDQ6VXNlcjM4NDkzMDkx", "avatar_url": "https://avatars3.githubusercontent.com/u/38493091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vcarpani", "html_url": "https://github.com/vcarpani", "followers_url": "https://api.github.com/users/vcarpani/followers", "following_url": "https://api.github.com/users/vcarpani/following{/other_user}", "gists_url": "https://api.github.com/users/vcarpani/gists{/gist_id}", "starred_url": "https://api.github.com/users/vcarpani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vcarpani/subscriptions", "organizations_url": "https://api.github.com/users/vcarpani/orgs", "repos_url": "https://api.github.com/users/vcarpani/repos", "events_url": "https://api.github.com/users/vcarpani/events{/privacy}", "received_events_url": "https://api.github.com/users/vcarpani/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2089185327, "node_id": "MDU6TGFiZWwyMDg5MTg1MzI3", "url": "https://api.github.com/repos/pytorch/vision/labels/high%20priority", "name": "high priority", "color": "b60205", "default": false, "description": ""}, {"id": 1479831546, "node_id": "MDU6TGFiZWwxNDc5ODMxNTQ2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20c++%20frontend", "name": "module: c++ frontend", "color": "f7e101", "default": false, "description": ""}, {"id": 719389156, "node_id": "MDU6TGFiZWw3MTkzODkxNTY=", "url": "https://api.github.com/repos/pytorch/vision/labels/needs%20reproduction", "name": "needs reproduction", "color": "64fca1", "default": false, "description": null}, {"id": 1868786748, "node_id": "MDU6TGFiZWwxODY4Nzg2NzQ4", "url": "https://api.github.com/repos/pytorch/vision/labels/triage%20review", "name": "triage review", "color": "cc317c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-11T11:29:29Z", "updated_at": "2020-08-20T11:31:53Z", "closed_at": "2020-08-20T11:31:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nAfter converting a maskrcnn model torchscript and loading it in c++, with torchvision version 0.7.0 I get:\r\n```\r\nRuntimeError: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. 'torchvision::nms' is only available for these backends: [CPU].\r\n```\r\n\r\nWith torchvision 0.7.0-rc2 I do not have this problem, it looks to be related to the new `autocast` functionality.\r\n\r\n## Environment\r\n\r\n - PyTorch / torchvision Version (e.g., 1.0 / 0.4.0): 1.6.0 / 0.7.0\r\n - OS (e.g., Linux): Arch Linux\r\n - How you installed PyTorch / torchvision (`conda`, `pip`, source): packet manager (pacman) / built from source\r\n - Build command you used (if compiling from source): cmake FORCE_CUDA=ON && make $$ make install\r\n - Python version: 3.8\r\n - CUDA/cuDNN version: 11.0.2 / 8.0.0\r\n - GPU models and configuration: 2080Ti\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2574", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2574/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2574/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2574/events", "html_url": "https://github.com/pytorch/vision/issues/2574", "id": 676587592, "node_id": "MDU6SXNzdWU2NzY1ODc1OTI=", "number": 2574, "title": "ValueError: bad value(s) in fds_to_keep", "user": {"login": "siyangbing", "id": 38023527, "node_id": "MDQ6VXNlcjM4MDIzNTI3", "avatar_url": "https://avatars0.githubusercontent.com/u/38023527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/siyangbing", "html_url": "https://github.com/siyangbing", "followers_url": "https://api.github.com/users/siyangbing/followers", "following_url": "https://api.github.com/users/siyangbing/following{/other_user}", "gists_url": "https://api.github.com/users/siyangbing/gists{/gist_id}", "starred_url": "https://api.github.com/users/siyangbing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/siyangbing/subscriptions", "organizations_url": "https://api.github.com/users/siyangbing/orgs", "repos_url": "https://api.github.com/users/siyangbing/repos", "events_url": "https://api.github.com/users/siyangbing/events{/privacy}", "received_events_url": "https://api.github.com/users/siyangbing/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-11T05:18:17Z", "updated_at": "2020-08-11T17:21:26Z", "closed_at": "2020-08-11T17:21:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "Traceback (most recent call last):\r\n  File \"/home/sucom/hdd_1T/project/video_rec/my_video_rec/self_video_train.py\", line 161, in <module>\r\n    trainer.train(task)\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/site-packages/classy_vision/trainer/local_trainer.py\", line 27, in train\r\n    super().train(task)\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/site-packages/classy_vision/trainer/classy_trainer.py\", line 45, in train\r\n    task.on_phase_start()\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/site-packages/classy_vision/tasks/classification_task.py\", line 945, in on_phase_start\r\n    self.advance_phase()\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/site-packages/classy_vision/tasks/classification_task.py\", line 847, in advance_phase\r\n    self.create_data_iterator()\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/site-packages/classy_vision/tasks/classification_task.py\", line 900, in create_data_iterator\r\n    self.data_iterator = iter(self.dataloaders[self.phase_type])\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 279, in __iter__\r\n    return _MultiProcessingDataLoaderIter(self)\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 721, in __init__\r\n    w.start()\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 59, in _launch\r\n    cmd, self._fds)\r\n  File \"/home/sucom/.conda/envs/classy_vision/lib/python3.6/multiprocessing/util.py\", line 417, in spawnv_passfds\r\n    False, False, None)\r\nValueError: bad value(s) in fds_to_keep\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2572", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2572/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2572/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2572/events", "html_url": "https://github.com/pytorch/vision/issues/2572", "id": 676534036, "node_id": "MDU6SXNzdWU2NzY1MzQwMzY=", "number": 2572, "title": "How to fill in splits_dir and metadata_file in the video classification, my ufc101 data set only has pictures, how can I get them, if I can provide any help, I would be very grateful", "user": {"login": "siyangbing", "id": 38023527, "node_id": "MDQ6VXNlcjM4MDIzNTI3", "avatar_url": "https://avatars0.githubusercontent.com/u/38023527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/siyangbing", "html_url": "https://github.com/siyangbing", "followers_url": "https://api.github.com/users/siyangbing/followers", "following_url": "https://api.github.com/users/siyangbing/following{/other_user}", "gists_url": "https://api.github.com/users/siyangbing/gists{/gist_id}", "starred_url": "https://api.github.com/users/siyangbing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/siyangbing/subscriptions", "organizations_url": "https://api.github.com/users/siyangbing/orgs", "repos_url": "https://api.github.com/users/siyangbing/repos", "events_url": "https://api.github.com/users/siyangbing/events{/privacy}", "received_events_url": "https://api.github.com/users/siyangbing/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-11T02:35:10Z", "updated_at": "2020-08-11T06:16:55Z", "closed_at": "2020-08-11T06:16:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n### Please note that this issue tracker is not a help form and this issue will be closed.\r\n\r\nWe have a set of [listed resources available on the website](https://pytorch.org/resources). Our primary means of support is our discussion forum:\r\n\r\n- [Discussion Forum](https://discuss.pytorch.org/)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2571", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2571/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2571/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2571/events", "html_url": "https://github.com/pytorch/vision/issues/2571", "id": 676059941, "node_id": "MDU6SXNzdWU2NzYwNTk5NDE=", "number": 2571, "title": "Travis CI is broken on onnx tests", "user": {"login": "vfdev-5", "id": 2459423, "node_id": "MDQ6VXNlcjI0NTk0MjM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2459423?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vfdev-5", "html_url": "https://github.com/vfdev-5", "followers_url": "https://api.github.com/users/vfdev-5/followers", "following_url": "https://api.github.com/users/vfdev-5/following{/other_user}", "gists_url": "https://api.github.com/users/vfdev-5/gists{/gist_id}", "starred_url": "https://api.github.com/users/vfdev-5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vfdev-5/subscriptions", "organizations_url": "https://api.github.com/users/vfdev-5/orgs", "repos_url": "https://api.github.com/users/vfdev-5/repos", "events_url": "https://api.github.com/users/vfdev-5/events{/privacy}", "received_events_url": "https://api.github.com/users/vfdev-5/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2171914405, "node_id": "MDU6TGFiZWwyMTcxOTE0NDA1", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ci", "name": "module: ci", "color": "e2908e", "default": false, "description": ""}, {"id": 1706804376, "node_id": "MDU6TGFiZWwxNzA2ODA0Mzc2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20onnx", "name": "module: onnx", "color": "edaea8", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-10T11:20:36Z", "updated_at": "2020-08-14T18:12:45Z", "closed_at": "2020-08-14T18:12:45Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nCurrently, Travis CI is failing on `test_onnx.py`\r\n\r\n> E       onnxruntime.capi.onnxruntime_pybind11_state.NotImplemented: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for the node Greater_1795:Greater(9)\r\n\r\nhttps://travis-ci.org/github/pytorch/vision/jobs/716516509#L704\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2567", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2567/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2567/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2567/events", "html_url": "https://github.com/pytorch/vision/issues/2567", "id": 675907309, "node_id": "MDU6SXNzdWU2NzU5MDczMDk=", "number": 2567, "title": "\u600e\u4e48\u53bb\u94fe\u63a5\u81ea\u5df1\u7684PYTHON3", "user": {"login": "ts19970816", "id": 51779812, "node_id": "MDQ6VXNlcjUxNzc5ODEy", "avatar_url": "https://avatars1.githubusercontent.com/u/51779812?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ts19970816", "html_url": "https://github.com/ts19970816", "followers_url": "https://api.github.com/users/ts19970816/followers", "following_url": "https://api.github.com/users/ts19970816/following{/other_user}", "gists_url": "https://api.github.com/users/ts19970816/gists{/gist_id}", "starred_url": "https://api.github.com/users/ts19970816/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ts19970816/subscriptions", "organizations_url": "https://api.github.com/users/ts19970816/orgs", "repos_url": "https://api.github.com/users/ts19970816/repos", "events_url": "https://api.github.com/users/ts19970816/events{/privacy}", "received_events_url": "https://api.github.com/users/ts19970816/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-10T06:39:23Z", "updated_at": "2020-08-10T08:36:50Z", "closed_at": "2020-08-10T08:36:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "ts@ts:~/opt/vision-master/build$ cmake -DCMAKE_PREFIX_PATH=/opt/libtorch-cxx11-abi-shared-with-deps-1.5.0/libtorch -DCMAKE_INSTALL_PREFIX=/where/to/install/torchvision -DCMAKE_BUILD_TYPE=Release ..\r\nCMake Warning at CMakeLists.txt:13 (find_package):\r\n  By not providing \"FindPython3.cmake\" in CMAKE_MODULE_PATH this project has\r\n  asked CMake to find a package configuration file provided by \"Python3\", but\r\n  CMake did not find one.\r\n\r\n  Could not find a package configuration file provided by \"Python3\" with any\r\n  of the following names:\r\n\r\n    Python3Config.cmake\r\n    python3-config.cmake\r\n\r\n  Add the installation prefix of \"Python3\" to CMAKE_PREFIX_PATH or set\r\n  \"Python3_DIR\" to a directory containing one of the above files.  If\r\n  \"Python3\" provides a separate development package or SDK, be sure it has\r\n  been installed.\r\n\r\n\r\n-- Caffe2: CUDA detected: 10.2\r\n-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\r\n-- Caffe2: CUDA toolkit directory: /usr/local/cuda\r\n-- Caffe2: Header version is: 10.2\r\n-- Found cuDNN: v7.6.5  (include: /usr/local/cuda/include, library: /usr/local/cuda/lib64/libcudnn.so)\r\n-- Autodetected CUDA architecture(s):  6.1\r\n-- Added CUDA NVCC flags for: -gencode;arch=compute_61,code=sm_61\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/ts/opt/vision-master/build\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2560", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2560/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2560/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2560/events", "html_url": "https://github.com/pytorch/vision/issues/2560", "id": 674998608, "node_id": "MDU6SXNzdWU2NzQ5OTg2MDg=", "number": 2560, "title": "DeformConv2d(torchvision.ops) view size is not compatible runtime error with loss.backward", "user": {"login": "charlie4284", "id": 37652070, "node_id": "MDQ6VXNlcjM3NjUyMDcw", "avatar_url": "https://avatars2.githubusercontent.com/u/37652070?v=4", "gravatar_id": "", "url": "https://api.github.com/users/charlie4284", "html_url": "https://github.com/charlie4284", "followers_url": "https://api.github.com/users/charlie4284/followers", "following_url": "https://api.github.com/users/charlie4284/following{/other_user}", "gists_url": "https://api.github.com/users/charlie4284/gists{/gist_id}", "starred_url": "https://api.github.com/users/charlie4284/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/charlie4284/subscriptions", "organizations_url": "https://api.github.com/users/charlie4284/orgs", "repos_url": "https://api.github.com/users/charlie4284/repos", "events_url": "https://api.github.com/users/charlie4284/events{/privacy}", "received_events_url": "https://api.github.com/users/charlie4284/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2089185327, "node_id": "MDU6TGFiZWwyMDg5MTg1MzI3", "url": "https://api.github.com/repos/pytorch/vision/labels/high%20priority", "name": "high priority", "color": "b60205", "default": false, "description": ""}, {"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}, {"id": 719389156, "node_id": "MDU6TGFiZWw3MTkzODkxNTY=", "url": "https://api.github.com/repos/pytorch/vision/labels/needs%20reproduction", "name": "needs reproduction", "color": "64fca1", "default": false, "description": null}, {"id": 1868786748, "node_id": "MDU6TGFiZWwxODY4Nzg2NzQ4", "url": "https://api.github.com/repos/pytorch/vision/labels/triage%20review", "name": "triage review", "color": "cc317c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-07T12:57:48Z", "updated_at": "2020-08-08T11:15:53Z", "closed_at": "2020-08-08T11:15:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nRuntime error occurs when `loss.backward()` with `nn.CrossEntropyLoss()` is run. \r\n\r\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead. (view at ../aten/src/ATen/native/TensorShape.cpp:1329)\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create any net using torchvision.ops.DeformConv2d\r\n2. Run loss.backward() on the net with DeformConv2d\r\n3. Runtime Error\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n```\r\nclass SimpleNet(nn.Module):\r\n    def __init__(self, in_channels, num_classes, kernel_size=1, stride=1,\r\n                 dilation=1, groups=1, offset_groups=1):\r\n        super().__init__()\r\n        offset_channels = 2 * kernel_size * kernel_size\r\n        self.conv2d_offset = nn.Conv2d(\r\n            in_channels,\r\n            offset_channels * offset_groups,\r\n            kernel_size=3,\r\n            stride=stride,\r\n            padding=dilation,\r\n            dilation=dilation,\r\n        )\r\n        self.conv2d = DeformConv2d(\r\n            in_channels,\r\n            16,\r\n            kernel_size=kernel_size,\r\n            stride=stride,\r\n            padding=1,\r\n            dilation=dilation,\r\n            groups=groups,\r\n            bias=False\r\n        )\r\n\r\n        self.fc = nn.Linear(16 * 32 * 32, num_classes)\r\n\r\n    def forward(self, x):\r\n        offset = self.conv2d_offset(x)\r\n        x = self.conv2d(x, offset)\r\n        x = x.view(-1, 16 * 32 * 32)\r\n        print(\"X:\", x.shape)\r\n        return self.fc(x)\r\n\r\nfor idx, batch in enumerate(train_loader):\r\n        data, label = batch\r\n        out = model(data.to(device=device))\r\n\r\n        print(\"OUT:\", out.shape)\r\n        print(\"LABEL:\", label.shape)\r\n        optimizer.zero_grad()\r\n\r\n        loss = criterion(out, label.to(device=device))\r\n        losses.append(loss)\r\n        loss.backward() #### <-- ERROR HERE ####\r\n        optimizer.step()\r\n        if idx % 10 == 0:\r\n            print(f\"Loss: {loss}\")\r\n\r\n#### ERROR STACK ####\r\nTraceback (most recent call last):\r\n  File \"deformable.py\", line 72, in <module>\r\n    loss.backward()\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/tensor.py\", line 198, in backward\r\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\r\n  File \"/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\r\n    allow_unreachable=True)  # allow_unreachable flag\r\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead. (view at ../aten/src/ATen/native/TensorShape.cpp:1329)\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x6c (0x7f18a962d36c in /opt/conda/lib/python3.6/site-packages/torch/lib/libc10.so)\r\nframe #1: at::native::view(at::Tensor const&, c10::ArrayRef<long>) + 0x31b (0x7f18ff38939b in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\nframe #2: <unknown function> + 0x31f415b (0x7f18aca4015b in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)\r\nframe #3: <unknown function> + 0x32591b7 (0x7f18acaa51b7 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)\r\nframe #4: <unknown function> + 0x2afc996 (0x7f19012bf996 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\nframe #5: <unknown function> + 0xe5d0c7 (0x7f18ff6200c7 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\nframe #6: at::Tensor::view(c10::ArrayRef<long>) const + 0xff (0x7f18728859df in /opt/conda/lib/python3.6/site-packages/torchvision/_C.so)\r\nframe #7: <unknown function> + 0xdd08e (0x7f18728a808e in /opt/conda/lib/python3.6/site-packages/torchvision/_C.so)\r\nframe #8: DeformConv2d_backward_cuda(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, std::pair<int, int>, std::pair<int, int>, std::pair<int, int>, int, int) + 0x1fc (0x7f18728a9075 in /opt/conda/lib/python3.6/site-packages/torchvision/_C.so)\r\nframe #9: DeformConv2d_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, std::pair<int, int> const&, std::pair<int, int> const&, std::pair<int, int> const&, int, int) + 0x1e2 (0x7f1872822422 in /opt/conda/lib/python3.6/site-packages/torchvision/_C.so)\r\nframe #10: DeformConv2dFunction::backward(torch::autograd::AutogradContext*, std::vector<at::Tensor, std::allocator<at::Tensor> >) + 0x4e9 (0x7f1872840de9 in /opt/conda/lib/python3.6/site-packages/torchvision/_C.so)\r\nframe #11: torch::autograd::CppNode<DeformConv2dFunction>::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x13c (0x7f187284441c in /opt/conda/lib/python3.6/site-packages/torchvision/_C.so)\r\nframe #12: <unknown function> + 0x2bcbb1c (0x7f190138eb1c in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\nframe #13: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x169b (0x7f190138bb8b in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\nframe #14: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x579 (0x7f190138ca89 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\nframe #15: torch::autograd::Engine::thread_init(int) + 0x49 (0x7f1901384569 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)\r\nframe #16: torch::autograd::python::PythonEngine::thread_init(int) + 0x48 (0x7f1904631608 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\r\nframe #17: <unknown function> + 0xc819d (0x7f19072e719d in /opt/conda/bin/../lib/libstdc++.so.6)\r\nframe #18: <unknown function> + 0x76db (0x7f193ccc86db in /lib/x86_64-linux-gnu/libpthread.so.0)\r\nframe #19: clone + 0x3f (0x7f193c9f188f in /lib/x86_64-linux-gnu/libc.so.6)\r\n```\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nNo runtime error\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\nPyTorch version: 1.5.0a0+8f84ded\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.2.89\r\nGPU models and configuration: GPU 0: GeForce GTX 1050 Ti with Max-Q Design\r\nNvidia driver version: 440.100\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip] msgpack-numpy==0.4.3.2\r\n[pip] numpy==1.18.1\r\n[pip] pytorch-transformers==1.1.0\r\n[pip] torch==1.5.0a0+8f84ded\r\n[pip] torchtext==0.4.0\r\n[pip] torchvision==0.6.0a0\r\n[conda] magma-cuda101             2.5.1                         1    local\r\n[conda] mkl                       2019.1                      144  \r\n[conda] mkl-include               2019.1                      144  \r\n[conda] msgpack-numpy             0.4.3.2                  py36_0  \r\n[conda] nomkl                     3.0                           0  \r\n[conda] numpy                     1.18.1           py36h94c655d_0  \r\n[conda] numpy-base                1.18.1           py36h2f8d375_1  \r\n[conda] pytorch-transformers      1.1.0                    pypi_0    pypi\r\n[conda] torch                     1.5.0a0+8f84ded          pypi_0    pypi\r\n[conda] torchtext                 0.4.0                    pypi_0    pypi\r\n[conda] torchvision               0.6.0a0                  pypi_0    pypi\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\nEDIT:\r\n```\r\ntransform = transforms.Compose([transforms.ToTensor()])\r\n\r\ntrain_dataset = datasets.cifar.CIFAR10(\r\n    \"./\", train=True, transform=transform, download=True)\r\ntrain_loader = torch.utils.data.DataLoader(\r\n    train_dataset, BATCH_SIZE, shuffle=True)\r\n```\r\nsimple CIFAR10 dataset used in the example :)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2557", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2557/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2557/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2557/events", "html_url": "https://github.com/pytorch/vision/issues/2557", "id": 674511856, "node_id": "MDU6SXNzdWU2NzQ1MTE4NTY=", "number": 2557, "title": "broken link to documentation in readme", "user": {"login": "martinResearch", "id": 18285382, "node_id": "MDQ6VXNlcjE4Mjg1Mzgy", "avatar_url": "https://avatars3.githubusercontent.com/u/18285382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinResearch", "html_url": "https://github.com/martinResearch", "followers_url": "https://api.github.com/users/martinResearch/followers", "following_url": "https://api.github.com/users/martinResearch/following{/other_user}", "gists_url": "https://api.github.com/users/martinResearch/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinResearch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinResearch/subscriptions", "organizations_url": "https://api.github.com/users/martinResearch/orgs", "repos_url": "https://api.github.com/users/martinResearch/repos", "events_url": "https://api.github.com/users/martinResearch/events{/privacy}", "received_events_url": "https://api.github.com/users/martinResearch/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1391938214, "node_id": "MDU6TGFiZWwxMzkxOTM4MjE0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20documentation", "name": "module: documentation", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "jlin27", "id": 8042156, "node_id": "MDQ6VXNlcjgwNDIxNTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/8042156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlin27", "html_url": "https://github.com/jlin27", "followers_url": "https://api.github.com/users/jlin27/followers", "following_url": "https://api.github.com/users/jlin27/following{/other_user}", "gists_url": "https://api.github.com/users/jlin27/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlin27/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlin27/subscriptions", "organizations_url": "https://api.github.com/users/jlin27/orgs", "repos_url": "https://api.github.com/users/jlin27/repos", "events_url": "https://api.github.com/users/jlin27/events{/privacy}", "received_events_url": "https://api.github.com/users/jlin27/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jlin27", "id": 8042156, "node_id": "MDQ6VXNlcjgwNDIxNTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/8042156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlin27", "html_url": "https://github.com/jlin27", "followers_url": "https://api.github.com/users/jlin27/followers", "following_url": "https://api.github.com/users/jlin27/following{/other_user}", "gists_url": "https://api.github.com/users/jlin27/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlin27/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlin27/subscriptions", "organizations_url": "https://api.github.com/users/jlin27/orgs", "repos_url": "https://api.github.com/users/jlin27/repos", "events_url": "https://api.github.com/users/jlin27/events{/privacy}", "received_events_url": "https://api.github.com/users/jlin27/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-08-06T18:21:38Z", "updated_at": "2020-08-19T16:42:35Z", "closed_at": "2020-08-19T16:42:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n the link to the documentation in the readme file [http://pytorch.org/docs/master/torchvision/](http://pytorch.org/docs/master/torchvision/) is broken. It should be replaced by [https://pytorch.org/docs/stable/torchvision](https://pytorch.org/docs/stable/torchvision) I believe.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2555", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2555/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2555/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2555/events", "html_url": "https://github.com/pytorch/vision/issues/2555", "id": 673527297, "node_id": "MDU6SXNzdWU2NzM1MjcyOTc=", "number": 2555, "title": "Unable to load fasterrcnn state_dict with custom num_classes", "user": {"login": "devarshi16", "id": 17444318, "node_id": "MDQ6VXNlcjE3NDQ0MzE4", "avatar_url": "https://avatars1.githubusercontent.com/u/17444318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/devarshi16", "html_url": "https://github.com/devarshi16", "followers_url": "https://api.github.com/users/devarshi16/followers", "following_url": "https://api.github.com/users/devarshi16/following{/other_user}", "gists_url": "https://api.github.com/users/devarshi16/gists{/gist_id}", "starred_url": "https://api.github.com/users/devarshi16/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/devarshi16/subscriptions", "organizations_url": "https://api.github.com/users/devarshi16/orgs", "repos_url": "https://api.github.com/users/devarshi16/repos", "events_url": "https://api.github.com/users/devarshi16/events{/privacy}", "received_events_url": "https://api.github.com/users/devarshi16/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-05T13:09:57Z", "updated_at": "2020-08-05T15:14:34Z", "closed_at": "2020-08-05T15:14:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\ntorchvision.models.detection.fasterrcnn_resnet50_fpn() giving error when the parameter pretrained is set to True and num_classes parameter is also supplied(other than 91). \r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\n>> from torchvision import models\r\n>> my_model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True,num_classes=50)\r\n```\r\nThe error that it gives\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/username/miniconda2/envs/form_ocr/lib/python3.7/site-packages/torchvision/models/detection/faster_rcnn.py\", line 354, in fasterrcnn_resnet50_fpn\r\n    model.load_state_dict(state_dict)\r\n  File \"/home/username/miniconda2/envs/form_ocr/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 847, in load_state_dict\r\n    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\nRuntimeError: Error(s) in loading state_dict for FasterRCNN:\r\n\tsize mismatch for roi_heads.box_predictor.cls_score.weight: copying a param with shape torch.Size([91, 1024]) from checkpoint, the shape in current model is torch.Size([50, 1024]).\r\n\tsize mismatch for roi_heads.box_predictor.cls_score.bias: copying a param with shape torch.Size([91]) from checkpoint, the shape in current model is torch.Size([50]).\r\n\tsize mismatch for roi_heads.box_predictor.bbox_pred.weight: copying a param with shape torch.Size([364, 1024]) from checkpoint, the shape in current model is torch.Size([200, 1024]).\r\n\tsize mismatch for roi_heads.box_predictor.bbox_pred.bias: copying a param with shape torch.Size([364]) from checkpoint, the shape in current model is torch.Size([200]).\r\n\r\n```\r\n\r\n## Expected behavior\r\n\r\nI was hoping it would load the state_dict on the base model and then change the `model.roi_heads.box_predictor.cls_score` layer.\r\nSomething like this perhaps,\r\n```\r\nfrom torchvision import models\r\nimport torch.nn as nn\r\n\r\nclass RCNN_Model(nn.Module):\r\n    def __init__(self,pretrained=True,out_classes=91):\r\n        super(RCNN_Model,self).__init__()\r\n        self.model = models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrained)#,num_classes=out_classes)\r\n        if out_classes!=91:\r\n            self.model.roi_heads.box_predictor.cls_score = nn.Linear(in_features=1024,out_features=out_classes,bias=True)\r\n            \r\n    def forward(self,x):\r\n        return self.model(x)\r\n```\r\n\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.5.1\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.13.3\r\n[pip3] torch==1.0.1.post2\r\n[pip3] torchvision==0.4.0\r\n[conda] blas                      1.0                         mkl  \r\n[conda] cudatoolkit               9.0                  h13b8566_0  \r\n[conda] mkl                       2019.4                      243  \r\n[conda] mkl-service               2.3.0            py37he904b0f_0  \r\n[conda] mkl_fft                   1.0.14           py37ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py37hd6b4f25_0  \r\n[conda] numpy                     1.17.4                   pypi_0    pypi\r\n[conda] numpy-base                1.17.2           py37hde5b4d6_0  \r\n[conda] pytorch-nightly           1.0.0.dev20190328 py3.7_cuda9.0.176_cudnn7.4.2_0    pytorch\r\n[conda] torch                     1.5.1                    pypi_0    pypi\r\n[conda] torchvision               0.6.1                    pypi_0    pypi\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2551", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2551/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2551/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2551/events", "html_url": "https://github.com/pytorch/vision/issues/2551", "id": 672654373, "node_id": "MDU6SXNzdWU2NzI2NTQzNzM=", "number": 2551, "title": "Functional affine documentation for Version 1.6.0 on torchvision.functional.transform.affine does not match code", "user": {"login": "Mut1nyJD", "id": 34618634, "node_id": "MDQ6VXNlcjM0NjE4NjM0", "avatar_url": "https://avatars3.githubusercontent.com/u/34618634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mut1nyJD", "html_url": "https://github.com/Mut1nyJD", "followers_url": "https://api.github.com/users/Mut1nyJD/followers", "following_url": "https://api.github.com/users/Mut1nyJD/following{/other_user}", "gists_url": "https://api.github.com/users/Mut1nyJD/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mut1nyJD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mut1nyJD/subscriptions", "organizations_url": "https://api.github.com/users/Mut1nyJD/orgs", "repos_url": "https://api.github.com/users/Mut1nyJD/repos", "events_url": "https://api.github.com/users/Mut1nyJD/events{/privacy}", "received_events_url": "https://api.github.com/users/Mut1nyJD/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1391938214, "node_id": "MDU6TGFiZWwxMzkxOTM4MjE0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20documentation", "name": "module: documentation", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "jlin27", "id": 8042156, "node_id": "MDQ6VXNlcjgwNDIxNTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/8042156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlin27", "html_url": "https://github.com/jlin27", "followers_url": "https://api.github.com/users/jlin27/followers", "following_url": "https://api.github.com/users/jlin27/following{/other_user}", "gists_url": "https://api.github.com/users/jlin27/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlin27/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlin27/subscriptions", "organizations_url": "https://api.github.com/users/jlin27/orgs", "repos_url": "https://api.github.com/users/jlin27/repos", "events_url": "https://api.github.com/users/jlin27/events{/privacy}", "received_events_url": "https://api.github.com/users/jlin27/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jlin27", "id": 8042156, "node_id": "MDQ6VXNlcjgwNDIxNTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/8042156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlin27", "html_url": "https://github.com/jlin27", "followers_url": "https://api.github.com/users/jlin27/followers", "following_url": "https://api.github.com/users/jlin27/following{/other_user}", "gists_url": "https://api.github.com/users/jlin27/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlin27/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlin27/subscriptions", "organizations_url": "https://api.github.com/users/jlin27/orgs", "repos_url": "https://api.github.com/users/jlin27/repos", "events_url": "https://api.github.com/users/jlin27/events{/privacy}", "received_events_url": "https://api.github.com/users/jlin27/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-04T09:38:37Z", "updated_at": "2020-08-19T16:42:54Z", "closed_at": "2020-08-19T16:41:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udcda Documentation\r\n\r\nIf you check the documentation on pytorch.org go to Libraries torchvision/ transforms / functional transforms\r\n\r\nhttps://pytorch.org/docs/stable/torchvision/transforms.html#functional-transforms\r\n\r\nLook at torchvision.transforms.functional.affine\r\nthe documentation says under parameters:\r\n\r\nimg (PIL Image or Tensor) \u2013 image to be rotated.\r\n\r\nBut when you actually use a tensor as input using the official pywheel torchvision0.7cu101 package a tensor import is not supported  if you look at the source code torchvision/transforms/functional.py from the installed package, there is a line like this:\r\n\r\n   if not _is_pil_image(img):\r\n        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\r\n\r\nAlso that source code from the installed package for the function does not match the source link in the pytorch.,org online documentation ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2546", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2546/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2546/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2546/events", "html_url": "https://github.com/pytorch/vision/issues/2546", "id": 671887661, "node_id": "MDU6SXNzdWU2NzE4ODc2NjE=", "number": 2546, "title": "Batch support for torchvision.transforms.functional", "user": {"login": "Shubhammawa", "id": 30144662, "node_id": "MDQ6VXNlcjMwMTQ0NjYy", "avatar_url": "https://avatars3.githubusercontent.com/u/30144662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Shubhammawa", "html_url": "https://github.com/Shubhammawa", "followers_url": "https://api.github.com/users/Shubhammawa/followers", "following_url": "https://api.github.com/users/Shubhammawa/following{/other_user}", "gists_url": "https://api.github.com/users/Shubhammawa/gists{/gist_id}", "starred_url": "https://api.github.com/users/Shubhammawa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Shubhammawa/subscriptions", "organizations_url": "https://api.github.com/users/Shubhammawa/orgs", "repos_url": "https://api.github.com/users/Shubhammawa/repos", "events_url": "https://api.github.com/users/Shubhammawa/events{/privacy}", "received_events_url": "https://api.github.com/users/Shubhammawa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619883, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODM=", "url": "https://api.github.com/repos/pytorch/vision/labels/duplicate", "name": "duplicate", "color": "cccccc", "default": true, "description": null}, {"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-03T08:08:10Z", "updated_at": "2020-08-03T09:11:48Z", "closed_at": "2020-08-03T09:11:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Support for a batch of images in torchvision.transforms.functional.\r\n\r\nCurrently the torchvision.transforms.functional transformations take only a single image as input. Sometimes after creating the dataloader, I need to transform the images during the training loop, but passing the batch of images to transforms.functional raises an error expecting a 2/3 dimensional input while it gets a 4-dimensional input. I am currently solving the issue by looping through the images in the batch but it would be nice if the transforms could handle a batch of images on their own.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2520", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2520/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2520/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2520/events", "html_url": "https://github.com/pytorch/vision/issues/2520", "id": 668384188, "node_id": "MDU6SXNzdWU2NjgzODQxODg=", "number": 2520, "title": "Possible BC break by the use of torch.rand()", "user": {"login": "hkchengrex", "id": 7107196, "node_id": "MDQ6VXNlcjcxMDcxOTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/7107196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hkchengrex", "html_url": "https://github.com/hkchengrex", "followers_url": "https://api.github.com/users/hkchengrex/followers", "following_url": "https://api.github.com/users/hkchengrex/following{/other_user}", "gists_url": "https://api.github.com/users/hkchengrex/gists{/gist_id}", "starred_url": "https://api.github.com/users/hkchengrex/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hkchengrex/subscriptions", "organizations_url": "https://api.github.com/users/hkchengrex/orgs", "repos_url": "https://api.github.com/users/hkchengrex/repos", "events_url": "https://api.github.com/users/hkchengrex/events{/privacy}", "received_events_url": "https://api.github.com/users/hkchengrex/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-30T05:27:43Z", "updated_at": "2020-07-30T10:02:36Z", "closed_at": "2020-07-30T10:02:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I find that `random.random()` was replaced by `torch.rand()` in some of the random transforms (e.g. RandomHorizontalFlip) not in some others (e.g. RandomGrayscale).\r\n\r\nI believe a lot of users rely on the previous `random.random()` behavior by manually seeding `random` to apply an identical transform to the image/segmentation/etc. See this highly upvoted (and thus copied and used) comment: https://github.com/pytorch/vision/issues/9#issuecomment-304224800\r\n\r\nExisting code will still train with inferior performance and it is hard to notice. This is kind of horrible.\r\n\r\nIf the change is inevitable, maybe it can at least be mentioned in the release note? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2519", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2519/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2519/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2519/events", "html_url": "https://github.com/pytorch/vision/issues/2519", "id": 668015797, "node_id": "MDU6SXNzdWU2NjgwMTU3OTc=", "number": 2519, "title": "setup.py dynamically changes the pytorch version dependency.", "user": {"login": "anguelos", "id": 1092463, "node_id": "MDQ6VXNlcjEwOTI0NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/1092463?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anguelos", "html_url": "https://github.com/anguelos", "followers_url": "https://api.github.com/users/anguelos/followers", "following_url": "https://api.github.com/users/anguelos/following{/other_user}", "gists_url": "https://api.github.com/users/anguelos/gists{/gist_id}", "starred_url": "https://api.github.com/users/anguelos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anguelos/subscriptions", "organizations_url": "https://api.github.com/users/anguelos/orgs", "repos_url": "https://api.github.com/users/anguelos/repos", "events_url": "https://api.github.com/users/anguelos/events{/privacy}", "received_events_url": "https://api.github.com/users/anguelos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1588820772, "node_id": "MDU6TGFiZWwxNTg4ODIwNzcy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20binaries", "name": "topic: binaries", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-29T17:30:19Z", "updated_at": "2020-07-30T11:57:05Z", "closed_at": "2020-07-30T11:57:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nsetup.py sets the pytorch dependency version to whatever was available when the package was built.\r\nThis changes the behavior (requirements) of the torchvision package depending on the system on which it is being packaged (setup.py runs).\r\nI believe a dictionary with the table in https://pypi.org/project/torchvision/\r\nI am not sure if I am missing something on why this should be dynamic.\r\nBut as far as I understand, having a version that forces upgrading to 1.6.0 while it is documented requiring <=1.0.1 seems like a bug.\r\n\r\nI believe the solution would be to the table in  https://pypi.org/project/torchvision/ explicitly coded as a dictionary in setup.py\r\n```python\r\nversion = '0.6.0'\r\n\r\n#####\r\n\r\ntorchvion_pytorch_dependencies = {'0.6.0': '1.5.0', '0.5.0': '1.4.0'} # etc\r\n\r\n#####\r\n\r\npytorch_dep = 'torch>=' + torchvion_pytorch_dependencies[version]\r\n\r\n```\r\nAlso I think >= is more flexible than ==  but I am not sure what might be the downside.\r\n\r\nIn conclusion, I am not sure this is a bug but while I can see the drawbacks of such a design, I fail to see the benefits.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nIn a vanilla environment:\r\n```bash\r\n#1) install a reasonable pytorch version eg: 1.5.0\r\npip3 install torch==1.5.0  -f https://download.pytorch.org/whl/torch_stable.html --user\r\npython3 -c \"import torch;print(torch.__version__)\"\r\n# prints 1.5.0+cu92\r\n\r\n#install a very old torchvision version\r\npip3 install torchvision==0.2.2 --user\r\npython3 -c \"import torch;print(torch.__version__)\"\r\n#prints 1.6.0\r\n```\r\n\r\n\r\n## Expected behavior\r\n\r\nI would expect that torchvision 0.2.2 is either satisfied with pytorch 1.5.0 or,  that it enforced a dependency on pytorch<=1.0.1 as documented when it was written (https://pypi.org/project/torchvision/)\r\n\r\n\r\n## Environment\r\n\r\n# This was run after install torchvision 0.2.2\r\n\r\nCollecting environment information...\r\nPyTorch version: 1.6.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: \r\nGPU 0: TITAN V\r\nGPU 1: GeForce GTX 980 Ti\r\n\r\nNvidia driver version: 450.51.06\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.19.1\r\n[pip3] torch==1.6.0\r\n[pip3] torchvision==0.2.2\r\n[conda] Could not collect\r\n```\r\n\r\n - PyTorch / torchvision Version (e.g., 1.0 / 0.4.0):\r\n - OS (e.g., Linux):\r\n - How you installed PyTorch / torchvision (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n## Additional context\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2517", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2517/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2517/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2517/events", "html_url": "https://github.com/pytorch/vision/issues/2517", "id": 667872629, "node_id": "MDU6SXNzdWU2Njc4NzI2Mjk=", "number": 2517, "title": "Resize sometimes fails", "user": {"login": "ag14774", "id": 10788242, "node_id": "MDQ6VXNlcjEwNzg4MjQy", "avatar_url": "https://avatars0.githubusercontent.com/u/10788242?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ag14774", "html_url": "https://github.com/ag14774", "followers_url": "https://api.github.com/users/ag14774/followers", "following_url": "https://api.github.com/users/ag14774/following{/other_user}", "gists_url": "https://api.github.com/users/ag14774/gists{/gist_id}", "starred_url": "https://api.github.com/users/ag14774/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ag14774/subscriptions", "organizations_url": "https://api.github.com/users/ag14774/orgs", "repos_url": "https://api.github.com/users/ag14774/repos", "events_url": "https://api.github.com/users/ag14774/events{/privacy}", "received_events_url": "https://api.github.com/users/ag14774/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-29T14:05:00Z", "updated_at": "2020-08-03T12:40:15Z", "closed_at": "2020-08-03T12:39:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "https://github.com/pytorch/vision/blob/300ef76d3b6e9c33c58cd124e5f5514a927cadf1/torchvision/transforms/functional_tensor.py#L589\r\n\r\nThe specific line above will sometimes cause the image to be returned unresized with no warning even when an explicit size (h,w) is given. This will also cause problems to the transform `RandomResizedCrop`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2514", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2514/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2514/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2514/events", "html_url": "https://github.com/pytorch/vision/issues/2514", "id": 667668588, "node_id": "MDU6SXNzdWU2Njc2Njg1ODg=", "number": 2514, "title": "AttributeError: module 'torch.jit' has no attribute '_script_if_tracing'", "user": {"login": "gnthibault", "id": 5237397, "node_id": "MDQ6VXNlcjUyMzczOTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5237397?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gnthibault", "html_url": "https://github.com/gnthibault", "followers_url": "https://api.github.com/users/gnthibault/followers", "following_url": "https://api.github.com/users/gnthibault/following{/other_user}", "gists_url": "https://api.github.com/users/gnthibault/gists{/gist_id}", "starred_url": "https://api.github.com/users/gnthibault/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gnthibault/subscriptions", "organizations_url": "https://api.github.com/users/gnthibault/orgs", "repos_url": "https://api.github.com/users/gnthibault/repos", "events_url": "https://api.github.com/users/gnthibault/events{/privacy}", "received_events_url": "https://api.github.com/users/gnthibault/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}, {"id": 2238847121, "node_id": "MDU6TGFiZWwyMjM4ODQ3MTIx", "url": "https://api.github.com/repos/pytorch/vision/labels/version%20incompatibility", "name": "version incompatibility", "color": "62d664", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-29T08:51:22Z", "updated_at": "2020-07-30T15:26:20Z", "closed_at": "2020-07-29T08:56:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Dear all, for some reason, I recently started to have problems with torchvision, although it looks like I haven't changed anything recently.\r\n\r\nDo you have any idea what happened ?\r\nThank you in advance for your help\r\n\r\n```\r\n    import segmentation_models_pytorch as smp\r\n  File \"/usr/local/lib/python3.6/dist-packages/segmentation_models_pytorch/__init__.py\", line 1, in <module>\r\n    from .unet import Unet\r\n  File \"/usr/local/lib/python3.6/dist-packages/segmentation_models_pytorch/unet/__init__.py\", line 1, in <module>\r\n    from .model import Unet\r\n  File \"/usr/local/lib/python3.6/dist-packages/segmentation_models_pytorch/unet/model.py\", line 3, in <module>\r\n    from ..encoders import get_encoder\r\n  File \"/usr/local/lib/python3.6/dist-packages/segmentation_models_pytorch/encoders/__init__.py\", line 4, in <module>\r\n    from .resnet import resnet_encoders\r\n  File \"/usr/local/lib/python3.6/dist-packages/segmentation_models_pytorch/encoders/resnet.py\", line 28, in <module>\r\n    from torchvision.models.resnet import ResNet\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/__init__.py\", line 5, in <module>\r\n    from torchvision import models\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/models/__init__.py\", line 12, in <module>\r\n    from . import detection\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\r\n    from .faster_rcnn import *\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\r\n    from torchvision.ops import misc as misc_nn_ops\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/ops/__init__.py\", line 1, in <module>\r\n    from .boxes import nms, box_iou\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/ops/boxes.py\", line 43, in <module>\r\n    @torch.jit._script_if_tracing\r\nAttributeError: module 'torch.jit' has no attribute '_script_if_tracing'\r\n```\r\n\r\nWhich versions am I using:\r\n\r\n> pip freeze | grep torch\r\n> efficientnet-pytorch==0.6.3\r\n> segmentation-models-pytorch==0.1.0\r\n> torch==1.4.0\r\n> torchvision==0.5.0\r\n\r\n\r\n\r\ncc @suo @gmagogsfm", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2512", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2512/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2512/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2512/events", "html_url": "https://github.com/pytorch/vision/issues/2512", "id": 667425714, "node_id": "MDU6SXNzdWU2Njc0MjU3MTQ=", "number": 2512, "title": "Pad() fails on floating point image with TypeError", "user": {"login": "jph00", "id": 346999, "node_id": "MDQ6VXNlcjM0Njk5OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/346999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jph00", "html_url": "https://github.com/jph00", "followers_url": "https://api.github.com/users/jph00/followers", "following_url": "https://api.github.com/users/jph00/following{/other_user}", "gists_url": "https://api.github.com/users/jph00/gists{/gist_id}", "starred_url": "https://api.github.com/users/jph00/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jph00/subscriptions", "organizations_url": "https://api.github.com/users/jph00/orgs", "repos_url": "https://api.github.com/users/jph00/repos", "events_url": "https://api.github.com/users/jph00/events{/privacy}", "received_events_url": "https://api.github.com/users/jph00/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2089185327, "node_id": "MDU6TGFiZWwyMDg5MTg1MzI3", "url": "https://api.github.com/repos/pytorch/vision/labels/high%20priority", "name": "high priority", "color": "b60205", "default": false, "description": ""}, {"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}, {"id": 1868786748, "node_id": "MDU6TGFiZWwxODY4Nzg2NzQ4", "url": "https://api.github.com/repos/pytorch/vision/labels/triage%20review", "name": "triage review", "color": "cc317c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "pmeier", "id": 6849766, "node_id": "MDQ6VXNlcjY4NDk3NjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6849766?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pmeier", "html_url": "https://github.com/pmeier", "followers_url": "https://api.github.com/users/pmeier/followers", "following_url": "https://api.github.com/users/pmeier/following{/other_user}", "gists_url": "https://api.github.com/users/pmeier/gists{/gist_id}", "starred_url": "https://api.github.com/users/pmeier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pmeier/subscriptions", "organizations_url": "https://api.github.com/users/pmeier/orgs", "repos_url": "https://api.github.com/users/pmeier/repos", "events_url": "https://api.github.com/users/pmeier/events{/privacy}", "received_events_url": "https://api.github.com/users/pmeier/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pmeier", "id": 6849766, "node_id": "MDQ6VXNlcjY4NDk3NjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6849766?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pmeier", "html_url": "https://github.com/pmeier", "followers_url": "https://api.github.com/users/pmeier/followers", "following_url": "https://api.github.com/users/pmeier/following{/other_user}", "gists_url": "https://api.github.com/users/pmeier/gists{/gist_id}", "starred_url": "https://api.github.com/users/pmeier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pmeier/subscriptions", "organizations_url": "https://api.github.com/users/pmeier/orgs", "repos_url": "https://api.github.com/users/pmeier/repos", "events_url": "https://api.github.com/users/pmeier/events{/privacy}", "received_events_url": "https://api.github.com/users/pmeier/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-28T22:36:34Z", "updated_at": "2020-07-30T10:04:33Z", "closed_at": "2020-07-30T10:04:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\ntorchvision.transforms.Pad raises `TypeError: must be real number, not tuple`.\r\n\r\n## To Reproduce\r\n\r\n```\r\nimport torch, torchvision, PIL\r\nt = torch.empty(20,16).uniform_(0,1)\r\nx = PIL.Image.fromarray(t.numpy())\r\nf = torchvision.transforms.Pad(2)\r\nf(x)\r\n```\r\n\r\n## Expected behavior\r\n\r\n`x` should be padded. However, instead, `TypeError: must be real number, not tuple` is raised.\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.6.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.243\r\nGPU models and configuration:\r\nGPU 0: TITAN RTX\r\nGPU 1: TITAN RTX\r\nGPU 2: TITAN RTX\r\nGPU 3: TITAN RTX\r\nGPU 4: TITAN RTX\r\nGPU 5: TITAN RTX\r\nGPU 6: TITAN RTX\r\n\r\nNvidia driver version: 440.26\r\ncuDNN version: Probably one of the following:\r\n/usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4\r\n/usr/local/cuda-10.0/lib64/libcudnn.so.7.6.1\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.13.3\r\n[conda] blas                      1.0                         mkl\r\n[conda] cudatoolkit               10.1.243             h6bb024c_0\r\n[conda] mkl                       2019.4                      243\r\n[conda] mkl-service               2.3.0            py37he904b0f_0\r\n[conda] mkl_fft                   1.1.0            py37h23d657b_0\r\n[conda] mkl_random                1.1.0            py37hd6b4f25_0\r\n[conda] numpy                     1.18.5           py37ha1c710e_0\r\n[conda] numpy-base                1.18.5           py37hde5b4d6_0\r\n[conda] numpydoc                  1.1.0                      py_0\r\n[conda] pytorch                   1.6.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\r\n[conda] swish-torch               0.0.1                     dev_0    <develop>\r\n[conda] torchvision               0.7.0                py37_cu101    pytorch\r\n```\r\n\r\n## Additional context\r\n\r\nStack trace:\r\n\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-28-086b6b55847c> in <module>\r\n      4 x = PIL.Image.fromarray(t.numpy())\r\n      5 f = torchvision.transforms.Pad(2)\r\n----> 6 f(x)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py in __call__(self, img)\r\n    338             PIL Image: Padded image.\r\n    339         \"\"\"\r\n--> 340         return F.pad(img, self.padding, self.fill, self.padding_mode)\r\n    341 \r\n    342     def __repr__(self):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py in pad(img, padding, fill, padding_mode)\r\n    405             return image\r\n    406 \r\n--> 407         return ImageOps.expand(img, border=padding, fill=fill)\r\n    408     else:\r\n    409         if isinstance(padding, int):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/PIL/ImageOps.py in expand(image, border, fill)\r\n    360     width = left + image.size[0] + right\r\n    361     height = top + image.size[1] + bottom\r\n--> 362     out = Image.new(image.mode, (width, height), _color(fill, image.mode))\r\n    363     out.paste(image, (left, top))\r\n    364     return out\r\n\r\n~/anaconda3/lib/python3.7/site-packages/PIL/Image.py in new(mode, size, color)\r\n   2611         im.palette = ImagePalette.ImagePalette()\r\n   2612         color = im.palette.getcolor(color)\r\n-> 2613     return im._new(core.fill(mode, size, color))\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2508", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2508/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2508/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2508/events", "html_url": "https://github.com/pytorch/vision/issues/2508", "id": 665612063, "node_id": "MDU6SXNzdWU2NjU2MTIwNjM=", "number": 2508, "title": "Number of anchors VS. number of aspect ratios.", "user": {"login": "fulkast", "id": 9142922, "node_id": "MDQ6VXNlcjkxNDI5MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/9142922?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fulkast", "html_url": "https://github.com/fulkast", "followers_url": "https://api.github.com/users/fulkast/followers", "following_url": "https://api.github.com/users/fulkast/following{/other_user}", "gists_url": "https://api.github.com/users/fulkast/gists{/gist_id}", "starred_url": "https://api.github.com/users/fulkast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fulkast/subscriptions", "organizations_url": "https://api.github.com/users/fulkast/orgs", "repos_url": "https://api.github.com/users/fulkast/repos", "events_url": "https://api.github.com/users/fulkast/events{/privacy}", "received_events_url": "https://api.github.com/users/fulkast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-25T16:15:42Z", "updated_at": "2020-07-30T12:30:11Z", "closed_at": "2020-07-30T12:30:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/pytorch/vision/blob/1aef87d01eec2c0989458387fa04baebcc86ea7b/torchvision/models/detection/faster_rcnn.py#L188\r\n\r\nThe line above seems to fetch, for each location, the number of aspect ratios of anchors (not multiplying by the number of different sized anchors).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2506", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2506/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2506/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2506/events", "html_url": "https://github.com/pytorch/vision/issues/2506", "id": 665141435, "node_id": "MDU6SXNzdWU2NjUxNDE0MzU=", "number": 2506, "title": "ROIAlign.h(29,30): error C2039: 'typed': is not a member of 'c10::OperatorHandle'", "user": {"login": "simonvaj", "id": 32535395, "node_id": "MDQ6VXNlcjMyNTM1Mzk1", "avatar_url": "https://avatars1.githubusercontent.com/u/32535395?v=4", "gravatar_id": "", "url": "https://api.github.com/users/simonvaj", "html_url": "https://github.com/simonvaj", "followers_url": "https://api.github.com/users/simonvaj/followers", "following_url": "https://api.github.com/users/simonvaj/following{/other_user}", "gists_url": "https://api.github.com/users/simonvaj/gists{/gist_id}", "starred_url": "https://api.github.com/users/simonvaj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/simonvaj/subscriptions", "organizations_url": "https://api.github.com/users/simonvaj/orgs", "repos_url": "https://api.github.com/users/simonvaj/repos", "events_url": "https://api.github.com/users/simonvaj/events{/privacy}", "received_events_url": "https://api.github.com/users/simonvaj/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1385340512, "node_id": "MDU6TGFiZWwxMzg1MzQwNTEy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20build", "name": "topic: build", "color": "0e8a16", "default": false, "description": ""}, {"id": 2238847121, "node_id": "MDU6TGFiZWwyMjM4ODQ3MTIx", "url": "https://api.github.com/repos/pytorch/vision/labels/version%20incompatibility", "name": "version incompatibility", "color": "62d664", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-24T12:40:14Z", "updated_at": "2020-07-30T12:20:12Z", "closed_at": "2020-07-28T14:38:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Trying to build the source using cmake with Visual Studio 2019 on Windows, pytorch version: 1.5.1, while compiling  I get the error messages below. I have verified that e.g. `typed` is not a member of `c10::OpeationHandle`, am I mixing versions even though I use the latest torch and torchvision?\r\n\r\nI used the command `cmake --build . --config Release`\r\n\r\n```\r\nD:\\vision-master\\torchvision\\csrc\\ROIAlign.h(29,30): error C2039: 'typed': is not a member of 'c10::OperatorHandle' [D:\\vision-master\\build\\torchvision.vcxproj]\r\nC:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\torch\\include\\ATen/core/dispatch/Dispatcher.h(179): message : see declaration of 'c10::OperatorHandle' [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\ROIAlign.h(29,50): error C2062: type 'at::Tensor (const at::Tensor &,const at::Tensor &,const double,const int64_t,const int64_t,const int64_t,const bool)' unexpected [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\ROIAlign.h(30,12): error C3536: 'op': cannot be used before it is initialized [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\ROIAlign.h(77,17): error C2039: 'typed': is not a member of 'c10::OperatorHandle' [D:\\vision-master\\build\\torchvision.vcxproj]\r\nC:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\torch\\include\\ATen/core/dispatch/Dispatcher.h(179): message : see declaration of 'c10::OperatorHandle' [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\ROIAlign.h(77,47): error C2062: type 'at::Tensor (const at::Tensor &,const at::Tensor &,const double,const int64_t,const int64_t,const int64_t,const int64_t,const int64_t,const int64_t,const int64_t,const bool)' unexpected [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\ROIAlign.h(78,12): error C3536: 'op': cannot be used before it is initialized [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\nms.h(19,30): error C2039: 'typed': is not a member of 'c10::OperatorHandle' [D:\\vision-master\\build\\torchvision.vcxproj]\r\nC:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\torch\\include\\ATen/core/dispatch/Dispatcher.h(179): message : see declaration of 'c10::OperatorHandle' [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\nms.h(19,44): error C2062: type 'at::Tensor (const at::Tensor &,const at::Tensor &,const double)' unexpected [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\nms.h(20,12): error C3536: 'op': cannot be used before it is initialized [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(45,15): error C2065: 'torchvision': undeclared identifier [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(45,28): error C2065: 'm': undeclared identifier [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(45,29): error C4430: missing type specifier - int assumed. Note: C++ does not support default-int [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(45,31): error C2448: 'TORCH_LIBRARY': function-style initializer appears to be a function definition [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(59,20): error C2065: 'torchvision': undeclared identifier [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(59,33): error C2065: 'CPU': undeclared identifier [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(59,38): error C2065: 'm': undeclared identifier [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(59,39): error C4430: missing type specifier - int assumed. Note: C++ does not support default-int [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(59,41): error C2448: 'TORCH_LIBRARY_IMPL': function-style initializer appears to be a function definition [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(82,20): error C2065: 'torchvision': undeclared identifier [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(82,33): error C2065: 'Autograd': undeclared identifier [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(82,43): error C2065: 'm': undeclared identifier [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(82,44): error C4430: missing type specifier - int assumed. Note: C++ does not support default-int [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(82,1): error C2374: 'TORCH_LIBRARY_IMPL': redefinition; multiple initialization [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(59): message : see declaration of 'TORCH_LIBRARY_IMPL' [D:\\vision-master\\build\\torchvision.vcxproj]\r\nD:\\vision-master\\torchvision\\csrc\\vision.cpp(82,46): error C2448: 'TORCH_LIBRARY_IMPL': function-style initializer appears to be a function definition [D:\\vision-master\\build\\torchvision.vcxproj]\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2505", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2505/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2505/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2505/events", "html_url": "https://github.com/pytorch/vision/issues/2505", "id": 665011672, "node_id": "MDU6SXNzdWU2NjUwMTE2NzI=", "number": 2505, "title": "Error when training Resnet with nn.DistributedDataParallel", "user": {"login": "jiahaosuda", "id": 40142236, "node_id": "MDQ6VXNlcjQwMTQyMjM2", "avatar_url": "https://avatars3.githubusercontent.com/u/40142236?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiahaosuda", "html_url": "https://github.com/jiahaosuda", "followers_url": "https://api.github.com/users/jiahaosuda/followers", "following_url": "https://api.github.com/users/jiahaosuda/following{/other_user}", "gists_url": "https://api.github.com/users/jiahaosuda/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiahaosuda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiahaosuda/subscriptions", "organizations_url": "https://api.github.com/users/jiahaosuda/orgs", "repos_url": "https://api.github.com/users/jiahaosuda/repos", "events_url": "https://api.github.com/users/jiahaosuda/events{/privacy}", "received_events_url": "https://api.github.com/users/jiahaosuda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388460222, "node_id": "MDU6TGFiZWwxMzg4NDYwMjIy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20classification", "name": "topic: classification", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-24T08:38:04Z", "updated_at": "2020-08-10T11:51:33Z", "closed_at": "2020-08-03T12:45:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I try to train [Resnet](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py) with `nn.DistributedDataParallel` using multi-gpus, the error occurs as below. But when I use only one gpu, it's just ok. \r\n\r\n![image](https://user-images.githubusercontent.com/40142236/88374211-ed35c280-cdcb-11ea-8f8b-e452e52c11ce.png)\r\n\r\n\r\nSome of the code:\r\n```\r\nclass Bottleneck(nn.Module):\r\n    expansion = 4\r\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n        super(Bottleneck, self).__init__()\r\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)  # decrease the channel, does't change size\r\n        self.bn1 = nn.BatchNorm2d(planes)\r\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\r\n                               padding=1, bias=False)\r\n        self.bn2 = nn.BatchNorm2d(planes)\r\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\r\n        self.bn3 = nn.BatchNorm2d(planes * 4)\r\n        self.relu = nn.ReLU(inplace=False)\r\n        self.downsample = downsample\r\n        self.stride = stride\r\n\r\n    def forward(self, x):\r\n        residual = x\r\n\r\n        out = self.conv1(x)\r\n        out = self.bn1(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv2(out)\r\n        out = self.bn2(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv3(out)\r\n        out = self.bn3(out)\r\n\r\n        if self.downsample is not None:\r\n            residual = self.downsample(x)\r\n\r\n        out = out + residual\r\n        out = self.relu(out)\r\n\r\n        return out\r\n\r\n\r\nclass ResNet(nn.Module):\r\n\r\n    def __init__(self, block, layers, num_classes=9):\r\n        self.inplanes = 64\r\n        super(ResNet, self).__init__()\r\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\r\n                               bias=False)  # the size become 1/2\r\n        self.bn1 = nn.BatchNorm2d(64)\r\n        self.relu = nn.ReLU(inplace=False)\r\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # the size become 1/2\r\n        self.layer1 = self._make_layer(block, 64, layers[0])\r\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\r\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\r\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\r\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n        # self.fc = nn.Linear(512 * block.expansion, num_classes)\r\n        self.fc1 = nn.Linear(2048, 1024)\r\n        self.fc2 = nn.Linear(1024, num_classes)\r\n\r\n\r\n        for m in self.modules():\r\n            if isinstance(m, nn.Conv2d):\r\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\r\n                m.weight.data.normal_(0, math.sqrt(2. / n))\r\n            elif isinstance(m, nn.BatchNorm2d):\r\n                m.weight.data.fill_(1)\r\n                m.bias.data.zero_()\r\n\r\n    def _make_layer(self, block, planes, blocks, stride=1):\r\n        #  block: object, planes: output channel, blocks: the num of blocks\r\n        downsample = None\r\n        if stride != 1 or self.inplanes != planes * block.expansion:\r\n            downsample = nn.Sequential(\r\n                nn.Conv2d(self.inplanes, planes * block.expansion,\r\n                          kernel_size=1, stride=stride, bias=False),\r\n                nn.BatchNorm2d(planes * block.expansion),\r\n            )\r\n\r\n        layers = []\r\n        layers.append(block(self.inplanes, planes, stride, downsample))\r\n        self.inplanes = planes * block.expansion  # the input channel num become 4 times\r\n        for i in range(1, blocks):\r\n            layers.append(block(self.inplanes, planes))\r\n\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.bn1(x)\r\n        x = self.relu(x)\r\n        x = self.maxpool(x)\r\n\r\n        x = self.layer1(x)\r\n        x = self.layer2(x)\r\n        x = self.layer3(x)\r\n        x = self.layer4(x)\r\n\r\n        x = self.avgpool(x)\r\n        x = x.view(x.size(0), -1)\r\n        x = self.fc1(x)\r\n        x = nn.init.normal_(x, mean=0, std=1024 ** -0.5)\r\n        # x = self.fc2(x)\r\n        return x\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2502", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2502/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2502/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2502/events", "html_url": "https://github.com/pytorch/vision/issues/2502", "id": 663769980, "node_id": "MDU6SXNzdWU2NjM3Njk5ODA=", "number": 2502, "title": "Why do we need target put .to(device)?", "user": {"login": "dmitrysarov", "id": 19648595, "node_id": "MDQ6VXNlcjE5NjQ4NTk1", "avatar_url": "https://avatars3.githubusercontent.com/u/19648595?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dmitrysarov", "html_url": "https://github.com/dmitrysarov", "followers_url": "https://api.github.com/users/dmitrysarov/followers", "following_url": "https://api.github.com/users/dmitrysarov/following{/other_user}", "gists_url": "https://api.github.com/users/dmitrysarov/gists{/gist_id}", "starred_url": "https://api.github.com/users/dmitrysarov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dmitrysarov/subscriptions", "organizations_url": "https://api.github.com/users/dmitrysarov/orgs", "repos_url": "https://api.github.com/users/dmitrysarov/repos", "events_url": "https://api.github.com/users/dmitrysarov/events{/privacy}", "received_events_url": "https://api.github.com/users/dmitrysarov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619884, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODQ=", "url": "https://api.github.com/repos/pytorch/vision/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 1373819307, "node_id": "MDU6TGFiZWwxMzczODE5MzA3", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20reference%20scripts", "name": "module: reference scripts", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-22T13:38:19Z", "updated_at": "2020-07-30T12:10:54Z", "closed_at": "2020-07-30T12:10:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Consider key points detection task.\r\nThe question refers to this line \r\nhttps://github.com/pytorch/vision/blob/1aef87d01eec2c0989458387fa04baebcc86ea7b/references/detection/engine.py#L86\r\nSeems to be redundant.\r\nIn my case, I comment out this line and remove .item() in line 95, and at least evaluation starts.\r\nMoreover, COCO dataset output is a tuple({'image_id': int, 'annotations': list(...)}) and I do not get it how it could work in 86 line.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2501", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2501/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2501/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2501/events", "html_url": "https://github.com/pytorch/vision/issues/2501", "id": 663689106, "node_id": "MDU6SXNzdWU2NjM2ODkxMDY=", "number": 2501, "title": "vision executed problem about cuda (warning)", "user": {"login": "Dewey1994", "id": 13182028, "node_id": "MDQ6VXNlcjEzMTgyMDI4", "avatar_url": "https://avatars3.githubusercontent.com/u/13182028?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dewey1994", "html_url": "https://github.com/Dewey1994", "followers_url": "https://api.github.com/users/Dewey1994/followers", "following_url": "https://api.github.com/users/Dewey1994/following{/other_user}", "gists_url": "https://api.github.com/users/Dewey1994/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dewey1994/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dewey1994/subscriptions", "organizations_url": "https://api.github.com/users/Dewey1994/orgs", "repos_url": "https://api.github.com/users/Dewey1994/repos", "events_url": "https://api.github.com/users/Dewey1994/events{/privacy}", "received_events_url": "https://api.github.com/users/Dewey1994/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}, {"id": 1479831546, "node_id": "MDU6TGFiZWwxNDc5ODMxNTQ2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20c++%20frontend", "name": "module: c++ frontend", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-22T11:28:14Z", "updated_at": "2020-07-27T05:21:08Z", "closed_at": "2020-07-25T13:43:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "when i use libtorch=1.5.0  downloaded from pytorch website and vision=0.6.0, both of them compiled with cuda, im using the retinanet to inference with c++.  but , the result of the c++ inference is not correct with warning\r\n\r\n```\r\nWarning: Registered a catch-all kernel for operator torchvision::nms that overwrote a previously registered catch-all kernel for the same operator. (setCatchallKernel at ../aten/src/ATen/core/dispatch/DispatchTable.h:123)\r\n```\r\n\r\n\r\npython code for retinanet\r\n\r\n```python\r\n    def forward(self, inputs):\r\n\r\n        if self.training:\r\n            img_batch, annotations = inputs\r\n        else:\r\n            img_batch = inputs\r\n\r\n        x = self.conv1(img_batch)\r\n        x = self.bn1(x)\r\n        x = self.relu(x)\r\n        x = self.maxpool(x)\r\n\r\n        x1 = self.layer1(x)\r\n        x2 = self.layer2(x1)\r\n        x3 = self.layer3(x2)\r\n        x4 = self.layer4(x3)\r\n\r\n        features = self.fpn([x2, x3, x4])\r\n\r\n        regression = torch.cat([self.regressionModel(feature) for feature in features], dim=1)\r\n\r\n        classification = torch.cat([self.classificationModel(feature) for feature in features], dim=1)\r\n\r\n        anchors = self.anchors(img_batch)\r\n\r\n        if self.training:\r\n            return self.focalLoss(classification, regression, anchors, annotations)\r\n        else:\r\n            transformed_anchors = self.regressBoxes(anchors, regression)\r\n            transformed_anchors = self.clipBoxes(transformed_anchors, img_batch)\r\n\r\n            finalResult = [[], [], []]\r\n\r\n            finalScores = torch.Tensor([])\r\n            finalAnchorBoxesIndexes = torch.Tensor([]).long()\r\n            finalAnchorBoxesCoordinates = torch.Tensor([])\r\n\r\n            if torch.cuda.is_available():\r\n                finalScores = finalScores.cuda()\r\n                finalAnchorBoxesIndexes = finalAnchorBoxesIndexes.cuda()\r\n                finalAnchorBoxesCoordinates = finalAnchorBoxesCoordinates.cuda()\r\n\r\n            for i in range(classification.shape[2]):\r\n                scores = torch.squeeze(classification[:, :, i])\r\n                scores_over_thresh = (scores > 0.05)\r\n                if scores_over_thresh.sum() == 0:\r\n                    # no boxes to NMS, just continue\r\n                    continue\r\n\r\n                scores = scores[scores_over_thresh]\r\n                anchorBoxes = torch.squeeze(transformed_anchors)\r\n                anchorBoxes = anchorBoxes[scores_over_thresh]\r\n                anchors_nms_idx = nms(anchorBoxes, scores, 0.5)\r\n\r\n                finalResult[0].extend(scores[anchors_nms_idx])\r\n                finalResult[1].extend(torch.tensor([i] * anchors_nms_idx.shape[0]))\r\n                finalResult[2].extend(anchorBoxes[anchors_nms_idx])\r\n\r\n                finalScores = torch.cat((finalScores, scores[anchors_nms_idx]))\r\n                finalAnchorBoxesIndexesValue = torch.tensor([i] * anchors_nms_idx.shape[0])\r\n                if torch.cuda.is_available():\r\n                    finalAnchorBoxesIndexesValue = finalAnchorBoxesIndexesValue.cuda()\r\n\r\n                finalAnchorBoxesIndexes = torch.cat((finalAnchorBoxesIndexes, finalAnchorBoxesIndexesValue))\r\n                finalAnchorBoxesCoordinates = torch.cat((finalAnchorBoxesCoordinates, anchorBoxes[anchors_nms_idx]))\r\n\r\n            return finalScores, finalAnchorBoxesIndexes, finalAnchorBoxesCoordinates\r\n```\r\n\r\n\r\n```c++\r\n\r\n#include <iostream>\r\n#include \"torch/script.h\"\r\n#include \"torch/torch.h\"\r\n#include \"torchvision/nms.h\"\r\n#include \"torchvision/ROIAlign.h\"\r\n#include \"torchvision/ROIPool.h\"\r\n#include \"torchvision/empty_tensor_op.h\"\r\n#include<opencv2/opencv.hpp>\r\n#include\"opencv2/highgui/highgui.hpp\"\r\n\r\nusing namespace std;\r\n\r\nstatic auto registry =\r\n        torch::RegisterOperators()\r\n                .op(\"torchvision::nms\", &nms);\r\n             \r\n\r\nint main() {\r\n    cv::Mat img = cv::imread(\"/home/duwei/000467.jpg\");\r\n    //img.convertTo(img,CV_32F);\r\n    cv::imwrite(\"/home/duwei/img.jpg\",img);\r\n    cv::Mat img_resize;\r\n    //img_resize.convertTo(img_resize,CV_32F);\r\n    //cout<<img_resize.type()<<endl;\r\n    int rows = img.rows;\r\n    int cols = img.cols;\r\n    auto channel = img.channels();\r\n    auto smallest_side = min(rows, cols);\r\n    auto largest_side = max(rows, cols);\r\n    float min_side = 608.0;\r\n    float max_side = 1024.0;\r\n    float scale = min_side / smallest_side;\r\n    if(largest_side * scale > max_side)\r\n        scale = max_side/largest_side;\r\n    cv::Size dsize = cv::Size(round(cols*scale), round(rows*scale));\r\n    cv::resize(img,img_resize,dsize,0,0,CV_INTER_AREA);\r\n    cv::imwrite(\"/home/duwei/resize.jpg\",img_resize);\r\n    //cout<<img_resize.type()<<endl;\r\n    rows = img_resize.rows;\r\n    cols = img_resize.cols;\r\n    channel = img_resize.channels();\r\n    //cout<<\"channel=\"<<channel<<endl;\r\n    int pad_w = 32 - rows%32;\r\n    int pad_h = 32 - cols%32;\r\n    //cv::Mat new_image(rows+pad_w, cols+pad_h,CV_8UC3, cv::Scalar(0,0,0));\r\n    img_resize.convertTo(img_resize,CV_32F);\r\n    cv::Mat new_image = cv::Mat::zeros(rows+pad_w, cols+pad_h,CV_32FC3);\r\n    //cout<<img_resize.type()<<endl;\r\n    //cout<<new_image.type()<<endl;\r\n    for(int i=0;i<rows;i++)\r\n    {\r\n        for(int j=0;j<cols;j++)\r\n        {\r\n\r\n            //new_image.at<cv::Vec3b>(i,j)[0]=cv::saturate_cast<float>(((img_resize.at<cv::Vec3b>(i,j)[0]/255.0)-0.485)/0.229);\r\n            new_image.at<cv::Vec3f>(i,j)[0]=((img_resize.at<cv::Vec3f>(i,j)[0]/255.0)-0.485)/0.229;\r\n            //cout<<(new_image.at<cv::Vec3f>(i,j)[0])<<endl;\r\n            // saturate_cast \u9632\u6b62\u6570\u636e\u6ea2\u51fa\r\n            new_image.at<cv::Vec3f>(i,j)[1]=((img_resize.at<cv::Vec3f>(i,j)[1]/255.0)-0.456)/0.224;\r\n            //new_image.at<cv::Vec3b>(i,j)[1]=cv::saturate_cast<float>(((img_resize.at<cv::Vec3b>(i,j)[1]/255.0)-0.456)/0.224);\r\n            new_image.at<cv::Vec3f>(i,j)[2]=((img_resize.at<cv::Vec3f>(i,j)[2]/255.0)-0.406)/0.225;\r\n            //new_image.at<cv::Vec3b>(i,j)[2]=cv::saturate_cast<float>(((img_resize.at<cv::Vec3b>(i,j)[2]/255.0)-0.406)/0.225);\r\n//            cv::Vec3b pix = img_resize.at<cv::Vec3b>(j,i);\r\n//            uchar B = pix[0];\r\n//            uchar G = pix[1];\r\n//            uchar R = pix[2];\r\n//            cout<<\"old:\"<<B<<\" \"<<G<<\" \"<<R<<endl;\r\n//            cv::Vec3b pix_new = new_image.at<cv::Vec3b>(j,i);\r\n//            pix_new[0] = B;\r\n//            pix_new[1] = G;\r\n//            pix_new[2] = R;\r\n//            cout<<\"new:\"<<pix_new[0]<<\" \"<<pix_new[1]<<\" \"<<pix_new[2]<<endl;\r\n\r\n        }\r\n    }\r\n\r\n    cv::imwrite(\"/home/duwei/a.jpg\",new_image);\r\n    if(!new_image.data)\r\n    {\r\n        cout<<\"failed load\"<<endl;\r\n    }\r\n    auto tensor_img = torch::from_blob(new_image.data,{1,new_image.rows,new_image.cols,3}, torch::kByte);\r\n\r\n    tensor_img = tensor_img.toType(torch::kFloat);\r\n//    tensor_img = tensor_img.div(255);\r\n//    tensor_img[0][0] = tensor_img[0][0].sub_(0.485).div_(0.229);\r\n//    tensor_img[0][1] = tensor_img[0][1].sub_(0.456).div_(0.224);\r\n//    tensor_img[0][2] = tensor_img[0][2].sub_(0.406).div_(0.225);\r\n    tensor_img = tensor_img.permute({0,3,1,2});\r\n\r\n    torch::jit::script::Module module;\r\n    try {\r\n        module = torch::jit::load(\"/home/duwei/retinanet.pt\");\r\n    }\r\n    catch (const c10::Error& e) {\r\n        std::cerr << \"error loading the model\\n\";\r\n        return -1;\r\n    }\r\n    torch::DeviceType device_type; //\u8bbe\u7f6eDevice\u7c7b\u578b\r\n    device_type = torch::kCUDA;  //torch::kCUDA  and torch::kCPU\r\n    torch::Device device(device_type, 0);\r\n\r\n    //\u6a21\u578b\u8f6c\u5230GPU\u4e2d\u53bb\r\n    module.to(device);\r\n    module.eval();\r\n    torch::cuda::is_available(); //\u5224\u65ad\u662f\u5426\u652f\u6301GPU\u52a0\u901f\r\n    // Create a vector of inputs.\r\n    std::vector<torch::jit::IValue> inputs;\r\n    inputs.push_back(tensor_img.to(device));\r\n\r\n\r\n    //\u6307\u5b9a\u6267\u884c\u4f4d\u7f6e\r\n    // Execute the model and turn its output into a tensor.\r\n    auto output = module.forward(inputs).toTuple();\r\n    auto scores = output->elements()[0].toTensor();\r\n    auto boxIndex = output->elements()[1].toTensor();\r\n    auto boxCoord = output->elements()[2].toTensor();\r\n    cout<<scores<<endl;\r\n    cout<<boxIndex<<endl;\r\n    cout<<boxCoord<<endl;\r\n    //at::Tensor output1 = module.forward(inputs).toTuple()->elements()[1].toTensor();\r\n    //at::Tensor output2 = module.forward(inputs).toTuple()->elements()[2].toTensor();\r\n\r\n    //std::cout << output.slice(/*dim=*/1, /*start=*/0, /*end=*/5) << '\\n';\r\n\r\n}\r\n\r\n```\r\n\r\nc++ output \r\n```\r\n/home/duwei/axx/cmake-build-debug/testvision\r\nWarning: Registered a catch-all kernel for operator torchvision::nms that overwrote a previously registered catch-all kernel for the same operator. (setCatchallKernel at ../aten/src/ATen/core/dispatch/DispatchTable.h:123)\r\n 1.0000\r\n 0.9998\r\n 0.9996\r\n 0.9968\r\n 0.9936\r\n 0.9597\r\n 0.9220\r\n 0.8982\r\n 0.7435\r\n 0.5531\r\n 0.4879\r\n 0.3955\r\n 0.2697\r\n 0.2050\r\n 0.0811\r\n 0.0747\r\n[ CUDAFloatType{16} ]\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  0\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  1\r\n  2\r\n  2\r\n  2\r\n  2\r\n  2\r\n  2\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  3\r\n  7\r\n  7\r\n  7\r\n  8\r\n  8\r\n  8\r\n 10\r\n 13\r\n 13\r\n 13\r\n 13\r\n 13\r\n 13\r\n 13\r\n 13\r\n 13\r\n 13\r\n 13\r\n 16\r\n 17\r\n 17\r\n 17\r\n 24\r\n 24\r\n 24\r\n 24\r\n 24\r\n 24\r\n 24\r\n 24\r\n 24\r\n 26\r\n 26\r\n 26\r\n 26\r\n 26\r\n 26\r\n 26\r\n 26\r\n 26\r\n 26\r\n 28\r\n 31\r\n 31\r\n 32\r\n 32\r\n 34\r\n 35\r\n 35\r\n 35\r\n 35\r\n 35\r\n 35\r\n 36\r\n 36\r\n 36\r\n 36\r\n 36\r\n 39\r\n 39\r\n 56\r\n 56\r\n[ CUDALongType{194} ]\r\n   0.0000    0.0000  928.0000  640.0000\r\n 518.5232    0.0000  864.2178  640.0000\r\n 504.5483    0.0000  661.3814  640.0000\r\n 124.2457    0.0000  549.2112  640.0000\r\n 337.4405    0.0000  679.1821  640.0000\r\n 435.9211    0.0000  928.0000  368.9894\r\n 400.0215  438.7448  595.5874  640.0000\r\n 393.6984  473.7527  815.1821  640.0000\r\n   0.0000  514.0546  527.2248  640.0000\r\n 728.7057   88.5137  916.1039  640.0000\r\n   0.0000   94.3519  624.0402  328.3116\r\n 502.1493    9.9758  696.1823  315.1542\r\n 210.5342  508.0726  693.8755  640.0000\r\n 322.0452    0.0000  455.6772  640.0000\r\n  49.1752    0.0000  776.7460  295.2959\r\n 657.2726  233.5335  846.3484  620.2892\r\n[ CUDAFloatType{16,4} ]\r\nWarning: Registered a catch-all kernel for operator torchvision::nms that overwrote a previously registered catch-all kernel for the same operator. (setCatchallKernel at ../aten/src/ATen/core/dispatch/DispatchTable.h:123)\r\n```\r\n\r\nthe mid of the input is normal , the others is abnormal\r\n\r\nplease, what should i do", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2500", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2500/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2500/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2500/events", "html_url": "https://github.com/pytorch/vision/issues/2500", "id": 663594274, "node_id": "MDU6SXNzdWU2NjM1OTQyNzQ=", "number": 2500, "title": "Adding more outputs to Faster R-CNN", "user": {"login": "juliwern", "id": 38659984, "node_id": "MDQ6VXNlcjM4NjU5OTg0", "avatar_url": "https://avatars0.githubusercontent.com/u/38659984?v=4", "gravatar_id": "", "url": "https://api.github.com/users/juliwern", "html_url": "https://github.com/juliwern", "followers_url": "https://api.github.com/users/juliwern/followers", "following_url": "https://api.github.com/users/juliwern/following{/other_user}", "gists_url": "https://api.github.com/users/juliwern/gists{/gist_id}", "starred_url": "https://api.github.com/users/juliwern/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/juliwern/subscriptions", "organizations_url": "https://api.github.com/users/juliwern/orgs", "repos_url": "https://api.github.com/users/juliwern/repos", "events_url": "https://api.github.com/users/juliwern/events{/privacy}", "received_events_url": "https://api.github.com/users/juliwern/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1915198580, "node_id": "MDU6TGFiZWwxOTE1MTk4NTgw", "url": "https://api.github.com/repos/pytorch/vision/labels/feature%20request", "name": "feature request", "color": "abf791", "default": false, "description": ""}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-22T08:57:34Z", "updated_at": "2020-08-05T16:33:41Z", "closed_at": "2020-08-05T16:33:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n## \ud83d\ude80 Feature\r\nIn addition to the current output from the Faster R-CNN model, where only the detections after NMS are given out, adding outputs from before the NMS for deeper insight in class distributions.\r\n\r\n## Motivation\r\n\r\nAfter training the network on a custom dataset (with good results actually!), I had found several false positives and wrongly classified objects. It would be useful to me to get a deeper insight how the score for the real object class is and use the class distribution for further processing.\r\n\r\n## Pitch\r\n\r\nMy idea (proposal):\r\nAdding 3 more keys to the output dictionary.\r\nE.g. \"boxes_raw\", \"labels_raw\" and \"scores_raw\" with outputs from before the NMS.\r\n\r\n- boxes_raw [N, num_classes, 4]\r\n- labels_raw [N, num_classes]\r\n- scores_raw [N, num_classes]\r\n\r\n## Alternatives\r\n\r\nNone from my side so far. Would love to hear other approaches\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2498", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2498/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2498/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2498/events", "html_url": "https://github.com/pytorch/vision/issues/2498", "id": 663272601, "node_id": "MDU6SXNzdWU2NjMyNzI2MDE=", "number": 2498, "title": "RuntimeError: No such operator torchvision::deform_conv2d", "user": {"login": "burhanmudassar", "id": 25460500, "node_id": "MDQ6VXNlcjI1NDYwNTAw", "avatar_url": "https://avatars2.githubusercontent.com/u/25460500?v=4", "gravatar_id": "", "url": "https://api.github.com/users/burhanmudassar", "html_url": "https://github.com/burhanmudassar", "followers_url": "https://api.github.com/users/burhanmudassar/followers", "following_url": "https://api.github.com/users/burhanmudassar/following{/other_user}", "gists_url": "https://api.github.com/users/burhanmudassar/gists{/gist_id}", "starred_url": "https://api.github.com/users/burhanmudassar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/burhanmudassar/subscriptions", "organizations_url": "https://api.github.com/users/burhanmudassar/orgs", "repos_url": "https://api.github.com/users/burhanmudassar/repos", "events_url": "https://api.github.com/users/burhanmudassar/events{/privacy}", "received_events_url": "https://api.github.com/users/burhanmudassar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619883, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODM=", "url": "https://api.github.com/repos/pytorch/vision/labels/duplicate", "name": "duplicate", "color": "cccccc", "default": true, "description": null}, {"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}, {"id": 2238847121, "node_id": "MDU6TGFiZWwyMjM4ODQ3MTIx", "url": "https://api.github.com/repos/pytorch/vision/labels/version%20incompatibility", "name": "version incompatibility", "color": "62d664", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-21T20:01:29Z", "updated_at": "2020-08-03T09:51:13Z", "closed_at": "2020-07-30T12:07:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nImporting the DeformConv2D and running it with a sample input throws the error\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nfrom torchvision import ops\r\ndeform_layer = ops.DeformConv2d(in_channels=3, out_channels=64, kernel_size=3) \r\nx = torch.randn((1,3,9,9))\r\noffset = torch.randn(1,3*3*2,7,7)\r\nout = deform_layer(x, offset)\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/bmudassar3/.conda/envs/act/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/home/bmudassar3/.conda/envs/act/lib/python3.6/site-packages/torchvision/ops/deform_conv.py\", line 126, in forward\r\n    padding=self.padding, dilation=self.dilation)\r\n  File \"/home/bmudassar3/.conda/envs/act/lib/python3.6/site-packages/torchvision/ops/deform_conv.py\", line 67, in deform_conv2d\r\n    return torch.ops.torchvision.deform_conv2d(\r\n  File \"/home/bmudassar3/.conda/envs/act/lib/python3.6/site-packages/torch/_ops.py\", line 61, in __getattr__\r\n    op = torch._C._jit_get_operation(qualified_op_name)\r\nRuntimeError: No such operator torchvision::deform_conv2d\r\n```\r\n\r\n## Expected behavior\r\n\r\nOutput of the deformable convolution is generated\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.4.0+cu100\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.0\r\n\r\nOS: Ubuntu 16.04.4 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: \r\nGPU 0: GeForce GTX 1080 Ti\r\nGPU 1: GeForce GTX 1080 Ti\r\n\r\nNvidia driver version: 410.48\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.1.4\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.19.0\r\n[pip3] torch==1.4.0+cu100\r\n[pip3] torchvision==0.5.0\r\n[conda] numpy                     1.19.0                   pypi_0    pypi\r\n[conda] torch                     1.4.0+cu100              pypi_0    pypi\r\n[conda] torchvision               0.5.0                    pypi_0    pypi\r\n\r\n## Additional context\r\n\r\nCould be related to https://github.com/pytorch/vision/issues/1405\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2497", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2497/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2497/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2497/events", "html_url": "https://github.com/pytorch/vision/issues/2497", "id": 662943717, "node_id": "MDU6SXNzdWU2NjI5NDM3MTc=", "number": 2497, "title": "Grayscale image mask is transformed in a performance decreasing way with ToTensor()", "user": {"login": "Areiser", "id": 14922864, "node_id": "MDQ6VXNlcjE0OTIyODY0", "avatar_url": "https://avatars2.githubusercontent.com/u/14922864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Areiser", "html_url": "https://github.com/Areiser", "followers_url": "https://api.github.com/users/Areiser/followers", "following_url": "https://api.github.com/users/Areiser/following{/other_user}", "gists_url": "https://api.github.com/users/Areiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/Areiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Areiser/subscriptions", "organizations_url": "https://api.github.com/users/Areiser/orgs", "repos_url": "https://api.github.com/users/Areiser/repos", "events_url": "https://api.github.com/users/Areiser/events{/privacy}", "received_events_url": "https://api.github.com/users/Areiser/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-21T12:07:06Z", "updated_at": "2020-07-30T12:22:02Z", "closed_at": "2020-07-24T16:56:39Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nPreface: This is only in the context of my usage, where I use a custom dataset for semantic segmentation. My goal was to train different models on a semantic segmentation dataset and obviously I wanted to use the torchvision transforms.\r\nThe dataset does not matter much, but the labels are interesting: The labels are grayscale in a 2d array with values from 0 to NUM_CLASSES). (I mean in form of a PIL image when I say array for the label)\r\n\r\nI realized after training on a subset of the data, that the performance was incredibly bad and the models could not even overfit on a simple dataset.\r\n\r\nI debugged for a while and finally realized, that the ToTensor() operation changes the arrays from (W, H) to (3, W, H) and the values become some float values because of the [0,255] to [0,1] rescaling. What I did not realize is how much of a performance impact this change has. When just using torch.tensor() to create a tensor from the array, the performance was WAY better (see chart below, the gray performance was using the torch.tensor approach). Note that in the chart, the ONLY change I made is replace the transforms (see in reproduction explanation).\r\n\r\nCharts with MIoU and Loss, pink: HRNet with old transform, orange: DeepLabV3+ with old transform, grey: HRNet with new transform. (All pretrained on a different dataset btw)\r\n![Screenshot from 2020-07-21 14-04-06](https://user-images.githubusercontent.com/14922864/88052834-24516d00-cb5b-11ea-8d18-164190cf329e.png)\r\n\r\n![Screenshot from 2020-07-21 14-04-19](https://user-images.githubusercontent.com/14922864/88052842-27e4f400-cb5b-11ea-8296-5407c6024dba.png)\r\n\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create labelset that does not use RGB labels but uses a grayscale array with each class having a corresponding number\r\n1. Prepare a semantic segmentation model (I used HRNet and DeepLabV3+) for training\r\n1. Load the dataset with these transforms for the labels:  \r\n```\r\nlabel_transform = transforms.Compose([\r\n    transforms.Resize(downsampling_size, interpolation=Image.NEAREST),\r\n    transforms.ToTensor(),\r\n])\r\n```\r\n1. Train the model, plot performance (mIoU is bad even though loss keeps decreasing)\r\n1. Load the dataset with the following different transforms:  \r\n```\r\ncustom_to_tensor = lambda a : torch.tensor(np.array(a))\r\nlabel_transform = transforms.Compose([\r\n    # Nearest interpolation to keep valid labels\r\n    transforms.Resize(downsampling_size, interpolation=Image.NEAREST),\r\n    custom_to_tensor,\r\n])\r\n```\r\n1. Train again, realize the performance is way better??\r\n\r\n## Expected behavior\r\n\r\nToTensor() should not lead to such a huge performance loss when using grayscale image masks :(\r\n\r\n## Environment\r\n\r\nUsing pytorch/pytorch:1.5.1-cuda10.1-cudnn7-runtime with these pip dependencies installed:\r\n* tensorboard==2.2.0\r\n* matplotlib==3.2.2\r\n* tensorboardx==2.0\r\n* Pillow==7.2.0\r\n* numpy==1.19.0\r\n* python-box==5.0.1\r\n* pytorch-ignite==0.4.0.post1 \r\n\r\n GPU is Nvidia Quadro P6000, only used one so far\r\n\r\n\r\n## Additional context\r\n\r\nI realize this might not be a bug per definition, but it still threw me for a loop. I absolutely did not expect the simple usage of ToTensor() to hinder the performance this much.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2490", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2490/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2490/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2490/events", "html_url": "https://github.com/pytorch/vision/issues/2490", "id": 660829124, "node_id": "MDU6SXNzdWU2NjA4MjkxMjQ=", "number": 2490, "title": "[Bug?] Lack of frames using torchvision.io.video_read", "user": {"login": "JuanFMontesinos", "id": 32466310, "node_id": "MDQ6VXNlcjMyNDY2MzEw", "avatar_url": "https://avatars2.githubusercontent.com/u/32466310?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JuanFMontesinos", "html_url": "https://github.com/JuanFMontesinos", "followers_url": "https://api.github.com/users/JuanFMontesinos/followers", "following_url": "https://api.github.com/users/JuanFMontesinos/following{/other_user}", "gists_url": "https://api.github.com/users/JuanFMontesinos/gists{/gist_id}", "starred_url": "https://api.github.com/users/JuanFMontesinos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JuanFMontesinos/subscriptions", "organizations_url": "https://api.github.com/users/JuanFMontesinos/orgs", "repos_url": "https://api.github.com/users/JuanFMontesinos/repos", "events_url": "https://api.github.com/users/JuanFMontesinos/events{/privacy}", "received_events_url": "https://api.github.com/users/JuanFMontesinos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1447973685, "node_id": "MDU6TGFiZWwxNDQ3OTczNjg1", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20io", "name": "module: io", "color": "f7e101", "default": false, "description": ""}, {"id": 1447974097, "node_id": "MDU6TGFiZWwxNDQ3OTc0MDk3", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20video", "name": "topic: video", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-07-19T13:11:28Z", "updated_at": "2020-08-03T14:37:40Z", "closed_at": "2020-07-28T18:54:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nHi,\r\nI\u2019ve realized that torchvision as well as other libraries suck as skvideo and opencv retrieve less amount of frames than ffmpeg.\r\nI found this happens only for some videos.\r\n\r\nContext:\r\nI ve a rencoded dataset of videos which are 25.0 FPS. Rencoding has been done via ffmpeg. \r\n\r\nRecording (.mkv) contains audio stream and video stream.\r\nBoth streams are same duration (according to metadata info from ffprobe)\r\nAudio stream\u2019s duration match the ones stated by metadata\r\n\r\nExtracting frames via unix command line with ffmpeg provides a proper amount of frames (3688 in case of the given video example)\r\n`ffmpeg -i /media/jfm/Slave/SkDataset/videos/cello/1u3yHICR_BU.mkv  %05d.bmp`\r\n\r\nExtracting frames with other libraries such us skvideo or opencv only obtains 3537 frames. \r\nMy knowledge about the intrisecs of these libraries is limited. I verified that torchvision reader is not discarding frames with negative stamps (seems not to be the case). \r\n\r\nI found a library which captures the proper amount of videos: imageio. However it's reader only counts 3537 frames (but reads 3688)\r\n## To Reproduce\r\n\r\nVideo example to reproduce the issue.\r\nVideo example: https://drive.google.com/file/d/1DIRsDf1SrLOTGbVejoL-PEIlxDPP0LMC/view?usp=sharing\r\n\r\n```\r\nfrom imageio import get_reader, mimread\r\nfrom torchvision.io import read_video\r\n\r\nPATH = '/media/jfm/Slave/SkDataset/videos/cello/1u3yHICR_BU.mkv'\r\n\r\ntorchvision_video, torchvision_audio, info = read_video(PATH, pts_unit='sec')\r\n\r\n# Expected duration\r\ndur = torchvision_audio.shape[1] / info['audio_fps']\r\nmin = dur // 60\r\nsec = dur % 60\r\nprint('Expected duration: %d min, %d sec'%(min,sec))\r\nprint('Expected amount of frames %d'%int(dur*25))\r\nreader = get_reader(PATH)\r\nprint('Expected frames by different readers %d'%reader.count_frames())\r\nprint('Frames obtained by torchvision: %d '%torchvision_video.shape[0])\r\nimageio_video = mimread(PATH, memtest=False)\r\nprint('Frames obtained by imageio: %d' %len(imageio_video))\r\nprint('')\r\n```\r\n\r\n## Environment  \r\nTorchvision version: `0.5.0`\r\nImageio version : `2.5.0`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2481", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2481/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2481/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2481/events", "html_url": "https://github.com/pytorch/vision/issues/2481", "id": 658860928, "node_id": "MDU6SXNzdWU2NTg4NjA5Mjg=", "number": 2481, "title": "How to use torchvision roi_align?", "user": {"login": "Huangxt57", "id": 44627253, "node_id": "MDQ6VXNlcjQ0NjI3MjUz", "avatar_url": "https://avatars3.githubusercontent.com/u/44627253?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Huangxt57", "html_url": "https://github.com/Huangxt57", "followers_url": "https://api.github.com/users/Huangxt57/followers", "following_url": "https://api.github.com/users/Huangxt57/following{/other_user}", "gists_url": "https://api.github.com/users/Huangxt57/gists{/gist_id}", "starred_url": "https://api.github.com/users/Huangxt57/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Huangxt57/subscriptions", "organizations_url": "https://api.github.com/users/Huangxt57/orgs", "repos_url": "https://api.github.com/users/Huangxt57/repos", "events_url": "https://api.github.com/users/Huangxt57/events{/privacy}", "received_events_url": "https://api.github.com/users/Huangxt57/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-17T04:57:15Z", "updated_at": "2020-07-30T14:52:03Z", "closed_at": "2020-07-29T09:59:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm confused about the input parameter `boxes` and output of `torchvision.ops.roi_align`. Now I have an input image and one bbox coordinate `[x1, y1, x2, y2]`. Does `roi_align` directly return the region determined by the coordinate?\r\n\r\nFor exampe, here is my test code:\r\n\r\n```python\r\nimport torch\r\nfrom torchvision.ops import roi_align\r\n\r\na = torch.Tensor([[i * 6 + j for j in range(6)] for i in range(6)])\r\nprint(a)\r\na = a.unsqueeze(dim=0)\r\n\r\nboxes = [torch.Tensor([[0, 2, 2, 4]])]\r\na = a.unsqueeze(dim=0)\r\n\r\naligned_rois = roi_align(input=a, boxes=boxes, output_size=2)\r\nprint(aligned_rois.shape)\r\nprint(\"aligned_rois:\", aligned_rois)\r\n```\r\n\r\nAnd the result is:\r\n\r\n```\r\ntensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\r\n        [ 6.,  7.,  8.,  9., 10., 11.],\r\n        [12., 13., 14., 15., 16., 17.],\r\n        [18., 19., 20., 21., 22., 23.],\r\n        [24., 25., 26., 27., 28., 29.],\r\n        [30., 31., 32., 33., 34., 35.]])\r\ntorch.Size([1, 1, 2, 2])\r\naligned_rois: tensor([[[[15.5000, 16.5000],\r\n          [21.5000, 22.5000]]]])\r\n```\r\nWhat I want to know is why the returned region is `[15, 16; 21, 22]`?\r\n\r\nThanks for answering!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2470", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2470/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2470/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2470/events", "html_url": "https://github.com/pytorch/vision/issues/2470", "id": 656665861, "node_id": "MDU6SXNzdWU2NTY2NjU4NjE=", "number": 2470, "title": "torchvision c++ api build from source, Build error about C++14 and C++11", "user": {"login": "weijian-sun", "id": 13504794, "node_id": "MDQ6VXNlcjEzNTA0Nzk0", "avatar_url": "https://avatars2.githubusercontent.com/u/13504794?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weijian-sun", "html_url": "https://github.com/weijian-sun", "followers_url": "https://api.github.com/users/weijian-sun/followers", "following_url": "https://api.github.com/users/weijian-sun/following{/other_user}", "gists_url": "https://api.github.com/users/weijian-sun/gists{/gist_id}", "starred_url": "https://api.github.com/users/weijian-sun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weijian-sun/subscriptions", "organizations_url": "https://api.github.com/users/weijian-sun/orgs", "repos_url": "https://api.github.com/users/weijian-sun/repos", "events_url": "https://api.github.com/users/weijian-sun/events{/privacy}", "received_events_url": "https://api.github.com/users/weijian-sun/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}, {"id": 1385340512, "node_id": "MDU6TGFiZWwxMzg1MzQwNTEy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20build", "name": "topic: build", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-14T14:39:59Z", "updated_at": "2020-08-03T13:16:18Z", "closed_at": "2020-07-20T08:01:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "##  torchvision c++ api build from source, in master branch, Build error about C++14 and C++11\r\n\r\n### Environment\r\nPyTorch Version:  1.5.1 build from source\r\nOS (e.g., Linux): Ubuntu 16\r\nHow you installed PyTorch (conda, pip, source): source\r\nBuild command you used (if compiling from source): \r\n#!/bin/bash\r\nWORKSPACE=$(cd $(dirname $0);pwd)\r\nexport PATH=/opt/protobuf/bin:$PATH\r\nmkdir build\r\ncd build\r\n/opt/cmake/bin/cmake -DCMAKE_INSTALL_PREFIX=${WORKSPACE}/output \\\r\n      -DCMAKE_PREFIX_PATH=/opt/had_deps/libtorch1.5 -DWITH_CUDA=ON ..\r\nmake -j`getconf _NPROCESSORS_CONF` install\r\nPython version: 3.5\r\nCUDA/cuDNN version: 10.0\r\n\r\n\r\n### error message:\r\n- The C compiler identification is GNU 5.4.0\r\n-- The CXX compiler identification is GNU 5.4.0\r\n-- Check for working C compiler: /usr/bin/cc\r\n-- Check for working C compiler: /usr/bin/cc -- works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Check for working CXX compiler: /usr/bin/c++\r\n-- Check for working CXX compiler: /usr/bin/c++ -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- The CUDA compiler identification is NVIDIA 10.0.130\r\n-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc\r\n-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc -- works\r\n-- Detecting CUDA compiler ABI info\r\n-- Detecting CUDA compiler ABI info - done\r\n-- Found Python3: /usr/lib/python3.5/config-3.5m-x86_64-linux-gnu/libpython3.5m.so (found version \"3.5.2\") found components:  Development\r\n-- Looking for pthread.h\r\n-- Looking for pthread.h - found\r\n-- Looking for pthread_create\r\n-- Looking for pthread_create - not found\r\n-- Looking for pthread_create in pthreads\r\n-- Looking for pthread_create in pthreads - not found\r\n-- Looking for pthread_create in pthread\r\n-- Looking for pthread_create in pthread - found\r\n-- Found Threads: TRUE\r\nCMake Warning (dev) at /opt/had_deps/lib/cmake/protobuf/protobuf-config-version.cmake:50 (if):\r\n  Policy CMP0054 is not set: Only interpret if() arguments as variables or\r\n  keywords when unquoted.  Run \"cmake --help-policy CMP0054\" for policy\r\n  details.  Use the cmake_policy command to set the policy and suppress this\r\n  warning.\r\n\r\n  Quoted variables like \"\" will no longer be dereferenced when the policy is\r\n  set to NEW.  Since the policy is not set the OLD behavior will be used.\r\nCall Stack (most recent call first):\r\n  /opt/had_deps/libtorch1.5/share/cmake/Caffe2/public/protobuf.cmake:4 (find_package)\r\n  /opt/had_deps/libtorch1.5/share/cmake/Caffe2/Caffe2Config.cmake:56 (include)\r\n  /opt/had_deps/libtorch1.5/share/cmake/Torch/TorchConfig.cmake:40 (find_package)\r\n  CMakeLists.txt:16 (find_package)\r\nThis warning is for project developers.  Use -Wno-dev to suppress it.\r\n\r\n-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.8\")\r\n-- Caffe2: Found protobuf with new-style protobuf targets.\r\n-- Caffe2: Protobuf version 3.3.0\r\n-- Found CUDA: /usr/local/cuda (found version \"10.0\")\r\n-- Caffe2: CUDA detected: 10.0\r\n-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\r\n-- Caffe2: CUDA toolkit directory: /usr/local/cuda\r\n-- Caffe2: Header version is: 10.0\r\n-- Found CUDNN: /usr/lib/x86_64-linux-gnu/libcudnn.so\r\n-- Found cuDNN: v7.5.0  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\r\n-- Autodetected CUDA architecture(s):  7.5\r\n-- Added CUDA NVCC flags for: -gencode;arch=compute_75,code=sm_75\r\n-- Found torch: /opt/had_deps/libtorch1.5/lib/libtorch.so\r\n-- Found PNG: /usr/lib/x86_64-linux-gnu/libpng.so (found version \"1.2.54\")\r\n-- Found JPEG: /usr/lib/x86_64-linux-gnu/libjpeg.so (found version \"80\")\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/administrator/workspace/vision/build\r\nScanning dependencies of target torchvision\r\n[  3%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/alexnet.cpp.o\r\n[  7%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/densenet.cpp.o\r\n[ 10%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/googlenet.cpp.o\r\n[ 14%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/inception.cpp.o\r\n[ 17%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/mnasnet.cpp.o\r\n[ 21%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/mobilenet.cpp.o\r\n[ 25%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/resnet.cpp.o\r\n[ 28%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/shufflenetv2.cpp.o\r\n[ 32%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/squeezenet.cpp.o\r\n[ 35%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/vgg.cpp.o\r\n[ 39%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/PSROIAlign_cpu.cpp.o\r\n[ 42%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/DeformConv_cpu.cpp.o\r\n[ 46%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/PSROIPool_cpu.cpp.o\r\n[ 50%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/ROIAlign_cpu.cpp.o\r\n[ 53%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/ROIPool_cpu.cpp.o\r\n[ 57%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/image/image.cpp.o\r\n[ 60%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/image/readjpeg_cpu.cpp.o\r\n[ 64%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/image/readpng_cpu.cpp.o\r\n[ 67%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/nms_cpu.cpp.o\r\n[ 71%] Building CUDA object CMakeFiles/torchvision.dir/torchvision/csrc/cuda/DeformConv_cuda.cu.o\r\nIn file included from /usr/include/c++/5/initializer_list:36:0,\r\n                 from /opt/had_deps/libtorch1.5/include/c10/util/SmallVector.h:31,\r\n                 from /opt/had_deps/libtorch1.5/include/c10/util/ArrayRef.h:18,\r\n                 from /opt/had_deps/libtorch1.5/include/c10/core/MemoryFormat.h:5,\r\n                 from /opt/had_deps/libtorch1.5/include/ATen/core/TensorBody.h:5,\r\n                 from /opt/had_deps/libtorch1.5/include/ATen/Tensor.h:11,\r\n                 from /opt/had_deps/libtorch1.5/include/ATen/Context.h:4,\r\n                 from /opt/had_deps/libtorch1.5/include/ATen/ATen.h:5,\r\n                 from /home/administrator/workspace/vision/torchvision/csrc/cuda/DeformConv_cuda.cu:69:\r\n/usr/include/c++/5/bits/c++0x_warning.h:32:2: error: #error This file requires compiler and library support for the ISO C++ 2011 standard. This support must be enabled with the -std=c++11 or -std=gnu++11 compiler options.\r\n #error This file requires compiler and library support \\\r\n  ^\r\nIn file included from /opt/had_deps/libtorch1.5/include/c10/util/ArrayRef.h:19:0,\r\n                 from /opt/had_deps/libtorch1.5/include/c10/core/MemoryFormat.h:5,\r\n                 from /opt/had_deps/libtorch1.5/include/ATen/core/TensorBody.h:5,\r\n                 from /opt/had_deps/libtorch1.5/include/ATen/Tensor.h:11,\r\n                 from /opt/had_deps/libtorch1.5/include/ATen/Context.h:4,\r\n                 from /opt/had_deps/libtorch1.5/include/ATen/ATen.h:5,\r\n                 from /home/administrator/workspace/vision/torchvision/csrc/cuda/DeformConv_cuda.cu:69:\r\n/opt/had_deps/libtorch1.5/include/c10/util/C++17.h:24:2: error: #error You need C++14 to compile PyTorch\r\n #error You need C++14 to compile PyTorch\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2469", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2469/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2469/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2469/events", "html_url": "https://github.com/pytorch/vision/issues/2469", "id": 656339422, "node_id": "MDU6SXNzdWU2NTYzMzk0MjI=", "number": 2469, "title": "ImageNet pre-trained model code and hyper-parameters", "user": {"login": "Jobanan", "id": 66058062, "node_id": "MDQ6VXNlcjY2MDU4MDYy", "avatar_url": "https://avatars0.githubusercontent.com/u/66058062?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jobanan", "html_url": "https://github.com/Jobanan", "followers_url": "https://api.github.com/users/Jobanan/followers", "following_url": "https://api.github.com/users/Jobanan/following{/other_user}", "gists_url": "https://api.github.com/users/Jobanan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jobanan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jobanan/subscriptions", "organizations_url": "https://api.github.com/users/Jobanan/orgs", "repos_url": "https://api.github.com/users/Jobanan/repos", "events_url": "https://api.github.com/users/Jobanan/events{/privacy}", "received_events_url": "https://api.github.com/users/Jobanan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373819307, "node_id": "MDU6TGFiZWwxMzczODE5MzA3", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20reference%20scripts", "name": "module: reference scripts", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-14T05:35:23Z", "updated_at": "2020-07-14T06:58:07Z", "closed_at": "2020-07-14T06:58:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nIs the code used to trained the torchvision models (especially Resnet) on ImageNet available ? What are the hyper-parameters used  ? Did you use specific methods (dropout, weight decay, specific augmentation such as cutout...etc) during training ? \r\n\r\nThank you very much", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2461", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2461/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2461/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2461/events", "html_url": "https://github.com/pytorch/vision/issues/2461", "id": 655221331, "node_id": "MDU6SXNzdWU2NTUyMjEzMzE=", "number": 2461, "title": "couldn't import models from torchvision", "user": {"login": "Lothakim", "id": 33170472, "node_id": "MDQ6VXNlcjMzMTcwNDcy", "avatar_url": "https://avatars1.githubusercontent.com/u/33170472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lothakim", "html_url": "https://github.com/Lothakim", "followers_url": "https://api.github.com/users/Lothakim/followers", "following_url": "https://api.github.com/users/Lothakim/following{/other_user}", "gists_url": "https://api.github.com/users/Lothakim/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lothakim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lothakim/subscriptions", "organizations_url": "https://api.github.com/users/Lothakim/orgs", "repos_url": "https://api.github.com/users/Lothakim/repos", "events_url": "https://api.github.com/users/Lothakim/events{/privacy}", "received_events_url": "https://api.github.com/users/Lothakim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-11T14:45:16Z", "updated_at": "2020-07-12T15:32:01Z", "closed_at": "2020-07-12T00:13:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was using the textbook **Deep-Learning-with-PyTorch** to get familiar with the pytorch. Here I tried to\r\n`from torchvision import models`\r\nbut failed, the error message is\r\n`module 'torch.jit' has no attribute '_script_if_tracing'`\r\nI have no idea what's wrong. Please help, thank you", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2460", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2460/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2460/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2460/events", "html_url": "https://github.com/pytorch/vision/issues/2460", "id": 655122605, "node_id": "MDU6SXNzdWU2NTUxMjI2MDU=", "number": 2460, "title": "[IO] Add warning in torchvision.io if seeking for a pts out of the video. Silent error otherwise", "user": {"login": "JuanFMontesinos", "id": 32466310, "node_id": "MDQ6VXNlcjMyNDY2MzEw", "avatar_url": "https://avatars2.githubusercontent.com/u/32466310?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JuanFMontesinos", "html_url": "https://github.com/JuanFMontesinos", "followers_url": "https://api.github.com/users/JuanFMontesinos/followers", "following_url": "https://api.github.com/users/JuanFMontesinos/following{/other_user}", "gists_url": "https://api.github.com/users/JuanFMontesinos/gists{/gist_id}", "starred_url": "https://api.github.com/users/JuanFMontesinos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JuanFMontesinos/subscriptions", "organizations_url": "https://api.github.com/users/JuanFMontesinos/orgs", "repos_url": "https://api.github.com/users/JuanFMontesinos/repos", "events_url": "https://api.github.com/users/JuanFMontesinos/events{/privacy}", "received_events_url": "https://api.github.com/users/JuanFMontesinos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1915198580, "node_id": "MDU6TGFiZWwxOTE1MTk4NTgw", "url": "https://api.github.com/repos/pytorch/vision/labels/feature%20request", "name": "feature request", "color": "abf791", "default": false, "description": ""}, {"id": 1447973685, "node_id": "MDU6TGFiZWwxNDQ3OTczNjg1", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20io", "name": "module: io", "color": "f7e101", "default": false, "description": ""}, {"id": 1447974097, "node_id": "MDU6TGFiZWwxNDQ3OTc0MDk3", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20video", "name": "topic: video", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-11T03:14:24Z", "updated_at": "2020-07-29T11:35:41Z", "closed_at": "2020-07-29T11:35:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\nAdd a warning/error when reading a video using `torchvision.io.read_video` and seeking for a timestamp which points out of the video.\r\n\r\n## Motivation\r\nExample:\r\nI have a video which is 30s duration.\r\nI ask video reader to load from t= 35 to t=50.\r\nreader will silently fail to do so and will return the last frame of the video stream.\r\n\r\n## Pitch\r\n\r\nI want to add a simple warning/error to prevent that. Like: \r\n`BufferError('Video stream is trying to seek out of bounds. %s'video_path)`\r\nCan be easily done by checking if max(pts)<seek_offset.   \r\n\r\n\r\nKindly suggested\r\nJuan M\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2458", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2458/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2458/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2458/events", "html_url": "https://github.com/pytorch/vision/issues/2458", "id": 655016647, "node_id": "MDU6SXNzdWU2NTUwMTY2NDc=", "number": 2458, "title": "[do not delete] testing probot", "user": {"login": "astaff", "id": 1032174, "node_id": "MDQ6VXNlcjEwMzIxNzQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1032174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/astaff", "html_url": "https://github.com/astaff", "followers_url": "https://api.github.com/users/astaff/followers", "following_url": "https://api.github.com/users/astaff/following{/other_user}", "gists_url": "https://api.github.com/users/astaff/gists{/gist_id}", "starred_url": "https://api.github.com/users/astaff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/astaff/subscriptions", "organizations_url": "https://api.github.com/users/astaff/orgs", "repos_url": "https://api.github.com/users/astaff/repos", "events_url": "https://api.github.com/users/astaff/events{/privacy}", "received_events_url": "https://api.github.com/users/astaff/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373812224, "node_id": "MDU6TGFiZWwxMzczODEyMjI0", "url": "https://api.github.com/repos/pytorch/vision/labels/windows", "name": "windows", "color": "d4c5f9", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-10T20:23:52Z", "updated_at": "2020-07-24T18:21:17Z", "closed_at": "2020-07-24T18:21:17Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "\n\ncc @astaff", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2449", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2449/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2449/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2449/events", "html_url": "https://github.com/pytorch/vision/issues/2449", "id": 654506699, "node_id": "MDU6SXNzdWU2NTQ1MDY2OTk=", "number": 2449, "title": "Custom Weights for Pytorch Hub for yolo v5", "user": {"login": "sakshamjn", "id": 38393682, "node_id": "MDQ6VXNlcjM4MzkzNjgy", "avatar_url": "https://avatars1.githubusercontent.com/u/38393682?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sakshamjn", "html_url": "https://github.com/sakshamjn", "followers_url": "https://api.github.com/users/sakshamjn/followers", "following_url": "https://api.github.com/users/sakshamjn/following{/other_user}", "gists_url": "https://api.github.com/users/sakshamjn/gists{/gist_id}", "starred_url": "https://api.github.com/users/sakshamjn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sakshamjn/subscriptions", "organizations_url": "https://api.github.com/users/sakshamjn/orgs", "repos_url": "https://api.github.com/users/sakshamjn/repos", "events_url": "https://api.github.com/users/sakshamjn/events{/privacy}", "received_events_url": "https://api.github.com/users/sakshamjn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1899996218, "node_id": "MDU6TGFiZWwxODk5OTk2MjE4", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20hub", "name": "module: hub", "color": "cde228", "default": false, "description": ""}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-10T04:47:29Z", "updated_at": "2020-07-10T06:49:43Z", "closed_at": "2020-07-10T06:23:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\nHello\r\nJust wanted to know if there a way of import yolo v5 model using PyTorch Hub and then loading my custom weights on top of it.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2433", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2433/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2433/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2433/events", "html_url": "https://github.com/pytorch/vision/issues/2433", "id": 653515006, "node_id": "MDU6SXNzdWU2NTM1MTUwMDY=", "number": 2433, "title": "test_rgb2hsv is flaky", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 2089185327, "node_id": "MDU6TGFiZWwyMDg5MTg1MzI3", "url": "https://api.github.com/repos/pytorch/vision/labels/high%20priority", "name": "high priority", "color": "b60205", "default": false, "description": ""}, {"id": 1373821066, "node_id": "MDU6TGFiZWwxMzczODIxMDY2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20tests", "name": "module: tests", "color": "f7e101", "default": false, "description": ""}, {"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-08T18:42:21Z", "updated_at": "2020-07-16T09:56:58Z", "closed_at": "2020-07-16T09:56:58Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It looks like `test_rgb2hsv` is flaky and fails sometimes.\r\n\r\nhttps://app.circleci.com/pipelines/github/pytorch/vision/3217/workflows/77e60582-2ddc-46db-933f-33c45c27387c/jobs/178179/tests\r\n\r\nExample error that we get\r\n```python\r\n    def test_rgb2hsv(self):\r\n        shape = (3, 150, 100)\r\n        for _ in range(20):\r\n            img = torch.rand(*shape, dtype=torch.float)\r\n            ft_hsv_img = F_t._rgb2hsv(img).permute(1, 2, 0).flatten(0, 1)\r\n    \r\n            r, g, b, = img.unbind(0)\r\n            r = r.flatten().numpy()\r\n            g = g.flatten().numpy()\r\n            b = b.flatten().numpy()\r\n    \r\n            hsv = []\r\n            for r1, g1, b1 in zip(r, g, b):\r\n                hsv.append(colorsys.rgb_to_hsv(r1, g1, b1))\r\n    \r\n            colorsys_img = torch.tensor(hsv, dtype=torch.float32)\r\n    \r\n            max_diff = (colorsys_img - ft_hsv_img).abs().max()\r\n>           self.assertLess(max_diff, 1e-5)\r\nE           AssertionError: tensor(1.) not less than 1e-05\r\n\r\ntest\\test_functional_tensor.py:118: AssertionError\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2400", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2400/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2400/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2400/events", "html_url": "https://github.com/pytorch/vision/issues/2400", "id": 651961094, "node_id": "MDU6SXNzdWU2NTE5NjEwOTQ=", "number": 2400, "title": "DownSample", "user": {"login": "jianjiandandande", "id": 15951818, "node_id": "MDQ6VXNlcjE1OTUxODE4", "avatar_url": "https://avatars1.githubusercontent.com/u/15951818?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jianjiandandande", "html_url": "https://github.com/jianjiandandande", "followers_url": "https://api.github.com/users/jianjiandandande/followers", "following_url": "https://api.github.com/users/jianjiandandande/following{/other_user}", "gists_url": "https://api.github.com/users/jianjiandandande/gists{/gist_id}", "starred_url": "https://api.github.com/users/jianjiandandande/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jianjiandandande/subscriptions", "organizations_url": "https://api.github.com/users/jianjiandandande/orgs", "repos_url": "https://api.github.com/users/jianjiandandande/repos", "events_url": "https://api.github.com/users/jianjiandandande/events{/privacy}", "received_events_url": "https://api.github.com/users/jianjiandandande/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-07T03:17:34Z", "updated_at": "2020-07-07T09:21:55Z", "closed_at": "2020-07-07T09:21:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/pytorch/vision/blob/86b6c3e22e9d7d8b0fa25d08704e6a31a364973b/torchvision/models/resnet.py#L195\r\n\r\nWhy don't we need a downsample in this loop??", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2393", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2393/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2393/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2393/events", "html_url": "https://github.com/pytorch/vision/issues/2393", "id": 651033774, "node_id": "MDU6SXNzdWU2NTEwMzM3NzQ=", "number": 2393, "title": "Mask R-CNN: get all the parts and train specific ones", "user": {"login": "FiReTiTi", "id": 6014800, "node_id": "MDQ6VXNlcjYwMTQ4MDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/6014800?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FiReTiTi", "html_url": "https://github.com/FiReTiTi", "followers_url": "https://api.github.com/users/FiReTiTi/followers", "following_url": "https://api.github.com/users/FiReTiTi/following{/other_user}", "gists_url": "https://api.github.com/users/FiReTiTi/gists{/gist_id}", "starred_url": "https://api.github.com/users/FiReTiTi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FiReTiTi/subscriptions", "organizations_url": "https://api.github.com/users/FiReTiTi/orgs", "repos_url": "https://api.github.com/users/FiReTiTi/repos", "events_url": "https://api.github.com/users/FiReTiTi/events{/privacy}", "received_events_url": "https://api.github.com/users/FiReTiTi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-05T09:21:15Z", "updated_at": "2020-07-07T09:33:13Z", "closed_at": "2020-07-07T09:32:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI would like to access all the different parts of Mask R-CNN in order to only train some of them.\r\nI learnt in the discussion forum that I can use `requires_grad` to enable/disable training, but how can I access all the `trainable` parts?\r\nThanks,\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2392", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2392/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2392/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2392/events", "html_url": "https://github.com/pytorch/vision/issues/2392", "id": 650884943, "node_id": "MDU6SXNzdWU2NTA4ODQ5NDM=", "number": 2392, "title": "build error in ubuntu with libpng", "user": {"login": "maminus", "id": 61622237, "node_id": "MDQ6VXNlcjYxNjIyMjM3", "avatar_url": "https://avatars3.githubusercontent.com/u/61622237?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maminus", "html_url": "https://github.com/maminus", "followers_url": "https://api.github.com/users/maminus/followers", "following_url": "https://api.github.com/users/maminus/following{/other_user}", "gists_url": "https://api.github.com/users/maminus/gists{/gist_id}", "starred_url": "https://api.github.com/users/maminus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maminus/subscriptions", "organizations_url": "https://api.github.com/users/maminus/orgs", "repos_url": "https://api.github.com/users/maminus/repos", "events_url": "https://api.github.com/users/maminus/events{/privacy}", "received_events_url": "https://api.github.com/users/maminus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2089185327, "node_id": "MDU6TGFiZWwyMDg5MTg1MzI3", "url": "https://api.github.com/repos/pytorch/vision/labels/high%20priority", "name": "high priority", "color": "b60205", "default": false, "description": ""}, {"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}, {"id": 1385340512, "node_id": "MDU6TGFiZWwxMzg1MzQwNTEy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20build", "name": "topic: build", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "andfoy", "id": 1878982, "node_id": "MDQ6VXNlcjE4Nzg5ODI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1878982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andfoy", "html_url": "https://github.com/andfoy", "followers_url": "https://api.github.com/users/andfoy/followers", "following_url": "https://api.github.com/users/andfoy/following{/other_user}", "gists_url": "https://api.github.com/users/andfoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/andfoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andfoy/subscriptions", "organizations_url": "https://api.github.com/users/andfoy/orgs", "repos_url": "https://api.github.com/users/andfoy/repos", "events_url": "https://api.github.com/users/andfoy/events{/privacy}", "received_events_url": "https://api.github.com/users/andfoy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andfoy", "id": 1878982, "node_id": "MDQ6VXNlcjE4Nzg5ODI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1878982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andfoy", "html_url": "https://github.com/andfoy", "followers_url": "https://api.github.com/users/andfoy/followers", "following_url": "https://api.github.com/users/andfoy/following{/other_user}", "gists_url": "https://api.github.com/users/andfoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/andfoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andfoy/subscriptions", "organizations_url": "https://api.github.com/users/andfoy/orgs", "repos_url": "https://api.github.com/users/andfoy/repos", "events_url": "https://api.github.com/users/andfoy/events{/privacy}", "received_events_url": "https://api.github.com/users/andfoy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-07-04T12:41:10Z", "updated_at": "2020-07-06T20:54:42Z", "closed_at": "2020-07-06T20:54:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI tried to build torchvision package.\r\nI found build error at linking image.so.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```shell\r\n$ git clone https://github.com/pytorch/vision.git\r\n$ cd vision\r\n$ python setup.py install\r\n```\r\nAnd error message.\r\n\r\n```\r\ng++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/data/python3.6/vision/torchvision/csrc/cpu/image/image.o build/temp.linux-x86_64-3.6/data/python3.6/vision/torchvision/csrc/cpu/image/readpng_cpu.o -Llibpng-config: --libdir option is disabled in Debian/Ubuntu -L/var/lib/jenkins/.local/lib/python3.6/site-packages/torch/lib -L/opt/rocm/lib -lpng -lc10 -ltorch -ltorch_cpu -ltorch_python -lc10_hip -ltorch_hip -o build/lib.linux-x86_64-3.6/torchvision/image.so\r\ng++: error: option: No such file or directory\r\ng++: error: is: No such file or directory\r\ng++: error: disabled: No such file or directory\r\ng++: error: in: No such file or directory\r\ng++: error: Debian/Ubuntu: No such file or directory\r\ng++: error: unrecognized command line option \u2018--libdir\u2019; did you mean \u2018--dumpdir\u2019?\r\nerror: command 'g++' failed with exit status 1\r\n```\r\n\r\ng++ option `-Llibpng-config: --libdir option is disabled in Debian/Ubuntu` is wrong.\r\n\r\n## Expected behavior\r\n\r\n`-L` option is correct libpng library path.\r\n\r\n## Root Cause & Environment\r\nNow, setup.py is using libpng-config command with `--libdir` option, but it is disabled in Debian/Ubuntu.\r\n\r\n```shell\r\n$ libpng-config --libdir\r\nlibpng-config: --libdir option is disabled in Debian/Ubuntu\r\n```\r\n\r\nI tried `rocm/pytorch:rocm3.5_ubuntu18.04_py3.6` docker image, but I think it reproduce in normal Ubuntu18.04.\r\n\r\n```shell\r\n$ python -m torch.utils.collect_env\r\nCollecting environment information...\r\nPyTorch version: 1.7.0a0+f083cea\r\nIs debug build: No\r\nCUDA used to build PyTorch: Could not collect\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.14.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.18.1\r\n[pip] torch==1.7.0a0+f083cea\r\n[pip] torchvision==0.8.0a0+75f5b57\r\n[conda] blas                      1.0                         mkl  \r\n[conda] mkl                       2020.1                      217  \r\n[conda] mkl-include               2020.1                      217  \r\n[conda] mkl-service               2.3.0            py36he904b0f_0  \r\n[conda] mkl_fft                   1.0.15           py36ha843d7b_0  \r\n[conda] mkl_random                1.1.1            py36h0573a6f_0  \r\n[conda] numpy                     1.18.1           py36h4f9e942_0  \r\n[conda] numpy-base                1.18.1           py36hde5b4d6_1  \r\n[conda] torchvision               0.8.0a0+75f5b57          pypi_0    pypi\r\n```\r\n* torch : master branch\r\n* torchvision : master branch\r\n\r\n## Additional context\r\n\r\n`--L_opts` option is enabled instead, but it's empty path in my environment.\r\n\r\nSo I tried to following patch, then build is succeeded.\r\n\r\n```diff\r\ndiff --git a/setup.py b/setup.py\r\nindex 01276f1..e95137f 100644\r\n--- a/setup.py\r\n+++ b/setup.py\r\n@@ -262,14 +262,21 @@ def get_extensions():\r\n             png_version = parse_version(png_version)\r\n             if png_version >= parse_version(\"1.6.0\"):\r\n                 print('Building torchvision with PNG image support')\r\n-                png_lib = subprocess.run([libpng, '--libdir'],\r\n+                help_result = subprocess.run([libpng, '--help'],\r\n+                                         stdout=subprocess.PIPE)\r\n+                lib_opt = '--libdir'\r\n+                if '--L_opts' in help_result.stdout.decode('utf-8'):\r\n+                    lib_opt = '--L_opts'\r\n+                png_lib = subprocess.run([libpng, lib_opt],\r\n                                          stdout=subprocess.PIPE)\r\n                 png_include = subprocess.run([libpng, '--I_opts'],\r\n                                              stdout=subprocess.PIPE)\r\n                 png_include = png_include.stdout.strip().decode('utf-8')\r\n                 _, png_include = png_include.split('-I')\r\n                 print('libpng include path: {0}'.format(png_include))\r\n-                image_library += [png_lib.stdout.strip().decode('utf-8')]\r\n+                png_lib = png_lib.stdout.strip().decode('utf-8')\r\n+                if png_lib:\r\n+                    image_library += [png_lib]\r\n                 image_include += [png_include]\r\n                 image_link_flags.append('png')\r\n             else:\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2391", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2391/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2391/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2391/events", "html_url": "https://github.com/pytorch/vision/issues/2391", "id": 650862936, "node_id": "MDU6SXNzdWU2NTA4NjI5MzY=", "number": 2391, "title": "How to Change All BN layers to GN layers?", "user": {"login": "mobassir94", "id": 24439592, "node_id": "MDQ6VXNlcjI0NDM5NTky", "avatar_url": "https://avatars2.githubusercontent.com/u/24439592?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mobassir94", "html_url": "https://github.com/mobassir94", "followers_url": "https://api.github.com/users/mobassir94/followers", "following_url": "https://api.github.com/users/mobassir94/following{/other_user}", "gists_url": "https://api.github.com/users/mobassir94/gists{/gist_id}", "starred_url": "https://api.github.com/users/mobassir94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mobassir94/subscriptions", "organizations_url": "https://api.github.com/users/mobassir94/orgs", "repos_url": "https://api.github.com/users/mobassir94/repos", "events_url": "https://api.github.com/users/mobassir94/events{/privacy}", "received_events_url": "https://api.github.com/users/mobassir94/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-07-04T09:52:25Z", "updated_at": "2020-07-07T09:31:44Z", "closed_at": "2020-07-07T09:31:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "i tried this : \r\n\r\n```\r\nimport torchvision.models as models\r\nmodel  = models.resnet18()\r\n\r\n#then this : \r\n\r\nfor name, module in model.named_modules():\r\n    if isinstance(module, nn.BatchNorm2d):\r\n        # Get current bn layer\r\n        bn = getattr(model, name)\r\n        # Create new gn layer\r\n        gn = nn.GroupNorm(1, bn.num_features)\r\n        # Assign gn\r\n        print('Swapping {} with {}'.format(bn, gn))\r\n        setattr(model, name, gn)\r\n\r\nprint(model)\r\n```\r\n\r\nand it gives this error :\r\n\r\n```\r\nSwapping BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) with GroupNorm(1, 64, eps=1e-05, affine=True)\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-26-dc2f23e093cc> in <module>\r\n      2     if isinstance(module, nn.BatchNorm2d):\r\n      3         # Get current bn layer\r\n----> 4         bn = getattr(model, name)\r\n      5         # Create new gn layer\r\n      6         gn = nn.GroupNorm(1, bn.num_features)\r\n\r\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in __getattr__(self, name)\r\n    592                 return modules[name]\r\n    593         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\r\n--> 594             type(self).__name__, name))\r\n    595 \r\n    596     def __setattr__(self, name, value):\r\n\r\nAttributeError: 'ResNet' object has no attribute 'layer1.0.bn1'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2390", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2390/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2390/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2390/events", "html_url": "https://github.com/pytorch/vision/issues/2390", "id": 650839166, "node_id": "MDU6SXNzdWU2NTA4MzkxNjY=", "number": 2390, "title": "Excessive memory consumption while using DistributedDataParallel ", "user": {"login": "Sentient07", "id": 6195312, "node_id": "MDQ6VXNlcjYxOTUzMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6195312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sentient07", "html_url": "https://github.com/Sentient07", "followers_url": "https://api.github.com/users/Sentient07/followers", "following_url": "https://api.github.com/users/Sentient07/following{/other_user}", "gists_url": "https://api.github.com/users/Sentient07/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sentient07/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sentient07/subscriptions", "organizations_url": "https://api.github.com/users/Sentient07/orgs", "repos_url": "https://api.github.com/users/Sentient07/repos", "events_url": "https://api.github.com/users/Sentient07/events{/privacy}", "received_events_url": "https://api.github.com/users/Sentient07/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-04T06:46:25Z", "updated_at": "2020-07-07T09:44:35Z", "closed_at": "2020-07-07T09:44:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nTL;DR : While using `DistributedDataParallel` and multiple GPU, memory consumption on each GPU seems to be more than twice as much as what is observed when without using `DistributedDataParallel` on a single GPU.\r\n \r\n## To Reproduce\r\n\r\nI have been using FasterRCNN from Torchvision\u2019s models that uses DistributedDataParallel for training. However, I find that while using multiple GPU, the memory consumption is far more than without multiple GPU. Here is my code\r\n\r\n```\r\nkwargs = {}\r\n  kwargs['min_size'] = args.min_size\r\n  kwargs['max_size'] = args.max_size\r\n  model = ModifiedFRCNN(cfg=cfg, custom_anchor=args.custom_anchor,\r\n                        use_def=args.use_def, cpm=args.cpm,\r\n                        default_filter=args.default_filter,\r\n                        soft_nms=args.soft_nms,\r\n                        upscale_r=args.upscale_r, **kwargs).cuda().eval()\r\n  model = restore_network(model)\r\n  model_without_ddp = model\r\n  dataset = GenData(args.test_dataset,\r\n                    args.base_path,\r\n                    dataset_param=None,\r\n                    train=False)\r\n\r\n  if args.n_gpu > 1:\r\n      init_distributed_mode(args)\r\n      model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu],\r\n                                                        find_unused_parameters=True)\r\n      model_without_ddp = model.module\r\n      sampler = torch.utils.data.distributed.DistributedSampler(dataset)\r\n      batch_sampler = torch.utils.data.BatchSampler(sampler,\r\n                                                    args.batch_size,\r\n                                                    drop_last=True)\r\n      data_loader = torch.utils.data.DataLoader(dataset,\r\n                                                batch_sampler=batch_sampler,\r\n                                                num_workers=args.num_workers,\r\n                                                collate_fn=coco_collate)\r\n      metric_logger = MetricLogger(delimiter=\"  \")\r\n      header = 'Valid:'\r\n      batch_iterator = metric_logger.log_every(data_loader, 100, header)\r\n  else:\r\n      model = model.cuda()\r\n      data_loader =  iter(data.DataLoader(dataset, args.batch_size, shuffle=False,\r\n                                                num_workers=args.num_workers,\r\n                                                collate_fn=coco_collate))\r\n      batch_iterator = iter(data_loader)\r\n```\r\n`ModifiedFRCNN` is a class that inherits `FasterRCNN` to make trivial changes, such as parameter, postprocessing etc.\r\nCase 1 : When n_gpu=1, I am able to use a batch size of upto 8.\r\nCase 2 : When n_gpu=4, I am unable to even use a batch size of 1.\r\n\r\nBoth the above mentioned cases are on same the GPU, 2080Ti. \r\n\r\n## Expected behavior\r\n\r\nConsume comparable memory if not equal on each GPUs as the case of training on a single GPU.\r\n\r\n## Environment\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.2.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.0.130\r\n\r\nOS: Debian GNU/Linux 10 (buster)\r\nGCC version: (Debian 8.3.0-6) 8.3.0\r\nCMake version: version 3.13.4\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: \r\nGPU 0: GeForce RTX 2080 Ti\r\nGPU 1: GeForce RTX 2080 Ti\r\n\r\nNvidia driver version: 430.14\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.19.0\r\n[pip3] torch==1.2.0\r\n[pip3] torchvision==0.4.0\r\n```\r\n## Additional context\r\n\r\nThe command I use to launch\r\n\r\n```\r\npython -m torch.distributed.launch --nproc_per_node=4 --use_env test.py <other_arguments> --world_size 4 --n_gpu 4\r\n```\r\n\r\n## PS\r\n\r\nI have posted this issue [here](https://discuss.pytorch.org/t/excessive-memory-consumption-while-using-distributeddataparallel/87568) and since I did not receive any response, I was not sure whether the place where I posted this was correct, hence re-posting here. Apologies if that shouldn't be done.\r\n\r\nThank you!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2387", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2387/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2387/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2387/events", "html_url": "https://github.com/pytorch/vision/issues/2387", "id": 650559176, "node_id": "MDU6SXNzdWU2NTA1NTkxNzY=", "number": 2387, "title": "CelebA dataset error", "user": {"login": "Nilanshrajput", "id": 28673745, "node_id": "MDQ6VXNlcjI4NjczNzQ1", "avatar_url": "https://avatars3.githubusercontent.com/u/28673745?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nilanshrajput", "html_url": "https://github.com/Nilanshrajput", "followers_url": "https://api.github.com/users/Nilanshrajput/followers", "following_url": "https://api.github.com/users/Nilanshrajput/following{/other_user}", "gists_url": "https://api.github.com/users/Nilanshrajput/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nilanshrajput/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nilanshrajput/subscriptions", "organizations_url": "https://api.github.com/users/Nilanshrajput/orgs", "repos_url": "https://api.github.com/users/Nilanshrajput/repos", "events_url": "https://api.github.com/users/Nilanshrajput/events{/privacy}", "received_events_url": "https://api.github.com/users/Nilanshrajput/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619883, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODM=", "url": "https://api.github.com/repos/pytorch/vision/labels/duplicate", "name": "duplicate", "color": "cccccc", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-03T12:15:11Z", "updated_at": "2020-07-03T12:33:34Z", "closed_at": "2020-07-03T12:26:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n CelebA Dataset download produce bad zip file\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n`from torchvision.datasets import CelebA\r\nimport os\r\nos.mkdir('Data')\r\nliader = CelebA(root = '/Data',download=True)`\r\n\r\n\r\n## Environment\r\nOn google Colab \r\nPlease copy and paste the output from our\r\n`Collecting environment information...\r\nPyTorch version: 1.5.1+cu101\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: 10.1.243\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.5\r\n[pip3] torch==1.5.1+cu101\r\n[pip3] torchsummary==1.5.1\r\n[pip3] torchtext==0.3.1\r\n[pip3] torchvision==0.6.1+cu101\r\n[conda] Could not collect`\r\n\r\n\r\n\r\n\r\n## Additional context\r\n\r\n`---------------------------------------------------------------------------\r\nBadZipFile                                Traceback (most recent call last)\r\n<ipython-input-12-1f78590b780f> in <module>()\r\n      2 import os\r\n      3 #os.mkdir('Data')\r\n----> 4 liader = CelebA(root = '/Data',download=True)\r\n\r\n3 frames\r\n/usr/lib/python3.6/zipfile.py in _RealGetContents(self)\r\n   1196             raise BadZipFile(\"File is not a zip file\")\r\n   1197         if not endrec:\r\n-> 1198             raise BadZipFile(\"File is not a zip file\")\r\n   1199         if self.debug > 1:\r\n   1200             print(endrec)\r\n\r\nBadZipFile: File is not a zip file`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2380", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2380/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2380/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2380/events", "html_url": "https://github.com/pytorch/vision/issues/2380", "id": 649376896, "node_id": "MDU6SXNzdWU2NDkzNzY4OTY=", "number": 2380, "title": "ONNX export of FasterRCNN: inference fails when no detections are present", "user": {"login": "drwaltman", "id": 556045, "node_id": "MDQ6VXNlcjU1NjA0NQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/556045?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drwaltman", "html_url": "https://github.com/drwaltman", "followers_url": "https://api.github.com/users/drwaltman/followers", "following_url": "https://api.github.com/users/drwaltman/following{/other_user}", "gists_url": "https://api.github.com/users/drwaltman/gists{/gist_id}", "starred_url": "https://api.github.com/users/drwaltman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drwaltman/subscriptions", "organizations_url": "https://api.github.com/users/drwaltman/orgs", "repos_url": "https://api.github.com/users/drwaltman/repos", "events_url": "https://api.github.com/users/drwaltman/events{/privacy}", "received_events_url": "https://api.github.com/users/drwaltman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 684873012, "node_id": "MDU6TGFiZWw2ODQ4NzMwMTI=", "url": "https://api.github.com/repos/pytorch/vision/labels/awaiting%20response", "name": "awaiting response", "color": "5319e7", "default": false, "description": null}, {"id": 1706804376, "node_id": "MDU6TGFiZWwxNzA2ODA0Mzc2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20onnx", "name": "module: onnx", "color": "edaea8", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-01T22:51:01Z", "updated_at": "2020-07-04T04:42:10Z", "closed_at": "2020-07-03T20:36:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI am running into a similar issue as the one reported in https://github.com/pytorch/vision/issues/2251 where my exported ONNX model fails to run inference when no detections are present, but for FasterRCNN instead of MaskRCNN.\r\n\r\nRunning inference on a random tensor that will not create detections results in a similar runtime exception:\r\n\r\n`RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running ReduceMax node. Name:'ReduceMax_1814' Status Message: /onnxruntime_src/onnxruntime/core/providers/cuda/reduction/reduction_ops.cc:351 onnxruntime::common::Status onnxruntime::cuda::PrepareForReduce(onnxruntime::OpKernelContext*, bool, const std::vector<long int>&, const onnxruntime::Tensor**, onnxruntime::Tensor**, int64_t&, int64_t&, std::vector<long int>&, std::vector<long int>&, std::vector<long int>&, int64_t&, int64_t&) keepdims || dim != 0 was false. Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:{0,4}`\r\n\r\nI updated my environment to use recent torch, torchvision, and onnxruntime versions as instructed in the closed issue, but I still hit the same runtime exception.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior (mostly copied from closed issue):\r\n\r\n1.  Export a pretrained FasterRCNN model to ONNX:\r\n\r\n    ```\r\n    torch.onnx.export(\r\n        model, \r\n        inputs, \r\n        onnx_model_filepath,\r\n        opset_version=11,\r\n        do_constant_folding=True,\r\n        verbose=True,\r\n        input_names=[\r\n            \"data\"\r\n        ],\r\n        output_names=[\r\n            \"boxes\", \r\n            \"labels\", \r\n            \"scores\"\r\n        ],\r\n        dynamic_axes={\r\n            \"data\": [1, 2],\r\n            \"boxes\": [0],\r\n            \"labels\": [0],\r\n            \"scores\": [0]\r\n        }\r\n    )\r\n    ```\r\n\r\n1.  Run inference on an image that will result in detections and see output without failure:\r\n\r\n    ```\r\n    ort_session = onnxruntime.InferenceSession(onnx_model_name)\r\n    input_array = input_tensor.cpu().numpy()\r\n    ort_inputs = {\"data\": input_array}\r\n    ort_outputs = ort_session.run(None, ort_inputs)\r\n    ```\r\n\r\n1.  Run inference on an image that will not result in detections and hit the runtime exception provided above:\r\n\r\n    ```\r\n    random_tensor = torch.randn(input_tensor.shape)\r\n    random_array = random_tensor.cpu().numpy()\r\n    ort_inputs = {\"data\": random_array}\r\n    ort_outputs = ort_session.run(None, ort_inputs)\r\n    ```\r\n\r\n## Expected behavior\r\n\r\nI am expecting output from the ONNX exported FasterRCNN that is similar to the output from the PyTorch version:\r\n\r\n```\r\n[{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward>),\r\n  'labels': tensor([], dtype=torch.int64),\r\n  'scores': tensor([], grad_fn=<IndexBackward>)}]\r\n```\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.7.0a0+4102fbd\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\nCMake version: version 3.10.2\r\n\r\nPython version: 3.8\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.243\r\nGPU models and configuration: \r\nGPU 0: TITAN Xp\r\nGPU 1: TITAN Xp\r\nGPU 2: TITAN Xp\r\n\r\nNvidia driver version: 440.64.00\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.5\r\n[pip3] torch==1.7.0a0+4102fbd\r\n[pip3] torchvision==0.8.0a0+bea6127\r\n[conda] magma-cuda101             2.5.2                         1    pytorch\r\n[conda] mkl                       2020.1                      217  \r\n[conda] mkl-include               2020.1                      219    conda-forge\r\n[conda] numpy                     1.18.5           py38h8854b6b_0    conda-forge\r\n[conda] torch                     1.7.0a0+4102fbd          pypi_0    pypi\r\n[conda] torchvision               0.8.0a0+bea6127          pypi_0    pypi\r\n```\r\n\r\n`!pip freeze | grep onnx`\r\n\r\n```\r\nonnx==1.7.0\r\nonnxruntime-gpu==1.3.0\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2370", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2370/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2370/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2370/events", "html_url": "https://github.com/pytorch/vision/issues/2370", "id": 648123352, "node_id": "MDU6SXNzdWU2NDgxMjMzNTI=", "number": 2370, "title": "focal loss for faster rcnn classification", "user": {"login": "muaz-urwa", "id": 43106180, "node_id": "MDQ6VXNlcjQzMTA2MTgw", "avatar_url": "https://avatars2.githubusercontent.com/u/43106180?v=4", "gravatar_id": "", "url": "https://api.github.com/users/muaz-urwa", "html_url": "https://github.com/muaz-urwa", "followers_url": "https://api.github.com/users/muaz-urwa/followers", "following_url": "https://api.github.com/users/muaz-urwa/following{/other_user}", "gists_url": "https://api.github.com/users/muaz-urwa/gists{/gist_id}", "starred_url": "https://api.github.com/users/muaz-urwa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/muaz-urwa/subscriptions", "organizations_url": "https://api.github.com/users/muaz-urwa/orgs", "repos_url": "https://api.github.com/users/muaz-urwa/repos", "events_url": "https://api.github.com/users/muaz-urwa/events{/privacy}", "received_events_url": "https://api.github.com/users/muaz-urwa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1915198580, "node_id": "MDU6TGFiZWwxOTE1MTk4NTgw", "url": "https://api.github.com/repos/pytorch/vision/labels/feature%20request", "name": "feature request", "color": "abf791", "default": false, "description": ""}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-30T12:14:35Z", "updated_at": "2020-07-30T11:59:21Z", "closed_at": "2020-07-08T17:44:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\nadds focal loss to faster rcnn classification loss\r\n\r\n## Motivation\r\n\r\nThough faster rcnn can cope with issue of class imbalance between foreground and background, using foreground background sampling and related hyper parameters. But imbalance between foreground classes is still a challenge.  Furthermore, hard negative mining is not incorporated in module yet. \r\n\r\nFocal loss can help address these problems. \r\n\r\n## Pitch\r\nCross entropy loss currently used does this:\r\nCE(pt) =\u2212log(pt)\r\nwhere pt = softmax probability of correct class\r\n\r\nFocal loss as defined here is:\r\nFL(pt) =\u2212(1\u2212pt)^\u03b3 log(pt)\r\n\r\nI want an option to chose between the two, so I can empirically deduce the more suitable version for my dataset. \r\n\r\n## Alternatives\r\n\r\n..\r\n\r\n## Additional context\r\n\r\nI have created a pull request with the solution here: https://github.com/pytorch/vision/pull/2369\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2367", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2367/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2367/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2367/events", "html_url": "https://github.com/pytorch/vision/issues/2367", "id": 647711245, "node_id": "MDU6SXNzdWU2NDc3MTEyNDU=", "number": 2367, "title": "torchvision doesn't recompile if torchvision/csrc/ROIAlign.h is edited", "user": {"login": "ezyang", "id": 13564, "node_id": "MDQ6VXNlcjEzNTY0", "avatar_url": "https://avatars0.githubusercontent.com/u/13564?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ezyang", "html_url": "https://github.com/ezyang", "followers_url": "https://api.github.com/users/ezyang/followers", "following_url": "https://api.github.com/users/ezyang/following{/other_user}", "gists_url": "https://api.github.com/users/ezyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ezyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ezyang/subscriptions", "organizations_url": "https://api.github.com/users/ezyang/orgs", "repos_url": "https://api.github.com/users/ezyang/repos", "events_url": "https://api.github.com/users/ezyang/events{/privacy}", "received_events_url": "https://api.github.com/users/ezyang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 2089185327, "node_id": "MDU6TGFiZWwyMDg5MTg1MzI3", "url": "https://api.github.com/repos/pytorch/vision/labels/high%20priority", "name": "high priority", "color": "b60205", "default": false, "description": ""}, {"id": 1385340512, "node_id": "MDU6TGFiZWwxMzg1MzQwNTEy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20build", "name": "topic: build", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-29T22:25:07Z", "updated_at": "2020-07-07T20:08:21Z", "closed_at": "2020-07-07T20:08:21Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Steps to reproduce:\r\n1. Build torchvision `python setup.py develop`\r\n2. Introduce error to torchvision/csrc/ROIAlign.h\r\n3. Rebuild\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2354", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2354/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2354/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2354/events", "html_url": "https://github.com/pytorch/vision/issues/2354", "id": 646590788, "node_id": "MDU6SXNzdWU2NDY1OTA3ODg=", "number": 2354, "title": "[transform_tensor] adjust_hue broken", "user": {"login": "SsnL", "id": 5674597, "node_id": "MDQ6VXNlcjU2NzQ1OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5674597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SsnL", "html_url": "https://github.com/SsnL", "followers_url": "https://api.github.com/users/SsnL/followers", "following_url": "https://api.github.com/users/SsnL/following{/other_user}", "gists_url": "https://api.github.com/users/SsnL/gists{/gist_id}", "starred_url": "https://api.github.com/users/SsnL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SsnL/subscriptions", "organizations_url": "https://api.github.com/users/SsnL/orgs", "repos_url": "https://api.github.com/users/SsnL/repos", "events_url": "https://api.github.com/users/SsnL/events{/privacy}", "received_events_url": "https://api.github.com/users/SsnL/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-27T02:28:54Z", "updated_at": "2020-06-29T13:24:02Z", "closed_at": "2020-06-29T13:08:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<img width=\"1130\" alt=\"Screenshot 2020-06-26 22 28 03\" src=\"https://user-images.githubusercontent.com/5674597/85912687-69081380-b7fc-11ea-9000-c0796980cb09.png\">\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2350", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2350/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2350/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2350/events", "html_url": "https://github.com/pytorch/vision/issues/2350", "id": 644722376, "node_id": "MDU6SXNzdWU2NDQ3MjIzNzY=", "number": 2350, "title": "Support other modes of padding for torch Tensors", "user": {"login": "vfdev-5", "id": 2459423, "node_id": "MDQ6VXNlcjI0NTk0MjM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2459423?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vfdev-5", "html_url": "https://github.com/vfdev-5", "followers_url": "https://api.github.com/users/vfdev-5/followers", "following_url": "https://api.github.com/users/vfdev-5/following{/other_user}", "gists_url": "https://api.github.com/users/vfdev-5/gists{/gist_id}", "starred_url": "https://api.github.com/users/vfdev-5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vfdev-5/subscriptions", "organizations_url": "https://api.github.com/users/vfdev-5/orgs", "repos_url": "https://api.github.com/users/vfdev-5/repos", "events_url": "https://api.github.com/users/vfdev-5/events{/privacy}", "received_events_url": "https://api.github.com/users/vfdev-5/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}, {"id": 1775338355, "node_id": "MDU6TGFiZWwxNzc1MzM4MzU1", "url": "https://api.github.com/repos/pytorch/vision/labels/torchscript", "name": "torchscript", "color": "17d180", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-24T15:48:07Z", "updated_at": "2020-07-02T11:48:42Z", "closed_at": "2020-07-02T11:48:42Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n\r\nFollowing https://github.com/pytorch/vision/pull/2345 we would like to improve the support for other types of `padding_mode` (other than \"constant\") for torch Tensors in `Pad` and `F.pad`\r\n\r\ncc @fmassa \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2348", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2348/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2348/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2348/events", "html_url": "https://github.com/pytorch/vision/issues/2348", "id": 644276340, "node_id": "MDU6SXNzdWU2NDQyNzYzNDA=", "number": 2348, "title": "update_s3_htmls is not running after the nightly build", "user": {"login": "peterjc123", "id": 9998726, "node_id": "MDQ6VXNlcjk5OTg3MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/9998726?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peterjc123", "html_url": "https://github.com/peterjc123", "followers_url": "https://api.github.com/users/peterjc123/followers", "following_url": "https://api.github.com/users/peterjc123/following{/other_user}", "gists_url": "https://api.github.com/users/peterjc123/gists{/gist_id}", "starred_url": "https://api.github.com/users/peterjc123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peterjc123/subscriptions", "organizations_url": "https://api.github.com/users/peterjc123/orgs", "repos_url": "https://api.github.com/users/peterjc123/repos", "events_url": "https://api.github.com/users/peterjc123/events{/privacy}", "received_events_url": "https://api.github.com/users/peterjc123/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-24T02:50:27Z", "updated_at": "2020-06-30T16:42:27Z", "closed_at": "2020-06-30T16:40:13Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nPer title. The download link for those wheels won't be available until the next day.\r\n\r\ncc @seemethere ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2344", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2344/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2344/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2344/events", "html_url": "https://github.com/pytorch/vision/issues/2344", "id": 643873012, "node_id": "MDU6SXNzdWU2NDM4NzMwMTI=", "number": 2344, "title": "TypeError: len() of a 0-d tensor", "user": {"login": "JsPassion", "id": 12843539, "node_id": "MDQ6VXNlcjEyODQzNTM5", "avatar_url": "https://avatars1.githubusercontent.com/u/12843539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JsPassion", "html_url": "https://github.com/JsPassion", "followers_url": "https://api.github.com/users/JsPassion/followers", "following_url": "https://api.github.com/users/JsPassion/following{/other_user}", "gists_url": "https://api.github.com/users/JsPassion/gists{/gist_id}", "starred_url": "https://api.github.com/users/JsPassion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JsPassion/subscriptions", "organizations_url": "https://api.github.com/users/JsPassion/orgs", "repos_url": "https://api.github.com/users/JsPassion/repos", "events_url": "https://api.github.com/users/JsPassion/events{/privacy}", "received_events_url": "https://api.github.com/users/JsPassion/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-23T14:08:39Z", "updated_at": "2020-06-26T12:02:29Z", "closed_at": "2020-06-26T12:02:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nKindly help me to solve the error arising due to assert len(..) = len(..) stmt which was initially written using torch 0.2.0 torchvision 0.1.9 but is causing an issue in torch 1.5.1 torchvision 0.5.0 (for compatibility with cuda 10.1).\r\n\r\nTraceback (most recent call last):\r\nFile \"./main.py\", line 186, in\r\ncuda=cuda\r\nFile \"/home/js/GR/train.py\", line 102, in train\r\ncollate_fn=collate_fn,\r\nFile \"/home/js/GR/dgr.py\", line 130, in train_with_replay\r\ncollate_fn=collate_fn,\r\nFile \"/home/js/GR/dgr.py\", line 205, in _train_batch_trainable_with_replay\r\ncallback(trainable, progress, batch_index, result)\r\nFile \"/home/js/GR/train.py\", line 157, in cb\r\nresult['g_loss'], 'generator g loss', iteration, env=env\r\nFile \"/home/js/GR/visual.py\", line 88, in visualize_scalar\r\n[name], name, iteration, env=env\r\nFile \"/home/js/GR/visual.py\", line 93, in visualize_scalars\r\nassert len(scalars) == len(names)\r\nFile \"/home/js/anaconda3/envs/env_con/lib/python3.5/site-packages/torch/tensor.py\", line 445, in len\r\nraise TypeError(\"len() of a 0-d tensor\")\r\nTypeError: len() of a 0-d tensor", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2339", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2339/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2339/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2339/events", "html_url": "https://github.com/pytorch/vision/issues/2339", "id": 643325558, "node_id": "MDU6SXNzdWU2NDMzMjU1NTg=", "number": 2339, "title": "Nightlies are currently incompatible with upstream nightlies", "user": {"login": "seemethere", "id": 1700823, "node_id": "MDQ6VXNlcjE3MDA4MjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1700823?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seemethere", "html_url": "https://github.com/seemethere", "followers_url": "https://api.github.com/users/seemethere/followers", "following_url": "https://api.github.com/users/seemethere/following{/other_user}", "gists_url": "https://api.github.com/users/seemethere/gists{/gist_id}", "starred_url": "https://api.github.com/users/seemethere/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seemethere/subscriptions", "organizations_url": "https://api.github.com/users/seemethere/orgs", "repos_url": "https://api.github.com/users/seemethere/repos", "events_url": "https://api.github.com/users/seemethere/events{/privacy}", "received_events_url": "https://api.github.com/users/seemethere/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1588820772, "node_id": "MDU6TGFiZWwxNTg4ODIwNzcy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20binaries", "name": "topic: binaries", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-06-22T20:00:18Z", "updated_at": "2020-06-25T14:33:32Z", "closed_at": "2020-06-23T19:46:31Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Originally reported by @pbelevich but I've observed that `torchvision` nightlies are currently incompatible with `torch` nightlies due to a tight version constraint.\r\n\r\nSee:\r\n```\r\npip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\r\n\r\nLooking in indexes: https://pypi.org/simple, http://100.97.64.150\r\nLooking in links: https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\r\nCollecting torch\r\n  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-1.6.0.dev20200622%2Bcpu-cp37-cp37m-linux_x86_64.whl (155.0 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 155.0 MB 64.1 MB/s\r\nCollecting torchvision\r\n  Downloading https://download.pytorch.org/whl/nightly/cpu/torchvision-0.7.0.dev20200622%2Bcpu-cp37-cp37m-linux_x86_64.whl (5.0 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.0 MB 3.3 MB/s\r\nProcessing /private/home/eliuriegas/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0/future-0.18.2-py3-none-any.whl\r\nCollecting numpy\r\n  Downloading numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl (14.6 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.6 MB 14.3 MB/s\r\nCollecting pillow>=4.1.1\r\n  Downloading Pillow-7.1.2-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.1 MB 16.2 MB/s\r\nERROR: torchvision 0.7.0.dev20200622+cpu has requirement torch==1.6.0.dev20200610+cpu, but you'll have torch 1.6.0.dev20200622+cpu which is incompatible.\r\nInstalling collected packages: future, numpy, torch, pillow, torchvision\r\nSuccessfully installed future-0.18.2 numpy-1.19.0 pillow-7.1.2 torch-1.6.0.dev20200622+cpu torchvision-0.7.0.dev20200622+cpu\r\n```\r\n\r\nI think this is related to https://github.com/pytorch/pytorch/pull/40352 and subsequently https://github.com/pytorch/pytorch/pull/39669\r\n\r\nWill close this after I see the issue resolve itself.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2338", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2338/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2338/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2338/events", "html_url": "https://github.com/pytorch/vision/issues/2338", "id": 643286740, "node_id": "MDU6SXNzdWU2NDMyODY3NDA=", "number": 2338, "title": "AttributeError: module 'torchvision.datasets' has no attribute 'USPS'", "user": {"login": "ChangweiXu", "id": 33238360, "node_id": "MDQ6VXNlcjMzMjM4MzYw", "avatar_url": "https://avatars0.githubusercontent.com/u/33238360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChangweiXu", "html_url": "https://github.com/ChangweiXu", "followers_url": "https://api.github.com/users/ChangweiXu/followers", "following_url": "https://api.github.com/users/ChangweiXu/following{/other_user}", "gists_url": "https://api.github.com/users/ChangweiXu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChangweiXu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChangweiXu/subscriptions", "organizations_url": "https://api.github.com/users/ChangweiXu/orgs", "repos_url": "https://api.github.com/users/ChangweiXu/repos", "events_url": "https://api.github.com/users/ChangweiXu/events{/privacy}", "received_events_url": "https://api.github.com/users/ChangweiXu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-22T18:45:36Z", "updated_at": "2020-06-23T16:57:10Z", "closed_at": "2020-06-23T16:57:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nWhen I was trying to use the USPS dataset with torchvision.datasets, the console gave me the error:\r\n\r\n`AttributeError: module 'torchvision.datasets' has no attribute 'USPS'`\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\n$ python3\r\n>>> import torchvision as tv\r\n>>> tv.datasets.USPS\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'torchvision.datasets' has no attribute 'USPS'\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nIt should load the USPS dataset as shown in the documentation: [link](https://pytorch.org/docs/master/torchvision/datasets.html#usps).\r\n\r\n## Environment\r\n\r\n - PyTorch / torchvision Version (e.g., 1.0 / 0.4.0): 1.5.1 / 0.6.1\r\n - OS (e.g., Linux): Win 10\r\n - How you installed PyTorch / torchvision (`conda`, `pip`, source): `conda`\r\n - CUDA used to build PyTorch: 10.2\r\n - Python version: 3.7\r\n - CUDA version: 11.0\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n```\r\n[pip3] numpy==1.18.1\r\n[pip3] torch==1.5.1\r\n[pip3] torchvision==0.6.1\r\n[conda] blas                      1.0                         mkl\r\n[conda] cudatoolkit               10.2.89              h74a9793_1\r\n[conda] mkl                       2020.1                      216\r\n[conda] mkl-service               2.3.0            py37hb782905_0\r\n[conda] mkl_fft                   1.1.0            py37h45dec08_0\r\n[conda] mkl_random                1.1.1            py37h47e9c7a_0\r\n[conda] numpy                     1.18.1           py37h93ca92e_0\r\n[conda] numpy-base                1.18.1           py37hc3f5095_1\r\n[conda] pytorch                   1.5.1           py3.7_cuda102_cudnn7_0    pytorch\r\n[conda] torchvision               0.6.1                py37_cu102    pytorch\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2336", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2336/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2336/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2336/events", "html_url": "https://github.com/pytorch/vision/issues/2336", "id": 643050942, "node_id": "MDU6SXNzdWU2NDMwNTA5NDI=", "number": 2336, "title": " from torchvision.transforms import ImageOps ImportError: cannot import name 'ImageOps'", "user": {"login": "JsPassion", "id": 12843539, "node_id": "MDQ6VXNlcjEyODQzNTM5", "avatar_url": "https://avatars1.githubusercontent.com/u/12843539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JsPassion", "html_url": "https://github.com/JsPassion", "followers_url": "https://api.github.com/users/JsPassion/followers", "following_url": "https://api.github.com/users/JsPassion/following{/other_user}", "gists_url": "https://api.github.com/users/JsPassion/gists{/gist_id}", "starred_url": "https://api.github.com/users/JsPassion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JsPassion/subscriptions", "organizations_url": "https://api.github.com/users/JsPassion/orgs", "repos_url": "https://api.github.com/users/JsPassion/repos", "events_url": "https://api.github.com/users/JsPassion/events{/privacy}", "received_events_url": "https://api.github.com/users/JsPassion/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}, {"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-22T12:58:35Z", "updated_at": "2020-06-23T08:53:47Z", "closed_at": "2020-06-23T08:53:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "cuda version 10.1\r\ntorch version 1.5.1\r\ntorchvision version 0.6.0\r\nPIL version 5.2.0 \r\n\r\nI have also tried installing Pillow version 6.1 and torchvision version 0.5.0 and torch 1.4.0 using both methods conda and pip. But the error persists. \r\nKindly help!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2330", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2330/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2330/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2330/events", "html_url": "https://github.com/pytorch/vision/issues/2330", "id": 641169927, "node_id": "MDU6SXNzdWU2NDExNjk5Mjc=", "number": 2330, "title": "Error while compailing for raspberry pi   \"error: no matching function for call to \u2018min(size_t&, long unsigned int)\u2019\"", "user": {"login": "overclock98", "id": 28886297, "node_id": "MDQ6VXNlcjI4ODg2Mjk3", "avatar_url": "https://avatars0.githubusercontent.com/u/28886297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/overclock98", "html_url": "https://github.com/overclock98", "followers_url": "https://api.github.com/users/overclock98/followers", "following_url": "https://api.github.com/users/overclock98/following{/other_user}", "gists_url": "https://api.github.com/users/overclock98/gists{/gist_id}", "starred_url": "https://api.github.com/users/overclock98/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/overclock98/subscriptions", "organizations_url": "https://api.github.com/users/overclock98/orgs", "repos_url": "https://api.github.com/users/overclock98/repos", "events_url": "https://api.github.com/users/overclock98/events{/privacy}", "received_events_url": "https://api.github.com/users/overclock98/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1385340512, "node_id": "MDU6TGFiZWwxMzg1MzQwNTEy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20build", "name": "topic: build", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-06-18T12:32:31Z", "updated_at": "2020-07-06T12:08:48Z", "closed_at": "2020-06-18T17:11:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "**I'm trying to build torchvision on raspberry pi but getting thiss error. how can i fix?** \r\n\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:58:47: **error: no matching function for call to \u2018min(size_t&, long unsigned int)\u2019**\r\n   buffer_.resize(std::min(maxBytes, 4 * 1024UL));\r\n                                               ^\r\nIn file included from /usr/include/c++/8/bits/char_traits.h:39,\r\n                 from /usr/include/c++/8/string:40,\r\n                 from /usr/include/c++/8/stdexcept:39,\r\n                 from /usr/include/c++/8/array:39,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/defs.h:3,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.h:3,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:1:\r\n/usr/include/c++/8/bits/stl_algobase.h:195:5: note: candidate: \u2018template<class _Tp> constexpr const _Tp& std::min(const _Tp&, const _Tp&)\u2019\r\n     min(const _Tp& __a, const _Tp& __b)\r\n     ^~~\r\n/usr/include/c++/8/bits/stl_algobase.h:195:5: note:   template argument deduction/substitution failed:\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:58:47: note:   deduced conflicting types for parameter \u2018const _Tp\u2019 (\u2018unsigned int\u2019 and \u2018long unsigned int\u2019)\r\n   buffer_.resize(std::min(maxBytes, 4 * 1024UL));\r\n                                               ^\r\nIn file included from /usr/include/c++/8/bits/char_traits.h:39,\r\n                 from /usr/include/c++/8/string:40,\r\n                 from /usr/include/c++/8/stdexcept:39,\r\n                 from /usr/include/c++/8/array:39,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/defs.h:3,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.h:3,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:1:\r\n/usr/include/c++/8/bits/stl_algobase.h:243:5: note: candidate: \u2018template<class _Tp, class _Compare> constexpr const _Tp& std::min(const _Tp&, const _Tp&, _Compare)\u2019\r\n     min(const _Tp& __a, const _Tp& __b, _Compare __comp)\r\n     ^~~\r\n/usr/include/c++/8/bits/stl_algobase.h:243:5: note:   template argument deduction/substitution failed:\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:58:47: note:   deduced conflicting types for parameter \u2018const _Tp\u2019 (\u2018unsigned int\u2019 and \u2018long unsigned int\u2019)\r\n   buffer_.resize(std::min(maxBytes, 4 * 1024UL));\r\n                                               ^\r\nIn file included from /usr/include/c++/8/algorithm:62,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Registry.h:12,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Flags.h:36,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Logging.h:12,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:2:\r\n/usr/include/c++/8/bits/stl_algo.h:3450:5: note: candidate: \u2018template<class _Tp> constexpr _Tp std::min(std::initializer_list<_Tp>)\u2019\r\n     min(initializer_list<_Tp> __l)\r\n     ^~~\r\n/usr/include/c++/8/bits/stl_algo.h:3450:5: note:   template argument deduction/substitution failed:\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:58:47: note:   mismatched types \u2018std::initializer_list<_Tp>\u2019 and \u2018unsigned int\u2019\r\n   buffer_.resize(std::min(maxBytes, 4 * 1024UL));\r\n                                               ^\r\nIn file included from /usr/include/c++/8/algorithm:62,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Registry.h:12,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Flags.h:36,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Logging.h:12,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:2:\r\n/usr/include/c++/8/bits/stl_algo.h:3456:5: note: candidate: \u2018template<class _Tp, class _Compare> constexpr _Tp std::min(std::initializer_list<_Tp>, _Compare)\u2019\r\n     min(initializer_list<_Tp> __l, _Compare __comp)\r\n     ^~~\r\n/usr/include/c++/8/bits/stl_algo.h:3456:5: note:   template argument deduction/substitution failed:\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:58:47: note:   mismatched types \u2018std::initializer_list<_Tp>\u2019 and \u2018unsigned int\u2019\r\n   buffer_.resize(std::min(maxBytes, 4 * 1024UL));\r\n                                               ^\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:69:24: warning: comparison of integer expressions of different signedness: \u2018long int\u2019 and \u2018size_t\u2019 {aka \u2018unsigned int\u2019} [-Wsign-compare]\r\n   while (!eof_ && end_ < maxBytes && (hasTime = watcher())) {\r\n                   ~~~~~^~~~~~~~~~\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:74:16: warning: comparison of integer expressions of different signedness: \u2018long int\u2019 and \u2018std::vector<unsigned char>::size_type\u2019 {aka \u2018unsigned int\u2019} [-Wsign-compare]\r\n       if (end_ == buffer_.size()) {\r\n           ~~~~~^~~~~~~~~~~~~~~~~\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:75:53: **error: no matching function for call to \u2018min(long unsigned int, size_t&)\u2019**\r\n         buffer_.resize(std::min(end_ * 4UL, maxBytes));\r\n                                                     ^\r\nIn file included from /usr/include/c++/8/bits/char_traits.h:39,\r\n                 from /usr/include/c++/8/string:40,\r\n                 from /usr/include/c++/8/stdexcept:39,\r\n                 from /usr/include/c++/8/array:39,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/defs.h:3,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.h:3,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:1:\r\n/usr/include/c++/8/bits/stl_algobase.h:195:5: note: candidate: \u2018template<class _Tp> constexpr const _Tp& std::min(const _Tp&, const _Tp&)\u2019\r\n     min(const _Tp& __a, const _Tp& __b)\r\n     ^~~\r\n/usr/include/c++/8/bits/stl_algobase.h:195:5: note:   template argument deduction/substitution failed:\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:75:53: note:   deduced conflicting types for parameter \u2018const _Tp\u2019 (\u2018long unsigned int\u2019 and \u2018size_t\u2019 {aka \u2018unsigned int\u2019})\r\n         buffer_.resize(std::min(end_ * 4UL, maxBytes));\r\n                                                     ^\r\nIn file included from /usr/include/c++/8/bits/char_traits.h:39,\r\n                 from /usr/include/c++/8/string:40,\r\n                 from /usr/include/c++/8/stdexcept:39,\r\n                 from /usr/include/c++/8/array:39,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/defs.h:3,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.h:3,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:1:\r\n/usr/include/c++/8/bits/stl_algobase.h:243:5: note: candidate: \u2018template<class _Tp, class _Compare> constexpr const _Tp& std::min(const _Tp&, const _Tp&, _Compare)\u2019\r\n     min(const _Tp& __a, const _Tp& __b, _Compare __comp)\r\n     ^~~\r\n/usr/include/c++/8/bits/stl_algobase.h:243:5: note:   template argument deduction/substitution failed:\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:75:53: note:   deduced conflicting types for parameter \u2018const _Tp\u2019 (\u2018long unsigned int\u2019 and \u2018size_t\u2019 {aka \u2018unsigned int\u2019})\r\n         buffer_.resize(std::min(end_ * 4UL, maxBytes));\r\n                                                     ^\r\nIn file included from /usr/include/c++/8/algorithm:62,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Registry.h:12,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Flags.h:36,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Logging.h:12,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:2:\r\n/usr/include/c++/8/bits/stl_algo.h:3450:5: note: candidate: \u2018template<class _Tp> constexpr _Tp std::min(std::initializer_list<_Tp>)\u2019\r\n     min(initializer_list<_Tp> __l)\r\n     ^~~\r\n/usr/include/c++/8/bits/stl_algo.h:3450:5: note:   template argument deduction/substitution failed:\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:75:53: note:   mismatched types \u2018std::initializer_list<_Tp>\u2019 and \u2018long unsigned int\u2019\r\n         buffer_.resize(std::min(end_ * 4UL, maxBytes));\r\n                                                     ^\r\nIn file included from /usr/include/c++/8/algorithm:62,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Registry.h:12,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Flags.h:36,\r\n                 from /home/pi/.local/lib/python3.7/site-packages/torch/include/c10/util/Logging.h:12,\r\n                 from /home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:2:\r\n/usr/include/c++/8/bits/stl_algo.h:3456:5: note: candidate: \u2018template<class _Tp, class _Compare> constexpr _Tp std::min(std::initializer_list<_Tp>, _Compare)\u2019\r\n     min(initializer_list<_Tp> __l, _Compare __comp)\r\n     ^~~\r\n/usr/include/c++/8/bits/stl_algo.h:3456:5: note:   template argument deduction/substitution failed:\r\n/home/pi/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:75:53: note:   mismatched types \u2018std::initializer_list<_Tp>\u2019 and \u2018long unsigned int\u2019\r\n         buffer_.resize(std::min(end_ * 4UL, maxBytes));\r\n                                                     ^\r\n**error: command 'arm-linux-gnueabihf-gcc' failed with exit status 1**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2329", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2329/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2329/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2329/events", "html_url": "https://github.com/pytorch/vision/issues/2329", "id": 641027294, "node_id": "MDU6SXNzdWU2NDEwMjcyOTQ=", "number": 2329, "title": "A problem of multiclassifier task with Squeezenet trained on VOC2012", "user": {"login": "Lollipop9z", "id": 42562532, "node_id": "MDQ6VXNlcjQyNTYyNTMy", "avatar_url": "https://avatars0.githubusercontent.com/u/42562532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lollipop9z", "html_url": "https://github.com/Lollipop9z", "followers_url": "https://api.github.com/users/Lollipop9z/followers", "following_url": "https://api.github.com/users/Lollipop9z/following{/other_user}", "gists_url": "https://api.github.com/users/Lollipop9z/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lollipop9z/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lollipop9z/subscriptions", "organizations_url": "https://api.github.com/users/Lollipop9z/orgs", "repos_url": "https://api.github.com/users/Lollipop9z/repos", "events_url": "https://api.github.com/users/Lollipop9z/events{/privacy}", "received_events_url": "https://api.github.com/users/Lollipop9z/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-18T08:48:09Z", "updated_at": "2020-07-07T15:07:28Z", "closed_at": "2020-07-07T15:07:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I got a problem when I dealed with a multiclassifier task with squeezenent on VOC2012. I just wrote a train code, and called the '''torchversion.models.squeezenet1_1''', changed num_classes. I used '''torch.nn.MultiLabelSoftMarginLoss()''' for my loss function. However, my loss never changed when I trained my network. If there is someone having same problem like me, and having some specific soluation, please help me. please! Thank you~\r\n```\r\nEpoch: [  0/2000] step:  0, Loss: 0.754, mAP 26.93%\r\nEpoch: [  0/2000] step: 20, Loss: 0.693, mAP 7.48%\r\nEpoch: [  0/2000] step: 40, Loss: 0.693, mAP 6.65%\r\nEpoch: [  0/2000] step: 60, Loss: 0.693, mAP 6.43%\r\nEpoch: [  0/2000] step: 80, Loss: 0.693, mAP 6.39%\r\nEpoch: [  0/2000] step: 100, Loss: 0.693, mAP 6.55%\r\nEpoch: [  0/2000] step: 120, Loss: 0.693, mAP 6.83%\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2325", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2325/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2325/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2325/events", "html_url": "https://github.com/pytorch/vision/issues/2325", "id": 639949269, "node_id": "MDU6SXNzdWU2Mzk5NDkyNjk=", "number": 2325, "title": "pytorch pre-trained models preprocessing results 9 images", "user": {"login": "aliamiri1380", "id": 26299133, "node_id": "MDQ6VXNlcjI2Mjk5MTMz", "avatar_url": "https://avatars3.githubusercontent.com/u/26299133?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aliamiri1380", "html_url": "https://github.com/aliamiri1380", "followers_url": "https://api.github.com/users/aliamiri1380/followers", "following_url": "https://api.github.com/users/aliamiri1380/following{/other_user}", "gists_url": "https://api.github.com/users/aliamiri1380/gists{/gist_id}", "starred_url": "https://api.github.com/users/aliamiri1380/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aliamiri1380/subscriptions", "organizations_url": "https://api.github.com/users/aliamiri1380/orgs", "repos_url": "https://api.github.com/users/aliamiri1380/repos", "events_url": "https://api.github.com/users/aliamiri1380/events{/privacy}", "received_events_url": "https://api.github.com/users/aliamiri1380/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-16T20:24:38Z", "updated_at": "2020-06-19T10:00:17Z", "closed_at": "2020-06-17T19:29:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using vgg16 and for preprocessing I use transforms module (as used in the documentation)\r\nand I don't know why, but when it takes my image as input, it outputs 9 small copy of the input image and combines them into one single image (nonetheless the output is correct)\r\n\r\nis it a problem?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2317", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2317/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2317/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2317/events", "html_url": "https://github.com/pytorch/vision/issues/2317", "id": 637940283, "node_id": "MDU6SXNzdWU2Mzc5NDAyODM=", "number": 2317, "title": "Failed to download CelebA in Colab", "user": {"login": "sickmz", "id": 24682196, "node_id": "MDQ6VXNlcjI0NjgyMTk2", "avatar_url": "https://avatars3.githubusercontent.com/u/24682196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sickmz", "html_url": "https://github.com/sickmz", "followers_url": "https://api.github.com/users/sickmz/followers", "following_url": "https://api.github.com/users/sickmz/following{/other_user}", "gists_url": "https://api.github.com/users/sickmz/gists{/gist_id}", "starred_url": "https://api.github.com/users/sickmz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sickmz/subscriptions", "organizations_url": "https://api.github.com/users/sickmz/orgs", "repos_url": "https://api.github.com/users/sickmz/repos", "events_url": "https://api.github.com/users/sickmz/events{/privacy}", "received_events_url": "https://api.github.com/users/sickmz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-12T18:44:30Z", "updated_at": "2020-07-03T12:52:57Z", "closed_at": "2020-07-03T12:52:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nIt fails to download the following files **img_align_celeba.zip**\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. `from torchvision import datasets`\r\n`trainset = datasets.CelebA(root='./data/', split='train', target_type=\"attr\", transform=transform, download=True)`\r\n\r\nError:\r\n```\r\nTraceback (most recent call last):\r\n  File \"transfer_learning.py\", line 123, in <module>\r\n    trainset = datasets.CelebA(root='./data/', split='train', transform=transform, download=True)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/datasets/celeba.py\", line 66, in __init__\r\n    self.download()\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/datasets/celeba.py\", line 120, in download\r\n    with zipfile.ZipFile(os.path.join(self.root, self.base_folder, \"img_align_celeba.zip\"), \"r\") as f:\r\n  File \"/usr/lib/python3.6/zipfile.py\", line 1131, in __init__\r\n    self._RealGetContents()\r\n  File \"/usr/lib/python3.6/zipfile.py\", line 1198, in _RealGetContents\r\n    raise BadZipFile(\"File is not a zip file\")\r\nzipfile.BadZipFile: File is not a zip file\r\n```\r\n\r\n## Expected behavior\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.5.0+cu101\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: No\r\nCUDA runtime version: 10.1.243\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.5\r\n[pip3] torch==1.5.0+cu101\r\n[pip3] torchsummary==1.5.1\r\n[pip3] torchtext==0.3.1\r\n[pip3] torchvision==0.6.0+cu101\r\n[conda] Could not collect\r\n```\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2308", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2308/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2308/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2308/events", "html_url": "https://github.com/pytorch/vision/issues/2308", "id": 636127025, "node_id": "MDU6SXNzdWU2MzYxMjcwMjU=", "number": 2308, "title": "exported MASKRCNN ONNX model cannot run:  Op (Slice) [ShapeInferenceError] Input axes has invalid data", "user": {"login": "qizhen816", "id": 18132150, "node_id": "MDQ6VXNlcjE4MTMyMTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/18132150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qizhen816", "html_url": "https://github.com/qizhen816", "followers_url": "https://api.github.com/users/qizhen816/followers", "following_url": "https://api.github.com/users/qizhen816/following{/other_user}", "gists_url": "https://api.github.com/users/qizhen816/gists{/gist_id}", "starred_url": "https://api.github.com/users/qizhen816/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qizhen816/subscriptions", "organizations_url": "https://api.github.com/users/qizhen816/orgs", "repos_url": "https://api.github.com/users/qizhen816/repos", "events_url": "https://api.github.com/users/qizhen816/events{/privacy}", "received_events_url": "https://api.github.com/users/qizhen816/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1706804376, "node_id": "MDU6TGFiZWwxNzA2ODA0Mzc2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20onnx", "name": "module: onnx", "color": "edaea8", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-10T10:20:15Z", "updated_at": "2020-06-19T10:20:45Z", "closed_at": "2020-06-19T10:20:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nI exported my mask-rcnn model with resnet-101 as backbone using the most recently built torch and torchvision,  but cannot run by onnxruntime 1.3.0.\r\n```\r\n    img = cv2.resize(img,(1333,800))\r\n    img = np.expand_dims(img,0)\r\n    img = np.transpose(img,(0,3,1,2)).astype(np.float32)/255\r\n    dummy_input1 = torch.from_numpy(img)\r\n    model.eval()\r\n    input_names = [\"input\"]\r\n    torch.onnx.export(model, dummy_input1,\r\n                      \"traced_maskrcnn.onnx\",\r\n                      output_names=[\"boxes\", \"labels\", \"scores\", \"masks\"],\r\n                      # do_constant_folding=True,\r\n                      verbose=True,\r\n                      opset_version=11,\r\n                      input_names=input_names)\r\n```\r\nHere is the export log:\r\n```\r\nC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\tensor.py:460: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\r\n  'incorrect results).', category=RuntimeWarning)\r\nD:\\Garage\\maskvision\\transforms.py:315: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\r\n  mean = torch.as_tensor(self.image_mean, dtype=dtype, device=device)\r\nD:\\Garage\\maskvision\\transforms.py:316: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\r\n  std = torch.as_tensor(self.image_std, dtype=dtype, device=device)\r\nC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torchvision\\models\\detection\\rpn.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\r\nC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\boxes.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\r\nC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\boxes.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\r\nC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torchvision\\ops\\poolers.py:216: UserWarning: This overload of nonzero is deprecated:\r\n\tnonzero(Tensor input, *, Tensor out)\r\nConsider using one of the following signatures instead:\r\n\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:761.)\r\n  idx_in_level = torch.nonzero(levels == level).squeeze(1)\r\nC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torchvision\\models\\detection\\roi_heads.py:368: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\r\n  return torch.tensor(M + 2 * padding).to(torch.float32) / torch.tensor(M).to(torch.float32)\r\nC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:2225: UserWarning: Exporting aten::index operator of advanced indexing in opset 11 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\r\n  \"If indices include negative values, the exported graph will produce incorrect results.\")\r\n```\r\nThe onnx model is generated after the above warnings, but onnxruntime throw an error:\r\n`Node (Slice_1492) Op (Slice) [ShapeInferenceError] Input axes has invalid data`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2299", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2299/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2299/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2299/events", "html_url": "https://github.com/pytorch/vision/issues/2299", "id": 634371336, "node_id": "MDU6SXNzdWU2MzQzNzEzMzY=", "number": 2299, "title": "Downloading pre-trained models to a custom path(which I prefer to), instead of a fixed one", "user": {"login": "Sean16SYSU", "id": 32086937, "node_id": "MDQ6VXNlcjMyMDg2OTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/32086937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sean16SYSU", "html_url": "https://github.com/Sean16SYSU", "followers_url": "https://api.github.com/users/Sean16SYSU/followers", "following_url": "https://api.github.com/users/Sean16SYSU/following{/other_user}", "gists_url": "https://api.github.com/users/Sean16SYSU/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sean16SYSU/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sean16SYSU/subscriptions", "organizations_url": "https://api.github.com/users/Sean16SYSU/orgs", "repos_url": "https://api.github.com/users/Sean16SYSU/repos", "events_url": "https://api.github.com/users/Sean16SYSU/events{/privacy}", "received_events_url": "https://api.github.com/users/Sean16SYSU/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-08T08:37:52Z", "updated_at": "2020-06-08T10:18:42Z", "closed_at": "2020-06-08T10:18:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\n\r\nWhen using the pre-trained models with `pretrained=True`, I find no way to input my custom path for downloading or loading models.\r\n\r\nI have read the source codes in my local version of `torchvision` and the latest code in github, and found no way to input the self-defined path for downloading or loading, both.\r\n\r\n## Motivation\r\n\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\nWell, there is no bug in the source codes(for the very design) of any versions. And I am sure that everything works well even without the design I requested. However, I still feel a bit unaccustomed and inflexible while using it, because I always want to arrange the downloading files in my PC.\r\n\r\nBTW, I thinking it easy to implement.\r\n\r\n## Pitch\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\na new parameter like `model_path=None` is added to the models or functions.\r\n\r\n## Alternatives\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, if any. -->\r\n\r\nsame as `Pitch`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2297", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2297/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2297/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2297/events", "html_url": "https://github.com/pytorch/vision/issues/2297", "id": 633074712, "node_id": "MDU6SXNzdWU2MzMwNzQ3MTI=", "number": 2297, "title": "Cannot import module after installation from source (not just from vision folder)", "user": {"login": "clemkoa", "id": 6000142, "node_id": "MDQ6VXNlcjYwMDAxNDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/6000142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/clemkoa", "html_url": "https://github.com/clemkoa", "followers_url": "https://api.github.com/users/clemkoa/followers", "following_url": "https://api.github.com/users/clemkoa/following{/other_user}", "gists_url": "https://api.github.com/users/clemkoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/clemkoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/clemkoa/subscriptions", "organizations_url": "https://api.github.com/users/clemkoa/orgs", "repos_url": "https://api.github.com/users/clemkoa/repos", "events_url": "https://api.github.com/users/clemkoa/events{/privacy}", "received_events_url": "https://api.github.com/users/clemkoa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1391938214, "node_id": "MDU6TGFiZWwxMzkxOTM4MjE0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20documentation", "name": "module: documentation", "color": "f7e101", "default": false, "description": ""}, {"id": 719389156, "node_id": "MDU6TGFiZWw3MTkzODkxNTY=", "url": "https://api.github.com/repos/pytorch/vision/labels/needs%20reproduction", "name": "needs reproduction", "color": "64fca1", "default": false, "description": null}, {"id": 1385340512, "node_id": "MDU6TGFiZWwxMzg1MzQwNTEy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20build", "name": "topic: build", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-07T05:45:20Z", "updated_at": "2020-06-10T08:55:05Z", "closed_at": "2020-06-10T08:55:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI'm trying to build torchvision from source. Importing the module in python always fails.\r\nThe error is the same as described here: https://github.com/pytorch/vision/issues/2239 except it happens in all folders, not just vision.\r\nI'm aware that this is usually due to a version mismatch between pytorch and torchvision. I installed the nightly pytorch using this command: \r\n`pip install --user --pre torch -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html`\r\n\r\nI am on macOS 10.15.5, no CUDA, python 3.7.6\r\n\r\n## To Reproduce\r\n\r\n```\r\nPython 3.7.6 (default, Dec 30 2019, 19:38:26)\r\n[Clang 11.0.0 (clang-1100.0.33.16)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import torch\r\n>>> import torchvision\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/torchvision-0.7.0a0+3e06bc6-py3.7-macosx-10.15-x86_64.egg/torchvision/__init__.py\", line 5, in <module>\r\n    from torchvision import models\r\n  File \"/usr/local/lib/python3.7/site-packages/torchvision-0.7.0a0+3e06bc6-py3.7-macosx-10.15-x86_64.egg/torchvision/models/__init__.py\", line 12, in <module>\r\n    from . import detection\r\n  File \"/usr/local/lib/python3.7/site-packages/torchvision-0.7.0a0+3e06bc6-py3.7-macosx-10.15-x86_64.egg/torchvision/models/detection/__init__.py\", line 1, in <module>\r\n    from .faster_rcnn import *\r\n  File \"/usr/local/lib/python3.7/site-packages/torchvision-0.7.0a0+3e06bc6-py3.7-macosx-10.15-x86_64.egg/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\r\n    from torchvision.ops import misc as misc_nn_ops\r\n  File \"/usr/local/lib/python3.7/site-packages/torchvision-0.7.0a0+3e06bc6-py3.7-macosx-10.15-x86_64.egg/torchvision/ops/__init__.py\", line 1, in <module>\r\n    from .boxes import nms, box_iou\r\n  File \"/usr/local/lib/python3.7/site-packages/torchvision-0.7.0a0+3e06bc6-py3.7-macosx-10.15-x86_64.egg/torchvision/ops/boxes.py\", line 7, in <module>\r\n    @torch.jit.script\r\n  File \"/Users/clementjoudet/Library/Python/3.7/lib/python/site-packages/torch/jit/__init__.py\", line 1333, in script\r\n    fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj))\r\nRuntimeError:\r\nobject has no attribute ops:\r\n  File \"/usr/local/lib/python3.7/site-packages/torchvision-0.7.0a0+3e06bc6-py3.7-macosx-10.15-x86_64.egg/torchvision/ops/boxes.py\", line 41\r\n        by NMS, sorted in decreasing order of scores\r\n    \"\"\"\r\n    return torchvision.ops.nms(boxes, scores, iou_threshold)\r\n           ~~~~~~~~~~~~~~~ <--- HERE\r\n```\r\n\r\n## Expected behavior\r\n\r\nThe import should work\r\n\r\n## Environment\r\nCollecting environment information...\r\nPyTorch version: N/A\r\nIs debug build: N/A\r\nCUDA used to build PyTorch: N/A\r\n\r\nOS: Mac OSX 10.15.5\r\nGCC version: Could not collect\r\nCMake version: version 3.17.3\r\n\r\nPython version: 3.7\r\nIs CUDA available: N/A\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: Could not collect\r\nNvidia driver version: Could not collect\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.1\r\n[pip3] torch==1.6.0.dev20200528\r\n[conda] Could not collect\r\n\r\n## Additional context\r\n\r\nFor the record I tried installing pytorch from source, but it fails on macOS. I've opened an issue: https://github.com/pytorch/pytorch/issues/39634\r\nThe reason I'm trying to install torchvision locally is to open a PR to contribute to the project. I have to admit it's a bit hard to get started because there is no Contributing.md document, and the steps to set up the environment locally are not clear. It is not clear how to install pytorch to make torchvision work in dev mode. Additionnaly, it is unclear how to run the tests. This could be the topic of another issue/PR, but I'd be happy to commit a document to describe how to set up the environment and contribute to the project if you deem it needed!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2296", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2296/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2296/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2296/events", "html_url": "https://github.com/pytorch/vision/issues/2296", "id": 632765935, "node_id": "MDU6SXNzdWU2MzI3NjU5MzU=", "number": 2296, "title": "Video models pretrained weights on Kinetics 700", "user": {"login": "DAVEISHAN", "id": 27220560, "node_id": "MDQ6VXNlcjI3MjIwNTYw", "avatar_url": "https://avatars1.githubusercontent.com/u/27220560?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DAVEISHAN", "html_url": "https://github.com/DAVEISHAN", "followers_url": "https://api.github.com/users/DAVEISHAN/followers", "following_url": "https://api.github.com/users/DAVEISHAN/following{/other_user}", "gists_url": "https://api.github.com/users/DAVEISHAN/gists{/gist_id}", "starred_url": "https://api.github.com/users/DAVEISHAN/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DAVEISHAN/subscriptions", "organizations_url": "https://api.github.com/users/DAVEISHAN/orgs", "repos_url": "https://api.github.com/users/DAVEISHAN/repos", "events_url": "https://api.github.com/users/DAVEISHAN/events{/privacy}", "received_events_url": "https://api.github.com/users/DAVEISHAN/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-06T22:14:33Z", "updated_at": "2020-07-24T20:35:39Z", "closed_at": "2020-07-24T20:35:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\nPlease, add pre-trained weights for the Kinetics 700 dataset for video ResNet Models, Currently, only Kinetics 400 weights are available and it is a bit outdated now. \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2291", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2291/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2291/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2291/events", "html_url": "https://github.com/pytorch/vision/issues/2291", "id": 631574890, "node_id": "MDU6SXNzdWU2MzE1NzQ4OTA=", "number": 2291, "title": "Package libjpeg and libpng within torchvision", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2089185327, "node_id": "MDU6TGFiZWwyMDg5MTg1MzI3", "url": "https://api.github.com/repos/pytorch/vision/labels/high%20priority", "name": "high priority", "color": "b60205", "default": false, "description": ""}, {"id": 1588820772, "node_id": "MDU6TGFiZWwxNTg4ODIwNzcy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20binaries", "name": "topic: binaries", "color": "0e8a16", "default": false, "description": ""}, {"id": 1385340512, "node_id": "MDU6TGFiZWwxMzg1MzQwNTEy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20build", "name": "topic: build", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "andfoy", "id": 1878982, "node_id": "MDQ6VXNlcjE4Nzg5ODI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1878982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andfoy", "html_url": "https://github.com/andfoy", "followers_url": "https://api.github.com/users/andfoy/followers", "following_url": "https://api.github.com/users/andfoy/following{/other_user}", "gists_url": "https://api.github.com/users/andfoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/andfoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andfoy/subscriptions", "organizations_url": "https://api.github.com/users/andfoy/orgs", "repos_url": "https://api.github.com/users/andfoy/repos", "events_url": "https://api.github.com/users/andfoy/events{/privacy}", "received_events_url": "https://api.github.com/users/andfoy/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andfoy", "id": 1878982, "node_id": "MDQ6VXNlcjE4Nzg5ODI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1878982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andfoy", "html_url": "https://github.com/andfoy", "followers_url": "https://api.github.com/users/andfoy/followers", "following_url": "https://api.github.com/users/andfoy/following{/other_user}", "gists_url": "https://api.github.com/users/andfoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/andfoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andfoy/subscriptions", "organizations_url": "https://api.github.com/users/andfoy/orgs", "repos_url": "https://api.github.com/users/andfoy/repos", "events_url": "https://api.github.com/users/andfoy/events{/privacy}", "received_events_url": "https://api.github.com/users/andfoy/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-06-05T13:05:35Z", "updated_at": "2020-06-30T17:23:32Z", "closed_at": "2020-06-30T17:23:32Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "With the addition of image-reading functions enabled by default in torchvision #1632 #1881 #1909, we will need to properly package libjpeg and libpng (and other libraries will be used soon as well, like ffmpeg) so that users of {Windows, Linux, OSX} x {pip, conda, source} can use those new functionalities in torchvision without issues.\r\n\r\nI believe the current recommended way that PyTorch deals with 3rd-party libraries is the following:\r\n- for conda, we use conda's package manager to handle the dependencies. Both [libjpeg](https://anaconda.org/conda-forge/libjpeg-turbo) and [libpng](https://anaconda.org/anaconda/libpng) are available in standard channels, although I'm not sure if using the `conda-forge` channel would bring problems due to conflicts with other libraries we use.\r\n- for pip, I believe the preferred way is to include the libraries together with the torchvision wheel\r\n- for source, we would need to handle the common installation locations, or at least provide clear instructions on how to provide the path to the libraries, either via CMake or performing the handling via python like [Pillow does (although the logic seems quite intricate)](https://github.com/python-pillow/Pillow/blob/master/setup.py).\r\n\r\nWe will also need to make sure our CI (which is fairly tied to binary builds) is updated.\r\n\r\ncc @seemethere @rgommers ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2290", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2290/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2290/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2290/events", "html_url": "https://github.com/pytorch/vision/issues/2290", "id": 631491187, "node_id": "MDU6SXNzdWU2MzE0OTExODc=", "number": 2290, "title": "search", "user": {"login": "kuyedie520", "id": 55888536, "node_id": "MDQ6VXNlcjU1ODg4NTM2", "avatar_url": "https://avatars2.githubusercontent.com/u/55888536?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kuyedie520", "html_url": "https://github.com/kuyedie520", "followers_url": "https://api.github.com/users/kuyedie520/followers", "following_url": "https://api.github.com/users/kuyedie520/following{/other_user}", "gists_url": "https://api.github.com/users/kuyedie520/gists{/gist_id}", "starred_url": "https://api.github.com/users/kuyedie520/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kuyedie520/subscriptions", "organizations_url": "https://api.github.com/users/kuyedie520/orgs", "repos_url": "https://api.github.com/users/kuyedie520/repos", "events_url": "https://api.github.com/users/kuyedie520/events{/privacy}", "received_events_url": "https://api.github.com/users/kuyedie520/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-05T10:37:09Z", "updated_at": "2020-06-05T12:41:30Z", "closed_at": "2020-06-05T12:41:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "\u60f3\u95ee\u4e00\u4e0b\u8be5\u5de5\u7a0b\u662f\u8fd9\u7bc7\u8bba\u6587Grafted Network for Person Re-Identification\u7684\u590d\u73b0\u5417\uff1f\u5728\u8bba\u6587\u4e2d\u770b\u5230\u8fd9\u4e2a\u94fe\u63a5\u4e0d\u786e\u5b9a\u662f\u4e0d\u662f\u3002", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2286", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2286/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2286/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2286/events", "html_url": "https://github.com/pytorch/vision/issues/2286", "id": 630544615, "node_id": "MDU6SXNzdWU2MzA1NDQ2MTU=", "number": 2286, "title": "Architecture differences in Zoo Models ?", "user": {"login": "nitin2212", "id": 65274078, "node_id": "MDQ6VXNlcjY1Mjc0MDc4", "avatar_url": "https://avatars1.githubusercontent.com/u/65274078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nitin2212", "html_url": "https://github.com/nitin2212", "followers_url": "https://api.github.com/users/nitin2212/followers", "following_url": "https://api.github.com/users/nitin2212/following{/other_user}", "gists_url": "https://api.github.com/users/nitin2212/gists{/gist_id}", "starred_url": "https://api.github.com/users/nitin2212/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nitin2212/subscriptions", "organizations_url": "https://api.github.com/users/nitin2212/orgs", "repos_url": "https://api.github.com/users/nitin2212/repos", "events_url": "https://api.github.com/users/nitin2212/events{/privacy}", "received_events_url": "https://api.github.com/users/nitin2212/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388460222, "node_id": "MDU6TGFiZWwxMzg4NDYwMjIy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20classification", "name": "topic: classification", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-04T06:22:57Z", "updated_at": "2020-06-05T09:19:08Z", "closed_at": "2020-06-05T09:18:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I am comparing few zoo models implementation in DL4J with Pytorch zoo models and found\r\nthat the padding in Convolution layers does not match most of time ?\r\n\r\nFor **Resnet50 and SqueezeNet** :\r\n\r\nIn DL4J, they **do not** apply padding : [0, 0] ; while in PyTorch they have padding [1, 1].\r\nThis results in different output in layers\r\n\r\nIn DL4J, they apply **Bias** in Conv layers while in PyTorch, they do not.\r\n\r\nWhy such irregularities in Network structure across frameworks ?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2285", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2285/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2285/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2285/events", "html_url": "https://github.com/pytorch/vision/issues/2285", "id": 630323378, "node_id": "MDU6SXNzdWU2MzAzMjMzNzg=", "number": 2285, "title": "Finetuning deeplab/FCN", "user": {"login": "gaussiangit", "id": 43418057, "node_id": "MDQ6VXNlcjQzNDE4MDU3", "avatar_url": "https://avatars1.githubusercontent.com/u/43418057?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaussiangit", "html_url": "https://github.com/gaussiangit", "followers_url": "https://api.github.com/users/gaussiangit/followers", "following_url": "https://api.github.com/users/gaussiangit/following{/other_user}", "gists_url": "https://api.github.com/users/gaussiangit/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaussiangit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaussiangit/subscriptions", "organizations_url": "https://api.github.com/users/gaussiangit/orgs", "repos_url": "https://api.github.com/users/gaussiangit/repos", "events_url": "https://api.github.com/users/gaussiangit/events{/privacy}", "received_events_url": "https://api.github.com/users/gaussiangit/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373819307, "node_id": "MDU6TGFiZWwxMzczODE5MzA3", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20reference%20scripts", "name": "module: reference scripts", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388459896, "node_id": "MDU6TGFiZWwxMzg4NDU5ODk2", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20semantic%20segmentation", "name": "topic: semantic segmentation", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-03T20:53:38Z", "updated_at": "2020-06-05T09:16:56Z", "closed_at": "2020-06-05T09:16:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "How do I fine tune deeplabv3 ? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2275", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2275/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2275/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2275/events", "html_url": "https://github.com/pytorch/vision/issues/2275", "id": 628095807, "node_id": "MDU6SXNzdWU2MjgwOTU4MDc=", "number": 2275, "title": "Additional param in `torchvision.ops.nms` to set max no. of bounding boxes to return.", "user": {"login": "PseudoCodeNerd", "id": 33770878, "node_id": "MDQ6VXNlcjMzNzcwODc4", "avatar_url": "https://avatars3.githubusercontent.com/u/33770878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PseudoCodeNerd", "html_url": "https://github.com/PseudoCodeNerd", "followers_url": "https://api.github.com/users/PseudoCodeNerd/followers", "following_url": "https://api.github.com/users/PseudoCodeNerd/following{/other_user}", "gists_url": "https://api.github.com/users/PseudoCodeNerd/gists{/gist_id}", "starred_url": "https://api.github.com/users/PseudoCodeNerd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PseudoCodeNerd/subscriptions", "organizations_url": "https://api.github.com/users/PseudoCodeNerd/orgs", "repos_url": "https://api.github.com/users/PseudoCodeNerd/repos", "events_url": "https://api.github.com/users/PseudoCodeNerd/events{/privacy}", "received_events_url": "https://api.github.com/users/PseudoCodeNerd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-31T19:26:37Z", "updated_at": "2020-06-01T11:25:41Z", "closed_at": "2020-06-01T10:16:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\n#### `torchvision.ops.nms(boxes, scores, iou_threshold)` --> `torchvision.ops.nms(boxes, scores, max_output_size, iou_threshold)`\r\nWhere:\r\n\r\n- `max_output_size:` A scalar integer `Tensor` representing the maximum number of boxes to be selected by non max suppression.\r\n## Motivation\r\nOften, we only like a certain number of bounding boxes even after non-max suppression. This parameter accomplishes just that by returning selected indices from the `boxes` tensor of shape `[M]` where `M <= max_output_size`.\r\n\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\nThis is already implemented in Tensforflow [here](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/image/non_max_suppression).\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2266", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2266/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2266/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2266/events", "html_url": "https://github.com/pytorch/vision/issues/2266", "id": 625494179, "node_id": "MDU6SXNzdWU2MjU0OTQxNzk=", "number": 2266, "title": "resnet_fpn_backbone with resnext101_32x8d error", "user": {"login": "breezelj", "id": 43465142, "node_id": "MDQ6VXNlcjQzNDY1MTQy", "avatar_url": "https://avatars0.githubusercontent.com/u/43465142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/breezelj", "html_url": "https://github.com/breezelj", "followers_url": "https://api.github.com/users/breezelj/followers", "following_url": "https://api.github.com/users/breezelj/following{/other_user}", "gists_url": "https://api.github.com/users/breezelj/gists{/gist_id}", "starred_url": "https://api.github.com/users/breezelj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/breezelj/subscriptions", "organizations_url": "https://api.github.com/users/breezelj/orgs", "repos_url": "https://api.github.com/users/breezelj/repos", "events_url": "https://api.github.com/users/breezelj/events{/privacy}", "received_events_url": "https://api.github.com/users/breezelj/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-27T08:34:59Z", "updated_at": "2020-05-29T13:34:52Z", "closed_at": "2020-05-29T13:34:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n**when I try to load resnet_fpn_backbone with resnext101_32x8d**\r\n\r\n`from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\r\nbackbone = resnet_fpn_backbone('resnext101_32x8d', pretrained_backbone=True)`\r\n\r\n**it give a error like this, it seems the resnext101_32x8d is not  corresponding with the pretrained model structure**:\r\nFile \"train_with_resnet101.py\", line 68, in fasterrcnn_resnet101_fpn\r\n    backbone = resnet_fpn_backbone('resnext101_32x8d', pretrained_backbone)\r\n  File \"/miniconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/detection/backbone_utils.py\", line 47, in resnet_fpn_backbone\r\n    norm_layer=misc_nn_ops.FrozenBatchNorm2d)\r\n  File \"miniconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/resnet.py\", line 313, in resnext101_32x8d\r\n    pretrained, progress, **kwargs)\r\n  File \"miniconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/resnet.py\", line 224, in _resnet\r\n    model.load_state_dict(state_dict)\r\n  File \"miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 830, in load_state_dict\r\n    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\r\nRuntimeError: Error(s) in loading state_dict for ResNet:\r\n        Unexpected key(s) in state_dict: \"bn1.num_batches_tracked\", \"layer1.0.bn1.num_batches_tracked\", \"layer1.0.bn2.num_batches_tracked\", \"layer1.0.bn3.num_batches_tracked\", \"layer1.0.downsample.1.num_batches_tracked\", \"layer1.1.bn1.num_batches_tracked\", \"layer1.1.bn2.num_batches_tracked\", \"layer1.1.bn3.num_batches_tracked\", \"layer1.2.bn1.num_batches_tracked\", \"layer1.2.bn2.num_batches_tracked\", \"layer1.2.bn3.num_batches_tracked\", \"layer2.0.bn1.num_batches_tracked\", \"layer2.0.bn2.num_batches_tracked\", \"layer2.0.bn3.num_batches_tracked\", \"layer2.0.downsample.1.num_batches_tracked\", \"layer2.1.bn1.num_batches_tracked\", \"layer2.1.bn2.num_batches_tracked\", \"layer2.1.bn3.num_batches_tracked\", \"layer2.2.bn1.num_batches_tracked\", \"layer2.2.bn2.num_batches_tracked\", \"layer2.2.bn3.num_batches_tracked\", \"layer2.3.bn1.num_batches_tracked\", \"layer2.3.bn2.num_batches_tracked\", \"layer2.3.bn3.num_batches_tracked\", \"layer3.0.bn1.num_batches_tracked\", \"layer3.0.bn2.num_batches_tracked\", \"layer3.0.bn3.num_batches_tracked\", \"layer3.0.downsample.1.num_batches_tracked\", \"layer3.1.bn1.num_batches_tracked\", \"layer3.1.bn2.num_batches_tracked\", \"layer3.1.bn3.num_batches_tracked\", \"layer3.2.bn1.num_batches_tracked\", \"layer3.2.bn2.num_batches_tracked\", \"layer3.2.bn3.num_batches_tracked\", \"layer3.3.bn1.num_batches_tracked\", \"layer3.3.bn2.num_batches_tracked\", \"layer3.3.bn3.num_batches_tracked\", \"layer3.4.bn1.num_batches_tracked\", \"layer3.4.bn2.num_batches_tracked\", \"layer3.4.bn3.num_batches_tracked\", \"layer3.5.bn1.num_batches_tracked\", \"layer3.5.bn2.num_batches_tracked\", \"layer3.5.bn3.num_batches_tracked\", \"layer3.6.bn1.num_batches_tracked\", \"layer3.6.bn2.num_batches_tracked\", \"layer3.6.bn3.num_batches_tracked\", \"layer3.7.bn1.num_batches_tracked\", \"layer3.7.bn2.num_batches_tracked\", \"layer3.7.bn3.num_batches_tracked\", \"layer3.8.bn1.num_batches_tracked\", \"layer3.8.bn2.num_batches_tracked\", \"layer3.8.bn3.num_batches_tracked\", \"layer3.9.bn1.num_batches_tracked\", \"layer3.9.bn2.num_batches_tracked\", \"layer3.9.bn3.num_batches_tracked\", \"layer3.10.bn1.num_batches_tracked\", \"layer3.10.bn2.num_batches_tracked\", \"layer3.10.bn3.num_batches_tracked\", \"layer3.11.bn1.num_batches_tracked\", \"layer3.11.bn2.num_batches_tracked\", \"layer3.11.bn3.num_batches_tracked\", \"layer3.12.bn1.num_batches_tracked\", \"layer3.12.bn2.num_batches_tracked\", \"layer3.12.bn3.num_batches_tracked\", \"layer3.13.bn1.num_batches_tracked\", \"layer3.13.bn2.num_batches_tracked\", \"layer3.13.bn3.num_batches_tracked\", \"layer3.14.bn1.num_batches_tracked\", \"layer3.14.bn2.num_batches_tracked\", \"layer3.14.bn3.num_batches_tracked\", \"layer3.15.bn1.num_batches_tracked\", \"layer3.15.bn2.num_batches_tracked\", \"layer3.15.bn3.num_batches_tracked\", \"layer3.16.bn1.num_batches_tracked\", \"layer3.16.bn2.num_batches_tracked\", \"layer3.16.bn3.num_batches_tracked\", \"layer3.17.bn1.num_batches_tracked\", \"layer3.17.bn2.num_batches_tracked\", \"layer3.17.bn3.num_batches_tracked\", \"layer3.18.bn1.num_batches_tracked\", \"layer3.18.bn2.num_batches_tracked\", \"layer3.18.bn3.num_batches_tracked\", \"layer3.19.bn1.num_batches_tracked\", \"layer3.19.bn2.num_batches_tracked\", \"layer3.19.bn3.num_batches_tracked\", \"layer3.20.bn1.num_batches_tracked\", \"layer3.20.bn2.num_batches_tracked\", \"layer3.20.bn3.num_batches_tracked\", \"layer3.21.bn1.num_batches_tracked\", \"layer3.21.bn2.num_batches_tracked\", \"layer3.21.bn3.num_batches_tracked\", \"layer3.22.bn1.num_batches_tracked\", \"layer3.22.bn2.num_batches_tracked\", \"layer3.22.bn3.num_batches_tracked\", \"layer4.0.bn1.num_batches_tracked\", \"layer4.0.bn2.num_batches_tracked\", \"layer4.0.bn3.num_batches_tracked\", \"layer4.0.downsample.1.num_batches_tracked\", \"layer4.1.bn1.num_batches_tracked\", \"layer4.1.bn2.num_batches_tracked\", \"layer4.1.bn3.num_batches_tracked\", \"layer4.2.bn1.num_batches_tracked\", \"layer4.2.bn2.num_batches_tracked\", \"layer4.2.bn3.num_batches_tracked\".\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n\r\n## Environment\r\n\r\n - PyTorch / torchvision Version (e.g., 1.0 / 0.4.0):pytorch1.4 and torchvision 0.5.0            \r\n - OS (e.g., Linux):Linux\r\n - How you installed PyTorch / torchvision (`conda`, `pip`, source):\r\nconda install pytorch torchvision cudatoolkit=10.0 -c pytorch\r\n - Python version:py37\r\n - CUDA/cuDNN version:V10.0.130\r\n - GPU models and configuration:GeForce RTX 2080ti\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2265", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2265/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2265/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2265/events", "html_url": "https://github.com/pytorch/vision/issues/2265", "id": 625488889, "node_id": "MDU6SXNzdWU2MjU0ODg4ODk=", "number": 2265, "title": "UCF101 datasets with DataLoader returns error when stacking examples in mini-batches", "user": {"login": "AndreaCossu", "id": 8200219, "node_id": "MDQ6VXNlcjgyMDAyMTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/8200219?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AndreaCossu", "html_url": "https://github.com/AndreaCossu", "followers_url": "https://api.github.com/users/AndreaCossu/followers", "following_url": "https://api.github.com/users/AndreaCossu/following{/other_user}", "gists_url": "https://api.github.com/users/AndreaCossu/gists{/gist_id}", "starred_url": "https://api.github.com/users/AndreaCossu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AndreaCossu/subscriptions", "organizations_url": "https://api.github.com/users/AndreaCossu/orgs", "repos_url": "https://api.github.com/users/AndreaCossu/repos", "events_url": "https://api.github.com/users/AndreaCossu/events{/privacy}", "received_events_url": "https://api.github.com/users/AndreaCossu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 2089185327, "node_id": "MDU6TGFiZWwyMDg5MTg1MzI3", "url": "https://api.github.com/repos/pytorch/vision/labels/high%20priority", "name": "high priority", "color": "b60205", "default": false, "description": ""}, {"id": 1447973685, "node_id": "MDU6TGFiZWwxNDQ3OTczNjg1", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20io", "name": "module: io", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-05-27T08:27:25Z", "updated_at": "2020-08-01T17:35:48Z", "closed_at": "2020-06-05T14:16:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n`UCF101` dataset returns a `RunTimeError` when combined with standard `DataLoader` class. It returns the error when trying to stack multiple tensors in batches.\r\n\r\n## To Reproduce\r\n```\r\nimport torchvision.datasets as datasets\r\nimport torchvision.transforms as transforms\r\nfrom torch.utils.data import DataLoader\r\n\r\ntfs = transforms.Compose([\r\n            transforms.Lambda(lambda x: x / 255.), # scale in [0, 1]\r\n            transforms.Lambda(lambda x: x.permute(0, 3, 1, 2) ) # reshape into (T, C, H, W)\r\n    ])\r\n\r\n\r\n# root, root_labels are the directories containing data and labels\r\nd = datasets.UCF101(root, root_labels, frames_per_clip=25, step_between_clips=25, train=False, transform=tfs)\r\ndataset = DataLoader(d, batch_size=7, shuffle=True, drop_last=True)\r\n\r\nfor i, (v, a, l) in enumerate(dataset):  # <- RunTimeError occurs here\r\n    pass\r\n```\r\n\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n      1 print(len(dataset))\r\n----> 2 for i, (v, a, l) in enumerate(dataset):\r\n      3     pass\r\n\r\n~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)\r\n    343 \r\n    344     def __next__(self):\r\n--> 345         data = self._next_data()\r\n    346         self._num_yielded += 1\r\n    347         if self._dataset_kind == _DatasetKind.Iterable and \\\r\n\r\n~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py in _next_data(self)\r\n    383     def _next_data(self):\r\n    384         index = self._next_index()  # may raise StopIteration\r\n--> 385         data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\r\n    386         if self._pin_memory:\r\n    387             data = _utils.pin_memory.pin_memory(data)\r\n\r\n~/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py in fetch(self, possibly_batched_index)\r\n     45         else:\r\n     46             data = self.dataset[possibly_batched_index]\r\n---> 47         return self.collate_fn(data)\r\n\r\n~/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in default_collate(batch)\r\n     77     elif isinstance(elem, container_abcs.Sequence):\r\n     78         transposed = zip(*batch)\r\n---> 79         return [default_collate(samples) for samples in transposed]\r\n     80 \r\n     81     raise TypeError(default_collate_err_msg_format.format(elem_type))\r\n\r\n~/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in <listcomp>(.0)\r\n     77     elif isinstance(elem, container_abcs.Sequence):\r\n     78         transposed = zip(*batch)\r\n---> 79         return [default_collate(samples) for samples in transposed]\r\n     80 \r\n     81     raise TypeError(default_collate_err_msg_format.format(elem_type))\r\n\r\n~/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in default_collate(batch)\r\n     53             storage = elem.storage()._new_shared(numel)\r\n     54             out = elem.new(storage)\r\n---> 55         return torch.stack(batch, 0, out=out)\r\n     56     elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\r\n     57             and elem_type.__name__ != 'string_':\r\n\r\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 2 and 1 in dimension 1 at /opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/TH/generic/THTensor.cpp:612\r\n```\r\n\r\n\r\n## Expected behavior\r\n\r\nThe iteration over the dataloader should return a video tensor of size `(B, T, C, H, W)` where B is batch size, T is the number of frames, C are the image channels and H and W the image dimensions.\r\n\r\n## Environment\r\n - PyTorch / torchvision Version: 1.4.0 / 0.5.0\r\n - OS (e.g., Linux): CentOS Linux 7\r\n - How you installed PyTorch / torchvision (`conda`, `pip`, source): conda\r\n - Python version: 3.7.3\r\n ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2262", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2262/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2262/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2262/events", "html_url": "https://github.com/pytorch/vision/issues/2262", "id": 625115763, "node_id": "MDU6SXNzdWU2MjUxMTU3NjM=", "number": 2262, "title": "Unable to load CelebA dataset. File is not zip file error. ", "user": {"login": "ajayrfhp", "id": 4273609, "node_id": "MDQ6VXNlcjQyNzM2MDk=", "avatar_url": "https://avatars1.githubusercontent.com/u/4273609?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajayrfhp", "html_url": "https://github.com/ajayrfhp", "followers_url": "https://api.github.com/users/ajayrfhp/followers", "following_url": "https://api.github.com/users/ajayrfhp/following{/other_user}", "gists_url": "https://api.github.com/users/ajayrfhp/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajayrfhp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajayrfhp/subscriptions", "organizations_url": "https://api.github.com/users/ajayrfhp/orgs", "repos_url": "https://api.github.com/users/ajayrfhp/repos", "events_url": "https://api.github.com/users/ajayrfhp/events{/privacy}", "received_events_url": "https://api.github.com/users/ajayrfhp/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619883, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODM=", "url": "https://api.github.com/repos/pytorch/vision/labels/duplicate", "name": "duplicate", "color": "cccccc", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1373818326, "node_id": "MDU6TGFiZWwxMzczODE4MzI2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20datasets", "name": "module: datasets", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-05-25T18:16:03Z", "updated_at": "2020-08-07T16:38:17Z", "closed_at": "2020-07-03T12:52:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n## \ud83d\udc1b Bug\r\n\r\nUnable to download and load celeba dataset into a loader. \r\n\r\n## To Reproduce\r\n\r\n\r\n1. Try to load CeleBA dataset with download true returns error\r\n```\r\nbatch_size=25\r\ntrain_loader = torch.utils.data.DataLoader(\r\n        datasets.CelebA('../data', split=\"train\", download=True,\r\n                       transform=transforms.Compose([\r\n                           transforms.ToTensor(),\r\n                           transforms.Normalize((0.5,), (0.5,))\r\n                       ])),\r\n        batch_size=batch_size, shuffle=True)\r\n```\r\n\r\nReturns \r\n```\r\n/usr/local/lib/python3.6/dist-packages/torchvision/datasets/celeba.py in __init__(self, root, split, target_type, transform, target_transform, download)\r\n     64 \r\n     65         if download:\r\n---> 66             self.download()\r\n     67 \r\n     68         if not self._check_integrity():\r\n\r\n/usr/local/lib/python3.6/dist-packages/torchvision/datasets/celeba.py in download(self)\r\n    118             download_file_from_google_drive(file_id, os.path.join(self.root, self.base_folder), filename, md5)\r\n    119 \r\n--> 120         with zipfile.ZipFile(os.path.join(self.root, self.base_folder, \"img_align_celeba.zip\"), \"r\") as f:\r\n    121             f.extractall(os.path.join(self.root, self.base_folder))\r\n    122 \r\n\r\n/usr/lib/python3.6/zipfile.py in __init__(self, file, mode, compression, allowZip64)\r\n   1129         try:\r\n   1130             if mode == 'r':\r\n-> 1131                 self._RealGetContents()\r\n   1132             elif mode in ('w', 'x'):\r\n   1133                 # set the modified flag so central directory gets written\r\n\r\n/usr/lib/python3.6/zipfile.py in _RealGetContents(self)\r\n   1196             raise BadZipFile(\"File is not a zip file\")\r\n   1197         if not endrec:\r\n-> 1198             raise BadZipFile(\"File is not a zip file\")\r\n   1199         if self.debug > 1:\r\n   1200             print(endrec)\r\n\r\nBadZipFile: File is not a zip file\r\n```\r\n\r\n## Environment\r\n\r\n- PyTorch version: 1.5.0+cu101\r\n- Is debug build: No\r\n- CUDA used to build PyTorch: 10.1\r\n\r\n- OS: Ubuntu 18.04.3 LTS\r\n- GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n- CMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\n- Is CUDA available: Yes\r\n- CUDA runtime version: 10.1.243\r\n- GPU models and configuration: GPU 0: Tesla T4\r\n- Nvidia driver version: 418.67\r\n- cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n- [pip3] numpy==1.18.4\r\n- [pip3] torch==1.5.0+cu101\r\n- [pip3] torchsummary==1.5.1\r\n- [pip3] torchtext==0.3.1\r\n- [pip3] torchvision==0.6.0+cu101", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2255", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2255/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2255/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2255/events", "html_url": "https://github.com/pytorch/vision/issues/2255", "id": 623601313, "node_id": "MDU6SXNzdWU2MjM2MDEzMTM=", "number": 2255, "title": "Avoid `using namespace at` in the header file?", "user": {"login": "ShawnZhong", "id": 6421097, "node_id": "MDQ6VXNlcjY0MjEwOTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/6421097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ShawnZhong", "html_url": "https://github.com/ShawnZhong", "followers_url": "https://api.github.com/users/ShawnZhong/followers", "following_url": "https://api.github.com/users/ShawnZhong/following{/other_user}", "gists_url": "https://api.github.com/users/ShawnZhong/gists{/gist_id}", "starred_url": "https://api.github.com/users/ShawnZhong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ShawnZhong/subscriptions", "organizations_url": "https://api.github.com/users/ShawnZhong/orgs", "repos_url": "https://api.github.com/users/ShawnZhong/repos", "events_url": "https://api.github.com/users/ShawnZhong/events{/privacy}", "received_events_url": "https://api.github.com/users/ShawnZhong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-23T07:28:47Z", "updated_at": "2020-05-26T11:06:51Z", "closed_at": "2020-05-26T11:06:37Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nSome header files have `using namespace at` at the top level, which contaminates the file that included it, increasing the chance of name collision. \r\n\r\nhttps://github.com/pytorch/vision/blob/d88d8961ae51507d0cb680329d985b1488b1b76b/torchvision/csrc/empty_tensor_op.h#L8\r\n\r\nhttps://github.com/pytorch/vision/blob/57c789f893950331daf2721d08a7367a261317e1/torchvision/csrc/PSROIPool.h#L71\r\n\r\nhttps://github.com/pytorch/vision/blob/57c789f893950331daf2721d08a7367a261317e1/torchvision/csrc/ROIPool.h#L71\r\n\r\nhttps://github.com/pytorch/vision/blob/57c789f893950331daf2721d08a7367a261317e1/torchvision/csrc/DeformConv.h#L91\r\n\r\nhttps://github.com/pytorch/vision/blob/57c789f893950331daf2721d08a7367a261317e1/torchvision/csrc/ROIAlign.h#L92\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2254", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2254/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2254/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2254/events", "html_url": "https://github.com/pytorch/vision/issues/2254", "id": 623592436, "node_id": "MDU6SXNzdWU2MjM1OTI0MzY=", "number": 2254, "title": "Using `vision.references`", "user": {"login": "Sentient07", "id": 6195312, "node_id": "MDQ6VXNlcjYxOTUzMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6195312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sentient07", "html_url": "https://github.com/Sentient07", "followers_url": "https://api.github.com/users/Sentient07/followers", "following_url": "https://api.github.com/users/Sentient07/following{/other_user}", "gists_url": "https://api.github.com/users/Sentient07/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sentient07/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sentient07/subscriptions", "organizations_url": "https://api.github.com/users/Sentient07/orgs", "repos_url": "https://api.github.com/users/Sentient07/repos", "events_url": "https://api.github.com/users/Sentient07/events{/privacy}", "received_events_url": "https://api.github.com/users/Sentient07/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373819307, "node_id": "MDU6TGFiZWwxMzczODE5MzA3", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20reference%20scripts", "name": "module: reference scripts", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-23T06:19:33Z", "updated_at": "2020-05-29T10:32:56Z", "closed_at": "2020-05-26T14:31:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI was wondering if there was a way by which I can use the modules inside `vision.references`, especially `vision.references.detection.engine`'s `train_one_epoch` method. At the moment, I am unable to import and use it rather would have to copy-paste or download. Could this be simplified into an import? (by adding an `__init__.py`) ? Or, perhaps there is a way to do this more elegantly and I'm unaware? \r\n\r\nThanks and Regards,", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2251", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2251/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2251/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2251/events", "html_url": "https://github.com/pytorch/vision/issues/2251", "id": 623195272, "node_id": "MDU6SXNzdWU2MjMxOTUyNzI=", "number": 2251, "title": "ONNX export of MaskRCNN: inference fails when no detections are present", "user": {"login": "zuzaanto", "id": 24386215, "node_id": "MDQ6VXNlcjI0Mzg2MjE1", "avatar_url": "https://avatars1.githubusercontent.com/u/24386215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zuzaanto", "html_url": "https://github.com/zuzaanto", "followers_url": "https://api.github.com/users/zuzaanto/followers", "following_url": "https://api.github.com/users/zuzaanto/following{/other_user}", "gists_url": "https://api.github.com/users/zuzaanto/gists{/gist_id}", "starred_url": "https://api.github.com/users/zuzaanto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zuzaanto/subscriptions", "organizations_url": "https://api.github.com/users/zuzaanto/orgs", "repos_url": "https://api.github.com/users/zuzaanto/repos", "events_url": "https://api.github.com/users/zuzaanto/events{/privacy}", "received_events_url": "https://api.github.com/users/zuzaanto/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1706804376, "node_id": "MDU6TGFiZWwxNzA2ODA0Mzc2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20onnx", "name": "module: onnx", "color": "edaea8", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-05-22T13:11:02Z", "updated_at": "2020-07-03T09:18:35Z", "closed_at": "2020-05-22T15:32:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nAfter exporting MaskRCNN to ONNX, inference works correctly on images on which there are detection. However, when trying to infer on a tensor that will have nothing detected on it, exception is thrown:\r\n`[E:onnxruntime:, sequential_executor.cc:183 Execute] Non-zero status code returned while running ReduceMax node. Name:'' Status Message: /onnxruntime_src/onnxruntime/core/providers/cuda/reduction/reduction_ops.cc:110 onnxruntime::common::Status onnxruntime::cuda::PrepareForReduce(onnxruntime::OpKernelContext*, bool, const std::vector<long int>&, const onnxruntime::Tensor**, onnxruntime::Tensor**, int64_t&, int64_t&, std::vector<long int>&, std::vector<long int>&, std::vector<long int>&) keepdims || dim != 0 was false. Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:{0,4}`\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1.Export a pretrained MaskRCNN model:\r\n```\r\ntorch.onnx.export(\r\n        model,\r\n        input_tensor.float(),\r\n        onnx_model_filepath,\r\n        export_params=True,\r\n        opset_version=11,\r\n        do_constant_folding=True,\r\n        verbose=False,\r\n        input_names=[\"input\"],\r\n        output_names=[\"output\"],\r\n        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output: {0: \"batch_size\"}},\r\n    )\r\n```\r\n2. Infer on an image that has detections:\r\n```\r\nort_session = onnxruntime.InferenceSession(onnx_model_filepath)\r\ninput_array = input_tensor.cpu().numpy()\r\nort_inputs = {\"input\": input_array}\r\nfor i in tqdm(range(1), desc=\"ort_session.run\"):\r\n        ort_outputs = ort_session.run(None, ort_inputs)\r\n```\r\nNo exceptions here. Now\r\n3. Infer on an image that will have no detections, ex. a random one:\r\n```\r\nrandom_tensor = torch.randn(input_tensor.shape)\r\nrandom_array = random_tensor.cpu().numpy()\r\nort_inputs = {\"input\": random_array}\r\nfor i in tqdm(range(1), desc=\"ort_session.run\"):\r\n        ort_outputs = ort_session.run(None, ort_inputs)\r\n```\r\nThis throws the exception:\r\n```\r\n`[E:onnxruntime:, sequential_executor.cc:183 Execute] Non-zero status code returned while running ReduceMax node. Name:'' Status Message: /onnxruntime_src/onnxruntime/core/providers/cuda/reduction/reduction_ops.cc:110 onnxruntime::common::Status onnxruntime::cuda::PrepareForReduce(onnxruntime::OpKernelContext*, bool, const std::vector<long int>&, const onnxruntime::Tensor**, onnxruntime::Tensor**, int64_t&, int64_t&, std::vector<long int>&, std::vector<long int>&, std::vector<long int>&) keepdims || dim != 0 was false. Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:{0,4}`\r\n```\r\n```\r\nStacktrace:\r\n\r\nort_session.run:   0%|                                                                                                                                                                | 0/1 [00:00<?, ?it/s]\r\nTraceback (most recent call last):\r\n  File \"maskrcnn_deployment.py\", line 205, in infer_onnx_model\r\n    ort_outputs = ort_session.run(None, ort_inputs)\r\n  File \"/.../lib/python3.6/site-packages/onnxruntime/capi/session.py\", line 144, in run\r\n    return self._sess.run(output_names, input_feed, run_options)\r\nonnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running ReduceMax node. Name:'' Status Message: /onnxruntime_src/onnxruntime/core/providers/cuda/reduction/reduction_ops.cc:110 onnxruntime::common::Status onnxruntime::cuda::PrepareForReduce(onnxruntime::OpKernelContext*, bool, const std::vector<long int>&, const onnxruntime::Tensor**, onnxruntime::Tensor**, int64_t&, int64_t&, std::vector<long int>&, std::vector<long int>&, std::vector<long int>&) keepdims || dim != 0 was false. Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:{0,4}\r\n```\r\n\r\n## Expected behavior\r\n\r\nI would expect to obtain output from the ONNX exported MaskRCNN similar to the output from PyTorch version, i.e. a list of \"boxes\", \"labels\", \"scores\" and \"masks\", with their 1st dimension = 0\r\n\r\n## Environment\r\n```\r\nPlPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: Could not collect\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.0.130\r\nGPU models and configuration: \r\nGPU 0: GeForce RTX 2080 Ti\r\nGPU 1: GeForce RTX 2080 Ti\r\nGPU 2: GeForce RTX 2080 Ti\r\nGPU 3: GeForce RTX 2080 Ti\r\n\r\nNvidia driver version: 418.87.01\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.1\r\n[pip3] torch==1.4.0\r\n[pip3] torchvision==0.5.0\r\n[conda] Could not collect\r\n\r\n```\r\nAlso:\r\n```\r\n[pip3] onnx==1.6.0\r\n[pip3] onnxruntime==1.1.2\r\n[pip3] onnxruntime-gpu==1.1.2\r\n\r\n```\r\n## Additional context\r\n\r\nI'm using torchvision 0.5.0, because according to changelog of version 0.6.0, in 0.6.0 support of MaskRCNN export to ONNX is temporarily suspended. It has been claimed to work for version 0.5.0, or so I understand.\r\nThanks for your help!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2250", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2250/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2250/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2250/events", "html_url": "https://github.com/pytorch/vision/issues/2250", "id": 622649976, "node_id": "MDU6SXNzdWU2MjI2NDk5NzY=", "number": 2250, "title": "cuda10.0 support for torchvision6", "user": {"login": "feihuidiqiu", "id": 15182877, "node_id": "MDQ6VXNlcjE1MTgyODc3", "avatar_url": "https://avatars1.githubusercontent.com/u/15182877?v=4", "gravatar_id": "", "url": "https://api.github.com/users/feihuidiqiu", "html_url": "https://github.com/feihuidiqiu", "followers_url": "https://api.github.com/users/feihuidiqiu/followers", "following_url": "https://api.github.com/users/feihuidiqiu/following{/other_user}", "gists_url": "https://api.github.com/users/feihuidiqiu/gists{/gist_id}", "starred_url": "https://api.github.com/users/feihuidiqiu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/feihuidiqiu/subscriptions", "organizations_url": "https://api.github.com/users/feihuidiqiu/orgs", "repos_url": "https://api.github.com/users/feihuidiqiu/repos", "events_url": "https://api.github.com/users/feihuidiqiu/events{/privacy}", "received_events_url": "https://api.github.com/users/feihuidiqiu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1588820772, "node_id": "MDU6TGFiZWwxNTg4ODIwNzcy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20binaries", "name": "topic: binaries", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-21T17:13:19Z", "updated_at": "2020-05-21T18:20:42Z", "closed_at": "2020-05-21T18:20:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "I try to install torchvision6-cu100 with pip but failed, I can only find  the cu92 and cu101 version,  is there no support for cuda10.0 ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2245", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2245/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2245/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2245/events", "html_url": "https://github.com/pytorch/vision/issues/2245", "id": 621707309, "node_id": "MDU6SXNzdWU2MjE3MDczMDk=", "number": 2245, "title": "[C++ Frontend] Simple example with VGG gives memory error", "user": {"login": "ntatsisk", "id": 45266491, "node_id": "MDQ6VXNlcjQ1MjY2NDkx", "avatar_url": "https://avatars2.githubusercontent.com/u/45266491?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ntatsisk", "html_url": "https://github.com/ntatsisk", "followers_url": "https://api.github.com/users/ntatsisk/followers", "following_url": "https://api.github.com/users/ntatsisk/following{/other_user}", "gists_url": "https://api.github.com/users/ntatsisk/gists{/gist_id}", "starred_url": "https://api.github.com/users/ntatsisk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ntatsisk/subscriptions", "organizations_url": "https://api.github.com/users/ntatsisk/orgs", "repos_url": "https://api.github.com/users/ntatsisk/repos", "events_url": "https://api.github.com/users/ntatsisk/events{/privacy}", "received_events_url": "https://api.github.com/users/ntatsisk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1479831546, "node_id": "MDU6TGFiZWwxNDc5ODMxNTQ2", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20c++%20frontend", "name": "module: c++ frontend", "color": "f7e101", "default": false, "description": ""}, {"id": 719389156, "node_id": "MDU6TGFiZWw3MTkzODkxNTY=", "url": "https://api.github.com/repos/pytorch/vision/labels/needs%20reproduction", "name": "needs reproduction", "color": "64fca1", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2020-05-20T12:05:48Z", "updated_at": "2020-07-12T15:30:25Z", "closed_at": "2020-07-12T15:30:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nHello! I have compiled the master branch of torchvision and used the pre-built libtorch lib. I manage to run the simple HelloWorld example using the ResNet18 but I get \"Unhandled exception at 0x00007FFDB7D2A799\" error when using the VGG16 network. It fails both for Release and Debug configurations (while ResNet works for both of them). Any ideas? Thanks. \r\n\r\n## To Reproduce\r\n\r\n```\r\n#include <iostream>\r\n#include <torchvision/models/vgg.h>\r\n//#include <torchvision/models/resnet.h>\r\n\r\nint main()\r\n{\r\n\r\n\tauto model = vision::models::VGG16();\r\n\t//auto model = vision::models::ResNet18();\r\n\r\n\tmodel->eval();\r\n\r\n\t// Create a random input tensor and run it through the model.\r\n\t//auto in = torch::rand({ 1, 3, 10, 10 });\r\n\tauto in = torch::rand({ 10, 3, 224, 224 });\r\n\tauto out = model->forward(in);\r\n\r\n\tstd::cout << out;\r\n\r\n\tsystem(\"pause\");\r\n}\r\n```\r\n\r\nBy the way as a sanity check, the equivalent python code works:\r\n\r\n```\r\nimport torch\r\nimport torchvision.models as models\r\n\r\nvgg16 = models.vgg16(pretrained=False)\r\n\r\nvgg16.eval()\r\n\r\nin_tensor = torch.rand(size=(10, 3, 224, 224))\r\nout_tensor = vgg16.forward(in_tensor)\r\n\r\nprint(out_tensor)\r\n```\r\n\r\n## Environment\r\nWindows 10\r\nVisual Studio 2017\r\npre-build libtorch\r\nTorchvision build from master repo\r\nCMake 3.16\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2240", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2240/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2240/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2240/events", "html_url": "https://github.com/pytorch/vision/issues/2240", "id": 620859805, "node_id": "MDU6SXNzdWU2MjA4NTk4MDU=", "number": 2240, "title": "Raise error if target boxes are degenerate in Faster R-CNN", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619884, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODQ=", "url": "https://api.github.com/repos/pytorch/vision/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-19T10:23:48Z", "updated_at": "2020-05-29T13:29:54Z", "closed_at": "2020-05-29T13:29:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We have had a number of reports with users saying that their training loss is nan after a few iterations.\r\n\r\nMost of the time, this is due to degenerate boxes (i.e., boxes with negative sizes or zero area). We should improve the user experience in those situations.\r\n\r\nI think that raising an error in `GeneralizedRCNN` if the target boxes are degenerate would be a good compromise.\r\n\r\nRelated issues: https://github.com/pytorch/vision/issues/2235 https://github.com/pytorch/vision/issues/1994 https://github.com/pytorch/vision/issues/1176 https://github.com/pytorch/vision/issues/1128 #1120 and #997", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2237", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2237/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2237/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2237/events", "html_url": "https://github.com/pytorch/vision/issues/2237", "id": 620737468, "node_id": "MDU6SXNzdWU2MjA3Mzc0Njg=", "number": 2237, "title": "fresh installation of pytorch 1.5 and torchvision .6 yields error with docs ", "user": {"login": "EMCP", "id": 3691722, "node_id": "MDQ6VXNlcjM2OTE3MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3691722?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EMCP", "html_url": "https://github.com/EMCP", "followers_url": "https://api.github.com/users/EMCP/followers", "following_url": "https://api.github.com/users/EMCP/following{/other_user}", "gists_url": "https://api.github.com/users/EMCP/gists{/gist_id}", "starred_url": "https://api.github.com/users/EMCP/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EMCP/subscriptions", "organizations_url": "https://api.github.com/users/EMCP/orgs", "repos_url": "https://api.github.com/users/EMCP/repos", "events_url": "https://api.github.com/users/EMCP/events{/privacy}", "received_events_url": "https://api.github.com/users/EMCP/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373819307, "node_id": "MDU6TGFiZWwxMzczODE5MzA3", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20reference%20scripts", "name": "module: reference scripts", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-19T07:15:13Z", "updated_at": "2020-05-20T10:32:24Z", "closed_at": "2020-05-20T10:32:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nusing the latest installations from the pytorch recommended conda line, along with the following required libraries\r\n\r\n```\r\ncython\r\npycocotools\r\nmatplotlib\r\n```\r\n\r\nI was able to hit an error in the line given under https://github.com/pytorch/vision/blob/master/references/detection/README.md\r\nfor performing Faster R CNN\r\n\r\nI would also wonder if I can improve the docs by mentioning the fact that, in order to run that example you must pip install cython, pycocotools, and matplotlib ?\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. copy the `references/detection/` folder somewhere\r\n2. create a conda environment and install latest stable pytorch and torchvision\r\n3. attempt to run the `README.md` provided command\r\n\r\n```\r\n(clone_reference_torchvision) emcp@2600k:~/Dev/git/clone_reference_torchvision$ python -m torch.distributed.launch --nproc_per_node=8 --use_env train.py --dataset coco --model fasterrcnn_resnet50_fpn --epochs 26 --lr-steps 16 22 --aspect-ratio-group-factor 3\r\n*****************************************\r\nSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n*****************************************\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp line=59 error=101 : invalid device ordinal\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp line=59 error=101 : invalid device ordinal\r\n| distributed init (rank 0): env://\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 201, in <module>\r\n    main(args)\r\n  File \"train.py\", line 60, in main\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 201, in <module>\r\n        main(args)\r\n  File \"train.py\", line 60, in main\r\n    utils.init_distributed_mode(args)\r\n  File \"/home/emcp/Dev/git/clone_reference_torchvision/utils.py\", line 317, in init_distributed_mode\r\nutils.init_distributed_mode(args)\r\n    torch.cuda.set_device(args.gpu)\r\n  File \"/home/emcp/anaconda3/envs/clone_reference_torchvision/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 245, in set_device\r\n  File \"/home/emcp/Dev/git/clone_reference_torchvision/utils.py\", line 317, in init_distributed_mode\r\n    torch._C._cuda_setDevice(device)\r\n    torch.cuda.set_device(args.gpu)\r\n  File \"/home/emcp/anaconda3/envs/clone_reference_torchvision/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 245, in set_device\r\nRuntimeError    torch._C._cuda_setDevice(device)\r\nRuntimeError: cuda runtime error (101) : invalid device ordinal at /opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp:59\r\n: cuda runtime error (101) : invalid device ordinal at /opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp:59\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp line=59 error=101 : invalid device ordinal\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 201, in <module>\r\n    main(args)\r\n  File \"train.py\", line 60, in main\r\n    utils.init_distributed_mode(args)\r\n  File \"/home/emcp/Dev/git/clone_reference_torchvision/utils.py\", line 317, in init_distributed_mode\r\n    torch.cuda.set_device(args.gpu)\r\n  File \"/home/emcp/anaconda3/envs/clone_reference_torchvision/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 245, in set_device\r\n    torch._C._cuda_setDevice(device)\r\nRuntimeError: cuda runtime error (101) : invalid device ordinal at /opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp:59\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp line=59 error=101 : invalid device ordinal\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 201, in <module>\r\n    main(args)\r\n  File \"train.py\", line 60, in main\r\n    utils.init_distributed_mode(args)\r\n  File \"/home/emcp/Dev/git/clone_reference_torchvision/utils.py\", line 317, in init_distributed_mode\r\n    torch.cuda.set_device(args.gpu)\r\n  File \"/home/emcp/anaconda3/envs/clone_reference_torchvision/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 245, in set_device\r\n    torch._C._cuda_setDevice(device)\r\nRuntimeError: cuda runtime error (101) : invalid device ordinal at /opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp:59\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp line=59 error=101 : invalid device ordinal\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 201, in <module>\r\n    main(args)\r\n  File \"train.py\", line 60, in main\r\n    utils.init_distributed_mode(args)\r\n  File \"/home/emcp/Dev/git/clone_reference_torchvision/utils.py\", line 317, in init_distributed_mode\r\n    torch.cuda.set_device(args.gpu)\r\n  File \"/home/emcp/anaconda3/envs/clone_reference_torchvision/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 245, in set_device\r\n    torch._C._cuda_setDevice(device)\r\nRuntimeError: cuda runtime error (101) : invalid device ordinal at /opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp:59\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp line=59 error=101 : invalid device ordinal\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 201, in <module>\r\n    main(args)\r\n  File \"train.py\", line 60, in main\r\n    utils.init_distributed_mode(args)\r\n  File \"/home/emcp/Dev/git/clone_reference_torchvision/utils.py\", line 317, in init_distributed_mode\r\n    torch.cuda.set_device(args.gpu)\r\n  File \"/home/emcp/anaconda3/envs/clone_reference_torchvision/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 245, in set_device\r\n    torch._C._cuda_setDevice(device)\r\nRuntimeError: cuda runtime error (101) : invalid device ordinal at /opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp:59\r\nTHCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp line=59 error=101 : invalid device ordinal\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 201, in <module>\r\n    main(args)\r\n  File \"train.py\", line 60, in main\r\n    utils.init_distributed_mode(args)\r\n  File \"/home/emcp/Dev/git/clone_reference_torchvision/utils.py\", line 317, in init_distributed_mode\r\n    torch.cuda.set_device(args.gpu)\r\n  File \"/home/emcp/anaconda3/envs/clone_reference_torchvision/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 245, in set_device\r\n    torch._C._cuda_setDevice(device)\r\nRuntimeError: cuda runtime error (101) : invalid device ordinal at /opt/conda/conda-bld/pytorch_1587428207430/work/torch/csrc/cuda/Module.cpp:59\r\n\r\n```\r\n## Expected behavior\r\n\r\nit should execute training\r\n\r\n## Environment\r\n\r\n```\r\n/home/emcp/anaconda3/envs/clone_reference_torchvision/bin/python /home/emcp/Dev/git/clone_reference_torchvision/collect_env.py\r\nCollecting environment information...\r\nPyTorch version: 1.5.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 20.04 LTS\r\nGCC version: (Ubuntu 9.3.0-10ubuntu2) 9.3.0\r\nCMake version: Could not collect\r\n\r\nPython version: 3.8\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: GeForce GTX 1060 6GB\r\nNvidia driver version: 440.64\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.18.1\r\n[pip] torch==1.5.0\r\n[pip] torchvision==0.6.0a0+82fd1c8\r\n[conda] blas                      1.0                         mkl  \r\n[conda] cudatoolkit               10.2.89              hfd86e86_1  \r\n[conda] mkl                       2020.1                      217  \r\n[conda] mkl-service               2.3.0            py38he904b0f_0  \r\n[conda] mkl_fft                   1.0.15           py38ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py38h962f231_0  \r\n[conda] numpy                     1.18.1           py38h4f9e942_0  \r\n[conda] numpy-base                1.18.1           py38hde5b4d6_1  \r\n[conda] pytorch                   1.5.0           py3.8_cuda10.2.89_cudnn7.6.5_0    pytorch\r\n[conda] torchvision               0.6.0                py38_cu102    pytorch\r\n\r\nProcess finished with exit code 0\r\n\r\n```\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2235", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2235/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2235/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2235/events", "html_url": "https://github.com/pytorch/vision/issues/2235", "id": 620690623, "node_id": "MDU6SXNzdWU2MjA2OTA2MjM=", "number": 2235, "title": "NaN Loss for FasterRCNN on Multiclass Object Detection on Custom Dataset COCO", "user": {"login": "sarmientoj24", "id": 8830319, "node_id": "MDQ6VXNlcjg4MzAzMTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/8830319?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sarmientoj24", "html_url": "https://github.com/sarmientoj24", "followers_url": "https://api.github.com/users/sarmientoj24/followers", "following_url": "https://api.github.com/users/sarmientoj24/following{/other_user}", "gists_url": "https://api.github.com/users/sarmientoj24/gists{/gist_id}", "starred_url": "https://api.github.com/users/sarmientoj24/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sarmientoj24/subscriptions", "organizations_url": "https://api.github.com/users/sarmientoj24/orgs", "repos_url": "https://api.github.com/users/sarmientoj24/repos", "events_url": "https://api.github.com/users/sarmientoj24/events{/privacy}", "received_events_url": "https://api.github.com/users/sarmientoj24/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-05-19T05:32:03Z", "updated_at": "2020-05-19T17:47:49Z", "closed_at": "2020-05-19T10:24:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\nCode\r\n# Dataloader / DataLoading\r\n```\r\nclass OwnDataset(torch.utils.data.Dataset):\r\n    def __init__(self, root, annotation, transforms=None):\r\n        self.root = root\r\n        self.transforms = transforms\r\n        self.coco = COCO(annotation)\r\n        self.ids = list(sorted(self.coco.imgs.keys()))\r\n\r\n    def __getitem__(self, index):\r\n        # Own coco file\r\n        coco = self.coco\r\n        # Image ID\r\n        img_id = self.ids[index]\r\n        # List: get annotation id from coco\r\n        ann_ids = coco.getAnnIds(imgIds=img_id)\r\n        # Dictionary: target coco_annotation file for an image\r\n        coco_annotation = coco.loadAnns(ann_ids)\r\n        # print(coco_annotation)\r\n        # path for input image\r\n        path = coco.loadImgs(img_id)[0]['file_name']\r\n        # open the input image\r\n        img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\r\n        width, height = img.size\r\n        # number of objects in the image\r\n        num_objs = len(coco_annotation)\r\n\r\n        # Bounding boxes for objects\r\n        # In coco format, bbox = [xmin, ymin, width, height]\r\n        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\r\n        boxes = []\r\n        labelings = []\r\n        for i in range(num_objs):\r\n            xmin = max(coco_annotation[i]['bbox'][0], 0)\r\n            ymin = max(coco_annotation[i]['bbox'][1], 0)\r\n            xmax = max(xmin + coco_annotation[i]['bbox'][2], 0)\r\n            ymax = max(ymin + coco_annotation[i]['bbox'][3], 0)\r\n            boxes.append([xmin, ymin, xmax, ymax])\r\n            labelings.append(coco_annotation[i]['category_id'])\r\n            assert xmin >= 0\r\n            assert xmax <= width\r\n            assert xmin <= xmax\r\n\r\n            assert ymin >= 0\r\n            assert ymax <= height\r\n            assert ymin <= ymax\r\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\r\n        boxes = boxes.reshape(-1, 4)\r\n        # Labels (In my case, I only one class: target class or background)\r\n        labels = torch.as_tensor(labelings, dtype=torch.int64)\r\n        # Tensorise img_id\r\n        img_id = torch.tensor([img_id])\r\n        # Size of bbox (Rectangular)\r\n        areas = []\r\n        for i in range(num_objs):\r\n            areas.append(coco_annotation[i]['area'])\r\n        areas = torch.as_tensor(areas, dtype=torch.float32)\r\n        # Iscrowd\r\n        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\r\n\r\n        # Annotation is in dictionary format\r\n        my_annotation = {}\r\n        my_annotation[\"boxes\"] = boxes\r\n        my_annotation[\"labels\"] = labels\r\n        my_annotation[\"image_id\"] = img_id\r\n        my_annotation[\"area\"] = areas\r\n        my_annotation[\"iscrowd\"] = iscrowd\r\n\r\n        if self.transforms is not None:\r\n            img = self.transforms(img)\r\n        \r\n        # img.type(torch.float32)\r\n\r\n        return img, my_annotation\r\n\r\n    def __len__(self):\r\n        return len(self.ids)\r\n\r\nfrom torchvision import transforms\r\ndef get_transform():\r\n    custom_transforms = [\r\n        transforms.RandomHorizontalFlip(),\r\n        transforms.ToTensor(),\r\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n    ]\r\n    return torchvision.transforms.Compose(custom_transforms)\r\n\r\n# path to your own data and coco file\r\ntrain_data_dir = '/root/output2/imgs/'\r\ntrain_coco = '/root/output2/train.json'\r\n\r\n# create own Dataset\r\nmy_dataset = OwnDataset(root=train_data_dir, \r\n                        annotation=train_coco, \r\n                        transforms=get_transform()\r\n                        )\r\n\r\n# collate_fn needs for batch\r\ndef collate_fn(batch):\r\n    return tuple(zip(*batch))\r\n\r\n# Batch size\r\ntrain_batch_size = 2\r\n\r\n# own DataLoader\r\ndata_loader = torch.utils.data.DataLoader(my_dataset,\r\n                                          batch_size=train_batch_size,\r\n                                          shuffle=True,\r\n                                          num_workers=2,\r\n                                          collate_fn=collate_fn,\r\n                                          pin_memory=True)\r\n```\r\n\r\n# Training procedure and Model Instace for FasterRCNN\r\n```\r\ndef get_model_instance_segmentation(num_classes):\r\n    backbone = torchvision.models.mobilenet_v2(pretrained=True, progress=False).features\r\n\r\n    backbone.out_channels = 1280\r\n    anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256),),\r\n                                    aspect_ratios=((0.5, 1.0, 2.0),))\r\n    roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\r\n                                                  output_size=7,\r\n                                                  sampling_ratio=2)\r\n    model = FasterRCNN(backbone,\r\n                   num_classes=num_classes,\r\n                   rpn_anchor_generator=anchor_generator,\r\n                   box_roi_pool=roi_pooler)\r\n    return model\r\n\r\nmodel = get_model_instance_segmentation(num_classes)\r\n\r\nparams = [p for p in model.parameters() if p.requires_grad]\r\noptimizer = torch.optim.SGD(params, lr=0.0001, momentum=0.9, weight_decay=0.0005)\r\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\r\n                                                   step_size=3,\r\n                                                   gamma=0.1)\r\n\r\nlen_dataloader = len(data_loader)\r\ntotal_len = num_epochs * len_dataloader\r\nmodel.to(device)\r\nold_epoch = 0\r\n\r\nimport time\r\nnum_epochs = 10000\r\n\r\ntime_s = time.time()\r\ntotal_processed = 0\r\ntotal_len = num_epochs * len_dataloader\r\nfor epoch in range(old_epoch, num_epochs):\r\n    print(\"---------------------------------------------------------------\")\r\n    print(\"EPOCH: \", epoch)\r\n    model.train()\r\n    for imgs, annotations in data_loader:\r\n        imgs = list(img.to(device) for img in imgs)\r\n        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\r\n        loss_dict = model(imgs, annotations)\r\n        losses = sum(loss for loss in loss_dict.values())\r\n        optimizer.zero_grad()\r\n        losses.backward()\r\n        optimizer.step()\r\n        lr_scheduler.step()\r\n```\r\n\r\n\r\n## Expected behavior\r\n\r\nI am getting NaN as Loss after some few epochs\r\n\r\n## Environment\r\n\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: version 3.5.1\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.243\r\nGPU models and configuration: GPU 0: Tesla T4\r\nNvidia driver version: 440.64.00\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.3\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.4\r\n[pip3] sagemaker-pytorch-training==1.3.0\r\n[pip3] torch==1.5.0\r\n[pip3] torchvision==0.6.0\r\n[conda] magma-cuda101             2.5.1                         1    pytorch\r\n[conda] mkl                       2019.4                      243    anaconda\r\n[conda] mkl-include               2019.4                      243    anaconda\r\n[conda] mkl-service               2.3.0            py36he904b0f_0    anaconda\r\n[conda] mkl_random                1.1.0            py36hd6b4f25_0    anaconda\r\n[conda] numpy                     1.18.4                   pypi_0    pypi\r\n[conda] sagemaker-pytorch-training 1.3.0                    pypi_0    pypi\r\n[conda] torch                     1.5.0                    pypi_0    pypi\r\n[conda] torchvision               0.6.0                    pypi_0    pypi\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2228", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2228/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2228/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2228/events", "html_url": "https://github.com/pytorch/vision/issues/2228", "id": 620280978, "node_id": "MDU6SXNzdWU2MjAyODA5Nzg=", "number": 2228, "title": "Can't import torchvision after building from source", "user": {"login": "fepegar", "id": 12688084, "node_id": "MDQ6VXNlcjEyNjg4MDg0", "avatar_url": "https://avatars1.githubusercontent.com/u/12688084?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fepegar", "html_url": "https://github.com/fepegar", "followers_url": "https://api.github.com/users/fepegar/followers", "following_url": "https://api.github.com/users/fepegar/following{/other_user}", "gists_url": "https://api.github.com/users/fepegar/gists{/gist_id}", "starred_url": "https://api.github.com/users/fepegar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fepegar/subscriptions", "organizations_url": "https://api.github.com/users/fepegar/orgs", "repos_url": "https://api.github.com/users/fepegar/repos", "events_url": "https://api.github.com/users/fepegar/events{/privacy}", "received_events_url": "https://api.github.com/users/fepegar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 689153061, "node_id": "MDU6TGFiZWw2ODkxNTMwNjE=", "url": "https://api.github.com/repos/pytorch/vision/labels/needs%20discussion", "name": "needs discussion", "color": "e99695", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-05-18T15:00:42Z", "updated_at": "2020-05-19T10:02:03Z", "closed_at": "2020-05-18T17:33:10Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```shell\r\nconda create -n tv python -y && conda activate tv\r\ngit clone --depth 1 git@github.com:pytorch/vision.git\r\ncd vision\r\nMACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py install\r\npython -c \"import torchvision\"\r\n```\r\n\r\n<details>\r\n<p>\r\n\r\n```python-traceback\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: done\r\n\r\n\r\n==> WARNING: A newer version of conda exists. <==\r\n  current version: 4.7.12\r\n  latest version: 4.8.3\r\n\r\nPlease update conda by running\r\n\r\n    $ conda update -n base -c defaults conda\r\n\r\n\r\n\r\n## Package Plan ##\r\n\r\n  environment location: /usr/local/Caskroom/miniconda/base/envs/tv\r\n\r\n  added / updated specs:\r\n    - python\r\n\r\n\r\nThe following NEW packages will be INSTALLED:\r\n\r\n  ca-certificates    pkgs/main/osx-64::ca-certificates-2020.1.1-0\r\n  certifi            pkgs/main/osx-64::certifi-2020.4.5.1-py38_0\r\n  libcxx             pkgs/main/osx-64::libcxx-10.0.0-1\r\n  libedit            pkgs/main/osx-64::libedit-3.1.20181209-hb402a30_0\r\n  libffi             pkgs/main/osx-64::libffi-3.3-h0a44026_1\r\n  ncurses            pkgs/main/osx-64::ncurses-6.2-h0a44026_1\r\n  openssl            pkgs/main/osx-64::openssl-1.1.1g-h1de35cc_0\r\n  pip                pkgs/main/osx-64::pip-20.0.2-py38_3\r\n  python             pkgs/main/osx-64::python-3.8.2-hf48f09d_13\r\n  readline           pkgs/main/osx-64::readline-8.0-h1de35cc_0\r\n  setuptools         pkgs/main/osx-64::setuptools-46.2.0-py38_0\r\n  sqlite             pkgs/main/osx-64::sqlite-3.31.1-h5c1f38d_1\r\n  tk                 pkgs/main/osx-64::tk-8.6.8-ha441bb4_0\r\n  wheel              pkgs/main/osx-64::wheel-0.34.2-py38_0\r\n  xz                 pkgs/main/osx-64::xz-5.2.5-h1de35cc_0\r\n  zlib               pkgs/main/osx-64::zlib-1.2.11-h1de35cc_3\r\n\r\n\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\n#\r\n# To activate this environment, use\r\n#\r\n#     $ conda activate tv\r\n#\r\n# To deactivate an active environment, use\r\n#\r\n#     $ conda deactivate\r\n\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: done\r\n\r\n\r\n==> WARNING: A newer version of conda exists. <==\r\n  current version: 4.7.12\r\n  latest version: 4.8.3\r\n\r\nPlease update conda by running\r\n\r\n    $ conda update -n base -c defaults conda\r\n\r\n\r\n\r\n## Package Plan ##\r\n\r\n  environment location: /usr/local/Caskroom/miniconda/base/envs/tv\r\n\r\n  added / updated specs:\r\n    - av\r\n\r\n\r\nThe following NEW packages will be INSTALLED:\r\n\r\n  av                 conda-forge/osx-64::av-8.0.1-py38haad2d5e_0\r\n  bzip2              conda-forge/osx-64::bzip2-1.0.8-h0b31af3_2\r\n  ffmpeg             conda-forge/osx-64::ffmpeg-4.2-h5c2b479_0\r\n  freetype           conda-forge/osx-64::freetype-2.10.2-h8da9a1a_0\r\n  gettext            conda-forge/osx-64::gettext-0.19.8.1-h1f1d5ed_1\r\n  gmp                conda-forge/osx-64::gmp-6.2.0-h4a8c4bd_2\r\n  gnutls             conda-forge/osx-64::gnutls-3.6.5-h53004b3_1002\r\n  jpeg               conda-forge/osx-64::jpeg-9c-h1de35cc_1001\r\n  lame               conda-forge/osx-64::lame-3.100-h1de35cc_1001\r\n  libblas            conda-forge/osx-64::libblas-3.8.0-16_openblas\r\n  libcblas           conda-forge/osx-64::libcblas-3.8.0-16_openblas\r\n  libgfortran        conda-forge/osx-64::libgfortran-4.0.0-2\r\n  libiconv           conda-forge/osx-64::libiconv-1.15-h0b31af3_1006\r\n  liblapack          conda-forge/osx-64::liblapack-3.8.0-16_openblas\r\n  libopenblas        conda-forge/osx-64::libopenblas-0.3.9-h3d69b6c_0\r\n  libpng             conda-forge/osx-64::libpng-1.6.37-hbbe82c9_1\r\n  libtiff            conda-forge/osx-64::libtiff-4.1.0-h2ae36a8_6\r\n  libwebp-base       conda-forge/osx-64::libwebp-base-1.1.0-h0b31af3_3\r\n  llvm-openmp        conda-forge/osx-64::llvm-openmp-10.0.0-h28b9765_0\r\n  lz4-c              conda-forge/osx-64::lz4-c-1.9.2-h4a8c4bd_1\r\n  nettle             conda-forge/osx-64::nettle-3.4.1-h3efe00b_1002\r\n  numpy              conda-forge/osx-64::numpy-1.18.4-py38h1f821a2_0\r\n  olefile            conda-forge/noarch::olefile-0.46-py_0\r\n  openh264           conda-forge/osx-64::openh264-1.8.0-hd9629dc_1000\r\n  pillow             pkgs/main/osx-64::pillow-7.1.2-py38h4655f20_0\r\n  python_abi         conda-forge/osx-64::python_abi-3.8-1_cp38\r\n  x264               conda-forge/osx-64::x264-1!152.20180806-h1de35cc_0\r\n  zstd               conda-forge/osx-64::zstd-1.4.4-h4b3e974_3\r\n\r\nThe following packages will be UPDATED:\r\n\r\n  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.4.5.1-hecc5488_0\r\n\r\nThe following packages will be SUPERSEDED by a higher-priority channel:\r\n\r\n  certifi              pkgs/main::certifi-2020.4.5.1-py38_0 --> conda-forge::certifi-2020.4.5.1-py38h32f6830_0\r\n  openssl              pkgs/main::openssl-1.1.1g-h1de35cc_0 --> conda-forge::openssl-1.1.1g-h0b31af3_0\r\n\r\n\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: done\r\n\r\n\r\n==> WARNING: A newer version of conda exists. <==\r\n  current version: 4.7.12\r\n  latest version: 4.8.3\r\n\r\nPlease update conda by running\r\n\r\n    $ conda update -n base -c defaults conda\r\n\r\n\r\n\r\n## Package Plan ##\r\n\r\n  environment location: /usr/local/Caskroom/miniconda/base/envs/tv\r\n\r\n  added / updated specs:\r\n    - pytorch\r\n\r\n\r\nThe following NEW packages will be INSTALLED:\r\n\r\n  intel-openmp       pkgs/main/osx-64::intel-openmp-2020.1-216\r\n  mkl                pkgs/main/osx-64::mkl-2020.1-216\r\n  ninja              pkgs/main/osx-64::ninja-1.9.0-py38h04f5b5a_0\r\n  pytorch            pytorch/osx-64::pytorch-1.4.0-py3.8_0\r\n\r\nThe following packages will be SUPERSEDED by a higher-priority channel:\r\n\r\n  certifi            conda-forge::certifi-2020.4.5.1-py38h~ --> pkgs/main::certifi-2020.4.5.1-py38_0\r\n\r\n\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\nCloning into 'vision'...\r\nremote: Enumerating objects: 446, done.\r\nremote: Counting objects: 100% (446/446), done.\r\nremote: Compressing objects: 100% (385/385), done.\r\nremote: Total 446 (delta 70), reused 199 (delta 50), pack-reused 0\r\nReceiving objects: 100% (446/446), 5.75 MiB | 3.43 MiB/s, done.\r\nResolving deltas: 100% (70/70), done.\r\nBuilding wheel torchvision-0.7.0a0+e2e511b\r\nrunning install\r\nrunning bdist_egg\r\nrunning egg_info\r\ncreating torchvision.egg-info\r\nwriting torchvision.egg-info/PKG-INFO\r\nwriting dependency_links to torchvision.egg-info/dependency_links.txt\r\nwriting requirements to torchvision.egg-info/requires.txt\r\nwriting top-level names to torchvision.egg-info/top_level.txt\r\nwriting manifest file 'torchvision.egg-info/SOURCES.txt'\r\nreading manifest file 'torchvision.egg-info/SOURCES.txt'\r\nreading manifest template 'MANIFEST.in'\r\nwarning: no previously-included files matching '__pycache__' found under directory '*'\r\nwarning: no previously-included files matching '*.py[co]' found under directory '*'\r\nwriting manifest file 'torchvision.egg-info/SOURCES.txt'\r\ninstalling library code to build/bdist.macosx-10.9-x86_64/egg\r\nrunning install_lib\r\nrunning build_py\r\ncreating build\r\ncreating build/lib.macosx-10.9-x86_64-3.8\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncopying torchvision/version.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncopying torchvision/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncopying torchvision/utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncopying torchvision/extension.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/flickr.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/coco.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/cityscapes.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/video_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/vision.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/stl10.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/lsun.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/usps.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/folder.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/imagenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/sbd.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/ucf101.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/svhn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/celeba.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/semeion.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/cifar.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/voc.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/hmdb51.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/sbu.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/caltech.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/fakedata.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/kinetics.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/phototour.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/mnist.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/omniglot.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/io\r\ncopying torchvision/io/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/io\r\ncopying torchvision/io/_video_opt.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/io\r\ncopying torchvision/io/video.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/io\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/shufflenetv2.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/googlenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/mnasnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/vgg.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/squeezenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/densenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/inception.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/mobilenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/resnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/alexnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/functional_tensor.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/transforms.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/_functional_video.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/functional.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/_transforms_video.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/deform_conv.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/misc.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/poolers.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/roi_align.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/boxes.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/roi_pool.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/feature_pyramid_network.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/ps_roi_align.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/_register_onnx_ops.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/new_empty_tensor.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/ps_roi_pool.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/samplers\r\ncopying torchvision/datasets/samplers/clip_sampler.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/samplers\r\ncopying torchvision/datasets/samplers/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/samplers\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models/video\r\ncopying torchvision/models/video/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/video\r\ncopying torchvision/models/video/resnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/video\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/fcn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/deeplabv3.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/segmentation.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/shufflenetv2.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/googlenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/inception.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/mobilenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/resnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/rpn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/faster_rcnn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/generalized_rcnn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/backbone_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/transform.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/mask_rcnn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/image_list.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/keypoint_rcnn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/roi_heads.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\nrunning build_ext\r\nbuilding 'torchvision._C' extension\r\ncreating build/temp.macosx-10.9-x86_64-3.8\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/vision.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/DeformConv_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/DeformConv_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/ROIAlign_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/ROIPool_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/ROIPool_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/PSROIPool_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/PSROIPool_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/PSROIAlign_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/PSROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/nms_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\nclang++ -bundle -undefined dynamic_lookup -L/usr/local/Caskroom/miniconda/base/envs/tv/lib -arch x86_64 -L/usr/local/Caskroom/miniconda/base/envs/tv/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/vision.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/DeformConv_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/ROIAlign_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/ROIPool_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/PSROIPool_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/PSROIAlign_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/nms_cpu.o -o build/lib.macosx-10.9-x86_64-3.8/torchvision/_C.so\r\nbuilding 'torchvision.video_reader' extension\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/video_reader\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:95:3: warning: comparison of integers of different signs: 'int64_t' (aka 'long long') and\r\n      'std::__1::vector<ffmpeg::DecoderOutputMessage, std::__1::allocator<ffmpeg::DecoderOutputMessage> >::size_type' (aka 'unsigned long') [-Wsign-compare]\r\n  CHECK_EQ(framePts.size(0), msgs.size());\r\n  ^        ~~~~~~~~~~~~~~~~  ~~~~~~~~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:131:51: note: expanded from macro 'CHECK_EQ'\r\n#define CHECK_EQ(val1, val2) CHECK_OP(val1, val2, ==)\r\n                                      ~~~~  ~~~~  ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:128:18: note: expanded from macro 'CHECK_OP'\r\n  FATAL_IF((val1 op val2)) << \"Check failed: \" #val1 \" \" #op \" \" #val2 \" \"\r\n            ~~~~ ^  ~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:110:3: note: expanded from macro 'FATAL_IF'\r\n  condition ? (void)0                  \\\r\n  ^~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:590:17: warning: unused variable 'media' [-Wunused-variable]\r\n    const auto& media = header.format;\r\n                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:95:3: warning: comparison of integers of different signs: 'int64_t' (aka 'long long') and\r\n      'std::__1::vector<ffmpeg::DecoderOutputMessage, std::__1::allocator<ffmpeg::DecoderOutputMessage> >::size_type' (aka 'unsigned long') [-Wsign-compare]\r\n  CHECK_EQ(framePts.size(0), msgs.size());\r\n  ^        ~~~~~~~~~~~~~~~~  ~~~~~~~~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:131:51: note: expanded from macro 'CHECK_EQ'\r\n#define CHECK_EQ(val1, val2) CHECK_OP(val1, val2, ==)\r\n                                      ~~~~  ~~~~  ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:128:18: note: expanded from macro 'CHECK_OP'\r\n  FATAL_IF((val1 op val2)) << \"Check failed: \" #val1 \" \" #op \" \" #val2 \" \"\r\n            ~~~~ ^  ~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:110:3: note: expanded from macro 'FATAL_IF'\r\n  condition ? (void)0                  \\\r\n  ^~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:128:10: note: in instantiation of function template specialization 'video_reader::fillTensor<unsigned char>'\r\n      requested here\r\n  return fillTensor<uint8_t>(msgs, videoFrame, videoFramePts, num, den);\r\n         ^\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:95:3: warning: comparison of integers of different signs: 'int64_t' (aka 'long long') and\r\n      'std::__1::vector<ffmpeg::DecoderOutputMessage, std::__1::allocator<ffmpeg::DecoderOutputMessage> >::size_type' (aka 'unsigned long') [-Wsign-compare]\r\n  CHECK_EQ(framePts.size(0), msgs.size());\r\n  ^        ~~~~~~~~~~~~~~~~  ~~~~~~~~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:131:51: note: expanded from macro 'CHECK_EQ'\r\n#define CHECK_EQ(val1, val2) CHECK_OP(val1, val2, ==)\r\n                                      ~~~~  ~~~~  ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:128:18: note: expanded from macro 'CHECK_OP'\r\n  FATAL_IF((val1 op val2)) << \"Check failed: \" #val1 \" \" #op \" \" #val2 \" \"\r\n            ~~~~ ^  ~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:110:3: note: expanded from macro 'FATAL_IF'\r\n  condition ? (void)0                  \\\r\n  ^~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:137:10: note: in instantiation of function template specialization 'video_reader::fillTensor<float>' requested\r\n      here\r\n  return fillTensor<float>(msgs, audioFrame, audioFramePts, num, den);\r\n         ^\r\n4 warnings generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:69:24: warning: comparison of integers of different signs: 'long' and 'size_t' (aka 'unsigned long')\r\n      [-Wsign-compare]\r\n  while (!eof_ && end_ < maxBytes && (hasTime = watcher())) {\r\n                  ~~~~ ^ ~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:74:16: warning: comparison of integers of different signs: 'long' and 'std::__1::vector<unsigned char,\r\n      std::__1::allocator<unsigned char> >::size_type' (aka 'unsigned long') [-Wsign-compare]\r\n      if (end_ == buffer_.size()) {\r\n          ~~~~ ^  ~~~~~~~~~~~~~~\r\n2 warnings generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/cc_stream.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/cc_stream.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/util.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:52:25: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          s += sizeof(y.pict.linesize[i]);\r\n                        ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:52:30: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          s += sizeof(y.pict.linesize[i]);\r\n                             ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:53:18: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          s += y.pict.linesize[i];\r\n                 ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:53:23: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          s += y.pict.linesize[i];\r\n                      ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:96:41: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          if (!serializeItem(d, l, p, x.pict.linesize[i])) {\r\n                                        ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:96:46: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          if (!serializeItem(d, l, p, x.pict.linesize[i])) {\r\n                                             ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:99:21: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          if (p + x.pict.linesize[i] > l) {\r\n                    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:99:26: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          if (p + x.pict.linesize[i] > l) {\r\n                         ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:102:27: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(d + p, x.pict.data[i], x.pict.linesize[i]);\r\n                          ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:102:32: warning: 'data' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(d + p, x.pict.data[i], x.pict.linesize[i]);\r\n                               ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3867:5: note: 'data' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:102:43: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(d + p, x.pict.data[i], x.pict.linesize[i]);\r\n                                          ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:102:48: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(d + p, x.pict.data[i], x.pict.linesize[i]);\r\n                                               ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:103:18: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          p += x.pict.linesize[i];\r\n                 ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:103:23: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          p += x.pict.linesize[i];\r\n                      ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:175:43: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          if (!deserializeItem(y, l, p, x.pict.linesize[i])) {\r\n                                          ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:175:48: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          if (!deserializeItem(y, l, p, x.pict.linesize[i])) {\r\n                                               ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:178:21: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          if (p + x.pict.linesize[i] > l) {\r\n                    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:178:26: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          if (p + x.pict.linesize[i] > l) {\r\n                         ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:181:13: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          x.pict.data[i] = (uint8_t*)av_malloc(x.pict.linesize[i]);\r\n            ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:181:18: warning: 'data' is deprecated [-Wdeprecated-declarations]\r\n          x.pict.data[i] = (uint8_t*)av_malloc(x.pict.linesize[i]);\r\n                 ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3867:5: note: 'data' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:181:50: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          x.pict.data[i] = (uint8_t*)av_malloc(x.pict.linesize[i]);\r\n                                                 ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:181:55: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          x.pict.data[i] = (uint8_t*)av_malloc(x.pict.linesize[i]);\r\n                                                      ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:182:20: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(x.pict.data[i], y + p, x.pict.linesize[i]);\r\n                   ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:182:25: warning: 'data' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(x.pict.data[i], y + p, x.pict.linesize[i]);\r\n                        ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3867:5: note: 'data' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:182:43: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(x.pict.data[i], y + p, x.pict.linesize[i]);\r\n                                          ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:182:48: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(x.pict.data[i], y + p, x.pict.linesize[i]);\r\n                                               ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:183:18: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          p += x.pict.linesize[i];\r\n                 ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:183:23: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          p += x.pict.linesize[i];\r\n                      ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n28 warnings generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_sampler.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_sampler.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/audio_stream.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/audio_stream.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/audio_stream.cpp:10:20: warning: comparison of integers of different signs: 'const size_t' (aka 'const unsigned long') and\r\n      'const int' [-Wsign-compare]\r\n  return x.samples == y.sample_rate && x.channels == y.channels &&\r\n         ~~~~~~~~~ ^  ~~~~~~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/audio_stream.cpp:10:51: warning: comparison of integers of different signs: 'const size_t' (aka 'const unsigned long') and\r\n      'const int' [-Wsign-compare]\r\n  return x.samples == y.sample_rate && x.channels == y.channels &&\r\n                                       ~~~~~~~~~~ ^  ~~~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/audio_stream.cpp:15:20: warning: comparison of integers of different signs: 'const size_t' (aka 'const unsigned long') and\r\n      'const int' [-Wsign-compare]\r\n  return x.samples == y.sample_rate && x.channels == y.channels &&\r\n         ~~~~~~~~~ ^  ~~~~~~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/audio_stream.cpp:15:51: warning: comparison of integers of different signs: 'const size_t' (aka 'const unsigned long') and\r\n      'const int' [-Wsign-compare]\r\n  return x.samples == y.sample_rate && x.channels == y.channels &&\r\n                                       ~~~~~~~~~~ ^  ~~~~~~~~~~\r\n4 warnings generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_stream.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_stream.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nIn file included from /private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_stream.cpp:1:\r\nIn file included from /private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_stream.h:3:\r\nIn file included from /private/tmp/vision/torchvision/csrc/cpu/decoder/stream.h:4:\r\nIn file included from /private/tmp/vision/torchvision/csrc/cpu/decoder/defs.h:12:\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:1454:16: warning: 'convergence_duration' is deprecated [-Wdeprecated-declarations]\r\ntypedef struct AVPacket {\r\n               ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_stream.cpp:50:14: note: in implicit copy constructor for 'AVPacket' first required here\r\n  auto pkt = packet ? *packet : avPacket;\r\n             ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:1505:5: note: 'convergence_duration' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n1 warning generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/audio_sampler.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/audio_sampler.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/stream.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/stream.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/stream.cpp:234:19: warning: 'av_frame_get_best_effort_timestamp' is deprecated [-Wdeprecated-declarations]\r\n    header->pts = av_frame_get_best_effort_timestamp(frame_);\r\n                  ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/frame.h:682:1: note: 'av_frame_get_best_effort_timestamp' has been explicitly marked deprecated here\r\nattribute_deprecated\r\n^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n1 warning generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/time_keeper.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/time_keeper.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/memory_buffer.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/memory_buffer.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/decoder.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/decoder.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/decoder.cpp:198:5: warning: 'av_register_all' is deprecated [-Wdeprecated-declarations]\r\n    av_register_all();\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavformat/avformat.h:2049:1: note: 'av_register_all' has been explicitly marked deprecated here\r\nattribute_deprecated\r\n^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/decoder.cpp:199:5: warning: 'avcodec_register_all' is deprecated [-Wdeprecated-declarations]\r\n    avcodec_register_all();\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:4158:1: note: 'avcodec_register_all' has been explicitly marked deprecated here\r\nattribute_deprecated\r\n^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/decoder.cpp:202:5: warning: 'av_lockmgr_register' is deprecated [-Wdeprecated-declarations]\r\n    av_lockmgr_register(&ffmpeg_lock);\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavcodec/avcodec.h:6162:1: note: 'av_lockmgr_register' has been explicitly marked deprecated here\r\nattribute_deprecated\r\n^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/decoder.cpp:385:47: warning: 'codec' is deprecated [-Wdeprecated-declarations]\r\n    const auto media = inputCtx_->streams[i]->codec->codec_type;\r\n                                              ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavformat/avformat.h:884:5: note: 'codec' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/decoder.cpp:382:21: warning: comparison of integers of different signs: 'int' and 'unsigned int' [-Wsign-compare]\r\n  for (int i = 0; i < inputCtx_->nb_streams; i++) {\r\n                  ~ ^ ~~~~~~~~~~~~~~~~~~~~~\r\n5 warnings generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/sync_decoder.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/sync_decoder.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/video_stream.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/video_stream.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/video_stream.cpp:9:18: warning: comparison of integers of different signs: 'const size_t' (aka 'const unsigned long') and\r\n      'const int' [-Wsign-compare]\r\n  return x.width == y.width && x.height == y.height && x.format == y.format;\r\n         ~~~~~~~ ^  ~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/video_stream.cpp:9:41: warning: comparison of integers of different signs: 'const size_t' (aka 'const unsigned long') and\r\n      'const int' [-Wsign-compare]\r\n  return x.width == y.width && x.height == y.height && x.format == y.format;\r\n                               ~~~~~~~~ ^  ~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/video_stream.cpp:13:18: warning: comparison of integers of different signs: 'const size_t' (aka 'const unsigned long') and\r\n      'const int' [-Wsign-compare]\r\n  return x.width == y.width && x.height == y.height && x.format == y.pix_fmt;\r\n         ~~~~~~~ ^  ~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/video_stream.cpp:13:41: warning: comparison of integers of different signs: 'const size_t' (aka 'const unsigned long') and\r\n      'const int' [-Wsign-compare]\r\n  return x.width == y.width && x.height == y.height && x.format == y.pix_fmt;\r\n                               ~~~~~~~~ ^  ~~~~~~~~\r\n4 warnings generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/Caskroom/miniconda/base/envs/tv/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/video_sampler.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/video_sampler.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nclang++ -bundle -undefined dynamic_lookup -L/usr/local/Caskroom/miniconda/base/envs/tv/lib -arch x86_64 -L/usr/local/Caskroom/miniconda/base/envs/tv/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/cc_stream.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/util.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_sampler.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/audio_stream.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/subtitle_stream.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/audio_sampler.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/stream.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/time_keeper.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/memory_buffer.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/decoder.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/sync_decoder.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/video_stream.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/video_sampler.o -lavcodec -lavformat -lavutil -lswresample -lswscale -o build/lib.macosx-10.9-x86_64-3.8/torchvision/video_reader.so -std=c++14\r\ncreating build/bdist.macosx-10.9-x86_64\r\ncreating build/bdist.macosx-10.9-x86_64/egg\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/_C.so -> build/bdist.macosx-10.9-x86_64/egg/torchvision\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/version.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/flickr.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/coco.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/cityscapes.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/video_utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/vision.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/stl10.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/lsun.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/usps.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/folder.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/imagenet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/sbd.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/ucf101.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/svhn.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/celeba.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/semeion.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/samplers\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/samplers/clip_sampler.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/samplers\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/samplers/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/samplers\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/cifar.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/voc.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/hmdb51.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/sbu.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/caltech.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/fakedata.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/kinetics.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/phototour.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/mnist.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/omniglot.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/io\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/io/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/io\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/io/_video_opt.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/io\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/io/video.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/io\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/shufflenetv2.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/models/video\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/video/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/video\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/video/resnet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/video\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/googlenet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/mnasnet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/vgg.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/squeezenet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation/fcn.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation/deeplabv3.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation/_utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation/segmentation.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/densenet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/inception.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization/shufflenetv2.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization/googlenet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization/inception.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization/mobilenet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization/resnet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization/utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/mobilenet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/resnet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/alexnet.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/rpn.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/faster_rcnn.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/generalized_rcnn.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/backbone_utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/transform.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/mask_rcnn.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/image_list.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/keypoint_rcnn.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/roi_heads.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection/_utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/models/_utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/models\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/video_reader.so -> build/bdist.macosx-10.9-x86_64/egg/torchvision\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms/functional_tensor.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms/transforms.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms/_functional_video.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms/functional.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms/_transforms_video.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/extension.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision\r\ncreating build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/deform_conv.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/misc.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/poolers.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/roi_align.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/boxes.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/roi_pool.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/feature_pyramid_network.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/ps_roi_align.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/_register_onnx_ops.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/new_empty_tensor.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/ps_roi_pool.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\ncopying build/lib.macosx-10.9-x86_64-3.8/torchvision/ops/_utils.py -> build/bdist.macosx-10.9-x86_64/egg/torchvision/ops\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/version.py to version.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/flickr.py to flickr.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/coco.py to coco.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/cityscapes.py to cityscapes.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/video_utils.py to video_utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/vision.py to vision.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/stl10.py to stl10.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/lsun.py to lsun.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/usps.py to usps.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/folder.py to folder.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/imagenet.py to imagenet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/sbd.py to sbd.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/ucf101.py to ucf101.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/svhn.py to svhn.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/celeba.py to celeba.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/utils.py to utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/semeion.py to semeion.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/samplers/clip_sampler.py to clip_sampler.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/samplers/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/cifar.py to cifar.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/voc.py to voc.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/hmdb51.py to hmdb51.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/sbu.py to sbu.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/caltech.py to caltech.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/fakedata.py to fakedata.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/kinetics.py to kinetics.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/phototour.py to phototour.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/mnist.py to mnist.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/datasets/omniglot.py to omniglot.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/io/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/io/_video_opt.py to _video_opt.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/io/video.py to video.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/shufflenetv2.py to shufflenetv2.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/video/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/video/resnet.py to resnet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/googlenet.py to googlenet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/mnasnet.py to mnasnet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/vgg.py to vgg.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/squeezenet.py to squeezenet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation/fcn.py to fcn.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation/deeplabv3.py to deeplabv3.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation/_utils.py to _utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/segmentation/segmentation.py to segmentation.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/densenet.py to densenet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/inception.py to inception.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization/shufflenetv2.py to shufflenetv2.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization/googlenet.py to googlenet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization/inception.py to inception.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization/mobilenet.py to mobilenet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization/resnet.py to resnet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/quantization/utils.py to utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/mobilenet.py to mobilenet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/resnet.py to resnet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/utils.py to utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/alexnet.py to alexnet.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/rpn.py to rpn.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/faster_rcnn.py to faster_rcnn.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/generalized_rcnn.py to generalized_rcnn.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/backbone_utils.py to backbone_utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/transform.py to transform.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/mask_rcnn.py to mask_rcnn.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/image_list.py to image_list.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/keypoint_rcnn.py to keypoint_rcnn.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/roi_heads.py to roi_heads.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/detection/_utils.py to _utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/models/_utils.py to _utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms/functional_tensor.py to functional_tensor.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms/transforms.py to transforms.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms/_functional_video.py to _functional_video.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms/functional.py to functional.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/transforms/_transforms_video.py to _transforms_video.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/utils.py to utils.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/extension.py to extension.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/deform_conv.py to deform_conv.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/misc.py to misc.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/poolers.py to poolers.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/roi_align.py to roi_align.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/__init__.py to __init__.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/boxes.py to boxes.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/roi_pool.py to roi_pool.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/feature_pyramid_network.py to feature_pyramid_network.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/ps_roi_align.py to ps_roi_align.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/_register_onnx_ops.py to _register_onnx_ops.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/new_empty_tensor.py to new_empty_tensor.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/ps_roi_pool.py to ps_roi_pool.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/ops/_utils.py to _utils.cpython-38.pyc\r\ncreating stub loader for torchvision/_C.so\r\ncreating stub loader for torchvision/video_reader.so\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/_C.py to _C.cpython-38.pyc\r\nbyte-compiling build/bdist.macosx-10.9-x86_64/egg/torchvision/video_reader.py to video_reader.cpython-38.pyc\r\ncreating build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\r\ncopying torchvision.egg-info/PKG-INFO -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\r\ncopying torchvision.egg-info/SOURCES.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\r\ncopying torchvision.egg-info/dependency_links.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\r\ncopying torchvision.egg-info/not-zip-safe -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\r\ncopying torchvision.egg-info/requires.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\r\ncopying torchvision.egg-info/top_level.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\r\nwriting build/bdist.macosx-10.9-x86_64/egg/EGG-INFO/native_libs.txt\r\ncreating dist\r\ncreating 'dist/torchvision-0.7.0a0+e2e511b-py3.8-macosx-10.9-x86_64.egg' and adding 'build/bdist.macosx-10.9-x86_64/egg' to it\r\nremoving 'build/bdist.macosx-10.9-x86_64/egg' (and everything under it)\r\nProcessing torchvision-0.7.0a0+e2e511b-py3.8-macosx-10.9-x86_64.egg\r\ncreating /usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torchvision-0.7.0a0+e2e511b-py3.8-macosx-10.9-x86_64.egg\r\nExtracting torchvision-0.7.0a0+e2e511b-py3.8-macosx-10.9-x86_64.egg to /usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages\r\nAdding torchvision 0.7.0a0+e2e511b to easy-install.pth file\r\n\r\nInstalled /usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torchvision-0.7.0a0+e2e511b-py3.8-macosx-10.9-x86_64.egg\r\nProcessing dependencies for torchvision==0.7.0a0+e2e511b\r\nSearching for Pillow==7.1.2\r\nBest match: Pillow 7.1.2\r\nAdding Pillow 7.1.2 to easy-install.pth file\r\n\r\nUsing /usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages\r\nSearching for torch==1.4.0\r\nBest match: torch 1.4.0\r\nAdding torch 1.4.0 to easy-install.pth file\r\nInstalling convert-caffe2-to-onnx script to /usr/local/Caskroom/miniconda/base/envs/tv/bin\r\nInstalling convert-onnx-to-caffe2 script to /usr/local/Caskroom/miniconda/base/envs/tv/bin\r\n\r\nUsing /usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages\r\nSearching for numpy==1.18.4\r\nBest match: numpy 1.18.4\r\nAdding numpy 1.18.4 to easy-install.pth file\r\nInstalling f2py script to /usr/local/Caskroom/miniconda/base/envs/tv/bin\r\nInstalling f2py3 script to /usr/local/Caskroom/miniconda/base/envs/tv/bin\r\nInstalling f2py3.8 script to /usr/local/Caskroom/miniconda/base/envs/tv/bin\r\n\r\nUsing /usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages\r\nFinished processing dependencies for torchvision==0.7.0a0+e2e511b\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/private/tmp/vision/torchvision/__init__.py\", line 5, in <module>\r\n    from torchvision import models\r\n  File \"/private/tmp/vision/torchvision/models/__init__.py\", line 12, in <module>\r\n    from . import detection\r\n  File \"/private/tmp/vision/torchvision/models/detection/__init__.py\", line 1, in <module>\r\n    from .faster_rcnn import *\r\n  File \"/private/tmp/vision/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\r\n    from torchvision.ops import misc as misc_nn_ops\r\n  File \"/private/tmp/vision/torchvision/ops/__init__.py\", line 1, in <module>\r\n    from .boxes import nms, box_iou\r\n  File \"/private/tmp/vision/torchvision/ops/boxes.py\", line 8, in <module>\r\n    def nms(boxes, scores, iou_threshold):\r\n  File \"/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/jit/__init__.py\", line 1281, in script\r\n    fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj))\r\nRuntimeError:\r\nobject has no attribute nms:\r\n  File \"/private/tmp/vision/torchvision/ops/boxes.py\", line 41\r\n        by NMS, sorted in decreasing order of scores\r\n    \"\"\"\r\n    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\r\n           ~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\r\n```\r\n</p>\r\n</details>\r\n\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Environment\r\n\r\n```\r\nCollecting environment information...\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.15.4\r\nGCC version: Could not collect\r\nCMake version: version 3.17.2\r\n\r\nPython version: 3.8\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.18.4\r\n[pip] torch==1.4.0\r\n[pip] torchvision==0.7.0a0+e2e511b\r\n[conda] mkl                       2020.1                      216\r\n[conda] numpy                     1.18.4           py38h1f821a2_0    conda-forge\r\n[conda] pytorch                   1.4.0                   py3.8_0    pytorch\r\n[conda] torchvision               0.7.0a0+e2e511b          pypi_0    pypi\r\n```\r\n\r\n## Additional context\r\n\r\nRelated to #2220.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2223", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2223/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2223/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2223/events", "html_url": "https://github.com/pytorch/vision/issues/2223", "id": 619619951, "node_id": "MDU6SXNzdWU2MTk2MTk5NTE=", "number": 2223, "title": "Messy function lists printed in recent version.", "user": {"login": "xkszltl", "id": 5203025, "node_id": "MDQ6VXNlcjUyMDMwMjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/5203025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xkszltl", "html_url": "https://github.com/xkszltl", "followers_url": "https://api.github.com/users/xkszltl/followers", "following_url": "https://api.github.com/users/xkszltl/following{/other_user}", "gists_url": "https://api.github.com/users/xkszltl/gists{/gist_id}", "starred_url": "https://api.github.com/users/xkszltl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xkszltl/subscriptions", "organizations_url": "https://api.github.com/users/xkszltl/orgs", "repos_url": "https://api.github.com/users/xkszltl/repos", "events_url": "https://api.github.com/users/xkszltl/events{/privacy}", "received_events_url": "https://api.github.com/users/xkszltl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}, {"id": 1775338355, "node_id": "MDU6TGFiZWwxNzc1MzM4MzU1", "url": "https://api.github.com/repos/pytorch/vision/labels/torchscript", "name": "torchscript", "color": "17d180", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-17T06:11:06Z", "updated_at": "2020-05-28T19:11:58Z", "closed_at": "2020-05-28T19:11:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nWhen using the latest master of torchvision, we got a lot of \"lists of functions\" printed out everywhere.\r\nAnother version we used, from days to weeks earlier, was just fine.\r\n\r\nHere you can see a simple `import torchvision` will print out a lot of them.\r\n\r\n```\r\n# python3 -c 'import torchvision'\r\n[('__call__', <function LevelMapper.__call__ at 0x7f8853f21950>), ('__init__', <function LevelMapper.__init__ at 0x7f8853f218c8>)]\r\n[('__call__', <function BalancedPositiveNegativeSampler.__call__ at 0x7f8853e4a620>), ('__init__', <function BalancedPositiveNegativeSampler.__init__ at 0x7f8853e4a598>)]\r\n[('__init__', <function BoxCoder.__init__ at 0x7f8853e5fa60>), ('decode', <function BoxCoder.decode at 0x7f8853e5fbf8>), ('decode_single', <function BoxCoder.decode_single at 0x7f8853e5fc80>), ('encode', <function BoxCoder.encode at 0x7f8853e5fae8>), ('encode_single', <function BoxCoder.encode_single at 0x7f8853e5fb70>)]\r\n[('__call__', <function Matcher.__call__ at 0x7f8853e5f950>), ('__init__', <function Matcher.__init__ at 0x7f8853e5fd90>), ('set_low_quality_matches_', <function Matcher.set_low_quality_matches_ at 0x7f8853e5f9d8>)]\r\n[('__init__', <function ImageList.__init__ at 0x7f8853e5fea0>), ('to', <function ImageList.to at 0x7f8853e5ff28>)]\r\n[('__init__', <function Timebase.__init__ at 0x7f8852b8c8c8>)]\r\n[('__init__', <function VideoMetaData.__init__ at 0x7f8852b8ca60>)]\r\n```\r\n\r\nWhen used with Detectron2 (which calls torchvision internally), it gets even worse:\r\n<img width=\"1787\" alt=\"image\" src=\"https://user-images.githubusercontent.com/5203025/82137132-cf863300-9847-11ea-829a-312131e22681.png\">\r\n## Environment\r\n\r\n```\r\n# python3 ./collect_env.py \r\nCollecting environment information...\r\nPyTorch version: 1.6.0a0+ea42a37\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: Ubuntu 18.04.4 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.17.2\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.2.89\r\nGPU models and configuration: \r\nGPU 0: Tesla V100-SXM2-32GB\r\nGPU 1: Tesla V100-SXM2-32GB\r\nGPU 2: Tesla V100-SXM2-32GB\r\nGPU 3: Tesla V100-SXM2-32GB\r\nGPU 4: Tesla V100-SXM2-32GB\r\nGPU 5: Tesla V100-SXM2-32GB\r\nGPU 6: Tesla V100-SXM2-32GB\r\nGPU 7: Tesla V100-SXM2-32GB\r\n\r\nNvidia driver version: 440.33.01\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.4\r\n[pip3] torch==1.6.0a0+ea42a37\r\n[pip3] torchvision==0.7.0a0+a6073f0\r\n[conda] Could not collect\r\n```\r\n\r\n - PyTorch / torchvision Version (e.g., 1.0 / 0.4.0): master/master\r\n - OS (e.g., Linux): Ubuntu 18.04\r\n - How you installed PyTorch / torchvision (`conda`, `pip`, source): source/source\r\n - Build command you used (if compiling from source): cmake+ninja\r\n - Python version: 3.6.9 (distro stock version)\r\n - CUDA/cuDNN version: 10.2/7.6.5\r\n - GPU models and configuration: V100\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2221", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2221/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2221/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2221/events", "html_url": "https://github.com/pytorch/vision/issues/2221", "id": 619399748, "node_id": "MDU6SXNzdWU2MTkzOTk3NDg=", "number": 2221, "title": "DenseNet memory_efficient mode appears subtly broken since torchscript changes", "user": {"login": "rwightman", "id": 5702664, "node_id": "MDQ6VXNlcjU3MDI2NjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/5702664?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rwightman", "html_url": "https://github.com/rwightman", "followers_url": "https://api.github.com/users/rwightman/followers", "following_url": "https://api.github.com/users/rwightman/following{/other_user}", "gists_url": "https://api.github.com/users/rwightman/gists{/gist_id}", "starred_url": "https://api.github.com/users/rwightman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rwightman/subscriptions", "organizations_url": "https://api.github.com/users/rwightman/orgs", "repos_url": "https://api.github.com/users/rwightman/repos", "events_url": "https://api.github.com/users/rwightman/events{/privacy}", "received_events_url": "https://api.github.com/users/rwightman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1388460222, "node_id": "MDU6TGFiZWwxMzg4NDYwMjIy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20classification", "name": "topic: classification", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-16T07:07:41Z", "updated_at": "2020-05-21T16:54:27Z", "closed_at": "2020-05-21T16:54:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI was working with DenseNet recently, I noticed memory_efficient training was faster than with the flag disabled (unexpected), and it wasn't training very well at all, also errors from checkpoint fn about args not having required_grad=True set.\r\n\r\nI believe #1342 subtly broke the checkpointing by wraping inputs in an extra layer of container\r\n\r\ndensenet.py:53\r\n``` \r\n    def call_checkpoint_bottleneck(self, input):\r\n        # type: (List[Tensor]) -> Tensor\r\n        def closure(*inputs):\r\n            return self.bn_function(*inputs)\r\n\r\n        return cp.checkpoint(closure, input)\r\n```\r\n\r\nshould be\r\n\r\n```\r\n    def call_checkpoint_bottleneck(self, input):\r\n        # type: (List[Tensor]) -> Tensor\r\n        def closure(*inputs):\r\n            return self.bn_function(inputs)  # remove *\r\n\r\n        return cp.checkpoint(closure, *input)  # add *\r\n```\r\n## To Reproduce\r\n\r\nTrain any densenet network with `memory_efficient=True`\r\n\r\n## Expected behavior\r\n\r\n\r\n## Environment\r\n\r\nAny\r\n\r\n - PyTorch / torchvision Version (e.g., 1.0 / 0.4.0): 1.4\r\n - OS (e.g., Linux): any\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2220", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2220/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2220/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2220/events", "html_url": "https://github.com/pytorch/vision/issues/2220", "id": 619113655, "node_id": "MDU6SXNzdWU2MTkxMTM2NTU=", "number": 2220, "title": "Error building from source on macOS", "user": {"login": "fepegar", "id": 12688084, "node_id": "MDQ6VXNlcjEyNjg4MDg0", "avatar_url": "https://avatars1.githubusercontent.com/u/12688084?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fepegar", "html_url": "https://github.com/fepegar", "followers_url": "https://api.github.com/users/fepegar/followers", "following_url": "https://api.github.com/users/fepegar/following{/other_user}", "gists_url": "https://api.github.com/users/fepegar/gists{/gist_id}", "starred_url": "https://api.github.com/users/fepegar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fepegar/subscriptions", "organizations_url": "https://api.github.com/users/fepegar/orgs", "repos_url": "https://api.github.com/users/fepegar/repos", "events_url": "https://api.github.com/users/fepegar/events{/privacy}", "received_events_url": "https://api.github.com/users/fepegar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-05-15T16:58:03Z", "updated_at": "2020-05-18T14:43:28Z", "closed_at": "2020-05-18T13:45:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nI can't build `torchvision` from source. I get the following error in the log:\r\n```\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:258:26: error: implicit instantiation of undefined template 'std::__1::array<char, 1024>'\r\n  std::array<char, 1024> buffer;\r\n```\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```cpp\r\n$ conda create -n tv python -y && conda activate tv\r\n$ git clone --depth 1 git@github.com:pytorch/vision.git\r\n$ cd vision\r\n$ MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py install\r\n```\r\n\r\n<details><summary>Output</summary>\r\n<p>\r\n\r\n```shell\r\nBuilding wheel torchvision-0.7.0a0+348dd5a\r\nrunning install\r\nrunning bdist_egg\r\nrunning egg_info\r\ncreating torchvision.egg-info\r\nwriting torchvision.egg-info/PKG-INFO\r\nwriting dependency_links to torchvision.egg-info/dependency_links.txt\r\nwriting requirements to torchvision.egg-info/requires.txt\r\nwriting top-level names to torchvision.egg-info/top_level.txt\r\nwriting manifest file 'torchvision.egg-info/SOURCES.txt'\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/utils/cpp_extension.py:304: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\r\n  warnings.warn(msg.format('we could not find ninja.'))\r\nreading manifest file 'torchvision.egg-info/SOURCES.txt'\r\nreading manifest template 'MANIFEST.in'\r\nwarning: no previously-included files matching '__pycache__' found under directory '*'\r\nwarning: no previously-included files matching '*.py[co]' found under directory '*'\r\nwriting manifest file 'torchvision.egg-info/SOURCES.txt'\r\ninstalling library code to build/bdist.macosx-10.9-x86_64/egg\r\nrunning install_lib\r\nrunning build_py\r\ncreating build\r\ncreating build/lib.macosx-10.9-x86_64-3.8\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncopying torchvision/version.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncopying torchvision/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncopying torchvision/utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncopying torchvision/extension.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/flickr.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/coco.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/cityscapes.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/video_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/vision.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/stl10.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/lsun.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/usps.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/folder.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/imagenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/sbd.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/ucf101.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/svhn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/celeba.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/semeion.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/cifar.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/voc.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/hmdb51.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/sbu.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/caltech.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/fakedata.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/kinetics.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/phototour.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/mnist.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncopying torchvision/datasets/omniglot.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/io\r\ncopying torchvision/io/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/io\r\ncopying torchvision/io/_video_opt.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/io\r\ncopying torchvision/io/video.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/io\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/shufflenetv2.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/googlenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/mnasnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/vgg.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/squeezenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/densenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/inception.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/mobilenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/resnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/alexnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncopying torchvision/models/_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/functional_tensor.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/transforms.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/_functional_video.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/functional.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncopying torchvision/transforms/_transforms_video.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/transforms\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/deform_conv.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/misc.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/poolers.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/roi_align.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/boxes.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/roi_pool.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/feature_pyramid_network.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/ps_roi_align.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/_register_onnx_ops.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/new_empty_tensor.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/ps_roi_pool.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncopying torchvision/ops/_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/ops\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/samplers\r\ncopying torchvision/datasets/samplers/clip_sampler.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/samplers\r\ncopying torchvision/datasets/samplers/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/datasets/samplers\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models/video\r\ncopying torchvision/models/video/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/video\r\ncopying torchvision/models/video/resnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/video\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/fcn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/deeplabv3.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncopying torchvision/models/segmentation/segmentation.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/segmentation\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/shufflenetv2.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/googlenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/inception.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/mobilenet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/resnet.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncopying torchvision/models/quantization/utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/quantization\r\ncreating build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/rpn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/faster_rcnn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/generalized_rcnn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/backbone_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/transform.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/mask_rcnn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/image_list.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/keypoint_rcnn.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/roi_heads.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\ncopying torchvision/models/detection/_utils.py -> build/lib.macosx-10.9-x86_64-3.8/torchvision/models/detection\r\nrunning build_ext\r\nbuilding 'torchvision._C' extension\r\ncreating build/temp.macosx-10.9-x86_64-3.8\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/vision.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/DeformConv_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/DeformConv_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/ROIAlign_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/ROIPool_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/ROIPool_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/PSROIPool_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/PSROIPool_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/PSROIAlign_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/PSROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/nms_cpu.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\r\nclang++ -bundle -undefined dynamic_lookup -L/usr/local/Caskroom/miniconda/base/envs/tv/lib -arch x86_64 -L/usr/local/Caskroom/miniconda/base/envs/tv/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/vision.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/DeformConv_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/ROIAlign_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/ROIPool_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/PSROIPool_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/PSROIAlign_cpu.o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/nms_cpu.o -L/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.macosx-10.9-x86_64-3.8/torchvision/_C.so\r\nbuilding 'torchvision.video_reader' extension\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/video_reader\r\ncreating build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:95:3: warning: comparison of integers of different signs: 'int64_t' (aka 'long long') and\r\n      'std::__1::vector<ffmpeg::DecoderOutputMessage, std::__1::allocator<ffmpeg::DecoderOutputMessage> >::size_type' (aka 'unsigned long') [-Wsign-compare]\r\n  CHECK_EQ(framePts.size(0), msgs.size());\r\n  ^        ~~~~~~~~~~~~~~~~  ~~~~~~~~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:133:51: note: expanded from macro 'CHECK_EQ'\r\n#define CHECK_EQ(val1, val2) CHECK_OP(val1, val2, ==)\r\n                                      ~~~~  ~~~~  ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:128:20: note: expanded from macro 'CHECK_OP'\r\n  FATAL_IF(((val1) op (val2)))                        \\\r\n             ~~~~  ^   ~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:110:3: note: expanded from macro 'FATAL_IF'\r\n  condition ? (void)0                  \\\r\n  ^~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:590:17: warning: unused variable 'media' [-Wunused-variable]\r\n    const auto& media = header.format;\r\n                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:95:3: warning: comparison of integers of different signs: 'int64_t' (aka 'long long') and\r\n      'std::__1::vector<ffmpeg::DecoderOutputMessage, std::__1::allocator<ffmpeg::DecoderOutputMessage> >::size_type' (aka 'unsigned long') [-Wsign-compare]\r\n  CHECK_EQ(framePts.size(0), msgs.size());\r\n  ^        ~~~~~~~~~~~~~~~~  ~~~~~~~~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:133:51: note: expanded from macro 'CHECK_EQ'\r\n#define CHECK_EQ(val1, val2) CHECK_OP(val1, val2, ==)\r\n                                      ~~~~  ~~~~  ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:128:20: note: expanded from macro 'CHECK_OP'\r\n  FATAL_IF(((val1) op (val2)))                        \\\r\n             ~~~~  ^   ~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:110:3: note: expanded from macro 'FATAL_IF'\r\n  condition ? (void)0                  \\\r\n  ^~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:128:10: note: in instantiation of function template specialization 'video_reader::fillTensor<unsigned char>'\r\n      requested here\r\n  return fillTensor<uint8_t>(msgs, videoFrame, videoFramePts, num, den);\r\n         ^\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:95:3: warning: comparison of integers of different signs: 'int64_t' (aka 'long long') and\r\n      'std::__1::vector<ffmpeg::DecoderOutputMessage, std::__1::allocator<ffmpeg::DecoderOutputMessage> >::size_type' (aka 'unsigned long') [-Wsign-compare]\r\n  CHECK_EQ(framePts.size(0), msgs.size());\r\n  ^        ~~~~~~~~~~~~~~~~  ~~~~~~~~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:133:51: note: expanded from macro 'CHECK_EQ'\r\n#define CHECK_EQ(val1, val2) CHECK_OP(val1, val2, ==)\r\n                                      ~~~~  ~~~~  ^\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:128:20: note: expanded from macro 'CHECK_OP'\r\n  FATAL_IF(((val1) op (val2)))                        \\\r\n             ~~~~  ^   ~~~~\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/c10/util/logging_is_not_google_glog.h:110:3: note: expanded from macro 'FATAL_IF'\r\n  condition ? (void)0                  \\\r\n  ^~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/video_reader/VideoReader.cpp:137:10: note: in instantiation of function template specialization 'video_reader::fillTensor<float>' requested\r\n      here\r\n  return fillTensor<float>(msgs, audioFrame, audioFramePts, num, den);\r\n         ^\r\n4 warnings generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:69:24: warning: comparison of integers of different signs: 'long' and 'size_t' (aka 'unsigned long')\r\n      [-Wsign-compare]\r\n  while (!eof_ && end_ < maxBytes && (hasTime = watcher())) {\r\n                  ~~~~ ^ ~~~~~~~~\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/seekable_buffer.cpp:74:16: warning: comparison of integers of different signs: 'long' and 'std::__1::vector<unsigned char,\r\n      std::__1::allocator<unsigned char> >::size_type' (aka 'unsigned long') [-Wsign-compare]\r\n      if (end_ == buffer_.size()) {\r\n          ~~~~ ^  ~~~~~~~~~~~~~~\r\n2 warnings generated.\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/cc_stream.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/cc_stream.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/usr/local/Caskroom/miniconda/base/envs/tv/include -arch x86_64 -I/private/tmp/vision/torchvision/csrc/cpu/decoder -I/private/tmp/vision/torchvision/csrc/cpu/video_reader -I/usr/local/include -I/private/tmp/vision/torchvision/csrc -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/TH -I/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torch/include/THC -I/usr/local/Caskroom/miniconda/base/envs/tv/include/python3.8 -c /private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp -o build/temp.macosx-10.9-x86_64-3.8/private/tmp/vision/torchvision/csrc/cpu/decoder/util.o -std=c++14 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=video_reader -D_GLIBCXX_USE_CXX11_ABI=0\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:52:25: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          s += sizeof(y.pict.linesize[i]);\r\n                        ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:52:30: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          s += sizeof(y.pict.linesize[i]);\r\n                             ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:53:18: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          s += y.pict.linesize[i];\r\n                 ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:53:23: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          s += y.pict.linesize[i];\r\n                      ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:96:41: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          if (!serializeItem(d, l, p, x.pict.linesize[i])) {\r\n                                        ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:96:46: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          if (!serializeItem(d, l, p, x.pict.linesize[i])) {\r\n                                             ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:99:21: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          if (p + x.pict.linesize[i] > l) {\r\n                    ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:99:26: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          if (p + x.pict.linesize[i] > l) {\r\n                         ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:102:27: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(d + p, x.pict.data[i], x.pict.linesize[i]);\r\n                          ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:102:32: warning: 'data' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(d + p, x.pict.data[i], x.pict.linesize[i]);\r\n                               ^\r\n/usr/local/include/libavcodec/avcodec.h:3867:5: note: 'data' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:102:43: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(d + p, x.pict.data[i], x.pict.linesize[i]);\r\n                                          ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:102:48: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(d + p, x.pict.data[i], x.pict.linesize[i]);\r\n                                               ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:103:18: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          p += x.pict.linesize[i];\r\n                 ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:103:23: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          p += x.pict.linesize[i];\r\n                      ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:175:43: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          if (!deserializeItem(y, l, p, x.pict.linesize[i])) {\r\n                                          ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:175:48: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          if (!deserializeItem(y, l, p, x.pict.linesize[i])) {\r\n                                               ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:178:21: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          if (p + x.pict.linesize[i] > l) {\r\n                    ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:178:26: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          if (p + x.pict.linesize[i] > l) {\r\n                         ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:181:13: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          x.pict.data[i] = (uint8_t*)av_malloc(x.pict.linesize[i]);\r\n            ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:181:18: warning: 'data' is deprecated [-Wdeprecated-declarations]\r\n          x.pict.data[i] = (uint8_t*)av_malloc(x.pict.linesize[i]);\r\n                 ^\r\n/usr/local/include/libavcodec/avcodec.h:3867:5: note: 'data' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:181:50: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          x.pict.data[i] = (uint8_t*)av_malloc(x.pict.linesize[i]);\r\n                                                 ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:181:55: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          x.pict.data[i] = (uint8_t*)av_malloc(x.pict.linesize[i]);\r\n                                                      ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:182:20: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(x.pict.data[i], y + p, x.pict.linesize[i]);\r\n                   ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:182:25: warning: 'data' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(x.pict.data[i], y + p, x.pict.linesize[i]);\r\n                        ^\r\n/usr/local/include/libavcodec/avcodec.h:3867:5: note: 'data' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:182:43: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(x.pict.data[i], y + p, x.pict.linesize[i]);\r\n                                          ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:182:48: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          memcpy(x.pict.data[i], y + p, x.pict.linesize[i]);\r\n                                               ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:183:18: warning: 'pict' is deprecated [-Wdeprecated-declarations]\r\n          p += x.pict.linesize[i];\r\n                 ^\r\n/usr/local/include/libavcodec/avcodec.h:3909:5: note: 'pict' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:183:23: warning: 'linesize' is deprecated [-Wdeprecated-declarations]\r\n          p += x.pict.linesize[i];\r\n                      ^\r\n/usr/local/include/libavcodec/avcodec.h:3869:5: note: 'linesize' has been explicitly marked deprecated here\r\n    attribute_deprecated\r\n    ^\r\n/usr/local/include/libavutil/attributes.h:94:49: note: expanded from macro 'attribute_deprecated'\r\n#    define attribute_deprecated __attribute__((deprecated))\r\n                                                ^\r\n/private/tmp/vision/torchvision/csrc/cpu/decoder/util.cpp:258:26: error: implicit instantiation of undefined template 'std::__1::array<char, 1024>'\r\n  std::array<char, 1024> buffer;\r\n                         ^\r\n/Library/Developer/CommandLineTools/usr/bin/../include/c++/v1/__tuple:219:64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^\r\n28 warnings and 1 error generated.\r\nerror: command 'clang' failed with exit status 1\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nSuccessful build.\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.5.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.15.4\r\nGCC version: Could not collect\r\nCMake version: version 3.17.2\r\n\r\nPython version: 3.8\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.18.4\r\n[pip] torch==1.5.0\r\n[conda] numpy                     1.18.4                   pypi_0    pypi\r\n[conda] torch                     1.5.0                    pypi_0    pypi\r\n```\r\n\r\n## Additional context\r\n```\r\n$  clang --version                                                                                               \r\nApple clang version 11.0.3 (clang-1103.0.32.59)\r\nTarget: x86_64-apple-darwin19.4.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n```\r\n<!-- Add any other context about the problem here. -->\r\n\r\nI'm building from source to try the `video_reader` backend: https://github.com/pytorch/vision/issues/2216#issuecomment-629287081.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2219", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2219/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2219/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2219/events", "html_url": "https://github.com/pytorch/vision/issues/2219", "id": 619096452, "node_id": "MDU6SXNzdWU2MTkwOTY0NTI=", "number": 2219, "title": "FasterRCNN Bounding box error", "user": {"login": "chkda", "id": 38988746, "node_id": "MDQ6VXNlcjM4OTg4NzQ2", "avatar_url": "https://avatars2.githubusercontent.com/u/38988746?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chkda", "html_url": "https://github.com/chkda", "followers_url": "https://api.github.com/users/chkda/followers", "following_url": "https://api.github.com/users/chkda/following{/other_user}", "gists_url": "https://api.github.com/users/chkda/gists{/gist_id}", "starred_url": "https://api.github.com/users/chkda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chkda/subscriptions", "organizations_url": "https://api.github.com/users/chkda/orgs", "repos_url": "https://api.github.com/users/chkda/repos", "events_url": "https://api.github.com/users/chkda/events{/privacy}", "received_events_url": "https://api.github.com/users/chkda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-15T16:28:04Z", "updated_at": "2020-05-19T09:32:29Z", "closed_at": "2020-05-19T09:32:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI am using a model for Faster RCNN `torchvision.models.detection`.  The problem is the value of the target bounding boxes keeps getting altered  The operation being performed is just a simple forward pass where loss is being evaluated.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nclass CustomDataset(torch.utils.data.Dataset):\r\n\r\n    def __init__(self,xtr,ytr):\r\n\r\n        self.xtr = xtr\r\n        self.ytr = ytr\r\n\r\n    def __getitem__(self,idx):\r\n\r\n        img = self.xtr[idx]\r\n        tar = self.ytr[idx]\r\n\r\n        return img,tar\r\n\r\n    def __len__(self):\r\n\r\n        return len(self.xtr)\r\n    \r\ndef collate_fn(batch):\r\n    return list(zip(*batch))\r\n\r\ndef from_numpy_to_tensor(images,labels_list):\r\n\r\n    images = torch.from_numpy(images).cuda()\r\n    for label in labels_list:\r\n        label[\"boxes\"] = torch.from_numpy(label[\"boxes\"]).cuda()\r\n        label[\"labels\"] = torch.from_numpy(label[\"labels\"]).cuda()\r\n\r\n    return images,labels_list\r\n\r\n\r\n\r\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False,num_classes=4)\r\nmodel.to(device)\r\noptimizer = optim.Adam(model.parameters(),lr=0.000001)\r\n\r\n## trying with one image only\r\nx_train = images[0:1]   \r\ny_train = labels[0:1]\r\n\r\n## Converts numpy to TorchCudaFloat \r\nx_train,y_train = from_numpy_to_tensor(x_train,y_train)\r\n\r\n## DataLoader object \r\ndataset = CustomDataset(x_train,y_train)\r\ndataloader = DataLoader(dataset,batch_size=1,collate_fn=collate_fn)\r\n\r\n\r\n## Iterations\r\nfor i in range(20):\r\n    print(\"Iter No:\",i)\r\n    for xtr,ytr in dataloader:\r\n        ytr = list(ytr)\r\n        print(ytr)\r\n        output = model(xtr,ytr)\r\n\r\n```\r\nThis is what my labels tensor looks like at the start of the iteration\r\n```\r\n[{'boxes': tensor([[ 311.9933, 1013.7640,  719.6339, 1142.7417],\r\n        [ 308.1646,  928.4176,  739.4443,  961.6580],\r\n        [ 308.7562,  830.7968,  740.0359,  864.0373],\r\n        [ 305.8657,  680.8315,  763.0424,  708.1243],\r\n        [ 300.3259,  439.0691,  790.4506,  523.2395],\r\n        [ 306.6932,  248.2031,  741.7596,  458.5648]], device='cuda:0'), 'labels': tensor([4, 3, 3, 3, 2, 1], device='cuda:0')}]\r\n```\r\nBy the end of the 20th iteration the target becomes something like this\r\n```\r\n[{'boxes': tensor([[117.7318, 383.4572, 271.5563, 432.2433],\r\n        [116.2870, 351.1749, 279.0319, 363.7481],\r\n        [116.5102, 314.2498, 279.2552, 326.8230],\r\n        [115.4195, 257.5252, 287.9367, 267.8488],\r\n        [113.3290, 166.0784, 298.2794, 197.9159],\r\n        [115.7318,  93.8831, 279.9056, 173.4527]], device='cuda:0'), 'labels': tensor([4, 3, 3, 3, 2, 1], device='cuda:0')}]\r\n```\r\nAs you can see the targets are getting altered by huge margins in just 20 iterations. \r\n\r\nThere is a workaround for the problem. The following code snippet works fine. It doesn't alter the bounding box values.\r\n```\r\nfor i in range(20):\r\n    print(\"Iter No:\",i)\r\n    for xtr,ytr in dataloader:\r\n        y_tr = [{k:v for k,v in t.items()} for t in ytr]\r\n        output = model(xtr,y_tr)\r\n        print(ytr)\r\n```\r\n\r\nIn the `images ` variable you can take a batch size of 1 image  with the size (1280,842,3) and `labels` value is the one that is specified above. \r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n## Expected behavior\r\n\r\nThe ideal behaviour would be for the values of target boxes to remain unaltered.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n## Environment\r\n\r\n```\r\nPyTorch version: 1.5.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\nCMake version: Could not collect\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.243\r\nGPU models and configuration: \r\nGPU 0: Tesla K80\r\nGPU 1: Tesla K80\r\nGPU 2: Tesla K80\r\nGPU 3: Tesla K80\r\nGPU 4: Tesla K80\r\nGPU 5: Tesla K80\r\nGPU 6: Tesla K80\r\nGPU 7: Tesla K80\r\n\r\nNvidia driver version: 418.87.01\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.18.1\r\n[pip] torch==1.5.0\r\n[pip] torchvision==0.6.0a0+82fd1c8\r\n[conda] blas                      1.0                         mkl  \r\n[conda] cudatoolkit               10.1.243             h6bb024c_0  \r\n[conda] mkl                       2020.0                      166  \r\n[conda] mkl-service               2.3.0            py37he904b0f_0  \r\n[conda] mkl_fft                   1.0.15           py37ha843d7b_0  \r\n[conda] mkl_random                1.1.0            py37hd6b4f25_0  \r\n[conda] numpy                     1.18.1           py37h4f9e942_0  \r\n[conda] numpy-base                1.18.1           py37hde5b4d6_1  \r\n[conda] pytorch                   1.5.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\r\n[conda] torchvision               0.6.0                py37_cu101    pytorch\r\n\r\n```\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2216", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2216/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2216/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2216/events", "html_url": "https://github.com/pytorch/vision/issues/2216", "id": 618446940, "node_id": "MDU6SXNzdWU2MTg0NDY5NDA=", "number": 2216, "title": "UserWarning: video_reader video backend is not available", "user": {"login": "fepegar", "id": 12688084, "node_id": "MDQ6VXNlcjEyNjg4MDg0", "avatar_url": "https://avatars1.githubusercontent.com/u/12688084?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fepegar", "html_url": "https://github.com/fepegar", "followers_url": "https://api.github.com/users/fepegar/followers", "following_url": "https://api.github.com/users/fepegar/following{/other_user}", "gists_url": "https://api.github.com/users/fepegar/gists{/gist_id}", "starred_url": "https://api.github.com/users/fepegar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fepegar/subscriptions", "organizations_url": "https://api.github.com/users/fepegar/orgs", "repos_url": "https://api.github.com/users/fepegar/repos", "events_url": "https://api.github.com/users/fepegar/events{/privacy}", "received_events_url": "https://api.github.com/users/fepegar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1447973685, "node_id": "MDU6TGFiZWwxNDQ3OTczNjg1", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20io", "name": "module: io", "color": "f7e101", "default": false, "description": ""}, {"id": 1588820772, "node_id": "MDU6TGFiZWwxNTg4ODIwNzcy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20binaries", "name": "topic: binaries", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-05-14T18:28:05Z", "updated_at": "2020-07-24T22:37:50Z", "closed_at": "2020-05-15T12:53:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nI get a \"`video_reader` video backend is not available\" warning when trying to set it.\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```shell\r\n$ conda create -n tv python -y && conda activate tv\r\n$ pip install numpy                                                                                               \r\n$ pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\r\n$ python -c \"import torchvision; torchvision.set_video_backend('video_reader')\"\r\n````\r\n\r\nOutput:\r\n\r\n```python-traceback\r\n[('__call__', <function LevelMapper.__call__ at 0x123462820>), ('__init__', <function LevelMapper.__init__ at 0x123462790>)]\r\n[('__call__', <function BalancedPositiveNegativeSampler.__call__ at 0x123649280>), ('__init__', <function BalancedPositiveNegativeSampler.__init__ at 0x1236491f0>)]\r\n[('__init__', <function BoxCoder.__init__ at 0x123657af0>), ('decode', <function BoxCoder.decode at 0x123657ca0>), ('decode_single', <function BoxCoder.decode_single at 0x123657d30>), ('encode', <function BoxCoder.encode at 0x123657b80>), ('encode_single', <function BoxCoder.encode_single at 0x123657c10>)]\r\n[('__call__', <function Matcher.__call__ at 0x1234628b0>), ('__init__', <function Matcher.__init__ at 0x123649160>), ('set_low_quality_matches_', <function Matcher.set_low_quality_matches_ at 0x123462700>)]\r\n[('__init__', <function ImageList.__init__ at 0x123657e50>), ('to', <function ImageList.to at 0x123657a60>)]\r\n[('__init__', <function Timebase.__init__ at 0x123b8cca0>)]\r\n[('__init__', <function VideoMetaData.__init__ at 0x123b8ce50>)]\r\n/usr/local/Caskroom/miniconda/base/envs/tv/lib/python3.8/site-packages/torchvision/__init__.py:65: UserWarning: video_reader video backend is not available\r\n  warnings.warn(\"video_reader video backend is not available\")\r\n```\r\n\r\nI'm using the nightly version because I hoped this would be fixed in #2183.\r\n\r\nI get only the warning (i.e. last two lines) in the stable pip release.\r\n\r\n## Expected behavior\r\n\r\nNo warning when I set the backend.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.6.0.dev20200514\r\nIs debug build: No\r\nCUDA used to build PyTorch: None\r\n\r\nOS: Mac OSX 10.15.4\r\nGCC version: Could not collect\r\nCMake version: version 3.17.2\r\n\r\nPython version: 3.8\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.18.4\r\n[pip] torch==1.6.0.dev20200514\r\n[pip] torchvision==0.7.0.dev20200514\r\n[conda] numpy                     1.18.4                   pypi_0    pypi\r\n[conda] torch                     1.6.0.dev20200514          pypi_0    pypi\r\n[conda] torchvision               0.7.0.dev20200514          pypi_0    pypi\r\n\r\n## Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\nDiscovered when I tried following @bjuncek advice in #1884.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2214", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2214/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2214/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2214/events", "html_url": "https://github.com/pytorch/vision/issues/2214", "id": 618167205, "node_id": "MDU6SXNzdWU2MTgxNjcyMDU=", "number": 2214, "title": "linux build error:  error: calling a constexpr __host__ function(\"ceil_div\") from a __global__ function(\"nms_kernel\") is not allowed.", "user": {"login": "qizhen816", "id": 18132150, "node_id": "MDQ6VXNlcjE4MTMyMTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/18132150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qizhen816", "html_url": "https://github.com/qizhen816", "followers_url": "https://api.github.com/users/qizhen816/followers", "following_url": "https://api.github.com/users/qizhen816/following{/other_user}", "gists_url": "https://api.github.com/users/qizhen816/gists{/gist_id}", "starred_url": "https://api.github.com/users/qizhen816/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qizhen816/subscriptions", "organizations_url": "https://api.github.com/users/qizhen816/orgs", "repos_url": "https://api.github.com/users/qizhen816/repos", "events_url": "https://api.github.com/users/qizhen816/events{/privacy}", "received_events_url": "https://api.github.com/users/qizhen816/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}, {"id": 1385340512, "node_id": "MDU6TGFiZWwxMzg1MzQwNTEy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20build", "name": "topic: build", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-14T11:52:44Z", "updated_at": "2020-05-14T22:16:16Z", "closed_at": "2020-05-14T22:16:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I build the latest torchvision with cuda 9.2, errors occur:\r\n```\r\n-- Caffe2: CUDA detected: 9.2\r\n-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\r\n-- Caffe2: CUDA toolkit directory: /usr/local/cuda\r\n-- Caffe2: Header version is: 9.2\r\n-- Found cuDNN: v7.6.3  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\r\n-- Autodetected CUDA architecture(s):  6.1 6.1 6.1 6.1\r\n-- Added CUDA NVCC flags for: -gencode;arch=compute_61,code=sm_61\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /mnt/cxx_restful/vision/build\r\n[  4%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/inception.cpp.o\r\n[  8%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/mnasnet.cpp.o\r\n[ 12%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/mobilenet.cpp.o\r\n[ 16%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/resnet.cpp.o\r\n[ 20%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/shufflenetv2.cpp.o\r\n[ 25%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/squeezenet.cpp.o\r\n[ 29%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/models/vgg.cpp.o\r\n[ 33%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/DeformConv_cpu.cpp.o\r\n[ 37%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/PSROIAlign_cpu.cpp.o\r\n[ 41%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/PSROIPool_cpu.cpp.o\r\n[ 45%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/ROIAlign_cpu.cpp.o\r\n[ 50%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/ROIPool_cpu.cpp.o\r\n[ 54%] Building CXX object CMakeFiles/torchvision.dir/torchvision/csrc/cpu/nms_cpu.cpp.o\r\n[ 58%] Building CUDA object CMakeFiles/torchvision.dir/torchvision/csrc/cuda/DeformConv_cuda.cu.o\r\n[ 62%] Building CUDA object CMakeFiles/torchvision.dir/torchvision/csrc/cuda/PSROIAlign_cuda.cu.o\r\n[ 66%] Building CUDA object CMakeFiles/torchvision.dir/torchvision/csrc/cuda/PSROIPool_cuda.cu.o\r\n[ 70%] Building CUDA object CMakeFiles/torchvision.dir/torchvision/csrc/cuda/ROIAlign_cuda.cu.o\r\n[ 75%] Building CUDA object CMakeFiles/torchvision.dir/torchvision/csrc/cuda/ROIPool_cuda.cu.o\r\n[ 79%] Building CUDA object CMakeFiles/torchvision.dir/torchvision/csrc/cuda/nms_cuda.cu.o\r\n/mnt/cxx_restful/vision/torchvision/csrc/cuda/nms_cuda.cu(66): error: calling a constexpr __host__ function(\"ceil_div\") from a __global__ function(\"nms_kernel\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n1 error detected in the compilation of \"/tmp/tmpxft_00008508_00000000-6_nms_cuda.cpp1.ii\".\r\nCMakeFiles/torchvision.dir/build.make:338: recipe for target 'CMakeFiles/torchvision.dir/torchvision/csrc/cuda/nms_cuda.cu.o' failed\r\nmake[2]: *** [CMakeFiles/torchvision.dir/torchvision/csrc/cuda/nms_cuda.cu.o] Error 1\r\nCMakeFiles/Makefile2:78: recipe for target 'CMakeFiles/torchvision.dir/all' failed\r\nmake[1]: *** [CMakeFiles/torchvision.dir/all] Error 2\r\nMakefile:132: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n```\r\nI checked `cuda.cmake` in libtorch and there is `list(APPEND CUDA_NVCC_FLAGS \"--expt-relaxed-constexpr\")`, apparently it didn't work. Any clue how to fix this?\r\n[CMakeLists.txt](https://github.com/pytorch/vision/files/4628070/CMakeLists.txt)\r\n \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2212", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2212/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2212/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2212/events", "html_url": "https://github.com/pytorch/vision/issues/2212", "id": 617974832, "node_id": "MDU6SXNzdWU2MTc5NzQ4MzI=", "number": 2212, "title": "TypeError when using transforms in inbuilt datasets ", "user": {"login": "SumitBamal", "id": 49608245, "node_id": "MDQ6VXNlcjQ5NjA4MjQ1", "avatar_url": "https://avatars3.githubusercontent.com/u/49608245?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SumitBamal", "html_url": "https://github.com/SumitBamal", "followers_url": "https://api.github.com/users/SumitBamal/followers", "following_url": "https://api.github.com/users/SumitBamal/following{/other_user}", "gists_url": "https://api.github.com/users/SumitBamal/gists{/gist_id}", "starred_url": "https://api.github.com/users/SumitBamal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SumitBamal/subscriptions", "organizations_url": "https://api.github.com/users/SumitBamal/orgs", "repos_url": "https://api.github.com/users/SumitBamal/repos", "events_url": "https://api.github.com/users/SumitBamal/events{/privacy}", "received_events_url": "https://api.github.com/users/SumitBamal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 684873012, "node_id": "MDU6TGFiZWw2ODQ4NzMwMTI=", "url": "https://api.github.com/repos/pytorch/vision/labels/awaiting%20response", "name": "awaiting response", "color": "5319e7", "default": false, "description": null}, {"id": 1373818954, "node_id": "MDU6TGFiZWwxMzczODE4OTU0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20transforms", "name": "module: transforms", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-14T06:57:25Z", "updated_at": "2020-05-15T07:17:00Z", "closed_at": "2020-05-15T07:17:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "I made a `torchvision.datasets` dataloader for `torchvision.datasets.SBDataset` :\r\n```\r\nsbd_data = torchvision.datasets.SBDataset('./',transforms = data_transforms['train'],download=False)\r\ndata_loader = torch.utils.data.DataLoader(sbd_data,\r\n                                          batch_size=4,\r\n                                          shuffle=True,\r\n                                          num_workers=4)\r\n```\r\nHere the `data_transforms['train']` is a `transforms.Compose` instance.\r\nAnd to show a batch i used this function : \r\n```\r\ndef imshow(inp, title=None):\r\n    \"\"\"Imshow for Tensor.\"\"\"\r\n    inp = inp.numpy().transpose((1, 2, 0))\r\n    inp = np.clip(inp, 0, 1)\r\n    plt.imshow(inp)\r\n    if title is not None:\r\n        plt.title(title)\r\n    plt.pause(0.001)  # pause a bit so that plots are updated\r\n```\r\nNow when i try to call this function as\r\n```\r\ninputs,_ = next(iter(data_loader))\r\nout = torchvision.utils.make_grid(inputs)\r\nimshow(out)\r\n```\r\nI get the following error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-21-6753e8965891> in <module>\r\n     13 \r\n     14 # Get a batch of training data\r\n---> 15 inputs,_ = next(iter(data_loader))\r\n     16 # Make a grid from batch\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py in __next__(self)\r\n    817             else:\r\n    818                 del self.task_info[idx]\r\n--> 819                 return self._process_data(data)\r\n    820 \r\n    821     next = __next__  # Python 2 compatibility\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py in _process_data(self, data)\r\n    844         self._try_put_index()\r\n    845         if isinstance(data, ExceptionWrapper):\r\n--> 846             data.reraise()\r\n    847         return data\r\n    848 \r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/_utils.py in reraise(self)\r\n    367             # (https://bugs.python.org/issue2651), so we work around it.\r\n    368             msg = KeyErrorMessage(msg)\r\n--> 369         raise self.exc_type(msg)\r\n\r\nTypeError: Caught TypeError in DataLoader worker process 0.\r\nOriginal Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\r\n    data = fetcher.fetch(index)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\r\n    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/datasets/sbd.py\", line 115, in __getitem__\r\n    img, target = self.transforms(img, target)\r\nTypeError: __call__() takes 2 positional arguments but 3 were given\r\n```\r\n\r\nI read the [sbd.py][1] for `SBDataset` class which inherits from `VisionDataset` which clearly implements a `StandardTransform` class, which is only used when inputs `transform` and `target_transform` are both provided, does it assume the `transforms` to be an instance of `StandardTransform`? Is this intentional? Is there a neat way to solve this?\r\nbecause the `StandardTransform` is not present in the docs.\r\nNote the `transform` and `transforms` difference.\r\nThe `transform.Compose` class clearly doesn't support two inputs ie `inputs , targets`.\r\n\r\nI could have just worked with `transform` but this class(`SBDataset`) only has `transforms` as an argument.\r\n\r\npytorch version : 1.2.0.dev20190805\r\n\r\n  [1]: https://github.com/pytorch/vision/blob/master/torchvision/datasets/sbd.py", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2209", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2209/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2209/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2209/events", "html_url": "https://github.com/pytorch/vision/issues/2209", "id": 617407263, "node_id": "MDU6SXNzdWU2MTc0MDcyNjM=", "number": 2209, "title": "Resize argument", "user": {"login": "leoshine", "id": 10215056, "node_id": "MDQ6VXNlcjEwMjE1MDU2", "avatar_url": "https://avatars2.githubusercontent.com/u/10215056?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leoshine", "html_url": "https://github.com/leoshine", "followers_url": "https://api.github.com/users/leoshine/followers", "following_url": "https://api.github.com/users/leoshine/following{/other_user}", "gists_url": "https://api.github.com/users/leoshine/gists{/gist_id}", "starred_url": "https://api.github.com/users/leoshine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leoshine/subscriptions", "organizations_url": "https://api.github.com/users/leoshine/orgs", "repos_url": "https://api.github.com/users/leoshine/repos", "events_url": "https://api.github.com/users/leoshine/events{/privacy}", "received_events_url": "https://api.github.com/users/leoshine/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-13T12:29:41Z", "updated_at": "2020-05-13T12:35:27Z", "closed_at": "2020-05-13T12:34:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udcda Documentation\r\n\r\nhttps://github.com/pytorch/vision/blob/7aea80c9497ff78353fef1d9699490c5da6f41b6/torchvision/transforms/transforms.py#L178\r\n\r\nResize argument should be (w,h) instead of (h,w).\r\n\r\nMy bad, it is indeed (h,w).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2205", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2205/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2205/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2205/events", "html_url": "https://github.com/pytorch/vision/issues/2205", "id": 616349655, "node_id": "MDU6SXNzdWU2MTYzNDk2NTU=", "number": 2205, "title": "Some issues in conv_transpose2d. ", "user": {"login": "dhiyu", "id": 37993729, "node_id": "MDQ6VXNlcjM3OTkzNzI5", "avatar_url": "https://avatars1.githubusercontent.com/u/37993729?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhiyu", "html_url": "https://github.com/dhiyu", "followers_url": "https://api.github.com/users/dhiyu/followers", "following_url": "https://api.github.com/users/dhiyu/following{/other_user}", "gists_url": "https://api.github.com/users/dhiyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhiyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhiyu/subscriptions", "organizations_url": "https://api.github.com/users/dhiyu/orgs", "repos_url": "https://api.github.com/users/dhiyu/repos", "events_url": "https://api.github.com/users/dhiyu/events{/privacy}", "received_events_url": "https://api.github.com/users/dhiyu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619886, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODY=", "url": "https://api.github.com/repos/pytorch/vision/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-12T04:30:00Z", "updated_at": "2020-05-12T13:21:51Z", "closed_at": "2020-05-12T13:21:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Recently I met this problem bothering me.\r\nIn TensorFlow, there is a funciton:\r\n`tf.nn.conv2d_transpose(\r\n    input, filters, output_shape, strides, padding='SAME', data_format='NHWC',\r\n    dilations=None, name=None\r\n)`\r\nBut in PyTorch:\r\n`torch.nn.functional.conv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) \u2192 Tensor`\r\nAs you can see there is no parameter named output_shape. But my project need this parameter to recitify the size of output. Anyone can help me? Thanks~", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2200", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2200/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2200/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2200/events", "html_url": "https://github.com/pytorch/vision/issues/2200", "id": 615861237, "node_id": "MDU6SXNzdWU2MTU4NjEyMzc=", "number": 2200, "title": "Support more flexible ways to instantiate models in `torchvision.models`, e.g., remove fc layers, support for `pretrained=True` and `num_classes\uff01=1000`", "user": {"login": "ljqcava", "id": 15867915, "node_id": "MDQ6VXNlcjE1ODY3OTE1", "avatar_url": "https://avatars0.githubusercontent.com/u/15867915?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ljqcava", "html_url": "https://github.com/ljqcava", "followers_url": "https://api.github.com/users/ljqcava/followers", "following_url": "https://api.github.com/users/ljqcava/following{/other_user}", "gists_url": "https://api.github.com/users/ljqcava/gists{/gist_id}", "starred_url": "https://api.github.com/users/ljqcava/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ljqcava/subscriptions", "organizations_url": "https://api.github.com/users/ljqcava/orgs", "repos_url": "https://api.github.com/users/ljqcava/repos", "events_url": "https://api.github.com/users/ljqcava/events{/privacy}", "received_events_url": "https://api.github.com/users/ljqcava/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 689153061, "node_id": "MDU6TGFiZWw2ODkxNTMwNjE=", "url": "https://api.github.com/repos/pytorch/vision/labels/needs%20discussion", "name": "needs discussion", "color": "e99695", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-11T12:52:32Z", "updated_at": "2020-05-15T13:16:04Z", "closed_at": "2020-05-15T13:16:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\nSupport more flexible ways to instantiate models in `torchvision.models`, \r\n\r\ne.g., instantiate ResNet-50 only for feature extraction without FC layer like [Keras style](https://keras.io/api/applications/resnet/#resnet50-function):\r\n```python\r\ntorchvision.models.resnet50(include_top=False)\r\n```\r\nload pretrained weights when class number doesn't equals to 1000(imagenet):\r\n```python\r\ntorchvision.models.resnet50(pretrained=True, num_classes=10)\r\n```\r\n## Motivation\r\nIn many situations, we need more flexiable ways to instantiate models in `torchvision.models`.\r\n\r\nFor examples, when finetuning a ResNet-50 classification model on a dataset of 10 classes, we need  `torchvision.models.resnet50(pretrained=True, num_classes=10)`, but it is not supported now. In current implementation, `num_classes` should be 1000 when `pretrained=True`. To implement this case, we should support partial copy from pretrained weights(load weights except for FC layer).\r\n\r\nAnother example: sometimes we need instantiate the models in `torchvision.models` as **backbone**, which means the FC layer is no more needed. Implementation in this case is also needed. We can support this case with an additional argument, like `include_top=False` in [Keras](https://keras.io/api/applications/resnet/#resnet50-function).\r\n## Pitch\r\nA possible solution is to modify some codes in [models constructions](https://github.com/pytorch/vision/tree/master/torchvision/models). At least two more features should be realized:\r\n\r\n1) **Support for loading partial weights**: when `num_classes!=1000`, weights can still be loaded except for last FC layer.\r\n2) **Support for backbone mode(FC layer moved)**: when an argument (like `include_top`) is set to `False`, the last layer(FC layer) will be moved.\r\n\r\nWe can apply these modifications to many basic models in `torchvision.models`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2198", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2198/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2198/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2198/events", "html_url": "https://github.com/pytorch/vision/issues/2198", "id": 615790584, "node_id": "MDU6SXNzdWU2MTU3OTA1ODQ=", "number": 2198, "title": "Dimension out of range (expected to be in range of [-1, 0] on transforms.py boxes.unbind(1)", "user": {"login": "sarmientoj24", "id": 8830319, "node_id": "MDQ6VXNlcjg4MzAzMTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/8830319?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sarmientoj24", "html_url": "https://github.com/sarmientoj24", "followers_url": "https://api.github.com/users/sarmientoj24/followers", "following_url": "https://api.github.com/users/sarmientoj24/following{/other_user}", "gists_url": "https://api.github.com/users/sarmientoj24/gists{/gist_id}", "starred_url": "https://api.github.com/users/sarmientoj24/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sarmientoj24/subscriptions", "organizations_url": "https://api.github.com/users/sarmientoj24/orgs", "repos_url": "https://api.github.com/users/sarmientoj24/repos", "events_url": "https://api.github.com/users/sarmientoj24/events{/privacy}", "received_events_url": "https://api.github.com/users/sarmientoj24/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619883, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODM=", "url": "https://api.github.com/repos/pytorch/vision/labels/duplicate", "name": "duplicate", "color": "cccccc", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-11T10:53:36Z", "updated_at": "2020-05-11T11:06:32Z", "closed_at": "2020-05-11T11:01:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create Dataset object\r\n```\r\nclass OwnDataset(torch.utils.data.Dataset):\r\n    def __init__(self, root, annotation, transforms=None):\r\n        self.root = root\r\n        self.transforms = transforms\r\n        self.coco = COCO(annotation)\r\n        self.ids = list(sorted(self.coco.imgs.keys()))\r\n\r\n    def __getitem__(self, index):\r\n        # Own coco file\r\n        coco = self.coco\r\n        # Image ID\r\n        img_id = self.ids[index]\r\n        # List: get annotation id from coco\r\n        ann_ids = coco.getAnnIds(imgIds=img_id)\r\n        # Dictionary: target coco_annotation file for an image\r\n        coco_annotation = coco.loadAnns(ann_ids)\r\n        # path for input image\r\n        path = coco.loadImgs(img_id)[0]['file_name']\r\n        # open the input image\r\n        img = Image.open(os.path.join(self.root, path))\r\n\r\n        # number of objects in the image\r\n        num_objs = len(coco_annotation)\r\n\r\n        # Bounding boxes for objects\r\n        # In coco format, bbox = [xmin, ymin, width, height]\r\n        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\r\n        boxes = []\r\n        for i in range(num_objs):\r\n            xmin = coco_annotation[i]['bbox'][0]\r\n            ymin = coco_annotation[i]['bbox'][1]\r\n            xmax = xmin + coco_annotation[i]['bbox'][2]\r\n            ymax = ymin + coco_annotation[i]['bbox'][3]\r\n            boxes.append([xmin, ymin, xmax, ymax])\r\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\r\n        # Labels (In my case, I only one class: target class or background)\r\n        labels = torch.ones((num_objs,), dtype=torch.int64)\r\n        # Tensorise img_id\r\n        img_id = torch.tensor([img_id])\r\n        # Size of bbox (Rectangular)\r\n        areas = []\r\n        for i in range(num_objs):\r\n            areas.append(coco_annotation[i]['area'])\r\n        areas = torch.as_tensor(areas, dtype=torch.float32)\r\n        # Iscrowd\r\n        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\r\n\r\n        # Annotation is in dictionary format\r\n        my_annotation = {}\r\n        my_annotation[\"boxes\"] = boxes\r\n        my_annotation[\"labels\"] = labels\r\n        my_annotation[\"image_id\"] = img_id\r\n        my_annotation[\"area\"] = areas\r\n        my_annotation[\"iscrowd\"] = iscrowd\r\n\r\n        if self.transforms is not None:\r\n            img = self.transforms(img)\r\n\r\n        return img, my_annotation\r\n\r\n    def __len__(self):\r\n        return len(self.ids)\r\n```\r\n\r\n2. Create DataLoader\r\n```\r\nfrom torchvision import transforms\r\ndef get_transform():\r\n    custom_transforms = [\r\n        transforms.ToTensor(),\r\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n    ]\r\n    return torchvision.transforms.Compose(custom_transforms)\r\n\r\ntrain_data_dir = '/content/datasets/imgs/'\r\ntrain_coco = '/content/datasets/outputs/train.json'\r\n\r\n\r\n# create own Dataset\r\nmy_dataset = OwnDataset(root=train_data_dir, \r\n                        annotation=train_coco, \r\n                        transforms=get_transform()\r\n                        )\r\n\r\n# collate_fn needs for batch\r\ndef collate_fn(batch):\r\n    return tuple(zip(*batch))\r\n\r\n# Batch size\r\ntrain_batch_size = 2\r\n\r\n# own DataLoader\r\ndata_loader = torch.utils.data.DataLoader(my_dataset,\r\n                                          batch_size=train_batch_size,\r\n                                          shuffle=True,\r\n                                          num_workers=4,\r\n                                          collate_fn=collate_fn)\r\n\r\n```\r\n\r\n2. Create a model of MobileNetV2 on top of Faster RCNN (below is my model instance)\r\n```\r\ndef get_model_instance_segmentation(num_classes):\r\n  # load a pre-trained model for classification and return\r\n  # only the features\r\n  backbone = torchvision.models.mobilenet_v2(pretrained=True).features\r\n  # FasterRCNN needs to know the number of\r\n  # output channels in a backbone. For mobilenet_v2, it's 1280\r\n  # so we need to add it here\r\n  backbone.out_channels = 1280\r\n  # let's make the RPN generate 5 x 3 anchors per spatial\r\n  # location, with 5 different sizes and 3 different aspect\r\n  # ratios. We have a Tuple[Tuple[int]] because each feature\r\n  # map could potentially have different sizes and\r\n  # aspect ratios\r\n  anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256),),\r\n                                    aspect_ratios=((0.5, 1.0, 2.0),))\r\n  # let's define what are the feature maps that we will\r\n  # use to perform the region of interest cropping, as well as\r\n  # the size of the crop after rescaling.\r\n  # if your backbone returns a Tensor, featmap_names is expected to\r\n  # be [0]. More generally, the backbone should return an\r\n  # OrderedDict[Tensor], and in featmap_names you can choose which\r\n  # feature maps to use.\r\n  roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\r\n                                                  output_size=7,\r\n                                                  sampling_ratio=2)\r\n  # put the pieces together inside a FasterRCNN model\r\n  model = FasterRCNN(backbone,\r\n                   num_classes=num_classes,\r\n                   rpn_anchor_generator=anchor_generator,\r\n                   box_roi_pool=roi_pooler)\r\n  return model\r\n```\r\n3. Train the model with libraries/modules from pytorch such as transforms.py, utils.py, engine.py, coco_eval.py, etc.\r\n```\r\nparams = [p for p in model.parameters() if p.requires_grad]\r\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\r\n\r\nlen_dataloader = len(data_loader)\r\ntotal_len = num_epochs * len_dataloader\r\ntotal_processed = 0\r\n\r\nimport time\r\n\r\ntime_s = time.time()\r\nfor epoch in range(num_epochs):\r\n  model.train()\r\n  i = 0    \r\n  for imgs, annotations in data_loader:\r\n    i += 1\r\n    total_processed += 1\r\n    imgs = list(img.to(device) for img in imgs)\r\n    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\r\n    loss_dict = model(imgs, annotations)\r\n    losses = sum(loss for loss in loss_dict.values())\r\n\r\n    optimizer.zero_grad()\r\n    losses.backward()\r\n    optimizer.step()\r\n\r\n    if i % 100 == 0:\r\n      print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')\r\n      time_elapsed = time.time() - time_s\r\n      ave_processing_time = total_processed / time_elapsed\r\n      remaining_records = total_len - total_processed\r\n      time_remaining = remaining_records / ave_processing_time\r\n      print(f\"Time remaining in seconds {time_remaining}s and {time_remaining / 60} min...\")\r\n  if epoch % 2 == 0:\r\n    print('Saving model')\r\n    torch.save(model, '/content/gdrive/My Drive/libraries/model_full.pth')\r\n    torch.save({\r\n            'epoch': epoch,\r\n            'model_state_dict': model.state_dict(),\r\n            'optimizer_state_dict': optimizer.state_dict(),\r\n            'loss': loss\r\n            }, '/content/gdrive/My Drive/libraries/model_full_resuming.pth') \r\n```\r\n4. Error comes out like this:\r\n\r\n```IndexError                                Traceback (most recent call last)\r\n<ipython-input-30-0ef74c49d85f> in <module>()\r\n     77     imgs = list(img.to(device) for img in imgs)\r\n     78     annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\r\n---> 79     loss_dict = model(imgs, annotations)\r\n     80     losses = sum(loss for loss in loss_dict.values())\r\n     81 \r\n\r\n5 frames\r\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    548             result = self._slow_forward(*input, **kwargs)\r\n    549         else:\r\n--> 550             result = self.forward(*input, **kwargs)\r\n    551         for hook in self._forward_hooks.values():\r\n    552             hook_result = hook(self, input, result)\r\n\r\n/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/generalized_rcnn.py in forward(self, images, targets)\r\n     64             original_image_sizes.append((val[0], val[1]))\r\n     65 \r\n---> 66         images, targets = self.transform(images, targets)\r\n     67         features = self.backbone(images.tensors)\r\n     68         if isinstance(features, torch.Tensor):\r\n\r\n/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\r\n    548             result = self._slow_forward(*input, **kwargs)\r\n    549         else:\r\n--> 550             result = self.forward(*input, **kwargs)\r\n    551         for hook in self._forward_hooks.values():\r\n    552             hook_result = hook(self, input, result)\r\n\r\n/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/transform.py in forward(self, images, targets)\r\n     43                                  \"of shape [C, H, W], got {}\".format(image.shape))\r\n     44             image = self.normalize(image)\r\n---> 45             image, target_index = self.resize(image, target_index)\r\n     46             images[i] = image\r\n     47             if targets is not None and target_index is not None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/transform.py in resize(self, image, target)\r\n     96 \r\n     97         bbox = target[\"boxes\"]\r\n---> 98         bbox = resize_boxes(bbox, (h, w), image.shape[-2:])\r\n     99         target[\"boxes\"] = bbox\r\n    100 \r\n\r\n/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/transform.py in resize_boxes(boxes, original_size, new_size)\r\n    218     ]\r\n    219     ratio_height, ratio_width = ratios\r\n--> 220     xmin, ymin, xmax, ymax = boxes.unbind(1)\r\n    221 \r\n    222     xmin = xmin * ratio_width\r\n\r\nIndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)```\r\n\r\n## Expected behavior\r\n\r\nExpected to have the training as normal without the bug.\r\n\r\n## Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\r\n# For security purposes, please check the contents of collect_env.py before running it.\r\npython collect_env.py\r\n```\r\n\r\nPyTorch version: 1.5.0+cu101\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 18.04.3 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.243\r\nGPU models and configuration: GPU 0: Tesla P100-PCIE-16GB\r\nNvidia driver version: 418.67\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.4\r\n[pip3] torch==1.5.0+cu101\r\n[pip3] torchsummary==1.5.1\r\n[pip3] torchtext==0.3.1\r\n[pip3] torchvision==0.6.0+cu101\r\n[conda] Could not collect\r\n\r\n## Additional context\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2197", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2197/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2197/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2197/events", "html_url": "https://github.com/pytorch/vision/issues/2197", "id": 615787465, "node_id": "MDU6SXNzdWU2MTU3ODc0NjU=", "number": 2197, "title": "[roi_pool/roi_align] Support dropped for tuple of Tensors", "user": {"login": "frgfm", "id": 26927750, "node_id": "MDQ6VXNlcjI2OTI3NzUw", "avatar_url": "https://avatars0.githubusercontent.com/u/26927750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/frgfm", "html_url": "https://github.com/frgfm", "followers_url": "https://api.github.com/users/frgfm/followers", "following_url": "https://api.github.com/users/frgfm/following{/other_user}", "gists_url": "https://api.github.com/users/frgfm/gists{/gist_id}", "starred_url": "https://api.github.com/users/frgfm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/frgfm/subscriptions", "organizations_url": "https://api.github.com/users/frgfm/orgs", "repos_url": "https://api.github.com/users/frgfm/repos", "events_url": "https://api.github.com/users/frgfm/events{/privacy}", "received_events_url": "https://api.github.com/users/frgfm/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619884, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODQ=", "url": "https://api.github.com/repos/pytorch/vision/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-11T10:48:47Z", "updated_at": "2020-05-11T14:56:22Z", "closed_at": "2020-05-11T14:52:33Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Support of Sequence of Tensors was downgraded to list of Tensors\r\n\r\nHello there,\r\n\r\nI used to have a `roi_align` applied to a Tuple of Tensors, which is not working anymore since I updated torchvision. I believe the change is due to this [commit](https://github.com/pytorch/vision/commit/505cd6957711af790211896d32b40291bea1bc21)\r\n\r\n## To Reproduce\r\n\r\n```\r\nimport torch\r\nfrom torchvision.ops import roi_align\r\n\r\nx = torch.rand((2, 32, 19, 19)) \r\nboxes = boxes = tuple([torch.tensor([[0, 0, 50, 50]], dtype=torch.float), torch.tensor([[50, 50, 100, 100]], dtype=torch.float)])\r\nout = roi_align(x, list(boxes), (7, 7), spatial_scale=0.15)\r\n```\r\nwhich yields\r\n```\r\nAssertionError: boxes is expected to be a Tensor[L, 5] or a List[Tensor[K, 4]]\r\n```\r\n\r\n## Expected behavior\r\n\r\nSince `torch.cat` [supports](https://pytorch.org/docs/stable/torch.html#torch.cat) all Sequence of Tensors, we might want to restore this support. I don't foresee any side effects or unwanted behaviours with this suggested change.\r\n\r\n## Environment\r\n\r\n - PyTorch / torchvision Version: 1.5.0 / 0.6.0a0+82fd1c8\r\n - OS: Ubuntu 18.04.4 LTS \r\n - How you installed PyTorch / torchvision: `conda`\r\n - Python version: 3.7\r\n - CUDA/cuDNN version: 10.2 (cuDNN 7.6.5)\r\n - GPU models and configuration: GeForce GTX 1050 (driver 440.82)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2196", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2196/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2196/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2196/events", "html_url": "https://github.com/pytorch/vision/issues/2196", "id": 615360090, "node_id": "MDU6SXNzdWU2MTUzNjAwOTA=", "number": 2196, "title": "WideResNet implementation doesn't use Dropout ", "user": {"login": "BlackHC", "id": 729312, "node_id": "MDQ6VXNlcjcyOTMxMg==", "avatar_url": "https://avatars3.githubusercontent.com/u/729312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BlackHC", "html_url": "https://github.com/BlackHC", "followers_url": "https://api.github.com/users/BlackHC/followers", "following_url": "https://api.github.com/users/BlackHC/following{/other_user}", "gists_url": "https://api.github.com/users/BlackHC/gists{/gist_id}", "starred_url": "https://api.github.com/users/BlackHC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BlackHC/subscriptions", "organizations_url": "https://api.github.com/users/BlackHC/orgs", "repos_url": "https://api.github.com/users/BlackHC/repos", "events_url": "https://api.github.com/users/BlackHC/events{/privacy}", "received_events_url": "https://api.github.com/users/BlackHC/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 689153061, "node_id": "MDU6TGFiZWw2ODkxNTMwNjE=", "url": "https://api.github.com/repos/pytorch/vision/labels/needs%20discussion", "name": "needs discussion", "color": "e99695", "default": false, "description": null}, {"id": 1388460222, "node_id": "MDU6TGFiZWwxMzg4NDYwMjIy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20classification", "name": "topic: classification", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-10T10:16:58Z", "updated_at": "2020-05-11T11:43:19Z", "closed_at": "2020-05-11T10:27:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nWideResNets as described in the original paper (\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>) use Dropout. The Torchvision implementation does not.\r\n\r\nIf this for performance reasons, or similar, please add a comment. It would be very helpful to point out that difference clearly. When it comes to reproducing baselines, confusion about what is a real WideResNet vs not could complicate research efforts.\r\n\r\nThanks for your consideration!\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nExamine model definition in https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py and compare to paper, or other implementations eg https://github.com/meliketoy/wide-resnet.pytorch/blob/master/networks/wide_resnet.py.\r\n\r\n## Expected behavior\r\n\r\nDropout layers to be added in the residual blocks.\r\n\r\n## Environment\r\n\r\ntorchvision 0.6/head", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2193", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2193/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2193/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2193/events", "html_url": "https://github.com/pytorch/vision/issues/2193", "id": 613997450, "node_id": "MDU6SXNzdWU2MTM5OTc0NTA=", "number": 2193, "title": "Duplicated function channel_shuffle()", "user": {"login": "xkszltl", "id": 5203025, "node_id": "MDQ6VXNlcjUyMDMwMjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/5203025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xkszltl", "html_url": "https://github.com/xkszltl", "followers_url": "https://api.github.com/users/xkszltl/followers", "following_url": "https://api.github.com/users/xkszltl/following{/other_user}", "gists_url": "https://api.github.com/users/xkszltl/gists{/gist_id}", "starred_url": "https://api.github.com/users/xkszltl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xkszltl/subscriptions", "organizations_url": "https://api.github.com/users/xkszltl/orgs", "repos_url": "https://api.github.com/users/xkszltl/repos", "events_url": "https://api.github.com/users/xkszltl/events{/privacy}", "received_events_url": "https://api.github.com/users/xkszltl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619882, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODI=", "url": "https://api.github.com/repos/pytorch/vision/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-07T11:54:40Z", "updated_at": "2020-05-12T13:22:58Z", "closed_at": "2020-05-12T13:22:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nGet the following error when compiling today with pytorch master.\r\nThis should be a recent regression as I was able to do the same in Apr.\r\n\r\n```\r\n../torchvision/csrc/models/shufflenetv2.cpp:83:33: error: call of overloaded 'channel_shuffle(at::Tensor&, int)' is ambiguous\r\n../torchvision/csrc/models/shufflenetv2.cpp:10:15: note: candidate: 'at::Tensor vision::models::channel_shuffle(at::Tensor, int64_t)'\r\n/usr/local/include/ATen/Functions.h:8045:22: note: candidate: 'at::Tensor at::channel_shuffle(const at::Tensor&, int64_t)'\r\n```\r\n\r\n## Environment\r\n\r\n - PyTorch / torchvision Version (e.g., 1.0 / 0.4.0): master/master\r\n - OS (e.g., Linux): Ubuntu 18.04\r\n - How you installed PyTorch / torchvision (`conda`, `pip`, source): source\r\n - Build command you used (if compiling from source): cmake+ninja+gcc-8\r\n - CUDA/cuDNN version: 10.2\r\n\r\n## Additional context\r\n\r\n<img width=\"1057\" alt=\"image\" src=\"https://user-images.githubusercontent.com/5203025/81291560-8e9a5b80-909c-11ea-92f7-d6131b4ea773.png\">\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2188", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2188/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2188/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2188/events", "html_url": "https://github.com/pytorch/vision/issues/2188", "id": 612997661, "node_id": "MDU6SXNzdWU2MTI5OTc2NjE=", "number": 2188, "title": "Is there any version can support cuda9.0?", "user": {"login": "Lucksong", "id": 20484903, "node_id": "MDQ6VXNlcjIwNDg0OTAz", "avatar_url": "https://avatars0.githubusercontent.com/u/20484903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lucksong", "html_url": "https://github.com/Lucksong", "followers_url": "https://api.github.com/users/Lucksong/followers", "following_url": "https://api.github.com/users/Lucksong/following{/other_user}", "gists_url": "https://api.github.com/users/Lucksong/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lucksong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lucksong/subscriptions", "organizations_url": "https://api.github.com/users/Lucksong/orgs", "repos_url": "https://api.github.com/users/Lucksong/repos", "events_url": "https://api.github.com/users/Lucksong/events{/privacy}", "received_events_url": "https://api.github.com/users/Lucksong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1588820772, "node_id": "MDU6TGFiZWwxNTg4ODIwNzcy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20binaries", "name": "topic: binaries", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-06T01:45:49Z", "updated_at": "2020-05-06T10:38:24Z", "closed_at": "2020-05-06T10:36:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n### Please note that this issue tracker is not a help form and this issue will be closed.\r\n\r\nWe have a set of [listed resources available on the website](https://pytorch.org/resources). Our primary means of support is our discussion forum:\r\n\r\n- [Discussion Forum](https://discuss.pytorch.org/)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2180", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2180/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2180/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2180/events", "html_url": "https://github.com/pytorch/vision/issues/2180", "id": 612180352, "node_id": "MDU6SXNzdWU2MTIxODAzNTI=", "number": 2180, "title": "Make ResNet max_resolution tuneable", "user": {"login": "EMCP", "id": 3691722, "node_id": "MDQ6VXNlcjM2OTE3MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3691722?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EMCP", "html_url": "https://github.com/EMCP", "followers_url": "https://api.github.com/users/EMCP/followers", "following_url": "https://api.github.com/users/EMCP/following{/other_user}", "gists_url": "https://api.github.com/users/EMCP/gists{/gist_id}", "starred_url": "https://api.github.com/users/EMCP/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EMCP/subscriptions", "organizations_url": "https://api.github.com/users/EMCP/orgs", "repos_url": "https://api.github.com/users/EMCP/repos", "events_url": "https://api.github.com/users/EMCP/events{/privacy}", "received_events_url": "https://api.github.com/users/EMCP/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619884, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODQ=", "url": "https://api.github.com/repos/pytorch/vision/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1391938214, "node_id": "MDU6TGFiZWwxMzkxOTM4MjE0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20documentation", "name": "module: documentation", "color": "f7e101", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-05-04T21:27:56Z", "updated_at": "2020-05-06T19:24:32Z", "closed_at": "2020-05-05T14:16:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\nPerhaps this is my ignorance.. but I am attempting to avoid cropping or downsampling of my 4K sized images.. as they go into Faster R CNN with a ResNet 101 backbone.  Details can be found at https://discuss.pytorch.org/t/how-do-i-avoid-downsampling-with-faster-rcnn-resnet-backbone/79740 \r\n\r\nI found the `max_size=` parameter.. but it took only an integer.. which I couldn't not quite understand what that was for.. perhaps I need to use `min_size=` ? \r\n\r\nI'm happy to help update docs pointing out where to go, in order to turn off downsampling.. however I have a feeling this is quite low in the api and no exposed at the levels I am utilizing torchvision..?\r\n\r\n## Motivation\r\n\r\nMy GPU has more RAM and I would like to minimize the downsampling and set batch_size to 1.. giving all possible RAM to avoid loss of pixel information as the image enters the training phase.\r\n\r\n## Pitch\r\n\r\nAdd either a explanation how to implement, or documentation stating what you must do if it cannot be done with the torchvision library in it's current roadmap.  I think my 6GB card is just the start and many people are starting to process larger than 4K images in training.\r\n\r\n## Alternatives\r\n\r\n\r\n\r\n## Additional context\r\n\r\nI was able to run maximum VRAM utilization with batch_size = 1 using this project\r\n\r\nhttps://github.com/jwyang/faster-rcnn.pytorch/tree/pytorch-1.0\r\n\r\nHoping I can port my work to torchvision and get more to do likewise, as it's much cleaner code!  Great work so far", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2176", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2176/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2176/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2176/events", "html_url": "https://github.com/pytorch/vision/issues/2176", "id": 611359121, "node_id": "MDU6SXNzdWU2MTEzNTkxMjE=", "number": 2176, "title": "EMNIST dataset class name error in torchvision", "user": {"login": "jydennis", "id": 58645973, "node_id": "MDQ6VXNlcjU4NjQ1OTcz", "avatar_url": "https://avatars1.githubusercontent.com/u/58645973?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jydennis", "html_url": "https://github.com/jydennis", "followers_url": "https://api.github.com/users/jydennis/followers", "following_url": "https://api.github.com/users/jydennis/following{/other_user}", "gists_url": "https://api.github.com/users/jydennis/gists{/gist_id}", "starred_url": "https://api.github.com/users/jydennis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jydennis/subscriptions", "organizations_url": "https://api.github.com/users/jydennis/orgs", "repos_url": "https://api.github.com/users/jydennis/repos", "events_url": "https://api.github.com/users/jydennis/events{/privacy}", "received_events_url": "https://api.github.com/users/jydennis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-03T08:13:13Z", "updated_at": "2020-05-03T08:15:50Z", "closed_at": "2020-05-03T08:15:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nThe predefined letters List `_merged_classes` of EMNIST dataset (located at `vision/torchvision/datasets/mnist.py`) should be lower-case, according to EMNIST paper: https://arxiv.org/pdf/1702.05373.pdf\r\n\r\nThe above-mentioned list in repo:\r\n`_merged_classes = set(['C', 'I', 'J', 'K', 'L', 'M', 'O', 'P', 'S', 'U', 'V', 'W', 'X', 'Y', 'Z'])`\r\n\r\nThe list it should be:\r\n`_merged_classes = set(['c', 'i', 'j', 'k', 'l', 'm', 'o', 'p', 's', 'u', 'v', 'w', 'x', 'y', 'z'])`\r\n## To Reproduce\r\n\r\nJust draw out a image-target pair and compare the target index with the class name list.\r\n\r\n## Expected behavior\r\n\r\nHighly likely They do not match.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2175", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2175/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2175/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2175/events", "html_url": "https://github.com/pytorch/vision/issues/2175", "id": 611347467, "node_id": "MDU6SXNzdWU2MTEzNDc0Njc=", "number": 2175, "title": "ModuleNotFoundError: No module named 'torchvision.models.detection'", "user": {"login": "feiyangsuo", "id": 47778268, "node_id": "MDQ6VXNlcjQ3Nzc4MjY4", "avatar_url": "https://avatars0.githubusercontent.com/u/47778268?v=4", "gravatar_id": "", "url": "https://api.github.com/users/feiyangsuo", "html_url": "https://github.com/feiyangsuo", "followers_url": "https://api.github.com/users/feiyangsuo/followers", "following_url": "https://api.github.com/users/feiyangsuo/following{/other_user}", "gists_url": "https://api.github.com/users/feiyangsuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/feiyangsuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/feiyangsuo/subscriptions", "organizations_url": "https://api.github.com/users/feiyangsuo/orgs", "repos_url": "https://api.github.com/users/feiyangsuo/repos", "events_url": "https://api.github.com/users/feiyangsuo/events{/privacy}", "received_events_url": "https://api.github.com/users/feiyangsuo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-03T06:51:40Z", "updated_at": "2020-05-04T12:33:56Z", "closed_at": "2020-05-04T12:33:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have pytorch1.1.0 and torchvision0.2.2 installed in my anaconda environment.\r\nI can: 1. `import torch`; 2.`import torchvision` (following the toturial) Yet when `from torchvision.models.detection.faster_rcnn import FastRCNNPredictor`, error raised as:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"D:\\Applications\\PyCharm 2019.2.3\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\nModuleNotFoundError: No module named 'torchvision.models.detection'\r\n```\r\nI suspect that my version of torchvision is somewhat low. But my GPU driver only support cudatoolkit9.0, and version 0.2.2 is automatically chosen when I install torchvision.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2171", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2171/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2171/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2171/events", "html_url": "https://github.com/pytorch/vision/issues/2171", "id": 610359627, "node_id": "MDU6SXNzdWU2MTAzNTk2Mjc=", "number": 2171, "title": "generate_anchors method in torchvision/models/detection/rpn.py is generating anchors with 1 / aspect_ratios instead of specified aspect_ratios", "user": {"login": "malhotraa", "id": 1097873, "node_id": "MDQ6VXNlcjEwOTc4NzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1097873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/malhotraa", "html_url": "https://github.com/malhotraa", "followers_url": "https://api.github.com/users/malhotraa/followers", "following_url": "https://api.github.com/users/malhotraa/following{/other_user}", "gists_url": "https://api.github.com/users/malhotraa/gists{/gist_id}", "starred_url": "https://api.github.com/users/malhotraa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/malhotraa/subscriptions", "organizations_url": "https://api.github.com/users/malhotraa/orgs", "repos_url": "https://api.github.com/users/malhotraa/repos", "events_url": "https://api.github.com/users/malhotraa/events{/privacy}", "received_events_url": "https://api.github.com/users/malhotraa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1391938214, "node_id": "MDU6TGFiZWwxMzkxOTM4MjE0", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20documentation", "name": "module: documentation", "color": "f7e101", "default": false, "description": ""}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-30T20:19:42Z", "updated_at": "2020-05-05T18:09:18Z", "closed_at": "2020-05-05T18:09:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n[generate_anchors](https://github.com/pytorch/vision/blob/master/torchvision/models/detection/rpn.py#L77) method in rpn.py is generating anchors with 1 / aspect_ratios instead of specified aspect_ratios\r\n\r\n## To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n* Call `generate_anchors` method with following input:\r\n   scales: [32]\r\n   aspect_ratios: [0.5]\r\n\r\n* Output from above call is [-22, -11, 22, 11]. Assuming the coordinates are in format [xmin, ymin, xmax, ymax] the aspect ratio is (22/11) = 2 instead of 0.5 which we would expect.\r\n\r\n## Expected behavior\r\nThe above method should produce anchors with specified aspect_ratios instead of 1/aspect_ratios\r\n\r\n## Environment\r\nPyTorch version: 1.4.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\n\r\nOS: Ubuntu 16.04.6 LTS\r\nGCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCMake version: Could not collect\r\n\r\nPython version: 3.7\r\nIs CUDA available: Yes\r\nCUDA runtime version: 10.1.243\r\nGPU models and configuration: GPU 0: GeForce RTX 2080 Ti\r\nNvidia driver version: 418.39\r\ncuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\r\n\r\nVersions of relevant libraries:\r\n[pip] numpy==1.18.1\r\n[pip] torch==1.4.0\r\n[pip] torchvision==0.5.0\r\n[conda] numpy                     1.18.1                   pypi_0    pypi\r\n[conda] torch                     1.4.0                    pypi_0    pypi\r\n[conda] torchvision               0.5.0                    pypi_0    pypi\r\n\r\n## Additional context\r\nN/A\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2169", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2169/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2169/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2169/events", "html_url": "https://github.com/pytorch/vision/issues/2169", "id": 610237291, "node_id": "MDU6SXNzdWU2MTAyMzcyOTE=", "number": 2169, "title": "[batchnorm] Add a eps on FrozenBatchNorm2d", "user": {"login": "frgfm", "id": 26927750, "node_id": "MDQ6VXNlcjI2OTI3NzUw", "avatar_url": "https://avatars0.githubusercontent.com/u/26927750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/frgfm", "html_url": "https://github.com/frgfm", "followers_url": "https://api.github.com/users/frgfm/followers", "following_url": "https://api.github.com/users/frgfm/following{/other_user}", "gists_url": "https://api.github.com/users/frgfm/gists{/gist_id}", "starred_url": "https://api.github.com/users/frgfm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/frgfm/subscriptions", "organizations_url": "https://api.github.com/users/frgfm/orgs", "repos_url": "https://api.github.com/users/frgfm/repos", "events_url": "https://api.github.com/users/frgfm/events{/privacy}", "received_events_url": "https://api.github.com/users/frgfm/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619884, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODQ=", "url": "https://api.github.com/repos/pytorch/vision/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 1373812961, "node_id": "MDU6TGFiZWwxMzczODEyOTYx", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20ops", "name": "module: ops", "color": "f7e101", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-30T16:56:14Z", "updated_at": "2020-05-11T14:56:06Z", "closed_at": "2020-05-11T14:52:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n\r\nIntroduce a `eps` attribute similar to the one of `BatchNorm2d` to enable erasing the difference in result between the two modules.\r\n\r\n## Motivation\r\n\r\nFirst, the inference does not match exactly `BatchNorm2d`:\r\n```\r\nimport torch\r\nfrom torch.nn import BatchNorm2d\r\nfrom torchvision.ops.misc import FrozenBatchNorm2d\r\n\r\ninput_t = torch.rand(1, 16, 8, 8)\r\nbn = BatchNorm2d(16).eval()\r\nfbn = FrozenBatchNorm2d(16)\r\nfbn.load_state_dict(bn.state_dict(), strict=False)\r\n\r\nwith torch.no_grad():\r\n    print(torch.equal(bn(input_t), fbn(input_t)))\r\n```\r\nyields `False` (average absolute difference around `2.5e-6` during my tests)\r\n\r\nSecond, in `torchvision`, the implementation of `FrozenBatchNorm2d` is used only [here](https://github.com/pytorch/vision/blob/master/torchvision/models/detection/backbone_utils.py#L44) to the best of my knowledge.\r\n\r\nIf `pretrained=True` in `resnet_fpn_backbone`:\r\n- existing `BatchNorm2d` will be replaced by `FrozenBatchNorm2d`\r\n- the frozen BN will received parameter values from resnets trained on ImageNet **but with actual `BatchNorm2d`**.\r\n\r\nMeaning that there might be a slightly better starting point for resnet with FPN added on top when using the pretrained version.\r\n\r\n\r\n## Pitch\r\n\r\nAdd a `eps` attribute to `FrozenBatchNorm2d` in the constructor and in the forward method to match the implementation of `BatchNorm2d` without the batch statistics. To avoid any backward compatibility issue or discrepancies, it might have to be set to 0 by default.\r\n\r\nHappy to come up with a PR if you think it might be worth it!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2167", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2167/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2167/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2167/events", "html_url": "https://github.com/pytorch/vision/issues/2167", "id": 609979040, "node_id": "MDU6SXNzdWU2MDk5NzkwNDA=", "number": 2167, "title": "engine.py error while following tutorial", "user": {"login": "EMCP", "id": 3691722, "node_id": "MDQ6VXNlcjM2OTE3MjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3691722?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EMCP", "html_url": "https://github.com/EMCP", "followers_url": "https://api.github.com/users/EMCP/followers", "following_url": "https://api.github.com/users/EMCP/following{/other_user}", "gists_url": "https://api.github.com/users/EMCP/gists{/gist_id}", "starred_url": "https://api.github.com/users/EMCP/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EMCP/subscriptions", "organizations_url": "https://api.github.com/users/EMCP/orgs", "repos_url": "https://api.github.com/users/EMCP/repos", "events_url": "https://api.github.com/users/EMCP/events{/privacy}", "received_events_url": "https://api.github.com/users/EMCP/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1373819307, "node_id": "MDU6TGFiZWwxMzczODE5MzA3", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20reference%20scripts", "name": "module: reference scripts", "color": "f7e101", "default": false, "description": ""}, {"id": 478619887, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODc=", "url": "https://api.github.com/repos/pytorch/vision/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 1388459342, "node_id": "MDU6TGFiZWwxMzg4NDU5MzQy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20object%20detection", "name": "topic: object detection", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-30T13:21:38Z", "updated_at": "2020-05-07T16:11:59Z", "closed_at": "2020-04-30T14:09:29Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udcda Documentation\r\n\r\nI have found this library via the examples at https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\r\n\r\nI ran the google colab and that successfully finished.. however when I go to copy `master` from here and use it locally I am getting an error..\r\n\r\nEngine.py line \r\n![image](https://user-images.githubusercontent.com/3691722/80714967-f9c0bc80-8af5-11ea-8d17-1d8f1278a69d.png)\r\n\r\n![image](https://user-images.githubusercontent.com/3691722/80715039-14933100-8af6-11ea-89ee-894b769723f7.png)\r\n\r\nError\r\n\r\n```\r\n    train_one_epoch(model, optimizer, training_data_loader, device, epoch, print_freq=model_conf[\"hyperParameters\"][\"display\"])\r\n  File \"/home/emcp/Dev/git/EMCP/faster-rcnn-torchvision/model_components/model/engine.py\", line 27, in train_one_epoch\r\n    images = list(image.to(device) for image in images)\r\n  File \"/home/emcp/Dev/git/EMCP/faster-rcnn-torchvision/model_components/model/engine.py\", line 27, in <genexpr>\r\n    images = list(image.to(device) for image in images)\r\nAttributeError: 'Image' object has no attribute 'to'\r\n``\r\nseems to be an image did not load perhaps ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2166", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2166/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2166/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2166/events", "html_url": "https://github.com/pytorch/vision/issues/2166", "id": 609805594, "node_id": "MDU6SXNzdWU2MDk4MDU1OTQ=", "number": 2166, "title": "Make initialization of GoogleNet / Inception faster", "user": {"login": "fmassa", "id": 9110200, "node_id": "MDQ6VXNlcjkxMTAyMDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9110200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fmassa", "html_url": "https://github.com/fmassa", "followers_url": "https://api.github.com/users/fmassa/followers", "following_url": "https://api.github.com/users/fmassa/following{/other_user}", "gists_url": "https://api.github.com/users/fmassa/gists{/gist_id}", "starred_url": "https://api.github.com/users/fmassa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fmassa/subscriptions", "organizations_url": "https://api.github.com/users/fmassa/orgs", "repos_url": "https://api.github.com/users/fmassa/repos", "events_url": "https://api.github.com/users/fmassa/events{/privacy}", "received_events_url": "https://api.github.com/users/fmassa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 478619884, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODQ=", "url": "https://api.github.com/repos/pytorch/vision/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 478619885, "node_id": "MDU6TGFiZWw0Nzg2MTk4ODU=", "url": "https://api.github.com/repos/pytorch/vision/labels/help%20wanted", "name": "help wanted", "color": "128A0C", "default": true, "description": null}, {"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1388460222, "node_id": "MDU6TGFiZWwxMzg4NDYwMjIy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20classification", "name": "topic: classification", "color": "0e8a16", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-30T10:36:15Z", "updated_at": "2020-05-05T17:19:38Z", "closed_at": "2020-05-05T17:19:38Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "There have been several reports from users that GoogleNet and Inception are very slow to construct, see https://github.com/pytorch/vision/issues/1797 , https://github.com/pytorch/vision/issues/1977 and https://github.com/pytorch/vision/issues/2145 for example.\r\n\r\nThe underlying issue is that these models use `scipy.truncnorm`, for which the implementation was recently updated and became 100x slower than it was before, see https://github.com/scipy/scipy/issues/11299 for reference. This slowdown has been fixed in scipy and will be present in the 1.5.0 release, but in the meantime, users of torchvision still obtain very long startup times.\r\n\r\nI think the simplest alternative is to make `init_weights` default to `False`, and use a weight initialization from PyTorch instead. This is BC-breaking for users who want to train Inception from scratch, but I'm not sure how much it will affect users in general.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2163", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2163/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2163/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2163/events", "html_url": "https://github.com/pytorch/vision/issues/2163", "id": 609337452, "node_id": "MDU6SXNzdWU2MDkzMzc0NTI=", "number": 2163, "title": "Cannot import video_reader", "user": {"login": "surisdi", "id": 15468123, "node_id": "MDQ6VXNlcjE1NDY4MTIz", "avatar_url": "https://avatars3.githubusercontent.com/u/15468123?v=4", "gravatar_id": "", "url": "https://api.github.com/users/surisdi", "html_url": "https://github.com/surisdi", "followers_url": "https://api.github.com/users/surisdi/followers", "following_url": "https://api.github.com/users/surisdi/following{/other_user}", "gists_url": "https://api.github.com/users/surisdi/gists{/gist_id}", "starred_url": "https://api.github.com/users/surisdi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/surisdi/subscriptions", "organizations_url": "https://api.github.com/users/surisdi/orgs", "repos_url": "https://api.github.com/users/surisdi/repos", "events_url": "https://api.github.com/users/surisdi/events{/privacy}", "received_events_url": "https://api.github.com/users/surisdi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 684873012, "node_id": "MDU6TGFiZWw2ODQ4NzMwMTI=", "url": "https://api.github.com/repos/pytorch/vision/labels/awaiting%20response", "name": "awaiting response", "color": "5319e7", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-04-29T20:28:51Z", "updated_at": "2020-05-05T16:37:11Z", "closed_at": "2020-05-05T16:37:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI cannot import `video_reader` (`io._HAS_VIDEO_OPT` is `False`).\r\n\r\nWhen `torchvision.io` is imported, and `torchvision/io/_video_opt.py` is executed, there is a `OSError` when the library `video_reader` is imported. The library is found properly.\r\n\r\nSpecifically, the `OSError` is caused in this line: `torch.ops.load_library(ext_specs.origin)`, and it is:\r\n\r\n`[...]/site-packages/torchvision-0.7.0a0+f9ef235-py3.7-linux-x86_64.egg/torchvision/video_reader.so: undefined symbol: _ZTIN6ffmpeg6StreamE`\r\n\r\nI installed torchvision from source, and the versions of the libraries are the following:\r\n\r\n`ffmpeg: 4.2.2`\r\n`torchvision: 0.7.0a0+f9ef235`\r\n`torch: 1.5.0`\r\n\r\nWhat do you think the problem could be? Thanks!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytorch/vision/issues/2161", "repository_url": "https://api.github.com/repos/pytorch/vision", "labels_url": "https://api.github.com/repos/pytorch/vision/issues/2161/labels{/name}", "comments_url": "https://api.github.com/repos/pytorch/vision/issues/2161/comments", "events_url": "https://api.github.com/repos/pytorch/vision/issues/2161/events", "html_url": "https://github.com/pytorch/vision/issues/2161", "id": 609146376, "node_id": "MDU6SXNzdWU2MDkxNDYzNzY=", "number": 2161, "title": "googlenet fires assert for not being an nn.Module with torch.jit.trace()", "user": {"login": "mneilly-et", "id": 55827703, "node_id": "MDQ6VXNlcjU1ODI3NzAz", "avatar_url": "https://avatars3.githubusercontent.com/u/55827703?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mneilly-et", "html_url": "https://github.com/mneilly-et", "followers_url": "https://api.github.com/users/mneilly-et/followers", "following_url": "https://api.github.com/users/mneilly-et/following{/other_user}", "gists_url": "https://api.github.com/users/mneilly-et/gists{/gist_id}", "starred_url": "https://api.github.com/users/mneilly-et/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mneilly-et/subscriptions", "organizations_url": "https://api.github.com/users/mneilly-et/orgs", "repos_url": "https://api.github.com/users/mneilly-et/repos", "events_url": "https://api.github.com/users/mneilly-et/events{/privacy}", "received_events_url": "https://api.github.com/users/mneilly-et/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1373818649, "node_id": "MDU6TGFiZWwxMzczODE4NjQ5", "url": "https://api.github.com/repos/pytorch/vision/labels/module:%20models", "name": "module: models", "color": "f7e101", "default": false, "description": ""}, {"id": 1388460222, "node_id": "MDU6TGFiZWwxMzg4NDYwMjIy", "url": "https://api.github.com/repos/pytorch/vision/labels/topic:%20classification", "name": "topic: classification", "color": "0e8a16", "default": false, "description": ""}, {"id": 1775338355, "node_id": "MDU6TGFiZWwxNzc1MzM4MzU1", "url": "https://api.github.com/repos/pytorch/vision/labels/torchscript", "name": "torchscript", "color": "17d180", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-29T15:25:08Z", "updated_at": "2020-04-30T15:25:18Z", "closed_at": "2020-04-30T15:24:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nTrying to trace the pretrained googlenet model with torch.jit.trace() fails with an assertion:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"./gn.py\", line 14, in <module>\r\n>     m = torch.jit.trace(model, input)\r\n>   File \"/eng/mneilly/.virtualenvs/machine_learning/lib/python3.6/site-packages/torch/jit/__init__.py\", line 875, in trace\r\n>     check_tolerance, _force_outplace, _module_class)\r\n>   File \"/eng/mneilly/.virtualenvs/machine_learning/lib/python3.6/site-packages/torch/jit/__init__.py\", line 1021, in trace_module\r\n>     module = make_module(mod, _module_class, _compilation_unit)\r\n>   File \"/eng/mneilly/.virtualenvs/machine_learning/lib/python3.6/site-packages/torch/jit/__init__.py\", line 720, in make_module\r\n>     return _module_class(mod, _compilation_unit=_compilation_unit)\r\n>   File \"/eng/mneilly/.virtualenvs/machine_learning/lib/python3.6/site-packages/torch/jit/__init__.py\", line 1884, in __init__\r\n>     tmp_module._modules[name] = make_module(submodule, TracedModule, _compilation_unit=None)\r\n>   File \"/eng/mneilly/.virtualenvs/machine_learning/lib/python3.6/site-packages/torch/jit/__init__.py\", line 720, in make_module\r\n>     return _module_class(mod, _compilation_unit=_compilation_unit)\r\n>   File \"/eng/mneilly/.virtualenvs/machine_learning/lib/python3.6/site-packages/torch/jit/__init__.py\", line 1845, in __init__\r\n>     assert(isinstance(orig, torch.nn.Module))\r\n> AssertionError\r\n\r\n\r\n## To Reproduce\r\n\r\n```\r\nimport torch\r\nimport torchvision\r\nfrom torchvision import transforms\r\nimport numpy as np\r\nfrom PIL import Image\r\n\r\npixels = np.random.rand(224, 224, 3) * 255\r\nimg = Image.fromarray(pixels.astype('uint8')).convert('RGB')\r\ninput = transforms.ToTensor()(img).unsqueeze_(0)\r\n        \r\nmodel = torchvision.models.googlenet(pretrained=True).eval()\r\nm = torch.jit.trace(model, input)\r\n```\r\n\r\n## Expected behavior\r\n\r\nModel traces successfully.\r\n\r\n## Environment\r\n\r\nPyTorch version: 1.5.0\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.2\r\n\r\nOS: CentOS Linux release 7.6.1810 (Core) \r\nGCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)\r\nCMake version: version 3.15.3\r\n\r\nPython version: 3.6\r\nIs CUDA available: Yes\r\nCUDA runtime version: Could not collect\r\nGPU models and configuration: GPU 0: Tesla T4\r\nNvidia driver version: 440.64.00\r\ncuDNN version: Could not collect\r\n\r\nVersions of relevant libraries:\r\n[pip3] numpy==1.18.2\r\n[pip3] torch==1.5.0\r\n[pip3] torch-glow==0.0.0\r\n[pip3] torchvision==0.6.0\r\n[conda] Could not collect\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}]}