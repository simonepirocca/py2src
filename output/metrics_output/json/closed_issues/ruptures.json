{"total_count": 20, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/deepcharles/ruptures/issues/37", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/37/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/37/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/37/events", "html_url": "https://github.com/deepcharles/ruptures/issues/37", "id": 654069741, "node_id": "MDU6SXNzdWU2NTQwNjk3NDE=", "number": 37, "title": "return value of predict in pelt", "user": {"login": "divyagupta25", "id": 30105023, "node_id": "MDQ6VXNlcjMwMTA1MDIz", "avatar_url": "https://avatars1.githubusercontent.com/u/30105023?v=4", "gravatar_id": "", "url": "https://api.github.com/users/divyagupta25", "html_url": "https://github.com/divyagupta25", "followers_url": "https://api.github.com/users/divyagupta25/followers", "following_url": "https://api.github.com/users/divyagupta25/following{/other_user}", "gists_url": "https://api.github.com/users/divyagupta25/gists{/gist_id}", "starred_url": "https://api.github.com/users/divyagupta25/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/divyagupta25/subscriptions", "organizations_url": "https://api.github.com/users/divyagupta25/orgs", "repos_url": "https://api.github.com/users/divyagupta25/repos", "events_url": "https://api.github.com/users/divyagupta25/events{/privacy}", "received_events_url": "https://api.github.com/users/divyagupta25/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-09T13:40:12Z", "updated_at": "2020-07-13T06:30:07Z", "closed_at": "2020-07-13T06:30:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI intend to detect change points in a uni-variate time sequence of length 49 using PELT search method. The values returned by predict are: [15, 20, 49]\r\nThe value of partition.keys() is [(0, 15), (15, 20), (20, 49)].\r\nhttps://github.com/deepcharles/ruptures/blob/1a422fc9218c5625de7ac79b333021bd0cf83516/ruptures/detection/pelt.py#L181\r\n\r\nI want to find the data points which have been detected as change points, and am not sure how to use this result. Are these indexes or positions? because they contain both 0 and 49\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/36", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/36/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/36/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/36/events", "html_url": "https://github.com/deepcharles/ruptures/issues/36", "id": 643468871, "node_id": "MDU6SXNzdWU2NDM0Njg4NzE=", "number": 36, "title": "Can CostAR handle multidimensional data?", "user": {"login": "daopingWu", "id": 35053990, "node_id": "MDQ6VXNlcjM1MDUzOTkw", "avatar_url": "https://avatars1.githubusercontent.com/u/35053990?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daopingWu", "html_url": "https://github.com/daopingWu", "followers_url": "https://api.github.com/users/daopingWu/followers", "following_url": "https://api.github.com/users/daopingWu/following{/other_user}", "gists_url": "https://api.github.com/users/daopingWu/gists{/gist_id}", "starred_url": "https://api.github.com/users/daopingWu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daopingWu/subscriptions", "organizations_url": "https://api.github.com/users/daopingWu/orgs", "repos_url": "https://api.github.com/users/daopingWu/repos", "events_url": "https://api.github.com/users/daopingWu/events{/privacy}", "received_events_url": "https://api.github.com/users/daopingWu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-23T01:55:09Z", "updated_at": "2020-06-23T07:20:39Z", "closed_at": "2020-06-23T07:20:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, thanks a lot for your work. I have one question regarding using vector autoregressive cost to detect change points. I notice in the document the input signal is required to be 1-d for CostAR. However, when I use multidimensional signals, no error occurs and change points can still be detected.  Does this mean that CostAR works as a vector autoregressive cost when the input signal is multidimensional? If not, is there any way that I can use vector autoregressive cost in ruptures?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/35", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/35/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/35/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/35/events", "html_url": "https://github.com/deepcharles/ruptures/issues/35", "id": 642523780, "node_id": "MDU6SXNzdWU2NDI1MjM3ODA=", "number": 35, "title": "High RAM consumption", "user": {"login": "hushchyn-mikhail", "id": 8237314, "node_id": "MDQ6VXNlcjgyMzczMTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/8237314?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hushchyn-mikhail", "html_url": "https://github.com/hushchyn-mikhail", "followers_url": "https://api.github.com/users/hushchyn-mikhail/followers", "following_url": "https://api.github.com/users/hushchyn-mikhail/following{/other_user}", "gists_url": "https://api.github.com/users/hushchyn-mikhail/gists{/gist_id}", "starred_url": "https://api.github.com/users/hushchyn-mikhail/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hushchyn-mikhail/subscriptions", "organizations_url": "https://api.github.com/users/hushchyn-mikhail/orgs", "repos_url": "https://api.github.com/users/hushchyn-mikhail/repos", "events_url": "https://api.github.com/users/hushchyn-mikhail/events{/privacy}", "received_events_url": "https://api.github.com/users/hushchyn-mikhail/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-21T08:53:35Z", "updated_at": "2020-06-23T07:13:53Z", "closed_at": "2020-06-23T07:13:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi all,\r\n\r\nThanks a lot for this library. It is great! However, I found that it takes a lot of RAM for large samples. For en example, Window CPD method requires about 7 GB RAM for 1D time series with 20k samples and 9 change points. And I suppose, that this leads to non-linear dependency of time from n_samples. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/33", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/33/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/33/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/33/events", "html_url": "https://github.com/deepcharles/ruptures/issues/33", "id": 642188679, "node_id": "MDU6SXNzdWU2NDIxODg2Nzk=", "number": 33, "title": "Link to documentation broken ?", "user": {"login": "ilyasst", "id": 443955, "node_id": "MDQ6VXNlcjQ0Mzk1NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/443955?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilyasst", "html_url": "https://github.com/ilyasst", "followers_url": "https://api.github.com/users/ilyasst/followers", "following_url": "https://api.github.com/users/ilyasst/following{/other_user}", "gists_url": "https://api.github.com/users/ilyasst/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilyasst/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilyasst/subscriptions", "organizations_url": "https://api.github.com/users/ilyasst/orgs", "repos_url": "https://api.github.com/users/ilyasst/repos", "events_url": "https://api.github.com/users/ilyasst/events{/privacy}", "received_events_url": "https://api.github.com/users/ilyasst/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-19T19:53:28Z", "updated_at": "2020-06-20T07:11:38Z", "closed_at": "2020-06-20T06:46:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI am trying to access the documentation of the rupture library from the README link but cannot reach it.\r\nIs the documentation still available somewhere ?\r\n\r\nCheers,\r\nIlyass", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/31", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/31/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/31/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/31/events", "html_url": "https://github.com/deepcharles/ruptures/issues/31", "id": 612710566, "node_id": "MDU6SXNzdWU2MTI3MTA1NjY=", "number": 31, "title": "calculate summary statistics per change point", "user": {"login": "bbartling", "id": 29737117, "node_id": "MDQ6VXNlcjI5NzM3MTE3", "avatar_url": "https://avatars2.githubusercontent.com/u/29737117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bbartling", "html_url": "https://github.com/bbartling", "followers_url": "https://api.github.com/users/bbartling/followers", "following_url": "https://api.github.com/users/bbartling/following{/other_user}", "gists_url": "https://api.github.com/users/bbartling/gists{/gist_id}", "starred_url": "https://api.github.com/users/bbartling/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bbartling/subscriptions", "organizations_url": "https://api.github.com/users/bbartling/orgs", "repos_url": "https://api.github.com/users/bbartling/repos", "events_url": "https://api.github.com/users/bbartling/events{/privacy}", "received_events_url": "https://api.github.com/users/bbartling/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-05T15:54:39Z", "updated_at": "2020-05-06T17:02:28Z", "closed_at": "2020-05-06T17:02:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi Charles,\r\n\r\nI recently opened in an issue using Binary Segmentation algorithm on offline electrical datasets. With pandas you helped me calculate delta time. Anyway I am still experimenting with good results and I was curious to ask if its possible to calculate (in addition to delta time) some summary statistics of the electrical demand per change point? \r\n\r\n(i think this stuff is pretty cool)\r\n\r\nFor each month (July shown below) I can randomly sample a few (with numpy random & datetime) days, and apply the Binary Segmentation algorithm. In addition to hours (delta time per change point), is it possible to retrieve the mean/stand deviation value kW per change point? \r\n\r\n![1](https://user-images.githubusercontent.com/29737117/81082864-75858500-8eb9-11ea-9d1c-7eb2df799627.PNG)\r\n![2](https://user-images.githubusercontent.com/29737117/81082878-78807580-8eb9-11ea-8eff-278f6d2028f8.PNG)\r\n![3](https://user-images.githubusercontent.com/29737117/81082885-7a4a3900-8eb9-11ea-9163-4b1ea9a6a091.PNG)\r\n\r\nI apologize for the long winded post here, as well as my at best novice python programming skills...\r\n\r\nThis is all the code used to produce the plots above. \r\n\r\n```\r\nimport pandas as pd\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nimport ruptures as rpt\r\nimport calendar\r\n\r\n#read CSV file\r\ndf = pd.read_csv('https://raw.githubusercontent.com/bbartling/Building-Demand-Electrical-Load-Profiles/master/School%202013_2014%20KW.csv', \r\n                 index_col='Date', parse_dates=True)\r\n\r\n#remove row of data where kW read zero\r\ndf = df[(df[['kW']] != 0).all(axis=1)]\r\n\r\n#metric for plotting\r\nmaxy = df.kW.max()\r\n\r\n#month of feb\r\njuly = df.loc[df.index.month.isin([7])]\r\n\r\n#metric for ruptures Binary Segmentation\r\nmetric = n_bkps=2\r\n\r\nprint(july.describe())\r\n\r\n#function for algorithm\r\ndef changPoint(df, dayNum, yTickMax, plotYesorNo):\r\n    df = df.loc[df.index.day.isin([dayNum])]\r\n    arr = np.array(df.kW)\r\n\r\n    \r\n    #Define Binary Segmentation search method\r\n    model = \"l2\"  \r\n    algo = rpt.Binseg(model=model).fit(arr)\r\n    my_bkps = algo.predict(metric)\r\n\r\n    # getting the timestamps of the change points\r\n    bkps_timestamps = df.iloc[[0] + my_bkps[:-1] +[-1]].index\r\n\r\n    # computing the durations between change points\r\n    durations = (bkps_timestamps[1:] - bkps_timestamps[:-1])\r\n    \r\n    #hours calc\r\n    d = durations.seconds/60/60\r\n    d_f = pd.DataFrame(d)\r\n    df2 = d_f.T\r\n    print(df2)\r\n    \r\n    if plotYesorNo == 'yes':\r\n      \r\n        # show results\r\n        rpt.show.display(arr, my_bkps, figsize=(17, 6))\r\n        #plot metrics\r\n        oneHrs = d_f.values[0][0]\r\n        twoHrs = d_f.values[1][0]\r\n        threeHrs = d_f.values[2][0]\r\n\r\n        one = f'morning {round(oneHrs,1)} hours'\r\n        two = f'high load {round(twoHrs,1)} hours'\r\n        three = f'evening {round(threeHrs,1)} hours'\r\n\r\n        d = df.index.day_name()[0]\r\n        m = df.index.month_name()[0]\r\n\r\n        title = f'Change Point Detection: Binary Segmentation Search Method {d} {m} {dayNum}'\r\n\r\n        plt.title(title)\r\n        plt.text(0, yTickMax/2, one)\r\n        plt.text(0, yTickMax/2-10, two)\r\n        plt.text(0, yTickMax/2-20, three)\r\n\r\n        plt.ylim(0, yTickMax)\r\n        plt.show()\r\n        \r\n    else:\r\n        return df2\r\n\r\njuly.plot(figsize=(20, 10))\r\nplt.ylim(5, maxy)\r\n\r\n#create plots\r\nchangPoint(july, np.random.randint(low=1, high=30, size=1), maxy, 'yes')\r\nchangPoint(july, np.random.randint(low=1, high=30, size=1), maxy, 'yes')\r\nchangPoint(july, np.random.randint(low=1, high=30, size=1), maxy, 'yes')\r\nchangPoint(july, np.random.randint(low=1, high=30, size=1), maxy, 'yes')\r\n```\r\nI also put this [Jupyter notebook file in the same git repo as the electrical data sets](https://github.com/bbartling/Building-Demand-Electrical-Load-Profiles).\r\n\r\n\r\nThanks for anytime you have in response.\r\nBen", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/30", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/30/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/30/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/30/events", "html_url": "https://github.com/deepcharles/ruptures/issues/30", "id": 611745651, "node_id": "MDU6SXNzdWU2MTE3NDU2NTE=", "number": 30, "title": "Some errors in the window method", "user": {"login": "yassineAlouini", "id": 8986994, "node_id": "MDQ6VXNlcjg5ODY5OTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/8986994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yassineAlouini", "html_url": "https://github.com/yassineAlouini", "followers_url": "https://api.github.com/users/yassineAlouini/followers", "following_url": "https://api.github.com/users/yassineAlouini/following{/other_user}", "gists_url": "https://api.github.com/users/yassineAlouini/gists{/gist_id}", "starred_url": "https://api.github.com/users/yassineAlouini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yassineAlouini/subscriptions", "organizations_url": "https://api.github.com/users/yassineAlouini/orgs", "repos_url": "https://api.github.com/users/yassineAlouini/repos", "events_url": "https://api.github.com/users/yassineAlouini/events{/privacy}", "received_events_url": "https://api.github.com/users/yassineAlouini/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-04T09:52:15Z", "updated_at": "2020-05-05T16:01:10Z", "closed_at": "2020-05-05T16:01:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/deepcharles/ruptures/blob/86140d08a9c210259346d7d61af713e3a65651e1/ruptures/detection/window.py#L258\r\n\r\nSome minor errors in the `predict` method of the `window` algo: penalty arg should be pen and missing epsilon. \r\n\r\nIf that works for you, I can make a PR this weekend. Let me know. :cat2: ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/29", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/29/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/29/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/29/events", "html_url": "https://github.com/deepcharles/ruptures/issues/29", "id": 608936716, "node_id": "MDU6SXNzdWU2MDg5MzY3MTY=", "number": 29, "title": "Implementing PCA based cost function", "user": {"login": "statefb", "id": 23316627, "node_id": "MDQ6VXNlcjIzMzE2NjI3", "avatar_url": "https://avatars0.githubusercontent.com/u/23316627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/statefb", "html_url": "https://github.com/statefb", "followers_url": "https://api.github.com/users/statefb/followers", "following_url": "https://api.github.com/users/statefb/following{/other_user}", "gists_url": "https://api.github.com/users/statefb/gists{/gist_id}", "starred_url": "https://api.github.com/users/statefb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/statefb/subscriptions", "organizations_url": "https://api.github.com/users/statefb/orgs", "repos_url": "https://api.github.com/users/statefb/repos", "events_url": "https://api.github.com/users/statefb/events{/privacy}", "received_events_url": "https://api.github.com/users/statefb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-29T10:14:06Z", "updated_at": "2020-05-03T06:33:56Z", "closed_at": "2020-05-03T06:33:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thank you for making this amazing library.\r\n\r\nI'm engaging in manufacturing industry and I found that PCA (Principal component analysis) based segmentation algorithm is useful for sensor data in this field.\r\n\r\nPCA based segmentation is realized by two types of cost function: Q statistics and T2 statistics.\r\nQ statistics is so-called reconstruction error of PCA and T2 is hotelling's T-squared.\r\n[Here is original paper (pp. 12-15)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.853.2380&rep=rep1&type=pdf) and it says:\r\n\r\n> The Q reconstruction error can be used to segment the time-series according to the direct change of the correlation  between  the  variables,  while  the  Hotelling's  T2  statistics  can  be  utilized  to  segment  the  time-series based on the drift of the center of the operating region. \r\n\r\nIndeed, ruptures already has mahalanobis implementation which computes cost function by using global structure i.e. inverse of covariance of entire signal. The difference is the paper's method computes inv cov matrix of each segment signal on subdimension at every iteration.\r\n\r\nI'd like to ask you if interested in adding these cost function to ruptures and accept PR.\r\nThank you in advance!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/28", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/28/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/28/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/28/events", "html_url": "https://github.com/deepcharles/ruptures/issues/28", "id": 604970392, "node_id": "MDU6SXNzdWU2MDQ5NzAzOTI=", "number": 28, "title": "Is it possible to calculate delta time?", "user": {"login": "bbartling", "id": 29737117, "node_id": "MDQ6VXNlcjI5NzM3MTE3", "avatar_url": "https://avatars2.githubusercontent.com/u/29737117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bbartling", "html_url": "https://github.com/bbartling", "followers_url": "https://api.github.com/users/bbartling/followers", "following_url": "https://api.github.com/users/bbartling/following{/other_user}", "gists_url": "https://api.github.com/users/bbartling/gists{/gist_id}", "starred_url": "https://api.github.com/users/bbartling/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bbartling/subscriptions", "organizations_url": "https://api.github.com/users/bbartling/orgs", "repos_url": "https://api.github.com/users/bbartling/repos", "events_url": "https://api.github.com/users/bbartling/events{/privacy}", "received_events_url": "https://api.github.com/users/bbartling/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-22T18:28:46Z", "updated_at": "2020-04-28T11:17:28Z", "closed_at": "2020-04-23T08:06:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \r\n\r\nI apologize in advance if this is a silly question, but I am attempting calculate in \"hours\" of electricity data daily load profiles the time it takes for rise & fall times in the data... For example this is a snip from a while paper on analyzing the data for building electricity demand.\r\n\r\n![LoadProfSnip](https://user-images.githubusercontent.com/29737117/80019155-b2568280-849c-11ea-81df-022107865d72.PNG)\r\n\r\nI think I can get sort of close using the Binary Segmentation search method [as shown in this Gist](https://gist.github.com/bbartling/17f0981ca9e37b9f5e79b648ba3a5692).\r\n\r\nCan I calculate in hours the delta time between each change point? Any tips greatly appreciated thank you for creating a cool repo!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/27", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/27/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/27/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/27/events", "html_url": "https://github.com/deepcharles/ruptures/issues/27", "id": 601572739, "node_id": "MDU6SXNzdWU2MDE1NzI3Mzk=", "number": 27, "title": "Circular Binary segmentation  ", "user": {"login": "rrazaghi", "id": 15005600, "node_id": "MDQ6VXNlcjE1MDA1NjAw", "avatar_url": "https://avatars3.githubusercontent.com/u/15005600?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rrazaghi", "html_url": "https://github.com/rrazaghi", "followers_url": "https://api.github.com/users/rrazaghi/followers", "following_url": "https://api.github.com/users/rrazaghi/following{/other_user}", "gists_url": "https://api.github.com/users/rrazaghi/gists{/gist_id}", "starred_url": "https://api.github.com/users/rrazaghi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rrazaghi/subscriptions", "organizations_url": "https://api.github.com/users/rrazaghi/orgs", "repos_url": "https://api.github.com/users/rrazaghi/repos", "events_url": "https://api.github.com/users/rrazaghi/events{/privacy}", "received_events_url": "https://api.github.com/users/rrazaghi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-16T23:03:22Z", "updated_at": "2020-04-21T06:39:00Z", "closed_at": "2020-04-21T06:37:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi Charles, and thank you for this great tool. Currently, we do not have a robust implementation of CBS in python. Do you think this is a feasible thing to implement in ruptures?\r\n\r\nThanks a lot,\r\nRoham", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/21", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/21/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/21/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/21/events", "html_url": "https://github.com/deepcharles/ruptures/issues/21", "id": 571366736, "node_id": "MDU6SXNzdWU1NzEzNjY3MzY=", "number": 21, "title": "It's now possible to install via conda. Update README", "user": {"login": "rpanai", "id": 21178372, "node_id": "MDQ6VXNlcjIxMTc4Mzcy", "avatar_url": "https://avatars0.githubusercontent.com/u/21178372?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rpanai", "html_url": "https://github.com/rpanai", "followers_url": "https://api.github.com/users/rpanai/followers", "following_url": "https://api.github.com/users/rpanai/following{/other_user}", "gists_url": "https://api.github.com/users/rpanai/gists{/gist_id}", "starred_url": "https://api.github.com/users/rpanai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rpanai/subscriptions", "organizations_url": "https://api.github.com/users/rpanai/orgs", "repos_url": "https://api.github.com/users/rpanai/repos", "events_url": "https://api.github.com/users/rpanai/events{/privacy}", "received_events_url": "https://api.github.com/users/rpanai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-02-26T13:31:15Z", "updated_at": "2020-02-27T11:25:35Z", "closed_at": "2020-02-26T14:12:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I created a conda-forge recipe and my [PR](https://github.com/conda-forge/staged-recipes/pull/10930) is merged so you can install this package with conda [link](https://anaconda.org/conda-forge/ruptures) using\r\n\r\n```\r\nconda install -c conda-forge ruptures\r\n```\r\n\r\nYou might consider to update the README accordingly.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/20", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/20/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/20/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/20/events", "html_url": "https://github.com/deepcharles/ruptures/issues/20", "id": 569962515, "node_id": "MDU6SXNzdWU1Njk5NjI1MTU=", "number": 20, "title": "pw_linear return extra dimension?", "user": {"login": "tylermanning", "id": 16857213, "node_id": "MDQ6VXNlcjE2ODU3MjEz", "avatar_url": "https://avatars2.githubusercontent.com/u/16857213?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tylermanning", "html_url": "https://github.com/tylermanning", "followers_url": "https://api.github.com/users/tylermanning/followers", "following_url": "https://api.github.com/users/tylermanning/following{/other_user}", "gists_url": "https://api.github.com/users/tylermanning/gists{/gist_id}", "starred_url": "https://api.github.com/users/tylermanning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tylermanning/subscriptions", "organizations_url": "https://api.github.com/users/tylermanning/orgs", "repos_url": "https://api.github.com/users/tylermanning/repos", "events_url": "https://api.github.com/users/tylermanning/events{/privacy}", "received_events_url": "https://api.github.com/users/tylermanning/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-24T16:14:53Z", "updated_at": "2020-02-26T14:11:24Z", "closed_at": "2020-02-26T14:11:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Why is this the case? It's kind of unexpected and is counter to the other functions where the length of the signal and number of dimensions given returns a dataset that is the same size.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/19", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/19/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/19/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/19/events", "html_url": "https://github.com/deepcharles/ruptures/issues/19", "id": 567095929, "node_id": "MDU6SXNzdWU1NjcwOTU5Mjk=", "number": 19, "title": "min_size", "user": {"login": "amessica", "id": 32812004, "node_id": "MDQ6VXNlcjMyODEyMDA0", "avatar_url": "https://avatars3.githubusercontent.com/u/32812004?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amessica", "html_url": "https://github.com/amessica", "followers_url": "https://api.github.com/users/amessica/followers", "following_url": "https://api.github.com/users/amessica/following{/other_user}", "gists_url": "https://api.github.com/users/amessica/gists{/gist_id}", "starred_url": "https://api.github.com/users/amessica/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amessica/subscriptions", "organizations_url": "https://api.github.com/users/amessica/orgs", "repos_url": "https://api.github.com/users/amessica/repos", "events_url": "https://api.github.com/users/amessica/events{/privacy}", "received_events_url": "https://api.github.com/users/amessica/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-02-18T19:03:29Z", "updated_at": "2020-02-27T11:13:42Z", "closed_at": "2020-02-27T09:19:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "min_size is not working for me  when using, for example:\r\nalgo = rpt.Window(width=10, model='l2', min_size = 40).fit(signal)\r\nmy_bkps = algo.predict(n_bkps=4)\r\n\r\nI get segments < 40 even though min_size = 40\r\nI am using a 1D time series - numpy array -  of  a stock's close prices (array length of 796) that were loaded from a CSV file into pandas dataframe such that:\r\n\r\nsignal = pandas.dataframe['close'].values", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/17", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/17/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/17/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/17/events", "html_url": "https://github.com/deepcharles/ruptures/issues/17", "id": 558836915, "node_id": "MDU6SXNzdWU1NTg4MzY5MTU=", "number": 17, "title": "Implementing c_rank cost function", "user": {"login": "TMiguelT", "id": 5019367, "node_id": "MDQ6VXNlcjUwMTkzNjc=", "avatar_url": "https://avatars1.githubusercontent.com/u/5019367?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TMiguelT", "html_url": "https://github.com/TMiguelT", "followers_url": "https://api.github.com/users/TMiguelT/followers", "following_url": "https://api.github.com/users/TMiguelT/following{/other_user}", "gists_url": "https://api.github.com/users/TMiguelT/gists{/gist_id}", "starred_url": "https://api.github.com/users/TMiguelT/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TMiguelT/subscriptions", "organizations_url": "https://api.github.com/users/TMiguelT/orgs", "repos_url": "https://api.github.com/users/TMiguelT/repos", "events_url": "https://api.github.com/users/TMiguelT/events{/privacy}", "received_events_url": "https://api.github.com/users/TMiguelT/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-03T04:38:08Z", "updated_at": "2020-02-03T08:41:59Z", "closed_at": "2020-02-03T08:41:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Thanks for your great work with this library.\r\n\r\nI notice that table 2 in the paper says that the L\u00e9vy-Leduc paper (citation 28) is implemented in `ruptures`, but it doesn't seem that a `c_rank` cost function is implemented. Is this correct?\r\n\r\nAre you interested in adding this cost function to `ruptures`? Would you accept a PR adding it?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/16", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/16/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/16/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/16/events", "html_url": "https://github.com/deepcharles/ruptures/issues/16", "id": 524380383, "node_id": "MDU6SXNzdWU1MjQzODAzODM=", "number": 16, "title": "Small window sizes throw errors", "user": {"login": "kathapand", "id": 33595918, "node_id": "MDQ6VXNlcjMzNTk1OTE4", "avatar_url": "https://avatars1.githubusercontent.com/u/33595918?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kathapand", "html_url": "https://github.com/kathapand", "followers_url": "https://api.github.com/users/kathapand/followers", "following_url": "https://api.github.com/users/kathapand/following{/other_user}", "gists_url": "https://api.github.com/users/kathapand/gists{/gist_id}", "starred_url": "https://api.github.com/users/kathapand/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kathapand/subscriptions", "organizations_url": "https://api.github.com/users/kathapand/orgs", "repos_url": "https://api.github.com/users/kathapand/repos", "events_url": "https://api.github.com/users/kathapand/events{/privacy}", "received_events_url": "https://api.github.com/users/kathapand/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-18T13:50:10Z", "updated_at": "2020-02-18T12:17:45Z", "closed_at": "2020-02-18T12:17:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\nI am using ruptures to detect change points in morphologic time series, e.g. [ts.txt](https://github.com/deepcharles/ruptures/files/3858828/ts.txt)\r\nIn my original application, the CPD method works fine. Now I am testing the influence of reduced temporal resolution and therefore simultaneously reduced window size in the change point detection. However, this throws an error when `width<10`. It is not clear to me why this should not work. Could this be a bug, that some dependent value is calculated too small? Shouldn't the calculation of median deviation work down to window sizes of >=3?\r\n\r\nMy code using [ts.txt](https://github.com/deepcharles/ruptures/files/3858828/ts.txt) is, e.g.:\r\n```\r\nimport numpy as np\r\nimport ruptures as rpt\r\nimport matplotlib.pyplot as plt\r\n\r\nts1d = np.loadtxt('ts.txt')\r\n\r\nwinsize=10 # smallest value that works\r\n# winsize=6 # throws an error\r\n\r\nalgo = rpt.Window(width=winsize, model='l1', min_size=1).fit(ts1d)\r\nbreakpoints = algo.predict(pen=1.0)\r\n\r\nrpt.show.display(ts1d, [], breakpoints,figsize=plt.figaspect(0.5))\r\nplt.show()\r\n```\r\nIf I reduce the width (winsize), the error is:\r\n\r\n```\r\n  File \"C:\\Python36\\lib\\site-packages\\ruptures\\detection\\window.py\", line 262, in predict\r\n    bkps = self._seg(n_bkps=n_bkps, pen=pen, epsilon=epsilon)\r\n  File \"C:\\Python36\\lib\\site-packages\\ruptures\\detection\\window.py\", line 175, in _seg\r\n    mode=\"wrap\")\r\n  File \"C:\\Python36\\lib\\site-packages\\scipy\\signal\\_peak_finding.py\", line 177, in argrelmax\r\n    return argrelextrema(data, np.greater, axis, order, mode)\r\n  File \"C:\\Python36\\lib\\site-packages\\scipy\\signal\\_peak_finding.py\", line 232, in argrelextrema\r\n    axis, order, mode)\r\n  File \"C:\\Python36\\lib\\site-packages\\scipy\\signal\\_peak_finding.py\", line 58, in _boolrelextrema\r\n    raise ValueError('Order must be an int >= 1')\r\nValueError: Order must be an int >= 1\r\n```\r\nI would appreciate any hint, what might be the issue here. And thanks for the useful change point detection package!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/15", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/15/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/15/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/15/events", "html_url": "https://github.com/deepcharles/ruptures/issues/15", "id": 512476033, "node_id": "MDU6SXNzdWU1MTI0NzYwMzM=", "number": 15, "title": "Weird behaviour correction when median(K) = 0 ", "user": {"login": "guillaumeGilles98", "id": 56997675, "node_id": "MDQ6VXNlcjU2OTk3Njc1", "avatar_url": "https://avatars1.githubusercontent.com/u/56997675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guillaumeGilles98", "html_url": "https://github.com/guillaumeGilles98", "followers_url": "https://api.github.com/users/guillaumeGilles98/followers", "following_url": "https://api.github.com/users/guillaumeGilles98/following{/other_user}", "gists_url": "https://api.github.com/users/guillaumeGilles98/gists{/gist_id}", "starred_url": "https://api.github.com/users/guillaumeGilles98/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guillaumeGilles98/subscriptions", "organizations_url": "https://api.github.com/users/guillaumeGilles98/orgs", "repos_url": "https://api.github.com/users/guillaumeGilles98/repos", "events_url": "https://api.github.com/users/guillaumeGilles98/events{/privacy}", "received_events_url": "https://api.github.com/users/guillaumeGilles98/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-25T11:59:27Z", "updated_at": "2020-02-14T12:17:28Z", "closed_at": "2020-02-14T12:17:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "\r\nDuring some different tests, we experiment a weird behaviour with PELT (RBF cost function)When median(K) is equal to 0, the segmentation is clearly weird : each segment have an equal length (5).To experiment this you can run the following code\r\n```python\r\nimport ruptures\r\nimport numpy as np\r\ncurve= [0, 528, 503, 0, 0, 0, 541, 542, 0, 542, 0, 0, 0, 542, \r\n             500, 530, 0, 0, 515, 0, 536, 0, 0, 539, 518, 0, 0, 530, 0, 0, \r\n             503, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \r\n             0, 0, 0]\r\ncurve = np.array(curve)\r\nalgo = ruptures.Pelt(model='rbf', min_size=1).fit(curve)\r\nseg = algo.predict(pen=1)\r\nruptures.display(curve, seg)\r\n```\r\nWhich leads to this segmentation :\r\n![rupture_error_segmentation](https://user-images.githubusercontent.com/56997675/67569577-88abe100-f72f-11e9-8059-cb59d6c147e4.png)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/10", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/10/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/10/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/10/events", "html_url": "https://github.com/deepcharles/ruptures/issues/10", "id": 461723646, "node_id": "MDU6SXNzdWU0NjE3MjM2NDY=", "number": 10, "title": "Too many changepoints returned for approximate search methods?", "user": {"login": "joelostblom", "id": 4560057, "node_id": "MDQ6VXNlcjQ1NjAwNTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/4560057?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joelostblom", "html_url": "https://github.com/joelostblom", "followers_url": "https://api.github.com/users/joelostblom/followers", "following_url": "https://api.github.com/users/joelostblom/following{/other_user}", "gists_url": "https://api.github.com/users/joelostblom/gists{/gist_id}", "starred_url": "https://api.github.com/users/joelostblom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joelostblom/subscriptions", "organizations_url": "https://api.github.com/users/joelostblom/orgs", "repos_url": "https://api.github.com/users/joelostblom/repos", "events_url": "https://api.github.com/users/joelostblom/events{/privacy}", "received_events_url": "https://api.github.com/users/joelostblom/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-06-27T20:04:54Z", "updated_at": "2019-07-01T13:41:46Z", "closed_at": "2019-07-01T10:00:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thanks for making all these changepoint detection methods available in Python!\r\n\r\nWhen I try the examples from the docs for the approximate search method, e.g. `Window().predict()`, the number of breakpoints returned is one more than the number specified. The final breakpoint is always the index of the last observation in the timeseries. For example, if I run\r\n\r\n``` python\r\nimport numpy as np\r\nimport matplotlib.pylab as plt\r\nimport ruptures as rpt\r\n# creation of data\r\nn, dim = 500, 3  # number of samples, dimension\r\nn_bkps, sigma = 3, 5  # number of change points, noise standart deviation\r\nsignal, bkps = rpt.pw_constant(n, dim, n_bkps, noise_std=sigma)\r\n\r\nmodel = \"l2\"  # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\"\r\nalgo = rpt.Window(width=40, model=model).fit(signal)\r\nmy_bkps = algo.predict(n_bkps=3)\r\nmy_bkps\r\n```\r\n\r\n`my_bkps` will actually consist of four values: `[120, 250, 375, 500]`, rather than three as specified with `n_bkps=3`. `500` is the length of `signal` in this case. Is this last returned value a real changepoint, or is it there for some other reason (e.g.\u00a0a helper value for drawing the filled areas with `show.display()`)?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/8", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/8/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/8/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/8/events", "html_url": "https://github.com/deepcharles/ruptures/issues/8", "id": 450760587, "node_id": "MDU6SXNzdWU0NTA3NjA1ODc=", "number": 8, "title": "Cost Function Examples and Documentation", "user": {"login": "dcdenu4", "id": 2659980, "node_id": "MDQ6VXNlcjI2NTk5ODA=", "avatar_url": "https://avatars3.githubusercontent.com/u/2659980?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcdenu4", "html_url": "https://github.com/dcdenu4", "followers_url": "https://api.github.com/users/dcdenu4/followers", "following_url": "https://api.github.com/users/dcdenu4/following{/other_user}", "gists_url": "https://api.github.com/users/dcdenu4/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcdenu4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcdenu4/subscriptions", "organizations_url": "https://api.github.com/users/dcdenu4/orgs", "repos_url": "https://api.github.com/users/dcdenu4/repos", "events_url": "https://api.github.com/users/dcdenu4/events{/privacy}", "received_events_url": "https://api.github.com/users/dcdenu4/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-31T11:50:57Z", "updated_at": "2020-03-03T10:12:04Z", "closed_at": "2020-03-03T10:12:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying my hand at a few of the cost functions, where I'm interested in both changing variance and mean shifts. I've been reading through the selective review paper and was interested in trying Cost function 3, which I believe is CostNormal in ruptures? Is it possible to expand on the documentation for this cost function in the Docs? For instance it's unclear to me if the second sigma term from equation C3 of the review paper is in the CostNormal function?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/7", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/7/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/7/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/7/events", "html_url": "https://github.com/deepcharles/ruptures/issues/7", "id": 444399085, "node_id": "MDU6SXNzdWU0NDQzOTkwODU=", "number": 7, "title": "Allow other plot **kwargs for show.display to be set", "user": {"login": "dcdenu4", "id": 2659980, "node_id": "MDQ6VXNlcjI2NTk5ODA=", "avatar_url": "https://avatars3.githubusercontent.com/u/2659980?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcdenu4", "html_url": "https://github.com/dcdenu4", "followers_url": "https://api.github.com/users/dcdenu4/followers", "following_url": "https://api.github.com/users/dcdenu4/following{/other_user}", "gists_url": "https://api.github.com/users/dcdenu4/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcdenu4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcdenu4/subscriptions", "organizations_url": "https://api.github.com/users/dcdenu4/orgs", "repos_url": "https://api.github.com/users/dcdenu4/repos", "events_url": "https://api.github.com/users/dcdenu4/events{/privacy}", "received_events_url": "https://api.github.com/users/dcdenu4/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-15T12:02:07Z", "updated_at": "2019-05-25T07:25:15Z", "closed_at": "2019-05-24T14:37:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "In ruptures.show.display() there is no avenue to pass along other general plotting options. While a **kwargs argument is taken in, it only sets specific elements found (which isn't clear in the docs). I would propose allowing the subplot call to eat all the extra args. I think this would be easier than having to use the returned fig or ax after the fact.\r\n\r\nbefore:\r\n`fig, axarr = plt.subplots(n_features, figsize=figsize, sharex=True)`\r\nafter:\r\n`fig, axarr = plt.subplots(n_features, figsize=figsize, sharex=True, **kwargs)`\r\n\r\nOf course this would change the way that **kwargs is currently used with setting **linewidth**, **alpha**, etc... But maybe those could be more implicit and parsed out or a separate input parameter.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/4", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/4/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/4/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/4/events", "html_url": "https://github.com/deepcharles/ruptures/issues/4", "id": 400843824, "node_id": "MDU6SXNzdWU0MDA4NDM4MjQ=", "number": 4, "title": "example setting the penalty parameter?", "user": {"login": "wqp89324", "id": 8864839, "node_id": "MDQ6VXNlcjg4NjQ4Mzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/8864839?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wqp89324", "html_url": "https://github.com/wqp89324", "followers_url": "https://api.github.com/users/wqp89324/followers", "following_url": "https://api.github.com/users/wqp89324/following{/other_user}", "gists_url": "https://api.github.com/users/wqp89324/gists{/gist_id}", "starred_url": "https://api.github.com/users/wqp89324/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wqp89324/subscriptions", "organizations_url": "https://api.github.com/users/wqp89324/orgs", "repos_url": "https://api.github.com/users/wqp89324/repos", "events_url": "https://api.github.com/users/wqp89324/events{/privacy}", "received_events_url": "https://api.github.com/users/wqp89324/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-01-18T18:44:03Z", "updated_at": "2019-03-15T10:23:37Z", "closed_at": "2019-03-15T10:23:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there an example about how to set the pen parameter for Pelt?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/deepcharles/ruptures/issues/3", "repository_url": "https://api.github.com/repos/deepcharles/ruptures", "labels_url": "https://api.github.com/repos/deepcharles/ruptures/issues/3/labels{/name}", "comments_url": "https://api.github.com/repos/deepcharles/ruptures/issues/3/comments", "events_url": "https://api.github.com/repos/deepcharles/ruptures/issues/3/events", "html_url": "https://github.com/deepcharles/ruptures/issues/3", "id": 391773880, "node_id": "MDU6SXNzdWUzOTE3NzM4ODA=", "number": 3, "title": "Online algorithms?", "user": {"login": "juliensiebert", "id": 4519149, "node_id": "MDQ6VXNlcjQ1MTkxNDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/4519149?v=4", "gravatar_id": "", "url": "https://api.github.com/users/juliensiebert", "html_url": "https://github.com/juliensiebert", "followers_url": "https://api.github.com/users/juliensiebert/followers", "following_url": "https://api.github.com/users/juliensiebert/following{/other_user}", "gists_url": "https://api.github.com/users/juliensiebert/gists{/gist_id}", "starred_url": "https://api.github.com/users/juliensiebert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/juliensiebert/subscriptions", "organizations_url": "https://api.github.com/users/juliensiebert/orgs", "repos_url": "https://api.github.com/users/juliensiebert/repos", "events_url": "https://api.github.com/users/juliensiebert/events{/privacy}", "received_events_url": "https://api.github.com/users/juliensiebert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-12-17T15:51:48Z", "updated_at": "2019-01-21T07:53:25Z", "closed_at": "2018-12-18T09:04:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi (bonjour),\r\n\r\nI am a bit of newbie in changepoint detection algorithms, I wanted to know if it is possible to use ruptures for online detection? So far I have the (probably false) impression that it focuses only on offline detection.\r\n\r\nAm I right? \r\n\r\nAll the best,\r\n\r\nJulien", "performed_via_github_app": null, "score": 1.0}]}