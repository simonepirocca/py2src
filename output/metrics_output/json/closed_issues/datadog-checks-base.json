{"total_count": 309, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/DataDog/integrations-core/issues/7350", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7350/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7350/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7350/events", "html_url": "https://github.com/DataDog/integrations-core/issues/7350", "id": 676953527, "node_id": "MDU6SXNzdWU2NzY5NTM1Mjc=", "number": 7350, "title": "gcp.redis.commands.usec_per_call has the wrong unit", "user": {"login": "alsyia", "id": 4249034, "node_id": "MDQ6VXNlcjQyNDkwMzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/4249034?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alsyia", "html_url": "https://github.com/alsyia", "followers_url": "https://api.github.com/users/alsyia/followers", "following_url": "https://api.github.com/users/alsyia/following{/other_user}", "gists_url": "https://api.github.com/users/alsyia/gists{/gist_id}", "starred_url": "https://api.github.com/users/alsyia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alsyia/subscriptions", "organizations_url": "https://api.github.com/users/alsyia/orgs", "repos_url": "https://api.github.com/users/alsyia/repos", "events_url": "https://api.github.com/users/alsyia/events{/privacy}", "received_events_url": "https://api.github.com/users/alsyia/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-11T15:05:22Z", "updated_at": "2020-08-20T12:48:11Z", "closed_at": "2020-08-20T12:48:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nWe are using GCP managed Redis (Memorystore), and it looks like `gcp.redis.commands.usec_per_call` metric's default unit is wrong: it is _seconds_ while, according to the name, Redis' doc, and also the actual values, it should be _microseconds_.\r\n\r\nI'm not sure if this is the right place to open this issue as Google Cloud Redis integration is not an agent integration, so please tell me if this issue should be somewhere else! :)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/7238", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7238/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7238/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7238/events", "html_url": "https://github.com/DataDog/integrations-core/issues/7238", "id": 668659893, "node_id": "MDU6SXNzdWU2Njg2NTk4OTM=", "number": 7238, "title": "kafka_consumer exception when kafka broker is not available", "user": {"login": "jose-ledesma", "id": 52402874, "node_id": "MDQ6VXNlcjUyNDAyODc0", "avatar_url": "https://avatars1.githubusercontent.com/u/52402874?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jose-ledesma", "html_url": "https://github.com/jose-ledesma", "followers_url": "https://api.github.com/users/jose-ledesma/followers", "following_url": "https://api.github.com/users/jose-ledesma/following{/other_user}", "gists_url": "https://api.github.com/users/jose-ledesma/gists{/gist_id}", "starred_url": "https://api.github.com/users/jose-ledesma/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jose-ledesma/subscriptions", "organizations_url": "https://api.github.com/users/jose-ledesma/orgs", "repos_url": "https://api.github.com/users/jose-ledesma/repos", "events_url": "https://api.github.com/users/jose-ledesma/events{/privacy}", "received_events_url": "https://api.github.com/users/jose-ledesma/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "FlorianVeaux", "id": 22912273, "node_id": "MDQ6VXNlcjIyOTEyMjcz", "avatar_url": "https://avatars3.githubusercontent.com/u/22912273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FlorianVeaux", "html_url": "https://github.com/FlorianVeaux", "followers_url": "https://api.github.com/users/FlorianVeaux/followers", "following_url": "https://api.github.com/users/FlorianVeaux/following{/other_user}", "gists_url": "https://api.github.com/users/FlorianVeaux/gists{/gist_id}", "starred_url": "https://api.github.com/users/FlorianVeaux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FlorianVeaux/subscriptions", "organizations_url": "https://api.github.com/users/FlorianVeaux/orgs", "repos_url": "https://api.github.com/users/FlorianVeaux/repos", "events_url": "https://api.github.com/users/FlorianVeaux/events{/privacy}", "received_events_url": "https://api.github.com/users/FlorianVeaux/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "FlorianVeaux", "id": 22912273, "node_id": "MDQ6VXNlcjIyOTEyMjcz", "avatar_url": "https://avatars3.githubusercontent.com/u/22912273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FlorianVeaux", "html_url": "https://github.com/FlorianVeaux", "followers_url": "https://api.github.com/users/FlorianVeaux/followers", "following_url": "https://api.github.com/users/FlorianVeaux/following{/other_user}", "gists_url": "https://api.github.com/users/FlorianVeaux/gists{/gist_id}", "starred_url": "https://api.github.com/users/FlorianVeaux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FlorianVeaux/subscriptions", "organizations_url": "https://api.github.com/users/FlorianVeaux/orgs", "repos_url": "https://api.github.com/users/FlorianVeaux/repos", "events_url": "https://api.github.com/users/FlorianVeaux/events{/privacy}", "received_events_url": "https://api.github.com/users/FlorianVeaux/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-07-30T12:11:01Z", "updated_at": "2020-08-03T13:47:52Z", "closed_at": "2020-08-03T13:37:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n```\r\n\u25cf datadog-agent.service - Datadog Agent\r\n   Loaded: loaded (/lib/systemd/system/datadog-agent.service; enabled; vendor preset: enabled)\r\n   Active: active (running) since Fri 2020-07-10 12:41:49 UTC; 2 weeks 5 days ago\r\n Main PID: 4207 (agent)\r\n    Tasks: 81 (limit: 4915)\r\n   CGroup: /system.slice/datadog-agent.service\r\n           \u251c\u25004207 /opt/datadog-agent/bin/agent/agent run -p /opt/datadog-agent/run/agent.pid\r\n           \u2514\u25004350 java -Xmx200m -Xms50m -classpath /opt/datadog-agent/bin/agent/dist/jmx/jmxfetch.jar org.datadog.jmxfetch.App --ipc_host localh\r\nGetting the status from the agent.\r\n\r\n\r\n===============\r\nAgent (v6.20.2)\r\n===============\r\n\r\n  Status date: 2020-07-30 12:06:32.970740 UTC\r\n  Agent start: 2020-07-10 12:41:49.938696 UTC\r\n  Pid: 4207\r\n  Go Version: go1.13.8\r\n  Python Version: 2.7.18\r\n  Build arch: amd64\r\n  Check Runners: 6\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 119\u00b5s\r\n    System UTC time: 2020-07-30 12:06:32.970740 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2020-07-10 12:38:50.000000 UTC\r\n    kernelArch: x86_64\r\n    kernelVersion: 5.3.0-1030-gcp\r\n    os: linux\r\n    platform: ubuntu\r\n    platformFamily: debian\r\n    platformVersion: 18.04\r\n    procs: 272\r\n    uptime: 3m1s\r\n    virtualizationRole: guest\r\n\r\n  Hostnames\r\n  =========\r\n    host_aliases: [kafka-broker-prod-gc-dsm-1.netlify-services]\r\n    hostname: kafka-broker-prod-gc-dsm-1\r\n    socket-fqdn: kafka-broker-prod-gc-dsm-1\r\n    socket-hostname: kafka-broker-prod-gc-dsm-1\r\n    host tags:\r\n    hostname provider: configuration\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: GCP\r\n    hostname_source: configuration\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 6, Total: 690,348\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-07-30 12:06:25.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:25.000000 UTC\r\n\r\n\r\n    disk (2.9.1)\r\n    ------------\r\n      Instance ID: disk:c8a8baa9e6351e18 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 42, Total: 4,832,478\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 39ms\r\n      Last Execution Date : 2020-07-30 12:06:22.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:22.000000 UTC\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 5, Total: 575,295\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-07-30 12:06:32.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:32.000000 UTC\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 169, Total: 19,018,597\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-07-30 12:06:24.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:24.000000 UTC\r\n\r\n\r\n    kafka_consumer (2.5.0)\r\n    ----------------------\r\n      Instance ID: kafka_consumer:c5b7b6907aa0d079 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kafka_consumer.d/conf.yaml\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 895, Total: 102,472,439\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 49ms\r\n      Last Execution Date : 2020-07-30 12:06:29.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:29.000000 UTC\r\n\r\n\r\n    kafka_healthcheck (unversioned)\r\n    -------------------------------\r\n      Instance ID: kafka_healthcheck:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kafka_healthcheck.yaml\r\n      Total Runs: 115,058\r\n      Metric Samples: Last Run: 2, Total: 230,105\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 4ms\r\n      Last Execution Date : 2020-07-30 12:06:21.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:21.000000 UTC\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 6, Total: 690,354\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-07-30 12:06:31.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:31.000000 UTC\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 17, Total: 1,956,003\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-07-30 12:06:23.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:23.000000 UTC\r\n\r\n\r\n    network (1.16.0)\r\n    ----------------\r\n      Instance ID: network:652386a5ce588ee6 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.yaml\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 37, Total: 4,257,183\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 17ms\r\n      Last Execution Date : 2020-07-30 12:06:28.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:28.000000 UTC\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 1,918\r\n      Metric Samples: Last Run: 1, Total: 1,918\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1,918\r\n      Average Execution Time : 823ms\r\n      Last Execution Date : 2020-07-30 11:56:52.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 11:56:52.000000 UTC\r\n\r\n\r\n    process (1.14.0)\r\n    ----------------\r\n      Instance ID: process:consul-template:7b99ffb7154e9afe [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/process.yaml\r\n      Total Runs: 115,058\r\n      Metric Samples: Last Run: 18, Total: 2,071,042\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 115,058\r\n      Average Execution Time : 17ms\r\n      Last Execution Date : 2020-07-30 12:06:19.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:19.000000 UTC\r\n\r\n      Instance ID: process:consul:af5c8603bacae686 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/process.yaml\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 18, Total: 2,071,060\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 115,059\r\n      Average Execution Time : 17ms\r\n      Last Execution Date : 2020-07-30 12:06:27.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:27.000000 UTC\r\n\r\n      Instance ID: process:dnsmasq:86eb00566db7abf2 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/process.yaml\r\n      Total Runs: 115,058\r\n      Metric Samples: Last Run: 18, Total: 2,071,042\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 115,058\r\n      Average Execution Time : 17ms\r\n      Last Execution Date : 2020-07-30 12:06:20.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:20.000000 UTC\r\n\r\n      Instance ID: process:filebeat:70f8103e69bd4182 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/process.yaml\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 18, Total: 2,070,707\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 115,050\r\n      Average Execution Time : 21ms\r\n      Last Execution Date : 2020-07-30 12:06:26.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:26.000000 UTC\r\n\r\n\r\n    ssl_expiration (unversioned)\r\n    ----------------------------\r\n      Instance ID: ssl_expiration:machine.crt:e24f478f7132c3fc [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ssl_expiration.yaml\r\n      Total Runs: 480\r\n      Metric Samples: Last Run: 1, Total: 480\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 2ms\r\n      Last Execution Date : 2020-07-30 11:41:52.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 11:41:52.000000 UTC\r\n\r\n\r\n    sys_net_tcp_mem (unversioned)\r\n    -----------------------------\r\n      Instance ID: sys_net_tcp_mem:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/sys_net_tcp_mem.yaml\r\n      Total Runs: 115,058\r\n      Metric Samples: Last Run: 1, Total: 115,058\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-07-30 12:06:18.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:18.000000 UTC\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 115,059\r\n      Metric Samples: Last Run: 1, Total: 115,059\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-07-30 12:06:30.000000 UTC\r\n      Last Successful Execution Date : 2020-07-30 12:06:30.000000 UTC\r\n\r\n  Python 3 Linter Warnings\r\n  =======================\r\n      kafka_healthcheck\r\n      -----------------\r\n        kafka_healthcheck.py:49:12 : print statement used (print-statement, E1601)\r\n\r\n      sys_net_tcp_mem\r\n      ---------------\r\n        sys_net_tcp_mem.py:29:72 : division w/o __future__ statement (old-division, W1619)\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    kafka\r\n      instance_name : kafka-localhost-9999\r\n      message : <no value>\r\n      metric_count : 179\r\n      service_check_count : 0\r\n      status : OK\r\n      instance_name : kafka-localhost-9999\r\n      message : <no value>\r\n      metric_count : 40\r\n      service_check_count : 0\r\n      status : OK\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 115,058\r\n    Connections: 0\r\n    Containers: 0\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 12,464\r\n    Metadata: 0\r\n    Pods: 0\r\n    Processes: 0\r\n    RTContainers: 0\r\n    RTProcesses: 0\r\n    Requeued: 2\r\n    Retried: 2\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 242,580\r\n    TimeseriesV1: 115,058\r\n\r\n  Transaction Errors\r\n  ==================\r\n    Total number: 1\r\n    Errors By Type:\r\n\r\n  HTTP Errors\r\n  ==================\r\n    Total number: 1\r\n    HTTP Errors By Code:\r\n      408: 1\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 8e752: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 8e752\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAPM Agent\r\n=========\r\n  Status: Not running or unreachable on localhost:8126.\r\n  Error: Get http://localhost:8126/debug/vars: dial tcp 127.0.0.1:8126: connect: connection refused\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 146,695,725\r\n  Dogstatsd Metric Sample: 89,864,103\r\n  Event: 1\r\n  Events Flushed: 1\r\n  Number Of Flushes: 115,058\r\n  Series Flushed: 171,107,888\r\n  Service Check: 2,419,034\r\n  Service Checks Flushed: 2,534,074\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 89,864,102\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 228,612\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 6,233,701,820\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 68,916,659\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n```\r\n\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):** Linux, GCP\r\n\r\n**Steps to reproduce the issue:**\r\n1. Stop kafka broker.\r\n2. Restart datadog agent\r\n3. kafka_consumer check will throw this error:\r\n```\r\n2020-07-10 12:39:01 UTC | CORE | ERROR | (pkg/collector/python/loader.go:228 in addExpvarConfigureError) | py.loader: could not configure check 'kafka_consumer\r\n (2.5.0)': could not invoke 'kafka_consumer' python check constructor. New constructor API returned:\r\nTraceback (most recent call last):\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/kafka_consumer/kafka_consumer.py\", line 54, in __new__\r\n    kafka_version = cls._determine_kafka_version(init_config, instance)\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/kafka_consumer/kafka_consumer.py\", line 465, in _determine_kafka_version\r\n    ssl_password=instance.get('ssl_password'),\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/kafka/client_async.py\", line 242, in __init__\r\n    self.config['api_version'] = self.check_version(timeout=check_timeout)\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/kafka/client_async.py\", line 898, in check_version\r\n    raise Errors.NoBrokersAvailable()\r\nNoBrokersAvailable: NoBrokersAvailable\r\n```\r\n4. kafka_consumer will not retry, so no metrics will  be sent\r\n\r\n**Describe the results you received:**\r\nno `kafka_consumer` metrics after this error. restarting datadog needed\r\n\r\n**Describe the results you expected:**\r\nkafka_consumer is able to recover from this failure\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/7226", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7226/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7226/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7226/events", "html_url": "https://github.com/DataDog/integrations-core/issues/7226", "id": 667121832, "node_id": "MDU6SXNzdWU2NjcxMjE4MzI=", "number": 7226, "title": "Work around to allow `exact_match: false` in Window's process integration", "user": {"login": "davidMcneil", "id": 1497626, "node_id": "MDQ6VXNlcjE0OTc2MjY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1497626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidMcneil", "html_url": "https://github.com/davidMcneil", "followers_url": "https://api.github.com/users/davidMcneil/followers", "following_url": "https://api.github.com/users/davidMcneil/following{/other_user}", "gists_url": "https://api.github.com/users/davidMcneil/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidMcneil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidMcneil/subscriptions", "organizations_url": "https://api.github.com/users/davidMcneil/orgs", "repos_url": "https://api.github.com/users/davidMcneil/repos", "events_url": "https://api.github.com/users/davidMcneil/events{/privacy}", "received_events_url": "https://api.github.com/users/davidMcneil/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 936577564, "node_id": "MDU6TGFiZWw5MzY1Nzc1NjQ=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/process", "name": "integration/process", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "albertvaka", "id": 980842, "node_id": "MDQ6VXNlcjk4MDg0Mg==", "avatar_url": "https://avatars0.githubusercontent.com/u/980842?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albertvaka", "html_url": "https://github.com/albertvaka", "followers_url": "https://api.github.com/users/albertvaka/followers", "following_url": "https://api.github.com/users/albertvaka/following{/other_user}", "gists_url": "https://api.github.com/users/albertvaka/gists{/gist_id}", "starred_url": "https://api.github.com/users/albertvaka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albertvaka/subscriptions", "organizations_url": "https://api.github.com/users/albertvaka/orgs", "repos_url": "https://api.github.com/users/albertvaka/repos", "events_url": "https://api.github.com/users/albertvaka/events{/privacy}", "received_events_url": "https://api.github.com/users/albertvaka/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "albertvaka", "id": 980842, "node_id": "MDQ6VXNlcjk4MDg0Mg==", "avatar_url": "https://avatars0.githubusercontent.com/u/980842?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albertvaka", "html_url": "https://github.com/albertvaka", "followers_url": "https://api.github.com/users/albertvaka/followers", "following_url": "https://api.github.com/users/albertvaka/following{/other_user}", "gists_url": "https://api.github.com/users/albertvaka/gists{/gist_id}", "starred_url": "https://api.github.com/users/albertvaka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albertvaka/subscriptions", "organizations_url": "https://api.github.com/users/albertvaka/orgs", "repos_url": "https://api.github.com/users/albertvaka/repos", "events_url": "https://api.github.com/users/albertvaka/events{/privacy}", "received_events_url": "https://api.github.com/users/albertvaka/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-07-28T14:30:26Z", "updated_at": "2020-07-29T15:12:17Z", "closed_at": "2020-07-29T15:04:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "Per this [comment](https://github.com/DataDog/integrations-core/blob/3fbe97799224e5ed6838b43df909fab33e8a2ab8/process/datadog_checks/process/data/conf.yaml.example#L79) and this section of the [docs](https://docs.datadoghq.com/agent/faq/windows-agent-ddagent-user/#process-check) setting the process integrations `exact_match` to `false` no longer works on Windows. Is there any work around to allow regex search of processes on Windows?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/7074", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7074/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7074/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7074/events", "html_url": "https://github.com/DataDog/integrations-core/issues/7074", "id": 652405121, "node_id": "MDU6SXNzdWU2NTI0MDUxMjE=", "number": 7074, "title": "Istio 1.5+ Dashboard - what is purpose of \"Average request latency by host\" graph", "user": {"login": "matthew-walters", "id": 31373947, "node_id": "MDQ6VXNlcjMxMzczOTQ3", "avatar_url": "https://avatars0.githubusercontent.com/u/31373947?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthew-walters", "html_url": "https://github.com/matthew-walters", "followers_url": "https://api.github.com/users/matthew-walters/followers", "following_url": "https://api.github.com/users/matthew-walters/following{/other_user}", "gists_url": "https://api.github.com/users/matthew-walters/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthew-walters/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthew-walters/subscriptions", "organizations_url": "https://api.github.com/users/matthew-walters/orgs", "repos_url": "https://api.github.com/users/matthew-walters/repos", "events_url": "https://api.github.com/users/matthew-walters/events{/privacy}", "received_events_url": "https://api.github.com/users/matthew-walters/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-07T15:12:41Z", "updated_at": "2020-07-29T12:21:24Z", "closed_at": "2020-07-29T12:21:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "This graph is using query\r\n\r\n\r\n`top(avg:istio.mesh.request.duration.milliseconds.sum{$cluster} by {host}, 10, 'mean', 'desc') / top(avg:istio.mesh.request.duration.milliseconds.count{$cluster} by {host}, 10, 'mean', 'desc')`\r\n\r\nBut since it's dividing milliseconds by milliseconds, then isn't this some dimensionless number, rather than one that calculates request latency in ms per host (which is what one would assume from the title) ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/7051", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7051/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7051/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/7051/events", "html_url": "https://github.com/DataDog/integrations-core/issues/7051", "id": 649992127, "node_id": "MDU6SXNzdWU2NDk5OTIxMjc=", "number": 7051, "title": " Error running check couch: [{\"message\": \"Unable to talk to the server: HTTPConnectionPool(host='10.0.1.137', port=5984)", "user": {"login": "4n70w4", "id": 38257723, "node_id": "MDQ6VXNlcjM4MjU3NzIz", "avatar_url": "https://avatars3.githubusercontent.com/u/38257723?v=4", "gravatar_id": "", "url": "https://api.github.com/users/4n70w4", "html_url": "https://github.com/4n70w4", "followers_url": "https://api.github.com/users/4n70w4/followers", "following_url": "https://api.github.com/users/4n70w4/following{/other_user}", "gists_url": "https://api.github.com/users/4n70w4/gists{/gist_id}", "starred_url": "https://api.github.com/users/4n70w4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/4n70w4/subscriptions", "organizations_url": "https://api.github.com/users/4n70w4/orgs", "repos_url": "https://api.github.com/users/4n70w4/repos", "events_url": "https://api.github.com/users/4n70w4/events{/privacy}", "received_events_url": "https://api.github.com/users/4n70w4/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 936565414, "node_id": "MDU6TGFiZWw5MzY1NjU0MTQ=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/couch", "name": "integration/couch", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-02T13:47:43Z", "updated_at": "2020-08-03T08:30:29Z", "closed_at": "2020-08-03T08:30:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "```bash\r\nDOCKER_CONTENT_TRUST=1 docker run -d --name dd-agent -v /var/run/docker.sock:/var/run/docker.sock:ro -v /proc/:/host/proc/:ro -v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro -e DD_API_KEY=<DATADOG_API_KEY> datadog/agent:7\r\n```\r\n\r\n```\r\n[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\r\n[s6-init] ensuring user provided files have correct perms...exited 0.\r\n[fix-attrs.d] applying ownership & permissions fixes...\r\n[fix-attrs.d] done.\r\n[cont-init.d] executing container initialization scripts...\r\n[cont-init.d] 01-check-apikey.sh: executing...\r\n[cont-init.d] 01-check-apikey.sh: exited 0.\r\n[cont-init.d] 50-cri.sh: executing...\r\n[cont-init.d] 50-cri.sh: exited 0.\r\n[cont-init.d] 50-ecs.sh: executing...\r\n[cont-init.d] 50-ecs.sh: exited 0.\r\n[cont-init.d] 50-eks.sh: executing...\r\n[cont-init.d] 50-eks.sh: exited 0.\r\n[cont-init.d] 50-kubernetes.sh: executing...\r\n[cont-init.d] 50-kubernetes.sh: exited 0.\r\n[cont-init.d] 50-mesos.sh: executing...\r\n[cont-init.d] 50-mesos.sh: exited 0.\r\n[cont-init.d] 51-docker.sh: executing...\r\n[cont-init.d] 51-docker.sh: exited 0.\r\n[cont-init.d] 59-defaults.sh: executing...\r\n[cont-init.d] 59-defaults.sh: exited 0.\r\n[cont-init.d] 60-network-check.sh: executing...\r\n[cont-init.d] 60-network-check.sh: exited 0.\r\n[cont-init.d] 89-copy-customfiles.sh: executing...\r\n[cont-init.d] 89-copy-customfiles.sh: exited 0.\r\n[cont-init.d] done.\r\n[services.d] starting services\r\nstarting trace-agent\r\nstarting system-probe\r\nstarting agent\r\nstarting process-agent\r\n[services.d] done.\r\n2020-07-02 13:43:10 UTC | CORE | INFO | (cmd/agent/app/run.go:179 in StartAgent) | Starting Datadog Agent v7.20.2\r\n2020-07-02 13:43:10 UTC | SYS-PROBE | INFO | (pkg/util/log/log.go:482 in func1) | no config exists at /etc/datadog-agent/system-probe.yaml, ignoring...\r\n2020-07-02 13:43:10 UTC | SYS-PROBE | INFO | (pkg/util/log/log.go:482 in func1) | overriding API key from env DD_API_KEY value\r\n2020-07-02 13:43:10 UTC | SYS-PROBE | INFO | (cmd/system-probe/main_common.go:73 in runAgent) | system probe not enabled. exiting.\r\n2020-07-02 13:43:10 UTC | PROCESS | INFO | (pkg/util/log/log.go:482 in func1) | Collector docker successfully detected\r\n2020-07-02 13:43:10 UTC | PROCESS | INFO | (pkg/util/log/log.go:482 in func1) | Using collector docker\r\n2020-07-02 13:43:10 UTC | PROCESS | INFO | (pkg/util/log/log.go:482 in func1) | overriding API key from env DD_API_KEY value\r\n2020-07-02 13:43:10 UTC | PROCESS | WARN | (pkg/util/log/log.go:491 in func1) | failed to get configuration value for key \"process_config.container_source\": unable to cast <nil> of type <nil> to []string\r\n2020-07-02 13:43:10 UTC | PROCESS | INFO | (pkg/process/config/config.go:261 in loadConfigIfExists) | no config exists at /etc/datadog-agent/system-probe.yaml, ignoring...\r\n2020-07-02 13:43:10 UTC | PROCESS | INFO | (pkg/process/config/config.go:418 in loadEnvVariables) | overriding API key from env DD_API_KEY value\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (cmd/agent/app/run.go:210 in StartAgent) | Hostname is: chanson\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (pkg/api/security/security.go:145 in fetchAuthToken) | Saved a new authentication token to /etc/datadog-agent/auth_token\r\n2020-07-02 13:43:12 UTC | TRACE | INFO | (pkg/util/log/log.go:482 in func1) | Loaded configuration: /etc/datadog-agent/datadog.yaml\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (cmd/agent/app/run.go:240 in StartAgent) | GUI server port -1 specified: not starting the GUI.\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (pkg/forwarder/forwarder.go:249 in Start) | Forwarder started, sending to 1 endpoint(s) with 1 worker(s) each: \"https://7-20-2-app.agent.datadoghq.eu\" (1 api key(s))\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (cmd/agent/app/run.go:285 in StartAgent) | logs-agent disabled\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (cmd/agent/app/run.go:289 in StartAgent) | System probe config not found, disabling pulling system probe info in the status page: open /etc/datadog-agent/system-probe.yaml: no such file or directory\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (pkg/dogstatsd/listeners/udp.go:97 in Listen) | dogstatsd-udp: starting to listen on 127.0.0.1:8125\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (pkg/tagger/tagger.go:152 in tryCollectors) | docker tag collector successfully started\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (pkg/collector/runner/runner.go:92 in NewRunner) | Runner started with 4 workers.\r\n2020-07-02 13:43:12 UTC | CORE | INFO | (pkg/collector/python/init.go:303 in Initialize) | Initializing rtloader with python3 /opt/datadog-agent/embedded\r\n2020-07-02 13:43:13 UTC | PROCESS | INFO | (main_common.go:106 in runAgent) | running on platform: linux-4.15.0-106-generic-x86_64-with-glibc2.2.5\r\n2020-07-02 13:43:13 UTC | PROCESS | INFO | (main_common.go:109 in runAgent) | running version: Version: 7.20.2, Git hash: 621dfb0, Git branch: HEAD, Build date: 2020-06-17T10:20:06, Go Version: go version go1.13.8 linux/amd64,\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (ddyaml.py:123) | monkey patching yaml.load...\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (ddyaml.py:127) | monkey patching yaml.load_all...\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (ddyaml.py:131) | monkey patching yaml.dump_all... (affects all yaml dump operations)\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (pkg/collector/collector.go:57 in NewCollector) | Embedding Python 3.8.1 (default, Jun 17 2020, 10:18:51) [GCC 4.7.2]\r\n2020-07-02 13:43:13 UTC | TRACE | INFO | (pkg/tagger/tagger.go:152 in tryCollectors) | docker tag collector successfully started\r\n2020-07-02 13:43:13 UTC | TRACE | INFO | (pkg/trace/agent/run.go:118 in Run) | Trace agent running on host chanson\r\n2020-07-02 13:43:13 UTC | TRACE | INFO | (pkg/trace/api/api.go:154 in Start) | Listening for traces at http://0.0.0.0:8126\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (cmd/agent/common/autoconfig.go:71 in SetupAutoConfig) | Registering docker config provider polled every 1s\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (pkg/autodiscovery/autoconfig.go:351 in initListenerCandidates) | docker listener successfully started\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (pkg/autodiscovery/providers/file.go:74 in Collect) | file: searching for configuration files at: /etc/datadog-agent/conf.d\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (pkg/autodiscovery/providers/file.go:74 in Collect) | file: searching for configuration files at: /opt/datadog-agent/bin/agent/dist/conf.d\r\n2020-07-02 13:43:13 UTC | CORE | WARN | (pkg/autodiscovery/providers/file.go:78 in Collect) | Skipping, open /opt/datadog-agent/bin/agent/dist/conf.d: no such file or directory\r\n2020-07-02 13:43:13 UTC | CORE | INFO | (pkg/autodiscovery/providers/file.go:74 in Collect) | file: searching for configuration files at:\r\n2020-07-02 13:43:13 UTC | CORE | WARN | (pkg/autodiscovery/providers/file.go:78 in Collect) | Skipping, open : no such file or directory\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check couch with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check cpu with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check disk with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check docker with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check file_handle with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check io with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check load with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check memory with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check network with an interval of 15s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check ntp with an interval of 15m0s\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check uptime with an interval of 15s\r\n2020-07-02 13:43:14 UTC | PROCESS | INFO | (pkg/tagger/tagger.go:152 in tryCollectors) | docker tag collector successfully started\r\n2020-07-02 13:43:14 UTC | CORE | INFO | (pkg/util/cloudprovider.go:48 in DetectCloudProvider) | No cloud provider detected\r\n2020-07-02 13:43:15 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check couch\r\n2020-07-02 13:43:15 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check ntp\r\n2020-07-02 13:43:15 UTC | PROCESS | INFO | (pkg/process/checks/container.go:43 in Init) | no network ID detected: could not detect network ID\r\n2020-07-02 13:43:15 UTC | PROCESS | INFO | (collector.go:175 in run) | Starting process-agent for host=chanson, endpoints=[https://process.datadoghq.eu], orchestrator endpoints=[https://orchestrator.datadoghq.eu], enabled checks=[container rtcontainer]\r\n2020-07-02 13:43:15 UTC | PROCESS | INFO | (pkg/forwarder/forwarder.go:249 in Start) | Forwarder started, sending to 1 endpoint(s) with 1 worker(s) each: \"https://process.datadoghq.eu\" (1 api key(s))\r\n2020-07-02 13:43:15 UTC | PROCESS | INFO | (pkg/forwarder/forwarder.go:249 in Start) | Forwarder started, sending to 1 endpoint(s) with 1 worker(s) each: \"https://orchestrator.datadoghq.eu\" (1 api key(s))\r\n2020-07-02 13:43:15 UTC | PROCESS | INFO | (collector.go:157 in runCheck) | Finished container check DataDog/datadog-agent#1 in 16.302293ms\r\nsystem-probe exited with code 0, disabling\r\n2020-07-02 13:43:18 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check uptime\r\n2020-07-02 13:43:18 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check uptime\r\n2020-07-02 13:43:19 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check memory\r\n2020-07-02 13:43:19 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check memory\r\n2020-07-02 13:43:19 UTC | CORE | INFO | (pkg/metadata/host/host.go:186 in getNetworkMeta) | could not get network metadata: could not detect network ID\r\n2020-07-02 13:43:19 UTC | CORE | INFO | (pkg/serializer/serializer.go:346 in SendMetadata) | Sent metadata payload, size (raw/compressed): 2745/1208 bytes.\r\n2020-07-02 13:43:19 UTC | CORE | INFO | (pkg/forwarder/transaction.go:272 in internalProcess) | Successfully posted payload to \"https://7-20-2-app.agent.datadoghq.eu/intake/?api_key=*************************b74af\", the agent will only log transaction success every 500 transactions\r\n2020-07-02 13:43:20 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check io\r\n2020-07-02 13:43:20 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check io\r\n2020-07-02 13:43:20 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check ntp\r\n2020-07-02 13:43:21 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check docker\r\n2020-07-02 13:43:21 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check docker\r\n2020-07-02 13:43:22 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check cpu\r\n2020-07-02 13:43:22 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check cpu\r\n2020-07-02 13:43:23 UTC | TRACE | INFO | (pkg/trace/info/stats.go:101 in LogStats) | No data received\r\n2020-07-02 13:43:25 UTC | CORE | ERROR | (pkg/collector/runner/runner.go:292 in work) | Error running check couch: [{\"message\": \"Unable to talk to the server: HTTPConnectionPool(host='10.0.1.137', port=5984): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f560c363c70>, 'Connection to 10.0.1.137 timed out. (connect timeout=10.0)'))\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connection.py\\\", line 159, in _new_conn\\n    conn = connection.create_connection(\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/util/connection.py\\\", line 84, in create_connection\\n    raise err\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/util/connection.py\\\", line 74, in create_connection\\n    sock.connect(sa)\\nsocket.timeout: timed out\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connectionpool.py\\\", line 670, in urlopen\\n    httplib_response = self._make_request(\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connectionpool.py\\\", line 392, in _make_request\\n    conn.request(method, url, **httplib_request_kw)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\\\", line 1230, in request\\n    self._send_request(method, url, body, headers, encode_chunked)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\\\", line 1276, in _send_request\\n    self.endheaders(body, encode_chunked=encode_chunked)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\\\", line 1225, in endheaders\\n    self._send_output(message_body, encode_chunked=encode_chunked)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\\\", line 1004, in _send_output\\n    self.send(msg)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\\\", line 944, in send\\n    self.connect()\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connection.py\\\", line 187, in connect\\n    conn = self._new_conn()\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connection.py\\\", line 164, in _new_conn\\n    raise ConnectTimeoutError(\\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7f560c363c70>, 'Connection to 10.0.1.137 timed out. (connect timeout=10.0)')\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/adapters.py\\\", line 439, in send\\n    resp = conn.urlopen(\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connectionpool.py\\\", line 724, in urlopen\\n    retries = retries.increment(\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/util/retry.py\\\", line 439, in increment\\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='10.0.1.137', port=5984): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f560c363c70>, 'Connection to 10.0.1.137 timed out. (connect timeout=10.0)'))\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/couch/couch.py\\\", line 70, in check\\n    version = self.get(self.get_server(instance), tags, True)['version']\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/couch/couch.py\\\", line 38, in get\\n    r = self.http.get(url, headers=request_headers)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/utils/http.py\\\", line 283, in get\\n    return self._request('get', url, options)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/utils/http.py\\\", line 325, in _request\\n    return getattr(requests, method)(url, **new_options)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/api.py\\\", line 75, in get\\n    return request('get', url, params=params, **kwargs)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/api.py\\\", line 60, in request\\n    return session.request(method=method, url=url, **kwargs)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/sessions.py\\\", line 533, in request\\n    resp = self.send(prep, **send_kwargs)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/sessions.py\\\", line 646, in send\\n    r = adapter.send(request, **kwargs)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/adapters.py\\\", line 504, in send\\n    raise ConnectTimeout(e, request=request)\\nrequests.exceptions.ConnectTimeout: HTTPConnectionPool(host='10.0.1.137', port=5984): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f560c363c70>, 'Connection to 10.0.1.137 timed out. (connect timeout=10.0)'))\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\\\", line 822, in run\\n    self.check(instance)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/couch/couch.py\\\", line 77, in check\\n    raise errors.ConnectionError(\\\"Unable to talk to the server: {}\\\".format(e))\\ndatadog_checks.couch.errors.ConnectionError: Unable to talk to the server: HTTPConnectionPool(host='10.0.1.137', port=5984): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f560c363c70>, 'Connection to 10.0.1.137 timed out. (connect timeout=10.0)'))\\n\"}]\r\n2020-07-02 13:43:25 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check couch\r\n2020-07-02 13:43:25 UTC | PROCESS | INFO | (collector.go:157 in runCheck) | Finished container check DataDog/datadog-agent#2 in 50.781367ms\r\n2020-07-02 13:43:25 UTC | PROCESS | INFO | (pkg/forwarder/transaction.go:272 in internalProcess) | Successfully posted payload to \"https://process.datadoghq.eu/api/v1/container\", the agent will only log transaction success every 500 transactions\r\n2020-07-02 13:43:26 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check network\r\n2020-07-02 13:43:26 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check network\r\n2020-07-02 13:43:27 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check load\r\n2020-07-02 13:43:27 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check load\r\n2020-07-02 13:43:28 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check file_handle\r\n2020-07-02 13:43:28 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check file_handle\r\n2020-07-02 13:43:29 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check disk\r\n2020-07-02 13:43:29 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check disk\r\n2020-07-02 13:43:30 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check couch\r\n2020-07-02 13:43:33 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check uptime\r\n2020-07-02 13:43:33 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check uptime\r\n2020-07-02 13:43:34 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check memory\r\n2020-07-02 13:43:34 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check memory\r\n2020-07-02 13:43:35 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check io\r\n2020-07-02 13:43:35 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check io\r\n2020-07-02 13:43:35 UTC | PROCESS | INFO | (collector.go:157 in runCheck) | Finished container check DataDog/datadog-agent#3 in 46.509579ms\r\n2020-07-02 13:43:36 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check docker\r\n2020-07-02 13:43:36 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check docker\r\n2020-07-02 13:43:37 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check cpu\r\n2020-07-02 13:43:37 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check cpu\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6974", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6974/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6974/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6974/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6974", "id": 645655099, "node_id": "MDU6SXNzdWU2NDU2NTUwOTk=", "number": 6974, "title": "What is the `use_psycopg2` setting refering too?", "user": {"login": "bhmayer", "id": 33523200, "node_id": "MDQ6VXNlcjMzNTIzMjAw", "avatar_url": "https://avatars1.githubusercontent.com/u/33523200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bhmayer", "html_url": "https://github.com/bhmayer", "followers_url": "https://api.github.com/users/bhmayer/followers", "following_url": "https://api.github.com/users/bhmayer/following{/other_user}", "gists_url": "https://api.github.com/users/bhmayer/gists{/gist_id}", "starred_url": "https://api.github.com/users/bhmayer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bhmayer/subscriptions", "organizations_url": "https://api.github.com/users/bhmayer/orgs", "repos_url": "https://api.github.com/users/bhmayer/repos", "events_url": "https://api.github.com/users/bhmayer/events{/privacy}", "received_events_url": "https://api.github.com/users/bhmayer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-25T15:27:26Z", "updated_at": "2020-06-25T17:07:20Z", "closed_at": "2020-06-25T17:07:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "I can't seem to find what this setting is referring too?  Is it still up to date? \r\n\r\nWhat is it using by default if `use_psycopg2` is not set?\r\n\r\nThanks!\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/f1d8118c107d02603a2addaa7207f424493844a0/postgres/datadog_checks/postgres/data/conf.yaml.example#L20", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6956", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6956/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6956/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6956/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6956", "id": 643979974, "node_id": "MDU6SXNzdWU2NDM5Nzk5NzQ=", "number": 6956, "title": "[redisdb] checks autodiscovery fail", "user": {"login": "chan43999", "id": 24863606, "node_id": "MDQ6VXNlcjI0ODYzNjA2", "avatar_url": "https://avatars2.githubusercontent.com/u/24863606?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chan43999", "html_url": "https://github.com/chan43999", "followers_url": "https://api.github.com/users/chan43999/followers", "following_url": "https://api.github.com/users/chan43999/following{/other_user}", "gists_url": "https://api.github.com/users/chan43999/gists{/gist_id}", "starred_url": "https://api.github.com/users/chan43999/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chan43999/subscriptions", "organizations_url": "https://api.github.com/users/chan43999/orgs", "repos_url": "https://api.github.com/users/chan43999/repos", "events_url": "https://api.github.com/users/chan43999/events{/privacy}", "received_events_url": "https://api.github.com/users/chan43999/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-23T16:27:20Z", "updated_at": "2020-06-26T09:23:29Z", "closed_at": "2020-06-26T09:23:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Summary**\r\nDatadog agent does not auto discover the `redisdb` checks when doing auto discovery by pod annotation with instance config `password: \"%%env_REDIS_PASSWORD%%\"`\r\n\r\n**Steps to reproduce the issue:**\r\nKubernetes Cluster version: 1.16.9\r\nDatadog agent Chart version: 2.0.4\r\n1. Install the datadog daemonset using this helm chart [https://github.com/helm/charts/tree/master/stable/datadog](url)\r\n2. Install redis by using this helm chart [https://github.com/bitnami/charts/tree/master/bitnami/redis](url) \r\nand supply the below datadog discovery annotations through helm value files\r\n```\r\nmaster.podAnnotations: {\r\n    ad.datadoghq.com/redis.check_names: '[\"redisdb\"]'\r\n    ad.datadoghq.com/redis.init_configs: '[{}]'\r\n    ad.datadoghq.com/redis.instances: |\r\n      [\r\n        {\r\n          \"host\": \"%%host%%\",\r\n          \"port\":\"6379\",\r\n          \"password\":\"%%env_REDIS_PASSWORD%%\"\r\n        }\r\n      ]\r\n }\r\n```\r\n3. use `kubectx exec -it <POD_NAME> sh ` to execute into the shell of the datadog agent on the same node as the redis pod\r\n4. execute `agent status` command\r\n\r\n**Actual Result:**\r\nI cannot see and `redis` check info display on the agent status\r\n\r\n**Expected:**\r\nIf the auto discover successful I must be able to see that the agent discover the redis pod\r\n<img width=\"771\" alt=\"Screen Shot 2563-06-23 at 23 20 41\" src=\"https://user-images.githubusercontent.com/24863606/85429037-51385180-b5a8-11ea-95f7-6997910c3615.png\">\r\n\r\n\r\n\r\n**Additional information:**\r\n1. Although i also try to use `agent configcheck` command but still could not see any information regard to the redis check\r\n\r\n2. However, when i try to hard code the redis password to the annotation for example:\r\n```\r\nmaster.podAnnotations: {\r\n    ad.datadoghq.com/redis.check_names: '[\"redisdb\"]'\r\n    ad.datadoghq.com/redis.init_configs: '[{}]'\r\n    ad.datadoghq.com/redis.instances: |\r\n      [\r\n        {\r\n          \"host\": \"%%host%%\",\r\n          \"port\":\"6379\",\r\n          \"password\":\"123456\"\r\n        }\r\n      ]\r\n }\r\n```\r\n\r\nSuddenly the auto discovery of the redis check work and the information of the check/discovery appear when I execute `agent status` and `agent cofigcheck`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6875", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6875/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6875/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6875/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6875", "id": 637101333, "node_id": "MDU6SXNzdWU2MzcxMDEzMzM=", "number": 6875, "title": "redisdb version 2.1.0 part of datadog-agent-7.20 is causing redis check to fail.", "user": {"login": "neb14", "id": 5797326, "node_id": "MDQ6VXNlcjU3OTczMjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/5797326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neb14", "html_url": "https://github.com/neb14", "followers_url": "https://api.github.com/users/neb14/followers", "following_url": "https://api.github.com/users/neb14/following{/other_user}", "gists_url": "https://api.github.com/users/neb14/gists{/gist_id}", "starred_url": "https://api.github.com/users/neb14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neb14/subscriptions", "organizations_url": "https://api.github.com/users/neb14/orgs", "repos_url": "https://api.github.com/users/neb14/repos", "events_url": "https://api.github.com/users/neb14/events{/privacy}", "received_events_url": "https://api.github.com/users/neb14/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-11T15:16:15Z", "updated_at": "2020-06-15T15:01:16Z", "closed_at": "2020-06-11T16:40:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\n2020-06-11 15:08:05 UTC | CORE | ERROR | (pkg/collector/runner/runner.go:292 in work) | Error running check redisdb: [{\"message\": \"unknown command 'CLIENT'\", \"traceback\": \"Traceback (most recent call last):\r\nFile \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\\\", line 822, in run\r\nself.check(instance)\r\nFile \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/redisdb/redisdb.py \\\", line 493, in check\r\nself._check_db()\r\nFile \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/redisdb/redisdb.py\\\", line 252, in _check_db\r\n clients = conn.client_list()\r\nFile \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/redis/client.py\\\", line 926, in client_list\r\nreturn self.execute_command('CLIENT LIST')\r\nFile \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/redis/client.py\\\", line 839, in execute_command\r\nreturn self.parse_response(conn, command_name, **options)\r\nFile \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/redis/client.py\\\", line 853, in parse_response\r\nresponse = connection.read_response()\r\nFile \\\"/opt/datadog-agent/embedded/lib/python4.8/site-packages/redis/connection.py\\\", line 718, in read_response\r\nraise response\\nredis.exceptions.ResponseError: unknown command 'CLIENT'\\n\"}]\r\n```\r\n\r\nReverting to datadog-agent-7.19.2 which uses version 2.0.2 of redisdb corrects the issue.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6858", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6858/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6858/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6858/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6858", "id": 635709442, "node_id": "MDU6SXNzdWU2MzU3MDk0NDI=", "number": 6858, "title": "ssh_check documentation references the wrong integration name", "user": {"login": "tylergohl", "id": 414608, "node_id": "MDQ6VXNlcjQxNDYwOA==", "avatar_url": "https://avatars3.githubusercontent.com/u/414608?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tylergohl", "html_url": "https://github.com/tylergohl", "followers_url": "https://api.github.com/users/tylergohl/followers", "following_url": "https://api.github.com/users/tylergohl/following{/other_user}", "gists_url": "https://api.github.com/users/tylergohl/gists{/gist_id}", "starred_url": "https://api.github.com/users/tylergohl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tylergohl/subscriptions", "organizations_url": "https://api.github.com/users/tylergohl/orgs", "repos_url": "https://api.github.com/users/tylergohl/repos", "events_url": "https://api.github.com/users/tylergohl/events{/privacy}", "received_events_url": "https://api.github.com/users/tylergohl/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-09T19:42:10Z", "updated_at": "2020-06-09T20:09:16Z", "closed_at": "2020-06-09T20:09:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The `ssh_check` documentation currently indicates to use `ssh` as the integration name for containerized configurations, however the correct integration name is `ssh_check` ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6778", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6778/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6778/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6778/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6778", "id": 628265321, "node_id": "MDU6SXNzdWU2MjgyNjUzMjE=", "number": 6778, "title": "Squid Integration fails if httpd_suppress_version_string is off", "user": {"login": "etherandrius", "id": 20625511, "node_id": "MDQ6VXNlcjIwNjI1NTEx", "avatar_url": "https://avatars0.githubusercontent.com/u/20625511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/etherandrius", "html_url": "https://github.com/etherandrius", "followers_url": "https://api.github.com/users/etherandrius/followers", "following_url": "https://api.github.com/users/etherandrius/following{/other_user}", "gists_url": "https://api.github.com/users/etherandrius/gists{/gist_id}", "starred_url": "https://api.github.com/users/etherandrius/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/etherandrius/subscriptions", "organizations_url": "https://api.github.com/users/etherandrius/orgs", "repos_url": "https://api.github.com/users/etherandrius/repos", "events_url": "https://api.github.com/users/etherandrius/events{/privacy}", "received_events_url": "https://api.github.com/users/etherandrius/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-01T08:54:07Z", "updated_at": "2020-06-26T16:04:39Z", "closed_at": "2020-06-26T16:04:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\nSquid integration fails if Squid is configured to suppress version string.\r\nSeems to only happen if datadog-agent is running as a DaemonSet\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n**Steps to reproduce the issue:**\r\n1. Datadog-agent running as a pod\r\n2. Running Squid with `httpd_suppress_version_string off` \r\n3. Will result in the squid check error.\r\n\r\n**Describe the results you received:**\r\nError (from agent status):\r\n```\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\", line 820, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/squid/squid.py\", line 83, in check\r\n          counters = self.get_counters(host, port, tags + custom_tags)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/squid/squid.py\", line 97, in get_counters\r\n          self.submit_version(headers)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/squid/squid.py\", line 144, in submit_version\r\n          self.log.debug(\"Squid version is unknown: %\", server_version)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 1785, in debug\r\n          self.log(DEBUG, msg, *args, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 1829, in log\r\n          self.logger.log(level, msg, *args, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 1500, in log\r\n          self._log(level, msg, args, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 1577, in _log\r\n          self.handle(record)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 1587, in handle\r\n          self.callHandlers(record)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 1649, in callHandlers\r\n          hdlr.handle(record)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 950, in handle\r\n          self.emit(record)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/log.py\", line 85, in emit\r\n          message = self.format(record)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 925, in format\r\n          return fmt.format(record)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/log.py\", line 62, in format\r\n          message = to_native_string(super(CheckLogFormatter, self).format(record))\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 664, in format\r\n          record.message = record.getMessage()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/logging/__init__.py\", line 369, in getMessage\r\n          msg = msg % self.args\r\n      ValueError: incomplete format\r\n```\r\n\r\n**Describe the results you expected:**\r\nThe check to work as if `httpd_suppress_version_string` is set to `on`\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nThis only seems to happen when datadog-agent is running as a pod rather than as a service on the machine. We caught this issue during a migration from service to pod.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6753", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6753/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6753/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6753/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6753", "id": 625668637, "node_id": "MDU6SXNzdWU2MjU2Njg2Mzc=", "number": 6753, "title": "Consul checks failing with ACL and TLS enabled when using K8s Autodiscovery and Secrets Management", "user": {"login": "krzysztof-miemiec", "id": 396693, "node_id": "MDQ6VXNlcjM5NjY5Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/396693?v=4", "gravatar_id": "", "url": "https://api.github.com/users/krzysztof-miemiec", "html_url": "https://github.com/krzysztof-miemiec", "followers_url": "https://api.github.com/users/krzysztof-miemiec/followers", "following_url": "https://api.github.com/users/krzysztof-miemiec/following{/other_user}", "gists_url": "https://api.github.com/users/krzysztof-miemiec/gists{/gist_id}", "starred_url": "https://api.github.com/users/krzysztof-miemiec/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/krzysztof-miemiec/subscriptions", "organizations_url": "https://api.github.com/users/krzysztof-miemiec/orgs", "repos_url": "https://api.github.com/users/krzysztof-miemiec/repos", "events_url": "https://api.github.com/users/krzysztof-miemiec/events{/privacy}", "received_events_url": "https://api.github.com/users/krzysztof-miemiec/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-05-27T12:48:01Z", "updated_at": "2020-05-28T13:26:29Z", "closed_at": "2020-05-28T13:26:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "I\u2019m using Consul & Datadog on Kubernetes with autodiscovery and `ENC[]` secrets feature. I deploy everything with Terraform (AWS, Kubernetes & Helm Providers).\r\n\r\nIt looks like `X-Consul-Token` is not passed correctly from encrypted values. When I replaced it with plaintext token it seems to be working.\r\n\r\nSecond issue is that default checks are running alongside checks I defined explicitly via annotations.\r\n\r\n## Debug info\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n<details>\r\n\r\n```text\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v7.19.0)\r\n===============\r\n\r\n  Status date: 2020-05-27 11:58:57.172295 UTC\r\n  Agent start: 2020-05-27 10:00:46.490660 UTC\r\n  Pid: 1\r\n  Go Version: go1.13.8\r\n  Python Version: 3.8.1\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: INFO\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -177\u00b5s\r\n    System UTC time: 2020-05-27 11:58:57.172295 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2020-05-23 14:08:58.000000 UTC\r\n    kernelVersion: 4.14.177-139.253.amzn2.x86_64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: bullseye/sid\r\n    procs: 60\r\n    uptime: 91h51m53s\r\n    virtualizationRole: guest\r\n    virtualizationSystem: xen\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: masked\r\n    host_aliases: [masked-internal]\r\n    hostname: i-09c9206a947a6ca48\r\n    instance-id: i-09c9206a947a6ca48\r\n    socket-fqdn: datadog-5gwph\r\n    socket-hostname: datadog-5gwph\r\n    host tags:\r\n      cluster_env:prod\r\n      cluster_name:internal\r\n      cluster_name:internal\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: AWS\r\n    hostname_source: aws\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    consul (1.13.0)\r\n    ---------------\r\n      Instance ID: consul:6a8b38227309fa30 [\u001b[31mERROR\u001b[0m]\r\n      Configuration Source: kubelet:docker://c0ff3b2859617a5a403e4f16ac5a5df99aad46f4fe1797f2a03700079dc81f81\r\n      Total Runs: 12\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 12\r\n      Average Execution Time : 14ms\r\n      Last Execution Date : 2020-05-27 11:58:54.000000 UTC\r\n      Last Successful Execution Date : Never\r\n      Error: 403 Client Error: Forbidden for url: https://10.15.5.140:8501/v1/agent/self\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\", line 820, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\", line 244, in check\r\n          self._collect_metadata()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\", line 528, in _collect_metadata\r\n          local_config = self._get_local_config()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\", line 103, in _get_local_config\r\n          self._local_config = self.consul_request('/v1/agent/self')\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\", line 76, in consul_request\r\n          resp.raise_for_status()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/models.py\", line 940, in raise_for_status\r\n          raise HTTPError(http_error_msg, response=self)\r\n      requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://10.15.5.140:8501/v1/agent/self\r\n      Instance ID: consul:8912e99ffe795c0c [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://f754c6add1f47b72d69e0851e3da20c88e81adac236558c2a73ab2e6ed7d111f\r\n      Total Runs: 21\r\n      Metric Samples: Last Run: 1, Total: 21\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 2, Total: 43\r\n      Average Execution Time : 164ms\r\n      Last Execution Date : 2020-05-27 11:58:55.000000 UTC\r\n      Last Successful Execution Date : 2020-05-27 11:58:55.000000 UTC\r\n      metadata:\r\n        version.major: 1\r\n        version.minor: 8\r\n        version.patch: 0\r\n        version.raw: 1.8.0\r\n        version.scheme: semver\r\n      \r\n      Instance ID: consul:93e60a3b2d57d7a2 [\u001b[31mERROR\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/consul.d/auto_conf.yaml\r\n      Total Runs: 473\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 473\r\n      Average Execution Time : 8ms\r\n      Last Execution Date : 2020-05-27 11:58:51.000000 UTC\r\n      Last Successful Execution Date : Never\r\n      Error: HTTPConnectionPool(host='10.15.5.127', port=8500): Max retries exceeded with url: /v1/status/leader (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f492c092fa0>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connection.py\", line 159, in _new_conn\r\n          conn = connection.create_connection(\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\r\n          raise err\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\r\n          sock.connect(sa)\r\n      ConnectionRefusedError: [Errno 111] Connection refused\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 670, in urlopen\r\n          httplib_response = self._make_request(\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 392, in _make_request\r\n          conn.request(method, url, **httplib_request_kw)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\", line 1230, in request\r\n          self._send_request(method, url, body, headers, encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\", line 1276, in _send_request\r\n          self.endheaders(body, encode_chunked=encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\", line 1225, in endheaders\r\n          self._send_output(message_body, encode_chunked=encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\", line 1004, in _send_output\r\n          self.send(msg)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/http/client.py\", line 944, in send\r\n          self.connect()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connection.py\", line 187, in connect\r\n          conn = self._new_conn()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connection.py\", line 171, in _new_conn\r\n          raise NewConnectionError(\r\n      urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f492c092fa0>: Failed to establish a new connection: [Errno 111] Connection refused\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\r\n          resp = conn.urlopen(\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 724, in urlopen\r\n          retries = retries.increment(\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/urllib3/util/retry.py\", line 439, in increment\r\n          raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n      urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='10.15.5.127', port=8500): Max retries exceeded with url: /v1/status/leader (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f492c092fa0>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\", line 820, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\", line 243, in check\r\n          self._check_for_leader_change()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\", line 152, in _check_for_leader_change\r\n          leader = self._get_cluster_leader()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\", line 109, in _get_cluster_leader\r\n          return self.consul_request('/v1/status/leader')\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\", line 74, in consul_request\r\n          resp = self.http.get(url)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/utils/http.py\", line 283, in get\r\n          return self._request('get', url, options)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/utils/http.py\", line 325, in _request\r\n          return getattr(requests, method)(url, **new_options)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/api.py\", line 75, in get\r\n          return request('get', url, params=params, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/api.py\", line 60, in request\r\n          return session.request(method=method, url=url, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/sessions.py\", line 533, in request\r\n          resp = self.send(prep, **send_kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/sessions.py\", line 646, in send\r\n          r = adapter.send(request, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\r\n          raise ConnectionError(e, request=request)\r\n      requests.exceptions.ConnectionError: HTTPConnectionPool(host='10.15.5.127', port=8500): Max retries exceeded with url: /v1/status/leader (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f492c092fa0>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\n    \r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n    \r\n  Failed checks\r\n  =============\r\n    no checks\r\n    \r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 472\r\n    Connections: 0\r\n    Containers: 0\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 60\r\n    Metadata: 0\r\n    Pods: 0\r\n    Processes: 0\r\n    RTContainers: 0\r\n    RTProcesses: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 1,004\r\n    TimeseriesV1: 472\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with xxxxx: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.eu - API Key ending with:\r\n      - xxxxx\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n    Sending compressed logs in HTTPS to agent-http-intake.logs.datadoghq.eu on port 443\r\n    BytesSent: 4.0940631e+07\r\n    EncodedBytesSent: 3.099292e+06\r\n    LogsProcessed: 48203\r\n    LogsSent: 48135\r\n\r\n  datadog/datadog-5gwph/process-agent\r\n  -----------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/datadog_datadog-5gwph_415ce591-db39-4514-b36f-05de797b87b3/process-agent/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  consul/consul-mesh-gateway-dcf8564c9-9zqsf/service-init\r\n  -------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-mesh-gateway-dcf8564c9-9zqsf_ef815eee-90f5-42e2-bdc7-e148bebbe6cc/service-init/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  consul/consul-mesh-gateway-dcf8564c9-9zqsf/get-auto-encrypt-client-ca\r\n  ---------------------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-mesh-gateway-dcf8564c9-9zqsf_ef815eee-90f5-42e2-bdc7-e148bebbe6cc/get-auto-encrypt-client-ca/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  consul/consul-jstnd/client-acl-init\r\n  -----------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-jstnd_faec1b8e-82d3-4f55-9920-61ebc8754762/client-acl-init/*.log\r\n    Status: OK\r\n      1 files tailed out of 1 files matching\r\n    Inputs: /var/log/pods/consul_consul-jstnd_faec1b8e-82d3-4f55-9920-61ebc8754762/client-acl-init/0.log \r\n\r\n  consul/consul-mesh-gateway-dcf8564c9-9zqsf/copy-consul-bin\r\n  ----------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-mesh-gateway-dcf8564c9-9zqsf_ef815eee-90f5-42e2-bdc7-e148bebbe6cc/copy-consul-bin/*.log\r\n    Status: OK\r\n      1 files tailed out of 1 files matching\r\n    Inputs: /var/log/pods/consul_consul-mesh-gateway-dcf8564c9-9zqsf_ef815eee-90f5-42e2-bdc7-e148bebbe6cc/copy-consul-bin/0.log \r\n\r\n  consul/consul-server-0/consul\r\n  -----------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-server-0_5cf038b3-1d69-459c-926a-41e14d6a8f48/consul/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  consul/consul-connect-injector-webhook-deployment-7bf98cdc6c-zvlxq/get-auto-encrypt-client-ca\r\n  ---------------------------------------------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-connect-injector-webhook-deployment-7bf98cdc6c-zvlxq_e90d06aa-e972-4141-ae9b-12189ca1d64a/get-auto-encrypt-client-ca/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  consul/consul-connect-injector-webhook-deployment-7bf98cdc6c-zvlxq/sidecar-injector\r\n  -----------------------------------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-connect-injector-webhook-deployment-7bf98cdc6c-zvlxq_e90d06aa-e972-4141-ae9b-12189ca1d64a/sidecar-injector/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  consul/consul-mesh-gateway-dcf8564c9-9zqsf/lifecycle-sidecar\r\n  ------------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-mesh-gateway-dcf8564c9-9zqsf_ef815eee-90f5-42e2-bdc7-e148bebbe6cc/lifecycle-sidecar/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  consul/consul-jstnd/consul\r\n  --------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-jstnd_faec1b8e-82d3-4f55-9920-61ebc8754762/consul/*.log\r\n    Status: OK\r\n      1 files tailed out of 1 files matching\r\n    Inputs: /var/log/pods/consul_consul-jstnd_faec1b8e-82d3-4f55-9920-61ebc8754762/consul/0.log \r\n\r\n  consul/consul-mesh-gateway-dcf8564c9-9zqsf/mesh-gateway\r\n  -------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/consul_consul-mesh-gateway-dcf8564c9-9zqsf_ef815eee-90f5-42e2-bdc7-e148bebbe6cc/mesh-gateway/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n============\r\nSystem Probe\r\n============\r\n  System Probe is not running:\r\n\r\n    Errors\r\n    ======\r\n    error setting up remote system probe util, socket path does not exist: stat /opt/datadog-agent/run/sysprobe.sock: no such file or directory\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 660,057\r\n  Dogstatsd Metric Sample: 1,181\r\n  Event: 10\r\n  Events Flushed: 10\r\n  Number Of Flushes: 472\r\n  Series Flushed: 505,828\r\n  Service Check: 11,266\r\n  Service Checks Flushed: 11,720\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 1,180\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 65,372\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 1,181\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n=====================\r\nDatadog Cluster Agent\r\n=====================\r\n\r\n  - Datadog Cluster Agent endpoint detected: https://172.20.245.213:5005\r\n  Successfully connected to the Datadog Cluster Agent.\r\n  - Running: 1.5.2+commit.60ee741\r\n\r\n```\r\n\r\n**agent secret output**\r\n```\r\nDefaulting container name to agent.\r\nUse 'kubectl describe pod/datadog-5gwph -n datadog' to see all of the containers in this pod.\r\n=== Checking executable rights ===\r\nExecutable path: /readsecret.py\r\nCheck Rights: OK, the executable has the correct rights\r\n\r\nRights Detail:\r\nfile mode: 100500\r\nOwner username: root\r\nGroup name: root\r\n\r\n=== Secrets stats ===\r\nNumber of secrets decrypted: 1\r\nSecrets handle decrypted:\r\n- consul_acl_token: from consul\r\n```\r\n</details>\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nConsul `1.8-beta2`, Datadog from Helm Chart `v2.3.5`\r\n\r\n## Steps to reproduce the issue:\r\n1. Configure Consul with ACL and TLS enabled on Kubernetes\r\n2. Try to configure Consul checks as follows\r\n\r\nMy Consul annotations:\r\n```yaml\r\nad.datadoghq.com/consul.logs: '[{ \"source\":\"consul\", \"service\":\"consul\" }]'\r\nad.datadoghq.com/consul.init_configs: '[{}]'\r\nad.datadoghq.com/consul.check_names: '[\"consul\"]'\r\nad.datadoghq.com/consul.instances: |\r\n  [{\r\n    \"url\": \"https://%%host%%:8501\",\r\n    \"acl_token\": \"ENC[consul_acl_token]\",\r\n    \"tls_verify\": false,\r\n    \"tls_ignore_warning\": true\r\n  }]\r\n```\r\n\r\nI mounted Kubernetes secret into Datadog Agents (Helm setup) and configured secret support as follows:\r\n```yaml\r\nenv:\r\n- name: DD_SECRET_BACKEND_COMMAND\r\n  value: /readsecret.py\r\n- name: DD_SECRET_BACKEND_ARGUMENTS\r\n  value: \"/etc/datadog-secrets\"\r\n\r\nvolumes:\r\n- name: datadog-secrets\r\n  secret:\r\n    secretName: datadog-secrets\r\nvolumeMounts:\r\n- name: datadog-secrets\r\n  mountPath: \"/etc/datadog-secrets\"\r\n  readOnly: true\r\n```\r\n\r\nI configured ACL in Consul and exported it to Kubernetes with Terraform:\r\n\r\n```tf\r\nresource \"consul_acl_policy\" \"monitoring\" {\r\n  name  = \"monitoring\"\r\n  description = \"Datadog Monitoring Policy\"\r\n  rules = <<-HCL\r\n    event_prefix \"\" {\r\n      policy = \"read\"\r\n    }\r\n    agent_prefix \"\" {\r\n      policy = \"read\"\r\n    }\r\n    node_prefix \"\" {\r\n      policy = \"read\"\r\n    }\r\n    service_prefix \"\" {\r\n      policy = \"read\"\r\n    }\r\n  HCL\r\n}\r\n\r\nresource \"consul_acl_token\" \"datadog\" {\r\n  description = \"Datadog\"\r\n  policies = [consul_acl_policy.monitoring.name]\r\n}\r\n\r\ndata \"consul_acl_token_secret_id\" \"datadog\" {\r\n  accessor_id = consul_acl_token.datadog.accessor_id\r\n}\r\n\r\nresource \"kubernetes_secret\" \"datadog_secrets\" {\r\n  metadata {\r\n    namespace = module.datadog.namespace\r\n    name = \"datadog-secrets\"\r\n  }\r\n\r\n  data = {\r\n    consul_acl_token = data.consul_acl_token_secret_id.datadog.secret_id\r\n  }\r\n}\r\n```\r\n\r\n## **Describe the results you received:**\r\n\r\nLogs from Consul\r\n```log\r\n2020-05-27T12:12:30.444Z [ERROR] agent.http: Request error: method=GET url=/v1/agent/self from=10.15.6.232:41628 error=\"ACL not found\"\r\n```\r\n\r\nLogs from Datadog agent\r\n```log\r\nError running check consul: [{\"message\": \"403 Client Error: Forbidden for url: https://10.15.4.223:8501/v1/agent/self\", \"traceback\": \"Traceback (most recent call last):\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\\\", line 820, in run\r\n    self.check(instance)\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\\\", line 244, in check\r\n    self._collect_metadata()\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\\\", line 528, in _collect_metadata\r\n    local_config = self._get_local_config()\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\\\", line 103, in _get_local_config\r\n    self._local_config = self.consul_request('/v1/agent/self')\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/consul/consul.py\\\", line 76, in consul_request\r\n    resp.raise_for_status()\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/requests/models.py\\\", line 940, in raise_for_status\r\n    raise HTTPError(http_error_msg, response=self)\r\nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://10.15.4.223:8501/v1/agent/self\r\n\"}]\r\n```\r\n\r\nAdditionally, when I replace `ENC[consul_acl_token]` with plaintext token:\r\n```\r\n Error running check consul: [{\"message\": \"HTTPConnectionPool(host='10.15.4.37', port=8500): Max retries exceeded with url: /v1/status/leader (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb812f11d90>: Failed to establish a new connection: [Errno 111] Connection refused'))\", \"traceback\": \"Traceback (most recent call last):\r\n```\r\n\r\n**Describe the results you expected:**\r\nNo errors when running checks with ENC[...].\r\nOnly checks defined by annotations should be run. Notice that I get errors with connecting to Consul on http@8500, while I'm explicitly passing https@8501.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI went through https://docs.datadoghq.com/agent/guide/secrets-management/?tab=linux#troubleshooting and there's one thing that does not match expected results in guide:\r\n\r\nWhen I run `agent configcheck` I get:\r\n\r\n<details>\r\n\r\n```\r\n=== consul check ===\r\nConfiguration provider: kubernetes\r\nConfiguration source: kubelet:docker://7ec881bfcd6073c234d56a9a03c58161fd03c17a50cbaeef985610684cde0ead\r\nInstance ID: consul:6a74708f3e6fa3c6\r\nacl_token: ********\r\ntags:\r\n- kube_namespace:consul\r\n- kube_stateful_set:consul-server\r\n- kube_container_name:consul\r\n- kube_service:consul-ui\r\n- kube_service:consul-dns\r\n- docker_image:consul:1.8.0-beta2\r\n- short_image:consul\r\n- image_tag:1.8.0-beta2\r\n- persistentvolumeclaim:data-consul-consul-server-0\r\n- kube_service:consul-server\r\n- image_name:consul\r\n- pod_phase:running\r\ntls_ignore_warning: true\r\ntls_verify: false\r\nurl: https://10.15.5.241:8501\r\n~\r\nInit Config:\r\n{}\r\nAuto-discovery IDs:\r\n* docker://7ec881bfcd6073c234d56a9a03c58161fd03c17a50cbaeef985610684cde0ead\r\n===\r\n=== consul check ===\r\nConfiguration provider: kubernetes\r\nConfiguration source: kubelet:docker://d138d03e36f46c31d31bde77b0f439c0d1ada553425d0d739aeffcefdcfb8d0c\r\nInstance ID: consul:5bd82da03f1c7903\r\nacl_token: ********\r\ntags:\r\n- kube_namespace:consul\r\n- short_image:consul\r\n- pod_phase:running\r\n- kube_stateful_set:consul-server\r\n- kube_container_name:consul\r\n- image_tag:1.8.0-beta2\r\n- kube_service:consul-server\r\n- kube_service:consul-ui\r\n- persistentvolumeclaim:data-consul-consul-server-0\r\n- docker_image:consul:1.8.0-beta2\r\n- image_name:consul\r\n- kube_service:consul-dns\r\ntls_ignore_warning: true\r\ntls_verify: false\r\nurl: https://10.15.5.228:8501\r\n~\r\nInit Config:\r\n{}\r\nAuto-discovery IDs:\r\n* docker://d138d03e36f46c31d31bde77b0f439c0d1ada553425d0d739aeffcefdcfb8d0c\r\n===\r\n=== consul check ===\r\nConfiguration provider: file\r\nConfiguration source: file:/etc/datadog-agent/conf.d/consul.d/auto_conf.yaml\r\nInstance ID: consul:93e60a3b2d57d7a2\r\ncatalog_checks: true\r\nnew_leader_checks: true\r\ntags:\r\n- kube_container_name:copy-consul-bin\r\n- short_image:consul\r\n- image_tag:1.8.0-beta2\r\n- docker_image:consul:1.8.0-beta2\r\n- image_name:consul\r\n- kube_namespace:consul\r\n- pod_phase:running\r\n- kube_deployment:consul-mesh-gateway\r\nurl: http://10.15.5.127:8500\r\n~\r\nAuto-discovery IDs:\r\n* consul\r\n===\r\n=== consul check ===\r\nConfiguration provider: kubernetes\r\nConfiguration source: kubelet:docker://b052fa34d8aad72b7402fb1bc6e3ebf16cd0e8057e1ce4db59af9dac14762ea3\r\nInstance ID: consul:b3d726e8a50f827f\r\nacl_token: ********\r\ntags:\r\n- image_tag:1.8.0-beta2\r\n- kube_daemon_set:consul\r\n- image_name:consul\r\n- kube_service:consul-dns\r\n- pod_phase:running\r\n- docker_image:consul:1.8.0-beta2\r\n- short_image:consul\r\n- kube_namespace:consul\r\n- kube_container_name:consul\r\ntls_ignore_warning: true\r\ntls_verify: false\r\nurl: https://10.15.5.228:8501\r\n~\r\n```\r\n\r\n</details>\r\n\r\nNote that checks from `/etc/datadog-agent/conf.d/consul.d/auto_conf.yaml` are present, which is not expected. I also see that `acl_token` shows up as `********` and not as decrypted value of token. According to docs, that value should show up as decrypted value.\r\n\r\n```\r\nsudo -u dd-agent -- datadog-agent configcheck\r\n\r\n=== a check ===\r\nSource: File Configuration Provider\r\nInstance 1:\r\nhost: <decrypted_host>\r\nport: <decrypted_port>\r\npassword: <decrypted_password>\r\n~\r\n===\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6743", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6743/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6743/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6743/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6743", "id": 625135855, "node_id": "MDU6SXNzdWU2MjUxMzU4NTU=", "number": 6743, "title": "nfsstat: incorrectly reporting an integration problem on systems with no NFS mounts", "user": {"login": "ebusto", "id": 8902413, "node_id": "MDQ6VXNlcjg5MDI0MTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/8902413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebusto", "html_url": "https://github.com/ebusto", "followers_url": "https://api.github.com/users/ebusto/followers", "following_url": "https://api.github.com/users/ebusto/following{/other_user}", "gists_url": "https://api.github.com/users/ebusto/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebusto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebusto/subscriptions", "organizations_url": "https://api.github.com/users/ebusto/orgs", "repos_url": "https://api.github.com/users/ebusto/repos", "events_url": "https://api.github.com/users/ebusto/events{/privacy}", "received_events_url": "https://api.github.com/users/ebusto/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-26T19:24:48Z", "updated_at": "2020-06-16T14:36:41Z", "closed_at": "2020-06-16T14:36:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Currently the NFS integration reports the absence of any NFS mounts as an integration problem. In environments which use the automounter, old mounts are often automatically unmounted.\r\n\r\nReporting zero mounts as a problem should be configurable.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6718", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6718/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6718/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6718/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6718", "id": 623940089, "node_id": "MDU6SXNzdWU2MjM5NDAwODk=", "number": 6718, "title": "Istio Integration 1.5.4 - could not get a 'istio' check instance with the new api", "user": {"login": "rbgran", "id": 3766873, "node_id": "MDQ6VXNlcjM3NjY4NzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/3766873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rbgran", "html_url": "https://github.com/rbgran", "followers_url": "https://api.github.com/users/rbgran/followers", "following_url": "https://api.github.com/users/rbgran/following{/other_user}", "gists_url": "https://api.github.com/users/rbgran/gists{/gist_id}", "starred_url": "https://api.github.com/users/rbgran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rbgran/subscriptions", "organizations_url": "https://api.github.com/users/rbgran/orgs", "repos_url": "https://api.github.com/users/rbgran/repos", "events_url": "https://api.github.com/users/rbgran/events{/privacy}", "received_events_url": "https://api.github.com/users/rbgran/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-24T17:57:27Z", "updated_at": "2020-05-26T14:53:51Z", "closed_at": "2020-05-26T14:53:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nIf you suspect your issue is a bug, please attach the output of the Agent status page,\r\nsee https://docs.datadoghq.com/agent/faq/agent-commands/#agent-information\r\n-->\r\n\r\n**Output of the info page (if this is a bug)**\r\n\r\n===============\r\nAgent (v7.19.0)\r\n===============\r\n\r\n  Status date: 2020-05-24 17:55:56.625100 UTC\r\n  Agent start: 2020-05-24 17:49:52.802714 UTC\r\n  Pid: 32234\r\n  Go Version: go1.13.8\r\n  Python Version: 3.8.1\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: INFO\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 728\u00b5s\r\n    System UTC time: 2020-05-24 17:55:56.625100 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2020-05-21 19:40:01.000000 UTC\r\n    kernelVersion: 4.14.177-139.253.amzn2.x86_64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: bullseye/sid\r\n    procs: 259\r\n    uptime: 70h9m56s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ip-10-30-0-17.us-west-2.compute.internal\r\n    host_aliases: [ip-10-30-0-17.us-west-2.compute.internal-app-eks-dev-us-west-2]\r\n    hostname: i-066770fa01a4f99df\r\n    instance-id: i-066770fa01a4f99df\r\n    socket-fqdn: datadog-4jbt4\r\n    socket-hostname: datadog-4jbt4\r\n    host tags:\r\n      cluster_name:app-eks-dev-us-west-2\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: AWS\r\n    hostname_source: aws\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 6, Total: 138\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-24 17:55:49.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:49.000000 UTC\r\n\r\n\r\n    disk (2.8.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 23\r\n      Metric Samples: Last Run: 310, Total: 7,130\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 23ms\r\n      Last Execution Date : 2020-05-24 17:55:41.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:41.000000 UTC\r\n\r\n\r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 528, Total: 12,672\r\n      Events: Last Run: 0, Total: 1\r\n      Service Checks: Last Run: 1, Total: 24\r\n      Average Execution Time : 52ms\r\n      Last Execution Date : 2020-05-24 17:55:48.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:48.000000 UTC\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 5, Total: 120\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-24 17:55:55.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:55.000000 UTC\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 39, Total: 909\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-24 17:55:47.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:47.000000 UTC\r\n\r\n\r\n    istio (3.0.0)\r\n    -------------\r\n      Instance ID: istio:d59b9b7e31c0f7a3 [ERROR]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/istio.yaml\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-24 17:55:42.000000 UTC\r\n      Last Successful Execution Date : Never\r\n      Error: list index out of range\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\", line 800, in run\r\n          instance = copy.deepcopy(self.instances[0])\r\n      IndexError: list index out of range\r\n\r\n    kubelet (4.0.0)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 624, Total: 14,952\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 4, Total: 96\r\n      Average Execution Time : 181ms\r\n      Last Execution Date : 2020-05-24 17:55:54.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:54.000000 UTC\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 6, Total: 144\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-24 17:55:46.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:46.000000 UTC\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 17, Total: 408\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-24 17:55:53.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:53.000000 UTC\r\n\r\n\r\n    network (1.15.1)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 31, Total: 744\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 1ms\r\n      Last Execution Date : 2020-05-24 17:55:45.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:45.000000 UTC\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1, Total: 1\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 294ms\r\n      Last Execution Date : 2020-05-24 17:49:58.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:49:58.000000 UTC\r\n\r\n\r\n    prometheus (3.2.1)\r\n    ------------------\r\n      Instance ID: prometheus:datadog.cluster_agent:f5472fa8014028f0 [OK]\r\n      Configuration Source: kubelet:docker://8cf8e0f012a8e55e6a677e745423fd0f42968c70576e3a859ee014e951fd5abc\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 38, Total: 912\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 24\r\n      Average Execution Time : 8ms\r\n      Last Execution Date : 2020-05-24 17:55:44.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:44.000000 UTC\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 24\r\n      Metric Samples: Last Run: 1, Total: 24\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-24 17:55:52.000000 UTC\r\n      Last Successful Execution Date : 2020-05-24 17:55:52.000000 UTC\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 24\r\n    Connections: 0\r\n    Containers: 0\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 4\r\n    Metadata: 0\r\n    Pods: 0\r\n    Processes: 0\r\n    RTContainers: 0\r\n    RTProcesses: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 52\r\n    TimeseriesV1: 24\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with cb7fe: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - cb7fe\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n    Sending compressed logs in HTTPS to agent-http-intake.logs.datadoghq.com on port 443\r\n    BytesSent: 894896\r\n    EncodedBytesSent: 163663\r\n    LogsProcessed: 923\r\n    LogsSent: 921\r\n\r\n  default/datadog-4jbt4/trace-agent\r\n  ---------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-4jbt4_61bf3c0e-1841-4775-b81a-0dbb16744b1d/trace-agent/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  container_collect_all\r\n  ---------------------\r\n    Type: docker\r\n    Status: Pending\r\n\r\n  default/datadog-cluster-agent-5784cbb9c6-g9726/cluster-agent\r\n  ------------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-cluster-agent-5784cbb9c6-g9726_fe714a06-77de-48ce-9fd4-019fe0fbce72/cluster-agent/*.log\r\n    Status: OK\r\n      1 files tailed out of 1 files matching\r\n    Inputs: /var/log/pods/default_datadog-cluster-agent-5784cbb9c6-g9726_fe714a06-77de-48ce-9fd4-019fe0fbce72/cluster-agent/0.log\r\n\r\n  default/datadog-4jbt4/agent\r\n  ---------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-4jbt4_61bf3c0e-1841-4775-b81a-0dbb16744b1d/agent/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/api3-dev-5dcb875948-cmqbb/istio-proxy\r\n  -----------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_api3-dev-5dcb875948-cmqbb_fee2bd40-7356-460b-bfe3-1e6e7f6ad6ab/istio-proxy/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  default/datadog-4jbt4/process-agent\r\n  -----------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-4jbt4_61bf3c0e-1841-4775-b81a-0dbb16744b1d/process-agent/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/webappworker-dev-7fcfb88b6d-l4bgk/istio-init\r\n  ------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_webappworker-dev-7fcfb88b6d-l4bgk_68ec6b86-6988-4ff4-8f40-d7f689b3e19e/istio-init/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/web3-dev-5bf67bc557-ddztq/web3\r\n  ----------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_web3-dev-5bf67bc557-ddztq_2da3d111-f296-4234-b3e0-4298cdb5115a/web3/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/webappapi-dev-6ddd66df57-z8xq9/istio-init\r\n  ---------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_webappapi-dev-6ddd66df57-z8xq9_2bf6e73a-5c3a-4e60-804b-eae6d7df3e14/istio-init/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/web3-dev-5bf67bc557-ddztq/istio-init\r\n  ----------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_web3-dev-5bf67bc557-ddztq_2da3d111-f296-4234-b3e0-4298cdb5115a/istio-init/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  kube-system/aws-node-bpjnv/aws-node\r\n  -----------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/kube-system_aws-node-bpjnv_f42792a6-a080-4463-babc-cacdf374a495/aws-node/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  default/datadog-4jbt4/seccomp-setup\r\n  -----------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-4jbt4_61bf3c0e-1841-4775-b81a-0dbb16744b1d/seccomp-setup/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  default/datadog-4jbt4/init-volume\r\n  ---------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-4jbt4_61bf3c0e-1841-4775-b81a-0dbb16744b1d/init-volume/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/api3-dev-5dcb875948-cmqbb/istio-init\r\n  ----------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_api3-dev-5dcb875948-cmqbb_fee2bd40-7356-460b-bfe3-1e6e7f6ad6ab/istio-init/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  kube-system/kube-proxy-292z4/kube-proxy\r\n  ---------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/kube-system_kube-proxy-292z4_cb76cb8f-e3ac-4f22-9b82-bdf49699174d/kube-proxy/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/nodeapi-dev-7c7f895f46-tpkdb/istio-proxy\r\n  --------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_nodeapi-dev-7c7f895f46-tpkdb_302f2709-0e13-4b9b-978b-e3082678be1f/istio-proxy/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/web3-dev-5bf67bc557-ddztq/istio-proxy\r\n  -----------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_web3-dev-5bf67bc557-ddztq_2da3d111-f296-4234-b3e0-4298cdb5115a/istio-proxy/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/webappworker-dev-7fcfb88b6d-l4bgk/istio-proxy\r\n  -------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_webappworker-dev-7fcfb88b6d-l4bgk_68ec6b86-6988-4ff4-8f40-d7f689b3e19e/istio-proxy/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  istio-system/istio-ingressgateway-f57db965c-ws7d9/istio-proxy\r\n  -------------------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/istio-system_istio-ingressgateway-f57db965c-ws7d9_9141d964-f553-4945-ad2a-878a8b7b6be9/istio-proxy/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  default/datadog-clusterchecks-58b868495b-h7zb4/agent\r\n  ----------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-clusterchecks-58b868495b-h7zb4_9c70bed7-030e-4c94-8892-5860ebb4f735/agent/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  kube-system/fluentd-logzio-8xcb5/fluentd\r\n  ----------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/kube-system_fluentd-logzio-8xcb5_8ce646d0-83f4-42a3-b511-129abe8ce219/fluentd/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/api3-dev-5dcb875948-cmqbb/api3\r\n  ----------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_api3-dev-5dcb875948-cmqbb_fee2bd40-7356-460b-bfe3-1e6e7f6ad6ab/api3/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/webappworker-dev-7fcfb88b6d-l4bgk/webappworker\r\n  --------------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_webappworker-dev-7fcfb88b6d-l4bgk_68ec6b86-6988-4ff4-8f40-d7f689b3e19e/webappworker/*.log\r\n    Status: Pending\r\n      2 files tailed out of 2 files matching\r\n\r\n  dev/nodeapi-dev-7c7f895f46-tpkdb/nodeapi\r\n  ----------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_nodeapi-dev-7c7f895f46-tpkdb_302f2709-0e13-4b9b-978b-e3082678be1f/nodeapi/*.log\r\n    Status: Pending\r\n      2 files tailed out of 2 files matching\r\n\r\n  default/datadog-4jbt4/system-probe\r\n  ----------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-4jbt4_61bf3c0e-1841-4775-b81a-0dbb16744b1d/system-probe/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/webappapi-dev-6ddd66df57-z8xq9/istio-proxy\r\n  ----------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_webappapi-dev-6ddd66df57-z8xq9_2bf6e73a-5c3a-4e60-804b-eae6d7df3e14/istio-proxy/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/nodeapi-dev-7c7f895f46-tpkdb/istio-init\r\n  -------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_nodeapi-dev-7c7f895f46-tpkdb_302f2709-0e13-4b9b-978b-e3082678be1f/istio-init/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  dev/webappapi-dev-6ddd66df57-z8xq9/webappapi\r\n  --------------------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/dev_webappapi-dev-6ddd66df57-z8xq9_2bf6e73a-5c3a-4e60-804b-eae6d7df3e14/webappapi/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n  default/datadog-4jbt4/init-config\r\n  ---------------------------------\r\n    Type: file\r\n    Path: /var/log/pods/default_datadog-4jbt4_61bf3c0e-1841-4775-b81a-0dbb16744b1d/init-config/*.log\r\n    Status: Pending\r\n      1 files tailed out of 1 files matching\r\n\r\n\r\n============\r\nSystem Probe\r\n============\r\n  System Probe is not running:\r\n\r\n    Errors\r\n    ======\r\n    error setting up remote system probe util, socket path does not exist: stat /opt/datadog-agent/run/sysprobe.sock: no such file or directory\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 38,729\r\n  Dogstatsd Metric Sample: 3,768\r\n  Event: 2\r\n  Events Flushed: 2\r\n  Number Of Flushes: 24\r\n  Series Flushed: 33,282\r\n  Service Check: 433\r\n  Service Checks Flushed: 456\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 3,767\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 356,284\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 3,768\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n=====================\r\nDatadog Cluster Agent\r\n=====================\r\n\r\n  - Could not detect the Datadog Cluster Agent's endpoint: temporary failure in clusterAgentClient, will retry later: try delay not elapsed yet\r\n\r\n  - Could not retrieve the version of the Datadog Cluster Agent.\r\n\r\n**Describe what happened:**\r\n\r\n`2020-05-24 17:49:56 UTC | CORE | WARN | (pkg/collector/python/check.go:237 in Configure) | could not get a 'istio' check instance with the new api: __init__() missing 1 required positional argument: 'agentConfig'\r\n2020-05-24 17:49:56 UTC | CORE | WARN | (pkg/collector/python/check.go:256 in Configure) | passing `agentConfig` to the constructor is deprecated, please use the `get_config` function from the 'datadog_agent' package (istio).\r\n2020-05-24 17:49:56 UTC | CORE | INFO | (pkg/collector/scheduler/scheduler.go:83 in Enter) | Scheduling check istio with an interval of 15s\r\n2020-05-24 17:49:57 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check istio\r\n2020-05-24 17:49:57 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | istio:d59b9b7e31c0f7a3 | (core.py:45) | Unable to transform `config` metadata value `None`: 'NoneType' object has no attribute 'get'\r\n2020-05-24 17:49:57 UTC | CORE | ERROR | (pkg/collector/runner/runner.go:292 in work) | Error running check istio: [{\"message\": \"list index out of range\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\\\", line 800, in run\\n    instance = copy.deepcopy(self.instances[0])\\nIndexError: list index out of range\\n\"}]\r\n2020-05-24 17:49:57 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check istio\r\n2020-05-24 17:50:12 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check istio\r\n2020-05-24 17:50:12 UTC | CORE | ERROR | (pkg/collector/runner/runner.go:292 in work) | Error running check istio: [{\"message\": \"list index out of range\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\\\", line 800, in run\\n    instance = copy.deepcopy(self.instances[0])\\nIndexError: list index out of range\\n\"}]`\r\n\r\n**Describe what you expected:**\r\n\r\nIstio agent to work.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nEnable Istio integration with Istio 1.5.4.\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):** \r\nAWS EKS 1.16\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6653", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6653/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6653/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6653/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6653", "id": 618954461, "node_id": "MDU6SXNzdWU2MTg5NTQ0NjE=", "number": 6653, "title": "Datadog incorrectly parsing enterprise version of haproxy", "user": {"login": "eddie4", "id": 6816635, "node_id": "MDQ6VXNlcjY4MTY2MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6816635?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddie4", "html_url": "https://github.com/eddie4", "followers_url": "https://api.github.com/users/eddie4/followers", "following_url": "https://api.github.com/users/eddie4/following{/other_user}", "gists_url": "https://api.github.com/users/eddie4/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddie4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddie4/subscriptions", "organizations_url": "https://api.github.com/users/eddie4/orgs", "repos_url": "https://api.github.com/users/eddie4/repos", "events_url": "https://api.github.com/users/eddie4/events{/privacy}", "received_events_url": "https://api.github.com/users/eddie4/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 936570431, "node_id": "MDU6TGFiZWw5MzY1NzA0MzE=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/haproxy", "name": "integration/haproxy", "color": "bfdadc", "default": false, "description": ""}, {"id": 293952856, "node_id": "MDU6TGFiZWwyOTM5NTI4NTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/bug", "name": "kind/bug", "color": "b60205", "default": false, "description": ""}, {"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-15T13:03:55Z", "updated_at": "2020-06-18T07:44:26Z", "closed_at": "2020-06-18T07:44:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the info page (if this is a bug)**\r\n```\r\n\u25cf datadog-agent.service - Datadog Agent\r\n     Loaded: loaded (/lib/systemd/system/datadog-agent.service; enabled; vendor preset: enabled)\r\n     Active: active (running) since Fri 2020-05-15 14:53:27 CEST; 14s ago\r\n   Main PID: 1593896 (agent)\r\n      Tasks: 51 (limit: 38370)\r\n     Memory: 54.1M\r\n     CGroup: /system.slice/datadog-agent.service\r\n             \u2514\u25001593896 /opt/datadog-agent/bin/agent/agent run -p /opt/datadog-agent/run/agent.pid\r\n\r\n```\r\n\r\n**Describe what happened:**\r\nDatadog reports: unable to find HAProxy version info\r\n\r\n```\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/check.go:72 in runCheck) | Running python check haproxy haproxy:2ab874cf83035b04\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:122 in LogMessage) | haproxy:2ab874cf83035b04 | (haproxy.py:123) | Processing HAProxy data for http://localhost:1361/admin?stats\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:122 in LogMessage) | haproxy:2ab874cf83035b04 | (haproxy.py:237) | collecting version info for HAProxy from http://localhost:1361/admin?stats\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:122 in LogMessage) | - | (connectionpool.py:226) | Starting new HTTP connection (1): localhost:1361\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:122 in LogMessage) | - | (connectionpool.py:433) | http://localhost:1361 \"GET /admin?stats HTTP/1.1\" 200 None\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:122 in LogMessage) | haproxy:2ab874cf83035b04 | (haproxy.py:253) | unable to find HAProxy version info\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:122 in LogMessage) | haproxy:2ab874cf83035b04 | (haproxy.py:201) | Fetching haproxy stats from url: http://localhost:1361/admin?stats/;csv;norefresh\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:122 in LogMessage) | - | (connectionpool.py:226) | Starting new HTTP connection (1): localhost:1361\r\n2020-05-15 14:54:14 CEST | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:122 in LogMessage) | - | (connectionpool.py:433) | http://localhost:1361 \"GET /admin?stats/;csv;norefresh HTTP/1.1\" 200 None\r\n\r\n```\r\n\r\n\r\n**Describe what you expected:**\r\nThe version of HAProxy to be parsed correctly\r\n\r\n**Steps to reproduce the issue:**\r\nInstall HAProxy Enterprise Edition\r\nSetup logging\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nBecause we are not running the opensource version but the enterprise edition the version is not properly parsed from the status page. I have attached the status page for the enterprise edition \r\n\r\nHTML /admin?stats\r\nhttps://pastebin.com/sT5eDwss\r\nCSV /admin?stats/;csv;norefresh\r\nhttps://pastebin.com/07JyDHGU\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6605", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6605/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6605/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6605/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6605", "id": 614465100, "node_id": "MDU6SXNzdWU2MTQ0NjUxMDA=", "number": 6605, "title": "Statsd SET method unable to publish strings value", "user": {"login": "keshcode", "id": 18310103, "node_id": "MDQ6VXNlcjE4MzEwMTAz", "avatar_url": "https://avatars2.githubusercontent.com/u/18310103?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keshcode", "html_url": "https://github.com/keshcode", "followers_url": "https://api.github.com/users/keshcode/followers", "following_url": "https://api.github.com/users/keshcode/following{/other_user}", "gists_url": "https://api.github.com/users/keshcode/gists{/gist_id}", "starred_url": "https://api.github.com/users/keshcode/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keshcode/subscriptions", "organizations_url": "https://api.github.com/users/keshcode/orgs", "repos_url": "https://api.github.com/users/keshcode/repos", "events_url": "https://api.github.com/users/keshcode/events{/privacy}", "received_events_url": "https://api.github.com/users/keshcode/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-08T02:46:59Z", "updated_at": "2020-05-08T03:07:59Z", "closed_at": "2020-05-08T03:07:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there a way to publish string value in datadog checks to datadog agent, like name of the SQL SERVER. \r\nTried statsd.set method to publish\r\nSQL SERVER NAME : WIN-OTU2UL9IG3Q \r\nbut all i can see in data dog dashboard is 1 for this respective metric\r\nIs this even supported what i am trying to do. if not shouldn't we throw proper error.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6591", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6591/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6591/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6591/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6591", "id": 613942824, "node_id": "MDU6SXNzdWU2MTM5NDI4MjQ=", "number": 6591, "title": "MSSQL SQLDriverConnect", "user": {"login": "MilanDasek", "id": 12279315, "node_id": "MDQ6VXNlcjEyMjc5MzE1", "avatar_url": "https://avatars1.githubusercontent.com/u/12279315?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MilanDasek", "html_url": "https://github.com/MilanDasek", "followers_url": "https://api.github.com/users/MilanDasek/followers", "following_url": "https://api.github.com/users/MilanDasek/following{/other_user}", "gists_url": "https://api.github.com/users/MilanDasek/gists{/gist_id}", "starred_url": "https://api.github.com/users/MilanDasek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MilanDasek/subscriptions", "organizations_url": "https://api.github.com/users/MilanDasek/orgs", "repos_url": "https://api.github.com/users/MilanDasek/repos", "events_url": "https://api.github.com/users/MilanDasek/events{/privacy}", "received_events_url": "https://api.github.com/users/MilanDasek/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-05-06T07:16:00Z", "updated_at": "2020-08-03T08:36:52Z", "closed_at": "2020-06-26T11:51:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nis there a way how to make MSSQL server drivers working in datadog-agent docker image?\r\n\r\nI have enabled integration using: https://docs.datadoghq.com/integrations/sqlserver/ ,but I get this:\r\n\r\n```\r\nsqlserver (1.16.2)\r\n    ------------------\r\n      Instance ID: sqlserver:94bb9d1db5faf8f2 [ERROR]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/sqlserver.yaml\r\n      Total Runs: 191\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 191\r\n      Average Execution Time : 3ms\r\n      Last Execution Date : 2020-05-06 07:05:04.000000 UTC\r\n      Last Successful Execution Date : Never\r\n      Error: Unable to connect to SQL Server for instance %REDACTED%,1433 - master: Error('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'SQL Server' : file not found (0) (SQLDriverConnect)\")\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\", line 713, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/sqlserver/sqlserver.py\", line 467, in check\r\n          self.do_perf_counter_check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/sqlserver/sqlserver.py\", line 482, in do_perf_counter_check\r\n          with self.open_managed_db_connections(instance, self.DEFAULT_DB_KEY):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/contextlib.py\", line 113, in __enter__\r\n          return next(self.gen)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/sqlserver/sqlserver.py\", line 612, in open_managed_db_connections\r\n          self.open_db_connections(instance, db_key, db_name)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/sqlserver/sqlserver.py\", line 669, in open_db_connections\r\n          raise_from(SQLConnectionError(message), None)\r\n        File \"<string>\", line 3, in raise_from\r\n      datadog_checks.sqlserver.sqlserver.SQLConnectionError: Unable to connect to SQL Server for instance %REDACTED%,1433 - master: Error('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'SQL Server' : file not found (0) (SQLDriverConnect)\")\r\n```\r\n\r\nI tried this: https://docs.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-2017\r\n\r\nBut there is a lot of broken stuff (for example broken dependency on package odbcinst1debian2)\r\n\r\n\r\nI am using helm chart for installing DD agent - https://github.com/helm/charts/tree/master/stable/datadog\r\n\r\n\r\nMotivation is to have this metric: `sqlserver.stats.lock_waits` from MSSQL server in DataDog.\r\n\r\nPlease advise.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6568", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6568/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6568/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6568/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6568", "id": 611819691, "node_id": "MDU6SXNzdWU2MTE4MTk2OTE=", "number": 6568, "title": "datadog 7.18.0 => 7.19.0 breaks compatibility with haproxy 2.1.4 stats socket ", "user": {"login": "wolfgangpfnuer", "id": 668408, "node_id": "MDQ6VXNlcjY2ODQwOA==", "avatar_url": "https://avatars1.githubusercontent.com/u/668408?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wolfgangpfnuer", "html_url": "https://github.com/wolfgangpfnuer", "followers_url": "https://api.github.com/users/wolfgangpfnuer/followers", "following_url": "https://api.github.com/users/wolfgangpfnuer/following{/other_user}", "gists_url": "https://api.github.com/users/wolfgangpfnuer/gists{/gist_id}", "starred_url": "https://api.github.com/users/wolfgangpfnuer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wolfgangpfnuer/subscriptions", "organizations_url": "https://api.github.com/users/wolfgangpfnuer/orgs", "repos_url": "https://api.github.com/users/wolfgangpfnuer/repos", "events_url": "https://api.github.com/users/wolfgangpfnuer/events{/privacy}", "received_events_url": "https://api.github.com/users/wolfgangpfnuer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-04T11:14:37Z", "updated_at": "2020-05-05T16:52:56Z", "closed_at": "2020-05-05T16:52:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the info page (if this is a bug)**\r\n```\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v7.19.0)\r\n===============\r\n\r\n  Status date: 2020-05-04 11:10:14.927133 UTC\r\n  Agent start: 2020-05-04 11:09:24.682282 UTC\r\n  Pid: 346\r\n  Go Version: go1.13.8\r\n  Python Version: 3.8.1\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -1.141ms\r\n    System UTC time: 2020-05-04 11:10:14.927133 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-09-02 13:26:44.000000 UTC\r\n    kernelVersion: 4.15.0-48-generic\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: bullseye/sid\r\n    procs: 70\r\n    uptime: 5877h42m55s\r\n    virtualizationRole: guest\r\n    virtualizationSystem: docker\r\n\r\n  Hostnames\r\n  =========\r\n    hostname: <hostname>\r\n    socket-fqdn: b9b895efc1f2\r\n    socket-hostname: b9b895efc1f2\r\n    host tags:\r\n      team:x\r\n      docker_swarm_node_role:worker\r\n    hostname provider: container\r\n    unused hostname providers:\r\n      aws: not retrieving hostname from AWS: the host is not an ECS instance, and other providers already retrieve non-default hostnames\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: Get http://169.254.169.254/computeMetadata/v1/instance/hostname: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\r\n\r\n  Metadata\r\n  ========\r\n    hostname_source: container\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 6, Total: 6\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-04 11:10:00.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:00.000000 UTC\r\n\r\n\r\n    disk (2.8.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 232, Total: 464\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 19ms\r\n      Last Execution Date : 2020-05-04 11:10:07.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:07.000000 UTC\r\n\r\n\r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 382, Total: 764\r\n      Events: Last Run: 0, Total: 2\r\n      Service Checks: Last Run: 1, Total: 2\r\n      Average Execution Time : 237ms\r\n      Last Execution Date : 2020-05-04 11:10:00.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:00.000000 UTC\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 5, Total: 10\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-04 11:10:06.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:06.000000 UTC\r\n\r\n\r\n    haproxy (2.8.0)\r\n    ---------------\r\n      Instance ID: haproxy:16580bb2f742b82 [ERROR]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/haproxy.d/haproxy.yaml\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 1ms\r\n      Last Execution Date : 2020-05-04 11:10:08.000000 UTC\r\n      Last Successful Execution Date : Never\r\n      Error: Got a different number of responses than expected\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\", line 820, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/haproxy/haproxy.py\", line 128, in check\r\n          info, data, tables = self._fetch_socket_data(parsed_url)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/haproxy/haproxy.py\", line 310, in _fetch_socket_data\r\n          (tables,) = self._run_socket_commands(parsed_url, (b\"show table\",))\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/haproxy/haproxy.py\", line 290, in _run_socket_commands\r\n          raise CheckException(\"Got a different number of responses than expected\")\r\n      datadog_checks.base.errors.CheckException: Got a different number of responses than expected\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 65, Total: 150\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-04 11:10:13.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:13.000000 UTC\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 6, Total: 12\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-04 11:10:05.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:05.000000 UTC\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 17, Total: 51\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-04 11:10:12.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:12.000000 UTC\r\n\r\n\r\n    network (1.15.1)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 43, Total: 80\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 2ms\r\n      Last Execution Date : 2020-05-04 11:10:04.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:04.000000 UTC\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1, Total: 1\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 103ms\r\n      Last Execution Date : 2020-05-04 11:09:39.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:09:39.000000 UTC\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 1, Total: 3\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-05-04 11:10:11.000000 UTC\r\n      Last Successful Execution Date : 2020-05-04 11:10:11.000000 UTC\r\n\r\n  Config Errors\r\n  ==============\r\n    disk\r\n    ----\r\n      yaml: line 97: did not find expected key\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 3\r\n    Connections: 0\r\n    Containers: 0\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 3\r\n    Metadata: 0\r\n    Pods: 0\r\n    Processes: 0\r\n    RTContainers: 0\r\n    RTProcesses: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 9\r\n    TimeseriesV1: 3\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 48f30: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 48f30\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n\r\n============\r\nSystem Probe\r\n============\r\n  System Probe is not running:\r\n\r\n    Errors\r\n    ======\r\n    error setting up remote system probe util, socket path does not exist: stat /opt/datadog-agent/run/sysprobe.sock: no such file or directory\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 1,590\r\n  Dogstatsd Metric Sample: 168\r\n  Event: 3\r\n  Events Flushed: 3\r\n  Number Of Flushes: 3\r\n  Series Flushed: 924\r\n  Service Check: 28\r\n  Service Checks Flushed: 29\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 167\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 10,679\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 168\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n```\r\n\r\n**Describe what happened:**\r\n    `datadog/agent:latest (==7.19.0)` does not seem to be able to get correct data from haproxy:latest (==2.1.4) through socket endpoint anymore. `datadog/agent:7.18.0` works like a charm.\r\n```2020-05-04 09:41:40 UTC | CORE | ERROR | (pkg/collector/runner/runner.go:292 in work) | Error running check haproxy: [{\"message\": \"Got a different number of responses than expected\", \"traceback\": \"Traceback (most recent call last):\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\\\", line 820, in run\r\n    self.check(instance)\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/haproxy/haproxy.py\\\", line 128, in check\r\n    info, data, tables = self._fetch_socket_data(parsed_url)\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/haproxy/haproxy.py\\\", line 310, in _fetch_socket_data\r\n    (tables,) = self._run_socket_commands(parsed_url, (b\\\"show table\\\",))\r\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/haproxy/haproxy.py\\\", line 290, in _run_socket_commands\r\n    raise CheckException(\\\"Got a different number of responses than expected\\\")\r\ndatadog_checks.base.errors.CheckException: Got a different number of responses than expected\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\ndocker swarm on docker 19.03.6 Ubuntu 18.04 host, baremetal.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6538", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6538/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6538/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6538/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6538", "id": 609352626, "node_id": "MDU6SXNzdWU2MDkzNTI2MjY=", "number": 6538, "title": "Openmetrics example config has wrong keys for TLS ignore", "user": {"login": "Apollorion", "id": 13936290, "node_id": "MDQ6VXNlcjEzOTM2Mjkw", "avatar_url": "https://avatars3.githubusercontent.com/u/13936290?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Apollorion", "html_url": "https://github.com/Apollorion", "followers_url": "https://api.github.com/users/Apollorion/followers", "following_url": "https://api.github.com/users/Apollorion/following{/other_user}", "gists_url": "https://api.github.com/users/Apollorion/gists{/gist_id}", "starred_url": "https://api.github.com/users/Apollorion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Apollorion/subscriptions", "organizations_url": "https://api.github.com/users/Apollorion/orgs", "repos_url": "https://api.github.com/users/Apollorion/repos", "events_url": "https://api.github.com/users/Apollorion/events{/privacy}", "received_events_url": "https://api.github.com/users/Apollorion/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-29T20:53:44Z", "updated_at": "2020-05-16T22:30:47Z", "closed_at": "2020-05-16T22:29:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "While setting up annotation on pods I came across [this](https://docs.datadoghq.com/agent/kubernetes/prometheus/#setup) document which has a note that says `Note: See the sample openmetrics.d/conf.yaml for all available configuration options.` that links to [this](https://github.com/DataDog/integrations-core/blob/master/openmetrics/datadog_checks/openmetrics/data/conf.yaml.example) example config. \r\n\r\nIn the example config there are params `tls_verify` as well as `tls_ignore_warning`, which through trial and error I found should actually be `ssl_verify` and `ssl_ignore_warning`. Im thinking the other `tls` params should also probably be `ssl` but I only verified the above two.\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nAmazon EKS, Datadog Agent 7\r\n\r\n**Steps to reproduce the issue:**\r\n1. create a pod with the annotation: \r\n```\r\n        ad.datadoghq.com/prometheus-server.instances: |\r\n          [\r\n            {\r\n              \"tls_verify\": \"false\",\r\n              \"tls_ignore_warning\": \"true\"\r\n            }\r\n          ]\r\n```\r\n2. see in the agent logs that datadog is not ignoring TLS issues\r\n3. change to `ssl_verify` and `ssl_ignore_warning` and see in the agent logs that it is now working as expected.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6399", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6399/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6399/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6399/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6399", "id": 602110479, "node_id": "MDU6SXNzdWU2MDIxMTA0Nzk=", "number": 6399, "title": "[postgresql] Logs full of pg_last_xlog_receive_location()", "user": {"login": "cep21", "id": 20358, "node_id": "MDQ6VXNlcjIwMzU4", "avatar_url": "https://avatars3.githubusercontent.com/u/20358?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cep21", "html_url": "https://github.com/cep21", "followers_url": "https://api.github.com/users/cep21/followers", "following_url": "https://api.github.com/users/cep21/following{/other_user}", "gists_url": "https://api.github.com/users/cep21/gists{/gist_id}", "starred_url": "https://api.github.com/users/cep21/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cep21/subscriptions", "organizations_url": "https://api.github.com/users/cep21/orgs", "repos_url": "https://api.github.com/users/cep21/repos", "events_url": "https://api.github.com/users/cep21/events{/privacy}", "received_events_url": "https://api.github.com/users/cep21/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "hithwen", "id": 611228, "node_id": "MDQ6VXNlcjYxMTIyOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/611228?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hithwen", "html_url": "https://github.com/hithwen", "followers_url": "https://api.github.com/users/hithwen/followers", "following_url": "https://api.github.com/users/hithwen/following{/other_user}", "gists_url": "https://api.github.com/users/hithwen/gists{/gist_id}", "starred_url": "https://api.github.com/users/hithwen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hithwen/subscriptions", "organizations_url": "https://api.github.com/users/hithwen/orgs", "repos_url": "https://api.github.com/users/hithwen/repos", "events_url": "https://api.github.com/users/hithwen/events{/privacy}", "received_events_url": "https://api.github.com/users/hithwen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "hithwen", "id": 611228, "node_id": "MDQ6VXNlcjYxMTIyOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/611228?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hithwen", "html_url": "https://github.com/hithwen", "followers_url": "https://api.github.com/users/hithwen/followers", "following_url": "https://api.github.com/users/hithwen/following{/other_user}", "gists_url": "https://api.github.com/users/hithwen/gists{/gist_id}", "starred_url": "https://api.github.com/users/hithwen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hithwen/subscriptions", "organizations_url": "https://api.github.com/users/hithwen/orgs", "repos_url": "https://api.github.com/users/hithwen/repos", "events_url": "https://api.github.com/users/hithwen/events{/privacy}", "received_events_url": "https://api.github.com/users/hithwen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-04-17T16:57:06Z", "updated_at": "2020-07-16T09:21:16Z", "closed_at": "2020-07-16T09:21:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "My agent logs are full of pg_last_xlog_receive_location after enabling the Auora collector.  I'm pointing to two instances (a reader and writer) inside my cluster.  The cluster is running Auora Postgresql 10.7.  I'm using datadog's cluster agent checks.\r\n\r\nI found https://github.com/DataDog/integrations-core/issues/4770 which claimed the bug should be fixed in my version.\r\n\r\nAgent version: v7.18.1\r\nIntegration version: 3.5.3\r\n\r\nAgent clusterchecks\r\n\r\n```\r\n=== postgres check ===\r\nConfiguration provider: file\r\nConfiguration source: file:/etc/datadog-agent/conf.d/postgres.yaml\r\nInstance ID: postgres:fXXXXXXXXX\r\ncollect_activity_metrics: true\r\ncollect_function_metrics: true\r\ndbname: inXXXXXXXX\r\nempty_default_hostname: true\r\nhost: analytiXXX.cluster-XXXX.us-west-2.rds.amazonaws.com\r\npassword: XXXXX\r\nport: 5432\r\ntag_replication_role: true\r\ntags:\r\n- dbclusteridentifier:analytiXXXXX\r\n- cluster_name:prod\r\nusername: datadog\r\n~\r\n```\r\n\r\nAgent logs\r\n```\r\n2020-04-17 16:40:35 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:40:50 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:41:05 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:41:20 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:41:35 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:41:50 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:42:05 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:42:20 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:42:35 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:42:50 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:43:05 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:43:20 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:43:35 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:43:50 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:44:05 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:44:20 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:44:35 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n2020-04-17 16:44:50 UTC | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | postgres:2c5f4148c9957c4f | (postgres.py:371) | Function pg_last_xlog_receive_location() is currently not supported for Aurora\r\n```\r\n\r\n\r\nAgent status relevant section\r\n```\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    postgres (3.5.3)\r\n    ----------------\r\n      Instance ID: postgres:2c5f4148c9957c4f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/postgres.yaml\r\n      Total Runs: 2,201\r\n      Metric Samples: Last Run: 145, Total: 319,145\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 2,201\r\n      Average Execution Time : 937ms\r\n      Last Execution Date : 2020-04-17 16:53:50.000000 UTC\r\n      Last Successful Execution Date : 2020-04-17 16:53:50.000000 UTC\r\n      metadata:\r\n        version.major: 10\r\n        version.minor: 7\r\n        version.patch: 0\r\n        version.raw: 10.7\r\n        version.scheme: semver\r\n\r\n      Instance ID: postgres:f07f60e6871363a1 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/postgres.yaml\r\n      Total Runs: 2,200\r\n      Metric Samples: Last Run: 165, Total: 363,826\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 2,200\r\n      Average Execution Time : 1.071s\r\n      Last Execution Date : 2020-04-17 16:53:43.000000 UTC\r\n      Last Successful Execution Date : 2020-04-17 16:53:43.000000 UTC\r\n      metadata:\r\n        version.major: 10\r\n        version.minor: 7\r\n        version.patch: 0\r\n        version.raw: 10.7\r\n        version.scheme: semver\r\n\r\n```\r\n\r\nAgent status\r\n\r\n```\r\n< kc exec datadog-datadog-clusterchecks-6cc84cd644-wv68g agent status\r\nkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v7.18.1)\r\n===============\r\n\r\n  Status date: 2020-04-17 16:53:54.612081 UTC\r\n  Agent start: 2020-04-17 04:36:32.240395 UTC\r\n  Pid: 355\r\n  Go Version: go1.12.9\r\n  Python Version: 3.8.1\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: info\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6321", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6321/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6321/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6321/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6321", "id": 598298598, "node_id": "MDU6SXNzdWU1OTgyOTg1OTg=", "number": 6321, "title": "Zookeeper Integration: invalid literal for int() with base 10: '0.0'", "user": {"login": "siegbenn", "id": 2792167, "node_id": "MDQ6VXNlcjI3OTIxNjc=", "avatar_url": "https://avatars0.githubusercontent.com/u/2792167?v=4", "gravatar_id": "", "url": "https://api.github.com/users/siegbenn", "html_url": "https://github.com/siegbenn", "followers_url": "https://api.github.com/users/siegbenn/followers", "following_url": "https://api.github.com/users/siegbenn/following{/other_user}", "gists_url": "https://api.github.com/users/siegbenn/gists{/gist_id}", "starred_url": "https://api.github.com/users/siegbenn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/siegbenn/subscriptions", "organizations_url": "https://api.github.com/users/siegbenn/orgs", "repos_url": "https://api.github.com/users/siegbenn/repos", "events_url": "https://api.github.com/users/siegbenn/events{/privacy}", "received_events_url": "https://api.github.com/users/siegbenn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-11T16:11:30Z", "updated_at": "2020-04-13T14:14:26Z", "closed_at": "2020-04-13T14:14:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "```text\r\n===============\r\nAgent (v7.18.1)\r\n===============\r\n\r\n  Status date: 2020-04-11 18:04:06.665406 CEST\r\n  Agent start: 2020-04-11 17:58:31.102234 CEST\r\n  Pid: 6615\r\n  Go Version: go1.12.9\r\n  Python Version: 3.8.1\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -198\u00b5s\r\n    System UTC time: 2020-04-11 18:04:06.665406 CEST\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2020-04-11 17:29:47.000000 CEST\r\n    kernelVersion: 4.18.0-147.5.1.el8_1.x86_64\r\n    os: linux\r\n    platform: centos\r\n    platformFamily: rhel\r\n    platformVersion: 8.1.1911\r\n    procs: 155\r\n    uptime: 28m44s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: CPN-1\r\n    hostname: CPN-1\r\n    instance-id: 5342048\r\n    socket-fqdn: CPN-1\r\n    socket-hostname: CPN-1\r\n    hostname provider: os\r\n    unused hostname providers:\r\n      aws: not retrieving hostname from AWS: the host is not an ECS instance, and other providers already retrieve non-\r\ndefault hostnames\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v\r\n1/instance/hostname\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: AWS\r\n    hostname_source: os\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 22\r\n      Metric Samples: Last Run: 6, Total: 126\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-04-11 18:03:54.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 18:03:54.000000 CEST\r\n\r\n\r\n    disk (2.7.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 22\r\n      Metric Samples: Last Run: 62, Total: 1,364\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 23ms\r\n      Last Execution Date : 2020-04-11 18:04:01.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 18:04:01.000000 CEST\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 22\r\n      Metric Samples: Last Run: 5, Total: 110\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-04-11 18:03:53.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 18:03:53.000000 CEST\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 22\r\n      Metric Samples: Last Run: 52, Total: 1,108\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-04-11 18:04:00.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 18:04:00.000000 CEST\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 22\r\n      Metric Samples: Last Run: 6, Total: 132\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-04-11 18:03:52.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 18:03:52.000000 CEST\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 22\r\n      Metric Samples: Last Run: 17, Total: 374\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-04-11 18:03:59.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 18:03:59.000000 CEST\r\n\r\n\r\n    network (1.14.0)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 23\r\n      Metric Samples: Last Run: 32, Total: 736\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 2ms\r\n      Last Execution Date : 2020-04-11 18:04:06.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 18:04:06.000000 CEST\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1, Total: 1\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 117ms\r\n      Last Execution Date : 2020-04-11 17:58:32.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 17:58:32.000000 CEST\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 22\r\n      Metric Samples: Last Run: 1, Total: 22\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Last Execution Date : 2020-04-11 18:03:58.000000 CEST\r\n      Last Successful Execution Date : 2020-04-11 18:03:58.000000 CEST\r\n\r\n\r\n    zk (2.4.0)\r\n    ----------\r\n      Instance ID: zk:a91b9701ff92ef2d [ERROR]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/zk.d/conf.yaml\r\n      Total Runs: 23\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 23\r\n      Average Execution Time : 12ms\r\n      Last Execution Date : 2020-04-11 18:04:02.000000 CEST\r\n      Last Successful Execution Date : Never\r\n      metadata:\r\n        version.major: 3\r\n        version.minor: 6\r\n        version.patch: 0\r\n        version.raw: 3.6.0--b4c89dc7f6083829e18fae6e446907ae0b1f22d7\r\n        version.release: -b4c89dc7f6083829e18fae6e446907ae0b1f22d7\r\n        version.scheme: semver\r\n      Error: invalid literal for int() with base 10: '0.0'\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\", line 713, in\r\n run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/zk/zk.py\", line 162, in check\r\n          metrics, new_tags, mode, zk_version = self.parse_stat(stat_out)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/zk/zk.py\", line 288, in parse_stat\r\n          l_min, l_avg, l_max = [int(v) for v in value.strip().split('/')]\r\n        File \"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/zk/zk.py\", line 288, in <listcomp>\r\n          l_min, l_avg, l_max = [int(v) for v in value.strip().split('/')]\r\n      ValueError: invalid literal for int() with base 10: '0.0'\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 22\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 4\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 48\r\n    TimeseriesV1: 22\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with b26ae: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - b26ae\r\n\r\n==========\r\nLogs Agent\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 4,374\r\n  Dogstatsd Metric Sample: 1,554\r\n  Event: 1\r\n  Events Flushed: 1\r\n  Number Of Flushes: 22\r\n  Series Flushed: 4,096\r\n  Service Check: 225\r\n  Service Checks Flushed: 243\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 1,553\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 100,123\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 1,554\r\n  Uds Bytes: 0\r\n==========\r\n\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\nCurrently running on Centos 8.1 on Hetzner cloud.\r\nZookeeper integration is failing on Centos8.1 with Zookeeper build 3.6.0.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Install zookeeper 3.6.0\r\n2. Add line in zoo.cfg: 4lw.commands.whitelist=srvr,stat,mntr\r\n3. Enable zk datadog-agent conf\r\n\r\n**Describe the results you received:**\r\nNo metrics are being sent to datadog for zk.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6273", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6273/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6273/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6273/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6273", "id": 595592694, "node_id": "MDU6SXNzdWU1OTU1OTI2OTQ=", "number": 6273, "title": "Lost metrics when integration with Prometheus.", "user": {"login": "codelipenghui", "id": 12592133, "node_id": "MDQ6VXNlcjEyNTkyMTMz", "avatar_url": "https://avatars2.githubusercontent.com/u/12592133?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codelipenghui", "html_url": "https://github.com/codelipenghui", "followers_url": "https://api.github.com/users/codelipenghui/followers", "following_url": "https://api.github.com/users/codelipenghui/following{/other_user}", "gists_url": "https://api.github.com/users/codelipenghui/gists{/gist_id}", "starred_url": "https://api.github.com/users/codelipenghui/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codelipenghui/subscriptions", "organizations_url": "https://api.github.com/users/codelipenghui/orgs", "repos_url": "https://api.github.com/users/codelipenghui/repos", "events_url": "https://api.github.com/users/codelipenghui/events{/privacy}", "received_events_url": "https://api.github.com/users/codelipenghui/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-07T05:03:39Z", "updated_at": "2020-08-03T08:28:53Z", "closed_at": "2020-08-03T08:28:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "The following is the original metrics in the Prometheus:(I have 100 partitions, part omitted)\r\n```\r\npulsar_rate_in{cluster=\"pulsar-datadog\",namespace=\"public/default\",topic=\"persistent://public/default/datadog-topic-1-partition-0\"} 10.016 1586235036960\r\npulsar_rate_in{cluster=\"pulsar-datadog\",namespace=\"public/default\",topic=\"persistent://public/default/datadog-topic-1-partition-1\"} 10.006 1586235036960\r\npulsar_rate_in{cluster=\"pulsar-datadog\",namespace=\"public/default\",topic=\"persistent://public/default/datadog-topic-1-partition-2\"} 9.006 1586235036960\r\n...\r\npulsar_rate_in{cluster=\"pulsar-datadog\",namespace=\"public/default\",topic=\"persistent://public/default/datadog-topic-1-partition-27\"} 9.406 1586235036960\r\n...\r\npulsar_rate_in{cluster=\"pulsar-datadog\",namespace=\"public/default\",topic=\"persistent://public/default/datadog-topic-1-partition-99\"} 9.806 1586235036960\r\n```\r\nBut when I check metrics in the Datadog:\r\n\r\n![image](https://user-images.githubusercontent.com/12592133/78631387-e0e63200-78ce-11ea-8dc1-15f6fd68db14.png)\r\n\r\nOnly can get one partition(partition-27)  metrics. I have checked the agent status and logs, everything looks well. And when I make a dashboard(`sum(pulsar_rate_in)`) also the value is incorrect(lost 98 partitions).\r\n\r\n![image](https://user-images.githubusercontent.com/12592133/78631491-20ad1980-78cf-11ea-8ed3-e72d11523e57.png)\r\n\r\nI'm not sure If I missed some configurations or some other reason. \r\n\r\n**Describe the results you expected:**\r\nDon't lose Prometheus metrics.\r\n\r\nI use the last Datadog agent(openmetrics configurations) and I have tried on macOS and centos, problems always appear.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6240", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6240/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6240/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6240/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6240", "id": 593232882, "node_id": "MDU6SXNzdWU1OTMyMzI4ODI=", "number": 6240, "title": "Disk check fails in kernel 5.5+", "user": {"login": "SerialVelocity", "id": 422338, "node_id": "MDQ6VXNlcjQyMjMzOA==", "avatar_url": "https://avatars0.githubusercontent.com/u/422338?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SerialVelocity", "html_url": "https://github.com/SerialVelocity", "followers_url": "https://api.github.com/users/SerialVelocity/followers", "following_url": "https://api.github.com/users/SerialVelocity/following{/other_user}", "gists_url": "https://api.github.com/users/SerialVelocity/gists{/gist_id}", "starred_url": "https://api.github.com/users/SerialVelocity/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SerialVelocity/subscriptions", "organizations_url": "https://api.github.com/users/SerialVelocity/orgs", "repos_url": "https://api.github.com/users/SerialVelocity/repos", "events_url": "https://api.github.com/users/SerialVelocity/events{/privacy}", "received_events_url": "https://api.github.com/users/SerialVelocity/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-02T16:03:39Z", "updated_at": "2020-05-03T20:31:32Z", "closed_at": "2020-05-03T20:31:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nIf you suspect your issue is a bug, please attach the output of the Agent status page,\r\nsee https://docs.datadoghq.com/agent/faq/agent-commands/#agent-information\r\n-->\r\n\r\n**I think this will be fixed by upgrading psutil to 5.7.0 (the release notes state that kernel 5.5 added two more fields which broke `disk_io_counters`)**\r\n\r\n**Describe what happened:**\r\nDisk check not working in kernel 5.5+\r\n\r\n```\r\n2020-04-02 15:22:46 UTC | CORE | ERROR | (pkg/collector/runner/runner.go:292 in work) | Error running check disk: [{\"message\": \"not sure how to interpret line '   8       0 sda 3243674 885162 2087107447 37513715 10525918 1142798 251099536 95120395 0 11322428 126936986 0 0 0 0 4462277 56879516\\\\n'\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/base/checks/base.py\\\", line 713, in run\\n    self.check(instance)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/disk/disk.py\\\", line 121, in check\\n    self.collect_latency_metrics()\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/datadog_checks/disk/disk.py\\\", line 244, in collect_latency_metrics\\n    for disk_name, disk in iteritems(psutil.disk_io_counters(True)):\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/psutil/__init__.py\\\", line 2168, in disk_io_counters\\n    rawdict = _psplatform.disk_io_counters(**kwargs)\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/psutil/_pslinux.py\\\", line 1125, in disk_io_counters\\n    for entry in gen:\\n  File \\\"/opt/datadog-agent/embedded/lib/python3.8/site-packages/psutil/_pslinux.py\\\", line 1098, in read_procfs\\n    raise ValueError(\\\"not sure how to interpret line %r\\\" % line)\\nValueError: not sure how to interpret line '   8       0 sda 3243674 885162 2087107447 37513715 10525918 1142798 251099536 95120395 0 11322428 126936986 0 0 0 0 4462277 56879516\\\\n'\\n\"}]\r\n```\r\n\r\n**Describe what you expected:**\r\nDisk check to work\r\n\r\n**Steps to reproduce the issue:**\r\nTry to run the check on kernel 5.5+\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nUsing Fedora CoreOS 31.20200223.3.0 with kernel 5.5.5-200.fc31.x86_64\r\nBare Metal host\r\nUsing datadog-agent 7 in kubernetes\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6126", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6126/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6126/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6126/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6126", "id": 586493140, "node_id": "MDU6SXNzdWU1ODY0OTMxNDA=", "number": 6126, "title": "[haproxy] Adds / to URL causing 404", "user": {"login": "bkimbrough88", "id": 53441835, "node_id": "MDQ6VXNlcjUzNDQxODM1", "avatar_url": "https://avatars0.githubusercontent.com/u/53441835?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bkimbrough88", "html_url": "https://github.com/bkimbrough88", "followers_url": "https://api.github.com/users/bkimbrough88/followers", "following_url": "https://api.github.com/users/bkimbrough88/following{/other_user}", "gists_url": "https://api.github.com/users/bkimbrough88/gists{/gist_id}", "starred_url": "https://api.github.com/users/bkimbrough88/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bkimbrough88/subscriptions", "organizations_url": "https://api.github.com/users/bkimbrough88/orgs", "repos_url": "https://api.github.com/users/bkimbrough88/repos", "events_url": "https://api.github.com/users/bkimbrough88/events{/privacy}", "received_events_url": "https://api.github.com/users/bkimbrough88/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-23T20:19:56Z", "updated_at": "2020-07-01T08:27:37Z", "closed_at": "2020-07-01T08:27:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "While attempting to setup the HAProxy integration in my OpenShift cluster, the check kept returning 404. It appears that the problem is that there is an extra `/` after my metrics URL. From the agent I was able to run `curl -k --user user:pass https://<host IP>:1936/metrics`. However the agent is running against the URL `https://<host IP>:1936/metrics/;csv;norefresh` and doing a curl against that or event against `https://<host IP>:1936/metrics/` it comes back as 404.\r\n\r\nIn [haproxy.py](https://github.com/DataDog/integrations-core/blob/6e90f8b6831cd41b2e4a6041dc102843b4914628/haproxy/datadog_checks/haproxy/haproxy.py#L18) I found that `/;csv;norefresh` is getting appended to my prometheus URL, is there any reason why?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6091", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6091/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6091/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6091/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6091", "id": 583967728, "node_id": "MDU6SXNzdWU1ODM5Njc3Mjg=", "number": 6091, "title": "Federated Prometheus URLs aren't working", "user": {"login": "jasonmcintosh", "id": 1070971, "node_id": "MDQ6VXNlcjEwNzA5NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1070971?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasonmcintosh", "html_url": "https://github.com/jasonmcintosh", "followers_url": "https://api.github.com/users/jasonmcintosh/followers", "following_url": "https://api.github.com/users/jasonmcintosh/following{/other_user}", "gists_url": "https://api.github.com/users/jasonmcintosh/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasonmcintosh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasonmcintosh/subscriptions", "organizations_url": "https://api.github.com/users/jasonmcintosh/orgs", "repos_url": "https://api.github.com/users/jasonmcintosh/repos", "events_url": "https://api.github.com/users/jasonmcintosh/events{/privacy}", "received_events_url": "https://api.github.com/users/jasonmcintosh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "cohenyair", "id": 26828068, "node_id": "MDQ6VXNlcjI2ODI4MDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/26828068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cohenyair", "html_url": "https://github.com/cohenyair", "followers_url": "https://api.github.com/users/cohenyair/followers", "following_url": "https://api.github.com/users/cohenyair/following{/other_user}", "gists_url": "https://api.github.com/users/cohenyair/gists{/gist_id}", "starred_url": "https://api.github.com/users/cohenyair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cohenyair/subscriptions", "organizations_url": "https://api.github.com/users/cohenyair/orgs", "repos_url": "https://api.github.com/users/cohenyair/repos", "events_url": "https://api.github.com/users/cohenyair/events{/privacy}", "received_events_url": "https://api.github.com/users/cohenyair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "cohenyair", "id": 26828068, "node_id": "MDQ6VXNlcjI2ODI4MDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/26828068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cohenyair", "html_url": "https://github.com/cohenyair", "followers_url": "https://api.github.com/users/cohenyair/followers", "following_url": "https://api.github.com/users/cohenyair/following{/other_user}", "gists_url": "https://api.github.com/users/cohenyair/gists{/gist_id}", "starred_url": "https://api.github.com/users/cohenyair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cohenyair/subscriptions", "organizations_url": "https://api.github.com/users/cohenyair/orgs", "repos_url": "https://api.github.com/users/cohenyair/repos", "events_url": "https://api.github.com/users/cohenyair/events{/privacy}", "received_events_url": "https://api.github.com/users/cohenyair/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2020-03-18T19:55:55Z", "updated_at": "2020-07-20T13:56:28Z", "closed_at": "2020-07-20T13:56:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "    openmetrics (1.5.0)\r\n    -------------------\r\n      Instance ID: openmetrics:spinnaker:760b133263cff92d [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/openmetrics.d/conf.yaml\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 7ms\r\n      Last Execution Date : 2020-03-18 19:52:18.000000 UTC\r\n      Last Successful Execution Date : 2020-03-18 19:52:18.000000 UTC\r\n\r\nWhen set to use a config:\r\n    init_config:\r\n    instances:\r\n      - prometheus_url: http://prometheus.testing:9090/federate?match[]={job=~\".+\"}\r\n        namespace: testing\r\n        metrics:\r\n          - '*'\r\n        health_service_check: false\r\n\r\nNo metric data is returned.  If I change the url to /metrics it works fine.  I've also tried URL encoding it to:\r\n\r\n      - prometheus_url: http://prometheus.testing:9090/federate?match[]=%7Bjob%3D~%22.%2B%22%7D\r\n\r\nand still no results.  ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6055", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6055/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6055/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6055/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6055", "id": 581287808, "node_id": "MDU6SXNzdWU1ODEyODc4MDg=", "number": 6055, "title": "redisdb integration doesn't work with Google Cloud Memorystore", "user": {"login": "sue445", "id": 608755, "node_id": "MDQ6VXNlcjYwODc1NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/608755?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sue445", "html_url": "https://github.com/sue445", "followers_url": "https://api.github.com/users/sue445/followers", "following_url": "https://api.github.com/users/sue445/following{/other_user}", "gists_url": "https://api.github.com/users/sue445/gists{/gist_id}", "starred_url": "https://api.github.com/users/sue445/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sue445/subscriptions", "organizations_url": "https://api.github.com/users/sue445/orgs", "repos_url": "https://api.github.com/users/sue445/repos", "events_url": "https://api.github.com/users/sue445/events{/privacy}", "received_events_url": "https://api.github.com/users/sue445/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-14T17:04:32Z", "updated_at": "2020-03-18T08:32:46Z", "closed_at": "2020-03-18T08:32:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\n$ kubectl exec -it datadog-cj5k6 agent status\r\nFetching cluster endpoint and auth data.\r\nkubeconfig entry generated for sentry-production.\r\nGetting the status from the agent.\r\n===============\r\nAgent (v7.17.1)\r\n===============\r\n  Status date: 2020-03-14 16:46:54.753946 UTC\r\n  Agent start: 2020-03-12 14:45:49.052441 UTC\r\n  Pid: 1\r\n  Go Version: go1.12.9\r\n  Python Version: 3.7.6\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: INFO\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n  Clocks\r\n  ======\r\n    NTP offset: -110\u00b5s\r\n    System UTC time: 2020-03-14 16:46:54.753946 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2020-02-25 03:31:35.000000 UTC\r\n    kernelVersion: 4.14.138&#43;\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: bullseye/sid\r\n    procs: 57\r\n    uptime: 395h14m17s\r\n  Hostnames\r\n  =========\r\n    host_aliases: [gke-sentry-productio-sentry-productio-21b83b9e-68h1.xxxxx-sentry gke-sentry-productio-sentry-productio-21b83b9e-68h1-sentry-production]\r\n    hostname: gke-sentry-productio-sentry-productio-21b83b9e-68h1.c.xxxxx-sentry.internal\r\n    socket-fqdn: datadog-cj5k6\r\n    socket-hostname: datadog-cj5k6\r\n    host tags:\r\n      [service:sentry\r\n      host-alert:disable\r\n      env:production]\r\n      cluster_name:sentry-production\r\n      env:production\r\n      gke-sentry-production-3c7ac730-node\r\n      zone:asia-northeast1-a\r\n      instance-type:n1-standard-4\r\n      internal-hostname:gke-sentry-productio-sentry-productio-21b83b9e-68h1.c.xxxxx-sentry.internal\r\n      instance-id:7827962741078436838\r\n      project:xxxxx-sentry\r\n      numeric_project_id:755912733718\r\n      disable-legacy-endpoints:true\r\n      cluster-uid:3c7ac730656b18c65ddf492dacba863da32e69eaea59a0e71ccc855ce4186e10\r\n      created-by:projects/755912733718/zones/asia-northeast1-a/instanceGroupManagers/gke-sentry-productio-sentry-productio-21b83b9e-grp\r\n      gci-update-strategy:update_disabled\r\n      instance-template:projects/755912733718/global/instanceTemplates/gke-sentry-productio-sentry-productio-21b83b9e\r\n      cluster-location:asia-northeast1\r\n      enable-oslogin:false\r\n      gci-ensure-gke-docker:true\r\n      cluster-name:sentry-production\r\n      kube-labels:beta.kubernetes.io/fluentd-ds-ready=true,cloud.google.com/gke-nodepool=sentry-production-primary,cloud.google.com/gke-os-distribution=cos,\r\nenv=production,service=sentry\r\n      google-compute-enable-pcid:true\r\n    hostname provider: gce\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n  Metadata\r\n  ========\r\n    cloud_provider: GCP\r\n    hostname_source: gce\r\n=========\r\nCollector\r\n=========\r\n  Running Checks\r\n  ==============\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 6, Total: 72,018\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n    disk (2.6.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 212, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 47ms\r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 1,280, Total: 1 M\r\n      Events: Last Run: 0, Total: 913\r\n      Service Checks: Last Run: 1, Total: 12,004\r\n      Average Execution Time : 254ms\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 5, Total: 60,020\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 182, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n    kube_dns (2.3.0)\r\n    ----------------\r\n      Instance ID: kube_dns:4a4d7381fc613b5 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kube_dns.d/auto_conf.yaml\r\n      Total Runs: 12,005\r\n      Metric Samples: Last Run: 84, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n     Average Execution Time : 23ms\r\n    kubelet (3.5.2)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 1,501, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 4, Total: 48,016\r\n      Average Execution Time : 883ms\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 6, Total: 72,024\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 17, Total: 204,068\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n    network (1.14.0)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 31, Total: 372,124\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 3ms\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 201\r\n      Metric Samples: Last Run: 1, Total: 201\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 201\r\n      Average Execution Time : 1.089s\r\n    postgres (3.5.0)\r\n    ----------------\r\n      Instance ID: postgres:6c667dda8f3fea91 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/postgres.yaml\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 46, Total: 578,735\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 12,004\r\n      Average Execution Time : 40ms\r\n      metadata:\r\n        version.major: 9\r\n        version.minor: 6\r\n        version.patch: 16\r\n        version.raw: 9.6.16\r\n        version.scheme: semver\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 12,004\r\n      Metric Samples: Last Run: 1, Total: 12,004\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n========\r\nJMXFetch\r\n========\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n=========\r\nForwarder\r\n=========\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 12,004\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 2,215\r\n    Metadata: 0\r\n    Requeued: 2\r\n    Retried: 2\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 26,223\r\n    TimeseriesV1: 12,004\r\n  Transaction Errors\r\n  ==================\r\n    Total number: 2\r\n    Errors By Type:\r\n\r\n  HTTP Errors\r\n  ==================\r\n    Total number: 2\r\n    HTTP Errors By Code:\r\n      500: 2\r\n  API Keys status\r\n  ===============\r\n    API key ending with e722e: API Key valid\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - e722e\r\n==========\r\nLogs Agent\r\n==========\r\n  Logs Agent is not running\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 32.4 M\r\n  Dogstatsd Metric Sample: 1\r\n  Event: 914\r\n  Events Flushed: 914\r\n  Number Of Flushes: 12,004\r\n  Series Flushed: 29.1 M\r\n  Service Check: 216,475\r\n  Service Checks Flushed: 228,474\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 0\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 0\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 1\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n* Google Cloud Memorystore\r\n\r\n**Steps to reproduce the issue:**\r\n1. Run Cloud Memorystore in my GCP project\r\n2. Deploy datadog agent to my GKE cluster with [helm chart](https://github.com/helm/charts/tree/master/stable/datadog)\r\n    * `values.yaml` is followings\r\n\r\n```yaml\r\ndatadog:\r\n  confd:\r\n    redisdb.yaml: |-\r\n      init_config:\r\n      instances:\r\n        - host: xxx.xxx.xxx.xxx # address to my Memorystore\r\n          port: 6379\r\n          tags:\r\n            - role:redis\r\n```\r\n\r\n**Describe the results you received:**\r\n```\r\nunknown command `CONFIG`, with args beginning with: `GET`, `maxclients`, \", \"traceback\": \"Traceback (most recent call last):\r\n File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 673, in run\r\n self.check(instance)\r\n File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/redisdb/redisdb.py\", line 484, in check\r\n self._check_db(instance, custom_tags)\r\n File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/redisdb/redisdb.py\", line 190, in _check_db\r\n config = conn.config_get(\"maxclients\")\r\n File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/redis/client.py\", line 971, in config_get\r\n return self.execute_command('CONFIG GET', pattern)\r\n File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/redis/client.py\", line 839, in execute_command\r\n return self.parse_response(conn, command_name, **options)\r\n File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/redis/client.py\", line 853, in parse_response\r\n response = connection.read_response()\r\n File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/redis/connection.py\", line 718, in read_response\r\n raise response\r\nredis.exceptions.ResponseError: unknown command `CONFIG`, with args beginning with: `GET`, `maxclients`\r\n```\r\n\r\n**Describe the results you expected:**\r\nNo error. I expected that redis metrics can be obtained.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n`CONFIG` is blocked by GCP.\r\nhttps://cloud.google.com/memorystore/docs/reference/redis-configs#blocked\r\n\r\nI want to skip without error If `CONFIG` cannot be used.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6054", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6054/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6054/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6054/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6054", "id": 581036573, "node_id": "MDU6SXNzdWU1ODEwMzY1NzM=", "number": 6054, "title": "Aggregator package is missing in actual production agent build", "user": {"login": "shuklaabhi", "id": 8133527, "node_id": "MDQ6VXNlcjgxMzM1Mjc=", "avatar_url": "https://avatars2.githubusercontent.com/u/8133527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shuklaabhi", "html_url": "https://github.com/shuklaabhi", "followers_url": "https://api.github.com/users/shuklaabhi/followers", "following_url": "https://api.github.com/users/shuklaabhi/following{/other_user}", "gists_url": "https://api.github.com/users/shuklaabhi/gists{/gist_id}", "starred_url": "https://api.github.com/users/shuklaabhi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shuklaabhi/subscriptions", "organizations_url": "https://api.github.com/users/shuklaabhi/orgs", "repos_url": "https://api.github.com/users/shuklaabhi/repos", "events_url": "https://api.github.com/users/shuklaabhi/events{/privacy}", "received_events_url": "https://api.github.com/users/shuklaabhi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-14T04:50:20Z", "updated_at": "2020-03-16T13:33:11Z", "closed_at": "2020-03-16T13:33:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\n\r\nroot@ip-10-1-12-166:/opt/datadog-agent/embedded# datadog-agent version\r\nAgent 7.16.1 - Commit: 02e0969 - Serialization version: 4.15.0 - Go version: go1.12.9\r\nroot@ip-10-1-12-166:/opt/datadog-agent/embedded#\r\n\r\n\r\nroot@ip-10-1-12-166:/opt/datadog-agent/embedded# /opt/datadog-agent/embedded/bin/python\r\nPython 3.7.4 (default, Dec 31 2019, 19:02:30)\r\n[GCC 4.7.2] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import aggregator\r\nTraceback (most recent call last):\r\nFile \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'aggregator'\r\n>>> from datadog_checks.base.checks.base import aggregator\r\n>>> type(aggregator)\r\n<class 'datadog_checks.base.stubs.aggregator.AggregatorStub'>\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n\r\n**Describe the results you received:**\r\nMongoDB integration doesn't dispatch events, because it uses aggregator, in absence of which it uses a stub which does nothing.  \r\n\r\n**Describe the results you expected:**\r\nEvents when replica status changes\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/6034", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6034/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6034/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/6034/events", "html_url": "https://github.com/DataDog/integrations-core/issues/6034", "id": 579809523, "node_id": "MDU6SXNzdWU1Nzk4MDk1MjM=", "number": 6034, "title": "consul integration does not collect all metrics", "user": {"login": "josefschabasser", "id": 45227795, "node_id": "MDQ6VXNlcjQ1MjI3Nzk1", "avatar_url": "https://avatars1.githubusercontent.com/u/45227795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josefschabasser", "html_url": "https://github.com/josefschabasser", "followers_url": "https://api.github.com/users/josefschabasser/followers", "following_url": "https://api.github.com/users/josefschabasser/following{/other_user}", "gists_url": "https://api.github.com/users/josefschabasser/gists{/gist_id}", "starred_url": "https://api.github.com/users/josefschabasser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josefschabasser/subscriptions", "organizations_url": "https://api.github.com/users/josefschabasser/orgs", "repos_url": "https://api.github.com/users/josefschabasser/repos", "events_url": "https://api.github.com/users/josefschabasser/events{/privacy}", "received_events_url": "https://api.github.com/users/josefschabasser/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-03-12T09:39:11Z", "updated_at": "2020-06-15T14:57:06Z", "closed_at": "2020-05-26T20:14:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\n    consul (1.11.0)\r\n    ---------------\r\n      Instance ID: consul:REDACTED [OK]\r\n      Configuration Source: kubelet:docker://RADACTED\r\n      Total Runs: 4,406\r\n      Metric Samples: Last Run: 97, Total: 427,382\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 43, Total: 189,670\r\n      Average Execution Time : 75ms\r\n      metadata:\r\n        version.major: 1\r\n        version.minor: 7\r\n        version.patch: 1\r\n        version.raw: 1.7.1\r\n        version.scheme: semver\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nAzure Kubernetes Service (k8s v1.15.5)\r\nconsul v1.7.1\r\ndd-agent v7.16.0\r\n\r\n**Steps to reproduce the issue:**\r\n1. install consul with dd autodiscovery annotations (using helm)\r\n2. install datadog (using helm)\r\n3. wait\r\n\r\n**Describe the results you received:**\r\nParts of the dashboard stay empty. Metrics explorer does not list `consul.raft` at all, other consul metrics are there.\r\n\r\n**Describe the results you expected:**\r\nConsul dashboard fully operational, metrics explorer showing `consul.raft` metrics.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nIf I tell consul to send metrics to dogstatsd, everything is working fine. Consul dogstatsd configuration is marked optional in datadog documentation. If I manually check the metrics, this happens:\r\n```\r\n$ kubectl port-forward svc/consul 8500:8500 &\r\n$ watch -n 5 \"curl -s http://127.0.0.1:8500/v1/agent/metrics | jq '.Samples[] | select(.Name==\\\"consul.raft.leader.lastContact\\\")'\"\r\n{\r\n  \"Name\": \"consul.raft.leader.lastContact\",\r\n  \"Count\": 8,\r\n  \"Rate\": 36.2,\r\n  \"Sum\": 362,\r\n  \"Min\": 8,\r\n  \"Max\": 83,\r\n  \"Mean\": 45.25,\r\n  \"Stddev\": 24.967121236881574,\r\n  \"Labels\": {}\r\n}\r\n```\r\nThis means, that the metrics are in fact provided, but dd doesn't collect them.\r\n\r\nPS: I didn't know what info output to post, so I decided to restrict it to the consul integration.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5950", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5950/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5950/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5950/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5950", "id": 574198858, "node_id": "MDU6SXNzdWU1NzQxOTg4NTg=", "number": 5950, "title": "Error: UPGRADE FAILED: failed to create resource: ConfigMap in version \"v1\" cannot be handled as a ConfigMap", "user": {"login": "nealAR", "id": 1644115, "node_id": "MDQ6VXNlcjE2NDQxMTU=", "avatar_url": "https://avatars3.githubusercontent.com/u/1644115?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nealAR", "html_url": "https://github.com/nealAR", "followers_url": "https://api.github.com/users/nealAR/followers", "following_url": "https://api.github.com/users/nealAR/following{/other_user}", "gists_url": "https://api.github.com/users/nealAR/gists{/gist_id}", "starred_url": "https://api.github.com/users/nealAR/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nealAR/subscriptions", "organizations_url": "https://api.github.com/users/nealAR/orgs", "repos_url": "https://api.github.com/users/nealAR/repos", "events_url": "https://api.github.com/users/nealAR/events{/privacy}", "received_events_url": "https://api.github.com/users/nealAR/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 592413329, "node_id": "MDU6TGFiZWw1OTI0MTMzMjk=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/containers", "name": "containers", "color": "0052cc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-02T19:36:05Z", "updated_at": "2020-07-29T12:28:46Z", "closed_at": "2020-07-29T12:28:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Per [this example](https://github.com/DataDog/integrations-core/blob/master/kube_scheduler/datadog_checks/kube_scheduler/data/conf.yaml.example)  I'm trying to upgrade our Helm installation of datadog using the following syntax: \r\n\r\n    helm upgrade datadog-monitoring --set datadog.confd.\"kube_scheduler\\.yaml\".instances[0].prometheus_url=\"http://localhost:10251/metrics\",datadog.confd.\"kube_scheduler\\.yaml\".init_config= stable/datadog\r\n\r\nHowever I'm getting the error below regardless of any attempt at altering the syntax of the `prometheus_url` value (putting the url in quotes, escaping the quotes, etc): \r\n\r\n> Error: UPGRADE FAILED: failed to create resource: ConfigMap in version \"v1\" cannot be handled as a ConfigMap: v1.ConfigMap.Data: ReadString: expects \" or n, but found {, error found in #10 byte of ...|er.yaml\":{\"instances|..., bigger context ...|{\"apiVersion\":\"v1\",\"data\":{\"kube_scheduler.yaml\":{\"instances\":[{\"prometheus_url\":\"\\\"http://localhost|...\r\n\r\nIf I add the `--dry-run --debug` flags I get the following yaml output: \r\n\r\n    REVISION: 7\r\n    RELEASED: Mon Mar  2 14:28:52 2020\r\n    CHART: datadog-1.39.7\r\n    USER-SUPPLIED VALUES:\r\n    datadog:\r\n      confd:\r\n        kube_scheduler.yaml:\r\n          init_config: \"\"\r\n          instances:\r\n          - prometheus_url: http://localhost:10251/metrics\r\n\r\nThe Yaml output appears to mesh with the integration as specified in the link above. \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5826", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5826/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5826/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5826/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5826", "id": 569183812, "node_id": "MDU6SXNzdWU1NjkxODM4MTI=", "number": 5826, "title": "[Supervisor] Confusing error message when proc_regex is a string", "user": {"login": "alexsegura", "id": 1162230, "node_id": "MDQ6VXNlcjExNjIyMzA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162230?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexsegura", "html_url": "https://github.com/alexsegura", "followers_url": "https://api.github.com/users/alexsegura/followers", "following_url": "https://api.github.com/users/alexsegura/following{/other_user}", "gists_url": "https://api.github.com/users/alexsegura/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexsegura/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexsegura/subscriptions", "organizations_url": "https://api.github.com/users/alexsegura/orgs", "repos_url": "https://api.github.com/users/alexsegura/repos", "events_url": "https://api.github.com/users/alexsegura/events{/privacy}", "received_events_url": "https://api.github.com/users/alexsegura/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-02-21T21:05:31Z", "updated_at": "2020-04-04T16:22:22Z", "closed_at": "2020-04-04T16:22:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "When `proc_regex` option is (wrongly) configured as a string (i.e `proc_regex: 'some-regex'`), the error message is unclear. I was struggling to understand, because when the string was indeed not empty and valid.\r\n\r\nIt should be something like\r\n> proc_regex should be a list of strings\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/9f39d4d93b3567570f7ac34253d216ff842a152e/supervisord/datadog_checks/supervisord/supervisord.py#L115-L122", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5825", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5825/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5825/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5825/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5825", "id": 569169422, "node_id": "MDU6SXNzdWU1NjkxNjk0MjI=", "number": 5825, "title": "[Supervisor] Can't use user & pass options when using socket", "user": {"login": "alexsegura", "id": 1162230, "node_id": "MDQ6VXNlcjExNjIyMzA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162230?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexsegura", "html_url": "https://github.com/alexsegura", "followers_url": "https://api.github.com/users/alexsegura/followers", "following_url": "https://api.github.com/users/alexsegura/following{/other_user}", "gists_url": "https://api.github.com/users/alexsegura/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexsegura/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexsegura/subscriptions", "organizations_url": "https://api.github.com/users/alexsegura/orgs", "repos_url": "https://api.github.com/users/alexsegura/repos", "events_url": "https://api.github.com/users/alexsegura/events{/privacy}", "received_events_url": "https://api.github.com/users/alexsegura/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-21T20:30:20Z", "updated_at": "2020-04-03T16:50:49Z", "closed_at": "2020-04-03T16:50:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "On my Supervisor installation, I have no `[inet_http_server]` section, and yet I can do `supervisorctl -c supervisord.conf -u <user> -p <password>`\r\n\r\n**/etc/supervisor/supervisord.conf**\r\n\r\n```ini\r\n[unix_http_server]\r\nfile=/var/run/supervisor.sock\r\n\r\n[supervisord]\r\n...\r\n\r\n[rpcinterface:supervisor]\r\nsupervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\r\n\r\n[supervisorctl]\r\nserverurl=unix:///var/run/supervisor.sock\r\n```\r\n\r\nThe code of the integration ignores the `user` & `pass` options when there is a `socket` option. \r\n\r\nhttps://github.com/DataDog/integrations-core/blob/5693dc717d4e41533aa693e2a87ad90f08a5985a/supervisord/datadog_checks/supervisord/supervisord.py#L164-L177", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5751", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5751/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5751/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5751/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5751", "id": 565382767, "node_id": "MDU6SXNzdWU1NjUzODI3Njc=", "number": 5751, "title": "ImportError: No module named datadog_checks.base", "user": {"login": "ypoplavs", "id": 45286051, "node_id": "MDQ6VXNlcjQ1Mjg2MDUx", "avatar_url": "https://avatars0.githubusercontent.com/u/45286051?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ypoplavs", "html_url": "https://github.com/ypoplavs", "followers_url": "https://api.github.com/users/ypoplavs/followers", "following_url": "https://api.github.com/users/ypoplavs/following{/other_user}", "gists_url": "https://api.github.com/users/ypoplavs/gists{/gist_id}", "starred_url": "https://api.github.com/users/ypoplavs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ypoplavs/subscriptions", "organizations_url": "https://api.github.com/users/ypoplavs/orgs", "repos_url": "https://api.github.com/users/ypoplavs/repos", "events_url": "https://api.github.com/users/ypoplavs/events{/privacy}", "received_events_url": "https://api.github.com/users/ypoplavs/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-02-14T15:05:49Z", "updated_at": "2020-02-26T09:02:20Z", "closed_at": "2020-02-26T09:02:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "Library `datadog_checks.base` cannot be imported anymore, however it worked perfectly fine about two weeks ago.\r\n\r\nI am trying to create a custom Datadog Agent check using Python script. However, it keeps giving me the following error: \r\n\r\n` from checks import AgentCheck\r\nImportError: No module named checks`\r\n\r\nI tried to import `datadog_checks.checks` module as well but all to no avail. The installation of library from sources did not help either. \r\n\r\nDatadog Version: v6.16.1\r\n\r\nPlease let me know if you need more information.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5675", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5675/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5675/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5675/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5675", "id": 562193698, "node_id": "MDU6SXNzdWU1NjIxOTM2OTg=", "number": 5675, "title": "Unable to get disk metrics for /sys/kernel/debug/tracing: [Errno 13] Permission denied: '/sys/kernel/debug/tracing'", "user": {"login": "SaloSentinelOne", "id": 57761470, "node_id": "MDQ6VXNlcjU3NzYxNDcw", "avatar_url": "https://avatars1.githubusercontent.com/u/57761470?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SaloSentinelOne", "html_url": "https://github.com/SaloSentinelOne", "followers_url": "https://api.github.com/users/SaloSentinelOne/followers", "following_url": "https://api.github.com/users/SaloSentinelOne/following{/other_user}", "gists_url": "https://api.github.com/users/SaloSentinelOne/gists{/gist_id}", "starred_url": "https://api.github.com/users/SaloSentinelOne/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SaloSentinelOne/subscriptions", "organizations_url": "https://api.github.com/users/SaloSentinelOne/orgs", "repos_url": "https://api.github.com/users/SaloSentinelOne/repos", "events_url": "https://api.github.com/users/SaloSentinelOne/events{/privacy}", "received_events_url": "https://api.github.com/users/SaloSentinelOne/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-02-09T15:30:33Z", "updated_at": "2020-02-28T22:05:30Z", "closed_at": "2020-02-28T22:05:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/DataDog/integrations-core/blob/c9f7ce47f923d546f81818bf4120a1d54cf0e4b8/disk/datadog_checks/disk/disk.py#L63\r\n\r\n```\r\n>>> import psutil\r\n>>> \r\n>>> psutil.disk_partitions(all=True)\r\n[\r\nsdiskpart(device='sysfs', mountpoint='/sys', fstype='sysfs', opts='rw,nosuid,nodev,noexec,relatime'), \r\nsdiskpart(device='proc', mountpoint='/proc', fstype='proc', opts='rw,nosuid,nodev,noexec,relatime'),\r\nsdiskpart(device='udev', mountpoint='/dev', fstype='devtmpfs', opts='rw,nosuid,relatime,size=65254592k,nr_inodes=16313648,mode=755'),\r\nsdiskpart(device='devpts', mountpoint='/dev/pts', fstype='devpts', opts='rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000'),\r\nsdiskpart(device='tmpfs', mountpoint='/run', fstype='tmpfs', opts='rw,nosuid,noexec,relatime,size=13053332k,mode=755'),\r\nsdiskpart(device='/dev/nvme0n1p2', mountpoint='/', fstype='ext4', opts='rw,relatime,data=ordered'),\r\nsdiskpart(device='securityfs', mountpoint='/sys/kernel/security', fstype='securityfs', opts='rw,nosuid,nodev,noexec,relatime'),\r\nsdiskpart(device='tmpfs', mountpoint='/dev/shm', fstype='tmpfs', opts='rw,nosuid,nodev'),\r\nsdiskpart(device='tmpfs', mountpoint='/run/lock', fstype='tmpfs', opts='rw,nosuid,nodev,noexec,relatime,size=5120k'),\r\nsdiskpart(device='tmpfs', mountpoint='/sys/fs/cgroup', fstype='tmpfs', opts='ro,nosuid,nodev,noexec,mode=755'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/systemd', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd'),\r\nsdiskpart(device='pstore', mountpoint='/sys/fs/pstore', fstype='pstore', opts='rw,nosuid,nodev,noexec,relatime'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/cpu,cpuacct', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,cpu,cpuacct'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/pids', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,pids'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/devices', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,devices'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/blkio', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,blkio'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/freezer', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,freezer'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/perf_event', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,perf_event'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/memory', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,memory'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/cpuset', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,cpuset'),\r\nsdiskpart(device='cgroup', mountpoint='/sys/fs/cgroup/net_cls,net_prio', fstype='cgroup', opts='rw,nosuid,nodev,noexec,relatime,net_cls,net_prio'),\r\nsdiskpart(device='systemd-1', mountpoint='/proc/sys/fs/binfmt_misc', fstype='autofs', opts='rw,relatime,fd=29,pgrp=1,timeout=0,minproto=5,maxproto=5,direct,pipe_ino=13040'),\r\nsdiskpart(device='mqueue', mountpoint='/dev/mqueue', fstype='mqueue', opts='rw,relatime'),\r\nsdiskpart(device='debugfs', mountpoint='/sys/kernel/debug', fstype='debugfs', opts='rw,relatime'),\r\nsdiskpart(device='hugetlbfs', mountpoint='/dev/hugepages', fstype='hugetlbfs', opts='rw,relatime'),\r\nsdiskpart(device='sunrpc', mountpoint='/run/rpc_pipefs', fstype='rpc_pipefs', opts='rw,relatime'),\r\nsdiskpart(device='/dev/md0', mountpoint='/mnt/dfs', fstype='xfs', opts='rw,noatime,attr2,inode64,noquota'),\r\nsdiskpart(device='binfmt_misc', mountpoint='/proc/sys/fs/binfmt_misc', fstype='binfmt_misc', opts='rw,relatime'),\r\nsdiskpart(device='tracefs', mountpoint='/sys/kernel/debug/tracing', fstype='tracefs', opts='rw,relatime')\r\n]\r\n```\r\n\r\n```bash\r\n# uname -a\r\nLinux node 4.9.0-11-amd64 #1 SMP Debian 4.9.189-3+deb9u2 (2019-11-11) x86_64 GNU/Linux\r\n```\r\n\r\n```bash\r\n# pip3 show psutil\r\nName: psutil\r\nVersion: 5.6.7\r\nSummary: Cross-platform lib for process and system monitoring in Python.\r\nHome-page: https://github.com/giampaolo/psutil\r\nAuthor: Giampaolo Rodola\r\nAuthor-email: g.rodola@gmail.com\r\nLicense: BSD\r\nLocation: /usr/local/lib/python3.5/dist-packages\r\nRequires: \r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5655", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5655/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5655/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5655/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5655", "id": 560502963, "node_id": "MDU6SXNzdWU1NjA1MDI5NjM=", "number": 5655, "title": "WMI integration throws Exception: SWbemLocator Not enough storage is available to process this command", "user": {"login": "rlaveycal", "id": 6595659, "node_id": "MDQ6VXNlcjY1OTU2NTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/6595659?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rlaveycal", "html_url": "https://github.com/rlaveycal", "followers_url": "https://api.github.com/users/rlaveycal/followers", "following_url": "https://api.github.com/users/rlaveycal/following{/other_user}", "gists_url": "https://api.github.com/users/rlaveycal/gists{/gist_id}", "starred_url": "https://api.github.com/users/rlaveycal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rlaveycal/subscriptions", "organizations_url": "https://api.github.com/users/rlaveycal/orgs", "repos_url": "https://api.github.com/users/rlaveycal/repos", "events_url": "https://api.github.com/users/rlaveycal/events{/privacy}", "received_events_url": "https://api.github.com/users/rlaveycal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-02-05T16:56:19Z", "updated_at": "2020-02-21T16:39:11Z", "closed_at": "2020-02-21T16:39:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "\r\n```text\r\n===============\r\nAgent (v7.16.0)\r\n===============\r\n\r\n  Status date: 2020-02-05 15:56:45.740020 GMT\r\n  Agent start: 2020-02-05 15:03:08.601503 GMT\r\n  Pid: 25188\r\n  Go Version: go1.12.9\r\n  Python Version: 3.7.4\r\n  Build arch: amd64\r\n\r\n Host Info\r\n  =========\r\n    bootTime: 2020-01-30 09:06:55.000000 GMT\r\n    os: windows\r\n    platform: Windows Server 2016 Datacenter\r\n    platformFamily: Windows Server 2016 Datacenter\r\n    platformVersion: 10.0 Build 14393\r\n    procs: 255\r\n    uptime: 149h56m12s\r\n\r\nwmi_check (1.6.0)\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nThe WMI Check integration is configured to capture metrics for multiple instances of a specific process and tag them using the command line, as below\r\n\r\n```yaml\r\n- class: Win32_PerfFormattedData_PerfProc_Process\r\n  metrics:\r\n  - - ThreadCount\r\n    - proc.threads.count\r\n    - gauge\r\n  - - VirtualBytes\r\n    - proc.mem.virtual\r\n    - gauge\r\n  - - PrivateBytes\r\n    - proc.mem.private\r\n    - gauge\r\n  - - WorkingSet\r\n    - proc.mem.workingset\r\n    - gauge\r\n  - - PageFaultsPerSec\r\n    - proc.mem.page_faults_per_sec\r\n    - gauge\r\n  - - PercentProcessorTime\r\n    - proc.cpu_pct\r\n    - gauge\r\n  - - IOReadBytesPerSec\r\n    - proc.io.bytes_read\r\n    - gauge\r\n  - - IOWriteBytesPerSec\r\n    - proc.io.bytes_written\r\n    - gauge\r\n  filters:\r\n    - Name: Calastone.Core.MessageAdapter.Console%\r\n  tag_by: Name\r\n  tag_queries:\r\n    - [IDProcess, Win32_Process, Handle, CommandLine]\r\n```\r\n\r\nThere are 17 instances of the process running.\r\n\r\n**Describe the results you received:**\r\n\r\n- After a period of time (can be 40+ minutes) the following error starts to be logged\r\n\r\n```\r\n2020-02-04 16:31:29 GMT | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | wmi_check:a7174f61bd7a5360 | (sampler.py:469) | Failed to execute WMI query (Select CommandLine from Win32_Process WHERE ( Handle = '8408' ))\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Datadog\\Datadog Agent\\embedded3\\lib\\site-packages\\datadog_checks\\base\\checks\\win\\wmi\\sampler.py\", line 464, in _query\r\n    raw_results = self.get_connection().ExecQuery(wql, \"WQL\", query_flags)\r\n  File \"C:\\Program Files\\Datadog\\Datadog Agent\\embedded3\\lib\\site-packages\\datadog_checks\\base\\checks\\win\\wmi\\sampler.py\", line 351, in get_connection\r\n    connection = locator.ConnectServer(self.host, self.namespace, self.username, self.password, *additional_args)\r\n  File \"<COMObject WbemScripting.SWbemLocator>\", line 5, in ConnectServer\r\n  File \"C:\\Program Files\\Datadog\\Datadog Agent\\embedded3\\lib\\site-packages\\win32com\\client\\dynamic.py\", line 287, in _ApplyTypes_\r\n    result = self._oleobj_.InvokeTypes(*(dispid, LCID, wFlags, retType, argTypes) + args)\r\npywintypes.com_error: (-2147352567, 'Exception occurred.', (0, 'SWbemLocator', 'Not enough storage is available to process this command. ', None, 0, -2147024888), None)\r\n2020-02-04 16:31:29 GMT | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | wmi_check:a7174f61bd7a5360 | (__init__.py:88) | Failed to extract a tag from `tag_queries` parameter: no result was returned. wmi_object={'threadcount': 27.0, 'virtualbytes': 823386112.0, 'privatebytes': 304635904.0, 'workingset': 367628288.0, 'pagefaultspersec': 0.0, 'percentprocessortime': 0.0, 'ioreadbytespersec': 0.0, 'iowritebytespersec': 0.0, 'idprocess': 8408.0, 'name': 'Calastone.Core.MessageAdapter.Console#3'} - query=['IDProcess', 'Win32_Process', 'Handle', 'CommandLine']\r\n2020-02-04 16:31:29 GMT | CORE | WARN | (pkg/collector/python/datadog_agent.go:118 in LogMessage) | wmi_check:a7174f61bd7a5360 | (sampler.py:469) | Failed to execute WMI query (Select CommandLine from Win32_Process WHERE ( Handle = '14836' ))\r\n```\r\n\r\n- The number of threads used by the agent process is observed to be rocketing (> 1700)\r\n- The server becomes unresponsive\r\n\r\n**Diagnosis:**\r\n\r\nThis issue didn't occur on the previous version of the agent we were using (6.7.0).\r\n\r\nLooking at the source code suggests the problem was introduced as part of #3987\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/010ed622d62c9dd7de28d76f1191a4be5960a965/datadog_checks_base/datadog_checks/base/checks/win/wmi/__init__.py#L117 creates a WMISampler for EVERY tag query that needs to be run. With the new logic that creates a thread for each query that is never released!\r\n\r\n**Solution:**\r\n\r\nThe follow hack fixes the problem. I'll put it into a PR.\r\n\r\nChange `sampler.py`\r\n\r\n```python\r\n    def _query_sample_loop(self):\r\n...\r\n        while True:\r\n            self._runSampleEvent.wait()\r\n            if self._stopping:\r\n                return\r\n\r\n    def dispose(self):\r\n        \"\"\"\r\n        Dispose of the internal thread\r\n        \"\"\"\r\n        self._stopping = True\r\n        self._runSampleEvent.set()\r\n```\r\n\r\nChange `__init__.py`\r\n```python\r\n    def _get_tag_query_tag(self, sampler, wmi_obj, tag_query):\r\n...\r\n        tag = \"{tag_name}:{tag_value}\".format(tag_name=target_property.lower(), tag_value=\"_\".join(link_value.split()))\r\n\r\n        tag_query_sampler.dispose()\r\n```\r\n\r\nThere also looks to be scope to cache these WMISampler classes like the main metric samplers. Also the connection created in `get_connection` could be created in the sampler thread method since it is now bound to that thread\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5611", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5611/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5611/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5611/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5611", "id": 558265435, "node_id": "MDU6SXNzdWU1NTgyNjU0MzU=", "number": 5611, "title": "[TLS: local_cert_path] unable to load PEM certs with .crt extensions", "user": {"login": "jslusher", "id": 93294, "node_id": "MDQ6VXNlcjkzMjk0", "avatar_url": "https://avatars3.githubusercontent.com/u/93294?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jslusher", "html_url": "https://github.com/jslusher", "followers_url": "https://api.github.com/users/jslusher/followers", "following_url": "https://api.github.com/users/jslusher/following{/other_user}", "gists_url": "https://api.github.com/users/jslusher/gists{/gist_id}", "starred_url": "https://api.github.com/users/jslusher/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jslusher/subscriptions", "organizations_url": "https://api.github.com/users/jslusher/orgs", "repos_url": "https://api.github.com/users/jslusher/repos", "events_url": "https://api.github.com/users/jslusher/events{/privacy}", "received_events_url": "https://api.github.com/users/jslusher/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-31T17:30:06Z", "updated_at": "2020-02-11T16:30:39Z", "closed_at": "2020-02-11T16:30:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v6.14.0)\r\n===============\r\n\r\n  Status date: 2020-01-31 17:19:17.071722 UTC\r\n  Agent start: 2020-01-31 00:15:35.947147 UTC\r\n  Pid: 339\r\n  Go Version: go1.12.9\r\n  Python Version: 2.7.16\r\n  Check Runners: 4\r\n  Log Level: WARNING\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 1.29ms\r\n    System UTC time: 2020-01-31 17:19:17.071722 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2020-01-24 17:51:55.000000 UTC\r\n    kernelVersion: 3.10.0-1062.9.1.el7.x86_64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: 10.1\r\n    procs: 69\r\n    uptime: 150h23m45s\r\n    virtualizationRole: host\r\n    virtualizationSystem: kvm\r\n\r\n  Hostnames\r\n  =========\r\n    host_aliases: [controller-1-opus-v1.staging.example.com]\r\n    hostname: controller-1-opus-v1.staging.example.com\r\n    socket-fqdn: datadog-2n5w6\r\n    socket-hostname: datadog-2n5w6\r\n    host tags:\r\n      env:staging\r\n      role:kubernetes\r\n      cluster:opus-staging\r\n    hostname provider: container\r\n    unused hostname providers:\r\n      aws: not retrieving hostname from AWS: the host is not an ECS instance, and other providers already retrieve non-default hostnames\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: Get http://169.254.169.254/computeMetadata/v1/instance/hostname: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    coredns (1.2.0)\r\n    ---------------\r\n      Instance ID: coredns:e9e54b44455e0e34 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/coredns.d/auto_conf.yaml\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 137, Total: 561,015\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,095\r\n      Average Execution Time : 30ms\r\n      \r\n    \r\n    cpu\r\n    ---\r\n      Instance ID: cpu [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 6, Total: 24,564\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    disk (2.5.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 314, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 91ms\r\n      \r\n    \r\n    docker\r\n    ------\r\n      Instance ID: docker [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.yaml\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 241, Total: 986,654\r\n      Events: Last Run: 0, Total: 1\r\n      Service Checks: Last Run: 1, Total: 4,094\r\n      Average Execution Time : 24ms\r\n      \r\n    \r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 5, Total: 20,475\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    io\r\n    --\r\n      Instance ID: io [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 65, Total: 266,065\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    kubelet (3.3.2)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 78, Total: 319,624\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 4, Total: 16,380\r\n      Average Execution Time : 154ms\r\n      \r\n    \r\n    load\r\n    ----\r\n      Instance ID: load [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 6, Total: 24,564\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    memory\r\n    ------\r\n      Instance ID: memory [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 17, Total: 69,598\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    network (1.11.4)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 61, Total: 249,795\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 2ms\r\n      \r\n    \r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 1, Total: 4,094\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,094\r\n      Average Execution Time : 15ms\r\n      \r\n    \r\n    tls (1.2.0)\r\n    -----------\r\n      Instance ID: tls:542c9cac6923a09f [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,094\r\n      Average Execution Time : 0s\r\n      \r\n      Instance ID: tls:67443a6e0603dad1 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,095\r\n      Average Execution Time : 0s\r\n      \r\n      Instance ID: tls:6bdaabf90ec05a5a [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,094\r\n      Average Execution Time : 0s\r\n      \r\n      Instance ID: tls:7a31a6a46b4dedde [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,094\r\n      Average Execution Time : 0s\r\n      \r\n      Instance ID: tls:8a5b466f7b05d1b7 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,095\r\n      Average Execution Time : 0s\r\n      \r\n      Instance ID: tls:9bffe636f25a9259 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,094\r\n      Average Execution Time : 0s\r\n      \r\n      Instance ID: tls:e43d8794821c495e [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,095\r\n      Average Execution Time : 0s\r\n      \r\n      Instance ID: tls:e4547a4365c5c93b [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,095\r\n      Average Execution Time : 0s\r\n      \r\n      Instance ID: tls:efe8c9aca44a1a8e [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 4,094\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 4,094\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    uptime\r\n    ------\r\n      Instance ID: uptime [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 4,095\r\n      Metric Samples: Last Run: 1, Total: 4,095\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n    \r\n  Failed checks\r\n  =============\r\n    no checks\r\n    \r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 4,094\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 342\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 8,530\r\n    TimeseriesV1: 4,094\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 70ee6: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 70ee6\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n    LogsProcessed: 7160\r\n    LogsSent: 7160\r\n\r\n  directory\r\n  ---------\r\n    Type: file\r\n    Path: /hostvarlog/kubelet.log\r\n    Status: OK\r\n    Inputs: /hostvarlog/kubelet.log \r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 3.9 M\r\n  Dogstatsd Metric Sample: 298,877\r\n  Event: 2\r\n  Events Flushed: 2\r\n  Number Of Flushes: 4,094\r\n  Series Flushed: 2.8 M\r\n  Service Check: 147,471\r\n  Service Checks Flushed: 151,540\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 298,876\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 19 M\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 298,877\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n=====================\r\nDatadog Cluster Agent\r\n=====================\r\n\r\n  - Datadog Cluster Agent endpoint detected: https://10.23.8.146:5005\r\n  Successfully connected to the Datadog Cluster Agent.\r\n  - Running: 1.3.2&#43;commit.e3f5101\r\n\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nDatadog cluster agent in kubernetes on bare metal (centos 7)\r\n**Steps to reproduce the issue:**\r\n1. Mount `/etc/kubernetes/pki` in the agent DaemonSet \r\n2. Configure the tls integration to check a .crt file\r\n```\r\n          - local_cert_path: \"/kube_pki/apiserver.crt\"\r\n            name: apiserver\r\n            validate_hostname: false\r\n```\r\n3. Run the check\r\n\r\n**Describe the results you received:**\r\n```\r\n[\r\n  {\r\n    \"check\": \"tls.cert_validation\",\r\n    \"host_name\": \"controller-1-opus-v1.staging.example.com\",\r\n    \"timestamp\": 1580430551,\r\n    \"status\": 2,\r\n    \"message\": \"Unable to parse the certificate: Unable to load certificate\",\r\n    \"tags\": []\r\n  }\r\n]\r\n```\r\n\r\n**Describe the results you expected:**\r\nI would expect it to be able to load the cert. Permissions are correct and the general status of the tls integration is OK:\r\n\r\n```\r\n    tls (1.2.0)\r\n    -----------\r\n      Instance ID: tls:542c9cac6923a09f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tls.yaml\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 0s\r\n```\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nI'm pretty sure this has to do with this line in [tls.py](https://github.com/DataDog/integrations-core/blob/master/tls/datadog_checks/tls/tls.py#L317-L318). The function is trying to use `load_der_x509_certificate` to load a PEM formatted certificate because of its filename extension.\r\n\r\n```\r\nhead -1 /kube_pki/apiserver.crt\r\n-----BEGIN CERTIFICATE-----\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5606", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5606/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5606/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5606/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5606", "id": 557876545, "node_id": "MDU6SXNzdWU1NTc4NzY1NDU=", "number": 5606, "title": "TCP Check is always OK status unless our process down.", "user": {"login": "ntsutake", "id": 58926594, "node_id": "MDQ6VXNlcjU4OTI2NTk0", "avatar_url": "https://avatars1.githubusercontent.com/u/58926594?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ntsutake", "html_url": "https://github.com/ntsutake", "followers_url": "https://api.github.com/users/ntsutake/followers", "following_url": "https://api.github.com/users/ntsutake/following{/other_user}", "gists_url": "https://api.github.com/users/ntsutake/gists{/gist_id}", "starred_url": "https://api.github.com/users/ntsutake/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ntsutake/subscriptions", "organizations_url": "https://api.github.com/users/ntsutake/orgs", "repos_url": "https://api.github.com/users/ntsutake/repos", "events_url": "https://api.github.com/users/ntsutake/events{/privacy}", "received_events_url": "https://api.github.com/users/ntsutake/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-31T02:36:07Z", "updated_at": "2020-01-31T04:51:59Z", "closed_at": "2020-01-31T04:51:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "I want to check tcp process alive or dead.\r\nAnd I check nginx tcp, but TCP Check is always OK status unless our process down.\r\n\r\n```text\r\n/etc/datadog-agent/conf.d/tcp_check.d/conf.yaml\r\n---\r\ninit_config:\r\n\r\ninstances:\r\n  - name: NginX\r\n    host: 127.0.0.1\r\n    port: 80\r\n---\r\n\r\n$ sudo datadog-agent status\r\n...snip...\r\ntcp_check (2.3.1)\r\n    -----------------\r\n      Instance ID: tcp_check:NginX:227a261a4235b61e [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/tcp_check.yaml\r\n      Total Runs: 11\r\n      Metric Samples: Last Run: 2, Total: 22\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 2, Total: 22\r\n      Average Execution Time : 0s\r\n...snip...\r\n$ sudo service nginx status\r\n\u25cf nginx.service - nginx - high performance web server\r\n   Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled)\r\n   Active: inactive (dead) since Fri 2020-01-31 02:20:24 UTC; 6min ago\r\n     Docs: http://nginx.org/en/docs/\r\n  Process: 19807 ExecStop=/bin/kill -s TERM $MAINPID (code=exited, status=0/SUCCESS)\r\n Main PID: 408 (code=exited, status=0/SUCCESS)\r\n\r\nJan 31 02:20:24 ip-192-168-101-58 systemd[1]: Stopping nginx - high performance web server...\r\nJan 31 02:20:24 ip-192-168-101-58 systemd[1]: Stopped nginx - high performance web server.\r\nWarning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.\r\n\r\n$ curl localhost\r\ncurl: (7) Failed to connect to localhost port 80: Connection refused\r\n```\r\n\r\n![Screenshot from 2020-01-31 11-34-08](https://user-images.githubusercontent.com/58926594/73507889-ae770f00-441d-11ea-8628-216d0b86f843.png)\r\n\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n* Ubuntu 18.04 in AWS\r\n* Agent 7.16.0 - Commit: 3e13b77 - Serialization version: 4.15.0 - Go version: go1.12.9\r\n\r\n**Steps to reproduce the issue:**\r\n1. install datadog-agent\r\n2. install nginx\r\n3. add conf.yaml\r\n4. restart datadog-agent and nginx\r\n5. stop nginx\r\n\r\n**Describe the results you received:**\r\n TCP Check is always OK status unless our process down.\r\n\r\n**Describe the results you expected:**\r\n TCP Check shows CRIT status if our process down.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI try to modify tcp_check.py source.\r\nI guess that this code always pass success case(), if this code catches the exception.\r\n\r\n```\r\n# (C) Datadog, Inc. 2010-2019\r\n# All rights reserved\r\n# Licensed under Simplified BSD License (see LICENSE)\r\nimport socket\r\nimport time\r\n\r\nfrom datadog_checks.base import AgentCheck\r\n\r\n\r\nclass BadConfException(Exception):\r\n    pass\r\n\r\n\r\nclass TCPCheck(AgentCheck):\r\n\r\n    SOURCE_TYPE_NAME = 'system'\r\n    SERVICE_CHECK_NAME = 'tcp.can_connect'\r\n\r\n    def __init__(self, name, init_config, instances):\r\n        super(TCPCheck, self).__init__(name, init_config, instances)\r\n        instance = self.instances[0]\r\n\r\n        self.instance_name = self.normalize_tag(instance['name'])\r\n        port = instance.get('port', None)\r\n        self.timeout = float(instance.get('timeout', 10))\r\n        self.response_time = instance.get('collect_response_time', False)\r\n        self.custom_tags = instance.get('tags', [])\r\n        self.socket_type = None\r\n\r\n        try:\r\n            self.port = int(port)\r\n        except Exception:\r\n            raise BadConfException(\"{} is not a correct port.\".format(str(port)))\r\n\r\n        try:\r\n            self.url = instance.get('host', None)\r\n            split = self.url.split(\":\")\r\n        except Exception:  # Would be raised if url is not a string\r\n            raise BadConfException(\"A valid url must be specified\")\r\n\r\n        # IPv6 address format: 2001:db8:85a3:8d3:1319:8a2e:370:7348\r\n        if len(split) == 8:  # It may then be a IP V6 address, we check that\r\n            for block in split:\r\n                if len(block) != 4:\r\n                    raise BadConfException(\"{} is not a correct IPv6 address.\".format(self.url))\r\n\r\n            self.addr = self.url\r\n            # It's a correct IP V6 address\r\n            self.socket_type = socket.AF_INET6\r\n\r\n        if self.socket_type is None:\r\n            try:\r\n                self.addr = socket.gethostbyname(self.url)\r\n                self.socket_type = socket.AF_INET\r\n            except Exception:\r\n                msg = \"URL: {} is not a correct IPv4, IPv6 or hostname\".format(self.url)\r\n                raise BadConfException(msg)\r\n\r\n    def check(self, instance):\r\n        start = time.time()\r\n+        fail_check = True\r\n        try:\r\n            self.log.debug(\"Connecting to {} {}\".format(self.addr, self.port))\r\n            sock = socket.socket(self.socket_type)\r\n            try:\r\n                sock.settimeout(self.timeout)\r\n                sock.connect((self.addr, self.port))\r\n            finally:\r\n                sock.close()\r\n\r\n        except socket.timeout as e:\r\n+            fail_check = False\r\n            # The connection timed out because it took more time than the specified value in the yaml config file\r\n            length = int((time.time() - start) * 1000)\r\n            self.log.info(\r\n                \"{}:{} is DOWN ({}). Connection failed after {} ms\".format(self.addr, self.port, str(e), length)\r\n            )\r\n            self.report_as_service_check(\r\n                AgentCheck.CRITICAL, \"{}. Connection failed after {} ms\".format(str(e), length)\r\n            )\r\n\r\n        except socket.error as e:\r\n+            fail_check = False\r\n            length = int((time.time() - start) * 1000)\r\n            if \"timed out\" in str(e):\r\n\r\n                # The connection timed out becase it took more time than the system tcp stack allows\r\n                self.log.warning(\r\n                    'The connection timed out because it took more time '\r\n                    'than the system tcp stack allows. You might want to '\r\n                    'change this setting to allow longer timeouts'\r\n                )\r\n                self.log.info(\"System tcp timeout. Assuming that the checked system is down\")\r\n                self.report_as_service_check(\r\n                    AgentCheck.CRITICAL,\r\n                    \"\"\"Socket error: {}.\r\n                 The connection timed out after {} ms because it took more time than the system tcp stack allows.\r\n                 You might want to change this setting to allow longer timeouts\"\"\".format(\r\n                        str(e), length\r\n                    ),\r\n                )\r\n\r\n            else:\r\n                self.log.info(\r\n                    \"{}:{} is DOWN ({}). Connection failed after {} ms\".format(self.addr, self.port, str(e), length)\r\n                )\r\n                self.report_as_service_check(\r\n                    AgentCheck.CRITICAL, \"{}. Connection failed after {} ms\".format(str(e), length)\r\n                )\r\n\r\n        except Exception as e:\r\n+            fail_check = False\r\n            length = int((time.time() - start) * 1000)\r\n            self.log.info(\r\n                \"{}:{} is DOWN ({}). Connection failed after {} ms\".format(self.addr, self.port, str(e), length)\r\n            )\r\n            self.report_as_service_check(\r\n                AgentCheck.CRITICAL, \"{}. Connection failed after {} ms\".format(str(e), length)\r\n            )\r\n\r\n        if self.response_time:\r\n            self.gauge(\r\n                'network.tcp.response_time',\r\n                time.time() - start,\r\n                tags=[\r\n                    'url:{}:{}'.format(instance.get('host', None), self.port),\r\n                    'instance:{}'.format(instance.get('name')),\r\n                ]\r\n                + self.custom_tags,\r\n            )\r\n-        self.log.debug(\"{}:{} is UP\".format(self.addr, self.port))\r\n-        self.report_as_service_check(AgentCheck.OK, 'UP')\r\n+        if fail_check:\r\n+           self.log.debug(\"{}:{} is UP\".format(self.addr, self.port))\r\n+            self.report_as_service_check(AgentCheck.OK, 'UP')\r\n\r\n    def report_as_service_check(self, status, msg=None):\r\n        if status == AgentCheck.OK:\r\n            msg = None\r\n\r\n        tags = self.custom_tags + [\r\n            'target_host:{}'.format(self.url),\r\n            'port:{}'.format(self.port),\r\n            'instance:{}'.format(self.instance_name),\r\n        ]\r\n\r\n        self.service_check(self.SERVICE_CHECK_NAME, status, tags=tags, message=msg)\r\n        # Report as a metric as well\r\n        self.gauge(\"network.tcp.can_connect\", 1 if status == AgentCheck.OK else 0, tags=tags)\r\n```\r\n\r\nI modify code `/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/tcp_check/tcp_check.py`, and I checked TCP Check shows CRIT status if nginx process down.\r\n\r\nBest, regards.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5604", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5604/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5604/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5604/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5604", "id": 557802075, "node_id": "MDU6SXNzdWU1NTc4MDIwNzU=", "number": 5604, "title": "HAProxy metric type mismatch between docs and source code", "user": {"login": "hasryan", "id": 1844006, "node_id": "MDQ6VXNlcjE4NDQwMDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/1844006?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hasryan", "html_url": "https://github.com/hasryan", "followers_url": "https://api.github.com/users/hasryan/followers", "following_url": "https://api.github.com/users/hasryan/following{/other_user}", "gists_url": "https://api.github.com/users/hasryan/gists{/gist_id}", "starred_url": "https://api.github.com/users/hasryan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hasryan/subscriptions", "organizations_url": "https://api.github.com/users/hasryan/orgs", "repos_url": "https://api.github.com/users/hasryan/repos", "events_url": "https://api.github.com/users/hasryan/events{/privacy}", "received_events_url": "https://api.github.com/users/hasryan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-30T22:45:17Z", "updated_at": "2020-02-13T18:36:12Z", "closed_at": "2020-02-11T13:31:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Our HAProxy integration metrics all have type=`gauge`, which matches the public-facing documentation at https://docs.datadoghq.com/integrations/haproxy/#metrics\r\n\r\nIt is not clear to me exactly how those docs are generated, but it seems the source for the types may be coming from this CSV: https://github.com/DataDog/integrations-core/blob/52006cd9d9b5adbb1729cb78335d7f4bbec1b453/haproxy/metadata.csv\r\n\r\nWhen I compare the metric types in the docs & CSV against the types in the code, it seems there is some disagreement. While the former list every metric as a `gauge` the code linked here lists several as `rate`: https://github.com/DataDog/integrations-core/blob/f8d406f3e382c9ba2aa60924fef3276c02483b72/haproxy/datadog_checks/haproxy/haproxy.py#L65-L94\r\n\r\nI apologize if I'm missing something here, as I am unfamiliar with this codebase. I started looking into this because we saw some strange values for our 1xx - 5xx HAProxy status code metrics and wondered if they are in fact rates or counts instead of gauges.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5598", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5598/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5598/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5598/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5598", "id": 557605619, "node_id": "MDU6SXNzdWU1NTc2MDU2MTk=", "number": 5598, "title": "Prometheus Check Unhandled Exception", "user": {"login": "mjhuber", "id": 19253559, "node_id": "MDQ6VXNlcjE5MjUzNTU5", "avatar_url": "https://avatars2.githubusercontent.com/u/19253559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjhuber", "html_url": "https://github.com/mjhuber", "followers_url": "https://api.github.com/users/mjhuber/followers", "following_url": "https://api.github.com/users/mjhuber/following{/other_user}", "gists_url": "https://api.github.com/users/mjhuber/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjhuber/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjhuber/subscriptions", "organizations_url": "https://api.github.com/users/mjhuber/orgs", "repos_url": "https://api.github.com/users/mjhuber/repos", "events_url": "https://api.github.com/users/mjhuber/events{/privacy}", "received_events_url": "https://api.github.com/users/mjhuber/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 936565809, "node_id": "MDU6TGFiZWw5MzY1NjU4MDk=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/datadog_checks_base", "name": "integration/datadog_checks_base", "color": "bfdadc", "default": false, "description": ""}, {"id": 936577614, "node_id": "MDU6TGFiZWw5MzY1Nzc2MTQ=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/prometheus", "name": "integration/prometheus", "color": "bfdadc", "default": false, "description": ""}, {"id": 293952856, "node_id": "MDU6TGFiZWwyOTM5NTI4NTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/bug", "name": "kind/bug", "color": "b60205", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-30T16:24:05Z", "updated_at": "2020-02-10T14:02:04Z", "closed_at": "2020-02-10T14:01:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\n\u2570\u2500 k exec -it datadog-k7ftb -n datadog -- agent status\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v7.16.1)\r\n===============\r\n\r\n  Status date: 2020-01-30 16:18:14.704738 UTC\r\n  Agent start: 2020-01-30 16:17:38.401717 UTC\r\n  Pid: 340\r\n  Go Version: go1.12.9\r\n  Python Version: 3.7.4\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: INFO\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 1.661ms\r\n    System UTC time: 2020-01-30 16:18:14.704738 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2020-01-14 19:37:05.000000 UTC\r\n    kernelVersion: 4.19.76&#43;\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: 10.2\r\n    procs: 67\r\n    uptime: 380h40m49s\r\n\r\n  Hostnames\r\n  =========\r\n    host_aliases: [redacted]\r\n    hostname: redacted\r\n    socket-fqdn: datadog-k7ftb\r\n    socket-hostname: datadog-k7ftb\r\n    host tags:\r\n      kubernetescluster:redacted\r\n      <redacted>\r\n      zone:us-central1-b\r\n      instance-type:n1-highmem-8\r\n      internal-hostname:<redacted>\r\n      instance-id:4624860398975428259\r\n      project:<redacted>\r\n      numeric_project_id:<redacted>\r\n      cluster-name:<redacted>\r\n      cluster-uid:ada42693ee7b356fef64e8d3b0c4fa4f07cc185679d2a81200eeb2087a0f4f9e\r\n      created-by:projects/174087007133/zones/us-central1-b/instanceGroupManagers/<redacted>\r\n      kube-labels:beta.kubernetes.io/fluentd-ds-ready=true,cloud.google.com/gke-nodepool=highmem01pool2,cloud.google.com/gke-os-distribution=cos\r\n      cluster-location:us-central1-a\r\n      google-compute-enable-pcid:true\r\n      disable-legacy-endpoints:true\r\n      gci-update-strategy:update_disabled\r\n      enable-oslogin:false\r\n      gci-ensure-gke-docker:true\r\n      instance-template:projects/174087007133/global/instanceTemplates/<redacted>\r\n    hostname provider: configuration\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: GCP\r\n    hostname_source: configuration\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 6, Total: 6\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    disk (2.5.3)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 214, Total: 214\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 1.901s\r\n\r\n\r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1,188, Total: 1,188\r\n      Events: Last Run: 1, Total: 1\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 1.301s\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 5, Total: 5\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 56, Total: 56\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    kubelet (3.4.0)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1,222, Total: 1,222\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 4, Total: 4\r\n      Average Execution Time : 4.206s\r\n\r\n\r\n    kubernetes_apiserver\r\n    --------------------\r\n      Instance ID: kubernetes_apiserver [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubernetes_apiserver.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 512ms\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 6, Total: 6\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 17, Total: 17\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    network (1.12.2)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 31, Total: 31\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 3ms\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1, Total: 1\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 190ms\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1, Total: 1\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n  Check Initialization Errors\r\n  ===========================\r\n\r\n\r\n      prometheus (3.2.0)\r\n      ------------------\r\n\r\n      instance 0:\r\n\r\n        could not invoke 'prometheus' python check constructor. New constructor API returned:\r\n__init__() missing 1 required positional argument: 'agentConfig'Deprecated constructor API returned:\r\nTraceback (most recent call last):\r\n  File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/prometheus/base_check.py\", line 92, in __init__\r\n    super(GenericPrometheusCheck, self).__init__(name, init_config, agentConfig, instances)\r\n  File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 234, in __init__\r\n    if metric_limit > 0:\r\nTypeError: '>' not supported between instances of 'str' and 'int'\r\n\r\n  Loading Errors\r\n  ==============\r\n    prometheus\r\n    ----------\r\n      Core Check Loader:\r\n        Check prometheus not found in Catalog\r\n\r\n      JMX Check Loader:\r\n        check is not a jmx check, or unable to determine if it's so\r\n\r\n      Python Check Loader:\r\n        Could not configure any python check prometheus\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 2\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 2\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 6\r\n    TimeseriesV1: 2\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 58bc2: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 58bc2\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 2,772\r\n  Dogstatsd Metric Sample: 5\r\n  Event: 2\r\n  Events Flushed: 1\r\n  Number Of Flushes: 2\r\n  Series Flushed: 873\r\n  Service Check: 19\r\n  Service Checks Flushed: 17\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 4\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 228\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 5\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nKubernetes cluster using datadog helm chart version 1.39.5\r\n\r\n**Steps to reproduce the issue:**\r\n1.  Deploy helm chart.\r\n\r\n**Describe the results you received:**\r\nCheck initialization errors reports an error for the prometheus check.  It is still unclear if this affects all prometheus integration checks.\r\n\r\n```\r\n        could not invoke 'prometheus' python check constructor. New constructor API returned:\r\n__init__() missing 1 required positional argument: 'agentConfig'Deprecated constructor API returned:\r\nTraceback (most recent call last):\r\n  File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/prometheus/base_check.py\", line 92, in __init__\r\n    super(GenericPrometheusCheck, self).__init__(name, init_config, agentConfig, instances)\r\n  File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 234, in __init__\r\n    if metric_limit > 0:\r\nTypeError: '>' not supported between instances of 'str' and 'int'\r\n```\r\n\r\n**Describe the results you expected:**\r\nNo check initialization errors.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5577", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5577/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5577/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5577/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5577", "id": 556355071, "node_id": "MDU6SXNzdWU1NTYzNTUwNzE=", "number": 5577, "title": "nginx_ingress.controller.upstream.latency.quantile not reported on ingress-nginx 0.27.1", "user": {"login": "juniorz", "id": 30809, "node_id": "MDQ6VXNlcjMwODA5", "avatar_url": "https://avatars1.githubusercontent.com/u/30809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/juniorz", "html_url": "https://github.com/juniorz", "followers_url": "https://api.github.com/users/juniorz/followers", "following_url": "https://api.github.com/users/juniorz/following{/other_user}", "gists_url": "https://api.github.com/users/juniorz/gists{/gist_id}", "starred_url": "https://api.github.com/users/juniorz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/juniorz/subscriptions", "organizations_url": "https://api.github.com/users/juniorz/orgs", "repos_url": "https://api.github.com/users/juniorz/repos", "events_url": "https://api.github.com/users/juniorz/events{/privacy}", "received_events_url": "https://api.github.com/users/juniorz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1180219631, "node_id": "MDU6TGFiZWwxMTgwMjE5NjMx", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/nginx_ingress_controller", "name": "integration/nginx_ingress_controller", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-01-27T23:21:25Z", "updated_at": "2020-02-05T22:15:23Z", "closed_at": "2020-02-05T16:19:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nIf you suspect your issue is a bug, please attach the output of the Agent status page,\r\nsee https://docs.datadoghq.com/agent/faq/agent-commands/#agent-information\r\n-->\r\n\r\n**Output of the info page (if this is a bug)**\r\n```\r\n(Paste the output of the info page here)\r\n```\r\n\r\n**Describe what happened:**\r\n\r\nAfter upgrading `ingress-nginx` from version `0.26.1` to version `0.27.1`, the metric `nginx_ingress.controller.upstream.latency.quantile` is not reported anymore.\r\n\r\nOther metrics, such as `nginx_ingress.controller.upstream.latency.sum` are still available.\r\n\r\n**Describe what you expected:**\r\n\r\nI would expect being able to see `nginx_ingress.controller.upstream.latency.quantile` in the metrics explorer.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n- Install `ingress-nginx` version `0.26.1` and configure the [DD integration](https://docs.datadoghq.com/integrations/nginx_ingress_controller/)\r\n- Generate traffic and look at the metric `nginx_ingress.controller.upstream.latency.quantile` on the metrics explorer.\r\n- Install `ingress-nginx` version `0.27.1` and configure the [DD integration](https://docs.datadoghq.com/integrations/nginx_ingress_controller/)\r\n- Generate traffic and look at the metric `nginx_ingress.controller.upstream.latency.quantile` on the metrics explorer.\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\nI compared the metrics provided by both versions and this is the only difference I was able to find:\r\n\r\n```\r\n$ kubectl exec -it -n kube-ingress <pod> -c nginx-ingress-controller -- curl http://127.0.0.1:10254/metrics | grep HELP > metrics-26.1.txt\r\n$ kubectl exec -it -n kube-ingress <pod> -c nginx-ingress-controller -- curl http://127.0.0.1:10254/metrics | grep HELP > metrics-27.1.txt\r\n```\r\n\r\nThe only difference found was:\r\n\r\n```\r\n$ diff metrics-0.26.1.txt metrics-0.27.1.txt\r\n34d33\r\n< # HELP nginx_ingress_controller_leader_election_status Gauge reporting status of the leader election, 0 indicates follower, 1 indicates leader. 'name' is the string used to identify the lease\r\n50d48\r\n< # HELP nginx_ingress_controller_ssl_expire_time_seconds Number of seconds since 1970 to the SSL Certificate expire.\\n\t\tAn example to check if this certificate will expire in 10 days is: \"nginx_ingress_controller_ssl_expire_time_seconds < (time() + (10 * 24 * 3600))\" \r\n```\r\n\r\n** agent status for both versions**\r\n\r\n### 0.26.1\r\n\r\n```\r\n$ kubectl exec -it -n datadog datadog-agent-jmg6l -- agent status\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v7.16.1)\r\n===============\r\n\r\n  Status date: 2020-01-27 22:54:49.631378 UTC\r\n  Agent start: 2020-01-27 18:45:17.432733 UTC\r\n  Pid: 336\r\n  Go Version: go1.12.9\r\n  Python Version: 3.7.4\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: ERROR\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 789\u00b5s\r\n    System UTC time: 2020-01-27 22:54:49.631378 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-12-24 14:05:38.000000 UTC\r\n    kernelVersion: 4.9.0-7-amd64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: 10.2\r\n    procs: 65\r\n    uptime: 820h39m46s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ip-10-106-6-94.ec2.internal\r\n    host_aliases: [ip-10-106-6-94.ec2.internal]\r\n    hostname: i-00d9303a29bfe2c37\r\n    instance-id: i-00d9303a29bfe2c37\r\n    socket-fqdn: datadog-agent-jmg6l\r\n    socket-hostname: datadog-agent-jmg6l\r\n    host tags:\r\n      cluster:kops\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: AWS\r\n    hostname_source: aws\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    cpu\r\n    ---\r\n      Instance ID: cpu [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 998\r\n      Metric Samples: Last Run: 6, Total: 5,982\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    disk (2.5.3)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 997\r\n      Metric Samples: Last Run: 198, Total: 197,406\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 69ms\r\n      \r\n    \r\n    docker\r\n    ------\r\n      Instance ID: docker [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 998\r\n      Metric Samples: Last Run: 366, Total: 439,846\r\n      Events: Last Run: 0, Total: 36\r\n      Service Checks: Last Run: 1, Total: 998\r\n      Average Execution Time : 133ms\r\n      \r\n    \r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 997\r\n      Metric Samples: Last Run: 5, Total: 4,985\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    io\r\n    --\r\n      Instance ID: io [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 998\r\n      Metric Samples: Last Run: 39, Total: 38,895\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    kube_dns (2.3.0)\r\n    ----------------\r\n      Instance ID: kube_dns:9c69332d09b33423 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kube_dns.d/auto_conf.yaml\r\n      Total Runs: 998\r\n      Metric Samples: Last Run: 84, Total: 83,832\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 42ms\r\n      \r\n    \r\n    kubelet (3.4.0)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default\r\n      Total Runs: 997\r\n      Metric Samples: Last Run: 429, Total: 496,174\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 4, Total: 3,988\r\n      Average Execution Time : 404ms\r\n      \r\n    \r\n    kubernetes_apiserver\r\n    --------------------\r\n      Instance ID: kubernetes_apiserver [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubernetes_apiserver.d/conf.yaml.default\r\n      Total Runs: 998\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    load\r\n    ----\r\n      Instance ID: load [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 997\r\n      Metric Samples: Last Run: 6, Total: 5,982\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    memory\r\n    ------\r\n      Instance ID: memory [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 998\r\n      Metric Samples: Last Run: 17, Total: 16,966\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    network (1.12.2)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 997\r\n      Metric Samples: Last Run: 31, Total: 30,907\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 10ms\r\n      \r\n    \r\n    nginx (3.5.0)\r\n    -------------\r\n      Instance ID: nginx:3512af2a3321e79a [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://41e08a103569192494ed2e70b64e755fc3ae5d05a41e2f35c67552acf41e935a\r\n      Total Runs: 217\r\n      Metric Samples: Last Run: 7, Total: 126\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 217\r\n      Average Execution Time : 37ms\r\n      metadata:\r\n        version.major: 1\r\n        version.minor: 15\r\n        version.patch: 8\r\n        version.raw: 1.15.8.2\r\n        version.scheme: semver\r\n      \r\n    \r\n    nginx_ingress_controller (1.1.0)\r\n    --------------------------------\r\n      Instance ID: nginx_ingress_controller:4fe7283a2b3e7561 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://41e08a103569192494ed2e70b64e755fc3ae5d05a41e2f35c67552acf41e935a\r\n      Total Runs: 217\r\n      Metric Samples: Last Run: 21, Total: 4,448\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 217\r\n      Average Execution Time : 59ms\r\n      \r\n    \r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 1, Total: 17\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 17\r\n      Average Execution Time : 244ms\r\n      \r\n    \r\n    uptime\r\n    ------\r\n      Instance ID: uptime [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 998\r\n      Metric Samples: Last Run: 1, Total: 998\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    vault (1.7.1)\r\n    -------------\r\n      Instance ID: vault:3116b5286580086d [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://cc60fc78aecc73909d2cbadff9c41e7118a99799df9da6959de303308e37b96a\r\n      Total Runs: 998\r\n      Metric Samples: Last Run: 1, Total: 998\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 3, Total: 2,994\r\n      Average Execution Time : 52ms\r\n      \r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n    \r\n  Failed checks\r\n  =============\r\n    no checks\r\n    \r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 998\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 129\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 2,125\r\n    TimeseriesV1: 998\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with dc69c: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - dc69c\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n    Sending uncompressed logs in SSL encrypted TCP to agent-intake.logs.datadoghq.com on port 10516\r\n    BytesSent: 1.0811161e&#43;07\r\n    EncodedBytesSent: 1.0811161e&#43;07\r\n    LogsProcessed: 8422\r\n    LogsSent: 8422\r\n\r\n  container_collect_all\r\n  ---------------------\r\n    Type: docker\r\n    Status: OK\r\n    Inputs: b94b697f22a486b0f3b4634fdaafa62634cd5e913b194604b3eddc68d337333c 83ba18cad92c2cc4b9fc8f74de1031b12362224890e4253f8c5299eb057843fb 67816f2b4698a365e11aacde40029eb32effc9de2a321208f93b475e8571decf 9f9bf8a0e38aa0b89734c184d17f4893945ee4a0c48e2009108a366793724699 2b78214ec243fe616fa5dab3fe6be3d4bd7cc6e05d73ec350758ccf50f4f9ede a64ccf2e4a354dac18d40dd601ba536d57caff55bd20cd71b2c9d85af6bb7876 478329e7ff692b68e8e409d8859406923dc83ff716706f31d4960086c2da2b4e c737111e79d8ccd216c32eadec60d4c1b4631820d2b7e0270f5f13804a7bdff2 cc60fc78aecc73909d2cbadff9c41e7118a99799df9da6959de303308e37b96a b5f4339e901abd6bc80e18a806e49a61a7604e14e6e5efff9dc38c8422e94a0a 007b1910df3ba9fab780d3505401ad0bd7c4d7bcd9838f7d0a2259d402792324 \r\n\r\n  logs\r\n  ----\r\n    Type: file\r\n    Path: /var/log/apiserver/*.log\r\n    Status: Error: could not find any file matching pattern /var/log/apiserver/*.log, check that all its subdirectories are executable\r\n      0 files tailed out of 0 files matching\r\n\r\n  docker\r\n  ------\r\n    Type: docker\r\n    Status: OK\r\n    Inputs: 7cc56b2cc68626935857bb006c6906dfb6a7e2f207d76fa7644f2f1a995266bb \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: 41e08a103569192494ed2e70b64e755fc3ae5d05a41e2f35c67552acf41e935a \r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 1.4 M\r\n  Dogstatsd Metric Sample: 388,485\r\n  Event: 37\r\n  Events Flushed: 37\r\n  Number Of Flushes: 998\r\n  Series Flushed: 1.5 M\r\n  Service Check: 32,607\r\n  Service Checks Flushed: 33,605\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 388,484\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 998\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 40.9 M\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 299,878\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n\r\n```\r\n\r\n### 0.27.1\r\n\r\n```\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v7.16.1)\r\n===============\r\n\r\n  Status date: 2020-01-27 23:02:40.830892 UTC\r\n  Agent start: 2020-01-27 18:45:17.432733 UTC\r\n  Pid: 336\r\n  Go Version: go1.12.9\r\n  Python Version: 3.7.4\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: ERROR\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 1.49ms\r\n    System UTC time: 2020-01-27 23:02:40.830892 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-12-24 14:05:38.000000 UTC\r\n    kernelVersion: 4.9.0-7-amd64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: 10.2\r\n    procs: 65\r\n    uptime: 820h39m46s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ip-10-106-6-94.ec2.internal\r\n    host_aliases: [ip-10-106-6-94.ec2.internal]\r\n    hostname: i-00d9303a29bfe2c37\r\n    instance-id: i-00d9303a29bfe2c37\r\n    socket-fqdn: datadog-agent-jmg6l\r\n    socket-hostname: datadog-agent-jmg6l\r\n    host tags:\r\n      cluster:kops\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: AWS\r\n    hostname_source: aws\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    cpu\r\n    ---\r\n      Instance ID: cpu [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 6, Total: 6,168\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    disk (2.5.3)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 198, Total: 203,742\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 62ms\r\n      \r\n    \r\n    docker\r\n    ------\r\n      Instance ID: docker [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 550, Total: 453,659\r\n      Events: Last Run: 0, Total: 46\r\n      Service Checks: Last Run: 1, Total: 1,029\r\n      Average Execution Time : 147ms\r\n      \r\n    \r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 5, Total: 5,145\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    io\r\n    --\r\n      Instance ID: io [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 39, Total: 40,104\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 1ms\r\n      \r\n    \r\n    kube_dns (2.3.0)\r\n    ----------------\r\n      Instance ID: kube_dns:9c69332d09b33423 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kube_dns.d/auto_conf.yaml\r\n      Total Runs: 1,030\r\n      Metric Samples: Last Run: 84, Total: 86,520\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 38ms\r\n      \r\n    \r\n    kubelet (3.4.0)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 602, Total: 512,393\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 4, Total: 4,116\r\n      Average Execution Time : 527ms\r\n      \r\n    \r\n    kubernetes_apiserver\r\n    --------------------\r\n      Instance ID: kubernetes_apiserver [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubernetes_apiserver.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    load\r\n    ----\r\n      Instance ID: load [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 6, Total: 6,174\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    memory\r\n    ------\r\n      Instance ID: memory [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 17, Total: 17,493\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 3ms\r\n      \r\n    \r\n    network (1.12.2)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 31, Total: 31,899\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 12ms\r\n      \r\n    \r\n    nginx (3.5.0)\r\n    -------------\r\n      Instance ID: nginx:87cd0ac81221c302 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://a2f912802af4fde3e0c911cba832632440e20d3abaaa6017d76db0acf223bed5\r\n      Total Runs: 13\r\n      Metric Samples: Last Run: 7, Total: 91\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 13\r\n      Average Execution Time : 29ms\r\n      metadata:\r\n        version.major: 1\r\n        version.minor: 17\r\n        version.patch: 7\r\n        version.raw: 1.17.7\r\n        version.scheme: semver\r\n      \r\n      Instance ID: nginx:f8d4cd636f3a5489 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://e24d8e39b95148a2350f1ae69e55b5322eb09c6a86881f58fff95e8ced4a4a18\r\n      Total Runs: 16\r\n      Metric Samples: Last Run: 7, Total: 112\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 16\r\n      Average Execution Time : 23ms\r\n      metadata:\r\n        version.major: 1\r\n        version.minor: 17\r\n        version.patch: 7\r\n        version.raw: 1.17.7\r\n        version.scheme: semver\r\n      \r\n      Instance ID: nginx:fe500e729f3c478c [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://6144da6fd687b40097393b64247e9e9d988d8ef10cc2067320943a20d49467af\r\n      Total Runs: 16\r\n      Metric Samples: Last Run: 7, Total: 112\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 16\r\n      Average Execution Time : 13ms\r\n      metadata:\r\n        version.major: 1\r\n        version.minor: 17\r\n        version.patch: 7\r\n        version.raw: 1.17.7\r\n        version.scheme: semver\r\n      \r\n    \r\n    nginx_ingress_controller (1.1.0)\r\n    --------------------------------\r\n      Instance ID: nginx_ingress_controller:9875947898e8b5dc [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://e24d8e39b95148a2350f1ae69e55b5322eb09c6a86881f58fff95e8ced4a4a18\r\n      Total Runs: 16\r\n      Metric Samples: Last Run: 17, Total: 272\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 16\r\n      Average Execution Time : 45ms\r\n      \r\n      Instance ID: nginx_ingress_controller:a46c61873dfee949 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://6144da6fd687b40097393b64247e9e9d988d8ef10cc2067320943a20d49467af\r\n      Total Runs: 16\r\n      Metric Samples: Last Run: 17, Total: 272\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 16\r\n      Average Execution Time : 56ms\r\n      \r\n      Instance ID: nginx_ingress_controller:ca49f9ae9c731fe1 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://a2f912802af4fde3e0c911cba832632440e20d3abaaa6017d76db0acf223bed5\r\n      Total Runs: 12\r\n      Metric Samples: Last Run: 17, Total: 204\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 12\r\n      Average Execution Time : 43ms\r\n      \r\n    \r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 18\r\n      Metric Samples: Last Run: 1, Total: 18\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 18\r\n      Average Execution Time : 246ms\r\n      \r\n    \r\n    uptime\r\n    ------\r\n      Instance ID: uptime [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 1, Total: 1,029\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    vault (1.7.1)\r\n    -------------\r\n      Instance ID: vault:3116b5286580086d [\u001b[32mOK\u001b[0m]\r\n      Configuration Source: kubelet:docker://cc60fc78aecc73909d2cbadff9c41e7118a99799df9da6959de303308e37b96a\r\n      Total Runs: 1,029\r\n      Metric Samples: Last Run: 1, Total: 1,029\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 3, Total: 3,087\r\n      Average Execution Time : 56ms\r\n      \r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n    \r\n  Failed checks\r\n  =============\r\n    no checks\r\n    \r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 1,029\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 139\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 2,197\r\n    TimeseriesV1: 1,029\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with dc69c: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - dc69c\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n    Sending uncompressed logs in SSL encrypted TCP to agent-intake.logs.datadoghq.com on port 10516\r\n    BytesSent: 1.1242902e&#43;07\r\n    EncodedBytesSent: 1.1242902e&#43;07\r\n    LogsProcessed: 8849\r\n    LogsSent: 8849\r\n\r\n  container_collect_all\r\n  ---------------------\r\n    Type: docker\r\n    Status: OK\r\n    Inputs: cc60fc78aecc73909d2cbadff9c41e7118a99799df9da6959de303308e37b96a b5f4339e901abd6bc80e18a806e49a61a7604e14e6e5efff9dc38c8422e94a0a 007b1910df3ba9fab780d3505401ad0bd7c4d7bcd9838f7d0a2259d402792324 b94b697f22a486b0f3b4634fdaafa62634cd5e913b194604b3eddc68d337333c 83ba18cad92c2cc4b9fc8f74de1031b12362224890e4253f8c5299eb057843fb 67816f2b4698a365e11aacde40029eb32effc9de2a321208f93b475e8571decf 9f9bf8a0e38aa0b89734c184d17f4893945ee4a0c48e2009108a366793724699 2b78214ec243fe616fa5dab3fe6be3d4bd7cc6e05d73ec350758ccf50f4f9ede a64ccf2e4a354dac18d40dd601ba536d57caff55bd20cd71b2c9d85af6bb7876 478329e7ff692b68e8e409d8859406923dc83ff716706f31d4960086c2da2b4e c737111e79d8ccd216c32eadec60d4c1b4631820d2b7e0270f5f13804a7bdff2 \r\n\r\n  logs\r\n  ----\r\n    Type: file\r\n    Path: /var/log/apiserver/*.log\r\n    Status: Error: could not find any file matching pattern /var/log/apiserver/*.log, check that all its subdirectories are executable\r\n      0 files tailed out of 0 files matching\r\n\r\n  docker\r\n  ------\r\n    Type: docker\r\n    Status: OK\r\n    Inputs: 30ec16f0fe16b2860368852596c57d36c4f98954ee6eb5428bf708315aee7d8a \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: ac6a8a0a102e96a6d81d8cb1a1a13c16d653ede63e746b5ad2158ca73574e2a3 \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: e24d8e39b95148a2350f1ae69e55b5322eb09c6a86881f58fff95e8ced4a4a18 \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: 6144da6fd687b40097393b64247e9e9d988d8ef10cc2067320943a20d49467af \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: a2f912802af4fde3e0c911cba832632440e20d3abaaa6017d76db0acf223bed5 \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: 64d7cda46bf8a3bc99e67c13ddbb437e2ef12463a564c41ce05c161e9857927a \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: 7b745ffd12f2ea23dfa45b3922df3bb96d82a37d994f46927ff1afc729904293 \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: 28456298e03eb7832a56f3cc72b640fc8e3783719320e5cc0e8d36995da81476 \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: dd69c86ad39dbee0e94023e04a5e1c4f21452b585958ba765715f4bbabf9cb48 \r\n    Type: docker\r\n    Status: OK\r\n    Inputs: 9561e5bf614916802a9cd6adbc95407b1f2dc5f8a196644ae564a9bc6983d43a \r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 1.4 M\r\n  Dogstatsd Metric Sample: 400,937\r\n  Event: 47\r\n  Events Flushed: 47\r\n  Number Of Flushes: 1,029\r\n  Series Flushed: 1.5 M\r\n  Service Check: 33,593\r\n  Service Checks Flushed: 34,608\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 400,936\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 1,029\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 42.2 M\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 309,270\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5534", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5534/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5534/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5534/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5534", "id": 554152155, "node_id": "MDU6SXNzdWU1NTQxNTIxNTU=", "number": 5534, "title": "[base] metric_limit fails due to missing type cast on Python 3", "user": {"login": "joekohlsdorf", "id": 32424163, "node_id": "MDQ6VXNlcjMyNDI0MTYz", "avatar_url": "https://avatars2.githubusercontent.com/u/32424163?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joekohlsdorf", "html_url": "https://github.com/joekohlsdorf", "followers_url": "https://api.github.com/users/joekohlsdorf/followers", "following_url": "https://api.github.com/users/joekohlsdorf/following{/other_user}", "gists_url": "https://api.github.com/users/joekohlsdorf/gists{/gist_id}", "starred_url": "https://api.github.com/users/joekohlsdorf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joekohlsdorf/subscriptions", "organizations_url": "https://api.github.com/users/joekohlsdorf/orgs", "repos_url": "https://api.github.com/users/joekohlsdorf/repos", "events_url": "https://api.github.com/users/joekohlsdorf/events{/privacy}", "received_events_url": "https://api.github.com/users/joekohlsdorf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-01-23T13:20:13Z", "updated_at": "2020-01-24T20:11:03Z", "closed_at": "2020-01-24T18:15:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Agent version**\r\n\r\n7.16.1\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n1. Configure a check which has a limit of the amount of metrics returned, for example Prometheus.\r\n\r\n**Describe the results you received:**\r\n\r\n```\r\n2020-01-22 18:31:29 UTC | CORE | ERROR | (pkg/collector/python/loader.go:224 in addExpvarConfigureError) | py.loader: could not configure check 'prometheus (3.2.0)': could not invoke 'prometheus' python check constructor. New constructor API returned:\r\n__init__() missing 1 required positional argument: 'agentConfig'Deprecated constructor API returned:\r\nTraceback (most recent call last):\r\n  File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/prometheus/base_check.py\", line 92, in __init__\r\n    super(GenericPrometheusCheck, self).__init__(name, init_config, agentConfig, instances)\r\n  File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 234, in __init__\r\n    if metric_limit > 0:\r\nTypeError: '>' not supported between instances of 'str' and 'int'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5526", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5526/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5526/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5526/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5526", "id": 553246073, "node_id": "MDU6SXNzdWU1NTMyNDYwNzM=", "number": 5526, "title": "Vulnerability in secondary dependency of datadog-checks-dev[cli]", "user": {"login": "instantlinux", "id": 3667505, "node_id": "MDQ6VXNlcjM2Njc1MDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/3667505?v=4", "gravatar_id": "", "url": "https://api.github.com/users/instantlinux", "html_url": "https://github.com/instantlinux", "followers_url": "https://api.github.com/users/instantlinux/followers", "following_url": "https://api.github.com/users/instantlinux/following{/other_user}", "gists_url": "https://api.github.com/users/instantlinux/gists{/gist_id}", "starred_url": "https://api.github.com/users/instantlinux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/instantlinux/subscriptions", "organizations_url": "https://api.github.com/users/instantlinux/orgs", "repos_url": "https://api.github.com/users/instantlinux/repos", "events_url": "https://api.github.com/users/instantlinux/events{/privacy}", "received_events_url": "https://api.github.com/users/instantlinux/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1762666438, "node_id": "MDU6TGFiZWwxNzYyNjY2NDM4", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/dependencies", "name": "dependencies", "color": "83fcf8", "default": false, "description": ""}, {"id": 992015121, "node_id": "MDU6TGFiZWw5OTIwMTUxMjE=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/datadog_checks_dev", "name": "integration/datadog_checks_dev", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-01-22T01:06:45Z", "updated_at": "2020-01-22T16:01:14Z", "closed_at": "2020-01-22T16:01:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "Version-pinning for python packages in datadog-checks-dev[cli] is outdated and links to a repo with vulnerability CVE-2017-18342.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create a Pipfile with this content:\r\n```\r\n[packages]\r\n\"datadog-checks-dev[cli]\" = \"*\"\r\npyyaml = \">5.1\"\r\n```\r\n2. Invoke the command\r\n```\r\npipenv lock\r\n```\r\n\r\n**Describe the results you received:**\r\nI get an incompatible-versions exception:\r\n```\r\nERROR: Could not find a version that matches pyyaml<4,>5.1,>=3.10,>=5.1\r\nTried: 3.10, 3.10, 3.11, 3.11, 3.12, 3.12, [...] 5.3, 5.3\r\nSkipped pre-versions: 3.13b1, 3.13b1, 3.13b1, [...] 5.3b1, 5.3b1, 5.3b1, 5.3b1, 5.3b1, 5.3b1, 5.3b1\r\nThere are incompatible versions in the resolved dependencies.\r\n[pipenv.exceptions.ResolutionFailure]:   File \"/var/tmp/foo/lib/python3.6/site-packages/pipenv/utils.py\", line 726, in resolve_deps\r\n ...\r\n```\r\n\r\n**Describe the results you expected:**\r\n\r\nI should be able to install the datadog-checks-dev[cli] without version conflicts against current versions of its dependencies.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nThe problem lies in [setup.py](https://github.com/DataDog/integrations-core/blob/master/datadog_checks_dev/setup.py) where it specifies an outdated docker-compose version.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5482", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5482/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5482/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5482/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5482", "id": 550322755, "node_id": "MDU6SXNzdWU1NTAzMjI3NTU=", "number": 5482, "title": "Apache version check does not support 'ServerTokens Full' format", "user": {"login": "dylancanfield", "id": 1152110, "node_id": "MDQ6VXNlcjExNTIxMTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1152110?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dylancanfield", "html_url": "https://github.com/dylancanfield", "followers_url": "https://api.github.com/users/dylancanfield/followers", "following_url": "https://api.github.com/users/dylancanfield/following{/other_user}", "gists_url": "https://api.github.com/users/dylancanfield/gists{/gist_id}", "starred_url": "https://api.github.com/users/dylancanfield/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dylancanfield/subscriptions", "organizations_url": "https://api.github.com/users/dylancanfield/orgs", "repos_url": "https://api.github.com/users/dylancanfield/repos", "events_url": "https://api.github.com/users/dylancanfield/events{/privacy}", "received_events_url": "https://api.github.com/users/dylancanfield/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 936563014, "node_id": "MDU6TGFiZWw5MzY1NjMwMTQ=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/apache", "name": "integration/apache", "color": "bfdadc", "default": false, "description": ""}, {"id": 293952856, "node_id": "MDU6TGFiZWwyOTM5NTI4NTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/bug", "name": "kind/bug", "color": "b60205", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "ChristineTChen", "id": 15065007, "node_id": "MDQ6VXNlcjE1MDY1MDA3", "avatar_url": "https://avatars3.githubusercontent.com/u/15065007?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChristineTChen", "html_url": "https://github.com/ChristineTChen", "followers_url": "https://api.github.com/users/ChristineTChen/followers", "following_url": "https://api.github.com/users/ChristineTChen/following{/other_user}", "gists_url": "https://api.github.com/users/ChristineTChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChristineTChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChristineTChen/subscriptions", "organizations_url": "https://api.github.com/users/ChristineTChen/orgs", "repos_url": "https://api.github.com/users/ChristineTChen/repos", "events_url": "https://api.github.com/users/ChristineTChen/events{/privacy}", "received_events_url": "https://api.github.com/users/ChristineTChen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ChristineTChen", "id": 15065007, "node_id": "MDQ6VXNlcjE1MDY1MDA3", "avatar_url": "https://avatars3.githubusercontent.com/u/15065007?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChristineTChen", "html_url": "https://github.com/ChristineTChen", "followers_url": "https://api.github.com/users/ChristineTChen/followers", "following_url": "https://api.github.com/users/ChristineTChen/following{/other_user}", "gists_url": "https://api.github.com/users/ChristineTChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChristineTChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChristineTChen/subscriptions", "organizations_url": "https://api.github.com/users/ChristineTChen/orgs", "repos_url": "https://api.github.com/users/ChristineTChen/repos", "events_url": "https://api.github.com/users/ChristineTChen/events{/privacy}", "received_events_url": "https://api.github.com/users/ChristineTChen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-01-15T17:18:54Z", "updated_at": "2020-01-17T15:31:56Z", "closed_at": "2020-01-17T15:31:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\n===============\r\nAgent (v6.16.1)\r\n===============\r\n\r\n  Status date: 2020-01-15 10:10:03.355973 MST\r\n  Agent start: 2020-01-15 09:19:38.988371 MST\r\n  Pid: 17341\r\n  Go Version: go1.12.9\r\n  Python Version: 2.7.17\r\n  Build arch: amd64\r\n  Check Runners: 6\r\n  Log Level: info\r\n\r\n...\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    apache (1.9.2)\r\n    --------------\r\n      Instance ID: apache:d915d6b961f0250d [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/apache.d/conf.yaml\r\n      Total Runs: 202\r\n      Metric Samples: Last Run: 12, Total: 2,424\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 202\r\n      Average Execution Time : 3ms\r\n      \r\n...\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nRed Hat Enterprise Linux Server release 7.7\r\n\r\n**Steps to reproduce the issue:**\r\n1. Enable apache checks\r\n\r\n**Describe the results you received:**\r\nError messages in /var/log/datadog/agent.log:\r\n```text\r\n2020-01-15 10:11:56 MST | CORE | INFO | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | apache:d915d6b961f0250d | (apache.py:136) | Cannot parse the complete Apache version from %s.\r\n```\r\n\r\n\r\n**Describe the results you expected:**\r\nVersion string parsed correctly\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nOur Server header looks like this:\r\n```text\r\nServer: Apache/2.4.6 (Red Hat Enterprise Linux) OpenSSL/1.0.2k-fips\r\n```\r\nThis is the \"Full\" format for the ServerTokens directive: https://httpd.apache.org/docs/2.4/mod/core.html#servertokens\r\n\r\nThis issue can easily be fixed by modifying VERSION_REGEX in apache/datadog_checks/apache/apache.py to support additional whitespace separated elements after the OS element and before the EOL\r\n```text\r\ndiff --git a/apache/datadog_checks/apache/apache.py b/apache/datadog_checks/apache/apache.py\r\nindex 0f4b34f8e..4249e2eda 100644\r\n--- a/apache/datadog_checks/apache/apache.py\r\n+++ b/apache/datadog_checks/apache/apache.py\r\n@@ -37,7 +37,7 @@ class Apache(AgentCheck):\r\n         'connect_timeout': {'name': 'connect_timeout', 'default': 5},\r\n     }\r\n \r\n-    VERSION_REGEX = re.compile(r'^Apache/([0-9]+\\.[0-9]+\\.[0-9]+)( \\(.*\\))?$')\r\n+    VERSION_REGEX = re.compile(r'^Apache/([0-9]+\\.[0-9]+\\.[0-9]+)( \\(.*\\))?( .*)*$')\r\n \r\n     def __init__(self, name, init_config, instances):\r\n         super(Apache, self).__init__(name, init_config, instances)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5467", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5467/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5467/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5467/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5467", "id": 549615492, "node_id": "MDU6SXNzdWU1NDk2MTU0OTI=", "number": 5467, "title": "[Harbor] Authentication failed", "user": {"login": "jgoret", "id": 1876639, "node_id": "MDQ6VXNlcjE4NzY2Mzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1876639?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgoret", "html_url": "https://github.com/jgoret", "followers_url": "https://api.github.com/users/jgoret/followers", "following_url": "https://api.github.com/users/jgoret/following{/other_user}", "gists_url": "https://api.github.com/users/jgoret/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgoret/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgoret/subscriptions", "organizations_url": "https://api.github.com/users/jgoret/orgs", "repos_url": "https://api.github.com/users/jgoret/repos", "events_url": "https://api.github.com/users/jgoret/events{/privacy}", "received_events_url": "https://api.github.com/users/jgoret/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-01-14T14:47:40Z", "updated_at": "2020-01-15T17:57:49Z", "closed_at": "2020-01-15T17:57:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v6.16.0)\r\n===============\r\n\r\n  Status date: 2020-01-14 14:38:13.991531 UTC\r\n  Agent start: 2020-01-14 14:38:03.729350 UTC\r\n  Pid: 23768\r\n  Go Version: go1.12.9\r\n  Python Version: 2.7.17\r\n  Build arch: amd64\r\n  Check Runners: 4\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -486\u00b5s\r\n    System UTC time: 2020-01-14 14:38:13.991531 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-11-10 10:31:24.000000 UTC\r\n    kernelVersion: 3.10.0-957.10.1.el7.x86_64\r\n    os: linux\r\n    platform: centos\r\n    platformFamily: rhel\r\n    platformVersion: 7.6.1810\r\n    procs: 202\r\n    uptime: 1564h6m40s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ***\r\n    hostname: ***\r\n    instance-id: ***\r\n    socket-fqdn: ***.\r\n    socket-hostname: ***\r\n    host tags: [***]\r\n    hostname provider: fqdn\r\n    unused hostname providers:\r\n      aws: not retrieving hostname from AWS: the host is not an ECS instance, and other providers already retrieve non-default hostnames\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: AWS\r\n    hostname_source: fqdn\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    disk (2.5.3)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 68, Total: 68\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 86ms\r\n\r\n\r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 174, Total: 174\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 64ms\r\n\r\n\r\n    harbor (1.2.0)\r\n    --------------\r\n      Instance ID: harbor:ccb8ce3e52e93650 [ERROR]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/harbor.d/conf.yaml\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 45ms\r\n      Error: 403 Client Error: Forbidden for url: https://***/c/login/\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 678, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/harbor/harbor.py\", line 116, in check\r\n          api.authenticate(username, password)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/harbor/api.py\", line 35, in authenticate\r\n          self._make_post_request(url, data=auth_form_data)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/harbor/api.py\", line 97, in _make_post_request\r\n          resp.raise_for_status()\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/models.py\", line 940, in raise_for_status\r\n          raise HTTPError(http_error_msg, response=self)\r\n      HTTPError: 403 Client Error: Forbidden for url: https://***/c/login/\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 8, Total: 8\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 17, Total: 17\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1, Total: 1\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 533ms\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1, Total: 1\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 0\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 1\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 1\r\n    TimeseriesV1: 0\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with e7a30: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - e7a30\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 283\r\n  Dogstatsd Metric Sample: 15\r\n  Event: 1\r\n  Service Check: 10\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 14\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 855\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 15\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nCentos 7 host on AWS running Harbor 1.9.X with docker-compose\r\n\r\n**Steps to reproduce the issue:**\r\nActivate harbor integration with this config\r\n```yaml\r\ninit_config: null\r\ninstances:\r\n- password: '******'\r\n  tls_ignore_warning: true\r\n  tls_verify: false\r\n  url: https://***\r\n  username: datadog_harbor_user\r\n  skip_proxy: true\r\n```\r\n\r\n**Describe the results you received:**\r\nDatadog agent cannot connect to the Harbor API with a \"HTTPError: 403 Client Error: Forbidden\" Error but the user can connect without error on the Harbor UI.\r\n\r\n**Describe the results you expected:**\r\nDatadog agent successfully authenticate to the Harbor API and get all needed metrics.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nThe integration is working again with this small patch :\r\n```bash\r\n--- harbor.py   2020-01-14 14:45:57.178346577 +0000\r\n+++ harbor.py   2020-01-14 14:38:42.853246872 +0000\r\n@@ -18,7 +18,7 @@\r\n         super(HarborCheck, self).__init__(name, init_config, instances)\r\n\r\n         # Prevent the use of Basic Auth using `username` and `password` from the config file.\r\n-        del self.http.options['auth']\r\n+#        del self.http.options['auth']\r\n\r\n         # Keep a single session in order to submit the session id cookie for each request.\r\n         self.http.persist_connections = True\r\n@@ -113,7 +113,7 @@\r\n         tags = instance.get(\"tags\", [])\r\n         try:\r\n             api = HarborAPI(harbor_url, self.http)\r\n-            api.authenticate(username, password)\r\n+            #api.authenticate(username, password)\r\n         except Exception:\r\n             self.log.exception(\"Harbor API is not reachable\")\r\n             self.service_check(CAN_CONNECT, AgentCheck.CRITICAL)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5444", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5444/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5444/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5444/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5444", "id": 548681530, "node_id": "MDU6SXNzdWU1NDg2ODE1MzA=", "number": 5444, "title": "[envoy] failed to parse stats_url", "user": {"login": "vvbogdanov87", "id": 17006789, "node_id": "MDQ6VXNlcjE3MDA2Nzg5", "avatar_url": "https://avatars1.githubusercontent.com/u/17006789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vvbogdanov87", "html_url": "https://github.com/vvbogdanov87", "followers_url": "https://api.github.com/users/vvbogdanov87/followers", "following_url": "https://api.github.com/users/vvbogdanov87/following{/other_user}", "gists_url": "https://api.github.com/users/vvbogdanov87/gists{/gist_id}", "starred_url": "https://api.github.com/users/vvbogdanov87/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vvbogdanov87/subscriptions", "organizations_url": "https://api.github.com/users/vvbogdanov87/orgs", "repos_url": "https://api.github.com/users/vvbogdanov87/repos", "events_url": "https://api.github.com/users/vvbogdanov87/events{/privacy}", "received_events_url": "https://api.github.com/users/vvbogdanov87/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 936567156, "node_id": "MDU6TGFiZWw5MzY1NjcxNTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/envoy", "name": "integration/envoy", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "ChristineTChen", "id": 15065007, "node_id": "MDQ6VXNlcjE1MDY1MDA3", "avatar_url": "https://avatars3.githubusercontent.com/u/15065007?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChristineTChen", "html_url": "https://github.com/ChristineTChen", "followers_url": "https://api.github.com/users/ChristineTChen/followers", "following_url": "https://api.github.com/users/ChristineTChen/following{/other_user}", "gists_url": "https://api.github.com/users/ChristineTChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChristineTChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChristineTChen/subscriptions", "organizations_url": "https://api.github.com/users/ChristineTChen/orgs", "repos_url": "https://api.github.com/users/ChristineTChen/repos", "events_url": "https://api.github.com/users/ChristineTChen/events{/privacy}", "received_events_url": "https://api.github.com/users/ChristineTChen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ChristineTChen", "id": 15065007, "node_id": "MDQ6VXNlcjE1MDY1MDA3", "avatar_url": "https://avatars3.githubusercontent.com/u/15065007?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChristineTChen", "html_url": "https://github.com/ChristineTChen", "followers_url": "https://api.github.com/users/ChristineTChen/followers", "following_url": "https://api.github.com/users/ChristineTChen/following{/other_user}", "gists_url": "https://api.github.com/users/ChristineTChen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChristineTChen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChristineTChen/subscriptions", "organizations_url": "https://api.github.com/users/ChristineTChen/orgs", "repos_url": "https://api.github.com/users/ChristineTChen/repos", "events_url": "https://api.github.com/users/ChristineTChen/events{/privacy}", "received_events_url": "https://api.github.com/users/ChristineTChen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-01-13T03:24:22Z", "updated_at": "2020-01-21T04:48:07Z", "closed_at": "2020-01-21T04:48:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\n```text\r\n===============\r\nAgent (v6.14.1)\r\n===============\r\n\r\n  Status date: 2020-01-13 03:14:54.690525 UTC\r\n  Agent start: 2020-01-13 03:14:14.000206 UTC\r\n  Pid: 14749\r\n  Go Version: go1.12.9\r\n  Python Version: 2.7.16\r\n  Check Runners: 4\r\n  Log Level: INFO\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 87\u00b5s\r\n    System UTC time: 2020-01-13 03:14:54.690525 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2020-01-10 02:09:12.000000 UTC\r\n    kernelVersion: 4.9.0-11-amd64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: 10.1\r\n    procs: 179\r\n    uptime: 73h5m9s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ***\r\n    host_aliases: [***]\r\n    hostname: ***\r\n    instance-id: ***\r\n    socket-fqdn: \r\n    socket-hostname: ip-10-63-75-42\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 6, Total: 6\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    disk (2.5.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 294, Total: 588\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 221ms\r\n\r\n\r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 204, Total: 408\r\n      Events: Last Run: 0, Total: 1\r\n      Service Checks: Last Run: 1, Total: 2\r\n      Average Execution Time : 258ms\r\n\r\n\r\n    envoy (1.9.0)\r\n    -------------\r\n      Instance ID: envoy:9f25ceac3801f302 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/envoy.yaml\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 3\r\n      Average Execution Time : 2ms\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 5, Total: 10\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 39, Total: 51\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    kubelet (3.3.2)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 299, Total: 589\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 4, Total: 8\r\n      Average Execution Time : 356ms\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 6, Total: 12\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 17, Total: 34\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 48ms\r\n\r\n\r\n    network (1.11.4)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 49, Total: 98\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 2ms\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 1, Total: 2\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 2\r\n      Average Execution Time : 187ms\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 1, Total: 3\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 2\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 2\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 6\r\n    TimeseriesV1: 2\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 69a75: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 69a75\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 1,850\r\n  Dogstatsd Metric Sample: 6\r\n  Event: 2\r\n  Events Flushed: 2\r\n  Number Of Flushes: 2\r\n  Series Flushed: 712\r\n  Service Check: 40\r\n  Service Checks Flushed: 31\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 5\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 274\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 6\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 1\r\n\r\n=====================\r\nDatadog Cluster Agent\r\n=====================\r\n\r\n  - Datadog Cluster Agent endpoint detected: https://100.67.10.181:5005\r\n  Successfully connected to the Datadog Cluster Agent.\r\n  - Running: 1.4.0&#43;commit.f102bd8\r\n```\r\n\r\n**Environment: Kubernetes**\r\n\r\n**Steps to reproduce the issue:**\r\nDD agent installed using helm chart with the next params:\r\n```\r\ndatadog:\r\n  confd:\r\n    envoy.yaml: |-\r\n      init_config:\r\n      instances:\r\n        - stats_url: \"http://%%host%%:15000/stats\"\r\n```\r\n\r\n**Describe the results you received:**\r\nThere are no envoy metrics\r\n\r\n**Describe the results you expected:**\r\nenvoy metrics\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nEnvoy check shows OK status. But in the agent log:\r\n```\r\n2020-01-13 03:14:22 UTC | CORE | ERROR | (pkg/collector/python/datadog_agent.go:114 in LogMessage) | envoy:9f25ceac3801f302 | (envoy.py:67) | Error acce\r\nssing Envoy endpoint `http://%%host%%:15000/stats`\r\nTraceback (most recent call last):\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/envoy/envoy.py\", line 56, in check\r\n    response = self.http.get(stats_url)\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/utils/http.py\", line 276, in get\r\n    return self._request('get', url, options)\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/utils/http.py\", line 316, in _request\r\n    return getattr(requests, method)(url, **self.populate_options(options))\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/api.py\", line 75, in get\r\n    return request('get', url, params=params, **kwargs)\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/api.py\", line 60, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/sessions.py\", line 519, in request\r\n    prep = self.prepare_request(req)\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/sessions.py\", line 462, in prepare_request\r\n    hooks=merge_hooks(request.hooks, self.hooks),\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/models.py\", line 313, in prepare\r\n    self.prepare_url(url, params)\r\n  File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/models.py\", line 381, in prepare_url\r\n    raise InvalidURL(*e.args)\r\nInvalidURL: Failed to parse: http://%%host%%:15000/stats\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5266", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5266/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5266/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5266/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5266", "id": 540815570, "node_id": "MDU6SXNzdWU1NDA4MTU1NzA=", "number": 5266, "title": "failure with apache check", "user": {"login": "fujigon", "id": 3805800, "node_id": "MDQ6VXNlcjM4MDU4MDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/3805800?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fujigon", "html_url": "https://github.com/fujigon", "followers_url": "https://api.github.com/users/fujigon/followers", "following_url": "https://api.github.com/users/fujigon/following{/other_user}", "gists_url": "https://api.github.com/users/fujigon/gists{/gist_id}", "starred_url": "https://api.github.com/users/fujigon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fujigon/subscriptions", "organizations_url": "https://api.github.com/users/fujigon/orgs", "repos_url": "https://api.github.com/users/fujigon/repos", "events_url": "https://api.github.com/users/fujigon/events{/privacy}", "received_events_url": "https://api.github.com/users/fujigon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-20T07:12:21Z", "updated_at": "2020-01-29T13:42:47Z", "closed_at": "2020-01-29T13:42:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/#agent-status-and-information)**\r\n\r\nwe also have error with fluentd, but this is because of our security setting, please ignore.\r\n\r\n```text\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v7.16.0)\r\n===============\r\n\r\n  Status date: 2019-12-20 06:38:50.350434 UTC\r\n  Agent start: 2019-12-19 09:32:10.422062 UTC\r\n  Pid: 337\r\n  Go Version: go1.12.9\r\n  Python Version: 3.7.4\r\n  Build arch: amd64\r\n  Check Runners: 7\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    System UTC time: 2019-12-20 06:38:50.350434 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-11-14 05:14:54.000000 UTC\r\n    kernelVersion: 4.14.146-93.123.amzn1.x86_64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: 10.2\r\n    procs: 69\r\n    uptime: 844h17m17s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ip-10-203-170-155\r\n    hostname: i-02c820113078c199f\r\n    instance-id: i-02c820113078c199f\r\n    socket-fqdn: db6dffd0ec79\r\n    socket-hostname: db6dffd0ec79\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n  Metadata\r\n  ========\r\n    cloud_provider: AWS\r\n    hostname_source: aws\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    apache (1.9.1)\r\n    --------------\r\n      Instance ID: apache:34ad6789c149be03 [ERROR]\r\n      Configuration Source: docker:docker://c16e612b1ba7e845ca3c1eeea50c379fe65ef35168779e8496a1a139c0c099c6\r\n      Total Runs: 308\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 308\r\n      Average Execution Time : 2ms\r\n      Error: list index out of range\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 678, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/apache/apache.py\", line 73, in check\r\n          self._collect_metadata(server)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/apache/apache.py\", line 115, in _collect_metadata\r\n          version = raw_version.split('/')[1]\r\n      IndexError: list index out of range\r\n      Instance ID: apache:b26e4868d750c734 [ERROR]\r\n      Configuration Source: docker:docker://70898e794c0334fe9907152792098573806e42054b6033aac45b1d0343b55b75\r\n      Total Runs: 308\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 308\r\n      Average Execution Time : 4ms\r\n      Error: list index out of range\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 678, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/apache/apache.py\", line 73, in check\r\n          self._collect_metadata(server)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/apache/apache.py\", line 115, in _collect_metadata\r\n          version = raw_version.split('/')[1]\r\n      IndexError: list index out of range\r\n      Instance ID: apache:c10db45e0ac6d9b6 [ERROR]\r\n      Configuration Source: docker:docker://f94c5460131f0aaee106b5afdd1230226a51ab73e575bb12878c669b683eeed7\r\n      Total Runs: 308\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 308\r\n      Average Execution Time : 6ms\r\n      Error: list index out of range\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 678, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/apache/apache.py\", line 73, in check\r\n          self._collect_metadata(server)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/apache/apache.py\", line 115, in _collect_metadata\r\n          version = raw_version.split('/')[1]\r\n      IndexError: list index out of range\r\n    \r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 5,067\r\n      Metric Samples: Last Run: 6, Total: 30,396\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    disk (2.5.3)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 5,067\r\n      Metric Samples: Last Run: 228, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 33ms\r\n      \r\n    \r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 5,066\r\n      Metric Samples: Last Run: 253, Total: 1 M\r\n      Events: Last Run: 0, Total: 45\r\n      Service Checks: Last Run: 1, Total: 5,066\r\n      Average Execution Time : 75ms\r\n      \r\n    \r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 5,067\r\n      Metric Samples: Last Run: 5, Total: 25,335\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    fluentd (1.5.0)\r\n    ---------------\r\n      Instance ID: fluentd:20451ce853e5abef [ERROR]\r\n      Configuration Source: docker:docker://90b5c56f011dfe749a2127e19e163e4d4fb74bd20b8371be869c0ab0b0ac2763\r\n      Total Runs: 308\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 308\r\n      Average Execution Time : 5.01s\r\n      Error: HTTPConnectionPool(host='ip-10-203-167-55.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff6889fd910>, 'Connection to ip-10-203-167-55.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 157, in _new_conn\r\n          (self._dns_host, self.port), self.timeout, **extra_kw\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/connection.py\", line 84, in create_connection\r\n          raise err\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/connection.py\", line 74, in create_connection\r\n          sock.connect(sa)\r\n      socket.timeout: timed out\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\r\n          chunked=chunked,\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\r\n          conn.request(method, url, **httplib_request_kw)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1244, in request\r\n          self._send_request(method, url, body, headers, encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1290, in _send_request\r\n          self.endheaders(body, encode_chunked=encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1239, in endheaders\r\n          self._send_output(message_body, encode_chunked=encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1026, in _send_output\r\n          self.send(msg)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 966, in send\r\n          self.connect()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 184, in connect\r\n          conn = self._new_conn()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 164, in _new_conn\r\n          % (self.host, self.timeout),\r\n      urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7ff6889fd910>, 'Connection to ip-10-203-167-55.ap-northeast-1.compute.internal timed out. (connect timeout=5)')\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\r\n          timeout=timeout\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\r\n          method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/retry.py\", line 436, in increment\r\n          raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n      urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='ip-10-203-167-55.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff6889fd910>, 'Connection to ip-10-203-167-55.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 678, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/fluentd/fluentd.py\", line 68, in check\r\n          r = self.http.get(url)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/utils/http.py\", line 286, in get\r\n          return self._request('get', url, options)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/utils/http.py\", line 319, in _request\r\n          return getattr(self.session, method)(url, **self.populate_options(options))\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 546, in get\r\n          return self.request('GET', url, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\r\n          resp = self.send(prep, **send_kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\r\n          r = adapter.send(request, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/adapters.py\", line 504, in send\r\n          raise ConnectTimeout(e, request=request)\r\n      requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='ip-10-203-167-55.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff6889fd910>, 'Connection to ip-10-203-167-55.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n      Instance ID: fluentd:46b5a82d5c7765d4 [ERROR]\r\n      Configuration Source: docker:docker://74bd95decea91f4216fda7fface246480118a8464f5c679a70f2b2971af922a8\r\n      Total Runs: 308\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 308\r\n      Average Execution Time : 5.008s\r\n      Error: HTTPConnectionPool(host='ip-10-203-170-90.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff65837b0d0>, 'Connection to ip-10-203-170-90.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 157, in _new_conn\r\n          (self._dns_host, self.port), self.timeout, **extra_kw\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/connection.py\", line 84, in create_connection\r\n          raise err\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/connection.py\", line 74, in create_connection\r\n          sock.connect(sa)\r\n      socket.timeout: timed out\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\r\n          chunked=chunked,\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\r\n          conn.request(method, url, **httplib_request_kw)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1244, in request\r\n          self._send_request(method, url, body, headers, encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1290, in _send_request\r\n          self.endheaders(body, encode_chunked=encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1239, in endheaders\r\n          self._send_output(message_body, encode_chunked=encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1026, in _send_output\r\n          self.send(msg)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 966, in send\r\n          self.connect()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 184, in connect\r\n          conn = self._new_conn()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 164, in _new_conn\r\n          % (self.host, self.timeout),\r\n      urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7ff65837b0d0>, 'Connection to ip-10-203-170-90.ap-northeast-1.compute.internal timed out. (connect timeout=5)')\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\r\n          timeout=timeout\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\r\n          method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/retry.py\", line 436, in increment\r\n          raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n      urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='ip-10-203-170-90.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff65837b0d0>, 'Connection to ip-10-203-170-90.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 678, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/fluentd/fluentd.py\", line 68, in check\r\n          r = self.http.get(url)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/utils/http.py\", line 286, in get\r\n          return self._request('get', url, options)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/utils/http.py\", line 319, in _request\r\n          return getattr(self.session, method)(url, **self.populate_options(options))\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 546, in get\r\n          return self.request('GET', url, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\r\n          resp = self.send(prep, **send_kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\r\n          r = adapter.send(request, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/adapters.py\", line 504, in send\r\n          raise ConnectTimeout(e, request=request)\r\n      requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='ip-10-203-170-90.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff65837b0d0>, 'Connection to ip-10-203-170-90.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n      Instance ID: fluentd:7305a4eb101e7c20 [ERROR]\r\n      Configuration Source: docker:docker://141056891af0eea618c7e517588724fa2dfe714768b3b3bbb92582d818916f7d\r\n      Total Runs: 308\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 308\r\n      Average Execution Time : 5.008s\r\n      Error: HTTPConnectionPool(host='ip-10-203-170-9.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff6889fd290>, 'Connection to ip-10-203-170-9.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 157, in _new_conn\r\n          (self._dns_host, self.port), self.timeout, **extra_kw\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/connection.py\", line 84, in create_connection\r\n          raise err\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/connection.py\", line 74, in create_connection\r\n          sock.connect(sa)\r\n      socket.timeout: timed out\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\r\n          chunked=chunked,\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\r\n          conn.request(method, url, **httplib_request_kw)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1244, in request\r\n          self._send_request(method, url, body, headers, encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1290, in _send_request\r\n          self.endheaders(body, encode_chunked=encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1239, in endheaders\r\n          self._send_output(message_body, encode_chunked=encode_chunked)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 1026, in _send_output\r\n          self.send(msg)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/http/client.py\", line 966, in send\r\n          self.connect()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 184, in connect\r\n          conn = self._new_conn()\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connection.py\", line 164, in _new_conn\r\n          % (self.host, self.timeout),\r\n      urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x7ff6889fd290>, 'Connection to ip-10-203-170-9.ap-northeast-1.compute.internal timed out. (connect timeout=5)')\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\r\n          timeout=timeout\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\r\n          method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/urllib3/util/retry.py\", line 436, in increment\r\n          raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n      urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='ip-10-203-170-9.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff6889fd290>, 'Connection to ip-10-203-170-9.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n      \r\n      During handling of the above exception, another exception occurred:\r\n      \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/checks/base.py\", line 678, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/fluentd/fluentd.py\", line 68, in check\r\n          r = self.http.get(url)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/utils/http.py\", line 286, in get\r\n          return self._request('get', url, options)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/datadog_checks/base/utils/http.py\", line 319, in _request\r\n          return getattr(self.session, method)(url, **self.populate_options(options))\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 546, in get\r\n          return self.request('GET', url, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\r\n          resp = self.send(prep, **send_kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\r\n          r = adapter.send(request, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python3.7/site-packages/requests/adapters.py\", line 504, in send\r\n          raise ConnectTimeout(e, request=request)\r\n      requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='ip-10-203-170-9.ap-northeast-1.compute.internal', port=24220): Max retries exceeded with url: /api/plugins.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7ff6889fd290>, 'Connection to ip-10-203-170-9.ap-northeast-1.compute.internal timed out. (connect timeout=5)'))\r\n    \r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 5,066\r\n      Metric Samples: Last Run: 104, Total: 526,792\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 5,067\r\n      Metric Samples: Last Run: 6, Total: 30,402\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 5,066\r\n      Metric Samples: Last Run: 17, Total: 86,122\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    network (1.12.2)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 5,067\r\n      Metric Samples: Last Run: 31, Total: 157,077\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 1ms\r\n      \r\n    \r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 85\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 85\r\n      Average Execution Time : 20.009s\r\n      \r\n    \r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 5,066\r\n      Metric Samples: Last Run: 1, Total: 5,066\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    tomcat\r\n      instance_name : tomcat-ip-10-203-170-90.ap-northeast-1.compute.internal-1099\r\n      message : \r\n      metric_count : 41\r\n      service_check_count : 0\r\n      status : OK\r\n      instance_name : tomcat-ip-10-203-167-55.ap-northeast-1.compute.internal-1099\r\n      message : \r\n      metric_count : 41\r\n      service_check_count : 0\r\n      status : OK\r\n      instance_name : tomcat-ip-10-203-170-9.ap-northeast-1.compute.internal-1099\r\n      message : \r\n      metric_count : 41\r\n      service_check_count : 0\r\n      status : OK\r\n  Failed checks\r\n  =============\r\n    no checks\r\n    \r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 5,066\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 571\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 10,703\r\n    TimeseriesV1: 5,066\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 2f992: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 2f992\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 3.2 M\r\n  Dogstatsd Metric Sample: 1 M\r\n  Event: 46\r\n  Events Flushed: 46\r\n  Number Of Flushes: 5,066\r\n  Series Flushed: 3.2 M\r\n  Service Check: 134,328\r\n  Service Checks Flushed: 139,373\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 1 M\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 23,493\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 165.3 M\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 808,586\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n- Apache/2.4.33 (Amazon)\r\n- on ECS, deployed with dockerLabels\r\n```\r\n                \"com.datadoghq.ad.check_names\": \"[\\\"apache\\\"]\",\r\n                \"com.datadoghq.ad.init_configs\": \"[{}]\",\r\n                \"com.datadoghq.ad.instances\": \"[{\\\"apache_status_url\\\": \\\"http://%%host%%/server-status?auto\\\", \\\"persist_connections\\\": true, \\\"tags\\\": [\\\"service:ncsp-core\\\"]}]\",\r\n                \"com.datadoghq.ad.logs\": \"[{}]\",\r\n```\r\n- server status response from apache is as followings\r\n\r\n```\r\nroot@db6dffd0ec79:/# curl 10.203.170.90/server-status?auto -v\r\n*   Trying 10.203.170.90:80...\r\n* TCP_NODELAY set\r\n* Connected to 10.203.170.90 (10.203.170.90) port 80 (#0)\r\n> GET /server-status?auto HTTP/1.1\r\n> Host: 10.203.170.90\r\n> User-Agent: curl/7.65.3\r\n> Accept: */*\r\n> \r\n* Mark bundle as not supporting multiuse\r\n< HTTP/1.1 200 OK\r\n< Date: Fri, 20 Dec 2019 07:06:20 GMT\r\n< Server: Apache\r\n< Content-Length: 3669\r\n< Content-Type: text/plain; charset=ISO-8859-1\r\n< \r\n10.203.170.90\r\nServerVersion: Apache/2.4.33 (Amazon) OpenSSL/1.0.2k-fips\r\nServerMPM: worker\r\nServer Built: Mar 28 2018 08:31:01\r\nCurrentTime: Friday, 20-Dec-2019 07:06:20 UTC\r\nRestartTime: Friday, 20-Dec-2019 05:21:51 UTC\r\nParentServerConfigGeneration: 1\r\nParentServerMPMGeneration: 0\r\nServerUptimeSeconds: 6269\r\nServerUptime: 1 hour 44 minutes 29 seconds\r\nLoad1: 8.49\r\nLoad5: 9.04\r\nLoad15: 9.67\r\nTotal Accesses: 14549657\r\nTotal kBytes: 12433134\r\nCPUUser: 2221.76\r\nCPUSystem: 1305.54\r\nCPUChildrenUser: 0\r\nCPUChildrenSystem: 0\r\nCPULoad: 56.2658\r\nUptime: 6269\r\nReqPerSec: 2320.89\r\nBytesPerSec: 2030870\r\nBytesPerReq: 875.04\r\nBusyWorkers: 66\r\nIdleWorkers: 2958\r\nScoreboard: _________________________________________W_____________W____________________________________________________________________________R_________________________________________________________________________________W_____________________________________________________K_______________________________________________K______________________________________________________________________________________________________WW_______K____W________________________________________________________________K________________________________________________________________W__________________________________________________________________________W____________________________________________________________________W_________________________________________________________________W_______________________________________________________________________W_______W_____________________________________________________________________K__________________________________________________________________________W________________________________________________________________W________W___________________________________________________________W____W_____________________________________________________________________________________W______________________________________________________________W________________________________________________________________W________________________________________________________________________________W_____________________________________________________________________________W_________________________________________W_______________________________________________________________________________W_____________________________K_________________________________________W____________________________________________________________________________R__K________________________________________________________________W__________W_______________________________________________W______________________________R__________________________________________W____________K________R_________________________________________________________________________W________________________________________________W______________________W_________________________________________________________________________WR___________________________________________________K___________________________W_______________________________________________________________________________________________________________________W_________W__________________________________________________________W_____________________W___________________________________________________________R__W___________________________________________________________________________________W________________________________________________________W___R_W_________________________________________________________________K_W__________________________________________________________________W_R_______________________________________________________________W________________R_______________________________________________________________________W___R___\r\n* Connection #0 to host 10.203.170.90 left intact\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n1. \r\n2.\r\n3.\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nThe point is that we set up apache not to respond version in response header, like\r\n```\r\nroot@db6dffd0ec79:/# curl 10.203.170.90/server-status?auto -v\r\n*   Trying 10.203.170.90:80...\r\n* TCP_NODELAY set\r\n* Connected to 10.203.170.90 (10.203.170.90) port 80 (#0)\r\n> GET /server-status?auto HTTP/1.1\r\n> Host: 10.203.170.90\r\n> User-Agent: curl/7.65.3\r\n> Accept: */*\r\n> \r\n* Mark bundle as not supporting multiuse\r\n< HTTP/1.1 200 OK\r\n< Date: Fri, 20 Dec 2019 07:06:20 GMT\r\n< Server: Apache\r\n< Content-Length: 3669\r\n< Content-Type: text/plain; charset=ISO-8859-1\r\n< \r\n```\r\nwith https://httpd.apache.org/docs/2.4/en/mod/core.html#servertokens `ServerTokens ProductOnly`.\r\n\r\nI think, after https://github.com/DataDog/integrations-core/pull/5144/files change, datadog agent try to extract version from response header `Server`, and fails at https://github.com/DataDog/integrations-core/blob/master/apache/datadog_checks/apache/apache.py#L115.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5270", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5270/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5270/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5270/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5270", "id": 540970661, "node_id": "MDU6SXNzdWU1NDA5NzA2NjE=", "number": 5270, "title": "Error: \"Version does not adhere to semantic versioning\" when running DataDog agent 6.16.0 on Ubuntu", "user": {"login": "albertoal", "id": 1752588, "node_id": "MDQ6VXNlcjE3NTI1ODg=", "avatar_url": "https://avatars3.githubusercontent.com/u/1752588?v=4", "gravatar_id": "", "url": "https://api.github.com/users/albertoal", "html_url": "https://github.com/albertoal", "followers_url": "https://api.github.com/users/albertoal/followers", "following_url": "https://api.github.com/users/albertoal/following{/other_user}", "gists_url": "https://api.github.com/users/albertoal/gists{/gist_id}", "starred_url": "https://api.github.com/users/albertoal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/albertoal/subscriptions", "organizations_url": "https://api.github.com/users/albertoal/orgs", "repos_url": "https://api.github.com/users/albertoal/repos", "events_url": "https://api.github.com/users/albertoal/events{/privacy}", "received_events_url": "https://api.github.com/users/albertoal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-19T20:35:16Z", "updated_at": "2019-12-20T23:40:40Z", "closed_at": "2019-12-20T23:40:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe what happened:**\r\nAfter upgrading the DataDog agent to version `6.16.0`, we are getting an agent error like the following posted to stdout about 10 times every second. This is causing a lot of noise on our logs.\r\n\r\n```\r\n2019-12-19 20:20:23 UTC | CORE | ERROR | (pkg/collector/python/datadog_agent.go:116 in LogMessage) | (core.py:45) | Unable to transform `version` metadata value `Shield`: Version does not adhere to semantic versioning\r\n```\r\n\r\nWe follow the default installation steps, just by executing `curl -L https://raw.githubusercontent.com/DataDog/datadog-agent/master/cmd/agent/install_script.sh` on Ubuntu\r\n\r\nThe following can be seen in the installation logs - perhaps the version string `6.16.0-1` is the cause of the SemVer error?\r\n\r\n```\r\nremote: Preparing to unpack .../datadog-agent_1%3a6.16.0-1_amd64.deb ...\r\nremote: INFO -- : Unpacking datadog-agent (1:6.16.0-1) ...\r\nremote: ....\r\nremote: INFO -- : Processing triggers for systemd (229-4ubuntu21.23) ...\r\nremote: INFO -- : Setting up datadog-agent (1:6.16.0-1) ...\r\n```\r\n\r\n**Describe what you expected:**\r\n\r\nNo version errors posted on stdout/stderr\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nInstall Datadog agent using `curl -L https://raw.githubusercontent.com/DataDog/datadog-agent/master/cmd/agent/install_script.sh` and start the agent using `/usr/bin/datadog-agent run`. \r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\nUbuntu Bionic running on Docker and hosted on AWS", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5247", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5247/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5247/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5247/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5247", "id": 539954641, "node_id": "MDU6SXNzdWU1Mzk5NTQ2NDE=", "number": 5247, "title": "Agent 7.16.0 cannot parse non-semantic nginx version", "user": {"login": "alexulyanov", "id": 22105378, "node_id": "MDQ6VXNlcjIyMTA1Mzc4", "avatar_url": "https://avatars0.githubusercontent.com/u/22105378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexulyanov", "html_url": "https://github.com/alexulyanov", "followers_url": "https://api.github.com/users/alexulyanov/followers", "following_url": "https://api.github.com/users/alexulyanov/following{/other_user}", "gists_url": "https://api.github.com/users/alexulyanov/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexulyanov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexulyanov/subscriptions", "organizations_url": "https://api.github.com/users/alexulyanov/orgs", "repos_url": "https://api.github.com/users/alexulyanov/repos", "events_url": "https://api.github.com/users/alexulyanov/events{/privacy}", "received_events_url": "https://api.github.com/users/alexulyanov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-18T20:50:50Z", "updated_at": "2020-08-06T14:16:14Z", "closed_at": "2019-12-19T15:35:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "After upgrading DataDog agent to 7.16.0 nginx integration stopped working.\r\n\r\nAgent Log:\r\n```Dec 18 15:42:50 nginxproxy agent[29323]: 2019-12-18 15:42:50 EST | CORE | ERROR | (pkg/collector/python/datadog_agent.go:116 in LogMessage) | nginx:17d65b5a97c80644 | (core.py:45) | Unable to transform `version` metadata value `nginx`: Version does not adhere to semantic versioning```\r\n\r\nnginx -v:\r\n`nginx version: nginx/1.13.9 (Ubuntu)`\r\n\r\nNothing changed in `nginx.d/conf.yaml` except status url:\r\n`- nginx_status_url: http://localhost:8080/stub_status/`\r\n\r\ndatadog-agent version:\r\n`Agent 7.16.0 - Commit: 3e13b77 - Serialization version: 4.15.0 - Go version: go1.12.9`\r\n\r\nWorked fine with version `Agent 6.15.1-1`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5136", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5136/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5136/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5136/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5136", "id": 532216953, "node_id": "MDU6SXNzdWU1MzIyMTY5NTM=", "number": 5136, "title": "Some kubernetes_state metrics values are doubled ", "user": {"login": "enummela", "id": 5798441, "node_id": "MDQ6VXNlcjU3OTg0NDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/5798441?v=4", "gravatar_id": "", "url": "https://api.github.com/users/enummela", "html_url": "https://github.com/enummela", "followers_url": "https://api.github.com/users/enummela/followers", "following_url": "https://api.github.com/users/enummela/following{/other_user}", "gists_url": "https://api.github.com/users/enummela/gists{/gist_id}", "starred_url": "https://api.github.com/users/enummela/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/enummela/subscriptions", "organizations_url": "https://api.github.com/users/enummela/orgs", "repos_url": "https://api.github.com/users/enummela/repos", "events_url": "https://api.github.com/users/enummela/events{/privacy}", "received_events_url": "https://api.github.com/users/enummela/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-03T19:37:29Z", "updated_at": "2019-12-03T20:01:26Z", "closed_at": "2019-12-03T20:01:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have noticed that some metrics collected from kube-state-metrics are doubled. Metrics in which I have observed doubling include `kubernetes_state.node.pods_capacity` and `kubernetes_state.node.count`.\r\n\r\nOther metrics such as `kubernetes_state.daemonset.scheduled` report the correct (undoubled) values.\r\n\r\nOnly one kube-state-metrics pod is running in my cluster.\r\n\r\n```\r\n$ kubectl get pods -n kube-state-metrics\r\nNAME                                  READY   STATUS    RESTARTS   AGE\r\nkube-state-metrics-84c5bbd44b-hhr4q   1/1     Running   0          27d\r\n```\r\n\r\nHere's the query that replicates the issue.\r\n\r\n```\r\nsum:kubernetes_state.daemonset.scheduled{*}, sum:kubernetes_state.node.count{*}\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\nThis is my kubernetes_state integration template.\r\n\r\n```\r\nad_identifiers:\r\n      - kube-state-metrics\r\n    init_config:\r\n    instances:\r\n      - kube_state_url: http://kube-state-metrics.kube-state-metrics.svc.cluster.local:8080/metrics\r\n        label_joins:\r\n          kube_node_labels:\r\n            label_to_match: node\r\n            labels_to_get:\r\n              - label_kubernetes_io_hostname\r\n              - label_node-group\r\n          kube_pod_labels:\r\n            label_to_match: pod\r\n            labels_to_get:\r\n              - label_app\r\n              - label_hosted_zone_type\r\n              - label_role\r\n              - label_team\r\n              - label_version\r\n          kube_deployment_labels:\r\n            label_to_match: deployment\r\n            labels_to_get:\r\n              - label_app\r\n              - label_hosted_zone_type\r\n              - label_role\r\n              - label_team\r\n              - label_version\r\n          kube_daemonset_labels:\r\n            label_to_match: daemonset\r\n            labels_to_get:\r\n              - label_app\r\n              - label_hosted_zone_type\r\n              - label_role\r\n              - label_team\r\n              - label_version\r\n          kube_replicaset_labels:\r\n            label_to_match: replicaset\r\n            labels_to_get:\r\n              - label_app\r\n              - label_hosted_zone_type\r\n              - label_role\r\n              - label_team\r\n              - label_version\r\n          kube_statefulset_labels:\r\n            label_to_match: statefulset\r\n            labels_to_get:\r\n              - label_app\r\n              - label_hosted_zone_type\r\n              - label_role\r\n              - label_team\r\n              - label_version\r\n        labels_mapper:\r\n          daemonset: kube_daemon_set\r\n          deployment: kube_deployment\r\n          job_name: kube_job\r\n          label_app: app\r\n          label_hosted_zone_type: hosted-zone-type\r\n          label_role: role\r\n          label_team: team\r\n          label_version: version\r\n          label_kubernetes_io_hostname: kube_node\r\n          label_node-group: kube_node_group\r\n          namespace: kube_namespace\r\n          node: kube_node\r\n          pod: pod_name\r\n          pod_ip: kube_pod_ip\r\n          replicaset: kube_replica_set\r\n          service: kube_service\r\n          statefulset: kube_stateful_set\r\n```\r\n\r\n**Agent status output**\r\n\r\n```\r\n\r\nkubernetes_state (4.7.1)\r\n------------------------\r\n  Instance ID: kubernetes_state:6a135f5d7a94cc54 [OK]\r\n  Configuration Source: file:/etc/datadog-agent/conf.d/kubernetes_state.d/conf.yaml\r\n  Total Runs: 23,581\r\n  Metric Samples: Last Run: 2,270, Total: 1 M\r\n  Events: Last Run: 0, Total: 0\r\n  Service Checks: Last Run: 18, Total: 424,602\r\n  Average Execution Time : 3.444s\r\n\r\n  Instance ID: kubernetes_state:82483f891045d1b9 [OK]\r\n  Configuration Source: file:/etc/datadog-agent/conf.d/kubernetes_state.d/auto_conf.yaml\r\n  Total Runs: 23,583\r\n  Metric Samples: Last Run: 2,270, Total: 1 M\r\n  Events: Last Run: 0, Total: 0\r\n  Service Checks: Last Run: 18, Total: 424,641\r\n  Average Execution Time : 2.683s\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5099", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5099/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5099/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5099/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5099", "id": 529422826, "node_id": "MDU6SXNzdWU1Mjk0MjI4MjY=", "number": 5099, "title": "Set `log_path` to `None` in Vertica integration", "user": {"login": "AlexandreYang", "id": 49917914, "node_id": "MDQ6VXNlcjQ5OTE3OTE0", "avatar_url": "https://avatars0.githubusercontent.com/u/49917914?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AlexandreYang", "html_url": "https://github.com/AlexandreYang", "followers_url": "https://api.github.com/users/AlexandreYang/followers", "following_url": "https://api.github.com/users/AlexandreYang/following{/other_user}", "gists_url": "https://api.github.com/users/AlexandreYang/gists{/gist_id}", "starred_url": "https://api.github.com/users/AlexandreYang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AlexandreYang/subscriptions", "organizations_url": "https://api.github.com/users/AlexandreYang/orgs", "repos_url": "https://api.github.com/users/AlexandreYang/repos", "events_url": "https://api.github.com/users/AlexandreYang/events{/privacy}", "received_events_url": "https://api.github.com/users/AlexandreYang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-27T15:36:02Z", "updated_at": "2019-11-27T15:36:23Z", "closed_at": "2019-11-27T15:36:23Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Set `log_path` to `None` in Vertica integration when https://github.com/vertica/vertica-python/pull/341 is released by upgrading vertica-python dependency version.\r\n\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n**Steps to reproduce the issue:**\r\n1.\r\n2.\r\n3.\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/5009", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5009/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5009/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/5009/events", "html_url": "https://github.com/DataDog/integrations-core/issues/5009", "id": 522740930, "node_id": "MDU6SXNzdWU1MjI3NDA5MzA=", "number": 5009, "title": "Repeated postgres \"current transaction aborted\" errors.", "user": {"login": "aflury", "id": 5658567, "node_id": "MDQ6VXNlcjU2NTg1Njc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5658567?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aflury", "html_url": "https://github.com/aflury", "followers_url": "https://api.github.com/users/aflury/followers", "following_url": "https://api.github.com/users/aflury/following{/other_user}", "gists_url": "https://api.github.com/users/aflury/gists{/gist_id}", "starred_url": "https://api.github.com/users/aflury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aflury/subscriptions", "organizations_url": "https://api.github.com/users/aflury/orgs", "repos_url": "https://api.github.com/users/aflury/repos", "events_url": "https://api.github.com/users/aflury/events{/privacy}", "received_events_url": "https://api.github.com/users/aflury/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-14T01:09:53Z", "updated_at": "2019-11-20T22:34:13Z", "closed_at": "2019-11-20T22:34:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nIf you suspect your issue is a bug, please attach the output of the Agent status page,\r\nsee https://docs.datadoghq.com/agent/faq/agent-commands/#agent-information\r\n-->\r\n\r\n**Describe what happened:**\r\n\r\ndatadog-agent encountered an error while executing a query against postgres to gather statistics. That error caused the agent to continue to fail on queries indefinitely. e.g.:\r\n```\r\n2019-11-13 23:18:37.026 UTC [19016] hawking [unknown] monitor 127.0.0.1(49432) 5d827718.4a48 ERROR:  current transaction is aborted, commands ignored until end of transaction block\r\n2019-11-13 23:18:37.026 UTC [19016] hawking [unknown] monitor 127.0.0.1(49432) 5d827718.4a48 STATEMENT:  SELECT psd.datname, numbackends, temp_bytes, blks_read, deadlocks, pg_database_size(psd.datname) as pg_database_size, temp_files, 2^31 - age(datfrozenxid) as wraparound, xact_commit, tup_deleted, xact_rollback, tup_inserted, tup_returned, tup_updated, blks_hit, tup_fetched FROM pg_stat_database psd JOIN pg_database pd ON psd.datname = pd.datname WHERE psd.datname not ilike 'template%%%%'   AND psd.datname not ilike 'rdsadmin'   AND psd.datname not ilike 'azure_maintenance'   AND psd.datname not ilike 'postgres'\r\n```\r\nI suspect that this is due to the agent holding open a long-lived postgres connection while doing those periodic `SELECT`s without ending each of their transactions. The fix might be as simple as forcing a `COMMIT` after each of those `SELECT`s.\r\n\r\n**Describe what you expected:**\r\n\r\nWould expect that a single query failure wouldn't cause future queries to continue to fail.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nYou could force a query to fail somehow, although I wasn't able to track down the original query that failed.\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\nUbuntu 14.04 on AWS:\r\n\r\n```\r\n===============\r\nAgent (v6.13.0)\r\n===============\r\n\r\n  Status date: 2019-11-14 01:04:41.954604 UTC\r\n  Agent start: 2019-11-13 23:34:03.746793 UTC\r\n  Pid: 29317\r\n  Go Version: go1.11.5\r\n  Python Version: 2.7.16\r\n  Check Runners: 10\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -358\u00b5s\r\n    System UTC time: 2019-11-14 01:04:41.954604 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-08-28 21:54:27.000000 UTC\r\n    kernelVersion: 4.4.0-148-generic\r\n    os: linux\r\n    platform: ubuntu\r\n    platformFamily: debian\r\n    platformVersion: 14.04\r\n    procs: 425\r\n    uptime: 1849h39m37s\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4999", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4999/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4999/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4999/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4999", "id": 521665532, "node_id": "MDU6SXNzdWU1MjE2NjU1MzI=", "number": 4999, "title": "TLS Support for consul on k8s", "user": {"login": "ryan-dyer-sp", "id": 16764971, "node_id": "MDQ6VXNlcjE2NzY0OTcx", "avatar_url": "https://avatars2.githubusercontent.com/u/16764971?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ryan-dyer-sp", "html_url": "https://github.com/ryan-dyer-sp", "followers_url": "https://api.github.com/users/ryan-dyer-sp/followers", "following_url": "https://api.github.com/users/ryan-dyer-sp/following{/other_user}", "gists_url": "https://api.github.com/users/ryan-dyer-sp/gists{/gist_id}", "starred_url": "https://api.github.com/users/ryan-dyer-sp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ryan-dyer-sp/subscriptions", "organizations_url": "https://api.github.com/users/ryan-dyer-sp/orgs", "repos_url": "https://api.github.com/users/ryan-dyer-sp/repos", "events_url": "https://api.github.com/users/ryan-dyer-sp/events{/privacy}", "received_events_url": "https://api.github.com/users/ryan-dyer-sp/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 592413329, "node_id": "MDU6TGFiZWw1OTI0MTMzMjk=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/containers", "name": "containers", "color": "0052cc", "default": false, "description": null}, {"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-11-12T16:41:34Z", "updated_at": "2020-06-25T13:41:31Z", "closed_at": "2020-06-25T13:41:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n**Steps to reproduce the issue:**\r\n1. Consul setup with helm charts on k8s.  It is configured for TLS with a cert issued by the internal k8s CA.\r\n2. Install DD Agent per https://app.datadoghq.com/account/settings#agent/kubernetes\r\n3. Configure auto discovery on the Consul STS with the following annotations:\r\n```        ad.datadoghq.com/consul.check_names: '[\"consul\"]'\r\n        ad.datadoghq.com/consul.init_configs: '[{}]'\r\n        ad.datadoghq.com/consul.instances: '[{\"url\": \"https://%%host%%:8501\",\"catalog_checks\": \"true\",\"new_leader_checks\": \"true\", \"tls_ca_cert\": \"/var/run/secrets/kubernetes/serviceaccount/ca.crt\"}]'\r\n```\r\n\r\n**Describe the results you received:**\r\nDD receives an error in log:\r\n```\r\nCaused by SSLError(CertificateError(\\\"hostname '10.1.0.162' doesn't match either of 'consul-server.consul.svc.cluster.local', 'server.vault-us-east-1.consul', '*.consul-server.consul.svc.cluster.local'\\\",),))\\n\"}]\r\n```\r\n\r\n\r\n**Describe the results you expected:**\r\nNeed to be able to perform consul checks against pods configured with TLS.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI believe this could be solved by adding a flag to use HostHeaderSSLAdapter as part of the requests in the code. https://toolbelt.readthedocs.io/en/latest/adapters.html#hostheaderssladapter\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4945", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4945/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4945/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4945/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4945", "id": 517443331, "node_id": "MDU6SXNzdWU1MTc0NDMzMzE=", "number": 4945, "title": "etcd prometheus check configuration broken/misdocumented", "user": {"login": "adammw", "id": 153219, "node_id": "MDQ6VXNlcjE1MzIxOQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/153219?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adammw", "html_url": "https://github.com/adammw", "followers_url": "https://api.github.com/users/adammw/followers", "following_url": "https://api.github.com/users/adammw/following{/other_user}", "gists_url": "https://api.github.com/users/adammw/gists{/gist_id}", "starred_url": "https://api.github.com/users/adammw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adammw/subscriptions", "organizations_url": "https://api.github.com/users/adammw/orgs", "repos_url": "https://api.github.com/users/adammw/repos", "events_url": "https://api.github.com/users/adammw/events{/privacy}", "received_events_url": "https://api.github.com/users/adammw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-04T22:34:21Z", "updated_at": "2019-11-06T17:48:53Z", "closed_at": "2019-11-06T17:48:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```\r\nAgent (v6.14.1)\r\n===============\r\n\r\n  Status date: 2019-11-04 22:24:56.314135 UTC\r\n  Agent start: 2019-10-28 17:27:43.277291 UTC\r\n  Pid: 26147\r\n  Go Version: go1.12.9\r\n  Python Version: 2.7.16\r\n  Check Runners: 4\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):** Ubuntu 16.04 running on AWS.\r\n\r\nhttps://github.com/DataDog/integrations-core/pull/4323 changed the documented configuration variables expected by the etcd check from `ssl_private_key`/`ssl_cert`/`ssl_ca_cert` to `tls_private_key`/`tls_cert`/`tls_ca_cert`, however this new mapping only works for the legacy (non-prometheus) integration. \r\n\r\nWhen using the prometheus check, the config context is passed directly to the openmetrics mixin which uses the `requests` module directly, therefore the `HTTP_CONFIG_REMAPPER` map is never used and the new options never get parsed. This can result in SSL connectivity errors in the etcd check when `use_preview` is True.\r\n\r\nFurther the configuration change was not listed in the integration changelog making older configurations invalid as well. I suggest the name changes be reverted or the documentation be updated to work with both variants of `use_preview`.\r\n\r\ncc @eatwithforks\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4923", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4923/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4923/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4923/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4923", "id": 514223768, "node_id": "MDU6SXNzdWU1MTQyMjM3Njg=", "number": 4923, "title": "Datadog's kubelet integration partially broken with kube 1.16.x", "user": {"login": "SleepyBrett", "id": 279521, "node_id": "MDQ6VXNlcjI3OTUyMQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/279521?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SleepyBrett", "html_url": "https://github.com/SleepyBrett", "followers_url": "https://api.github.com/users/SleepyBrett/followers", "following_url": "https://api.github.com/users/SleepyBrett/following{/other_user}", "gists_url": "https://api.github.com/users/SleepyBrett/gists{/gist_id}", "starred_url": "https://api.github.com/users/SleepyBrett/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SleepyBrett/subscriptions", "organizations_url": "https://api.github.com/users/SleepyBrett/orgs", "repos_url": "https://api.github.com/users/SleepyBrett/repos", "events_url": "https://api.github.com/users/SleepyBrett/events{/privacy}", "received_events_url": "https://api.github.com/users/SleepyBrett/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 592413329, "node_id": "MDU6TGFiZWw1OTI0MTMzMjk=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/containers", "name": "containers", "color": "0052cc", "default": false, "description": null}, {"id": 936572172, "node_id": "MDU6TGFiZWw5MzY1NzIxNzI=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/kubelet", "name": "integration/kubelet", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-29T21:05:47Z", "updated_at": "2019-10-31T16:01:44Z", "closed_at": "2019-10-30T17:46:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/master/kubelet/datadog_checks/kubelet/prometheus.py#L18 (note \"container_name\" and \"pod_name\")\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/master/kubelet/datadog_checks/kubelet/prometheus.py#L111 (note \"container_name\")\r\n\r\nhttps://github.com/kubernetes/kubernetes/pull/80376/files\r\npod_name and container_name on kubelet stats have been deprecated in favor of pod and container respectively.\r\n\r\nVerification of kubelet output:\r\n```\r\nroot@dd-prod-datadog-4jrsn:/# curl -ks -H \"Authorization: Bearer `cat /var/run/secrets/kubernetes.io/serviceaccount/token`\" https://172.27.188.233:10250/metrics/cadvisor | grep container_memory_usage_bytes | grep container | head\r\n# HELP container_memory_usage_bytes Current memory usage in bytes, including all memory regardless of when it was accessed\r\n# TYPE container_memory_usage_bytes gauge\r\ncontainer_memory_usage_bytes{container=\"\",id=\"/\",image=\"\",name=\"\",namespace=\"\",pod=\"\"} 1.1965345792e+10 1572383868784\r\ncontainer_memory_usage_bytes{container=\"\",id=\"/kubepods\",image=\"\",name=\"\",namespace=\"\",pod=\"\"} 1.844432896e+09 1572383868791\r\ncontainer_memory_usage_bytes{container=\"\",id=\"/kubepods/besteffort\",image=\"\",name=\"\",namespace=\"\",pod=\"\"} 6.0973056e+07 1572383860208\r\ncontainer_memory_usage_bytes{container=\"\",id=\"/kubepods/besteffort/pod19434bfe-7c58-497d-9216-29cbec0ab81e\",image=\"\",name=\"\",namespace=\"k8s-goldpinger\",pod=\"goldpinger-qhrl9\"} 2.5808896e+07 1572383867597\r\ncontainer_memory_usage_bytes{container=\"\",id=\"/kubepods/besteffort/pod91d589137af585dfa17062eec4a40d0a\",image=\"\",name=\"\",namespace=\"kube-system\",pod=\"pod-checkpointer-5vp77-ip-172-27-188-233.us-west-2.compute.internal\"} 7.770112e+06 1572383868022\r\ncontainer_memory_usage_bytes{container=\"\",id=\"/kubepods/besteffort/podc8f0dcef-df4c-459c-af1b-ac5a932ef701\",image=\"\",name=\"\",namespace=\"kube-system\",pod=\"pod-checkpointer-5vp77\"} 1.777664e+07 1572383864882\r\ncontainer_memory_usage_bytes{container=\"\",id=\"/kubepods/besteffort/podd758c5bb-a42c-4737-bbeb-3f9c8a996463\",image=\"\",name=\"\",namespace=\"k8s-startup-script\",pod=\"startup-script-hpm5q\"} 3.895296e+06 1572383866673\r\ncontainer_memory_usage_bytes{container=\"\",id=\"/kubepods/besteffort/pode0fc390a-d571-4f0e-bd28-9cc72e96a448\",image=\"\",name=\"\",namespace=\"k8s-sysdig\",pod=\"sysdig-4zc4d\"} 1.26976e+06 1572383858071\r\n```\r\n\r\nThis breaks many of the kubernetes.memory, cpu and network stats\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nKubernetes 1.16.x, dd agent 6.12-6.15.0-rc.8 inclusive tested\r\n\r\n**Steps to reproduce the issue:**\r\n1. deploy agent to 1.16.x kubernetes cluster\r\n2. attempt to look up something like kubernetes.memory.usage_pct for any given container\r\n3. notice that there are no stats\r\n\r\n**Describe the results you received:**\r\n\r\nNo stats.\r\n\r\n**Describe the results you expected:**\r\n\r\nStats.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4864", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4864/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4864/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4864/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4864", "id": 511369671, "node_id": "MDU6SXNzdWU1MTEzNjk2NzE=", "number": 4864, "title": "network integration uses sudo, which is not available in the docker agent", "user": {"login": "q42jaap", "id": 114642, "node_id": "MDQ6VXNlcjExNDY0Mg==", "avatar_url": "https://avatars0.githubusercontent.com/u/114642?v=4", "gravatar_id": "", "url": "https://api.github.com/users/q42jaap", "html_url": "https://github.com/q42jaap", "followers_url": "https://api.github.com/users/q42jaap/followers", "following_url": "https://api.github.com/users/q42jaap/following{/other_user}", "gists_url": "https://api.github.com/users/q42jaap/gists{/gist_id}", "starred_url": "https://api.github.com/users/q42jaap/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/q42jaap/subscriptions", "organizations_url": "https://api.github.com/users/q42jaap/orgs", "repos_url": "https://api.github.com/users/q42jaap/repos", "events_url": "https://api.github.com/users/q42jaap/events{/privacy}", "received_events_url": "https://api.github.com/users/q42jaap/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-23T14:39:04Z", "updated_at": "2019-10-30T16:53:03Z", "closed_at": "2019-10-30T16:53:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The line \r\n[https://github.com/DataDog/integrations-core/blob/master/network/datadog_checks/network/network.py#L475](https://github.com/DataDog/integrations-core/blob/fa5810146fd27d549e250bbdecc4e0f1963e7f2c/network/datadog_checks/network/network.py#L475)\r\n```\r\noutput, _, _ = get_subprocess_output([\"sudo\", conntrack_path, \"-S\"], self.log)\r\n```\r\nhas `sudo` in it.\r\n\r\nWe're running the datadog agent in the docker container https://hub.docker.com/r/datadog/agent (version 6.14.1).\r\nIn that container sudo is not installed so the command fails silently.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4812", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4812/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4812/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4812/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4812", "id": 508624123, "node_id": "MDU6SXNzdWU1MDg2MjQxMjM=", "number": 4812, "title": "SSL check is not working when a private CA is configured", "user": {"login": "renaudhager", "id": 12563305, "node_id": "MDQ6VXNlcjEyNTYzMzA1", "avatar_url": "https://avatars2.githubusercontent.com/u/12563305?v=4", "gravatar_id": "", "url": "https://api.github.com/users/renaudhager", "html_url": "https://github.com/renaudhager", "followers_url": "https://api.github.com/users/renaudhager/followers", "following_url": "https://api.github.com/users/renaudhager/following{/other_user}", "gists_url": "https://api.github.com/users/renaudhager/gists{/gist_id}", "starred_url": "https://api.github.com/users/renaudhager/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/renaudhager/subscriptions", "organizations_url": "https://api.github.com/users/renaudhager/orgs", "repos_url": "https://api.github.com/users/renaudhager/repos", "events_url": "https://api.github.com/users/renaudhager/events{/privacy}", "received_events_url": "https://api.github.com/users/renaudhager/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-10-17T17:41:01Z", "updated_at": "2019-10-18T16:47:39Z", "closed_at": "2019-10-18T16:47:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v6.14.0)\r\n===============\r\n\r\n  Status date: 2019-10-17 16:56:47.686227 UTC\r\n  Agent start: 2019-10-17 16:56:05.183719 UTC\r\n  Pid: 22918\r\n  Go Version: go1.12.9\r\n  Python Version: 2.7.16\r\n  Check Runners: 4\r\n  Log Level: debug\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -993\u00b5s\r\n    System UTC time: 2019-10-17 16:56:47.686227 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-10-16 17:12:52.000000 UTC\r\n    kernelVersion: 4.15.0-1027-aws\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: 10.1\r\n    procs: 178\r\n    uptime: 23h43m14s\r\n    virtualizationRole: guest\r\n    virtualizationSystem: docker\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ip-10-1-1-147.eu-west-1.compute.internal\r\n    hostname: consul-server-1-i-04dad273ab3198d97\r\n    instance-id: i-04dad273ab3198d97\r\n    socket-fqdn: 6a943b3d3603\r\n    socket-hostname: 6a943b3d3603\r\n    host tags:\r\n      location:eu-west-1\r\n      group_role:consul-server\r\n      provider:aws\r\n    hostname provider: configuration\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    consul (1.9.1)\r\n    --------------\r\n      Instance ID: consul:29cecf8b342b908c [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/consul.yaml\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 1, Total: 3\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 2, Total: 7\r\n      Average Execution Time : 13ms\r\n\r\n      Instance ID: consul:fd3ee6b1b01a81b4 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/consul.d/auto_conf.yaml\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 1, Total: 3\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 2, Total: 7\r\n      Average Execution Time : 17ms\r\n\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 6, Total: 12\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    disk (2.5.0)\r\n    ------------\r\n      Instance ID: disk:1a1171fc8f9456e3 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 134, Total: 268\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 101ms\r\n\r\n\r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 36, Total: 72\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 2\r\n      Average Execution Time : 11ms\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 5, Total: 15\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    http_check (4.2.0)\r\n    ------------------\r\n      Instance ID: http_check:Consul:928f17239ebab106 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/http_check.d/conf.yaml\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 5, Total: 15\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 2, Total: 6\r\n      Average Execution Time : 33ms\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 39, Total: 51\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 6, Total: 18\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 17, Total: 51\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    network (1.11.4)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 49, Total: 147\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 4ms\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:133ed7da27793e16 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.yaml\r\n      Total Runs: 2\r\n      Metric Samples: Last Run: 1, Total: 2\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 2\r\n      Average Execution Time : 0s\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 3\r\n      Metric Samples: Last Run: 1, Total: 3\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 2\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 2\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 6\r\n    TimeseriesV1: 2\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with <REDACTED>: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.eu - API Key ending with:\r\n      - <REDACTED>\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n    LogsProcessed: 728\r\n    LogsSent: 728\r\n\r\n  journald\r\n  --------\r\n    Type: journald\r\n    ExcludeUnits: proc-sys-fs-binfmt_misc.automount\r\n    Status: OK\r\n    Inputs: default\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 727\r\n  Dogstatsd Metric Sample: 1,929\r\n  Event: 1\r\n  Events Flushed: 1\r\n  Number Of Flushes: 2\r\n  Series Flushed: 430\r\n  Service Check: 58\r\n  Service Checks Flushed: 44\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 1,928\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 76,498\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 1,936\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n**Steps to reproduce the issue:**\r\n1. Enable `tls_verify`\r\n2. Configure a private with `tls_ca_cert`\r\n\r\n\r\n**Describe the results you received:**\r\n```\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/check.go:69 in runCheck) | Running python check http_check http_check:Consul:928f17239ebab106\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:111) | Connecting to https://consul-server-1.eu-west-1.dev.<REDACTED>:8501\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:815) | Starting new HTTPS connection (1): consul-server-1.eu-west-1.dev.<REDACTED>:8501\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:396) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 \"GET / HTTP/1.1\" 301 39\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:396) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 \"GET /ui/ HTTP/1.1\" 200 5729\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:92) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 is UP\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:318) | Site is down, unable to connect to get cert expiration: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)\r\n2019-10-17 16:53:40 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check http_check\r\n```\r\n\r\n**Describe the results you expected:**  \r\n\r\nI expect the SSL verification to work since the CA has been configured.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nAfter an investigation I think I got the bottom of it. [Here](https://github.com/DataDog/integrations-core/blob/master/http_check/datadog_checks/http_check/http_check.py#L302)  `instance_ca_certs` should be the value configured in the yaml. For some reason it's not, it the default CA of the Agent as you can see here:\r\n```\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/check.go:69 in runCheck) | Running python check http_check http_check:Consul:928f17239ebab106\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:111) | Connecting to https://consul-server-1.eu-west-1.dev.<REDACTED>:8501\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:815) | Starting new HTTPS connection (1): consul-server-1.eu-west-1.dev.<REDACTED>:8501\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:396) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 \"GET / HTTP/1.1\" 301 39\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:396) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 \"GET /ui/ HTTP/1.1\" 200 5729\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:92) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 is UP\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:292) | ca file /opt/datadog-agent/embedded/ssl/certs/cacert.pem\r\n2019-10-17 16:53:40 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:318) | Site is down, unable to connect to get cert expiration: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:727)\r\n2019-10-17 16:53:40 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check http_check\r\n```\r\n\r\nI fixed the issue by doing something like this:\r\n```python\r\nurl = instance.get('url')\r\nca_cert= instance.get('tls_ca_cert')\r\n\r\no = urlparse(url)\r\nhost = o.hostname\r\nserver_name = instance.get('ssl_server_name', o.hostname)\r\nport = o.port or 443\r\n\r\ntry:\r\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\r\n    sock.settimeout(float(timeout))\r\n    sock.connect((host, port))\r\n    context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)\r\n    context.verify_mode = ssl.CERT_REQUIRED\r\n    context.check_hostname = check_hostname\r\n    context.load_verify_locations(ca_cert)\r\n```\r\n\r\nHere the output\r\n```\r\n2019-10-17 17:08:48 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check http_check\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/check.go:69 in runCheck) | Running python check http_check http_check:Consul:928f17239ebab106\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:111) | Connecting to https://consul-server-1.eu-west-1.dev.<REDACTED>:8501\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:815) | Starting new HTTPS connection (1): consul-server-1.eu-west-1.dev.<REDACTED>:8501\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:396) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 \"GET / HTTP/1.1\" 301 39\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | - | (connectionpool.py:396) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 \"GET /ui/ HTTP/1.1\" 200 5729\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:92) | https://consul-server-1.eu-west-1.dev.<REDACTED>:8501 is UP\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:292) | ca file /opt/datadog-agent/embedded/ssl/certs/cacert.pem\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:307) | cert {'subjectAltName': (('DNS', 'consul.service.consul'), ('DNS', 'consul.eu-west-1.dev.<REDACTED>'), ('DNS', 'consul-server-1.eu-west-1.dev.<REDACTED>'), ('DNS', 'consul-server-2.eu-west-1.dev.<REDACTED>'), ('DNS', 'consul-server-3.eu-west-1.dev.<REDACTED>'), ('IP Address', '127.0.0.1'), ('IP Address', '172.17.0.1')), 'notBefore': u'Feb 16 19:43:15 2019 GMT', 'serialNumber': u'***************************CB8F5', 'notAfter': 'Feb 16 19:43:15 2020 GMT', 'version': 3L, 'subject': ((('organizationName', u'<REDACTED>'),), (('commonName', u'<REDACTED> cert'),)), 'issuer': ((('organizationName', u'<REDACTED>'),), (('commonName', u'<REDACTED> cert'),))}\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:326) | Exp_date: 2020-02-16 19:43:15\r\n2019-10-17 17:08:48 UTC | CORE | DEBUG | (pkg/collector/python/datadog_agent.go:120 in LogMessage) | http_check:Consul:928f17239ebab106 | (http_check.py:327) | seconds_left: 10550066.7529\r\n2019-10-17 17:08:48 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check http_check\r\n```\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4815", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4815/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4815/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4815/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4815", "id": 508663880, "node_id": "MDU6SXNzdWU1MDg2NjM4ODA=", "number": 4815, "title": "Agent Vault status check is not passing for standby instances", "user": {"login": "soeirosantos", "id": 454915, "node_id": "MDQ6VXNlcjQ1NDkxNQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/454915?v=4", "gravatar_id": "", "url": "https://api.github.com/users/soeirosantos", "html_url": "https://github.com/soeirosantos", "followers_url": "https://api.github.com/users/soeirosantos/followers", "following_url": "https://api.github.com/users/soeirosantos/following{/other_user}", "gists_url": "https://api.github.com/users/soeirosantos/gists{/gist_id}", "starred_url": "https://api.github.com/users/soeirosantos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/soeirosantos/subscriptions", "organizations_url": "https://api.github.com/users/soeirosantos/orgs", "repos_url": "https://api.github.com/users/soeirosantos/repos", "events_url": "https://api.github.com/users/soeirosantos/events{/privacy}", "received_events_url": "https://api.github.com/users/soeirosantos/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-10-17T16:33:26Z", "updated_at": "2019-11-05T16:01:41Z", "closed_at": "2019-11-05T16:01:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe what happened:**\r\n\r\nAfter enabling the Vault integration in my cluster as [described here](https://docs.datadoghq.com/integrations/vault/) I cannot get the Vault check passing in the standby instances. Here are the details:\r\n\r\nThis is what I get for `$ sudo datadog-agent status`\r\n```\r\nvault (1.5.0)\r\n    -------------\r\n      Instance ID: vault:10262e521e965031 [ERROR]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/vault.d/vault-conf.yaml\r\n      Total Runs: 264\r\n      Metric Samples: Last Run: 1, Total: 260\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 264\r\n      Average Execution Time : 84ms\r\n      Error:\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 556, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/vault/vault.py\", line 53, in check\r\n          api['check_health'](config, tags)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/vault/vault.py\", line 88, in check_health_v1\r\n          health_data = self.access_api(url, config, tags)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/vault/vault.py\", line 152, in access_api\r\n          raise ApiUnreachable\r\n      ApiUnreachable\r\n```\r\n\r\nThe log shows this error `HTTPError: 429 Client Error: Too Many Requests for url: http://localhost:8200/v1/sys/health`\r\n\r\nWhen I try this endpoint directly I get the following result:\r\n\r\n```\r\n$ curl http://localhost:8200/v1/sys/health\r\n{\"initialized\":true,\"sealed\":false,\"standby\":true,\"performance_standby\":false,\"replication_performance_mode\":\"unknown\",\"replication_dr_mode\":\"unknown\",\"server_time_utc\":1571327129,\"version\":\"1.2.2\",\"cluster_name\":\"vault-cluster-xxx\",\"cluster_id\":\"3fe63e38-f0f5-11e9-a713-2a2ae2xxxxxx\"}\r\n```\r\n\r\n**Describe what you expected:**\r\n\r\nI'd expect to see the datadog-agent status check passing in the standby instances.\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n**DD Agent**: Agent 6.14.1 - Commit: fa227f0 - Serialization version: 4.12.0 - Go version: go1.12.9\r\n**Vault version**: Vault v1.2.2\r\n**OS**: CentOS Linux 7\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4770", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4770/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4770/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4770/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4770", "id": 507045269, "node_id": "MDU6SXNzdWU1MDcwNDUyNjk=", "number": 4770, "title": "[Aurora] Function pg_last_xlog_receive_location() is currently not supported for Aurora", "user": {"login": "chrisduong", "id": 1848882, "node_id": "MDQ6VXNlcjE4NDg4ODI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1848882?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chrisduong", "html_url": "https://github.com/chrisduong", "followers_url": "https://api.github.com/users/chrisduong/followers", "following_url": "https://api.github.com/users/chrisduong/following{/other_user}", "gists_url": "https://api.github.com/users/chrisduong/gists{/gist_id}", "starred_url": "https://api.github.com/users/chrisduong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chrisduong/subscriptions", "organizations_url": "https://api.github.com/users/chrisduong/orgs", "repos_url": "https://api.github.com/users/chrisduong/repos", "events_url": "https://api.github.com/users/chrisduong/events{/privacy}", "received_events_url": "https://api.github.com/users/chrisduong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-10-15T06:56:01Z", "updated_at": "2020-04-16T08:49:23Z", "closed_at": "2019-11-22T22:20:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\n2019-10-14 16:14:10 UTC | CORE | INFO | (pkg/collector/runner/runner.go:261 in work) | Running check postgres\r\n2019-10-14 16:14:10 UTC | CORE | ERROR | (pkg/collector/runner/runner.go:292 in work) | Error running check postgres: [{\"message\": \"Function pg_last_xlog_receive_location() is currently not supported for Aurora\\n\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\\\", line 556, in run\\n    self.check(instance)\\n  File \\\"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\\\", line 1127, in check\\n    collect_default_db,\\n  File \\\"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\\\", line 858, in _collect_stats\\n    self._query_scope(cursor, scope, key, db, instance_tags, scope in custom_metrics, relations_config)\\n  File \\\"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\\\", line 714, in _query_scope\\n    cursor.execute(query.replace(r'%', r'%%'))\\nFeatureNotSupported: Function pg_last_xlog_receive_location() is currently not supported for Aurora\\n\\n\"}]\r\n2019-10-14 16:14:10 UTC | CORE | INFO | (pkg/collector/runner/runner.go:327 in work) | Done running check postgres\r\n2019-10-14 16:14:12 UTC | CORE | INFO | (pkg/collector/runner/runner.go:\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n**Steps to reproduce the issue:**\r\n1. Install Data Agent version **v6.14.0**\r\n2. Configure the Postgres Integration with AWS Aurora Postgres **v10.7**.\r\n3. Agent complain with the above error.\r\n\r\n**Describe the results you received:**\r\n- Postgres Check failed\r\n\r\n**Describe the results you expected:**\r\n- Postgres Check succeeds.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4706", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4706/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4706/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4706/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4706", "id": 503869476, "node_id": "MDU6SXNzdWU1MDM4Njk0NzY=", "number": 4706, "title": "[vault] Fix sealed nodes management ", "user": {"login": "jpiron", "id": 1668102, "node_id": "MDQ6VXNlcjE2NjgxMDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/1668102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpiron", "html_url": "https://github.com/jpiron", "followers_url": "https://api.github.com/users/jpiron/followers", "following_url": "https://api.github.com/users/jpiron/following{/other_user}", "gists_url": "https://api.github.com/users/jpiron/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpiron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpiron/subscriptions", "organizations_url": "https://api.github.com/users/jpiron/orgs", "repos_url": "https://api.github.com/users/jpiron/repos", "events_url": "https://api.github.com/users/jpiron/events{/privacy}", "received_events_url": "https://api.github.com/users/jpiron/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-10-08T07:12:04Z", "updated_at": "2019-10-18T13:04:04Z", "closed_at": "2019-10-18T13:04:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Vault `/sys/health` API endpoint returns a HTTP 503 code for sealed nodes.\r\n\r\nThe `access_api` method of the Vault check will handle this as an HTTPError and set the `SERVICE_CHECK_CONNECT` to `critical` while the API is perfectly reachable. It will also prevent other checks (`SERVICE_CHECK_UNSEALED` and `SERVICE_CHECK_INITIALIZED`) from being set to proper values resulting in wrong values for these 3 checks.\r\n\r\nThe check shouldn't handle [Vault specific HTTP codes](https://www.vaultproject.io/api/system/health.html#read-health-information) as errors.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4696", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4696/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4696/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4696/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4696", "id": 503423943, "node_id": "MDU6SXNzdWU1MDM0MjM5NDM=", "number": 4696, "title": "[vault] support HA mode", "user": {"login": "jpiron", "id": 1668102, "node_id": "MDQ6VXNlcjE2NjgxMDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/1668102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpiron", "html_url": "https://github.com/jpiron", "followers_url": "https://api.github.com/users/jpiron/followers", "following_url": "https://api.github.com/users/jpiron/following{/other_user}", "gists_url": "https://api.github.com/users/jpiron/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpiron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpiron/subscriptions", "organizations_url": "https://api.github.com/users/jpiron/orgs", "repos_url": "https://api.github.com/users/jpiron/repos", "events_url": "https://api.github.com/users/jpiron/events{/privacy}", "received_events_url": "https://api.github.com/users/jpiron/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 968479995, "node_id": "MDU6TGFiZWw5Njg0Nzk5OTU=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/vault", "name": "integration/vault", "color": "bfdadc", "default": false, "description": ""}, {"id": 293952856, "node_id": "MDU6TGFiZWwyOTM5NTI4NTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/bug", "name": "kind/bug", "color": "b60205", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "FlorianVeaux", "id": 22912273, "node_id": "MDQ6VXNlcjIyOTEyMjcz", "avatar_url": "https://avatars3.githubusercontent.com/u/22912273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FlorianVeaux", "html_url": "https://github.com/FlorianVeaux", "followers_url": "https://api.github.com/users/FlorianVeaux/followers", "following_url": "https://api.github.com/users/FlorianVeaux/following{/other_user}", "gists_url": "https://api.github.com/users/FlorianVeaux/gists{/gist_id}", "starred_url": "https://api.github.com/users/FlorianVeaux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FlorianVeaux/subscriptions", "organizations_url": "https://api.github.com/users/FlorianVeaux/orgs", "repos_url": "https://api.github.com/users/FlorianVeaux/repos", "events_url": "https://api.github.com/users/FlorianVeaux/events{/privacy}", "received_events_url": "https://api.github.com/users/FlorianVeaux/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "FlorianVeaux", "id": 22912273, "node_id": "MDQ6VXNlcjIyOTEyMjcz", "avatar_url": "https://avatars3.githubusercontent.com/u/22912273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FlorianVeaux", "html_url": "https://github.com/FlorianVeaux", "followers_url": "https://api.github.com/users/FlorianVeaux/followers", "following_url": "https://api.github.com/users/FlorianVeaux/following{/other_user}", "gists_url": "https://api.github.com/users/FlorianVeaux/gists{/gist_id}", "starred_url": "https://api.github.com/users/FlorianVeaux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FlorianVeaux/subscriptions", "organizations_url": "https://api.github.com/users/FlorianVeaux/orgs", "repos_url": "https://api.github.com/users/FlorianVeaux/repos", "events_url": "https://api.github.com/users/FlorianVeaux/events{/privacy}", "received_events_url": "https://api.github.com/users/FlorianVeaux/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-10-07T12:35:25Z", "updated_at": "2019-10-07T16:15:25Z", "closed_at": "2019-10-07T14:55:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Currently the Vault check doesn't work on standby nodes when Vault is configured in HA mode.\r\n\r\nStandby nodes `/sys/health` API endpoint returns a 429 HTTP code that is interpreted as the default HTTP `Too Many Requests` error by the agent, while the node is perfectly fine.\r\n\r\nHere is the output of the agent for the Vault check : \r\n```\r\n=========\r\nCollector\r\n=========\r\n\r\n\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    vault (1.5.0)\r\n    -------------\r\n      Instance ID: vault:96e271cf24556fcf [ERROR]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/vault.d/conf.yaml\r\n      Total Runs: 1\r\n      Metric Samples: Last Run: 1, Total: 1\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 1\r\n      Average Execution Time : 93ms\r\n      Error: \r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 556, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/vault/vault.py\", line 53, in check\r\n          api['check_health'](config, tags)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/vault/vault.py\", line 88, in check_health_v1\r\n          health_data = self.access_api(url, config, tags)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/vault/vault.py\", line 152, in access_api\r\n          raise ApiUnreachable\r\n      ApiUnreachable\r\n```\r\n\r\n[Here](https://www.vaultproject.io/api/system/health.html#read-health-information) are the HTTP codes the Vault API returns.\r\n\r\nThe Vault integration should handle these codes.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4688", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4688/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4688/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4688/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4688", "id": 503050160, "node_id": "MDU6SXNzdWU1MDMwNTAxNjA=", "number": 4688, "title": "Lighttpd check now requires authentication", "user": {"login": "bangpound", "id": 6731, "node_id": "MDQ6VXNlcjY3MzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/6731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bangpound", "html_url": "https://github.com/bangpound", "followers_url": "https://api.github.com/users/bangpound/followers", "following_url": "https://api.github.com/users/bangpound/following{/other_user}", "gists_url": "https://api.github.com/users/bangpound/gists{/gist_id}", "starred_url": "https://api.github.com/users/bangpound/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bangpound/subscriptions", "organizations_url": "https://api.github.com/users/bangpound/orgs", "repos_url": "https://api.github.com/users/bangpound/repos", "events_url": "https://api.github.com/users/bangpound/events{/privacy}", "received_events_url": "https://api.github.com/users/bangpound/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-06T04:22:16Z", "updated_at": "2019-10-07T15:27:53Z", "closed_at": "2019-10-07T15:27:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\n    lighttpd (1.5.0)\r\n    ----------------\r\n      Instance ID: lighttpd:ddc4a4b758a5b4ec [ERROR]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/lighttpd.yaml\r\n      Total Runs: 5,181\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      Error: Unsupported value of 'auth_type' variable in Lighttpd config: basic\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 556, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/lighttpd/lighttpd.py\", line 84, in check\r\n          raise Exception(msg)\r\n      Exception: Unsupported value of 'auth_type' variable in Lighttpd config: basic\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\nMy configuration is being set up through chef:\r\n\r\n```\r\ndefault['datadog']['lighttpd']['instances'] = [{ :status_url => 'http://localhost/server-status?auto' }]\r\n```\r\n\r\nThis produces the configuration:\r\n\r\n```\r\n---\r\nlogs: []\r\n\r\n\r\ninstances:\r\n  - lighttpd_status_url: http://localhost/server-status?auto\r\n\r\ninit_config:\r\n# No init_config section needed\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n1. Upgrade from datadog lighttpd check version 1.3.0 to version 1.5.0 with the same basic configuration. \r\n\r\n**Describe the results you received:**\r\n\r\n* Fatal exception saying that an auth_type I'm not even specifying nor do I want to use is not allowed.\r\n* Metrics are not reported.\r\n\r\n**Describe the results you expected:**\r\n\r\n* Metrics should be reported.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\n* Happens all the time after upgrading Datadog to a version where the lighttpd plugin is version 1.5.0", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4684", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4684/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4684/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4684/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4684", "id": 502738831, "node_id": "MDU6SXNzdWU1MDI3Mzg4MzE=", "number": 4684, "title": "Not all of Linkerd metrics are gathered", "user": {"login": "spender0", "id": 13725789, "node_id": "MDQ6VXNlcjEzNzI1Nzg5", "avatar_url": "https://avatars3.githubusercontent.com/u/13725789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/spender0", "html_url": "https://github.com/spender0", "followers_url": "https://api.github.com/users/spender0/followers", "following_url": "https://api.github.com/users/spender0/following{/other_user}", "gists_url": "https://api.github.com/users/spender0/gists{/gist_id}", "starred_url": "https://api.github.com/users/spender0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/spender0/subscriptions", "organizations_url": "https://api.github.com/users/spender0/orgs", "repos_url": "https://api.github.com/users/spender0/repos", "events_url": "https://api.github.com/users/spender0/events{/privacy}", "received_events_url": "https://api.github.com/users/spender0/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-10-04T16:44:23Z", "updated_at": "2020-07-30T00:21:46Z", "closed_at": "2019-10-10T15:48:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nIf you suspect your issue is a bug, please attach the output of the Agent status page,\r\nsee https://docs.datadoghq.com/agent/faq/agent-commands/#agent-information\r\n-->\r\n\r\n**Output of the info page (if this is a bug)**\r\n```\r\n===============\r\nAgent (v6.14.1)\r\n===============\r\n\r\n  Status date: 2019-10-04 16:32:29.759489 UTC\r\n  Agent start: 2019-10-04 16:17:06.455264 UTC\r\n  Pid: 337\r\n  Go Version: go1.12.9\r\n  Python Version: 2.7.16\r\n  Check Runners: 16\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 3.471ms\r\n    System UTC time: 2019-10-04 16:32:29.759489 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-05-22 08:29:25.000000 UTC\r\n    kernelVersion: 4.9.0-6-amd64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: 10.1\r\n    procs: 65\r\n    uptime: 3247h47m53s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ip-10-1-27-31.us-west-2.compute.internal\r\n    host_aliases: [ip-10-1-27-31.us-west-2.compute.internal]\r\n    hostname: i-05ae2f2162f48c1aa\r\n    instance-id: i-05ae2f2162f48c1aa\r\n    socket-fqdn: datadog-agent-fz6rk\r\n    socket-hostname: datadog-agent-fz6rk\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 6, Total: 360\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    disk (2.5.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/disk.d/conf.yaml.default\r\n      Total Runs: 60\r\n      Metric Samples: Last Run: 200, Total: 12,000\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 206ms\r\n      \r\n    \r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/docker.d/conf.yaml.default\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 700, Total: 42,648\r\n      Events: Last Run: 0, Total: 1\r\n      Service Checks: Last Run: 1, Total: 61\r\n      Average Execution Time : 232ms\r\n      \r\n    \r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default\r\n      Total Runs: 60\r\n      Metric Samples: Last Run: 5, Total: 300\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n          \r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/io.d/conf.yaml.default\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 52, Total: 3,136\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 8ms\r\n    \r\n    kubelet (3.3.2)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default\r\n      Total Runs: 60\r\n      Metric Samples: Last Run: 884, Total: 53,337\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 3, Total: 180\r\n      Average Execution Time : 1.81s\r\n      \r\n    \r\n    linkerd (2.3.0)\r\n    ---------------\r\n      Instance ID: linkerd:2c0c3215a89c0c75 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/linkerd.d/auto_conf.yaml\r\n      Total Runs: 60\r\n      Metric Samples: Last Run: 74, Total: 4,520\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 60\r\n      Average Execution Time : 140ms\r\n      \r\n    \r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/load.d/conf.yaml.default\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 6, Total: 366\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 2ms\r\n      \r\n    \r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/memory.d/conf.yaml.default\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 17, Total: 1,037\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    network (1.11.4)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/network.d/conf.yaml.default\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 181, Total: 11,041\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 76ms\r\n      \r\n    \r\n    ntp\r\n    ---\r\n      Instance ID: ntp:d884b5186b651429 [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 1, Total: 61\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 61\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Configuration Source: file:/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 1, Total: 61\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n    \r\n  Failed checks\r\n  =============\r\n    no checks\r\n    \r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 61\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 6\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 128\r\n    TimeseriesV1: 61\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 72519: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 72519\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 477,882\r\n  Dogstatsd Metric Sample: 12,478\r\n  Event: 2\r\n  Events Flushed: 2\r\n  Number Of Flushes: 61\r\n  Series Flushed: 463,359\r\n  Service Check: 3,096\r\n  Service Checks Flushed: 3,142\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 12,477\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 1 M\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 12,478\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n=====================\r\nDatadog Cluster Agent\r\n=====================\r\n\r\n  - Datadog Cluster Agent endpoint detected: https://100.69.32.14:5005\r\n  Successfully connected to the Datadog Cluster Agent.\r\n  - Running: 1.3.2&#43;commit.e3f5101\r\n\r\n```\r\n\r\n**Describe what happened:**\r\nConfigured Linkerd:\r\n/etc/datadog-agent/conf.d/linkerd.d/auto_conf.yaml \r\n```\r\nad_identifiers:\r\n  - linkerd\r\ninit_config:\r\ninstances:\r\n  - prometheus_url: http://%%host%%:9990/admin/metrics/prometheus \r\n```\r\nBut whent I check the collected metrics at Datadog UI some of them are absent.\r\ne.g. linkerd.rt.client.status.1XX_s, linkerd.rt.client.status.2XX_s, linkerd.rt.client.status.3XX_s ,linkerd.rt.client.status.4XX_s, linkerd.rt.client.status.5XX_s\r\nIf I check linkerd 9990 port endpoints directly, e.g. http://127.0.0.1:9990/admin/metrics/prometheus I see the metrics. \r\n\r\n**Describe what you expected:**\r\nAll Linkerd metrics collected (https://github.com/DataDog/integrations-core/blob/master/linkerd/metadata.csv)\r\n\r\n**Steps to reproduce the issue:**\r\n\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nk8s v1.11.9 on to of AWS\r\nLinkerd 1.6.4\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4663", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4663/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4663/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4663/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4663", "id": 501312618, "node_id": "MDU6SXNzdWU1MDEzMTI2MTg=", "number": 4663, "title": "Stop write warning in redisb if no keys configuration", "user": {"login": "xkrt", "id": 428187, "node_id": "MDQ6VXNlcjQyODE4Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/428187?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xkrt", "html_url": "https://github.com/xkrt", "followers_url": "https://api.github.com/users/xkrt/followers", "following_url": "https://api.github.com/users/xkrt/following{/other_user}", "gists_url": "https://api.github.com/users/xkrt/gists{/gist_id}", "starred_url": "https://api.github.com/users/xkrt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xkrt/subscriptions", "organizations_url": "https://api.github.com/users/xkrt/orgs", "repos_url": "https://api.github.com/users/xkrt/repos", "events_url": "https://api.github.com/users/xkrt/events{/privacy}", "received_events_url": "https://api.github.com/users/xkrt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-10-02T06:57:33Z", "updated_at": "2019-12-18T05:58:27Z", "closed_at": "2019-12-18T05:58:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi!\r\n\r\nredisdb integration supports [`keys` configuration setting](https://github.com/DataDog/integrations-core/blob/master/redisdb/datadog_checks/redisdb/data/conf.yaml.example#L77) to collect length of Redis keys.\r\n\r\nBut if I am not interested in this functionality \u2013 my check becomes `WARNING` state because of this https://github.com/DataDog/integrations-core/blob/master/redisdb/datadog_checks/redisdb/redisdb.py#L248.\r\n\r\nMy redisdb check shouldn't become WARNING if don't use `keys`.\r\n\r\nSee https://github.com/DataDog/integrations-core/commit/bb4e550980d803228b5468455260ad9bf0cbfb28, previously there was [guard `if`](https://github.com/DataDog/integrations-core/commit/bb4e550980d803228b5468455260ad9bf0cbfb28#diff-007657375bf223afe6f7c10e926f892bL235)\r\n\r\n/notify @masci @ofek ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4636", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4636/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4636/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4636/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4636", "id": 498877695, "node_id": "MDU6SXNzdWU0OTg4Nzc2OTU=", "number": 4636, "title": "Agent Redisdb warning after upgrade", "user": {"login": "KoenDG", "id": 1440619, "node_id": "MDQ6VXNlcjE0NDA2MTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1440619?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KoenDG", "html_url": "https://github.com/KoenDG", "followers_url": "https://api.github.com/users/KoenDG/followers", "following_url": "https://api.github.com/users/KoenDG/following{/other_user}", "gists_url": "https://api.github.com/users/KoenDG/gists{/gist_id}", "starred_url": "https://api.github.com/users/KoenDG/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KoenDG/subscriptions", "organizations_url": "https://api.github.com/users/KoenDG/orgs", "repos_url": "https://api.github.com/users/KoenDG/repos", "events_url": "https://api.github.com/users/KoenDG/events{/privacy}", "received_events_url": "https://api.github.com/users/KoenDG/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-09-26T13:15:31Z", "updated_at": "2019-10-24T01:08:16Z", "closed_at": "2019-09-27T20:21:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\nsudo service datadog-agent status\r\n\u25cf datadog-agent.service - Datadog Agent\r\n   Loaded: loaded (/lib/systemd/system/datadog-agent.service; enabled; vendor preset: enabled)\r\n   Active: active (running) since Thu 2019-09-26 14:51:09 CEST; 4min 57s ago\r\n Main PID: 13905 (agent)\r\n    Tasks: 17 (limit: 4915)\r\n   CGroup: /system.slice/datadog-agent.service\r\n           \u2514\u250013905 /opt/datadog-agent/bin/agent/agent run -p /opt/datadog-agent/run/agent.pid\r\n\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nUbuntu 18.04\r\nDatadog agent version 6.14.0-1\r\n\r\n**Steps to reproduce the issue:**\r\n1. Have redis set up for monitoring, restart the agent.\r\n\r\n\r\n**Describe the results you received:**\r\nThe check for redisdb keeps generating the following message:\r\n```\r\n CORE | WARN | (pkg/collector/python/datadog_agent.go:116 in LogMessage) | redisdb:b6c2c4a1887a36e9 | (redisdb.py:244) | keys in redis configuration is either not a list or empty\r\n```\r\n\r\n**Describe the results you expected:**\r\nNo such warning.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nMy configuration is a literal copy from this page: https://github.com/DataDog/integrations-core/tree/master/redisdb#metric-collection\r\n\r\nI've tried it with `instances: null` too, no effect is seen at all.\r\n\r\nRelevant code here:\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/master/redisdb/datadog_checks/redisdb/redisdb.py#L240-L248\r\n\r\nIf I change the code to print the `instance` object inside this method, I get:\r\n\r\n```\r\n{'host': 'localhost', 'port': 6379}\r\n```\r\n\r\nIt lacks a \"keys\" key, which will cause the if check on line 243 to fail.\r\n\r\nHowever, right after that, we see this:\r\n```\r\nwarn_on_missing_keys = is_affirmative(instance.get(\"warn_on_missing_keys\", True))\r\n```\r\nSomething tells me this flag needs to be taken into consideration earlier. I tried adding it to the configuration but the warning persists. So there is no earlier point that checks for it.\r\n\r\nThe expanded example conf, found here: https://github.com/DataDog/integrations-core/blob/master/redisdb/datadog_checks/redisdb/data/conf.yaml.example\r\n\r\nSpeaks of this flag `warn_on_missing_keys`, and it looks like that should happen before this check on line 243, not after.\r\n\r\nAlso, this seems to be set to \"default: true\", yet it isn't mentioned here: https://github.com/DataDog/integrations-core/tree/master/redisdb#metric-collection\r\n\r\nIf it's mandatory, since it has to be explicitly disabled or you get a warning, I would expect it to be shown in the example.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4617", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4617/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4617/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4617/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4617", "id": 497656305, "node_id": "MDU6SXNzdWU0OTc2NTYzMDU=", "number": 4617, "title": "[redis] Add support for redis URL instead of host", "user": {"login": "barelnir", "id": 5445098, "node_id": "MDQ6VXNlcjU0NDUwOTg=", "avatar_url": "https://avatars2.githubusercontent.com/u/5445098?v=4", "gravatar_id": "", "url": "https://api.github.com/users/barelnir", "html_url": "https://github.com/barelnir", "followers_url": "https://api.github.com/users/barelnir/followers", "following_url": "https://api.github.com/users/barelnir/following{/other_user}", "gists_url": "https://api.github.com/users/barelnir/gists{/gist_id}", "starred_url": "https://api.github.com/users/barelnir/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/barelnir/subscriptions", "organizations_url": "https://api.github.com/users/barelnir/orgs", "repos_url": "https://api.github.com/users/barelnir/repos", "events_url": "https://api.github.com/users/barelnir/events{/privacy}", "received_events_url": "https://api.github.com/users/barelnir/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-24T12:27:59Z", "updated_at": "2019-09-27T20:23:17Z", "closed_at": "2019-09-27T20:23:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\nHi DD team,\r\n\r\nIt will be awesome if you can support also redis url and not just host in the redis configuration file as shown on this sample:\r\nhttps://github.com/DataDog/integrations-core/blob/master/redisdb/datadog_checks/redisdb/data/conf.yaml.example\r\n\r\nA redis URL looks like that:\r\nredis://<FQDN/HOST>\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4616", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4616/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4616/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4616/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4616", "id": 497597026, "node_id": "MDU6SXNzdWU0OTc1OTcwMjY=", "number": 4616, "title": "nginx-ingress-controller - /nginx_status endpoint is no longer exposed by default", "user": {"login": "marekaf", "id": 16442967, "node_id": "MDQ6VXNlcjE2NDQyOTY3", "avatar_url": "https://avatars1.githubusercontent.com/u/16442967?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marekaf", "html_url": "https://github.com/marekaf", "followers_url": "https://api.github.com/users/marekaf/followers", "following_url": "https://api.github.com/users/marekaf/following{/other_user}", "gists_url": "https://api.github.com/users/marekaf/gists{/gist_id}", "starred_url": "https://api.github.com/users/marekaf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marekaf/subscriptions", "organizations_url": "https://api.github.com/users/marekaf/orgs", "repos_url": "https://api.github.com/users/marekaf/repos", "events_url": "https://api.github.com/users/marekaf/events{/privacy}", "received_events_url": "https://api.github.com/users/marekaf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-24T10:22:21Z", "updated_at": "2019-10-02T21:19:19Z", "closed_at": "2019-10-02T21:19:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello\r\n\r\nI'm using these annotations in my nginx-ingress-controller helm values as the docs https://github.com/DataDog/integrations-core/blob/master/nginx_ingress_controller/README.md suggests\r\n\r\n```\r\n  podAnnotations:\r\n    ad.datadoghq.com/nginx-ingress-controller.check_names: '[\"nginx\",\"nginx_ingress_controller\"]'\r\n    ad.datadoghq.com/nginx-ingress-controller.init_configs: '[{},{}]'\r\n    ad.datadoghq.com/nginx-ingress-controller.instances: '[{\"nginx_status_url\": \"http://%%host%%:%%port%%/nginx_status\"},{\"prometheus_url\": \"http://%%host%%:10254/metrics\"}]'\r\n    ad.datadoghq.com/nginx-ingress-controller.logs: '[{\"service\": \"controller\", \"source\":\"nginx-ingress-controller\"}]'\r\n```\r\n\r\nthe `nginx_status_url` does not seem to be exposed anymore, I'm getting these errors:\r\n\r\n```text\r\n2019-09-24 09:59:43 UTC | CORE | ERROR | (pkg/collector/runner/runner.go:294 in work) \r\n| Error running check nginx: [{\"message\": \"404 Client Error: Not Found for url: \r\nhttp://172.16.14.194:10254/nginx_status\", \"traceback\": \"Traceback (most recent call last)\r\n:\\n  File \\\"/opt/datadog-agent/embedded/lib/python2.7/site-\r\npackages/datadog_checks/base/checks/base.py\\\", line 503, in run\\n    self.check(instance)\\n  File \r\n\\\"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/nginx/nginx.py\\\", \r\nline 84, in check\\n    response, content_type = self._get_data(instance, url, ssl_validation, auth)\\n  \r\nFile \\\"/opt/datadog-agent/embedded/lib/python2.7/site-\r\npackages/datadog_checks/nginx/nginx.py\\\", line 155, in _get_data\\n    r = \r\nself._perform_service_check(instance, url, ssl_validation, auth)\\n  File \\\"/opt/datadog-\r\nagent/embedded/lib/python2.7/site-packages/datadog_checks/nginx/nginx.py\\\", line 186, in \r\n_perform_service_check\\n    r = self._perform_request(instance, url, ssl_validation, auth)\\n  File \r\n\\\"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/nginx/nginx.py\\\",\r\n line 170, in _perform_request\\n    r.raise_for_status()\\n  File \\\"/opt/datadog-\r\nagent/embedded/lib/python2.7/site-packages/requests/models.py\\\", line 940, in raise_for_status\\n  \r\n  raise HTTPError(http_error_msg, response=self)\\nHTTPError: 404 Client Error: Not Found for url: \r\nhttp://172.16.14.194:10254/nginx_status\\n\"}]\r\n\r\n```\r\n\r\npossible due to this breaking change https://github.com/kubernetes/ingress-nginx/blob/master/Changelog.md#0230\r\n\r\nI'm using the latest datadog agent helm chart\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4588", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4588/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4588/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4588/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4588", "id": 496017094, "node_id": "MDU6SXNzdWU0OTYwMTcwOTQ=", "number": 4588, "title": "Node status capacity metrics collected from kube-state-metrics are deprecated", "user": {"login": "enummela", "id": 5798441, "node_id": "MDQ6VXNlcjU3OTg0NDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/5798441?v=4", "gravatar_id": "", "url": "https://api.github.com/users/enummela", "html_url": "https://github.com/enummela", "followers_url": "https://api.github.com/users/enummela/followers", "following_url": "https://api.github.com/users/enummela/following{/other_user}", "gists_url": "https://api.github.com/users/enummela/gists{/gist_id}", "starred_url": "https://api.github.com/users/enummela/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/enummela/subscriptions", "organizations_url": "https://api.github.com/users/enummela/orgs", "repos_url": "https://api.github.com/users/enummela/repos", "events_url": "https://api.github.com/users/enummela/events{/privacy}", "received_events_url": "https://api.github.com/users/enummela/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-19T20:43:49Z", "updated_at": "2019-09-23T21:51:24Z", "closed_at": "2019-09-23T21:51:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "The metrics collected by the kubernetes_state integration have been [marked as deprecated](https://github.com/kubernetes/kube-state-metrics/blob/v1.7.2/docs/node-metrics.md) in the kube-state-metrics project. These metrics include:\r\n* `kube_node_status_capacity_cpu_cores`\r\n* `kube_node_status_capacity_memory_bytes`\r\n* `kube_node_status_capacity_pods`\r\n\r\nTo replace these deprecated metrics, a new metric named `kube_node_status_capacity` [was created](https://github.com/kubernetes/kube-state-metrics/pull/466/files).\r\n\r\nIn light of these metrics being marked as deprecated, can the integration be updated to also collect the new stable metric `kube_node_status_capacity`?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4552", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4552/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4552/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4552/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4552", "id": 493735612, "node_id": "MDU6SXNzdWU0OTM3MzU2MTI=", "number": 4552, "title": "Container Live monitoring - CPU Usage not honoring Limits value set in POD Spec", "user": {"login": "martin2176", "id": 14482998, "node_id": "MDQ6VXNlcjE0NDgyOTk4", "avatar_url": "https://avatars0.githubusercontent.com/u/14482998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martin2176", "html_url": "https://github.com/martin2176", "followers_url": "https://api.github.com/users/martin2176/followers", "following_url": "https://api.github.com/users/martin2176/following{/other_user}", "gists_url": "https://api.github.com/users/martin2176/gists{/gist_id}", "starred_url": "https://api.github.com/users/martin2176/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martin2176/subscriptions", "organizations_url": "https://api.github.com/users/martin2176/orgs", "repos_url": "https://api.github.com/users/martin2176/repos", "events_url": "https://api.github.com/users/martin2176/events{/privacy}", "received_events_url": "https://api.github.com/users/martin2176/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-15T13:08:43Z", "updated_at": "2019-09-24T11:52:06Z", "closed_at": "2019-09-23T19:49:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "In live monitoring, CPU limit is not honored. It always display the host number of CPU and ignore the value set in pod spec. \r\nEg below: I have set cpu limit to 300 mc. \r\nLive monitoring shows 4 CPU . 4 CPU is the host number of CPUs. Basically not honoring the CPU: limits set in POD spec.\r\non the other hand, Memory limit is honored. Live monitoring correctly displays 200m.\r\n\r\n(Datadog agent is latest run via daemon set. latest agent image)\r\n\r\nkubectl -n test1 describe pod busybox1\r\n...\r\n    Limits:\r\n      cpu:     300m\r\n      memory:  200Mi\r\n    Requests:\r\n      cpu:     200m\r\n      memory:  100Mi\r\n\r\nI have tried with both check and unchecking \"normalize cpu\" in the settings. No difference\r\n\r\n![image](https://user-images.githubusercontent.com/14482998/64922041-4094b880-d798-11e9-977b-1c524d69777f.png)\r\n\r\nOn the other hand, as you would see Mem Limit is correctly displayed.\r\n![image](https://user-images.githubusercontent.com/14482998/64922053-691cb280-d798-11e9-9e2b-3ad005e4a912.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4516", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4516/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4516/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4516/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4516", "id": 490055505, "node_id": "MDU6SXNzdWU0OTAwNTU1MDU=", "number": 4516, "title": "use_agent_proxy in openstack.d/conf.yaml seems to default to true when documented as false", "user": {"login": "jgibbons-cp", "id": 20524972, "node_id": "MDQ6VXNlcjIwNTI0OTcy", "avatar_url": "https://avatars0.githubusercontent.com/u/20524972?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgibbons-cp", "html_url": "https://github.com/jgibbons-cp", "followers_url": "https://api.github.com/users/jgibbons-cp/followers", "following_url": "https://api.github.com/users/jgibbons-cp/following{/other_user}", "gists_url": "https://api.github.com/users/jgibbons-cp/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgibbons-cp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgibbons-cp/subscriptions", "organizations_url": "https://api.github.com/users/jgibbons-cp/orgs", "repos_url": "https://api.github.com/users/jgibbons-cp/repos", "events_url": "https://api.github.com/users/jgibbons-cp/events{/privacy}", "received_events_url": "https://api.github.com/users/jgibbons-cp/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-05T23:16:05Z", "updated_at": "2019-10-03T18:25:41Z", "closed_at": "2019-10-03T18:25:41Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\nflare in ticket - https://datadog.zendesk.com/agent/tickets/251988\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\nLinux\r\n\r\n**Steps to reproduce the issue:**\r\n1. Set proxy for metrics in datadog.yaml\r\n2. Set keystone server in no_proxy\r\n3. leave use_agent_proxy as default in openstack/conf.yaml\r\n\r\n**Describe the results you received:**\r\n\r\nOpenStack integration tried to use the proxy\r\n\r\n**Describe the results you expected:**\r\n\r\nIt would not use the proxy\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nsetting the use_agent_proxy: false in conf.yaml caused integration to not try the proxy", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4515", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4515/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4515/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4515/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4515", "id": 490042512, "node_id": "MDU6SXNzdWU0OTAwNDI1MTI=", "number": 4515, "title": "Misleading gearman.workers metric", "user": {"login": "orgito", "id": 4852822, "node_id": "MDQ6VXNlcjQ4NTI4MjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4852822?v=4", "gravatar_id": "", "url": "https://api.github.com/users/orgito", "html_url": "https://github.com/orgito", "followers_url": "https://api.github.com/users/orgito/followers", "following_url": "https://api.github.com/users/orgito/following{/other_user}", "gists_url": "https://api.github.com/users/orgito/gists{/gist_id}", "starred_url": "https://api.github.com/users/orgito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/orgito/subscriptions", "organizations_url": "https://api.github.com/users/orgito/orgs", "repos_url": "https://api.github.com/users/orgito/repos", "events_url": "https://api.github.com/users/orgito/events{/privacy}", "received_events_url": "https://api.github.com/users/orgito/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-09-05T22:40:44Z", "updated_at": "2019-09-11T20:24:11Z", "closed_at": "2019-09-11T20:24:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The gearmand check is using `get_status()` to get the number of workers. The code is getting the number of workers for each task and adding all together to get the number of workers. The problem is that a single worker can be registered for multiple tasks. Unless you have all your workers dedicated to a single task the result will be much higher than reality.\r\n\r\nTo get the correct number of workers it should use the `get_workers()` function, possibly discarding any entry with no tasks.\r\n\r\nRough solution:\r\n```python\r\nworkers_list = client.get_workers()\r\nworkers = len([w for w in workers_list if w['tasks']]) \r\nself.gauge(\"gearman.workers\", workers, tags=tags)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4500", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4500/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4500/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4500/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4500", "id": 488469623, "node_id": "MDU6SXNzdWU0ODg0Njk2MjM=", "number": 4500, "title": "postgresql integration breaks on a Postgres hot standby after a conflict with recovery", "user": {"login": "Zhann", "id": 719108, "node_id": "MDQ6VXNlcjcxOTEwOA==", "avatar_url": "https://avatars3.githubusercontent.com/u/719108?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zhann", "html_url": "https://github.com/Zhann", "followers_url": "https://api.github.com/users/Zhann/followers", "following_url": "https://api.github.com/users/Zhann/following{/other_user}", "gists_url": "https://api.github.com/users/Zhann/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zhann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zhann/subscriptions", "organizations_url": "https://api.github.com/users/Zhann/orgs", "repos_url": "https://api.github.com/users/Zhann/repos", "events_url": "https://api.github.com/users/Zhann/events{/privacy}", "received_events_url": "https://api.github.com/users/Zhann/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-03T08:42:02Z", "updated_at": "2019-10-03T09:22:02Z", "closed_at": "2019-09-03T17:20:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v6.13.0)\r\n===============\r\n\r\n  Status date: 2019-09-03 08:26:45.296587 UTC\r\n  Agent start: 2019-08-29 05:53:49.027978 UTC\r\n  Pid: 9073\r\n  Go Version: go1.11.5\r\n  Python Version: 2.7.16\r\n  Check Runners: 4\r\n\r\n  Log File: /var/log/datadog/agent.log\r\n  Log Level: INFO\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 928\u00b5s\r\n    System UTC time: 2019-09-03 08:26:45.296587 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-02-24 20:11:07.000000 UTC\r\n    kernelVersion: 4.15.0-1027-gcp\r\n    os: linux\r\n    platform: ubuntu\r\n    platformFamily: debian\r\n    platformVersion: 16.04\r\n    procs: 232\r\n    uptime: 4449h42m43s\r\n\r\n  Hostnames\r\n  =========\r\n    secret \ud83d\ude05 \r\n=========\r\nCollector\r\n=========\r\n\r\n\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Total Runs: 29,411\r\n      Metric Samples: Last Run: 6, Total: 176,460\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    disk (2.4.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Total Runs: 29,412\r\n      Metric Samples: Last Run: 86, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 51ms\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Total Runs: 29,411\r\n      Metric Samples: Last Run: 5, Total: 147,055\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Total Runs: 29,412\r\n      Metric Samples: Last Run: 52, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Total Runs: 29,411\r\n      Metric Samples: Last Run: 6, Total: 176,466\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Total Runs: 29,412\r\n      Metric Samples: Last Run: 17, Total: 500,004\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    network (1.11.0)\r\n    ----------------\r\n      Instance ID: network:e0204ad63d43c949 [OK]\r\n      Total Runs: 29,411\r\n      Metric Samples: Last Run: 31, Total: 911,741\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 1ms\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:b4579e02d1981c12 [OK]\r\n      Total Runs: 29,412\r\n      Metric Samples: Last Run: 1, Total: 29,412\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 29,412\r\n      Average Execution Time : 1ms\r\n\r\n\r\n    postgres (3.0.0)\r\n    ----------------\r\n      Instance ID: postgres:d2658382b0380882 [ERROR]\r\n      Total Runs: 29,412\r\n      Metric Samples: Last Run: 0, Total: 1 M\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 24,796\r\n      Average Execution Time : 1ms\r\n      Error: current transaction is aborted, commands ignored until end of transaction block\r\n\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 503, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\", line 1099, in check\r\n          collect_default_db,\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\", line 835, in _collect_stats\r\n          cursor, db_instance_metrics, key, db, instance_tags, False, relations_config\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\", line 707, in _query_scope\r\n          cursor.execute(query.replace(r'%', r'%%'))\r\n      InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block\r\n\r\n    process (1.10.0)\r\n    ----------------\r\n      Instance ID: process:wal-g-basebackup:1d0573b35a443ab7 [WARNING]\r\n      Total Runs: 29,412\r\n      Metric Samples: Last Run: 1, Total: 29,412\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 29,412\r\n      Average Execution Time : 3ms\r\n\r\n      Warning: No matching process &#39;wal-g-basebackup&#39; was found\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Total Runs: 29,411\r\n      Metric Samples: Last Run: 1, Total: 29,411\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 29,411\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 2,237\r\n    Metadata: 0\r\n    Requeued: 2\r\n    Retried: 2\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 61,059\r\n    TimeseriesV1: 29,411\r\n\r\n  Transaction Errors\r\n  ==================\r\n    Total number: 1\r\n    Errors By Type:\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with ......: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - ........\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 7.6 M\r\n  Dogstatsd Metric Sample: 1.9 M\r\n  Event: 1\r\n  Events Flushed: 1\r\n  Number Of Flushes: 29,411\r\n  Series Flushed: 7 M\r\n  Service Check: 378,218\r\n  Service Checks Flushed: 407,620\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 1.9 M\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Bytes: 122.9 M\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 1.9 M\r\n  Uds Bytes: 0\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n```\r\n\r\nThe important bit:\r\n\r\n```\r\nTraceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 503, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\", line 1099, in check\r\n          collect_default_db,\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\", line 835, in _collect_stats\r\n          cursor, db_instance_metrics, key, db, instance_tags, False, relations_config\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\", line 707, in _query_scope\r\n          cursor.execute(query.replace(r'%', r'%%'))\r\n      InFailedSqlTransaction: current transaction is aborted, commands ignored until end of transaction block\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n1. run postgres integration on a read replica PG 9.6 (no streaming delay or `host_standby_feedback` configured)\r\n2. accidentally hit a `canceling statement due to conflict with recovery` error\r\n\r\nFrom then on you get `current transaction is aborted, commands ignored until end of transaction block` with the datadog agent until you either restart the agent, or restart postgresql.\r\n\r\n**Describe the results you received:**\r\n\r\ndatadog integration breaks\r\n\r\n**Describe the results you expected:**\r\n\r\nit should recover from that failed statement and happily continue", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4471", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4471/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4471/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4471/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4471", "id": 487158290, "node_id": "MDU6SXNzdWU0ODcxNTgyOTA=", "number": 4471, "title": "This SQL is incorrectly allowing non tables and unnecessary schemas ", "user": {"login": "dpierce-aledade", "id": 38014941, "node_id": "MDQ6VXNlcjM4MDE0OTQx", "avatar_url": "https://avatars1.githubusercontent.com/u/38014941?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dpierce-aledade", "html_url": "https://github.com/dpierce-aledade", "followers_url": "https://api.github.com/users/dpierce-aledade/followers", "following_url": "https://api.github.com/users/dpierce-aledade/following{/other_user}", "gists_url": "https://api.github.com/users/dpierce-aledade/gists{/gist_id}", "starred_url": "https://api.github.com/users/dpierce-aledade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dpierce-aledade/subscriptions", "organizations_url": "https://api.github.com/users/dpierce-aledade/orgs", "repos_url": "https://api.github.com/users/dpierce-aledade/repos", "events_url": "https://api.github.com/users/dpierce-aledade/events{/privacy}", "received_events_url": "https://api.github.com/users/dpierce-aledade/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-29T20:22:12Z", "updated_at": "2019-08-30T16:47:57Z", "closed_at": "2019-08-30T16:47:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "https://github.com/DataDog/integrations-core/blob/39b0c2691611a40f9fa96c983bfe543818d87e97/postgres/datadog_checks/postgres/postgres.py#L168\r\n```SQL\r\n 'query': \"\"\"\r\nSELECT\r\n  relname,\r\n  {metrics_columns}\r\nFROM pg_class C\r\nLEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)\r\nWHERE nspname NOT IN ('pg_catalog', 'information_schema') AND\r\n  nspname !~ '^pg_toast' AND\r\n  relkind IN ('r') AND  -- add parenthesis around final conditions, otherwise the final or negates everything else\r\n ( relname = ANY(array[{relations_names}]::text[]) or relname ~ ANY(array[{relations_regexes}]::text[]))\"\"\",\r\n    }\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4465", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4465/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4465/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4465/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4465", "id": 487041365, "node_id": "MDU6SXNzdWU0ODcwNDEzNjU=", "number": 4465, "title": "Global Distribution Metrics For Envoy", "user": {"login": "elee", "id": 158777, "node_id": "MDQ6VXNlcjE1ODc3Nw==", "avatar_url": "https://avatars1.githubusercontent.com/u/158777?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elee", "html_url": "https://github.com/elee", "followers_url": "https://api.github.com/users/elee/followers", "following_url": "https://api.github.com/users/elee/following{/other_user}", "gists_url": "https://api.github.com/users/elee/gists{/gist_id}", "starred_url": "https://api.github.com/users/elee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elee/subscriptions", "organizations_url": "https://api.github.com/users/elee/orgs", "repos_url": "https://api.github.com/users/elee/repos", "events_url": "https://api.github.com/users/elee/events{/privacy}", "received_events_url": "https://api.github.com/users/elee/received_events", "type": "User", "site_admin": true}, "labels": [{"id": 936567156, "node_id": "MDU6TGFiZWw5MzY1NjcxNTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/envoy", "name": "integration/envoy", "color": "bfdadc", "default": false, "description": ""}, {"id": 293952861, "node_id": "MDU6TGFiZWwyOTM5NTI4NjE=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/question", "name": "kind/question", "color": "cc317c", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-08-29T15:48:30Z", "updated_at": "2019-10-11T13:59:47Z", "closed_at": "2019-10-11T13:59:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nTaking a peek at the Envoy csv for emitted metrics I noticed most metrics are of type `counter` or `gauge` is there a simple way to emit the new global distribution metrics in their stead?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4392", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4392/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4392/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4392/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4392", "id": 481751554, "node_id": "MDU6SXNzdWU0ODE3NTE1NTQ=", "number": 4392, "title": "Unable to collect Gunicorn metrics using DogStatsD in K8s", "user": {"login": "mlaythe", "id": 15862573, "node_id": "MDQ6VXNlcjE1ODYyNTcz", "avatar_url": "https://avatars1.githubusercontent.com/u/15862573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mlaythe", "html_url": "https://github.com/mlaythe", "followers_url": "https://api.github.com/users/mlaythe/followers", "following_url": "https://api.github.com/users/mlaythe/following{/other_user}", "gists_url": "https://api.github.com/users/mlaythe/gists{/gist_id}", "starred_url": "https://api.github.com/users/mlaythe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mlaythe/subscriptions", "organizations_url": "https://api.github.com/users/mlaythe/orgs", "repos_url": "https://api.github.com/users/mlaythe/repos", "events_url": "https://api.github.com/users/mlaythe/events{/privacy}", "received_events_url": "https://api.github.com/users/mlaythe/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-16T19:24:32Z", "updated_at": "2019-08-20T20:09:18Z", "closed_at": "2019-08-20T20:09:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nEKS\r\n\r\n**Describe the results you received:**\r\nI setup a K8s cluster and one of the apps is a Gunicorn app and I'm trying to collect stats via DogStatsD. For DogStatsD, I set `nonLocalTraffic` to true in the `datadog-values.yaml` for the Helm chart. I then set the hostIP as an environment variable in the flask deployment:\r\n\r\n```\r\nenv:\r\n   - name: DD_AGENT_HOST\r\n      valueFrom:\r\n      fieldRef:\r\n      fieldPath: status.hostIP\r\n```\r\n\r\nWhen I deploy, Gunicorn has statsd host set to `statsd_host: ('192.168.2.11', 8125)` by referencing the env variable I defined above. And in the datadog pod logs it's listening for statsd requests:\r\n\r\n`2019-08-16 19:02:28 UTC | CORE | INFO | (pkg/dogstatsd/listeners/udp.go:79 in Listen) | dogstatsd-udp: starting to listen on [::]:8125`\r\n\r\n**Describe the results you expected:**\r\nI expected the statsd requests to come through and log to datadog.\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI'm not sure how to debug this, so any help would be greatly appreciated.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4384", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4384/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4384/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4384/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4384", "id": 481369895, "node_id": "MDU6SXNzdWU0ODEzNjk4OTU=", "number": 4384, "title": "pg_last_xlog_receive_location() is called for Postgres 10/11 databases", "user": {"login": "alexadriaanse", "id": 2073254, "node_id": "MDQ6VXNlcjIwNzMyNTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2073254?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexadriaanse", "html_url": "https://github.com/alexadriaanse", "followers_url": "https://api.github.com/users/alexadriaanse/followers", "following_url": "https://api.github.com/users/alexadriaanse/following{/other_user}", "gists_url": "https://api.github.com/users/alexadriaanse/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexadriaanse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexadriaanse/subscriptions", "organizations_url": "https://api.github.com/users/alexadriaanse/orgs", "repos_url": "https://api.github.com/users/alexadriaanse/repos", "events_url": "https://api.github.com/users/alexadriaanse/events{/privacy}", "received_events_url": "https://api.github.com/users/alexadriaanse/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-15T22:47:51Z", "updated_at": "2019-08-20T20:27:52Z", "closed_at": "2019-08-20T20:27:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "We're seeing the following errors resulting from queries that Datadog runs against one of our Postgres databases:\r\n```text\r\nfunction pg_last_xlog_receive_location() does not exist at character 35\r\n```\r\n\r\nIt looks like Datadog agent sometimes runs a pre-PG10 query against a PG10+ database.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\n\u25cf datadog-agent.service - Datadog Agent\r\n   Loaded: loaded (/lib/systemd/system/datadog-agent.service; enabled; vendor preset: enabled)\r\n   Active: active (running) since Thu 2019-08-15 20:07:29 UTC; 2min 26s ago\r\n Main PID: 10238 (agent)\r\n    Tasks: 70 (limit: 4915)\r\n   Memory: 231.4M\r\n      CPU: 22.802s\r\n   CGroup: /system.slice/datadog-agent.service\r\n           \u251c\u250010238 /opt/datadog-agent/bin/agent/agent run -p /opt/datadog-agent/run/agent.pid\r\n           \u2514\u250010408 java -Xmx200m -Xms50m -classpath /opt/datadog-agent/bin/agent/dist/jmx/jmxfetch.jar org.datadog.jmxfetch.App --ipc_host localhost --ipc_port 5001 --check_period 15000 --thread_pool_size 3 --collection_timeout 60 --reconnection_timeout 10 --reconnection_thread_pool_size 3 --log_level INFO --reporter\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nWe're running the datadog-agent 1:6.13.0-1 Debian package on Debian Stretch on a VM within AWS. The agent runs on the host directly, but the Postgres databases it monitors run within Docker containers.\r\n\r\n**Steps to reproduce the issue:**\r\nI haven't built an isolated test case, but this seemed to work in our environment:\r\n1. Have the Datadog agent monitor multiple Postgres database of different versions (9.6, 10, and 11). Configure it so that the configuration for a v9.6 database is immediately followed by the configuration for a v11 database in `/etc/datadog-agent/conf.d/postgres.d/conf.yaml`. If you flip the order (where the v9.6 database follows the v11 database in `conf.yaml`) the problem goes away, at least for the v11 database.\r\n2. Watch the logs of the v11 database for errors.\r\n\r\n**Describe the results you received:**\r\nI'm seeing this in the logs for the Postgres 11 database:\r\n```text\r\n2019-08-15 20:22:31 UTC [8802-121] staff@xref ERROR:  function pg_last_xlog_receive_location() does not exist at character 35\r\n2019-08-15 20:22:31 UTC [8802-122] staff@xref HINT:  No function matches the given name and argument types. You might need to add explicit type casts.\r\n2019-08-15 20:22:31 UTC [8802-123] staff@xref STATEMENT:\r\n\tSELECT abs(pg_xlog_location_diff(pg_last_xlog_receive_location(), pg_last_xlog_replay_location())) AS replication_delay_bytes, CASE WHEN pg_last_xlog_receive_location() = pg_last_xlog_replay_location() THEN 0 ELSE GREATEST (0, EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp())) END, abs(pg_xlog_location_diff(pg_last_xlog_receive_location(), pg_last_xlog_replay_location())) AS replication_delay_bytes_dup\r\n\t WHERE (SELECT pg_is_in_recovery())\r\n2019-08-15 20:22:46 UTC [8802-124] staff@xref ERROR:  function pg_last_xlog_receive_location() does not exist at character 35\r\n2019-08-15 20:22:46 UTC [8802-125] staff@xref HINT:  No function matches the given name and argument types. You might need to add explicit type casts.\r\n2019-08-15 20:22:46 UTC [8802-126] staff@xref STATEMENT:\r\n\tSELECT abs(pg_xlog_location_diff(pg_last_xlog_receive_location(), pg_last_xlog_replay_location())) AS replication_delay_bytes, CASE WHEN pg_last_xlog_receive_location() = pg_last_xlog_replay_location() THEN 0 ELSE GREATEST (0, EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp())) END, abs(pg_xlog_location_diff(pg_last_xlog_receive_location(), pg_last_xlog_replay_location())) AS replication_delay_bytes_dup\r\n\t WHERE (SELECT pg_is_in_recovery())\r\n```\r\n\r\n**Describe the results you expected:**\r\nNo query errors.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nI dug through the [postgres.py](https://github.com/DataDog/integrations-core/blob/master/postgres/datadog_checks/postgres/postgres.py) code a bit and added some debugging information to our local copy. This Postgres check has different queries for different versions of Postgres, and I can see that it picks the right query (one that doesn't call `pg_last_xlog_receive_location()`) for the PG11 database. I'm wondering if some variable is leaking between multiple database checks, where it's executing the query for the wrong (previous) database against the database in question at times.\r\n\r\nWe're seeing this errors very frequently, although I'm not sure if it happens every time the database is checked.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4361", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4361/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4361/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4361/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4361", "id": 480258678, "node_id": "MDU6SXNzdWU0ODAyNTg2Nzg=", "number": 4361, "title": "Move kube_dns to integrations-extra?", "user": {"login": "aerostitch", "id": 4210981, "node_id": "MDQ6VXNlcjQyMTA5ODE=", "avatar_url": "https://avatars1.githubusercontent.com/u/4210981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aerostitch", "html_url": "https://github.com/aerostitch", "followers_url": "https://api.github.com/users/aerostitch/followers", "following_url": "https://api.github.com/users/aerostitch/following{/other_user}", "gists_url": "https://api.github.com/users/aerostitch/gists{/gist_id}", "starred_url": "https://api.github.com/users/aerostitch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aerostitch/subscriptions", "organizations_url": "https://api.github.com/users/aerostitch/orgs", "repos_url": "https://api.github.com/users/aerostitch/repos", "events_url": "https://api.github.com/users/aerostitch/events{/privacy}", "received_events_url": "https://api.github.com/users/aerostitch/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-13T16:46:30Z", "updated_at": "2019-09-03T12:51:36Z", "closed_at": "2019-09-03T12:51:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "HI,\r\n\r\nkube-dns has been deprecated in favor of coredns in k8s long ago.\r\nI'm wondering if it still makes sense to ship kube_dns by default in integrations-core.\r\nI'm fine helping moving it to integrations-extra if needed but I just wanted your opinion before proposing such a change.\r\n\r\nThanks\r\nJoseph", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4341", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4341/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4341/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4341/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4341", "id": 479119199, "node_id": "MDU6SXNzdWU0NzkxMTkxOTk=", "number": 4341, "title": "Website is out of sync with doc in repo", "user": {"login": "tonglil", "id": 3250776, "node_id": "MDQ6VXNlcjMyNTA3NzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/3250776?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tonglil", "html_url": "https://github.com/tonglil", "followers_url": "https://api.github.com/users/tonglil/followers", "following_url": "https://api.github.com/users/tonglil/following{/other_user}", "gists_url": "https://api.github.com/users/tonglil/gists{/gist_id}", "starred_url": "https://api.github.com/users/tonglil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tonglil/subscriptions", "organizations_url": "https://api.github.com/users/tonglil/orgs", "repos_url": "https://api.github.com/users/tonglil/repos", "events_url": "https://api.github.com/users/tonglil/events{/privacy}", "received_events_url": "https://api.github.com/users/tonglil/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-09T18:45:16Z", "updated_at": "2019-08-13T21:41:34Z", "closed_at": "2019-08-13T21:41:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Website missing \"Service Checks\" heading and description.\r\nDoes the site not source it's docs from here?\r\n\r\nhttps://docs.datadoghq.com/integrations/tls/\r\n\r\n<img width=\"1245\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3250776/62801658-16662180-ba9b-11e9-9095-824a9f97a090.png\">\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/master/tls/README.md\r\n\r\n<img width=\"939\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3250776/62801674-1bc36c00-ba9b-11e9-815b-11439ea55194.png\">\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4310", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4310/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4310/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4310/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4310", "id": 477364408, "node_id": "MDU6SXNzdWU0NzczNjQ0MDg=", "number": 4310, "title": "Unable to get Controller, Scheduler and Metrics dashboards populated", "user": {"login": "taneishamitchell", "id": 13461624, "node_id": "MDQ6VXNlcjEzNDYxNjI0", "avatar_url": "https://avatars1.githubusercontent.com/u/13461624?v=4", "gravatar_id": "", "url": "https://api.github.com/users/taneishamitchell", "html_url": "https://github.com/taneishamitchell", "followers_url": "https://api.github.com/users/taneishamitchell/followers", "following_url": "https://api.github.com/users/taneishamitchell/following{/other_user}", "gists_url": "https://api.github.com/users/taneishamitchell/gists{/gist_id}", "starred_url": "https://api.github.com/users/taneishamitchell/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/taneishamitchell/subscriptions", "organizations_url": "https://api.github.com/users/taneishamitchell/orgs", "repos_url": "https://api.github.com/users/taneishamitchell/repos", "events_url": "https://api.github.com/users/taneishamitchell/events{/privacy}", "received_events_url": "https://api.github.com/users/taneishamitchell/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-06T12:56:04Z", "updated_at": "2019-08-14T16:05:51Z", "closed_at": "2019-08-13T22:58:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\nI am testing this integration with within minikube this will be configuration will be migrated to our staging infrastructure on AWS in an EKS cluster once it becomes available. What is happening is the following:\r\n```text\r\n\u279c kubectl exec datadog-znr26 agent status\r\n...\r\n    kube_metrics_server (1.0.0)\r\n    ---------------------------\r\n      Instance ID: kube_metrics_server:973042caf095d7a8 [ERROR]\r\n      Total Runs: 34\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 34\r\n      Average Execution Time : 19ms\r\n      Error: HTTPSConnectionPool(host='192.168.64.30', port=443): Max retries exceeded with url: /metrics (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f986018d410>: Failed to establish a new connection: [Errno 111] Connection refused',))\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 503, in run\r\n          self.check(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/kube_metrics_server/kube_metrics_server.py\", line 104, in check\r\n          self.process(scraper_config)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/openmetrics/mixins.py\", line 330, in process\r\n          for metric in self.scrape_metrics(scraper_config):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/openmetrics/mixins.py\", line 297, in scrape_metrics\r\n          response = self.poll(scraper_config)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/openmetrics/mixins.py\", line 479, in poll\r\n          response = self.send_request(endpoint, scraper_config, headers)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/openmetrics/mixins.py\", line 542, in send_request\r\n          auth=auth,\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/api.py\", line 75, in get\r\n          return request('get', url, params=params, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/api.py\", line 60, in request\r\n          return session.request(method=method, url=url, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/sessions.py\", line 533, in request\r\n          resp = self.send(prep, **send_kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/sessions.py\", line 646, in send\r\n          r = adapter.send(request, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/adapters.py\", line 516, in send\r\n          raise ConnectionError(e, request=request)\r\n      ConnectionError: HTTPSConnectionPool(host='192.168.64.30', port=443): Max retries exceeded with url: /metrics (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f986018d410>: Failed to establish a new connection: [Errno 111] Connection refused',))\r\n...\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n```\r\n\u279c minikube status\r\nhost: Running\r\nkubelet: Running\r\napiserver: Running\r\nkubectl: Correctly Configured: pointing to minikube-vm at 192.168.64.30\r\n...\r\ndatadog-values.yaml\r\n## Default values for Datadog Agent\r\n## See Datadog helm documentation to learn more:\r\n## https://docs.datadoghq.com/agent/kubernetes/helm/\r\nimage:\r\n  repository: datadog/agent\r\n  tag: 6.13.0\r\n  pullPolicy: Always\r\n\r\ndatadog:\r\n  apiKeyExistingSecret: datadog-secret\r\n  appKeyExistingSecret: datadog-app-secret\r\n\r\n  logLevel: DEBUG\r\n\r\n  tags:\r\n    - name: dev.webapp\r\n    - env: dev\r\n    - purpose: webapp\r\n    \r\n  apmEnabled: true\r\n  nonLocalTraffic: true\r\n  \r\n  collectEvents: true\r\n  logsEnabled: true\r\n\r\n  logsConfigContainerCollectAll: true\r\n\r\n  confd:\r\n    kubernetes_state.yaml: |-\r\n      cluster_check: true\r\n      ad_identifiers:\r\n        - kube-state-metrics\r\n      init_config:\r\n      instances:\r\n        - kube_state_url: http://%%host%%:8080/metrics\r\n    kube_controller_manager.yaml: |-\r\n      init_config:\r\n      instances:\r\n        - prometheus_url: http://192.168.64.30:10252/metrics\r\n    kube_scheduler.yaml: |-\r\n      init_config:\r\n      instances:\r\n        - prometheus_url: http://192.168.64.30:10251/metrics\r\n    kube_metrics_server.yaml: |-\r\n      init_config:\r\n      instances:\r\n        - prometheus_url: https://192.168.64.30:443/metrics\r\n  env:\r\n    - name: DD_LOGS_INJECTION\r\n      value: \"true\"\r\n    - name: DD_USE_DOGSTATSD\r\n      value: \"true\"\r\n    - name: DD_LOG_FORMAT_JSON\r\n      value: \"true\"\r\n    - name: DD_APP_KEY\r\n      value: \"===REDACTED===\"\r\n    - name: DD_APM_ENABLED\r\n      value: \"true\"\r\n    - name: DD_EXTRA_CONFIG_PROVIDERS\r\n      value: \"clusterchecks\"\r\n\r\nclusterAgent:\r\n  enabled: true\r\n  token: \"===REDACTED===\"\r\n\r\n  metricsProvider:\r\n    enabled: true\r\n\r\n  clusterChecks:\r\n    enabled: true\r\n  \r\ndaemonset:\r\n  useHostPort: true\r\n```\r\n**Steps to reproduce the issue:**\r\n1. Install helm in minikube \r\n2. Check IP for etcd, scheduler, or apiserver for k8s: `kubectl get po -o wide --all-namespaces`\r\n3. Replace IP in `datadog-values.yaml` where IP `192.168.64.30` is with that of `etcd` pod\r\n4. Install the datadog chart: `helm install -f datadog-values.yaml --name datadog stable/datadog`\r\n4. Run agent test once pods are up & running: `kubectl exec <datadog agent name> agent status\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\nA successful response similiar to:\r\n```\r\n    kube_scheduler (1.1.0)\r\n    ----------------------\r\n      Instance ID: kube_scheduler:287d9c0cb137ebcf [OK]\r\n      Total Runs: 7\r\n      Metric Samples: Last Run: 338, Total: 2,366\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 2, Total: 14\r\n      Average Execution Time : 211ms\r\n```\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4265", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4265/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4265/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4265/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4265", "id": 475381717, "node_id": "MDU6SXNzdWU0NzUzODE3MTc=", "number": 4265, "title": "Is it send_histogram_buckets or send_histograms_buckets?", "user": {"login": "tonglil", "id": 3250776, "node_id": "MDQ6VXNlcjMyNTA3NzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/3250776?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tonglil", "html_url": "https://github.com/tonglil", "followers_url": "https://api.github.com/users/tonglil/followers", "following_url": "https://api.github.com/users/tonglil/following{/other_user}", "gists_url": "https://api.github.com/users/tonglil/gists{/gist_id}", "starred_url": "https://api.github.com/users/tonglil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tonglil/subscriptions", "organizations_url": "https://api.github.com/users/tonglil/orgs", "repos_url": "https://api.github.com/users/tonglil/repos", "events_url": "https://api.github.com/users/tonglil/events{/privacy}", "received_events_url": "https://api.github.com/users/tonglil/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-31T22:17:07Z", "updated_at": "2019-07-31T22:27:05Z", "closed_at": "2019-07-31T22:27:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "What is the correct value/name of this parameter?\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/fe92b135cc68c5e38f2325306fe4395e29f43de9/prometheus/datadog_checks/prometheus/data/conf.yaml.example#L72-L75\r\n\r\nIt is spelt different in the same place:\r\n`send_histogram_buckets`\r\n`send_histograms_buckets`\r\n\r\nIt is also used as `send_histograms_buckets` here: https://docs.datadoghq.com/integrations/istio/#connect-the-agent\r\n\r\nAnd here: https://docs.datadoghq.com/getting_started/integrations/prometheus/?tab=kubernetes#configuration\r\n\r\n<img width=\"913\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3250776/62251957-38c6b380-b3a6-11e9-96ef-602e55be511e.png\">\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4244", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4244/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4244/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4244/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4244", "id": 474857164, "node_id": "MDU6SXNzdWU0NzQ4NTcxNjQ=", "number": 4244, "title": "Aerospike check missing agentConfig arg", "user": {"login": "wm-sammerry", "id": 50841552, "node_id": "MDQ6VXNlcjUwODQxNTUy", "avatar_url": "https://avatars2.githubusercontent.com/u/50841552?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wm-sammerry", "html_url": "https://github.com/wm-sammerry", "followers_url": "https://api.github.com/users/wm-sammerry/followers", "following_url": "https://api.github.com/users/wm-sammerry/following{/other_user}", "gists_url": "https://api.github.com/users/wm-sammerry/gists{/gist_id}", "starred_url": "https://api.github.com/users/wm-sammerry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wm-sammerry/subscriptions", "organizations_url": "https://api.github.com/users/wm-sammerry/orgs", "repos_url": "https://api.github.com/users/wm-sammerry/repos", "events_url": "https://api.github.com/users/wm-sammerry/events{/privacy}", "received_events_url": "https://api.github.com/users/wm-sammerry/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-30T22:51:20Z", "updated_at": "2019-07-30T23:36:06Z", "closed_at": "2019-07-30T23:36:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Additional environment details (Operating System, Cloud provider, etc):**\r\ndatadog-agent_6.9.0-1_amd64.deb\r\nubuntu 16.04\r\n\r\n**Steps to reproduce the issue:**\r\n1. add default aerospike config pointing to local host\r\n2. run datadog-agent status\r\n3. observe following error\r\n```\r\n      \r\n  Check Initialization Errors\r\n  ===========================\r\n\r\n    \r\n      aerospike (unversioned)\r\n      -----------------------\r\n\r\n      instance 0:\r\n\r\n        could not invoke python check constructor: __init__() got an unexpected keyword argument 'agentConfig'\r\n\r\n      instance 1:\r\n\r\n        could not invoke python check constructor: __init__() got an unexpected keyword argument 'agentConfig'\r\n```\r\n\r\n**Describe the results you received:**\r\nmissing agentConfig arg on __init__ method\r\n\r\n**Describe the results you expected:**\r\ncheck collects metrics about aerospike\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4206", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4206/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4206/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4206/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4206", "id": 472944251, "node_id": "MDU6SXNzdWU0NzI5NDQyNTE=", "number": 4206, "title": "nameserver ", "user": {"login": "bigred3142", "id": 5265765, "node_id": "MDQ6VXNlcjUyNjU3NjU=", "avatar_url": "https://avatars1.githubusercontent.com/u/5265765?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bigred3142", "html_url": "https://github.com/bigred3142", "followers_url": "https://api.github.com/users/bigred3142/followers", "following_url": "https://api.github.com/users/bigred3142/following{/other_user}", "gists_url": "https://api.github.com/users/bigred3142/gists{/gist_id}", "starred_url": "https://api.github.com/users/bigred3142/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bigred3142/subscriptions", "organizations_url": "https://api.github.com/users/bigred3142/orgs", "repos_url": "https://api.github.com/users/bigred3142/repos", "events_url": "https://api.github.com/users/bigred3142/events{/privacy}", "received_events_url": "https://api.github.com/users/bigred3142/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-25T15:53:44Z", "updated_at": "2019-08-28T15:36:39Z", "closed_at": "2019-08-28T15:36:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\n(paste your output here)\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n**Steps to reproduce the issue:**\r\n1.\r\n2.\r\n3.\r\n\r\n**Describe the results you received:**\r\n\r\n\r\n**Describe the results you expected:**\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4139", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4139/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4139/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4139/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4139", "id": 469513934, "node_id": "MDU6SXNzdWU0Njk1MTM5MzQ=", "number": 4139, "title": "Some `kubernetes_state` metrics tagged with labels from ksm pods, not originating pods ", "user": {"login": "shivshav", "id": 6853278, "node_id": "MDQ6VXNlcjY4NTMyNzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/6853278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivshav", "html_url": "https://github.com/shivshav", "followers_url": "https://api.github.com/users/shivshav/followers", "following_url": "https://api.github.com/users/shivshav/following{/other_user}", "gists_url": "https://api.github.com/users/shivshav/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivshav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivshav/subscriptions", "organizations_url": "https://api.github.com/users/shivshav/orgs", "repos_url": "https://api.github.com/users/shivshav/repos", "events_url": "https://api.github.com/users/shivshav/events{/privacy}", "received_events_url": "https://api.github.com/users/shivshav/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 592413329, "node_id": "MDU6TGFiZWw1OTI0MTMzMjk=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/containers", "name": "containers", "color": "0052cc", "default": false, "description": null}, {"id": 936572384, "node_id": "MDU6TGFiZWw5MzY1NzIzODQ=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/kubernetes_state", "name": "integration/kubernetes_state", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-18T00:34:53Z", "updated_at": "2019-09-03T17:18:43Z", "closed_at": "2019-09-03T17:18:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v6.10.1)\r\n===============\r\n\r\n  Status date: 2019-07-17 23:54:37.445934 UTC\r\n  Pid: 387\r\n  Python Version: 2.7.15\r\n  Logs:\r\n  Check Runners: 4\r\n  Log Level: WARN\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -1.899ms\r\n    System UTC time: 2019-07-17 23:54:37.445934 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-06-06 01:03:58.000000 UTC\r\n    kernelVersion: 4.9.0-9-amd64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: buster/sid\r\n    procs: 71\r\n    uptime: 1006h35m22s\r\n    virtualizationRole: guest\r\n    virtualizationSystem: xen\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: <redacted>\r\n    host_aliases: [<redacted>]\r\n    hostname: <redacted>\r\n    instance-id: <redacted>\r\n    socket-fqdn: default-datadog-metrics-7jmzl\r\n    socket-hostname: default-datadog-metrics-7jmzl\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 6, Total: 360\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    disk (2.1.0)\r\n    ------------\r\n      Instance ID: disk:4e2ef38058b61387 [OK]\r\n      Total Runs: 62\r\n      Metric Samples: Last Run: 194, Total: 12,028\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 215ms\r\n\r\n\r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 282, Total: 17,202\r\n      Events: Last Run: 0, Total: 1\r\n      Service Checks: Last Run: 1, Total: 61\r\n      Average Execution Time : 87ms\r\n\r\n\r\n    elastic (1.11.0)\r\n    ----------------\r\n      Instance ID: elastic:c8142181a967bdd7 [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 1,286, Total: 78,677\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 2, Total: 122\r\n      Average Execution Time : 715ms\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 5, Total: 305\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 65, Total: 3,920\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    kubelet (2.4.0)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 285, Total: 17,716\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 4, Total: 241\r\n      Average Execution Time : 534ms\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 6, Total: 366\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 17, Total: 1,037\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    network (1.9.0)\r\n    ---------------\r\n      Instance ID: network:2a218184ebe03606 [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 39, Total: 2,379\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 49ms\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:b4579e02d1981c12 [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 1, Total: 61\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 61\r\n      Average Execution Time : 0s\r\n\r\n\r\n    postgres (2.5.0)\r\n    ----------------\r\n      Instance ID: postgres:d07ba8004f7d106c [ERROR]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 61\r\n      Average Execution Time : 25ms\r\n      Error: ('communication error', gaierror(-2, 'Name or service not known'))\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 774, in run\r\n          self.check(copy.deepcopy(self.instances[0]))\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\", line 1056, in check\r\n          db = self.get_connection(key, host, port, user, password, dbname, ssl, connect_fct, tags)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/postgres/postgres.py\", line 857, in get_connection\r\n          password=password, database=dbname, ssl=ssl)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/pg8000/__init__.py\", line 328, in connect\r\n          user, host, unix_sock, port, database, password, ssl)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/pg8000/core.py\", line 961, in __init__\r\n          raise InterfaceError(\"communication error\", exc_info()[1])\r\n      InterfaceError: ('communication error', gaierror(-2, 'Name or service not known'))\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Total Runs: 61\r\n      Metric Samples: Last Run: 1, Total: 61\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 61\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 7\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 129\r\n    TimeseriesV1: 61\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 82bd4: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 82bd4\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 135,579\r\n  Dogstatsd Metric Sample: 153\r\n  Event: 2\r\n  Events Flushed: 2\r\n  Number Of Flushes: 61\r\n  Series Flushed: 122,245\r\n  Service Check: 1,280\r\n  Service Checks Flushed: 1,330\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 153\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 154\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n=====================\r\nDatadog Cluster Agent\r\n=====================\r\n\r\n  - Datadog Cluster Agent endpoint detected: https://100.69.60.138:5005\r\n  Successfully connected to the Datadog Cluster Agent.\r\n  - Running: {Major:1 Minor:2 Patch:0 Pre: Meta: Commit:52053af}\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nAWS, Debian (stretch)\r\n**Steps to reproduce the issue:**\r\n1. Install datadog agent with `helm` chart\r\n2. Configure `kubernetes_state` integration with configuration provided below\r\n3. Check metrics for `kubernetes_state.container.restarts` or `kubernetes_state.container.waiting` (Note: These are just the ones I've been actively trying to configure monitors with. There are likely more)\r\n4. Trigger a pod to have restarts or to go into `CrashLoopBackOff` (in this case, the relevant deployment is `default-growop-nutrients`\r\n\r\nHere is the `kubernetes_state.yaml` config I am using in the helm chart\r\n```yaml\r\ndatadog:\r\n  podLabelsAsTags:\r\n    app: kube_app\r\n    release: helm_release\r\n    k8s-app: kube_system_app\r\n    leafly.io/teams: dev_team\r\n  conf.d:\r\n    kubernetes_state.yaml: |-\r\n    # kubernetes_state.yaml\r\n      ad_identifiers:\r\n        - kube-state-metrics\r\n      init_config:\r\n      instances:\r\n        - kube_state_url: http://%%host%%:8080/metrics\r\n          ## @param label_joins - custom - optional\r\n          ## Add the tags to join from other KSM metrics.\r\n          ## Example: Joining for deployment metrics. Based on: kube_pod_labels{label_app=\"kube-state-metrics\",label_pod_template_hash=\"639670438\",label_release=\"jaundiced-numbat\",namespace=\"default\",pod=\"jaundiced-numbat-kube-state-metrics-b7fbc487d-4phhj\"}\r\n          ## Use the following config to add the value of label_app as a tag to your KSM deployment metrics.\r\n          label_joins:\r\n            kube_pod_labels:\r\n              label_to_match: pod\r\n              labels_to_get:\r\n                - label_app\r\n                - label_release\r\n                - label_k8s_app\r\n                - label_leafly_io_teams\r\n            kube_deployment_labels:\r\n              label_to_match: deployment\r\n              labels_to_get:\r\n                - label_app\r\n                - label_release\r\n                - label_k8s_app\r\n                - label_leafly_io_teams\r\n            kube_job_labels:\r\n              label_to_match: job_name\r\n              labels_to_get:\r\n                - label_app\r\n                - label_release\r\n                - label_k8s_app\r\n                - label_leafly_io_teams\r\n            kube_node_labels:\r\n              label_to_match: node\r\n              labels_to_get:\r\n                - label_leafly_node_util\r\n            kube_service_labels:\r\n              label_to_match: service\r\n              labels_to_get:\r\n                - label_app\r\n                - label_release\r\n                - label_k8s_app\r\n                - label_leafly_io_teams\r\n          labels_mapper:\r\n            pod: kube_pod\r\n            deployment: kube_deployment\r\n            namespace: kube_namespace\r\n            label_app: kube_app\r\n            label_release: helm_release\r\n            label_k8s_app: kube_system_app\r\n            label_leafly_io_teams: dev_team\r\n            label_leafly_node_util: util_node\r\n```\r\n\r\n**Describe the results you received:**\r\nNotice that the graphs for the metrics noted above filtered on both the crashlooping/restarting app and the `kube-state-metrics` deployment you are using will be **exactly** the same. \r\n\r\nTo graph the following metrics in a screenshottable manner. I filtered _over_ the `kube_app` label, but aggregated per `helm_release` just so I could get them to show side-by-side. \r\n\r\n`kubernetes_state.container.waiting` metric graph:\r\n\r\n<img width=\"1767\" alt=\"Screen Shot 2019-07-17 at 5 15 43 PM\" src=\"https://user-images.githubusercontent.com/6853278/61420327-c4c0e180-a8b6-11e9-87a0-8d576f6adbd9.png\">\r\n\r\n`kubernetes_state.container.restarts` graph\r\n<img width=\"1770\" alt=\"Screen Shot 2019-07-17 at 5 13 46 PM\" src=\"https://user-images.githubusercontent.com/6853278/61420276-9511d980-a8b6-11e9-85ff-4b796873d86d.png\">\r\n\r\nThe fact that the `kube-state-metrics` pods even show up after the filtering signals a label mapping/joining problem to me\r\n\r\n**Describe the results you expected:**\r\nI would expect the restarts and waiting states to only show up for the pod that is _actually_ waiting based on the labels/tags I am filtering on\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nThe `label_joins` and `label_mappers` were added after stumbling into [this issue](https://github.com/DataDog/integrations-core/issues/2137)\r\n\r\n_Note: Disregard the broken `postgres` check. It is unrelated and has been fixed._", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4136", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4136/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4136/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4136/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4136", "id": 469424547, "node_id": "MDU6SXNzdWU0Njk0MjQ1NDc=", "number": 4136, "title": "Add auto-discovery config for kube_controller_manager and kube_scheduler", "user": {"login": "jonmoter", "id": 1056506, "node_id": "MDQ6VXNlcjEwNTY1MDY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1056506?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonmoter", "html_url": "https://github.com/jonmoter", "followers_url": "https://api.github.com/users/jonmoter/followers", "following_url": "https://api.github.com/users/jonmoter/following{/other_user}", "gists_url": "https://api.github.com/users/jonmoter/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonmoter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonmoter/subscriptions", "organizations_url": "https://api.github.com/users/jonmoter/orgs", "repos_url": "https://api.github.com/users/jonmoter/repos", "events_url": "https://api.github.com/users/jonmoter/events{/privacy}", "received_events_url": "https://api.github.com/users/jonmoter/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 592413329, "node_id": "MDU6TGFiZWw1OTI0MTMzMjk=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/containers", "name": "containers", "color": "0052cc", "default": false, "description": null}, {"id": 1359932046, "node_id": "MDU6TGFiZWwxMzU5OTMyMDQ2", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/kube_apiserver_metrics", "name": "integration/kube_apiserver_metrics", "color": "bfdadc", "default": false, "description": ""}, {"id": 1180239566, "node_id": "MDU6TGFiZWwxMTgwMjM5NTY2", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/kube_controller_manager", "name": "integration/kube_controller_manager", "color": "bfdadc", "default": false, "description": ""}, {"id": 1291992509, "node_id": "MDU6TGFiZWwxMjkxOTkyNTA5", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/kube_scheduler", "name": "integration/kube_scheduler", "color": "bfdadc", "default": false, "description": ""}, {"id": 801472141, "node_id": "MDU6TGFiZWw4MDE0NzIxNDE=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/feature-request", "name": "kind/feature-request", "color": "84b6eb", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-17T20:20:19Z", "updated_at": "2020-02-12T09:36:49Z", "closed_at": "2020-02-12T09:36:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "For the `kube_apiserver_metrics` integration, you conveniently have auto-discovery set up, so it will work on `kube-apiserver` docker image\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/master/kube_apiserver_metrics/datadog_checks/kube_apiserver_metrics/data/auto_conf.yaml\r\n\r\nIt would be great if you could add similar files for `kube_controller_manager` and `kube_scheduler`.  Those components use docker images of the form `k8s.gcr.io/kube-controller-manager:v1.x.y` and `k8s.gcr.io/kube-scheduler:v1.x.y`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/4084", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4084/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4084/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/4084/events", "html_url": "https://github.com/DataDog/integrations-core/issues/4084", "id": 465885373, "node_id": "MDU6SXNzdWU0NjU4ODUzNzM=", "number": 4084, "title": "Untyped prometheus metrics not reported", "user": {"login": "mathewmoon", "id": 8572840, "node_id": "MDQ6VXNlcjg1NzI4NDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8572840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mathewmoon", "html_url": "https://github.com/mathewmoon", "followers_url": "https://api.github.com/users/mathewmoon/followers", "following_url": "https://api.github.com/users/mathewmoon/following{/other_user}", "gists_url": "https://api.github.com/users/mathewmoon/gists{/gist_id}", "starred_url": "https://api.github.com/users/mathewmoon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mathewmoon/subscriptions", "organizations_url": "https://api.github.com/users/mathewmoon/orgs", "repos_url": "https://api.github.com/users/mathewmoon/repos", "events_url": "https://api.github.com/users/mathewmoon/events{/privacy}", "received_events_url": "https://api.github.com/users/mathewmoon/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-07-09T16:49:05Z", "updated_at": "2020-04-07T05:36:35Z", "closed_at": "2019-07-11T14:43:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Agent 6.12.1 - Commit: 8ded3a9 - Serialization version: 4.7.1, Running Amazon Linux 2\r\n\r\ndatadog.yaml:\r\n```\r\nprocess_config:\r\n  enabled: \"true\"\r\ncollect_ec2_tags: true\r\nuse_dogstatsd: true\r\ndogstatsd_port: 8125\r\nbind_host: localhost\r\ndisable_file_logging: true\r\napi_key: ******************\r\nlogs_enabled: true\r\n```\r\nprometheus.d/conf.yaml:\r\n```\r\nnstances:\r\n  - prometheus_url: http://localhost:8080/metrics\r\n    namespace: \"pulsar\"\r\n    metrics:\r\n      - \"*\"\r\n    health_service_check: true\r\n```\r\n**Steps to reproduce the issue:**\r\n1. Configure a prometheus endpoint to scrape without any type overrides\r\n2. Run datadog agent\r\n\r\n**Describe the results you received:**\r\nDatadog agent no longer reports metrics with no type as \"gauge\". This was not the behavior in previous versions of the agent.\r\n\r\n**Describe the results you expected:**\r\nMetrics without a type to appear in the dashboard.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n This https://github.com/DataDog/integrations-core/blob/38a6d70c594a62b9443ed296cc4ee88602d5fc51/prometheus/datadog_checks/prometheus/data/conf.yaml.example#L55 implies that the previous behavior was seen as a bug. \"Fixing\" this and forcing a type override is a breaking change for many users and presents several problems:\r\n1. It broke our metrics reporting and caused a dangerous condition for support of our product\r\n2. type_overrides seems to not support regex/wildcards. It is unreasonable to expect users with thousands of metrics to scrape to configure all of these one by one.\r\n2. The application that is reporting the metrics may change and start reporting its type. This creates an unnecessary coupling between code and configuration of the agent and assumes that a devops team has specific details of the code base.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3907", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3907/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3907/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3907/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3907", "id": 455306807, "node_id": "MDU6SXNzdWU0NTUzMDY4MDc=", "number": 3907, "title": "Prometheus check rename does not behave according to documentation", "user": {"login": "martin-sucha", "id": 2007393, "node_id": "MDQ6VXNlcjIwMDczOTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2007393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martin-sucha", "html_url": "https://github.com/martin-sucha", "followers_url": "https://api.github.com/users/martin-sucha/followers", "following_url": "https://api.github.com/users/martin-sucha/following{/other_user}", "gists_url": "https://api.github.com/users/martin-sucha/gists{/gist_id}", "starred_url": "https://api.github.com/users/martin-sucha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martin-sucha/subscriptions", "organizations_url": "https://api.github.com/users/martin-sucha/orgs", "repos_url": "https://api.github.com/users/martin-sucha/repos", "events_url": "https://api.github.com/users/martin-sucha/events{/privacy}", "received_events_url": "https://api.github.com/users/martin-sucha/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-12T16:19:06Z", "updated_at": "2019-06-26T14:52:40Z", "closed_at": "2019-06-26T14:52:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Agent version**\r\n\r\nAgent 6.11.3 - Commit: 5416f75 - Serialization version: 4.7.1\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nAdd Prometheus instance with config like this:\r\n\r\n```\r\ninstances:\r\n  - prometheus_url: http://my-service:8080/metrics\r\n    namespace: \"my.namespace\"\r\n    metrics:\r\n      - metric1:metric2\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\nmetric1 was not scraped\r\n\r\n**Describe the results you expected:**\r\n\r\nmetric1 should be scraped and stored in metric2 in DataDog.\r\n\r\n**Additional information**\r\n\r\nThe code that parses the metrics configuration is at https://github.com/DataDog/integrations-core/blob/f6672f79dbfd9b1f21932f91dacc4ed0430a2219/datadog_checks_base/datadog_checks/base/checks/prometheus/base_check.py#L145-L149\r\n\r\nYou can see that it expects either string or dictionary. Indeed when space is added after the `:` then the remapping works. Some parts of documentation are without the space after `:`, like https://github.com/DataDog/integrations-core/blob/f6672f79dbfd9b1f21932f91dacc4ed0430a2219/prometheus/README.md so either the docs should be updated or the agent should accept strings with `:` in them (the metric name can't contain `:` anyway) or both.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3906", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3906/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3906/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3906/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3906", "id": 455268971, "node_id": "MDU6SXNzdWU0NTUyNjg5NzE=", "number": 3906, "title": "Agent v6: prometheus summary counts are not sent as monotonic counters", "user": {"login": "martin-sucha", "id": 2007393, "node_id": "MDQ6VXNlcjIwMDczOTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2007393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martin-sucha", "html_url": "https://github.com/martin-sucha", "followers_url": "https://api.github.com/users/martin-sucha/followers", "following_url": "https://api.github.com/users/martin-sucha/following{/other_user}", "gists_url": "https://api.github.com/users/martin-sucha/gists{/gist_id}", "starred_url": "https://api.github.com/users/martin-sucha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martin-sucha/subscriptions", "organizations_url": "https://api.github.com/users/martin-sucha/orgs", "repos_url": "https://api.github.com/users/martin-sucha/repos", "events_url": "https://api.github.com/users/martin-sucha/events{/privacy}", "received_events_url": "https://api.github.com/users/martin-sucha/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2019-06-12T15:06:36Z", "updated_at": "2020-07-09T15:39:56Z", "closed_at": "2020-07-09T15:39:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Prometheus check does not send the `.count` metric generated from summary as deltas, but the raw value is sent. A similar issue was solved for counters with `send_monotonic_counter` option, but `send_monotonic_counter` does not have any effect on counters which are part of summary metrics.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Add a summary metric to your prometheus endpoint\r\n2. Set the agent to scrape it\r\n3. Observe that the value is always increasing\r\n\r\n**Describe the results you received:**\r\n\r\n![Screenshot from 2019-06-12 16-56-31](https://user-images.githubusercontent.com/2007393/59362393-a9047180-8d33-11e9-8ca7-da43e8a4cdf9.png)\r\n\r\nA sloped line can be seen in this graph\r\n\r\n**Describe the results you expected:**\r\n\r\nDatadog agent should send deltas and and a (more or less) flat line should be visible. It should either respect `send_monotonic_counter` setting or a newly introduced similar setting (for backward compatibility).\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nThis issue is related to https://github.com/DataDog/integrations-core/issues/1303 where `send_monotonic_counter` was introduced and is probably also related to https://github.com/DataDog/integrations-core/issues/1303#issuecomment-496142520\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3790", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3790/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3790/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3790/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3790", "id": 446669619, "node_id": "MDU6SXNzdWU0NDY2Njk2MTk=", "number": 3790, "title": "[mongodb metric]  NoneType object has no attribute 'lower'", "user": {"login": "helloluoc", "id": 37561654, "node_id": "MDQ6VXNlcjM3NTYxNjU0", "avatar_url": "https://avatars2.githubusercontent.com/u/37561654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/helloluoc", "html_url": "https://github.com/helloluoc", "followers_url": "https://api.github.com/users/helloluoc/followers", "following_url": "https://api.github.com/users/helloluoc/following{/other_user}", "gists_url": "https://api.github.com/users/helloluoc/gists{/gist_id}", "starred_url": "https://api.github.com/users/helloluoc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/helloluoc/subscriptions", "organizations_url": "https://api.github.com/users/helloluoc/orgs", "repos_url": "https://api.github.com/users/helloluoc/repos", "events_url": "https://api.github.com/users/helloluoc/events{/privacy}", "received_events_url": "https://api.github.com/users/helloluoc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-21T14:59:11Z", "updated_at": "2019-05-22T14:38:24Z", "closed_at": "2019-05-22T14:38:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Note:** If you have a feature request, you should [contact support](https://docs.datadoghq.com/help/) so the request can be properly tracked.\r\n\r\n**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\n(paste your output here)\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n**Steps to reproduce the issue:**\r\n1.when i use the mongo.py get metric, i got this error:\r\n![image](https://user-images.githubusercontent.com/37561654/58106811-4da30000-7c1b-11e9-9ad0-12f0d52053da.png)\r\n\r\nIn line 920 of the mongo.py should be :\r\n`if is_affirmative(instance.get('collections_indexes_stats', False)):`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3782", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3782/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3782/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3782/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3782", "id": 445554361, "node_id": "MDU6SXNzdWU0NDU1NTQzNjE=", "number": 3782, "title": "Incorrect DNS latency numbers?", "user": {"login": "Firehed", "id": 354842, "node_id": "MDQ6VXNlcjM1NDg0Mg==", "avatar_url": "https://avatars0.githubusercontent.com/u/354842?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Firehed", "html_url": "https://github.com/Firehed", "followers_url": "https://api.github.com/users/Firehed/followers", "following_url": "https://api.github.com/users/Firehed/following{/other_user}", "gists_url": "https://api.github.com/users/Firehed/gists{/gist_id}", "starred_url": "https://api.github.com/users/Firehed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Firehed/subscriptions", "organizations_url": "https://api.github.com/users/Firehed/orgs", "repos_url": "https://api.github.com/users/Firehed/repos", "events_url": "https://api.github.com/users/Firehed/events{/privacy}", "received_events_url": "https://api.github.com/users/Firehed/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-05-17T17:58:39Z", "updated_at": "2020-04-09T10:35:04Z", "closed_at": "2019-07-02T13:40:27Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I have seen suspiciously high and unstable latency numbers being reported for both Redis connections as well as the generic DNS check basically since initially configuring Datadog in our cluster.\r\n\r\nAgent version 6.10.2 running in Kubernetes (GKE 1.12.6)\r\n\r\n<img width=\"747\" alt=\"Screen Shot 2019-05-17 at 10 27 46 AM\" src=\"https://user-images.githubusercontent.com/354842/57945371-8d21c300-788e-11e9-8c81-b70ce30351a1.png\">\r\n\r\nDNS agent config is managed with basic K8S annotations:\r\n```yaml\r\n      metadata:\r\n        annotations:\r\n          ad.datadoghq.com/dd-monitor.check_names: [\"dns_check\", \"dns_check\", \"dns_check\", \"dns_check\"]\r\n          ad.datadoghq.com/dd-monitor.init_configs: '[{},{},{},{}]'\r\n          ad.datadoghq.com/dd-monitor.instances: |-\r\n            [\r\n              {\"name\":\"www.google.com\", \"hostname\":\"www.google.com\"},\r\n              {\"name\":\"kube-dns.kube-system.svc.cluster.local. (trailing dot)\", \"hostname\":\"kube-dns.kube-system.svc.cluster.local.\"},\r\n              {\"name\":\"kube-dns.kube-system.svc.cluster.local\", \"hostname\":\"kube-dns.kube-system.svc.cluster.local\"},\r\n              {\"name\":\"kube-dns.kube-system\", \"hostname\":\"kube-dns.kube-system\"}\r\n            ]\r\n```\r\n\r\nComparison script:\r\n```php\r\n<?php\r\ndeclare(strict_types=1);\r\n\r\nuse DataDog\\DogStatsd;\r\n\r\n$config = require 'config.php';\r\n\r\n$hosts = [\r\n    'kube-dns.kube-system' => 'kube-dns.kube-system',\r\n    'kube-dns.kube-system.svc.cluster.local' => 'kube-dns.kube-system.svc.cluster.local',\r\n    'kube-dns.kube-system.svc.cluster.local.' => 'kube-dns.kube-system.svc.cluster.local (trailing dot)',\r\n    'www.google.com' => 'www.google.com',\r\n];\r\n\r\n$statsd = $config->get(Dogstatsd::class);\r\n\r\nwhile (true) {\r\n    foreach ($hosts as $hostname => $description) {\r\n        $tags = [\r\n            'resolved_hostname' => $hostname,\r\n            'instance' => $description,\r\n        ];\r\n        $start = hrtime(true);\r\n        $result = gethostbyname($hostname);\r\n        $end = hrtime(true);\r\n        $status = ($result === $hostname) ? 'error' : 'ok';\r\n        $tags['status'] = $status;\r\n        $duration = ($end - $start) / 1000000000;\r\n        $statsd->microtiming('dns.custom_response_time', $duration, 1.0, $tags);\r\n    }\r\n\r\n    sleep(1);\r\n}\r\n```\r\n\r\nI looked through the integration source code and didn't see anything suspicious. I see similar \"ping\" times on Redis (see #3689) so I have no idea what's at play, but it's really weird to see the discrepancy. Anecdotally, I don't see any other latencies we measure that would be impacted by slow DNS regularly jittery in the same way the numbers from the integration reports.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3774", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3774/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3774/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3774/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3774", "id": 444732974, "node_id": "MDU6SXNzdWU0NDQ3MzI5NzQ=", "number": 3774, "title": "Incorrect istio mesh metrics url in example", "user": {"login": "marcoferrer", "id": 35935108, "node_id": "MDQ6VXNlcjM1OTM1MTA4", "avatar_url": "https://avatars0.githubusercontent.com/u/35935108?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marcoferrer", "html_url": "https://github.com/marcoferrer", "followers_url": "https://api.github.com/users/marcoferrer/followers", "following_url": "https://api.github.com/users/marcoferrer/following{/other_user}", "gists_url": "https://api.github.com/users/marcoferrer/gists{/gist_id}", "starred_url": "https://api.github.com/users/marcoferrer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marcoferrer/subscriptions", "organizations_url": "https://api.github.com/users/marcoferrer/orgs", "repos_url": "https://api.github.com/users/marcoferrer/repos", "events_url": "https://api.github.com/users/marcoferrer/events{/privacy}", "received_events_url": "https://api.github.com/users/marcoferrer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-16T03:07:57Z", "updated_at": "2019-06-05T15:40:31Z", "closed_at": "2019-06-05T15:40:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Using istios default configuration the mesh metrics url is actually `http://istio-mesh.istio-system:42422/metrics`\r\n\r\nhttps://github.com/DataDog/integrations-core/blob/307516697bd8a2edb7f5e952ceaeeaf0c09a39d5/istio/datadog_checks/istio/data/conf.yaml.example#L12\r\n\r\nI can submit a PR correcting it if thats acceptable. But the [docs](https://docs.datadoghq.com/integrations/istio/) would still need to be updated ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3725", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3725/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3725/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3725/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3725", "id": 441338647, "node_id": "MDU6SXNzdWU0NDEzMzg2NDc=", "number": 3725, "title": "istio.mesh.request.count metric should be a monotonic count", "user": {"login": "jonmoter", "id": 1056506, "node_id": "MDQ6VXNlcjEwNTY1MDY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1056506?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonmoter", "html_url": "https://github.com/jonmoter", "followers_url": "https://api.github.com/users/jonmoter/followers", "following_url": "https://api.github.com/users/jonmoter/following{/other_user}", "gists_url": "https://api.github.com/users/jonmoter/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonmoter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonmoter/subscriptions", "organizations_url": "https://api.github.com/users/jonmoter/orgs", "repos_url": "https://api.github.com/users/jonmoter/repos", "events_url": "https://api.github.com/users/jonmoter/events{/privacy}", "received_events_url": "https://api.github.com/users/jonmoter/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "therve", "id": 159137, "node_id": "MDQ6VXNlcjE1OTEzNw==", "avatar_url": "https://avatars3.githubusercontent.com/u/159137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/therve", "html_url": "https://github.com/therve", "followers_url": "https://api.github.com/users/therve/followers", "following_url": "https://api.github.com/users/therve/following{/other_user}", "gists_url": "https://api.github.com/users/therve/gists{/gist_id}", "starred_url": "https://api.github.com/users/therve/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/therve/subscriptions", "organizations_url": "https://api.github.com/users/therve/orgs", "repos_url": "https://api.github.com/users/therve/repos", "events_url": "https://api.github.com/users/therve/events{/privacy}", "received_events_url": "https://api.github.com/users/therve/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "therve", "id": 159137, "node_id": "MDQ6VXNlcjE1OTEzNw==", "avatar_url": "https://avatars3.githubusercontent.com/u/159137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/therve", "html_url": "https://github.com/therve", "followers_url": "https://api.github.com/users/therve/followers", "following_url": "https://api.github.com/users/therve/following{/other_user}", "gists_url": "https://api.github.com/users/therve/gists{/gist_id}", "starred_url": "https://api.github.com/users/therve/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/therve/subscriptions", "organizations_url": "https://api.github.com/users/therve/orgs", "repos_url": "https://api.github.com/users/therve/repos", "events_url": "https://api.github.com/users/therve/events{/privacy}", "received_events_url": "https://api.github.com/users/therve/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 15, "created_at": "2019-05-07T16:59:30Z", "updated_at": "2020-06-01T20:35:43Z", "closed_at": "2020-06-01T20:35:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\n===============\r\nAgent (v6.11.1)\r\n===============\r\n\r\n  Status date: 2019-05-07 16:50:41.559676 UTC\r\n  Agent start: 2019-05-07 00:55:41.341177 UTC\r\n  Pid: 339\r\n  Python Version: 2.7.16\r\n  Check Runners: 4\r\n  Log Level: info\r\n\r\n...\r\n\r\n    istio (2.1.0)\r\n    -------------\r\n      Instance ID: istio:c630785e1593291 [OK]\r\n      Total Runs: 3,839\r\n      Metric Samples: Last Run: 148, Total: 568,172\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 51ms\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\n* Kubernetes version 1.11.7\r\n* Running on AWS via `kops`\r\n* Istio version 1.1.4, installed via Helm chart\r\n\r\nThe `istio-telemetry` pod has the following annotations:\r\n```\r\n    ad.datadoghq.com/mixer.check_names: '[\"istio\"]'\r\n    ad.datadoghq.com/mixer.init_configs: '[{}]'\r\n    ad.datadoghq.com/mixer.instances: |\r\n      [\r\n        {\r\n          \"istio_mesh_endpoint\": \"http://%%host%%:42422/metrics\",\r\n          \"mixer_endpoint\": \"http://%%host%%:15014/metrics\",\r\n          \"send_histograms_buckets\": true\r\n        }\r\n      ]\r\n```\r\n\r\n**Steps to reproduce the issue:**\r\n\r\nMy kubernetes cluster running Istio has very little activity on it. So the only requests happening regularly are health checks for the running services.\r\n\r\nHowever, when I look at the `istio.mesh.request.count` metric in Datadog for that cluster, it is steadily increasing at a constant rate:\r\n\r\n![Metric_Explorer___Datadog](https://user-images.githubusercontent.com/1056506/57318088-5c7fa380-70ae-11e9-8679-0f13d4ae47c1.jpg)\r\n\r\n**Describe the results you expected:**\r\n\r\nSince the traffic is constant, I expect that metric to be a flat horizontal line.\r\n\r\nI believe this is because Istio exposes that metric in the Prometheus/OpenMetrics format, where counts are constantly increasing.  The datadog agent _should_ take that into account and subtract the Nth value from the (N+1)th value.\r\n\r\nI've seen errors like this before, like in #1303, which I opened about a similar kube-dns metric.\r\n\r\nSee also #3121, which brings up the same issue, but also involved how to configure the Istio check when running as a Deamonset.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3715", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3715/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3715/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3715/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3715", "id": 440224128, "node_id": "MDU6SXNzdWU0NDAyMjQxMjg=", "number": 3715, "title": "feature request: postgres pg_prepared_statements", "user": {"login": "miketheman", "id": 529516, "node_id": "MDQ6VXNlcjUyOTUxNg==", "avatar_url": "https://avatars0.githubusercontent.com/u/529516?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miketheman", "html_url": "https://github.com/miketheman", "followers_url": "https://api.github.com/users/miketheman/followers", "following_url": "https://api.github.com/users/miketheman/following{/other_user}", "gists_url": "https://api.github.com/users/miketheman/gists{/gist_id}", "starred_url": "https://api.github.com/users/miketheman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miketheman/subscriptions", "organizations_url": "https://api.github.com/users/miketheman/orgs", "repos_url": "https://api.github.com/users/miketheman/repos", "events_url": "https://api.github.com/users/miketheman/events{/privacy}", "received_events_url": "https://api.github.com/users/miketheman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-05-03T21:12:29Z", "updated_at": "2019-05-10T23:36:52Z", "closed_at": "2019-05-07T21:56:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Postgres has a read-only built in View showing statistics about prepared statements, dating back to Postgres 8.2 (potentially even earlier).\r\nSee https://www.postgresql.org/docs/8.2/view-pg-prepared-statements.html\r\n\r\nIt would be awesome to collect some of these values and tag them appropriately, to help with any performance diagnosis, answering questions like:\r\n\r\n- how many statements are prepared (cached) in the db? (count of results in view)\r\n- how long ago was a given statement prepared? (`prepare_time` timestamp)\r\n- are these prepared statements manaully generated by clients or by the built-in protocol? (`from_sql` boolean value)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3707", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3707/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3707/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3707/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3707", "id": 439608827, "node_id": "MDU6SXNzdWU0Mzk2MDg4Mjc=", "number": 3707, "title": "[kafka_consumer] NoBrokersAvailable with SASL PLAINTEXT", "user": {"login": "lpicanco", "id": 8377, "node_id": "MDQ6VXNlcjgzNzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/8377?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lpicanco", "html_url": "https://github.com/lpicanco", "followers_url": "https://api.github.com/users/lpicanco/followers", "following_url": "https://api.github.com/users/lpicanco/following{/other_user}", "gists_url": "https://api.github.com/users/lpicanco/gists{/gist_id}", "starred_url": "https://api.github.com/users/lpicanco/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lpicanco/subscriptions", "organizations_url": "https://api.github.com/users/lpicanco/orgs", "repos_url": "https://api.github.com/users/lpicanco/repos", "events_url": "https://api.github.com/users/lpicanco/events{/privacy}", "received_events_url": "https://api.github.com/users/lpicanco/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-02T14:04:00Z", "updated_at": "2019-05-08T17:53:10Z", "closed_at": "2019-05-08T17:53:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\nkafka_consumer (1.8.1)                                                                                                                                                                                                                                                                 \r\n    ----------------------                                                                                                                                                                                                                                                                 \r\n      Instance ID: kafka_consumer:8c6b5b32f5ed5fbf [ERROR]                                                                                                                                                                                                                                 \r\n      Total Runs: 30                                                                                                                                                                                                                                                                       \r\n      Metric Samples: Last Run: 0, Total: 0                                                                                                                                                                                                                                                \r\n      Events: Last Run: 0, Total: 0                                                                                                                                                                                                                                                        \r\n      Service Checks: Last Run: 0, Total: 0                                                                                                                                                                                                                                                \r\n      Average Execution Time : 28ms                                                                                                                                                                                                                                                        \r\n      Error: NoBrokersAvailable                                                                                                                                                                                                                                                            \r\n      Traceback (most recent call last):                                                                                                                                                                                                                                                   \r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 854, in run                                                                                                                                                                \r\n          self.check(instance)                                                                                                                                                                                                                                                             \r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/kafka_consumer/kafka_consumer.py\", line 91, in check                                                                                                                                                  \r\n          cli = self._get_kafka_client(instance)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/kafka_consumer/kafka_consumer.py\", line 175, in _get_kafka_client\r\n          ssl_password=instance.get('ssl_password'))\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/kafka/client_async.py\", line 231, in __init__\r\n          self.config['api_version'] = self.check_version(timeout=check_timeout)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/kafka/client_async.py\", line 848, in check_version\r\n          raise Errors.NoBrokersAvailable()\r\n      NoBrokersAvailable: NoBrokersAvailable\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nAgent 6.11.0 - Commit: 6985f35 - Serialization version: 4.7.1\r\nKafka 2.0.0 with SASL PLAINTEXT\r\n\r\n**Steps to reproduce the issue:**\r\n1. configure kafka_consumer to use SASL PLAIN_TEXT\r\n2. restart datadog agent \r\n3. execute a check: datadog-agent check kafka_consumer \r\n\r\n**Describe the results you received:**\r\n```\r\nError: (conn.py:823) | <BrokerConnection node_id=bootstrap host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected                                                                                                                                               \r\nError: (client_async.py:288) | Unable to bootstrap from [('localhost', 9092, 0)]\r\n```\r\n\r\n**Describe the results you expected:**\r\nSuccessful connection to kafka broker at localhost:9092\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nIssue always happens.\r\n\r\nMy configuration:\r\n```yaml\r\ninit_config:\r\ninstances:\r\n  - kafka_connect_str: localhost:9092\r\n    zk_connect_str: localhost:2181\r\n    consumer_groups:\r\n      CG_BILLING_EVENTS_TOPIC_REPLICATOR:\r\n        billing_events: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\r\n    monitor_unlisted_consumer_groups: false\r\n    kafka_consumer_offsets: true\r\n    security_protocol: PLAINTEXT\r\n    sasl_mechanism: PLAIN\r\n    sasl_plain_username: <MY_USERNAME>\r\n    sasl_plain_password: <MY_PASSWORD>\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3693", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3693/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3693/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3693/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3693", "id": 438092740, "node_id": "MDU6SXNzdWU0MzgwOTI3NDA=", "number": 3693, "title": "Nginx logging broken", "user": {"login": "Matt-Yorkley", "id": 9029026, "node_id": "MDQ6VXNlcjkwMjkwMjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/9029026?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Matt-Yorkley", "html_url": "https://github.com/Matt-Yorkley", "followers_url": "https://api.github.com/users/Matt-Yorkley/followers", "following_url": "https://api.github.com/users/Matt-Yorkley/following{/other_user}", "gists_url": "https://api.github.com/users/Matt-Yorkley/gists{/gist_id}", "starred_url": "https://api.github.com/users/Matt-Yorkley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Matt-Yorkley/subscriptions", "organizations_url": "https://api.github.com/users/Matt-Yorkley/orgs", "repos_url": "https://api.github.com/users/Matt-Yorkley/repos", "events_url": "https://api.github.com/users/Matt-Yorkley/events{/privacy}", "received_events_url": "https://api.github.com/users/Matt-Yorkley/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 293952856, "node_id": "MDU6TGFiZWwyOTM5NTI4NTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/bug", "name": "kind/bug", "color": "b60205", "default": false, "description": ""}, {"id": 1437534848, "node_id": "MDU6TGFiZWwxNDM3NTM0ODQ4", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/logs", "name": "logs", "color": "ed538b", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-28T19:45:53Z", "updated_at": "2019-07-10T12:16:58Z", "closed_at": "2019-07-10T12:16:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "When following the linked advice for nginx logging, the log processing breaks.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Follow the advice for improving nginx logging in: https://www.datadoghq.com/blog/how-to-collect-nginx-metrics/#metrics-collection-nginx-logs\r\n2. Check nginx log entries\r\n3. Processing is broken, no attributes are shown\r\n\r\nIt can be fixed again by the user with these steps:\r\n- Clone the nginx log pipeline\r\n- Edit `Grok Parser: Parsing Nginx logs`\r\n- In parsing rules, add this line after the `access.combined ...` line: `access.nginx %{access.common} %{_response_time} \"%{_referer}\" \"%{_user_agent}\"( \"%{_x_forwarded_for}\")?.*`\r\n- Go to Advanced Rules -> Helper Rules\r\n- Add the line: `_response_time %{number:duration}`\r\n\r\n**Describe the results you expected:**\r\n\r\nIt would be great if either:\r\n- the default nginx parsing rules included these lines by default, so they don't break\r\n- the linked article explained how to un-break the log parsing", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3681", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3681/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3681/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3681/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3681", "id": 437433960, "node_id": "MDU6SXNzdWU0Mzc0MzM5NjA=", "number": 3681, "title": "Elastic integration spams logs when using self-signed certificates", "user": {"login": "rafaelmagu", "id": 197444, "node_id": "MDQ6VXNlcjE5NzQ0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/197444?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rafaelmagu", "html_url": "https://github.com/rafaelmagu", "followers_url": "https://api.github.com/users/rafaelmagu/followers", "following_url": "https://api.github.com/users/rafaelmagu/following{/other_user}", "gists_url": "https://api.github.com/users/rafaelmagu/gists{/gist_id}", "starred_url": "https://api.github.com/users/rafaelmagu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rafaelmagu/subscriptions", "organizations_url": "https://api.github.com/users/rafaelmagu/orgs", "repos_url": "https://api.github.com/users/rafaelmagu/repos", "events_url": "https://api.github.com/users/rafaelmagu/events{/privacy}", "received_events_url": "https://api.github.com/users/rafaelmagu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-04-25T23:10:24Z", "updated_at": "2019-05-27T04:06:35Z", "closed_at": "2019-05-27T04:06:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "If I turn on the Elasticsearch integration in the v6 agent for our Search Guard-secured cluster using private-CA certificates, the integration complains because `ssl_verify` is set to `false` (otherwise the requests fail).\r\n\r\n```text\r\n...\r\nApr 25 22:50:46 elastic-0e8457e75409d1fcd agent[1187]: /opt/datadog-agent/embedded/lib/python2.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\r\n...\r\n```\r\n\r\n### Additional environment details (Operating System, Cloud provider, etc)\r\nUbuntu 18.04, ES 6.3.2, Search Guard 24.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Set up ES cluster with self-signed certificates\r\n2. Enable elastic monitoring in the agent\r\n\r\n## Notes\r\nI know [this has been addressed in the http check](https://github.com/DataDog/integrations-core/pull/1574), but it seems the fix has not been applied here.\r\n\r\nMy suggestion is to allow me to pass a custom CA bundle for each instance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3668", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3668/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3668/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3668/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3668", "id": 436411013, "node_id": "MDU6SXNzdWU0MzY0MTEwMTM=", "number": 3668, "title": "Error in cadvisor when pod not returned from Kubelet", "user": {"login": "jonmoter", "id": 1056506, "node_id": "MDQ6VXNlcjEwNTY1MDY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1056506?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonmoter", "html_url": "https://github.com/jonmoter", "followers_url": "https://api.github.com/users/jonmoter/followers", "following_url": "https://api.github.com/users/jonmoter/following{/other_user}", "gists_url": "https://api.github.com/users/jonmoter/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonmoter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonmoter/subscriptions", "organizations_url": "https://api.github.com/users/jonmoter/orgs", "repos_url": "https://api.github.com/users/jonmoter/repos", "events_url": "https://api.github.com/users/jonmoter/events{/privacy}", "received_events_url": "https://api.github.com/users/jonmoter/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 592413329, "node_id": "MDU6TGFiZWw1OTI0MTMzMjk=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/containers", "name": "containers", "color": "0052cc", "default": false, "description": null}, {"id": 936572172, "node_id": "MDU6TGFiZWw5MzY1NzIxNzI=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/kubelet", "name": "integration/kubelet", "color": "bfdadc", "default": false, "description": ""}, {"id": 293952856, "node_id": "MDU6TGFiZWwyOTM5NTI4NTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/bug", "name": "kind/bug", "color": "b60205", "default": false, "description": ""}, {"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-23T22:07:51Z", "updated_at": "2020-02-11T15:15:43Z", "closed_at": "2020-02-11T15:15:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\nHere's the top section of the output; I'm not comfortable giving the full output in a public github issue:\r\n\r\n```text\r\nExecuting command on datadog-22sn7\r\nGetting the status from the agent.\r\n\r\n============================\r\nAgent (v6.10.3-logs-api-key)\r\n============================\r\n\r\n  Status date: 2019-04-23 21:37:09.208728 UTC\r\n  Pid: 387\r\n  Python Version: 2.7.15\r\n  Logs:\r\n  Check Runners: 16\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -999\u00b5s\r\n    System UTC time: 2019-04-23 21:37:09.208728 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-04-15 22:59:20.000000 UTC\r\n    kernelVersion: 4.4.0-1079-aws\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: buster/sid\r\n    procs: 463\r\n    uptime: 187h11m27s\r\n    virtualizationRole: guest\r\n    virtualizationSystem: xen\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n\r\nRunning Kubernetes v1.11.9 in AWS.\r\n\r\n** Info about the issue**\r\n\r\nIn our logs, I see a lot of errors like:\r\n\r\n```\r\n[ AGENT ] 2019-04-23 17:03:59 UTC | ERROR | (pkg/collector/py/datadog_agent.go:146 in LogMessage) | (cadvisor.py:108) | Unable to collect metrics for container: 27f509fdbca861480227545dddd5c14e35b402470437fc335ce4d6af7dedc31e ('NoneType' object has no attribute 'get')\r\n```\r\n\r\nI'm pretty sure that maps to this line of cadvisor.py: https://github.com/DataDog/integrations-core/blob/1288ba846c6b3c77c94d72e9ce7e6eb223828c9a/kubelet/datadog_checks/kubelet/cadvisor.py#L108\r\n\r\nLooking through [this block of code](https://github.com/DataDog/integrations-core/blob/6.10.x/kubelet/datadog_checks/kubelet/cadvisor.py#L157-L179), I see these lines:\r\n\r\n```python\r\n        pod = get_pod_by_uid(pod_uid, pod_list)\r\n        if pod is not None and is_static_pending_pod(pod):\r\n            in_static_pod = True\r\n```\r\nwhich implies to me that `pod` can be `None`.  But then about 12 lines later in the `else` clause of your switch statement, you're calling:\r\n```python\r\n        else:  # Standard container\r\n            cid = pod_list_utils.get_cid_by_name_tuple(\r\n                (pod.get('metadata', {}).get('namespace', \"\"),\r\n                 pod.get('metadata', {}).get('name', \"\"), k_container_name))\r\n```\r\n\r\nWhich means you might be calling `get` on an instance of `NoneType`.\r\n\r\nI believe this occurs when cadvisor reports metrics on a container that is not returned by kubelet. I think this could happen if you're running a static pod on the host.\r\n\r\nLet me know if you need any additional information.\r\n\r\ncc @dndungu, who has opened a ticket with Datadog support about this issue\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3619", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3619/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3619/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3619/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3619", "id": 432618840, "node_id": "MDU6SXNzdWU0MzI2MTg4NDA=", "number": 3619, "title": "Conntrack collection paths should be configurable", "user": {"login": "midN", "id": 6074297, "node_id": "MDQ6VXNlcjYwNzQyOTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/6074297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/midN", "html_url": "https://github.com/midN", "followers_url": "https://api.github.com/users/midN/followers", "following_url": "https://api.github.com/users/midN/following{/other_user}", "gists_url": "https://api.github.com/users/midN/gists{/gist_id}", "starred_url": "https://api.github.com/users/midN/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/midN/subscriptions", "organizations_url": "https://api.github.com/users/midN/orgs", "repos_url": "https://api.github.com/users/midN/repos", "events_url": "https://api.github.com/users/midN/events{/privacy}", "received_events_url": "https://api.github.com/users/midN/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-12T15:19:26Z", "updated_at": "2019-05-20T07:53:15Z", "closed_at": "2019-05-20T07:53:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Current conntrack max and count collection paths are hardcoded and are incorrect for a lot of Linux distributions.\r\n\r\n# Problem\r\nCurrent values: https://github.com/DataDog/integrations-core/blob/0cc48d4bc47cb4b288fff1152941913db069a642/network/datadog_checks/network/network.py#L441\r\n```\r\n2019-04-12 15:14:06 UTC | DEBUG | (pkg/collector/py/datadog_agent.go:152 in LogMessage) | (network.py:454) | Unable to read /proc/net/nf_conntrack. Skipping conntrack metrics pull.\r\n```\r\n\r\n# Example:\r\nOS: `Ubuntu 16.04.2 LTS`\r\nPackage: `conntrack`\r\nPlaces conntrack metrics/data under following path:\r\n```\r\nls /proc/sys/net/netfilter/nf_conntrack_*\r\n```\r\n\r\n# Solution\r\nEither:\r\na) Update check to read multiple common paths for all linux distributions.\r\nb) Update check to have conntrack max and count paths/files configurable in network config.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3614", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3614/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3614/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3614/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3614", "id": 432481635, "node_id": "MDU6SXNzdWU0MzI0ODE2MzU=", "number": 3614, "title": "[mongodb] False NetworkTimeout exception on a Mongo node that is resyncing", "user": {"login": "skijash", "id": 2774306, "node_id": "MDQ6VXNlcjI3NzQzMDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/2774306?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skijash", "html_url": "https://github.com/skijash", "followers_url": "https://api.github.com/users/skijash/followers", "following_url": "https://api.github.com/users/skijash/following{/other_user}", "gists_url": "https://api.github.com/users/skijash/gists{/gist_id}", "starred_url": "https://api.github.com/users/skijash/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skijash/subscriptions", "organizations_url": "https://api.github.com/users/skijash/orgs", "repos_url": "https://api.github.com/users/skijash/repos", "events_url": "https://api.github.com/users/skijash/events{/privacy}", "received_events_url": "https://api.github.com/users/skijash/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 752542943, "node_id": "MDU6TGFiZWw3NTI1NDI5NDM=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/stale", "name": "stale", "color": "d93f0b", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-12T09:17:17Z", "updated_at": "2019-07-05T12:20:32Z", "closed_at": "2019-07-05T12:20:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nIf you suspect your issue is a bug, please attach the output of the Agent status page,\r\nsee https://docs.datadoghq.com/agent/faq/agent-commands/#agent-information\r\n-->\r\n\r\n**Output of the info page (if this is a bug)**\r\n```\r\n==============\r\nAgent (v6.9.0)\r\n==============\r\n\r\n  Status date: 2019-04-12 09:02:14.515396 UTC\r\n  Pid: 17092\r\n  Python Version: 2.7.15\r\n  Logs:\r\n  Check Runners: 4\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 2.088ms\r\n    System UTC time: 2019-04-12 09:02:14.515396 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-04-12 06:50:30.000000 UTC\r\n    kernelVersion: 4.4.0-1079-aws\r\n    os: linux\r\n    platform: ubuntu\r\n    platformFamily: debian\r\n    platformVersion: 16.04\r\n    procs: 243\r\n    uptime: 1h10m23s\r\n    virtualizationRole: guest\r\n    virtualizationSystem: xen\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ip-10-0-200-207.us-west-1.compute.internal\r\n    hostname: i-0e48cff41937ff4fe\r\n    instance-id: i-0e48cff41937ff4fe\r\n    socket-fqdn: ip-10-0-200-207.us-west-1.compute.internal.\r\n    socket-hostname: ip-10-0-200-207\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n\r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Total Runs: 245\r\n      Metric Samples: Last Run: 6, Total: 1,464\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    disk (2.0.1)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [OK]\r\n      Total Runs: 245\r\n      Metric Samples: Last Run: 118, Total: 28,910\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 20ms\r\n\r\n\r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Total Runs: 245\r\n      Metric Samples: Last Run: 5, Total: 1,225\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Total Runs: 245\r\n      Metric Samples: Last Run: 52, Total: 12,704\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 5ms\r\n\r\n\r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Total Runs: 246\r\n      Metric Samples: Last Run: 6, Total: 1,476\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Total Runs: 245\r\n      Metric Samples: Last Run: 17, Total: 4,165\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    mongo (1.7.0)\r\n    -------------\r\n      Instance ID: mongo:a2b3e6885ac503ed [ERROR]\r\n      Total Runs: 82\r\n      Metric Samples: Last Run: 0, Total: 27\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 82\r\n      Average Execution Time : 30.033s\r\n      Error: localhost:27017: timed out\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 387, in run\r\n          self.check(copy.deepcopy(self.instances[0]))\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/mongo/mongo.py\", line 768, in check\r\n          status = db.command('serverStatus', tcmalloc=collect_tcmalloc_metrics)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/pymongo/database.py\", line 516, in command\r\n          codec_options, **kwargs)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/pymongo/database.py\", line 428, in _command\r\n          parse_write_concern_error=parse_write_concern_error)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/pymongo/pool.py\", line 482, in command\r\n          self._raise_connection_failure(error)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/pymongo/pool.py\", line 608, in _raise_connection_failure\r\n          _raise_connection_failure(self.address, error)\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/pymongo/pool.py\", line 259, in _raise_connection_failure\r\n          raise NetworkTimeout(msg)\r\n      NetworkTimeout: localhost:27017: timed out\r\n\r\n    network (1.8.0)\r\n    ---------------\r\n      Instance ID: network:2a218184ebe03606 [OK]\r\n      Total Runs: 246\r\n      Metric Samples: Last Run: 20, Total: 4,920\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n\r\n    ntp\r\n    ---\r\n      Instance ID: ntp:b4579e02d1981c12 [OK]\r\n      Total Runs: 245\r\n      Metric Samples: Last Run: 1, Total: 245\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 245\r\n      Average Execution Time : 7ms\r\n\r\n\r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Total Runs: 246\r\n      Metric Samples: Last Run: 1, Total: 246\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n\r\n  Failed checks\r\n  =============\r\n    no checks\r\n\r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 245\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 20\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 510\r\n    TimeseriesV1: 245\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with b0961: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - b0961\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 59,481\r\n  Dogstatsd Metric Sample: 3,059\r\n  Event: 1\r\n  Events Flushed: 1\r\n  Number Of Flushes: 245\r\n  Series Flushed: 53,468\r\n  Service Check: 2,377\r\n  Service Checks Flushed: 2,616\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 3,059\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 3,060\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n```\r\n\r\n**Describe what happened:**\r\nOn a Mongo node which is resyncing data (so it is in OTHER state, not SECONDARY), the agent is reporting `NetworkTimeout: localhost:27017: timed out` which isn't true. I am able to connect to Mongo shell on localhost:27017.\r\n\r\n\r\n**Describe what you expected:**\r\nOn running `datadog-agent status`, I would expect it to not throw an exception, but to report that the node is up, just not responding to stats queries.\r\n\r\n\r\n**Steps to reproduce the issue:**\r\nHave the agent running on a mongo node, with mongo integration active, delete the data directory and restart mongo service so it starts resyncing data. On running `datadog-agent status`, you should get the `NetworkTimeout: localhost:27017: timed out` exception.\r\n\r\n\r\n**Additional details:**\r\nWe have a monitor alerting us on high values of `mongodb.opcounters.updateps'. That monitor is alerting that it has `No data`. Looking at the agent code, I believe the reason is:\r\n* the agent opens a connection, preferring the primary, but it got localhost, which is in startup state\r\n* lists the databases\r\n* runs the stats command on a db, but gets no response, since the db is not operational\r\n* timeouts and reports a NetworkTimeout somewhere down the stack\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3609", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3609/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3609/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3609/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3609", "id": 432014444, "node_id": "MDU6SXNzdWU0MzIwMTQ0NDQ=", "number": 3609, "title": "Unable to detect the kubelet URL automatically", "user": {"login": "hden", "id": 1910549, "node_id": "MDQ6VXNlcjE5MTA1NDk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1910549?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hden", "html_url": "https://github.com/hden", "followers_url": "https://api.github.com/users/hden/followers", "following_url": "https://api.github.com/users/hden/following{/other_user}", "gists_url": "https://api.github.com/users/hden/gists{/gist_id}", "starred_url": "https://api.github.com/users/hden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hden/subscriptions", "organizations_url": "https://api.github.com/users/hden/orgs", "repos_url": "https://api.github.com/users/hden/repos", "events_url": "https://api.github.com/users/hden/events{/privacy}", "received_events_url": "https://api.github.com/users/hden/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-04-11T13:09:31Z", "updated_at": "2019-04-18T09:00:21Z", "closed_at": "2019-04-18T09:00:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```text\r\nGetting the status from the agent.\r\n\r\n===============\r\nAgent (v6.10.2)\r\n===============\r\n\r\n  Status date: 2019-04-11 13:04:51.894541 UTC\r\n  Pid: 376\r\n  Python Version: 2.7.15\r\n  Logs: \r\n  Check Runners: 4\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: -399\u00b5s\r\n    System UTC time: 2019-04-11 13:04:51.894541 UTC\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-04-09 01:35:59.000000 UTC\r\n    kernelVersion: 4.14.104-95.84.amzn2.x86_64\r\n    os: linux\r\n    platform: debian\r\n    platformFamily: debian\r\n    platformVersion: buster/sid\r\n    procs: 71\r\n    uptime: 59h23m57s\r\n\r\n  Hostnames\r\n  =========\r\n    ec2-hostname: ip-192-168-95-176.ap-northeast-1.compute.internal\r\n    hostname: i-0edb28b7904a45eb3\r\n    instance-id: i-0edb28b7904a45eb3\r\n    socket-fqdn: datadog-agent-4dfn2\r\n    socket-hostname: datadog-agent-4dfn2\r\n    hostname provider: aws\r\n    unused hostname providers:\r\n      configuration/environment: hostname is empty\r\n      gce: unable to retrieve hostname from GCE: status code 404 trying to GET http://169.254.169.254/computeMetadata/v1/instance/hostname\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    cpu\r\n    ---\r\n      Instance ID: cpu [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 20\r\n      Metric Samples: Last Run: 6, Total: 114\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    disk (2.1.0)\r\n    ------------\r\n      Instance ID: disk:e5dffb8bef24336f [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 20\r\n      Metric Samples: Last Run: 190, Total: 3,800\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 93ms\r\n      \r\n    \r\n    docker\r\n    ------\r\n      Instance ID: docker [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 19\r\n      Metric Samples: Last Run: 48, Total: 912\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 19\r\n      Average Execution Time : 37ms\r\n      \r\n    \r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 20\r\n      Metric Samples: Last Run: 5, Total: 100\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    io\r\n    --\r\n      Instance ID: io [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 19\r\n      Metric Samples: Last Run: 39, Total: 714\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    kubelet (2.4.0)\r\n    ---------------\r\n      Instance ID: kubelet:d884b5186b651429 [\u001b[31mERROR\u001b[0m]\r\n      Total Runs: 20\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 6ms\r\n      Error: Unable to detect the kubelet URL automatically.\r\n      Traceback (most recent call last):\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/base/checks/base.py\", line 774, in run\r\n          self.check(copy.deepcopy(self.instances[0]))\r\n        File \"/opt/datadog-agent/embedded/lib/python2.7/site-packages/datadog_checks/kubelet/kubelet.py\", line 124, in check\r\n          raise CheckException(\"Unable to detect the kubelet URL automatically.\")\r\n      CheckException: Unable to detect the kubelet URL automatically.\r\n    \r\n    kubernetes_apiserver\r\n    --------------------\r\n      Instance ID: kubernetes_apiserver [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 19\r\n      Metric Samples: Last Run: 0, Total: 0\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    load\r\n    ----\r\n      Instance ID: load [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 20\r\n      Metric Samples: Last Run: 6, Total: 120\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    memory\r\n    ------\r\n      Instance ID: memory [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 19\r\n      Metric Samples: Last Run: 17, Total: 323\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    network (1.9.0)\r\n    ---------------\r\n      Instance ID: network:2a218184ebe03606 [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 20\r\n      Metric Samples: Last Run: 33, Total: 660\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 2ms\r\n      \r\n    \r\n    ntp\r\n    ---\r\n      Instance ID: ntp:b4579e02d1981c12 [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 19\r\n      Metric Samples: Last Run: 1, Total: 19\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 19\r\n      Average Execution Time : 3ms\r\n      \r\n    \r\n    uptime\r\n    ------\r\n      Instance ID: uptime [\u001b[32mOK\u001b[0m]\r\n      Total Runs: 20\r\n      Metric Samples: Last Run: 1, Total: 20\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n    \r\n  Failed checks\r\n  =============\r\n    no checks\r\n    \r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 19\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 2\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 40\r\n    TimeseriesV1: 19\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with d4cbe: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - d4cbe\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  container_collect_all\r\n  ---------------------\r\n    Type: docker\r\n    Status: Pending\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 7,215\r\n  Dogstatsd Metric Sample: 48\r\n  Event: 1\r\n  Events Flushed: 1\r\n  Number Of Flushes: 19\r\n  Series Flushed: 3,531\r\n  Service Check: 255\r\n  Service Checks Flushed: 262\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 48\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 49\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n\r\n=====================\r\nDatadog Cluster Agent\r\n=====================\r\n\r\n  - Datadog Cluster Agent endpoint detected: https://10.100.238.126:5005\r\n  Successfully connected to the Datadog Cluster Agent.\r\n  - Running: {Major:1 Minor:2 Patch:0 Pre: Meta: Commit:52053af}\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nKubernetes 1.12 cluster on EKS.\r\n\r\n**Steps to reproduce the issue:**\r\n1. Deploy the Datadog agent using the provider Kubernetes resources.\r\n2. View logs\r\n\r\n**Describe the results you received:**\r\nhttps://gist.github.com/hden/9a947fd838d3e72c21f842ee8c4082bd\r\nMany dashboard entries remain empty.\r\n\r\n**Describe the results you expected:**\r\nNo errors, access to kubelet, functional Kubernetes dashboard.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nSeems to be the same problem as #2582. Tried `DD_KUBELET_TLS_VERIFY=false` and `DD_KUBERNETES_KUBELET_HOST -> spec.nodeName`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3476", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3476/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3476/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3476/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3476", "id": 429896519, "node_id": "MDU6SXNzdWU0Mjk4OTY1MTk=", "number": 3476, "title": "Pod/Deployment Labels to Kube_State_Metrics", "user": {"login": "midN", "id": 6074297, "node_id": "MDQ6VXNlcjYwNzQyOTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/6074297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/midN", "html_url": "https://github.com/midN", "followers_url": "https://api.github.com/users/midN/followers", "following_url": "https://api.github.com/users/midN/following{/other_user}", "gists_url": "https://api.github.com/users/midN/gists{/gist_id}", "starred_url": "https://api.github.com/users/midN/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/midN/subscriptions", "organizations_url": "https://api.github.com/users/midN/orgs", "repos_url": "https://api.github.com/users/midN/repos", "events_url": "https://api.github.com/users/midN/events{/privacy}", "received_events_url": "https://api.github.com/users/midN/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 592413329, "node_id": "MDU6TGFiZWw1OTI0MTMzMjk=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/containers", "name": "containers", "color": "0052cc", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2019-04-05T19:10:21Z", "updated_at": "2020-02-12T18:18:38Z", "closed_at": "2020-02-12T18:18:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "Currently, Kube_State_Metrics collected by Datadog are basic metrics without additional labels.\r\n\r\nMost of those metrics are extremely simple and limited to labels such as Name and Deployment.\r\n\r\nAs a result, it's impossible to filter out in Dashboards nor Monitoring some Deployments/Daemonsets based on extra Labels.\r\nAnd that's despite Agent having an option to provide \"DD_KUBERNETES_POD_LABELS_AS_TAGS\" environment variable.\r\nProvided tags in ENV variable are only applied to metrics collected directly from Kubernetes API.\r\n\r\n---------------------\r\n\r\nSolution:\r\nParse ignored INFO metrics containing extra labels per deployment/pod/daemonset - https://github.com/DataDog/integrations-core/blob/301111499c051fa1f4c7d783b3eae8568429ab97/kubernetes_state/datadog_checks/kubernetes_state/kubernetes_state.py#L185\r\n\r\nAnd add those as tags to original metrics.\r\n\r\n--------------------\r\n\r\nFYI: You can do so in Prometheus by grouping Pod metrics with PodInfo metrics for example.\r\nExamples of doing so are in kube-state-metrics repo.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3462", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3462/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3462/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3462/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3462", "id": 429406819, "node_id": "MDU6SXNzdWU0Mjk0MDY4MTk=", "number": 3462, "title": "Consul metrics do not always honor hostname or hostname_fqdn.", "user": {"login": "ebusto", "id": 8902413, "node_id": "MDQ6VXNlcjg5MDI0MTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/8902413?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebusto", "html_url": "https://github.com/ebusto", "followers_url": "https://api.github.com/users/ebusto/followers", "following_url": "https://api.github.com/users/ebusto/following{/other_user}", "gists_url": "https://api.github.com/users/ebusto/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebusto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebusto/subscriptions", "organizations_url": "https://api.github.com/users/ebusto/orgs", "repos_url": "https://api.github.com/users/ebusto/repos", "events_url": "https://api.github.com/users/ebusto/events{/privacy}", "received_events_url": "https://api.github.com/users/ebusto/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 936565341, "node_id": "MDU6TGFiZWw5MzY1NjUzNDE=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/integration/consul", "name": "integration/consul", "color": "bfdadc", "default": false, "description": ""}, {"id": 293952856, "node_id": "MDU6TGFiZWwyOTM5NTI4NTY=", "url": "https://api.github.com/repos/DataDog/integrations-core/labels/kind/bug", "name": "kind/bug", "color": "b60205", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-04T17:51:26Z", "updated_at": "2019-07-15T16:38:30Z", "closed_at": "2019-07-15T16:38:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n```Getting the status from the agent.\r\n\r\n===============\r\nAgent (v6.10.2)\r\n===============\r\n\r\n  Status date: 2019-04-04 10:46:27.365443 PDT\r\n  Pid: 30544\r\n  Python Version: 2.7.15\r\n  Logs: \r\n  Check Runners: 4\r\n  Log Level: info\r\n\r\n  Paths\r\n  =====\r\n    Config File: /etc/datadog-agent/datadog.yaml\r\n    conf.d: /etc/datadog-agent/conf.d\r\n    checks.d: /etc/datadog-agent/checks.d\r\n\r\n  Clocks\r\n  ======\r\n    NTP offset: 2.892ms\r\n    System UTC time: 2019-04-04 10:46:27.365443 PDT\r\n\r\n  Host Info\r\n  =========\r\n    bootTime: 2019-03-06 14:11:54.000000 PST\r\n    kernelVersion: 4.4.0-131-generic\r\n    os: linux\r\n    platform: ubuntu\r\n    platformFamily: debian\r\n    platformVersion: 16.04\r\n    procs: 291\r\n    uptime: 691h30m13s\r\n\r\n  Hostnames\r\n  =========\r\n    hostname: sc-it-netbox-01.nvidia.com\r\n    socket-fqdn: sc-it-netbox-01.nvidia.com.\r\n    socket-hostname: sc-it-netbox-01\r\n    hostname provider: configuration\r\n\r\n=========\r\nCollector\r\n=========\r\n\r\n  Running Checks\r\n  ==============\r\n    \r\n    consul (1.7.0)\r\n    --------------\r\n      Instance ID: consul:6eeb2cb1e4cb614d [OK]\r\n      Total Runs: 18\r\n      Metric Samples: Last Run: 57, Total: 1,026\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 16, Total: 289\r\n      Average Execution Time : 22ms\r\n      \r\n    \r\n    cpu\r\n    ---\r\n      Instance ID: cpu [OK]\r\n      Total Runs: 18\r\n      Metric Samples: Last Run: 6, Total: 102\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    disk (2.1.0)\r\n    ------------\r\n      Instance ID: disk:47614be83f4d6ddf [OK]\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 64, Total: 1,088\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 8ms\r\n      \r\n    \r\n    docker\r\n    ------\r\n      Instance ID: docker [OK]\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 142, Total: 2,414\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 17\r\n      Average Execution Time : 11ms\r\n      \r\n    \r\n    file_handle\r\n    -----------\r\n      Instance ID: file_handle [OK]\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 5, Total: 85\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    gunicorn (1.6.0)\r\n    ----------------\r\n      Instance ID: gunicorn:ea802015eed142e7 [OK]\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 2, Total: 34\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 17\r\n      Average Execution Time : 130ms\r\n      \r\n    \r\n    io\r\n    --\r\n      Instance ID: io [OK]\r\n      Total Runs: 18\r\n      Metric Samples: Last Run: 91, Total: 1,575\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    load\r\n    ----\r\n      Instance ID: load [OK]\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 6, Total: 102\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    memory\r\n    ------\r\n      Instance ID: memory [OK]\r\n      Total Runs: 18\r\n      Metric Samples: Last Run: 17, Total: 306\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n    \r\n    network (1.9.0)\r\n    ---------------\r\n      Instance ID: network:1a746eb44bf6fb0d [OK]\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 47, Total: 799\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 6ms\r\n      \r\n    \r\n    nginx (3.1.0)\r\n    -------------\r\n      Instance ID: nginx:27a01882b1b4b00c [OK]\r\n      Total Runs: 18\r\n      Metric Samples: Last Run: 7, Total: 126\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 18\r\n      Average Execution Time : 11ms\r\n      \r\n    \r\n    ntp\r\n    ---\r\n      Instance ID: ntp:b4579e02d1981c12 [OK]\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 1, Total: 17\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 17\r\n      Average Execution Time : 13ms\r\n      \r\n    \r\n    postgres (2.5.0)\r\n    ----------------\r\n      Instance ID: postgres:5430a4e9ffe0ac [OK]\r\n      Total Runs: 17\r\n      Metric Samples: Last Run: 30, Total: 510\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 1, Total: 17\r\n      Average Execution Time : 21ms\r\n      \r\n    \r\n    uptime\r\n    ------\r\n      Instance ID: uptime [OK]\r\n      Total Runs: 18\r\n      Metric Samples: Last Run: 1, Total: 18\r\n      Events: Last Run: 0, Total: 0\r\n      Service Checks: Last Run: 0, Total: 0\r\n      Average Execution Time : 0s\r\n      \r\n  Config Errors\r\n  ==============\r\n    process\r\n    -------\r\n      Configuration file contains no valid instances\r\n\r\n========\r\nJMXFetch\r\n========\r\n\r\n  Initialized checks\r\n  ==================\r\n    no checks\r\n    \r\n  Failed checks\r\n  =============\r\n    no checks\r\n    \r\n=========\r\nForwarder\r\n=========\r\n\r\n  Transactions\r\n  ============\r\n    CheckRunsV1: 17\r\n    Dropped: 0\r\n    DroppedOnInput: 0\r\n    Events: 0\r\n    HostMetadata: 0\r\n    IntakeV1: 2\r\n    Metadata: 0\r\n    Requeued: 0\r\n    Retried: 0\r\n    RetryQueueSize: 0\r\n    Series: 0\r\n    ServiceChecks: 0\r\n    SketchSeries: 0\r\n    Success: 36\r\n    TimeseriesV1: 17\r\n\r\n  API Keys status\r\n  ===============\r\n    API key ending with 28500: API Key valid\r\n\r\n==========\r\nEndpoints\r\n==========\r\n  https://app.datadoghq.com - API Key ending with:\r\n      - 28500\r\n\r\n==========\r\nLogs Agent\r\n==========\r\n\r\n  Logs Agent is not running\r\n\r\n=========\r\nAggregator\r\n=========\r\n  Checks Metric Sample: 8,657\r\n  Dogstatsd Metric Sample: 1,215\r\n  Event: 1\r\n  Events Flushed: 1\r\n  Number Of Flushes: 17\r\n  Series Flushed: 8,624\r\n  Service Check: 603\r\n  Service Checks Flushed: 595\r\n\r\n=========\r\nDogStatsD\r\n=========\r\n  Event Packets: 0\r\n  Event Parse Errors: 0\r\n  Metric Packets: 1,215\r\n  Metric Parse Errors: 0\r\n  Service Check Packets: 0\r\n  Service Check Parse Errors: 0\r\n  Udp Packet Reading Errors: 0\r\n  Udp Packets: 1,216\r\n  Uds Origin Detection Errors: 0\r\n  Uds Packet Reading Errors: 0\r\n  Uds Packets: 0\r\n```\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\nNone.\r\n\r\n**Steps to reproduce the issue:**\r\nConfigure the Datadog agent with a fully qualified hostname:\r\n```\r\n...\r\nhostname: sc-it-netbox-01.nvidia.com\r\nhostname_fqdn: true\r\n...\r\n```\r\n\r\n**Describe the results you received:**\r\nWhen the latency metrics are submitted, each node is tagged with the short hostname as the `host`, causing phantom hosts to show up in our infrastructure list with only a handful of Consul latency metrics.\r\n\r\n**Describe the results you expected:**\r\nThe node to be resolved to the fully qualified hostname, so that latency metrics roll up under existing hosts.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\nNone.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3440", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3440/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3440/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3440/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3440", "id": 428047774, "node_id": "MDU6SXNzdWU0MjgwNDc3NzQ=", "number": 3440, "title": "Fix the schema filtering in the configuration/query", "user": {"login": "fischaz", "id": 37970138, "node_id": "MDQ6VXNlcjM3OTcwMTM4", "avatar_url": "https://avatars3.githubusercontent.com/u/37970138?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fischaz", "html_url": "https://github.com/fischaz", "followers_url": "https://api.github.com/users/fischaz/followers", "following_url": "https://api.github.com/users/fischaz/following{/other_user}", "gists_url": "https://api.github.com/users/fischaz/gists{/gist_id}", "starred_url": "https://api.github.com/users/fischaz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fischaz/subscriptions", "organizations_url": "https://api.github.com/users/fischaz/orgs", "repos_url": "https://api.github.com/users/fischaz/repos", "events_url": "https://api.github.com/users/fischaz/events{/privacy}", "received_events_url": "https://api.github.com/users/fischaz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-04-02T06:34:30Z", "updated_at": "2019-04-24T13:44:54Z", "closed_at": "2019-04-24T13:44:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n- datadog docker agent 6.10.2\r\n- PGSQL 10\r\n- one database 'db'\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create PGSQL DB with 2 tables `public.users` and `private.users` (different schema)\r\n2. Create configuration for datadog with the db, and configure the relations to only look at one table (public.users) for example\r\n3. start agent\r\n4. run some activity on public.users\r\n\r\nexample of config:\r\n```\r\n    relations:\r\n      - relation_name: users\r\n        schemas:\r\n          - public\r\n```\r\n\r\n**Describe the results you received:**\r\n\r\nDepending on your luck, you may **not** receive any metric for the table public.users at all.\r\n\r\n**Describe the results you expected:**\r\n\r\nYou should receive metrics *only* for the `public.users` table and exclude the `private.users` table from the metrics collected.\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nThe issue of this ticket originally came from the bug in the `_query_scope` function during the processing of the returned rows.\r\n\r\nAt the time of the query to SQL, only the 'relations' names are used to limit the scope of the metrics returned, so in this case, although we want the table 'users', we'll get 2 rows from the SQL query metric. one for `public.users` and the other for `private.users`... \r\n\r\nThat's why the code will strip out 'bad' row that are not relevant to us:\r\n```\r\n        for row in results:\r\n            # Check that all columns will be processed\r\n            assert len(row) == len(cols) + len(desc)\r\n\r\n            # build a map of descriptors and their values\r\n            desc_map = dict(zip([x[1] for x in desc], row[0:len(desc)]))\r\n            if 'schema' in desc_map and relations:\r\n                try:\r\n                    relname = desc_map['table']\r\n                    config_schemas = relations_config[relname]['schemas']\r\n                    if config_schemas and desc_map['schema'] not in config_schemas:\r\n                        return len(results)\r\n                except KeyError:\r\n                    pass\r\n```\r\n\r\nthe issue here is that if the schema of the raw (desc_map['schema']) does not match the allowed schema in the configuration (`config_schemas = relations_config[relname]['schemas']`), the entire method return and **not** metric (well, the lucky loop iterations that managed to run will) will be pushed to datadog at all. \r\n\r\nit should at least 'continue' instead of 'return' to continue processing the remaining tables.\r\n\r\nSadly, I started fixing a few more things on the way:\r\n```\r\n--- postgres.py 2019-04-02 05:33:38.304563200 +0000\r\n+++ postgres.py.schema_filter   2019-04-02 06:29:53.691245600 +0000\r\n@@ -664,21 +664,28 @@\r\n         \"\"\"\r\n         config = {}\r\n         for element in yamlconfig:\r\n-            try:\r\n-                if isinstance(element, str):\r\n-                    config[element] = {'relation_name': element, 'schemas': []}\r\n-                elif isinstance(element, dict):\r\n-                    name = element['relation_name']\r\n-                    config[name] = {}\r\n-                    config[name]['schemas'] = element['schemas']\r\n-                    config[name]['relation_name'] = name\r\n-                else:\r\n-                    self.log.warning('Unhandled relations config type: {}'.format(element))\r\n-            except KeyError:\r\n-                self.log.warning('Failed to parse config element={}, check syntax'.format(element))\r\n+            if isinstance(element, str):\r\n+                config[element] = {\r\n+                    'relation_name': element,\r\n+                    'schemas': []\r\n+                }\r\n+            elif isinstance(element, dict):\r\n+                if 'relation_name' not in element or 'schemas' not in element:\r\n+                    self.log.warning(\"Unknown element format for relation element %s\", element)\r\n+                    continue\r\n+                if not isinstance(element['schemas'], list):\r\n+                    self.log.warning(\"Expected a list of schemas for %s\", element)\r\n+                    continue\r\n+                name = element['relation_name']\r\n+                config[name] = {\r\n+                    'relation_name': name,\r\n+                    'schemas': element['schemas'],\r\n+                }\r\n+            else:\r\n+                self.log.warning('Unhandled relations config type: {}'.format(element))\r\n         return config\r\n\r\n-    def _query_scope(self, cursor, scope, key, db, instance_tags, relations, is_custom_metrics, programming_error,\r\n+    def _query_scope(self, cursor, scope, key, db, instance_tags, is_custom_metrics, programming_error,\r\n                      relations_config):\r\n         if scope is None:\r\n             return None\r\n@@ -694,7 +701,7 @@\r\n\r\n         try:\r\n             # if this is a relation-specific query, we need to list all relations last\r\n-            if scope['relation'] and len(relations) > 0:\r\n+            if scope['relation'] and len(relations_config) > 0:\r\n                 relnames = ', '.join(\"'{0}'\".format(w) for w in relations_config)\r\n                 query = scope['query'] % (\", \".join(cols), \"%s\")  # Keep the last %s intact\r\n                 self.log.debug(\"Running query: %s with relations: %s\" % (query, relnames))\r\n@@ -726,20 +733,30 @@\r\n         # A row should look like this\r\n         # (descriptor, descriptor, ..., value, value, value, value, ...)\r\n         # with descriptor a PG relation or index name, which we use to create the tags\r\n+        valid_results_size = 0\r\n         for row in results:\r\n             # Check that all columns will be processed\r\n             assert len(row) == len(cols) + len(desc)\r\n\r\n             # build a map of descriptors and their values\r\n             desc_map = dict(zip([x[1] for x in desc], row[0:len(desc)]))\r\n-            if 'schema' in desc_map and relations:\r\n-                try:\r\n-                    relname = desc_map['table']\r\n-                    config_schemas = relations_config[relname]['schemas']\r\n-                    if config_schemas and desc_map['schema'] not in config_schemas:\r\n-                        return len(results)\r\n-                except KeyError:\r\n-                    pass\r\n+\r\n+            # if relations *and* schemas are set, filter out table not\r\n+            # matching the schema in the configuration\r\n+            if scope['relation'] and len(relations_config) > 0 and 'schema' in desc_map and 'table' in desc_map:\r\n+                row_table = desc_map['table']\r\n+                row_schema = desc_map['schema']\r\n+\r\n+                config_table_obj = relations_config.get(row_table)\r\n+                if not config_table_obj:\r\n+                    self.log.info(\"weird, got row %s.%s, but not relation\", row_schema, row_table)\r\n+                else:\r\n+                    config_schemas = config_table_obj.get('schemas')\r\n+                    if not config_schemas:\r\n+                        self.log.debug(\"all schemas are allowed for table %s.%s\", row_schema, row_table)\r\n+                    elif row_schema not in config_schemas:\r\n+                        self.log.debug(\"Skipping non match schema %s for table %s\", desc_map['schema'], row_table)\r\n+                        continue\r\n\r\n             # Build tags\r\n             # descriptors are: (pg_name, dd_tag_name): value\r\n@@ -762,8 +779,9 @@\r\n             # tags are\r\n             for v in zip([scope['metrics'][c] for c in cols], row[len(desc):]):\r\n                 v[0][1](self, v[0][0], v[1], tags=tags)\r\n+            valid_results_size += 1\r\n\r\n-        return len(results)\r\n+        return valid_results_size\r\n\r\n     def _collect_stats(self, key, db, instance_tags, relations, custom_metrics, collect_function_metrics,\r\n                        collect_count_metrics, collect_activity_metrics, collect_database_size_metrics,\r\n@@ -807,24 +825,24 @@\r\n\r\n         try:\r\n             cursor = db.cursor()\r\n-            results_len = self._query_scope(cursor, db_instance_metrics, key, db, instance_tags, relations,\r\n+            results_len = self._query_scope(cursor, db_instance_metrics, key, db, instance_tags,\r\n                                             False, programming_error, relations_config)\r\n             if results_len is not None:\r\n                 self.gauge(\"postgresql.db.count\", results_len,\r\n                            tags=[t for t in instance_tags if not t.startswith(\"db:\")])\r\n\r\n-            self._query_scope(cursor, bgw_instance_metrics, key, db, instance_tags, relations,\r\n+            self._query_scope(cursor, bgw_instance_metrics, key, db, instance_tags,\r\n                               False, programming_error, relations_config)\r\n-            self._query_scope(cursor, archiver_instance_metrics, key, db, instance_tags, relations,\r\n+            self._query_scope(cursor, archiver_instance_metrics, key, db, instance_tags,\r\n                               False, programming_error, relations_config)\r\n\r\n             if collect_activity_metrics:\r\n                 activity_metrics = self._get_activity_metrics(key, db)\r\n-                self._query_scope(cursor, activity_metrics, key, db, instance_tags, relations,\r\n+                self._query_scope(cursor, activity_metrics, key, db, instance_tags,\r\n                                   False, programming_error, relations_config)\r\n\r\n             for scope in list(metric_scope) + custom_metrics:\r\n-                self._query_scope(cursor, scope, key, db, instance_tags, relations,\r\n+                self._query_scope(cursor, scope, key, db, instance_tags,\r\n                                   scope in custom_metrics, programming_error, relations_config)\r\n\r\n             cursor.close()\r\n```\r\n\r\n** What does the patch do?\r\n\r\n- Better handling and loading of the 'relations' configuration (avoid catch KeyError and check for key instead). Better logging as well.\r\n- remove 'relations' parameter from the _query_scope method. The parameter relations_config is much better and contain the same information (assuming the config parsed well). Simplify the number of args in method.\r\n- Fix the schemas filtering when the relations_config is set and the scope['relations'] is True. If schema is not set (empty list), then all schemas are allowed (backward compat)\r\n- Fix thus the number of row returned as method result, excluding the filtered out rows (although really, this is only used to count number of db, so no impact)\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/DataDog/integrations-core/issues/3439", "repository_url": "https://api.github.com/repos/DataDog/integrations-core", "labels_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3439/labels{/name}", "comments_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3439/comments", "events_url": "https://api.github.com/repos/DataDog/integrations-core/issues/3439/events", "html_url": "https://github.com/DataDog/integrations-core/issues/3439", "id": 428041371, "node_id": "MDU6SXNzdWU0MjgwNDEzNzE=", "number": 3439, "title": "Do not hardcode datadog user in activity metrics", "user": {"login": "fischaz", "id": 37970138, "node_id": "MDQ6VXNlcjM3OTcwMTM4", "avatar_url": "https://avatars3.githubusercontent.com/u/37970138?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fischaz", "html_url": "https://github.com/fischaz", "followers_url": "https://api.github.com/users/fischaz/followers", "following_url": "https://api.github.com/users/fischaz/following{/other_user}", "gists_url": "https://api.github.com/users/fischaz/gists{/gist_id}", "starred_url": "https://api.github.com/users/fischaz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fischaz/subscriptions", "organizations_url": "https://api.github.com/users/fischaz/orgs", "repos_url": "https://api.github.com/users/fischaz/repos", "events_url": "https://api.github.com/users/fischaz/events{/privacy}", "received_events_url": "https://api.github.com/users/fischaz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-02T06:12:36Z", "updated_at": "2019-05-10T04:57:21Z", "closed_at": "2019-05-10T04:57:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Output of the [info page](https://docs.datadoghq.com/agent/guide/agent-commands/?tab=agentv6#agent-status-and-information)**\r\n\r\n**Additional environment details (Operating System, Cloud provider, etc):**\r\n- PGSQL 10\r\n- datadog docker agent 6.10.2\r\n\r\n\r\n**Steps to reproduce the issue:**\r\n1. Create `datadog2` PGSQL user with pg_monitor\r\n2. Configure datadog agent to connect to PGSQL with the user datadog2 (password and all correct)\r\n3. run datadog agent\r\n\r\n**Describe the results you received:**\r\n\r\nThe activity metrics will be off by one in terms of active connections and all. That is because the metric's query attempt to exclude itself from the result, but because the query excludes the hardcoded user 'datadog' from the query and we are running as the user 'datadog2' the exclusion process fails.\r\n\r\n**Describe the results you expected:**\r\nActivity metrics should regardless if the montoring user is called 'datadog' or 'mondog'\r\n\r\n\r\n**Additional information you deem important (e.g. issue happens only occasionally):**\r\n\r\nok, the patch this time is a bit more iffy as we use the format method to format the string, but it works. \r\n```\r\n--- postgres.py 2019-04-02 05:33:38.304563200 +0000\r\n+++ postgres.py.dduser  2019-04-02 06:11:31.520570700 +0000\r\n@@ -313,7 +313,7 @@\r\n     ACTIVITY_METRICS_9_6 = [\r\n         \"SUM(CASE WHEN xact_start IS NOT NULL THEN 1 ELSE 0 END)\",\r\n         \"SUM(CASE WHEN state = 'idle in transaction' THEN 1 ELSE 0 END)\",\r\n-        \"COUNT(CASE WHEN state = 'active' AND (query !~ '^autovacuum:' AND usename NOT IN ('postgres', 'datadog'))\"\r\n+        \"COUNT(CASE WHEN state = 'active' AND (query !~ '^autovacuum:' AND usename NOT IN ('postgres', '{datadog_user}'))\"\r\n         \"THEN 1 ELSE null END )\",\r\n         \"COUNT(CASE WHEN wait_event is NOT NULL AND query !~ '^autovacuum:' THEN 1 ELSE null END )\",\r\n     ]\r\n@@ -322,7 +322,7 @@\r\n     ACTIVITY_METRICS_9_2 = [\r\n         \"SUM(CASE WHEN xact_start IS NOT NULL THEN 1 ELSE 0 END)\",\r\n         \"SUM(CASE WHEN state = 'idle in transaction' THEN 1 ELSE 0 END)\",\r\n-        \"COUNT(CASE WHEN state = 'active' AND (query !~ '^autovacuum:' AND usename NOT IN ('postgres', 'datadog'))\"\r\n+        \"COUNT(CASE WHEN state = 'active' AND (query !~ '^autovacuum:' AND usename NOT IN ('postgres', '{datadog_user}'))\"\r\n         \"THEN 1 ELSE null END )\",\r\n         \"COUNT(CASE WHEN waiting = 't' AND query !~ '^autovacuum:' THEN 1 ELSE null END )\",\r\n     ]\r\n@@ -331,7 +331,7 @@\r\n     ACTIVITY_METRICS_8_3 = [\r\n         \"SUM(CASE WHEN xact_start IS NOT NULL THEN 1 ELSE 0 END)\",\r\n         \"SUM(CASE WHEN current_query LIKE '<IDLE> in transaction' THEN 1 ELSE 0 END)\",\r\n-        \"COUNT(CASE WHEN state = 'active' AND (query !~ '^autovacuum:' AND usename NOT IN ('postgres', 'datadog'))\"\r\n+        \"COUNT(CASE WHEN state = 'active' AND (query !~ '^autovacuum:' AND usename NOT IN ('postgres', '{datadog_user}'))\"\r\n         \"THEN 1 ELSE null END )\",\r\n         \"COUNT(CASE WHEN waiting = 't' AND query !~ '^autovacuum:' THEN 1 ELSE null END )\",\r\n     ]\r\n@@ -340,7 +340,7 @@\r\n     ACTIVITY_METRICS_LT_8_3 = [\r\n         \"SUM(CASE WHEN query_start IS NOT NULL THEN 1 ELSE 0 END)\",\r\n         \"SUM(CASE WHEN current_query LIKE '<IDLE> in transaction' THEN 1 ELSE 0 END)\",\r\n-        \"COUNT(CASE WHEN state = 'active' AND (query !~ '^autovacuum:' AND usename NOT IN ('postgres', 'datadog'))\"\r\n+        \"COUNT(CASE WHEN state = 'active' AND (query !~ '^autovacuum:' AND usename NOT IN ('postgres', '{datadog_user}'))\"\r\n         \"THEN 1 ELSE null END )\",\r\n         \"COUNT(CASE WHEN waiting = 't' AND query !~ '^autovacuum:' THEN 1 ELSE null END )\",\r\n     ]\r\n@@ -626,7 +626,7 @@\r\n             metrics = self.replication_metrics.get(key)\r\n         return metrics\r\n\r\n-    def _get_activity_metrics(self, key, db):\r\n+    def _get_activity_metrics(self, key, db, dbuser):\r\n         \"\"\" Use ACTIVITY_METRICS_LT_8_3 or ACTIVITY_METRICS_8_3 or ACTIVITY_METRICS_9_2\r\n         depending on the postgres version in conjunction with ACTIVITY_QUERY_10 or ACTIVITY_QUERY_LT_10.\r\n         Uses a dictionnary to save the result for each instance\r\n@@ -645,6 +645,7 @@\r\n             else:\r\n                 metrics_query = self.ACTIVITY_METRICS_LT_8_3\r\n\r\n+            metrics_query = [q.format(datadog_user=dbuser) if 'datadog_user' in q else q for q in metrics_query]\r\n             metrics = {k: v for k, v in zip(metrics_query, self.ACTIVITY_DD_METRICS)}\r\n             self.activity_metrics[key] = (metrics, query)\r\n         else:\r\n@@ -765,7 +766,7 @@\r\n\r\n         return len(results)\r\n\r\n-    def _collect_stats(self, key, db, instance_tags, relations, custom_metrics, collect_function_metrics,\r\n+    def _collect_stats(self, key, db, dbuser, instance_tags, relations, custom_metrics, collect_function_metrics,\r\n                        collect_count_metrics, collect_activity_metrics, collect_database_size_metrics,\r\n                        collect_default_db, interface_error, programming_error):\r\n         \"\"\"Query pg_stat_* for various metrics\r\n@@ -819,7 +820,7 @@\r\n                               False, programming_error, relations_config)\r\n\r\n             if collect_activity_metrics:\r\n-                activity_metrics = self._get_activity_metrics(key, db)\r\n+                activity_metrics = self._get_activity_metrics(key, db, dbuser)\r\n                 self._query_scope(cursor, activity_metrics, key, db, instance_tags, relations,\r\n                                   False, programming_error, relations_config)\r\n\r\n@@ -1056,14 +1057,14 @@\r\n             db = self.get_connection(key, host, port, user, password, dbname, ssl, connect_fct, tags)\r\n             version = self._get_version(key, db)\r\n             self.log.debug(\"Running check against version %s\" % version)\r\n-            self._collect_stats(key, db, tags, relations, custom_metrics, collect_function_metrics,\r\n+            self._collect_stats(key, db, user, tags, relations, custom_metrics, collect_function_metrics,\r\n                                 collect_count_metrics, collect_activity_metrics, collect_database_size_metrics,\r\n                                 collect_default_db, interface_error, programming_error)\r\n             self._get_custom_queries(db, tags, custom_queries, programming_error)\r\n         except ShouldRestartException:\r\n             self.log.info(\"Resetting the connection\")\r\n             db = self.get_connection(key, host, port, user, password, dbname, ssl, connect_fct, tags, use_cached=False)\r\n-            self._collect_stats(key, db, tags, relations, custom_metrics, collect_function_metrics,\r\n+            self._collect_stats(key, db, user, tags, relations, custom_metrics, collect_function_metrics,\r\n                                 collect_count_metrics, collect_activity_metrics, collect_database_size_metrics,\r\n                                 collect_default_db, interface_error, programming_error)\r\n             self._get_custom_queries(db, tags, custom_queries, programming_error)\r\n```\r\n\r\nBut basically, we're just passing down the dbuser (user) variable from the configuration file loaded down to the activity metric to properly replace those and run the right exclusions.\r\n", "performed_via_github_app": null, "score": 1.0}]}