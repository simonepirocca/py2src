{"total_count": 26, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/62", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/62/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/62/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/62/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/62", "id": 523942690, "node_id": "MDU6SXNzdWU1MjM5NDI2OTA=", "number": 62, "title": "I can open an S3 file in root, but not in a subdirectory", "user": {"login": "davidparks21", "id": 964997, "node_id": "MDQ6VXNlcjk2NDk5Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/964997?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidparks21", "html_url": "https://github.com/davidparks21", "followers_url": "https://api.github.com/users/davidparks21/followers", "following_url": "https://api.github.com/users/davidparks21/following{/other_user}", "gists_url": "https://api.github.com/users/davidparks21/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidparks21/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidparks21/subscriptions", "organizations_url": "https://api.github.com/users/davidparks21/orgs", "repos_url": "https://api.github.com/users/davidparks21/repos", "events_url": "https://api.github.com/users/davidparks21/events{/privacy}", "received_events_url": "https://api.github.com/users/davidparks21/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-17T06:14:41Z", "updated_at": "2019-11-17T18:35:48Z", "closed_at": "2019-11-17T18:26:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "Originally posted here:\r\nhttps://stackoverflow.com/questions/57227152/opening-a-file-in-pyfilesystems-s3-filesystem-fails\r\n\r\nI'm able to open a file in the root of an S3 bucket without a problem, however I cannot open a file with a standard path prefix:\r\n\r\n```\r\n>>> s3fs.listdir('dfparks/test')\r\n['test.txt']\r\n>>> s3fs.open('dfparks/test/test.txt')\r\n```\r\n\r\nI get the error:\r\n\r\n```\r\nfs.errors.ResourceNotFound: resource 'dfparks/test/test.txt' not found\r\n```\r\n\r\nI've tried every variant of the path / s3 url I can think of but I always get the not found error.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/57", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/57/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/57/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/57/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/57", "id": 480299397, "node_id": "MDU6SXNzdWU0ODAyOTkzOTc=", "number": 57, "title": "tree() and walk() don't work with minio", "user": {"login": "pitrou", "id": 1721820, "node_id": "MDQ6VXNlcjE3MjE4MjA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1721820?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pitrou", "html_url": "https://github.com/pitrou", "followers_url": "https://api.github.com/users/pitrou/followers", "following_url": "https://api.github.com/users/pitrou/following{/other_user}", "gists_url": "https://api.github.com/users/pitrou/gists{/gist_id}", "starred_url": "https://api.github.com/users/pitrou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pitrou/subscriptions", "organizations_url": "https://api.github.com/users/pitrou/orgs", "repos_url": "https://api.github.com/users/pitrou/repos", "events_url": "https://api.github.com/users/pitrou/events{/privacy}", "received_events_url": "https://api.github.com/users/pitrou/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-08-13T18:22:26Z", "updated_at": "2019-11-17T11:59:47Z", "closed_at": "2019-11-17T11:59:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a file in `somedir/subdir`:\r\n```\r\n>>> list(fs.listdir('somedir/subdir'))                                                                                                                               \r\n['mkpass.py']\r\n```\r\n\r\nHowever neither walk() nor tree() are able to see it:\r\n```\r\n>>> list(fs.walk('somedir/subdir'))                                                                                                                                  \r\nTraceback (most recent call last):\r\n  File \"<ipython-input-39-f399f0a633b1>\", line 1, in <module>\r\n    list(fs.walk('somedir/subdir'))\r\n  File \"/home/antoine/miniconda3/envs/pyarrow/lib/python3.7/site-packages/fs/walk.py\", line 337, in walk\r\n    for dir_path, info in _walk:\r\n  File \"/home/antoine/miniconda3/envs/pyarrow/lib/python3.7/site-packages/fs/walk.py\", line 433, in _walk_breadth\r\n    for info in _scan(fs, dir_path, namespaces=namespaces):\r\n  File \"/home/antoine/miniconda3/envs/pyarrow/lib/python3.7/site-packages/fs/walk.py\", line 298, in _scan\r\n    six.reraise(type(error), error)\r\n  File \"/home/antoine/miniconda3/envs/pyarrow/lib/python3.7/site-packages/six.py\", line 692, in reraise\r\n    raise value.with_traceback(tb)\r\nResourceNotFound: resource '/somedir/subdir' not found\r\n\r\n>>> fs.tree()                                                                                                                                                        \r\n\u251c\u2500\u2500 somedir\r\n\u2502   \u2514\u2500\u2500 error (resource '/somedir' not found)\r\n\u2514\u2500\u2500 bench-amd.txt\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/46", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/46/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/46/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/46/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/46", "id": 380522083, "node_id": "MDU6SXNzdWUzODA1MjIwODM=", "number": 46, "title": "Makedirs fails against vanilla minio instance", "user": {"login": "mhworth", "id": 486126, "node_id": "MDQ6VXNlcjQ4NjEyNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/486126?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mhworth", "html_url": "https://github.com/mhworth", "followers_url": "https://api.github.com/users/mhworth/followers", "following_url": "https://api.github.com/users/mhworth/following{/other_user}", "gists_url": "https://api.github.com/users/mhworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/mhworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mhworth/subscriptions", "organizations_url": "https://api.github.com/users/mhworth/orgs", "repos_url": "https://api.github.com/users/mhworth/repos", "events_url": "https://api.github.com/users/mhworth/events{/privacy}", "received_events_url": "https://api.github.com/users/mhworth/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-14T03:38:26Z", "updated_at": "2018-12-04T02:30:13Z", "closed_at": "2018-11-23T14:08:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "If I have a minio server running like this:\r\n\r\n`docker run -e \"MINIO_ACCESS_KEY=test\" -e \"MINIO_SECRET_KEY=password\" -p 9001:9000 minio/minio server /data`\r\n\r\nThen the following simple example fails:\r\n\r\n```python \r\nfrom fs_s3fs import S3FS\r\n\r\nMINIO_URL = \"http://localhost:9001\"\r\ns3fs = S3FS('scratch', endpoint_url=MINIO_URL,\r\n         aws_access_key_id=\"test\",\r\n         aws_secret_access_key=\"password\")\r\n\r\ns3fs.client.create_bucket(Bucket=\"scratch\")\r\ns3fs.makedirs(\"test/object\")\r\nwith s3fs.open(\"test/object/file.log\", \"w\") as f:\r\n    f.write(\"foo\")\r\n```\r\n\r\nwith the following error:\r\n\r\n```\r\n$ python test_s3fs.py\r\n ...\r\nfs.errors.ResourceNotFound: resource 'test/object' not found\r\n```\r\nI traced it through and found that the problem is that the directories aren't being made when makedirs  is called, causing the recursive creation of directories to fail. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/44", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/44/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/44/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/44/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/44", "id": 352317474, "node_id": "MDU6SXNzdWUzNTIzMTc0NzQ=", "number": 44, "title": "Release?", "user": {"login": "geoffjukes", "id": 1959570, "node_id": "MDQ6VXNlcjE5NTk1NzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1959570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/geoffjukes", "html_url": "https://github.com/geoffjukes", "followers_url": "https://api.github.com/users/geoffjukes/followers", "following_url": "https://api.github.com/users/geoffjukes/following{/other_user}", "gists_url": "https://api.github.com/users/geoffjukes/gists{/gist_id}", "starred_url": "https://api.github.com/users/geoffjukes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/geoffjukes/subscriptions", "organizations_url": "https://api.github.com/users/geoffjukes/orgs", "repos_url": "https://api.github.com/users/geoffjukes/repos", "events_url": "https://api.github.com/users/geoffjukes/events{/privacy}", "received_events_url": "https://api.github.com/users/geoffjukes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-08-20T22:21:53Z", "updated_at": "2018-08-21T09:17:47Z", "closed_at": "2018-08-21T09:17:47Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi @willmcgugan \r\n\r\nI'd like to use FS 2.1, but can't until this is also upped :)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/42", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/42/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/42/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/42/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/42", "id": 351273304, "node_id": "MDU6SXNzdWUzNTEyNzMzMDQ=", "number": 42, "title": "s3fs incompatible with latest fs", "user": {"login": "Spacerat", "id": 141427, "node_id": "MDQ6VXNlcjE0MTQyNw==", "avatar_url": "https://avatars3.githubusercontent.com/u/141427?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Spacerat", "html_url": "https://github.com/Spacerat", "followers_url": "https://api.github.com/users/Spacerat/followers", "following_url": "https://api.github.com/users/Spacerat/following{/other_user}", "gists_url": "https://api.github.com/users/Spacerat/gists{/gist_id}", "starred_url": "https://api.github.com/users/Spacerat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Spacerat/subscriptions", "organizations_url": "https://api.github.com/users/Spacerat/orgs", "repos_url": "https://api.github.com/users/Spacerat/repos", "events_url": "https://api.github.com/users/Spacerat/events{/privacy}", "received_events_url": "https://api.github.com/users/Spacerat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-08-16T16:12:17Z", "updated_at": "2018-08-17T22:14:41Z", "closed_at": "2018-08-17T15:55:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "The latest version of pyfilesystem2 [is 2.1.0](https://github.com/PyFilesystem/pyfilesystem2/blob/9e4d4b906893b321571fb64896d647e8451d520b/fs/_version.py), but s3fs [requires ~2.0.18](https://github.com/PyFilesystem/s3fs/blob/17605168bb1b9d65402c59010afa67d4bdd941e7/setup.py#L27). Is there a specific reason for this, or could this constraint be relaxed?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/41", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/41/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/41/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/41/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/41", "id": 348667134, "node_id": "MDU6SXNzdWUzNDg2NjcxMzQ=", "number": 41, "title": "botocore.vendored.requests.packages.urllib3.connectionpool: Resetting dropped connection: my-bucket.s3.us-west-2.amazonaws.com", "user": {"login": "fredmajor", "id": 9370903, "node_id": "MDQ6VXNlcjkzNzA5MDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/9370903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fredmajor", "html_url": "https://github.com/fredmajor", "followers_url": "https://api.github.com/users/fredmajor/followers", "following_url": "https://api.github.com/users/fredmajor/following{/other_user}", "gists_url": "https://api.github.com/users/fredmajor/gists{/gist_id}", "starred_url": "https://api.github.com/users/fredmajor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fredmajor/subscriptions", "organizations_url": "https://api.github.com/users/fredmajor/orgs", "repos_url": "https://api.github.com/users/fredmajor/repos", "events_url": "https://api.github.com/users/fredmajor/events{/privacy}", "received_events_url": "https://api.github.com/users/fredmajor/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-08-08T10:29:10Z", "updated_at": "2018-08-08T21:26:08Z", "closed_at": "2018-08-08T12:54:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nwhen reading files from S3, I see a lot of messages like the one in the subject line.\r\nCan anybody explain what that means and if this is something I should worry about?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/37", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/37/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/37/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/37/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/37", "id": 334691801, "node_id": "MDU6SXNzdWUzMzQ2OTE4MDE=", "number": 37, "title": "Release?", "user": {"login": "robo-corg", "id": 202000, "node_id": "MDQ6VXNlcjIwMjAwMA==", "avatar_url": "https://avatars3.githubusercontent.com/u/202000?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robo-corg", "html_url": "https://github.com/robo-corg", "followers_url": "https://api.github.com/users/robo-corg/followers", "following_url": "https://api.github.com/users/robo-corg/following{/other_user}", "gists_url": "https://api.github.com/users/robo-corg/gists{/gist_id}", "starred_url": "https://api.github.com/users/robo-corg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robo-corg/subscriptions", "organizations_url": "https://api.github.com/users/robo-corg/orgs", "repos_url": "https://api.github.com/users/robo-corg/repos", "events_url": "https://api.github.com/users/robo-corg/events{/privacy}", "received_events_url": "https://api.github.com/users/robo-corg/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "willmcgugan", "id": 554369, "node_id": "MDQ6VXNlcjU1NDM2OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/554369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/willmcgugan", "html_url": "https://github.com/willmcgugan", "followers_url": "https://api.github.com/users/willmcgugan/followers", "following_url": "https://api.github.com/users/willmcgugan/following{/other_user}", "gists_url": "https://api.github.com/users/willmcgugan/gists{/gist_id}", "starred_url": "https://api.github.com/users/willmcgugan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/willmcgugan/subscriptions", "organizations_url": "https://api.github.com/users/willmcgugan/orgs", "repos_url": "https://api.github.com/users/willmcgugan/repos", "events_url": "https://api.github.com/users/willmcgugan/events{/privacy}", "received_events_url": "https://api.github.com/users/willmcgugan/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "willmcgugan", "id": 554369, "node_id": "MDQ6VXNlcjU1NDM2OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/554369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/willmcgugan", "html_url": "https://github.com/willmcgugan", "followers_url": "https://api.github.com/users/willmcgugan/followers", "following_url": "https://api.github.com/users/willmcgugan/following{/other_user}", "gists_url": "https://api.github.com/users/willmcgugan/gists{/gist_id}", "starred_url": "https://api.github.com/users/willmcgugan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/willmcgugan/subscriptions", "organizations_url": "https://api.github.com/users/willmcgugan/orgs", "repos_url": "https://api.github.com/users/willmcgugan/repos", "events_url": "https://api.github.com/users/willmcgugan/events{/privacy}", "received_events_url": "https://api.github.com/users/willmcgugan/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-06-21T23:15:10Z", "updated_at": "2018-06-25T15:59:06Z", "closed_at": "2018-06-25T15:59:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "0.18 doesn't seem to have upload_args which would be extremely useful.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/36", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/36/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/36/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/36/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/36", "id": 331350748, "node_id": "MDU6SXNzdWUzMzEzNTA3NDg=", "number": 36, "title": "Encryption option for makedir()", "user": {"login": "julillae", "id": 18239431, "node_id": "MDQ6VXNlcjE4MjM5NDMx", "avatar_url": "https://avatars0.githubusercontent.com/u/18239431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/julillae", "html_url": "https://github.com/julillae", "followers_url": "https://api.github.com/users/julillae/followers", "following_url": "https://api.github.com/users/julillae/following{/other_user}", "gists_url": "https://api.github.com/users/julillae/gists{/gist_id}", "starred_url": "https://api.github.com/users/julillae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/julillae/subscriptions", "organizations_url": "https://api.github.com/users/julillae/orgs", "repos_url": "https://api.github.com/users/julillae/repos", "events_url": "https://api.github.com/users/julillae/events{/privacy}", "received_events_url": "https://api.github.com/users/julillae/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-06-11T21:07:41Z", "updated_at": "2018-06-25T16:02:53Z", "closed_at": "2018-06-25T16:02:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\n\r\nWould it be possible to extend the current support for encryption options to makedir() in the S3FS class?\r\n\r\nI was excited to be able to use upload_args to pass server side encryption options for file uploads to an s3 bucket. It works fine for file uploads. However, I am unable to create a directory in an s3 bucket that has an encryption policy. Looking at the code, I think that the upload_args are not passed to s3 in makedir() as they are when files are created. I know a directory is essentially a dummy file as far as s3 is concerned but, as I am using PyFilesystem to leverage the abstraction, I'd like to continue to use makedir() in my code (i.e. to make it easier to swap different storage backends in and out). \r\n\r\nThanks for the consideration!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/34", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/34/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/34/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/34/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/34", "id": 330046386, "node_id": "MDU6SXNzdWUzMzAwNDYzODY=", "number": 34, "title": "support Google Cloud Storage explicitly", "user": {"login": "tmbdev", "id": 333887, "node_id": "MDQ6VXNlcjMzMzg4Nw==", "avatar_url": "https://avatars0.githubusercontent.com/u/333887?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmbdev", "html_url": "https://github.com/tmbdev", "followers_url": "https://api.github.com/users/tmbdev/followers", "following_url": "https://api.github.com/users/tmbdev/following{/other_user}", "gists_url": "https://api.github.com/users/tmbdev/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmbdev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmbdev/subscriptions", "organizations_url": "https://api.github.com/users/tmbdev/orgs", "repos_url": "https://api.github.com/users/tmbdev/repos", "events_url": "https://api.github.com/users/tmbdev/events{/privacy}", "received_events_url": "https://api.github.com/users/tmbdev/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 719659188, "node_id": "MDU6TGFiZWw3MTk2NTkxODg=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/accepted", "name": "accepted", "color": "d4c5f9", "default": false, "description": null}, {"id": 657541012, "node_id": "MDU6TGFiZWw2NTc1NDEwMTI=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-06-06T21:52:59Z", "updated_at": "2018-11-12T10:00:57Z", "closed_at": "2018-11-12T10:00:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Google Cloud Storage uses the same protocol as S3 but a different API endpoint and different prefix (gs: vs s3:). It would be convenient if s3fs included the Google endpoint and prefix so that it can work with both object storage systems.\r\n\r\nSee here: https://cloud.google.com/storage/docs/interoperability\r\n\r\nRequest endpoints: https://cloud.google.com/storage/docs/request-endpoints\r\n\r\nExample endpoint: www.googleapis.com/storage/v1/[PATH_TO_RESOURCE]", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/32", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/32/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/32/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/32/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/32", "id": 318693121, "node_id": "MDU6SXNzdWUzMTg2OTMxMjE=", "number": 32, "title": "Cache-Control header", "user": {"login": "geoffjukes", "id": 1959570, "node_id": "MDQ6VXNlcjE5NTk1NzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1959570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/geoffjukes", "html_url": "https://github.com/geoffjukes", "followers_url": "https://api.github.com/users/geoffjukes/followers", "following_url": "https://api.github.com/users/geoffjukes/following{/other_user}", "gists_url": "https://api.github.com/users/geoffjukes/gists{/gist_id}", "starred_url": "https://api.github.com/users/geoffjukes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/geoffjukes/subscriptions", "organizations_url": "https://api.github.com/users/geoffjukes/orgs", "repos_url": "https://api.github.com/users/geoffjukes/repos", "events_url": "https://api.github.com/users/geoffjukes/events{/privacy}", "received_events_url": "https://api.github.com/users/geoffjukes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-04-29T06:15:31Z", "updated_at": "2018-06-10T06:11:35Z", "closed_at": "2018-06-10T06:11:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\r\n\r\nIs there any way to set additional headers when uploading files? Such as the 'Cache-Control' header?\r\n\r\nI'm uploading images, and have to modify the headers afterwards, thus making at least 2 calls. \r\n\r\nThanks in advance,\r\n\r\nGeoff", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/29", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/29/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/29/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/29/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/29", "id": 315896134, "node_id": "MDU6SXNzdWUzMTU4OTYxMzQ=", "number": 29, "title": "404 errors when accessing folders", "user": {"login": "simonm3", "id": 1199593, "node_id": "MDQ6VXNlcjExOTk1OTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1199593?v=4", "gravatar_id": "", "url": "https://api.github.com/users/simonm3", "html_url": "https://github.com/simonm3", "followers_url": "https://api.github.com/users/simonm3/followers", "following_url": "https://api.github.com/users/simonm3/following{/other_user}", "gists_url": "https://api.github.com/users/simonm3/gists{/gist_id}", "starred_url": "https://api.github.com/users/simonm3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/simonm3/subscriptions", "organizations_url": "https://api.github.com/users/simonm3/orgs", "repos_url": "https://api.github.com/users/simonm3/repos", "events_url": "https://api.github.com/users/simonm3/events{/privacy}", "received_events_url": "https://api.github.com/users/simonm3/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2018-04-19T14:12:44Z", "updated_at": "2018-07-17T12:43:45Z", "closed_at": "2018-04-19T14:47:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "Just started using this and looks like a great tool but does not seem to recognise some of my folders. For example the following recognises one of the folders but fails when I try to getinfo on any of the others.\r\n\r\nP.S. the actual output does print \"dir job-data\" but for some reason it does not show when I post it here.\r\n\r\n```\r\nfrom fs_s3fs import S3FS\r\ns3 = S3FS('registr1')\r\nprint(s3.listdir(\".\"))\r\nprint(s3.getinfo('job-data'))\r\nprint(s3.getinfo('jobs-new'))\r\n```\r\n```\r\n['job-data', 'job-ground-truth', 'jobs-failed', 'jobs-finished', 'jobs-new']\r\n<dir 'job-data'>\r\n---------------------------------------------------------------------------\r\nClientError                               Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in s3errors(path)\r\n    173     try:\r\n--> 174         yield\r\n    175     except ClientError as error:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in _get_object(self, path, key)\r\n    331                 obj = self.s3.Object(self._bucket_name, _key)\r\n--> 332                 obj.load()\r\n    333         except errors.ResourceNotFound:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\boto3\\resources\\factory.py in do_action(self, *args, **kwargs)\r\n    504             def do_action(self, *args, **kwargs):\r\n--> 505                 response = action(self, *args, **kwargs)\r\n    506                 self.meta.data = response\r\n\r\n~\\Anaconda3\\lib\\site-packages\\boto3\\resources\\action.py in __call__(self, parent, *args, **kwargs)\r\n     82 \r\n---> 83         response = getattr(parent.meta.client, operation_name)(**params)\r\n     84 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\botocore\\client.py in _api_call(self, *args, **kwargs)\r\n    323             # The \"self\" in this scope is referring to the BaseClient.\r\n--> 324             return self._make_api_call(operation_name, kwargs)\r\n    325 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\botocore\\client.py in _make_api_call(self, operation_name, api_params)\r\n    621             error_class = self.exceptions.from_code(error_code)\r\n--> 622             raise error_class(parsed_response, operation_name)\r\n    623         else:\r\n\r\nClientError: An error occurred (404) when calling the HeadObject operation: Not Found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nResourceNotFound                          Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in _get_object(self, path, key)\r\n    331                 obj = self.s3.Object(self._bucket_name, _key)\r\n--> 332                 obj.load()\r\n    333         except errors.ResourceNotFound:\r\n\r\n~\\Anaconda3\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n     98             try:\r\n---> 99                 self.gen.throw(type, value, traceback)\r\n    100             except StopIteration as exc:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in s3errors(path)\r\n    183         if http_status == 404:\r\n--> 184             raise errors.ResourceNotFound(path)\r\n    185         elif http_status == 403:\r\n\r\nResourceNotFound: resource 'jobs-new' not found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nClientError                               Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in s3errors(path)\r\n    173     try:\r\n--> 174         yield\r\n    175     except ClientError as error:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in _get_object(self, path, key)\r\n    337                 )\r\n--> 338                 obj.load()\r\n    339                 return obj\r\n\r\n~\\Anaconda3\\lib\\site-packages\\boto3\\resources\\factory.py in do_action(self, *args, **kwargs)\r\n    504             def do_action(self, *args, **kwargs):\r\n--> 505                 response = action(self, *args, **kwargs)\r\n    506                 self.meta.data = response\r\n\r\n~\\Anaconda3\\lib\\site-packages\\boto3\\resources\\action.py in __call__(self, parent, *args, **kwargs)\r\n     82 \r\n---> 83         response = getattr(parent.meta.client, operation_name)(**params)\r\n     84 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\botocore\\client.py in _api_call(self, *args, **kwargs)\r\n    323             # The \"self\" in this scope is referring to the BaseClient.\r\n--> 324             return self._make_api_call(operation_name, kwargs)\r\n    325 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\botocore\\client.py in _make_api_call(self, operation_name, api_params)\r\n    621             error_class = self.exceptions.from_code(error_code)\r\n--> 622             raise error_class(parsed_response, operation_name)\r\n    623         else:\r\n\r\nClientError: An error occurred (404) when calling the HeadObject operation: Not Found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nResourceNotFound                          Traceback (most recent call last)\r\n<ipython-input-163-2cd801c76678> in <module>()\r\n      1 print(s3.listdir(\".\"))\r\n      2 print(s3.getinfo('job-data'))\r\n----> 3 print(s3.getinfo('jobs-new'))\r\n\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in getinfo(self, path, namespaces)\r\n    448             })\r\n    449 \r\n--> 450         obj = self._get_object(path, _key)\r\n    451         info = self._info_from_object(obj, namespaces)\r\n    452         return Info(info)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in _get_object(self, path, key)\r\n    337                 )\r\n    338                 obj.load()\r\n--> 339                 return obj\r\n    340         else:\r\n    341             return obj\r\n\r\n~\\Anaconda3\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n     97                 value = type()\r\n     98             try:\r\n---> 99                 self.gen.throw(type, value, traceback)\r\n    100             except StopIteration as exc:\r\n    101                 # Suppress StopIteration *unless* it's the same exception that\r\n\r\n~\\Anaconda3\\lib\\site-packages\\fs_s3fs\\_s3fs.py in s3errors(path)\r\n    182             raise errors.ResourceError(path, exc=error, msg=error_msg)\r\n    183         if http_status == 404:\r\n--> 184             raise errors.ResourceNotFound(path)\r\n    185         elif http_status == 403:\r\n    186             raise errors.PermissionDenied(path=path, msg=error_msg)\r\n\r\nResourceNotFound: resource 'jobs-new' not found\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/27", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/27/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/27/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/27/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/27", "id": 298140741, "node_id": "MDU6SXNzdWUyOTgxNDA3NDE=", "number": 27, "title": "README.md typo?", "user": {"login": "prestonPD", "id": 15753439, "node_id": "MDQ6VXNlcjE1NzUzNDM5", "avatar_url": "https://avatars0.githubusercontent.com/u/15753439?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prestonPD", "html_url": "https://github.com/prestonPD", "followers_url": "https://api.github.com/users/prestonPD/followers", "following_url": "https://api.github.com/users/prestonPD/following{/other_user}", "gists_url": "https://api.github.com/users/prestonPD/gists{/gist_id}", "starred_url": "https://api.github.com/users/prestonPD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prestonPD/subscriptions", "organizations_url": "https://api.github.com/users/prestonPD/orgs", "repos_url": "https://api.github.com/users/prestonPD/repos", "events_url": "https://api.github.com/users/prestonPD/events{/privacy}", "received_events_url": "https://api.github.com/users/prestonPD/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-19T01:41:02Z", "updated_at": "2018-02-21T13:53:58Z", "closed_at": "2018-02-21T13:53:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, thank you for providing this package.\r\n\r\nUnder \"Opening a S3FS\" in README.md it says\r\n`from s3_s3fs import S3FS`\r\n\r\nI think this should maybe be\r\n`from fs_s3fs import S3FS`\r\n\r\nThe latter worked for me; the former did not.  Please let me know if I may submit a PR to fix this critical issue :D", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/25", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/25/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/25/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/25/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/25", "id": 298044470, "node_id": "MDU6SXNzdWUyOTgwNDQ0NzA=", "number": 25, "title": "ResourceNotFound exception on removetree", "user": {"login": "limx0", "id": 4816153, "node_id": "MDQ6VXNlcjQ4MTYxNTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/4816153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/limx0", "html_url": "https://github.com/limx0", "followers_url": "https://api.github.com/users/limx0/followers", "following_url": "https://api.github.com/users/limx0/following{/other_user}", "gists_url": "https://api.github.com/users/limx0/gists{/gist_id}", "starred_url": "https://api.github.com/users/limx0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/limx0/subscriptions", "organizations_url": "https://api.github.com/users/limx0/orgs", "repos_url": "https://api.github.com/users/limx0/repos", "events_url": "https://api.github.com/users/limx0/events{/privacy}", "received_events_url": "https://api.github.com/users/limx0/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 657541016, "node_id": "MDU6TGFiZWw2NTc1NDEwMTY=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/wontfix", "name": "wontfix", "color": "ffffff", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-02-17T23:13:59Z", "updated_at": "2018-11-26T02:25:11Z", "closed_at": "2018-03-29T20:59:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "`removetree` breaks when (presumably) boto cleans up a directory after all files have been deleted.\r\n\r\nTo replicate (I am using a local minio server to test against): \r\n\r\n```python \r\nbucket_name = 'test-bucket1'\r\n\r\nfrom minio import Minio\r\nm = Minio(\r\n    endpoint=MINIO_ENDPOINT, access_key=MINIO_KEY, \r\n    secret_key=MINIO_SECRET, secure=False\r\n)\r\nm.make_bucket(bucket_name)\r\n\r\nfrom fs_s3fs import S3FS\r\nfs = S3FS(\r\n    bucket_name=bucket_name, aws_access_key_id=MINIO_KEY,\r\n    aws_secret_access_key=MINIO_SECRET, endpoint_url='http://' + MINIO_ENDPOINT\r\n)\r\n\r\ndr = fs.makedirs('data/hello')\r\nwith dr.openbin('world', 'w') as f:\r\n    f.write(b'somedata')\r\n\r\nfs.removetree('data')\r\n```\r\n\r\nwhich raises\r\n\r\n```python\r\nResourceNotFound                          Traceback (most recent call last)\r\n<ipython-input-9-8b5db24ca94e> in <module>()\r\n----> 1 fs.removetree('data')\r\n\r\n~/anaconda3/envs/dev/lib/python3.6/site-packages/fs/base.py in removetree(self, dir_path)\r\n   1057             for _path, info in gen_info:\r\n   1058                 if info.is_dir:\r\n-> 1059                     self.removedir(_path)\r\n   1060                 else:\r\n   1061                     self.remove(_path)\r\n\r\n~/anaconda3/envs/dev/lib/python3.6/site-packages/fs_s3fs/_s3fs.py in removedir(self, path)\r\n    636         if _path == '/':\r\n    637             raise errors.RemoveRootError()\r\n--> 638         info = self.getinfo(_path)\r\n    639         if not info.is_dir:\r\n    640             raise errors.DirectoryExpected(path)\r\n\r\n~/anaconda3/envs/dev/lib/python3.6/site-packages/fs_s3fs/_s3fs.py in getinfo(self, path, namespaces)\r\n    433                     obj.load()\r\n    434         except errors.ResourceNotFound:\r\n--> 435             raise errors.ResourceNotFound(path)\r\n    436 \r\n    437         if _path == '/':\r\n\r\nResourceNotFound: resource '/data/hello' not found\r\n```\r\n\r\nI assume that boto is cleaning up the directory after all files have been deleted. In which case we probably want to do something in `removedir` like\r\n\r\n```python\r\ntry:\r\n    info = self.getinfo(_path)\r\nexcept ResourceNotFound:\r\n    return\r\n```\r\n\r\nThoughts?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/18", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/18/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/18/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/18/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/18", "id": 284700815, "node_id": "MDU6SXNzdWUyODQ3MDA4MTU=", "number": 18, "title": "Writing to S3 also writes **locally**, failing on large files due to local out-of-disk space", "user": {"login": "zevix", "id": 11682941, "node_id": "MDQ6VXNlcjExNjgyOTQx", "avatar_url": "https://avatars0.githubusercontent.com/u/11682941?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zevix", "html_url": "https://github.com/zevix", "followers_url": "https://api.github.com/users/zevix/followers", "following_url": "https://api.github.com/users/zevix/following{/other_user}", "gists_url": "https://api.github.com/users/zevix/gists{/gist_id}", "starred_url": "https://api.github.com/users/zevix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zevix/subscriptions", "organizations_url": "https://api.github.com/users/zevix/orgs", "repos_url": "https://api.github.com/users/zevix/repos", "events_url": "https://api.github.com/users/zevix/events{/privacy}", "received_events_url": "https://api.github.com/users/zevix/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 719659188, "node_id": "MDU6TGFiZWw3MTk2NTkxODg=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/accepted", "name": "accepted", "color": "d4c5f9", "default": false, "description": null}, {"id": 657541012, "node_id": "MDU6TGFiZWw2NTc1NDEwMTI=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-12-27T11:00:25Z", "updated_at": "2018-01-31T17:36:50Z", "closed_at": "2018-01-31T17:36:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "Using:\r\n```\r\nfs = open_fs(u\"s3://....\")\r\nf = fs.open(u\"filename\", \"wb\")\r\nwhile (...):\r\n    f.write(...)\r\n```\r\nCrashed after consuming all local disk space.\r\n\r\nNeed to have an option to work without local disk access", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/17", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/17/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/17/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/17/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/17", "id": 276051107, "node_id": "MDU6SXNzdWUyNzYwNTExMDc=", "number": 17, "title": "Fetching file in subfolder returns ResourceNotFound, error fetching info", "user": {"login": "Hernrup", "id": 2924505, "node_id": "MDQ6VXNlcjI5MjQ1MDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/2924505?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hernrup", "html_url": "https://github.com/Hernrup", "followers_url": "https://api.github.com/users/Hernrup/followers", "following_url": "https://api.github.com/users/Hernrup/following{/other_user}", "gists_url": "https://api.github.com/users/Hernrup/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hernrup/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hernrup/subscriptions", "organizations_url": "https://api.github.com/users/Hernrup/orgs", "repos_url": "https://api.github.com/users/Hernrup/repos", "events_url": "https://api.github.com/users/Hernrup/events{/privacy}", "received_events_url": "https://api.github.com/users/Hernrup/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-11-22T12:31:37Z", "updated_at": "2018-02-02T10:53:49Z", "closed_at": "2018-02-02T10:52:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Opening file on subfolder couses ResourceNotFound error.\r\n\r\nVersions:\r\n- fs (2.0.17)\r\n- fs-s3fs (0.1.5)\r\n\r\n### To reproduce\r\n\r\nWorking:\r\n```\r\nIn [1]: import fs_s3fs\r\nIn [2]: ffs = fs_s3fs.S3FS('bucket', dir_path='test')\r\nIn [3]: with ffs.open('999', 'wb') as f: f.write(b'test')\r\nIn [4]: with ffs.open('999', 'rb') as f: f.read()\r\n```\r\nNot working\r\n```\r\nIn [5]: import fs_s3fs\r\nIn [6]: ffs = fs_s3fs.S3FS('bucket')\r\nIn [7]: with ffs.open('test/999', 'wb') as f: f.write(b'test')\r\nIn [8]: with ffs.open('test/999', 'rb') as f: print(f.read())\r\n```\r\nStacktrace\r\n```\r\n----> 1 with ffs.open('test/999', 'rb') as f: print(f.read())\r\n\r\n/usr/lib/python3.5/site-packages/fs/base.py in open(self, path, mode, buffering, encoding, errors, newline, **options)\r\n    965         validate_open_mode(mode)\r\n    966         bin_mode = mode.replace('t', '')\r\n--> 967         bin_file = self.openbin(path, mode=bin_mode, buffering=buffering)\r\n    968         io_stream = iotools.make_stream(\r\n    969             path,\r\n\r\n/usr/lib/python3.5/site-packages/fs_s3fs/_s3fs.py in openbin(self, path, mode, buffering, **options)\r\n    537\r\n    538         if self.strict:\r\n--> 539             info = self.getinfo(path)\r\n    540             if info.is_dir:\r\n    541                 raise errors.FileExpected(path)\r\n\r\n/usr/lib/python3.5/site-packages/fs_s3fs/_s3fs.py in getinfo(self, path, namespaces)\r\n    421                 self._get_object(dir_path, _dir_key)\r\n    422         except errors.ResourceNotFound:\r\n--> 423             raise errors.ResourceNotFound(path)\r\n    424\r\n    425         if _path == '/':\r\n\r\nResourceNotFound: resource 'test/999' not found\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/16", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/16/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/16/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/16/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/16", "id": 275339977, "node_id": "MDU6SXNzdWUyNzUzMzk5Nzc=", "number": 16, "title": "ModuleNotFoundError: No module named 's3_s3fs'", "user": {"login": "zopyx", "id": 594239, "node_id": "MDQ6VXNlcjU5NDIzOQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/594239?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zopyx", "html_url": "https://github.com/zopyx", "followers_url": "https://api.github.com/users/zopyx/followers", "following_url": "https://api.github.com/users/zopyx/following{/other_user}", "gists_url": "https://api.github.com/users/zopyx/gists{/gist_id}", "starred_url": "https://api.github.com/users/zopyx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zopyx/subscriptions", "organizations_url": "https://api.github.com/users/zopyx/orgs", "repos_url": "https://api.github.com/users/zopyx/repos", "events_url": "https://api.github.com/users/zopyx/events{/privacy}", "received_events_url": "https://api.github.com/users/zopyx/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-20T12:32:13Z", "updated_at": "2017-12-28T13:14:21Z", "closed_at": "2017-12-28T13:14:21Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The very first example from the docs does not work:\r\n\r\n```\r\n>>> from s3_s3fs import s3FS\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 's3_s3fs'\r\n```\r\n\r\nSame setup as in #15 ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/15", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/15/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/15/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/15/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/15", "id": 275339739, "node_id": "MDU6SXNzdWUyNzUzMzk3Mzk=", "number": 15, "title": "Installation issue: fs.opener.errors.UnsupportedProtocol: protocol 's3' is not supported", "user": {"login": "zopyx", "id": 594239, "node_id": "MDQ6VXNlcjU5NDIzOQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/594239?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zopyx", "html_url": "https://github.com/zopyx", "followers_url": "https://api.github.com/users/zopyx/followers", "following_url": "https://api.github.com/users/zopyx/following{/other_user}", "gists_url": "https://api.github.com/users/zopyx/gists{/gist_id}", "starred_url": "https://api.github.com/users/zopyx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zopyx/subscriptions", "organizations_url": "https://api.github.com/users/zopyx/orgs", "repos_url": "https://api.github.com/users/zopyx/repos", "events_url": "https://api.github.com/users/zopyx/events{/privacy}", "received_events_url": "https://api.github.com/users/zopyx/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-20T12:31:14Z", "updated_at": "2017-11-20T12:44:03Z", "closed_at": "2017-11-20T12:36:46Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I installed fs=2.0.16 and s3fs inside Python 3.6 venv:\r\n\r\n```\r\najung@dev ~/src/s3 $ bin/pip freeze\r\nappdirs==1.4.3\r\nboto3==1.4.7\r\nbotocore==1.7.47\r\ndocutils==0.14\r\nfs==2.0.16\r\njmespath==0.9.3\r\npython-dateutil==2.6.1\r\npytz==2017.3\r\ns3fs==0.1.2\r\ns3transfer==0.1.11\r\nsix==1.11.0\r\najung@dev ~/src/s3 $ bin/python\r\nPython 3.6.2 (default, Jul 19 2017, 07:36:50) \r\n[GCC 7.1.1 20170622 (Red Hat 7.1.1-3)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from fs import open_fs\r\n>>> s3fs = open_fs('s3://mybucket')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ajung/src/s3/lib/python3.6/site-packages/fs/opener/registry.py\", line 179, in open_fs\r\n    default_protocol=default_protocol\r\n  File \"/home/ajung/src/s3/lib/python3.6/site-packages/fs/opener/registry.py\", line 136, in open\r\n    opener = self.get_opener(protocol)\r\n  File \"/home/ajung/src/s3/lib/python3.6/site-packages/fs/opener/registry.py\", line 75, in get_opener\r\n    \"protocol '{}' is not supported\".format(protocol)\r\nfs.opener.errors.UnsupportedProtocol: protocol 's3' is not supported\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/9", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/9/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/9/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/9/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/9", "id": 266265961, "node_id": "MDU6SXNzdWUyNjYyNjU5NjE=", "number": 9, "title": "Optimize uploading to S3", "user": {"login": "genben", "id": 3104779, "node_id": "MDQ6VXNlcjMxMDQ3Nzk=", "avatar_url": "https://avatars1.githubusercontent.com/u/3104779?v=4", "gravatar_id": "", "url": "https://api.github.com/users/genben", "html_url": "https://github.com/genben", "followers_url": "https://api.github.com/users/genben/followers", "following_url": "https://api.github.com/users/genben/following{/other_user}", "gists_url": "https://api.github.com/users/genben/gists{/gist_id}", "starred_url": "https://api.github.com/users/genben/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/genben/subscriptions", "organizations_url": "https://api.github.com/users/genben/orgs", "repos_url": "https://api.github.com/users/genben/repos", "events_url": "https://api.github.com/users/genben/events{/privacy}", "received_events_url": "https://api.github.com/users/genben/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-10-17T20:24:15Z", "updated_at": "2017-11-07T14:05:05Z", "closed_at": "2017-11-07T14:05:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Is it necessary to send `GET` request to S3 every time the file is uploaded? \r\n\r\nIn methods `S3FS.setbinfile()` and `S3FS.setbytes()`, it sends two GET requests. First time, it checks if the the parent directory exists (calls `S3FS.isdir()`).  Second time, it checks if the URL is not a directory (calls `S3FS.getinfo()`).  \r\n\r\nThese operations are quite expensive. The effective upload speed increases at least x3 times when these methods are not called.\r\n\r\nHere is the existing code:\r\n\r\n    def setbinfile(self, path, file):\r\n        _path = self.validatepath(path)\r\n        _key = self._path_to_key(_path)\r\n\r\n        if not self.isdir(dirname(path)):\r\n            raise errors.ResourceNotFound(path)\r\n        try:\r\n            info = self.getinfo(path)\r\n            if info.is_dir:\r\n                raise errors.FileExpected(path)\r\n        except errors.ResourceNotFound:\r\n            pass\r\n\r\n        with s3errors(path):\r\n            self.client.upload_fileobj(file, self._bucket_name, _key)\r\n\r\nProposed solution:\r\n\r\n    def setbinfile(self, path, file):\r\n        _path = self.validatepath(path)\r\n        _key = self._path_to_key(_path)\r\n\r\n        with s3errors(path):\r\n            self.client.upload_fileobj(file, self._bucket_name, _key)\r\n\r\n\r\nAnd similar changes should be applied to `setbytes()` method.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/8", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/8/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/8/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/8/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/8", "id": 265426322, "node_id": "MDU6SXNzdWUyNjU0MjYzMjI=", "number": 8, "title": "opendir raises a ResourceNotFound exception for a subdirectory which does exist.", "user": {"login": "nackjicholson", "id": 365247, "node_id": "MDQ6VXNlcjM2NTI0Nw==", "avatar_url": "https://avatars1.githubusercontent.com/u/365247?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nackjicholson", "html_url": "https://github.com/nackjicholson", "followers_url": "https://api.github.com/users/nackjicholson/followers", "following_url": "https://api.github.com/users/nackjicholson/following{/other_user}", "gists_url": "https://api.github.com/users/nackjicholson/gists{/gist_id}", "starred_url": "https://api.github.com/users/nackjicholson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nackjicholson/subscriptions", "organizations_url": "https://api.github.com/users/nackjicholson/orgs", "repos_url": "https://api.github.com/users/nackjicholson/repos", "events_url": "https://api.github.com/users/nackjicholson/events{/privacy}", "received_events_url": "https://api.github.com/users/nackjicholson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-10-13T21:40:11Z", "updated_at": "2017-10-16T18:09:24Z", "closed_at": "2017-10-16T18:09:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "```python\r\nwith open_fs('s3://my-bucket') as root_fs:\r\n     with root_fs.opendir('a_real_directory') as dir_fs:\r\n          print dir_fs.listdir(u'/')\r\n```\r\n\r\nRaises Not Found on the line which calls `opendir`\r\n\r\nI find things to work entirely when using `file://` or `osfs://` protocol urls, but things tend to explode when using `s3://`. Because I've hit two show stopping issues in two attempts to use s3fs and pyfilesystem, I'm gonna conclude that the premise of this being a compliant `FS` implementation is false, untested, and broken.\r\n\r\nIt's a grand idea to write interchangeable filesystem code, best of luck!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/7", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/7/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/7/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/7/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/7", "id": 264760567, "node_id": "MDU6SXNzdWUyNjQ3NjA1Njc=", "number": 7, "title": "AWS access key is not passed to S3 resource", "user": {"login": "genben", "id": 3104779, "node_id": "MDQ6VXNlcjMxMDQ3Nzk=", "avatar_url": "https://avatars1.githubusercontent.com/u/3104779?v=4", "gravatar_id": "", "url": "https://api.github.com/users/genben", "html_url": "https://github.com/genben", "followers_url": "https://api.github.com/users/genben/followers", "following_url": "https://api.github.com/users/genben/following{/other_user}", "gists_url": "https://api.github.com/users/genben/gists{/gist_id}", "starred_url": "https://api.github.com/users/genben/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/genben/subscriptions", "organizations_url": "https://api.github.com/users/genben/orgs", "repos_url": "https://api.github.com/users/genben/repos", "events_url": "https://api.github.com/users/genben/events{/privacy}", "received_events_url": "https://api.github.com/users/genben/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 719659188, "node_id": "MDU6TGFiZWw3MTk2NTkxODg=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/accepted", "name": "accepted", "color": "d4c5f9", "default": false, "description": null}, {"id": 657541010, "node_id": "MDU6TGFiZWw2NTc1NDEwMTA=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-10-11T22:50:09Z", "updated_at": "2017-10-16T18:04:42Z", "closed_at": "2017-10-15T19:51:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The options `aws_access_key_id` and `aws_secret_access_key` are not passed to boto3.resource() function.\r\n\r\nBelow is a fix.\r\n\r\nOriginal code (file `_s3fs.py`):\r\n\r\n    @property\r\n    def s3(self):\r\n        if not hasattr(self._tlocal, 's3'):\r\n            self._tlocal.s3 = boto3.resource('s3')\r\n        return self._tlocal.s3\r\n\r\nSolution:\r\n\r\n    @property\r\n    def s3(self):\r\n        if not hasattr(self._tlocal, 's3'):\r\n            self._tlocal.s3 = boto3.resource(\r\n                's3',\r\n                aws_access_key_id=self.aws_access_key_id,\r\n                aws_secret_access_key=self.aws_secret_access_key,\r\n                aws_session_token=self.aws_session_token\r\n            )\r\n        return self._tlocal.s3\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/6", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/6/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/6/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/6/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/6", "id": 263315936, "node_id": "MDU6SXNzdWUyNjMzMTU5MzY=", "number": 6, "title": "Support for S3 compatible services", "user": {"login": "geoffjukes", "id": 1959570, "node_id": "MDQ6VXNlcjE5NTk1NzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1959570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/geoffjukes", "html_url": "https://github.com/geoffjukes", "followers_url": "https://api.github.com/users/geoffjukes/followers", "following_url": "https://api.github.com/users/geoffjukes/following{/other_user}", "gists_url": "https://api.github.com/users/geoffjukes/gists{/gist_id}", "starred_url": "https://api.github.com/users/geoffjukes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/geoffjukes/subscriptions", "organizations_url": "https://api.github.com/users/geoffjukes/orgs", "repos_url": "https://api.github.com/users/geoffjukes/repos", "events_url": "https://api.github.com/users/geoffjukes/events{/privacy}", "received_events_url": "https://api.github.com/users/geoffjukes/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 719659188, "node_id": "MDU6TGFiZWw3MTk2NTkxODg=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/accepted", "name": "accepted", "color": "d4c5f9", "default": false, "description": null}, {"id": 657541012, "node_id": "MDU6TGFiZWw2NTc1NDEwMTI=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-10-06T01:54:33Z", "updated_at": "2017-10-19T08:57:55Z", "closed_at": "2017-10-19T08:57:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\r\n\r\nI just found PyFilesystem - and I was half way through my own implementation of the same concept (I was about to write the ftp adapter). So I\u2019m ditching my code, and using yours :) Thank you!\r\n\r\nThe only thing I\u2019m not sure how to do (cleanly) is to use the s3fs adapter with an S3 compatible service, for example Swift/Ceph/Wasabi - specifically Wasabi in my case. \r\n\r\nIn my implementation, I simply set the `endpoint_url` during the Boto3 client init. The rest was the same. \r\n\r\nThoughts?\r\n\r\nMany thanks,\r\n\r\nGeoff", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/5", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/5/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/5/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/5/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/5", "id": 260286154, "node_id": "MDU6SXNzdWUyNjAyODYxNTQ=", "number": 5, "title": "fs.walk raise fs.errors.ResourceNotFound", "user": {"login": "afarbos", "id": 7586111, "node_id": "MDQ6VXNlcjc1ODYxMTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/7586111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/afarbos", "html_url": "https://github.com/afarbos", "followers_url": "https://api.github.com/users/afarbos/followers", "following_url": "https://api.github.com/users/afarbos/following{/other_user}", "gists_url": "https://api.github.com/users/afarbos/gists{/gist_id}", "starred_url": "https://api.github.com/users/afarbos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/afarbos/subscriptions", "organizations_url": "https://api.github.com/users/afarbos/orgs", "repos_url": "https://api.github.com/users/afarbos/repos", "events_url": "https://api.github.com/users/afarbos/events{/privacy}", "received_events_url": "https://api.github.com/users/afarbos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 719659188, "node_id": "MDU6TGFiZWw3MTk2NTkxODg=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/accepted", "name": "accepted", "color": "d4c5f9", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-09-25T13:56:54Z", "updated_at": "2018-01-31T17:40:51Z", "closed_at": "2018-01-31T17:40:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI tried to use this new version of s3fs and I don't succeed to use walk.\r\n\r\n```\r\n% aws s3 ls --recursive s3://hevytest\r\n2017-09-25 15:29:38          0 tmp/tmp\r\n% python\r\nPython 2.7.13 (default, Jul 18 2017, 09:17:00)\r\n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from fs import open_fs\r\n>>> with open_fs('s3://hevytest') as fs:\r\n...     for path in fs.walk():\r\n...             print path\r\n...\r\n(u'/', [<dir 'tmp'>], [])\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/Users/hevy/env/lib/python2.7/site-packages/fs/walk.py\", line 293, in _walk_breadth\r\n    for info in self._scan(fs, dir_path, namespaces=namespaces):\r\n  File \"/Users/hevy/env/lib/python2.7/site-packages/fs_s3fs/_s3fs.py\", line 621, in scandir\r\n    info = self.getinfo(path)\r\n  File \"/Users/hevy/env/lib/python2.7/site-packages/fs_s3fs/_s3fs.py\", line 418, in getinfo\r\n    obj = self._get_object(path, _key)\r\n  File \"/Users/hevy/env/lib/python2.7/site-packages/fs_s3fs/_s3fs.py\", line 325, in _get_object\r\n    return obj\r\n  File \"/usr/local/Cellar/python/2.7.13_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py\", line 35, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/Users/hevy/env/lib/python2.7/site-packages/fs_s3fs/_s3fs.py\", line 180, in s3errors\r\n    raise errors.ResourceNotFound(path)\r\nfs.errors.ResourceNotFound: resource '/tmp' not found\r\n```\r\n\r\nWhy fs.errors.ResourceNotFound is raised ? Did I do something wrong ?\r\n\r\nMy environment:\r\n```\r\n% pip freeze\r\nappdirs==1.4.3\r\nboto3==1.4.7\r\nbotocore==1.7.16\r\ndocutils==0.14\r\nenum34==1.1.6\r\nfs==2.0.10\r\nfs-s3fs==0.1.3\r\nfutures==3.1.1\r\njmespath==0.9.3\r\npython-dateutil==2.6.1\r\npytz==2017.2\r\ns3transfer==0.1.11\r\nsix==1.10.0\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/4", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/4/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/4/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/4/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/4", "id": 255020078, "node_id": "MDU6SXNzdWUyNTUwMjAwNzg=", "number": 4, "title": "S3FS.remove('parent_directory/file') deletes both `file` and `parent_directory` when there is only one file in the directory", "user": {"login": "samuelsinayoko", "id": 17543358, "node_id": "MDQ6VXNlcjE3NTQzMzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/17543358?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelsinayoko", "html_url": "https://github.com/samuelsinayoko", "followers_url": "https://api.github.com/users/samuelsinayoko/followers", "following_url": "https://api.github.com/users/samuelsinayoko/following{/other_user}", "gists_url": "https://api.github.com/users/samuelsinayoko/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelsinayoko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelsinayoko/subscriptions", "organizations_url": "https://api.github.com/users/samuelsinayoko/orgs", "repos_url": "https://api.github.com/users/samuelsinayoko/repos", "events_url": "https://api.github.com/users/samuelsinayoko/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelsinayoko/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 719659188, "node_id": "MDU6TGFiZWw3MTk2NTkxODg=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/accepted", "name": "accepted", "color": "d4c5f9", "default": false, "description": null}, {"id": 657541010, "node_id": "MDU6TGFiZWw2NTc1NDEwMTA=", "url": "https://api.github.com/repos/PyFilesystem/s3fs/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-04T11:56:15Z", "updated_at": "2018-01-31T17:46:11Z", "closed_at": "2018-01-31T17:46:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've noticed that when there's only one file in a directory, running `botocore.s3.delete_object` deletes both the file and the parent directory. This is unexpected. I've raised an issue on the botocore list https://github.com/boto/botocore/issues/1275 but in the meantime I'd suggest modifying the implementation of `S3FS.remove` to something like\r\n```\r\n    def remove(self, path):\r\n        self.check()\r\n        _path = self.validatepath(path)\r\n        _key = self._path_to_key(_path)\r\n        info = self.getinfo(path)\r\n        if info.is_dir:\r\n            raise errors.FileExpected(path)\r\n\r\n        # get around unexpected behaviour in S3\r\n        # whereby deleting the last file in a directory\r\n        # deletes the parent directory as well\r\n        # https://github.com/boto/botocore/issues/1275\r\n        parent = self.delimiter.join(_key.split(self.delimiter)[:-1])\r\n        recreate_parent = len(self.listdir(parent)) == 1\r\n        self.client.delete_object(\r\n            Bucket=self._bucket_name,\r\n            Key=_key\r\n        )\r\n        if recreate_parent:\r\n            try:\r\n                 self.makedir(parent)\r\n            except Exception:  # use a more specific exception here\r\n                 pass\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/3", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/3/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/3/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/3/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/3", "id": 254383354, "node_id": "MDU6SXNzdWUyNTQzODMzNTQ=", "number": 3, "title": "Subdirectory with the same name as the parent doesn't appear in listdir()", "user": {"login": "samuelsinayoko", "id": 17543358, "node_id": "MDQ6VXNlcjE3NTQzMzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/17543358?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelsinayoko", "html_url": "https://github.com/samuelsinayoko", "followers_url": "https://api.github.com/users/samuelsinayoko/followers", "following_url": "https://api.github.com/users/samuelsinayoko/following{/other_user}", "gists_url": "https://api.github.com/users/samuelsinayoko/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelsinayoko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelsinayoko/subscriptions", "organizations_url": "https://api.github.com/users/samuelsinayoko/orgs", "repos_url": "https://api.github.com/users/samuelsinayoko/repos", "events_url": "https://api.github.com/users/samuelsinayoko/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelsinayoko/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-31T15:52:39Z", "updated_at": "2017-09-01T19:59:58Z", "closed_at": "2017-09-01T19:59:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Given a directory structure\r\n```\r\nbucket/dir/dir\r\n```\r\ndoing\r\n```\r\nfrom fs import open_fs\r\ns3fs = open_fs('s3://bucket')\r\ns3fs.listdir('dir')\r\n```\r\nreturns the empty list. I reckon this is because of line 440 in `_s3fs.py`:\r\n```\r\n~/miniconda3/envs/myenv/lib/python3.4/site-packages/fs_s3fs/_s3fs.py in listdir(self, path)\r\n    438                     _prefix = prefix.get('Prefix')\r\n    439                     _name = _prefix[prefix_len:]\r\n--> 440                     if _name != _s3_key:\r\n    441                         _directory.append(_name.rstrip(self.delimiter))\r\n    442                 for obj in result.get('Contents', ()):\r\n```\r\nIn this example, `_s3_key == _name == 'dir'` so the subdirectory isn't included in the list of directories :grimacing: ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/2", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/2/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/2/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/2/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/2", "id": 253952321, "node_id": "MDU6SXNzdWUyNTM5NTIzMjE=", "number": 2, "title": "Looser requirements in setup.py", "user": {"login": "samuelsinayoko", "id": 17543358, "node_id": "MDQ6VXNlcjE3NTQzMzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/17543358?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samuelsinayoko", "html_url": "https://github.com/samuelsinayoko", "followers_url": "https://api.github.com/users/samuelsinayoko/followers", "following_url": "https://api.github.com/users/samuelsinayoko/following{/other_user}", "gists_url": "https://api.github.com/users/samuelsinayoko/gists{/gist_id}", "starred_url": "https://api.github.com/users/samuelsinayoko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samuelsinayoko/subscriptions", "organizations_url": "https://api.github.com/users/samuelsinayoko/orgs", "repos_url": "https://api.github.com/users/samuelsinayoko/repos", "events_url": "https://api.github.com/users/samuelsinayoko/events{/privacy}", "received_events_url": "https://api.github.com/users/samuelsinayoko/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-08-30T10:33:14Z", "updated_at": "2017-09-01T19:59:45Z", "closed_at": "2017-09-01T19:59:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, am starting to use PyFilesystem and S3FS and I like it. One issue I'm having however is that some of my applications require older versions of boto3 (1.4.0) and botocore (1.4.28). \r\nI've done some tests and it doesn't seem to be an issue with `fs_s3fs`, so I was wondering if you could relax the requirements rules and use for example\r\n```\r\nREQUIREMENTS = [\r\n    \"boto3>=1.4.0, <1.5\",\r\n    \"fs>=2.0\",\r\n    \"six>=1.10\"\r\n]\r\n```\r\n\r\nThis is also more in line with https://blog.miguelgrinberg.com/post/the-package-dependency-blues \r\nHappy to submit a PR if that'd help.  \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/1", "repository_url": "https://api.github.com/repos/PyFilesystem/s3fs", "labels_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/1/labels{/name}", "comments_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/1/comments", "events_url": "https://api.github.com/repos/PyFilesystem/s3fs/issues/1/events", "html_url": "https://github.com/PyFilesystem/s3fs/issues/1", "id": 253193282, "node_id": "MDU6SXNzdWUyNTMxOTMyODI=", "number": 1, "title": "Everything gets placed in an empty '/' directory on s3", "user": {"login": "nackjicholson", "id": 365247, "node_id": "MDQ6VXNlcjM2NTI0Nw==", "avatar_url": "https://avatars1.githubusercontent.com/u/365247?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nackjicholson", "html_url": "https://github.com/nackjicholson", "followers_url": "https://api.github.com/users/nackjicholson/followers", "following_url": "https://api.github.com/users/nackjicholson/following{/other_user}", "gists_url": "https://api.github.com/users/nackjicholson/gists{/gist_id}", "starred_url": "https://api.github.com/users/nackjicholson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nackjicholson/subscriptions", "organizations_url": "https://api.github.com/users/nackjicholson/orgs", "repos_url": "https://api.github.com/users/nackjicholson/repos", "events_url": "https://api.github.com/users/nackjicholson/events{/privacy}", "received_events_url": "https://api.github.com/users/nackjicholson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-27T22:07:09Z", "updated_at": "2017-08-29T16:30:37Z", "closed_at": "2017-08-29T16:30:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm finding this package unusable because I can't control where files get placed.\r\n\r\n```python\r\nwith open_fs('s3://my-bucket') as root_fs:\r\n    with root_fs.open('foo.csv', 'wb') as output_file:\r\n        output_file.write('foo,bar')\r\n```\r\n\r\nThe file ends up at `s3://my-bucket//foo.csv` instead of `s3://my-bucket/foo.csv`\r\n", "performed_via_github_app": null, "score": 1.0}]}