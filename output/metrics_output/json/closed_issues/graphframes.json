{"total_count": 74, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/graphframes/graphframes/issues/367", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/367/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/367/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/367/events", "html_url": "https://github.com/graphframes/graphframes/issues/367", "id": 642541040, "node_id": "MDU6SXNzdWU2NDI1NDEwNDA=", "number": 367, "title": "Error when using shortestPaths in GraphFrames 0.8.0 for Spark 3.0", "user": {"login": "ebressot", "id": 51049124, "node_id": "MDQ6VXNlcjUxMDQ5MTI0", "avatar_url": "https://avatars0.githubusercontent.com/u/51049124?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebressot", "html_url": "https://github.com/ebressot", "followers_url": "https://api.github.com/users/ebressot/followers", "following_url": "https://api.github.com/users/ebressot/following{/other_user}", "gists_url": "https://api.github.com/users/ebressot/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebressot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebressot/subscriptions", "organizations_url": "https://api.github.com/users/ebressot/orgs", "repos_url": "https://api.github.com/users/ebressot/repos", "events_url": "https://api.github.com/users/ebressot/events{/privacy}", "received_events_url": "https://api.github.com/users/ebressot/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-21T11:00:56Z", "updated_at": "2020-07-29T19:01:50Z", "closed_at": "2020-07-29T19:01:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "I got the following error after upgrading to GraphFrames 0.8.0 for Spark 3.0 from GraphFrames 0.8.0 for Spark 2.4:\r\n\r\nAnalysisException: You're using untyped Scala UDF, which does not have the input type information. Spark may blindly pass null to the Scala closure with primitive-type argument, and the closure will see the default value of the Java type for the null argument, e.g. `udf((x: Int) => x, IntegerType)`, the result is 0 for null input. To get rid of this error, you could:\r\n---------------------------------------------------------------------------\r\nAnalysisException                         Traceback (most recent call last)\r\n<command-2369878291015010> in <module>\r\n----> 1 shortestPathToOmersVenturesDF = g.shortestPaths(landmarks=omersVenturesAsList)\r\n      2 distanceToOmersVenturesDF = shortestPathToOmersVenturesDF.select(\"id\", \"name\", \"domain\", \"facebook_url\", \"linkedin_url\", \"twitter_url\", explode(\"distances\").alias(\"uuid\", \"distance\"))\r\n      3 \r\n      4 display(distanceToOmersVenturesDF.sort(['distance', 'name'], ascending=[1, 1]))\r\n\r\n/local_disk0/spark-b5c3fbb0-16cd-4049-8b97-3d2e50a269cc/userFiles-68efc905-cfeb-44ac-bb86-f01aeee17e23/addedFile3754751852010423874graphframes_0_8_0_spark3_0_s_2_12-a07ea.jar/graphframes/graphframe.py in shortestPaths(self, landmarks)\r\n    404         :return: DataFrame with new vertices column \"distances\"\r\n    405         \"\"\"\r\n--> 406         jdf = self._jvm_graph.shortestPaths().landmarks(landmarks).run()\r\n    407         return DataFrame(jdf, self._sqlContext)\r\n    408 \r\n\r\n/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py in __call__(self, *args)\r\n   1303         answer = self.gateway_client.send_command(command)\r\n   1304         return_value = get_return_value(\r\n-> 1305             answer, self.gateway_client, self.target_id, self.name)\r\n   1306 \r\n   1307         for temp_arg in temp_args:\r\n\r\n/databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw)\r\n    132                 # Hide where the exception came from that shows a non-Pythonic\r\n    133                 # JVM exception message.\r\n--> 134                 raise_from(converted)\r\n    135             else:\r\n    136                 raise\r\n\r\n/databricks/spark/python/pyspark/sql/utils.py in raise_from(e)\r\n\r\nAnalysisException: You're using untyped Scala UDF, which does not have the input type information. Spark may blindly pass null to the Scala closure with primitive-type argument, and the closure will see the default value of the Java type for the null argument, e.g. `udf((x: Int) => x, IntegerType)`, the result is 0 for null input. To get rid of this error, you could:\r\n1. use typed Scala UDF APIs(without return type parameter), e.g. `udf((x: Int) => x)`\r\n2. use Java UDF APIs, e.g. `udf(new UDF1[String, Integer] { override def call(s: String): Integer = s.length() }, IntegerType)`, if input types are all non primitive\r\n3. set spark.sql.legacy.allowUntypedScalaUDF to true and use this API with caution;\r\n\r\nI understand that there is a workaround, but it doesn't sound like the ideal solution.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/358", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/358/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/358/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/358/events", "html_url": "https://github.com/graphframes/graphframes/issues/358", "id": 571873534, "node_id": "MDU6SXNzdWU1NzE4NzM1MzQ=", "number": 358, "title": "is there a way to do incremental Connected Components?", "user": {"login": "kant777", "id": 61204489, "node_id": "MDQ6VXNlcjYxMjA0NDg5", "avatar_url": "https://avatars0.githubusercontent.com/u/61204489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kant777", "html_url": "https://github.com/kant777", "followers_url": "https://api.github.com/users/kant777/followers", "following_url": "https://api.github.com/users/kant777/following{/other_user}", "gists_url": "https://api.github.com/users/kant777/gists{/gist_id}", "starred_url": "https://api.github.com/users/kant777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kant777/subscriptions", "organizations_url": "https://api.github.com/users/kant777/orgs", "repos_url": "https://api.github.com/users/kant777/repos", "events_url": "https://api.github.com/users/kant777/events{/privacy}", "received_events_url": "https://api.github.com/users/kant777/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-02-27T07:20:57Z", "updated_at": "2020-03-22T10:22:36Z", "closed_at": "2020-03-22T10:22:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "is there a way to do incremental Connected Components? \r\n\r\nFor example say at time `t1` I have edges Dataset `DS1` for which I computed Connected Components `CC1`. Now say at time `t2` I have edges Dataset `DS2` which can connect to edges in `DS1` How can I make sure I dont recompute connected components on the whole graph every time? My graph is evolving over time so the number of edges and vertices are increasing over time.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/357", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/357/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/357/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/357/events", "html_url": "https://github.com/graphframes/graphframes/issues/357", "id": 569582973, "node_id": "MDU6SXNzdWU1Njk1ODI5NzM=", "number": 357, "title": "Using UUIDv1 for Connected Components (SPARK-1153)", "user": {"login": "kant777", "id": 61204489, "node_id": "MDQ6VXNlcjYxMjA0NDg5", "avatar_url": "https://avatars0.githubusercontent.com/u/61204489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kant777", "html_url": "https://github.com/kant777", "followers_url": "https://api.github.com/users/kant777/followers", "following_url": "https://api.github.com/users/kant777/following{/other_user}", "gists_url": "https://api.github.com/users/kant777/gists{/gist_id}", "starred_url": "https://api.github.com/users/kant777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kant777/subscriptions", "organizations_url": "https://api.github.com/users/kant777/orgs", "repos_url": "https://api.github.com/users/kant777/repos", "events_url": "https://api.github.com/users/kant777/events{/privacy}", "received_events_url": "https://api.github.com/users/kant777/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-02-24T00:07:35Z", "updated_at": "2020-02-24T09:22:47Z", "closed_at": "2020-02-24T09:22:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Any chance of fixing this one ? https://spark-project.atlassian.net/browse/SPARK-1153 or offer some work around may be?\r\n\r\nCurrently, I got bunch of events streaming into kafka across various topics and they are stamped with an UUIDv1 for each event. so it is easy to construct edges using UUID. I am not quite sure how to generate a long based unique id without synchronization in a distributed setting. I had read this SO post which shows there are two ways one may be able to achieve this\r\n\r\n1.  UUID.randomUUID().getMostSignificantBits() & Long.MAX_VALUE\r\n\r\n2.  (System.currentTimeMillis() << 20) | (System.nanoTime() & ~9223372036854251520L)\r\n\r\nHowever I am concerned about collisions and looking for the probability of collisions for the above two approaches. any suggestions?\r\n\r\nI understand that algorithm depends on hashing integers heavily but I wonder why not fixed length byte[] ? that way we can convert any datatype to sequence of bytes.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/354", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/354/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/354/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/354/events", "html_url": "https://github.com/graphframes/graphframes/issues/354", "id": 558399737, "node_id": "MDU6SXNzdWU1NTgzOTk3Mzc=", "number": 354, "title": "GraphFrames 0.6.0 java.lang.IncompatibleClassChangeError", "user": {"login": "ashkan-leo", "id": 10341965, "node_id": "MDQ6VXNlcjEwMzQxOTY1", "avatar_url": "https://avatars0.githubusercontent.com/u/10341965?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashkan-leo", "html_url": "https://github.com/ashkan-leo", "followers_url": "https://api.github.com/users/ashkan-leo/followers", "following_url": "https://api.github.com/users/ashkan-leo/following{/other_user}", "gists_url": "https://api.github.com/users/ashkan-leo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashkan-leo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashkan-leo/subscriptions", "organizations_url": "https://api.github.com/users/ashkan-leo/orgs", "repos_url": "https://api.github.com/users/ashkan-leo/repos", "events_url": "https://api.github.com/users/ashkan-leo/events{/privacy}", "received_events_url": "https://api.github.com/users/ashkan-leo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-31T22:10:16Z", "updated_at": "2020-02-03T19:53:00Z", "closed_at": "2020-02-03T19:52:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using GraphFrames 0.6.0, Spark 2.20, and Scala 2.11.12 and when I try to create a graph I get the following error:\r\n```\r\n[info] com.conversantmedia.dsi.matchengine.core.graph.graphTest *** ABORTED ***\r\n[info]   java.lang.IncompatibleClassChangeError: Implementing class\r\n[info]   at java.lang.ClassLoader.defineClass1(Native Method)\r\n[info]   at java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n[info]   at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n[info]   at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\r\n[info]   at java.net.URLClassLoader.access$100(URLClassLoader.java:74)\r\n[info]   at java.net.URLClassLoader$1.run(URLClassLoader.java:369)\r\n[info]   at java.net.URLClassLoader$1.run(URLClassLoader.java:363)\r\n[info]   at java.security.AccessController.doPrivileged(Native Method)\r\n[info]   at java.net.URLClassLoader.findClass(URLClassLoader.java:362)\r\n[info]   at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n[info]   ...\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/353", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/353/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/353/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/353/events", "html_url": "https://github.com/graphframes/graphframes/issues/353", "id": 538267613, "node_id": "MDU6SXNzdWU1MzgyNjc2MTM=", "number": 353, "title": "Feature Request: need udf content for sendMsgToDst/Src and sendToSrc/Dst", "user": {"login": "HarborZeng", "id": 8568937, "node_id": "MDQ6VXNlcjg1Njg5Mzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8568937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HarborZeng", "html_url": "https://github.com/HarborZeng", "followers_url": "https://api.github.com/users/HarborZeng/followers", "following_url": "https://api.github.com/users/HarborZeng/following{/other_user}", "gists_url": "https://api.github.com/users/HarborZeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/HarborZeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HarborZeng/subscriptions", "organizations_url": "https://api.github.com/users/HarborZeng/orgs", "repos_url": "https://api.github.com/users/HarborZeng/repos", "events_url": "https://api.github.com/users/HarborZeng/events{/privacy}", "received_events_url": "https://api.github.com/users/HarborZeng/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-16T08:47:34Z", "updated_at": "2019-12-17T01:16:11Z", "closed_at": "2019-12-17T01:16:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "When using `pregel` and `aggragateMessages` function, we usually need to do some complex calculations that `Column` API does not supported yet, like `Vector multiplication`, which cause exceptions like:\r\n\r\n```\r\nException in thread \"main\" org.apache.spark.sql.AnalysisException: cannot resolve '(`src`.`someCol1` * `edge`.`someCol2`)' due to data type mismatch: '(`src`.`someCol1` * `edge`.`someCol2`)' requires numeric type, not vector;;\r\n```\r\n\r\nThe `Vector` mentioned above is `org.apache.spark.ml.linalg.Vector`.\r\n\r\nI would like to expect these 2 apis work like `DataFrame.filter` API, which support `func: T => Boolean` as well as `func: FilterFunction[T]` as well as `condition: Column`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/350", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/350/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/350/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/350/events", "html_url": "https://github.com/graphframes/graphframes/issues/350", "id": 532408428, "node_id": "MDU6SXNzdWU1MzI0MDg0Mjg=", "number": 350, "title": "Error when use connected component algorithm.", "user": {"login": "catmonkeylee", "id": 4240306, "node_id": "MDQ6VXNlcjQyNDAzMDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/4240306?v=4", "gravatar_id": "", "url": "https://api.github.com/users/catmonkeylee", "html_url": "https://github.com/catmonkeylee", "followers_url": "https://api.github.com/users/catmonkeylee/followers", "following_url": "https://api.github.com/users/catmonkeylee/following{/other_user}", "gists_url": "https://api.github.com/users/catmonkeylee/gists{/gist_id}", "starred_url": "https://api.github.com/users/catmonkeylee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/catmonkeylee/subscriptions", "organizations_url": "https://api.github.com/users/catmonkeylee/orgs", "repos_url": "https://api.github.com/users/catmonkeylee/repos", "events_url": "https://api.github.com/users/catmonkeylee/events{/privacy}", "received_events_url": "https://api.github.com/users/catmonkeylee/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-04T02:34:55Z", "updated_at": "2019-12-04T06:02:02Z", "closed_at": "2019-12-04T06:02:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi @felixcheung @mateiz @ankurdave @mengxr\r\nI think there is an error when compute the indexedEdges of connectedComponents,  but I don't know the really reason, anybody can help me?\r\n\r\n![image](https://user-images.githubusercontent.com/4240306/70053817-348afb00-1611-11ea-92ad-2ebba7f110b7.png)\r\n\r\n![image](https://user-images.githubusercontent.com/4240306/70053947-8764b280-1611-11ea-9a26-69d5da0007e1.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/334", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/334/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/334/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/334/events", "html_url": "https://github.com/graphframes/graphframes/issues/334", "id": 437547354, "node_id": "MDU6SXNzdWU0Mzc1NDczNTQ=", "number": 334, "title": "can't download dependency by maven repository", "user": {"login": "siyuzhiyue", "id": 12509105, "node_id": "MDQ6VXNlcjEyNTA5MTA1", "avatar_url": "https://avatars1.githubusercontent.com/u/12509105?v=4", "gravatar_id": "", "url": "https://api.github.com/users/siyuzhiyue", "html_url": "https://github.com/siyuzhiyue", "followers_url": "https://api.github.com/users/siyuzhiyue/followers", "following_url": "https://api.github.com/users/siyuzhiyue/following{/other_user}", "gists_url": "https://api.github.com/users/siyuzhiyue/gists{/gist_id}", "starred_url": "https://api.github.com/users/siyuzhiyue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/siyuzhiyue/subscriptions", "organizations_url": "https://api.github.com/users/siyuzhiyue/orgs", "repos_url": "https://api.github.com/users/siyuzhiyue/repos", "events_url": "https://api.github.com/users/siyuzhiyue/events{/privacy}", "received_events_url": "https://api.github.com/users/siyuzhiyue/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-26T07:58:55Z", "updated_at": "2019-04-26T09:38:27Z", "closed_at": "2019-04-26T09:38:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "I want to download dependency by maven dependency, but it doesn't work for me.\r\n```\r\n<!-- https://mvnrepository.com/artifact/graphframes/graphframes -->\r\n<dependency>\r\n    <groupId>graphframes</groupId>\r\n    <artifactId>graphframes</artifactId>\r\n    <version>0.6.0-spark2.2-s_2.11</version>\r\n</dependency>\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/326", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/326/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/326/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/326/events", "html_url": "https://github.com/graphframes/graphframes/issues/326", "id": 418043142, "node_id": "MDU6SXNzdWU0MTgwNDMxNDI=", "number": 326, "title": "Executing Pyspark Job", "user": {"login": "humehta", "id": 32849612, "node_id": "MDQ6VXNlcjMyODQ5NjEy", "avatar_url": "https://avatars1.githubusercontent.com/u/32849612?v=4", "gravatar_id": "", "url": "https://api.github.com/users/humehta", "html_url": "https://github.com/humehta", "followers_url": "https://api.github.com/users/humehta/followers", "following_url": "https://api.github.com/users/humehta/following{/other_user}", "gists_url": "https://api.github.com/users/humehta/gists{/gist_id}", "starred_url": "https://api.github.com/users/humehta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/humehta/subscriptions", "organizations_url": "https://api.github.com/users/humehta/orgs", "repos_url": "https://api.github.com/users/humehta/repos", "events_url": "https://api.github.com/users/humehta/events{/privacy}", "received_events_url": "https://api.github.com/users/humehta/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-06T22:41:20Z", "updated_at": "2019-03-10T19:48:48Z", "closed_at": "2019-03-10T19:48:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey ,\r\nI have written my code in a file called temp_pyspark.py\r\nWhat would be the command to execute it?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/315", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/315/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/315/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/315/events", "html_url": "https://github.com/graphframes/graphframes/issues/315", "id": 397081968, "node_id": "MDU6SXNzdWUzOTcwODE5Njg=", "number": 315, "title": "Publish 0.7.0 docs", "user": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-01-08T20:55:26Z", "updated_at": "2019-01-08T21:47:31Z", "closed_at": "2019-01-08T21:47:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I deleted graphframes.github.io repo and use gh-pages branch from this repo for hosting docs. Need to update README and a few links after.\r\n\r\ncc: @felixcheung @jkbradley ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/303", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/303/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/303/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/303/events", "html_url": "https://github.com/graphframes/graphframes/issues/303", "id": 387201596, "node_id": "MDU6SXNzdWUzODcyMDE1OTY=", "number": 303, "title": "Spark 2.4.x support?", "user": {"login": "chyh1990", "id": 1158375, "node_id": "MDQ6VXNlcjExNTgzNzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/1158375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chyh1990", "html_url": "https://github.com/chyh1990", "followers_url": "https://api.github.com/users/chyh1990/followers", "following_url": "https://api.github.com/users/chyh1990/following{/other_user}", "gists_url": "https://api.github.com/users/chyh1990/gists{/gist_id}", "starred_url": "https://api.github.com/users/chyh1990/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chyh1990/subscriptions", "organizations_url": "https://api.github.com/users/chyh1990/orgs", "repos_url": "https://api.github.com/users/chyh1990/repos", "events_url": "https://api.github.com/users/chyh1990/events{/privacy}", "received_events_url": "https://api.github.com/users/chyh1990/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-12-04T09:50:46Z", "updated_at": "2019-05-18T09:12:53Z", "closed_at": "2019-01-08T17:53:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "please provide release package on Spark Packages.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/282", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/282/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/282/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/282/events", "html_url": "https://github.com/graphframes/graphframes/issues/282", "id": 338505593, "node_id": "MDU6SXNzdWUzMzg1MDU1OTM=", "number": 282, "title": "Shortest Path Algorithm not returning distances.", "user": {"login": "jwgwalton", "id": 7936236, "node_id": "MDQ6VXNlcjc5MzYyMzY=", "avatar_url": "https://avatars3.githubusercontent.com/u/7936236?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwgwalton", "html_url": "https://github.com/jwgwalton", "followers_url": "https://api.github.com/users/jwgwalton/followers", "following_url": "https://api.github.com/users/jwgwalton/following{/other_user}", "gists_url": "https://api.github.com/users/jwgwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwgwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwgwalton/subscriptions", "organizations_url": "https://api.github.com/users/jwgwalton/orgs", "repos_url": "https://api.github.com/users/jwgwalton/repos", "events_url": "https://api.github.com/users/jwgwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/jwgwalton/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-05T09:56:51Z", "updated_at": "2018-11-09T15:27:09Z", "closed_at": "2018-07-05T11:30:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to use the shortest path algorithm and it's only returning distances for the landmarks to themselves.\r\n\r\nv = sqlContext.createDataFrame([\r\n  (\"CH1\", \"CH\"),\r\n  (\"CH2\", \"CH\"),\r\n  (\"VAT1\", \"VAT\"),\r\n  (\"VAT2\", \"VAT\"),\r\n  (\"PAYE1\", \"PAYE\"),\r\n  (\"PAYE2\", \"PAYE\"),\r\n], [\"id\", \"type\"])\r\n\r\ne = sqlContext.createDataFrame([\r\n  (\"CH1\", \"VAT1\", \"0.8\"),\r\n  (\"CH1\", \"VAT2\", \"0.9\"),\r\n  (\"CH2\", \"VAT2\", \"0.91\"),\r\n  (\"VAT1\", \"PAYE1\", \"0.8\"),\r\n  (\"VAT1\", \"PAYE2\", \"0.87\"),    \r\n], [\"src\", \"dst\", 'weight'])\r\n\r\nG = GraphFrame(v, e)\r\n\r\nshortest_paths_to_ch_nodes = G.shortestPaths(landmarks=['CH1\", \"CH2\"])\r\n\r\nshortest_paths_to_ch_nodes = [Row(id='PAYE2', type='PAYE', distances={}), Row(id='PAYE1', type='PAYE', distances={}), Row(id='CH1', type='CH', distances={'CH1': 0}), Row(id='VAT2', type='VAT', distances={}), Row(id='VAT1', type='VAT', distances={}), Row(id='CH2', type='CH', distances={'CH2': 0})]\r\n\r\nI'm hoping I've missed something fundamental but their is nothing in the api documentation and I can't understand how I'm getting this answer. Cheers\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/276", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/276/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/276/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/276/events", "html_url": "https://github.com/graphframes/graphframes/issues/276", "id": 332122907, "node_id": "MDU6SXNzdWUzMzIxMjI5MDc=", "number": 276, "title": "Fix negation in motif finding", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-06-13T19:01:10Z", "updated_at": "2018-07-03T04:25:30Z", "closed_at": "2018-07-03T04:25:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "This issue comes from thinking about https://github.com/graphframes/graphframes/issues/254\r\n\r\nRead below to see discussion on how to fix negation in motif finding.  Also, I wrote up more details in [this doc](https://docs.google.com/document/d/1e7HUdsTe7jNBjxYt2WflR0Pb5l3I9StjFplUitph6AE/).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/270", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/270/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/270/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/270/events", "html_url": "https://github.com/graphframes/graphframes/issues/270", "id": 318943216, "node_id": "MDU6SXNzdWUzMTg5NDMyMTY=", "number": 270, "title": "Timeline for 0.6 release?", "user": {"login": "kevinykuo", "id": 5582151, "node_id": "MDQ6VXNlcjU1ODIxNTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/5582151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevinykuo", "html_url": "https://github.com/kevinykuo", "followers_url": "https://api.github.com/users/kevinykuo/followers", "following_url": "https://api.github.com/users/kevinykuo/following{/other_user}", "gists_url": "https://api.github.com/users/kevinykuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevinykuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevinykuo/subscriptions", "organizations_url": "https://api.github.com/users/kevinykuo/orgs", "repos_url": "https://api.github.com/users/kevinykuo/repos", "events_url": "https://api.github.com/users/kevinykuo/events{/privacy}", "received_events_url": "https://api.github.com/users/kevinykuo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-04-30T16:01:03Z", "updated_at": "2018-07-09T07:24:43Z", "closed_at": "2018-07-09T07:24:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Wondering when the next release will be available on Maven. Currently, 0.5 only supports up to Spark 2.1 so is blocking for some folks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/246", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/246/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/246/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/246/events", "html_url": "https://github.com/graphframes/graphframes/issues/246", "id": 277894256, "node_id": "MDU6SXNzdWUyNzc4OTQyNTY=", "number": 246, "title": "Failed to parse bad motif string", "user": {"login": "geoHeil", "id": 1694964, "node_id": "MDQ6VXNlcjE2OTQ5NjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1694964?v=4", "gravatar_id": "", "url": "https://api.github.com/users/geoHeil", "html_url": "https://github.com/geoHeil", "followers_url": "https://api.github.com/users/geoHeil/followers", "following_url": "https://api.github.com/users/geoHeil/following{/other_user}", "gists_url": "https://api.github.com/users/geoHeil/gists{/gist_id}", "starred_url": "https://api.github.com/users/geoHeil/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/geoHeil/subscriptions", "organizations_url": "https://api.github.com/users/geoHeil/orgs", "repos_url": "https://api.github.com/users/geoHeil/repos", "events_url": "https://api.github.com/users/geoHeil/events{/privacy}", "received_events_url": "https://api.github.com/users/geoHeil/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-11-29T20:23:52Z", "updated_at": "2017-11-30T10:19:01Z", "closed_at": "2017-11-30T10:19:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "How can I Implement something like neo4j's: `(a)-[e*..3]-(b)` with graphFrames?\r\n\r\n- `(a)-[e]->(b); (b)-[e2]->(a)` will represent an undirected edge but  forces that there are actually vertices in both directions. Can I integrate an OR not just a AND into the Motif?\r\n\r\n- `[e*..3]` will match 0,1,2,3 edges - would I need to use aggregate messages or iteratively looping over the possible values and `UNION`ing the results`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/243", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/243/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/243/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/243/events", "html_url": "https://github.com/graphframes/graphframes/issues/243", "id": 273773996, "node_id": "MDU6SXNzdWUyNzM3NzM5OTY=", "number": 243, "title": "connectedComponents returns lost id info ", "user": {"login": "hrxu01", "id": 9206411, "node_id": "MDQ6VXNlcjkyMDY0MTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/9206411?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hrxu01", "html_url": "https://github.com/hrxu01", "followers_url": "https://api.github.com/users/hrxu01/followers", "following_url": "https://api.github.com/users/hrxu01/following{/other_user}", "gists_url": "https://api.github.com/users/hrxu01/gists{/gist_id}", "starred_url": "https://api.github.com/users/hrxu01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hrxu01/subscriptions", "organizations_url": "https://api.github.com/users/hrxu01/orgs", "repos_url": "https://api.github.com/users/hrxu01/repos", "events_url": "https://api.github.com/users/hrxu01/events{/privacy}", "received_events_url": "https://api.github.com/users/hrxu01/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2017-11-14T12:24:58Z", "updated_at": "2017-11-14T13:02:12Z", "closed_at": "2017-11-14T13:00:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "sorry, it is my fault.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/239", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/239/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/239/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/239/events", "html_url": "https://github.com/graphframes/graphframes/issues/239", "id": 261414955, "node_id": "MDU6SXNzdWUyNjE0MTQ5NTU=", "number": 239, "title": "missing or invalid dependency detected while loading class file 'Logging.class'.", "user": {"login": "RayTsui", "id": 13369167, "node_id": "MDQ6VXNlcjEzMzY5MTY3", "avatar_url": "https://avatars1.githubusercontent.com/u/13369167?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RayTsui", "html_url": "https://github.com/RayTsui", "followers_url": "https://api.github.com/users/RayTsui/followers", "following_url": "https://api.github.com/users/RayTsui/following{/other_user}", "gists_url": "https://api.github.com/users/RayTsui/gists{/gist_id}", "starred_url": "https://api.github.com/users/RayTsui/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RayTsui/subscriptions", "organizations_url": "https://api.github.com/users/RayTsui/orgs", "repos_url": "https://api.github.com/users/RayTsui/repos", "events_url": "https://api.github.com/users/RayTsui/events{/privacy}", "received_events_url": "https://api.github.com/users/RayTsui/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-28T18:23:35Z", "updated_at": "2017-10-16T21:35:29Z", "closed_at": "2017-10-16T21:34:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I use the following code to log in the cluster: \r\nspark-shell --master yarn --jars graphframes-0.5.0-spark2.1-s_2.11.jar scala-logging-slf4j_2.10-2.1.2.jar scala-logging-api_2.10-2.1.2.jar \r\n\r\nand run the follow spark code:\r\n\r\nimport org.apache.spark.SparkContext \r\nimport org.apache.spark.sql.SparkSession \r\nimport org.graphframes._\r\n\r\nval ss = SparkSession.builder().appName(\"ECommerce Fraud Detection by Graph\").config(\"spark.some.config.option\", \"some- value\").config(\"spark.hadoop.validateOutputSpecs\", \"false\").getOrCreate() \u2028\r\nval edges = ss.sql(\"select * from table\")\r\nval graphframes = GraphFrame.fromEdges(edges)\r\n\r\nand error info occurs as follows:\r\nrror: missing or invalid dependency detected while loading class file 'Logging.class'.\r\nCould not access term typesafe in package com,\r\nbecause it (or its dependencies) are missing. Check your build definition for\r\nmissing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)\r\nA full rebuild may help if 'Logging.class' was compiled against an incompatible version of com.\r\nerror: missing or invalid dependency detected while loading class file 'Logging.class'.\r\nCould not access term scalalogging in value com.typesafe,\r\nbecause it (or its dependencies) are missing. Check your build definition for\r\nmissing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)\r\nA full rebuild may help if 'Logging.class' was compiled against an incompatible version of com.typesafe.\r\nerror: missing or invalid dependency detected while loading class file 'Logging.class'.\r\nCould not access type LazyLogging in value com.slf4j,\r\nbecause it (or its dependencies) are missing. Check your build definition for\r\nmissing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)\r\nA full rebuild may help if 'Logging.class' was compiled against an incompatible version of com.slf4j.\r\n\r\nIs there any solution to solve this, thanks a lot.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/233", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/233/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/233/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/233/events", "html_url": "https://github.com/graphframes/graphframes/issues/233", "id": 257856358, "node_id": "MDU6SXNzdWUyNTc4NTYzNTg=", "number": 233, "title": "Inaccurate PageRank docs", "user": {"login": "danielfx90", "id": 7074012, "node_id": "MDQ6VXNlcjcwNzQwMTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/7074012?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielfx90", "html_url": "https://github.com/danielfx90", "followers_url": "https://api.github.com/users/danielfx90/followers", "following_url": "https://api.github.com/users/danielfx90/following{/other_user}", "gists_url": "https://api.github.com/users/danielfx90/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielfx90/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielfx90/subscriptions", "organizations_url": "https://api.github.com/users/danielfx90/orgs", "repos_url": "https://api.github.com/users/danielfx90/repos", "events_url": "https://api.github.com/users/danielfx90/events{/privacy}", "received_events_url": "https://api.github.com/users/danielfx90/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-09-14T21:05:32Z", "updated_at": "2017-09-23T08:22:51Z", "closed_at": "2017-09-23T08:22:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## **Current situation**\r\nPageRank scala docs and user guide say that the implementation which runs for a fixed number of iterations (through the `maxIter` parameter) uses the Graphframes interface when in fact it uses the graphX's Pregel one.\r\n\r\n## **What needs to be done?**\r\nBoth docs should match what the code does.\r\n\r\n**Note:** I'll be creating a PR for this", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/231", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/231/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/231/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/231/events", "html_url": "https://github.com/graphframes/graphframes/issues/231", "id": 257033617, "node_id": "MDU6SXNzdWUyNTcwMzM2MTc=", "number": 231, "title": "pageRank return incorrect results within graphframe 0.4+ spark 2.2 combination", "user": {"login": "artem-aliev", "id": 1150911, "node_id": "MDQ6VXNlcjExNTA5MTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/1150911?v=4", "gravatar_id": "", "url": "https://api.github.com/users/artem-aliev", "html_url": "https://github.com/artem-aliev", "followers_url": "https://api.github.com/users/artem-aliev/followers", "following_url": "https://api.github.com/users/artem-aliev/following{/other_user}", "gists_url": "https://api.github.com/users/artem-aliev/gists{/gist_id}", "starred_url": "https://api.github.com/users/artem-aliev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/artem-aliev/subscriptions", "organizations_url": "https://api.github.com/users/artem-aliev/orgs", "repos_url": "https://api.github.com/users/artem-aliev/repos", "events_url": "https://api.github.com/users/artem-aliev/events{/privacy}", "received_events_url": "https://api.github.com/users/artem-aliev/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-12T12:57:49Z", "updated_at": "2017-10-18T10:47:22Z", "closed_at": "2017-10-18T10:47:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "the strange thing is: all graph frames version return the same result with spark 2.0\r\ngraph frame 0.3 return the same result with spark 2.2\r\nso only latest graph frames and latest spark return different numbers.\r\nI also checked with apache tinkerPop, that algorithm return the same results as spark 2.0\r\nSo it looks like an issue.\r\n\r\nHere is a code I use to reproduce\r\n```\r\nimport org.graphframes._\r\nval g = examples.Graphs.friends\r\nval results2 = g.pageRank.resetProbability(0.15).maxIter(10).run()\r\nresults2.vertices.select(\"id\", \"pagerank\").orderBy(\"id\").show()\r\n```\r\n\r\nOutputs:\r\n\r\nspark-2.0.2-bin-hadoop2.7/./bin/spark-shell --packages graphframes:graphframes:$version\r\n\r\nSpark 2.0.2 graphframes:graphframes:0.3.0-spark2.0-s_2.11\r\n```\r\n+---+-------------------+\r\n| id|           pagerank|\r\n+---+-------------------+\r\n|  a|0.39143465933514154|\r\n|  b|  1.842259190054981|\r\n|  c|  1.877540087856477|\r\n|  d|0.28427148788098855|\r\n|  e|0.31616362485373634|\r\n|  f|0.28427148788098855|\r\n|  g|               0.15|\r\n+---+-------------------+\r\n```\r\n\r\nSpark 2.0.2 graphframes:graphframes:0.4.0-spark2.0-s_2.11, time: 6934ms\r\n```\r\n+---+-------------------+\r\n| id|           pagerank|\r\n+---+-------------------+\r\n|  a|0.39143465933514154|\r\n|  b|  1.842259190054981|\r\n|  c|  1.877540087856477|\r\n|  d|0.28427148788098855|\r\n|  e|0.31616362485373634|\r\n|  f|0.28427148788098855|\r\n|  g|               0.15|\r\n+---+-------------------+\r\n```\r\nSpark 2.0.2 graphframes:graphframes:0.5.0-spark2.0-s_2.11, time: 87887ms\r\n```\r\n+---+-------------------+\r\n| id|           pagerank|\r\n+---+-------------------+\r\n|  a|0.39143465933514154|\r\n|  b|  1.842259190054981|\r\n|  c|  1.877540087856477|\r\n|  d|0.28427148788098855|\r\n|  e|0.31616362485373634|\r\n|  f|0.28427148788098855|\r\n|  g|               0.15|\r\n+---+-------------------+\r\n```\r\nspark-2.2.0-bin-hadoop2.7/./bin/spark-shell --packages graph frames:graph frames:$version\r\n\r\nSpark 2.2 graphframes:graphframes:0.3.0-spark2.0-s_2.11\r\n```\r\n+---+-------------------+\r\n| id|           pagerank|\r\n+---+-------------------+\r\n|  a|0.39143465933514154|\r\n|  b|  1.842259190054981|\r\n|  c|  1.877540087856477|\r\n|  d|0.28427148788098855|\r\n|  e|0.31616362485373634|\r\n|  f|0.28427148788098855|\r\n|  g|               0.15|\r\n+---+-------------------+\r\n```\r\n\r\nSpark 2.2 graphframes:graphframes:0.4.0-spark2.0-s_2.11 time: 5809ms\r\n\r\n```\r\n+---+-------------------+\r\n| id|           pagerank|\r\n+---+-------------------+\r\n|  a| 0.4485115093698443|\r\n|  b| 2.7025217677349773|\r\n|  c| 2.6667877057849627|\r\n|  d|0.32504910549694244|\r\n|  e| 0.3613490987992571|\r\n|  f|0.32504910549694244|\r\n|  g|0.17073170731707318|\r\n+---+-------------------+\r\n```\r\nSpark 2.2 graphframes:graphframes:0.5.0-spark2.0-s_2.11, time: 70398ms\r\n\r\n```\r\n+---+-------------------+\r\n| id|           pagerank|\r\n+---+-------------------+\r\n|  a| 0.4485115093698443|\r\n|  b| 2.7025217677349773|\r\n|  c| 2.6667877057849627|\r\n|  d|0.32504910549694244|\r\n|  e| 0.3613490987992571|\r\n|  f|0.32504910549694244|\r\n|  g|0.17073170731707318|\r\n+---+\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014+\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/229", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/229/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/229/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/229/events", "html_url": "https://github.com/graphframes/graphframes/issues/229", "id": 256507208, "node_id": "MDU6SXNzdWUyNTY1MDcyMDg=", "number": 229, "title": "type GraphFrame not found ", "user": {"login": "asdspal", "id": 10200210, "node_id": "MDQ6VXNlcjEwMjAwMjEw", "avatar_url": "https://avatars2.githubusercontent.com/u/10200210?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asdspal", "html_url": "https://github.com/asdspal", "followers_url": "https://api.github.com/users/asdspal/followers", "following_url": "https://api.github.com/users/asdspal/following{/other_user}", "gists_url": "https://api.github.com/users/asdspal/gists{/gist_id}", "starred_url": "https://api.github.com/users/asdspal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asdspal/subscriptions", "organizations_url": "https://api.github.com/users/asdspal/orgs", "repos_url": "https://api.github.com/users/asdspal/repos", "events_url": "https://api.github.com/users/asdspal/events{/privacy}", "received_events_url": "https://api.github.com/users/asdspal/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-10T12:34:53Z", "updated_at": "2017-09-10T18:29:42Z", "closed_at": "2017-09-10T18:29:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm getting following error while running a simple example from graphframes docs in notebook apache-toree scala kernel\r\n\r\nName: Compile Error\r\nMessage: <console>:18: error: not found: type GraphFrame\r\n       val g: GraphFrame = examples.Graphs.friends\r\n              ^\r\napache- spark version = 2.2\r\ngraphframes version = 0.5.0-spark2.1-s_2.11\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/227", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/227/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/227/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/227/events", "html_url": "https://github.com/graphframes/graphframes/issues/227", "id": 251208796, "node_id": "MDU6SXNzdWUyNTEyMDg3OTY=", "number": 227, "title": "while doing kafkaStream = KafkaUtils.createDirectStream(ssc, ['twitterstream'], {\"metadata.broker.list\": [\"dn1001:6667\",\"dn2001:6667\",\"dn3001:6667\",\"dn4001:6667\"]})", "user": {"login": "saurabhbidwai", "id": 22415674, "node_id": "MDQ6VXNlcjIyNDE1Njc0", "avatar_url": "https://avatars1.githubusercontent.com/u/22415674?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saurabhbidwai", "html_url": "https://github.com/saurabhbidwai", "followers_url": "https://api.github.com/users/saurabhbidwai/followers", "following_url": "https://api.github.com/users/saurabhbidwai/following{/other_user}", "gists_url": "https://api.github.com/users/saurabhbidwai/gists{/gist_id}", "starred_url": "https://api.github.com/users/saurabhbidwai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saurabhbidwai/subscriptions", "organizations_url": "https://api.github.com/users/saurabhbidwai/orgs", "repos_url": "https://api.github.com/users/saurabhbidwai/repos", "events_url": "https://api.github.com/users/saurabhbidwai/events{/privacy}", "received_events_url": "https://api.github.com/users/saurabhbidwai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-18T10:47:58Z", "updated_at": "2017-08-18T18:47:32Z", "closed_at": "2017-08-18T18:47:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Py4JJavaError                             Traceback (most recent call last)\r\n<ipython-input-5-b7be21171e16> in <module>()\r\n----> 1 kafkaStream = KafkaUtils.createDirectStream(ssc, ['twitterstream'], {\"metadata.broker.list\": [\"dn1001:6667\",\"dn2001:6667\",\"dn3001:6667\",\"dn4001:6667\"]})\r\n\r\n/usr/hdp/current/spark-client/python/lib/pyspark.zip/pyspark/streaming/kafka.py in createDirectStream(ssc, topics, kafkaParams, fromOffsets, keyDecoder, valueDecoder, messageHandler)\r\n    150             if 'ClassNotFoundException' in str(e.java_exception):\r\n    151                 KafkaUtils._printErrorMsg(ssc.sparkContext)\r\n--> 152             raise e\r\n    153 \r\n    154         stream = DStream(jstream, ssc, ser).map(func)\r\n\r\nPy4JJavaError: An error occurred while calling o56.createDirectStreamWithoutMessageHandler.\r\n: java.lang.ClassCastException: java.util.ArrayList cannot be cast to java.lang.String\r\n\tat org.apache.spark.streaming.kafka.KafkaCluster$SimpleConsumerConfig$.apply(KafkaCluster.scala:405)\r\n\tat org.apache.spark.streaming.kafka.KafkaCluster.config(KafkaCluster.scala:53)\r\n\tat org.apache.spark.streaming.kafka.KafkaCluster.getPartitionMetadata(KafkaCluster.scala:130)\r\n\tat org.apache.spark.streaming.kafka.KafkaCluster.getPartitions(KafkaCluster.scala:119)\r\n\tat org.apache.spark.streaming.kafka.KafkaUtils$.getFromOffsets(KafkaUtils.scala:211)\r\n\tat org.apache.spark.streaming.kafka.KafkaUtilsPythonHelper.createDirectStream(KafkaUtils.scala:720)\r\n\tat org.apache.spark.streaming.kafka.KafkaUtilsPythonHelper.createDirectStreamWithoutMessageHandler(KafkaUtils.scala:688)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\r\n\tat py4j.Gateway.invoke(Gateway.java:259)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\r\n\tat java.lang.Thread.run(Thread.java:745)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/226", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/226/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/226/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/226/events", "html_url": "https://github.com/graphframes/graphframes/issues/226", "id": 247705030, "node_id": "MDU6SXNzdWUyNDc3MDUwMzA=", "number": 226, "title": "Connected Components Performance", "user": {"login": "brelloch", "id": 4350420, "node_id": "MDQ6VXNlcjQzNTA0MjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/4350420?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brelloch", "html_url": "https://github.com/brelloch", "followers_url": "https://api.github.com/users/brelloch/followers", "following_url": "https://api.github.com/users/brelloch/following{/other_user}", "gists_url": "https://api.github.com/users/brelloch/gists{/gist_id}", "starred_url": "https://api.github.com/users/brelloch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brelloch/subscriptions", "organizations_url": "https://api.github.com/users/brelloch/orgs", "repos_url": "https://api.github.com/users/brelloch/repos", "events_url": "https://api.github.com/users/brelloch/events{/privacy}", "received_events_url": "https://api.github.com/users/brelloch/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-08-03T13:23:42Z", "updated_at": "2018-01-31T20:06:27Z", "closed_at": "2017-08-18T17:55:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am running on spark 2.1, graphframes 0.5 and AWS EMR with 3 r4.xlarge instances. When the generating the connected components for a graph of about 12 million edges it is taking around 3 hours. Is this the expected performance or are there way to tune things to improve it?\r\n\r\nThe code is below. I am fairly new to spark so any suggestions would be awesome.\r\n```scala\r\ndef main(args: Array[String]): Unit = {\r\n  val sparkConf = new SparkConf()\r\n    .setMaster(\"yarn-cluster\")\r\n    .setAppName(\"Connected Component\")\r\n\r\n  val sc = new SparkContext(sparkConf)\r\n  sc.setCheckpointDir(\"s3a://......\")\r\n  AWSUtils.setS3Credentials(sc.hadoopConfiguration)\r\n\r\n  implicit val sqlContext = SQLContext.getOrCreate(sc)\r\n  import sqlContext.implicits._\r\n\r\n  val historical = sqlContext\r\n    .read\r\n    .option(\"mergeSchema\", \"false\")\r\n    .parquet(\"s3a://.....\")\r\n    .map(x => (x(0).toString, x(2).toString, x(1).toString, x(3).toString, x(4).toString.toLong, x(5).toString.toLong))\r\n\r\n  // Complete graph\r\n  val g = GraphFrame(\r\n    historical.flatMap(e => List((e._1, e._3, e._5), (e._2, e._4, e._5))).toDF(\"id\", \"type\", \"timestamp\"),\r\n    historical.toDF(\"src\", \"dst\", \"srcType\", \"dstType\", \"timestamp\", \"companyId\")\r\n  )\r\n\r\n  val connectedComponents: DataFrame = g.connectedComponents.run()\r\n\r\n  connectedComponents.toDF().show(100, false)\r\n\r\n  sc.stop()\r\n}\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/218", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/218/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/218/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/218/events", "html_url": "https://github.com/graphframes/graphframes/issues/218", "id": 238841913, "node_id": "MDU6SXNzdWUyMzg4NDE5MTM=", "number": 218, "title": "Cannot load graphframes in zeppelin", "user": {"login": "Swalloow", "id": 2902097, "node_id": "MDQ6VXNlcjI5MDIwOTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/2902097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Swalloow", "html_url": "https://github.com/Swalloow", "followers_url": "https://api.github.com/users/Swalloow/followers", "following_url": "https://api.github.com/users/Swalloow/following{/other_user}", "gists_url": "https://api.github.com/users/Swalloow/gists{/gist_id}", "starred_url": "https://api.github.com/users/Swalloow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Swalloow/subscriptions", "organizations_url": "https://api.github.com/users/Swalloow/orgs", "repos_url": "https://api.github.com/users/Swalloow/repos", "events_url": "https://api.github.com/users/Swalloow/events{/privacy}", "received_events_url": "https://api.github.com/users/Swalloow/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-06-27T12:57:38Z", "updated_at": "2018-07-03T19:12:18Z", "closed_at": "2017-06-29T05:43:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I tried to add graphframes as a spark package in my zeppelin interpreter.\r\nBut I get the following error:\r\n\r\n```\r\nError setting properties for interpreter 'spark.spark': Could not find artifact \r\ngraphframes:graphframes:jar:0.5.0-spark2.1-s_2.11 in central (http://repo1.maven.org/maven2/)\r\n```\r\n\r\nI tried to jar files but it also didn't work in pyspark. Same as following question.\r\n[https://stackoverflow.com/questions/43357329/pyspark-importerror-no-module-named-graphframes-in-zeppelin-0-7-1-osx](url)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/216", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/216/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/216/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/216/events", "html_url": "https://github.com/graphframes/graphframes/issues/216", "id": 236743537, "node_id": "MDU6SXNzdWUyMzY3NDM1Mzc=", "number": 216, "title": "[How to] use in pyspark using the assemby jar ?", "user": {"login": "thomasopsomer", "id": 11439747, "node_id": "MDQ6VXNlcjExNDM5NzQ3", "avatar_url": "https://avatars3.githubusercontent.com/u/11439747?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thomasopsomer", "html_url": "https://github.com/thomasopsomer", "followers_url": "https://api.github.com/users/thomasopsomer/followers", "following_url": "https://api.github.com/users/thomasopsomer/following{/other_user}", "gists_url": "https://api.github.com/users/thomasopsomer/gists{/gist_id}", "starred_url": "https://api.github.com/users/thomasopsomer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thomasopsomer/subscriptions", "organizations_url": "https://api.github.com/users/thomasopsomer/orgs", "repos_url": "https://api.github.com/users/thomasopsomer/repos", "events_url": "https://api.github.com/users/thomasopsomer/events{/privacy}", "received_events_url": "https://api.github.com/users/thomasopsomer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 314294554, "node_id": "MDU6TGFiZWwzMTQyOTQ1NTQ=", "url": "https://api.github.com/repos/graphframes/graphframes/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-18T20:28:19Z", "updated_at": "2017-06-20T17:21:49Z", "closed_at": "2017-06-20T17:21:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nWhile working on some changes in graphframes, I'm wondering how do I need to use the assembly jar to use the python graphframes API ? When running `pyspark --jars <path to jar>`, it doesn't find the python bindings, how do I specify that ?\r\n\r\nThanks,\r\nThomas", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/214", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/214/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/214/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/214/events", "html_url": "https://github.com/graphframes/graphframes/issues/214", "id": 235751739, "node_id": "MDU6SXNzdWUyMzU3NTE3Mzk=", "number": 214, "title": "Why NullPointerException for connected components?", "user": {"login": "bjjiangfs", "id": 6627763, "node_id": "MDQ6VXNlcjY2Mjc3NjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6627763?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjjiangfs", "html_url": "https://github.com/bjjiangfs", "followers_url": "https://api.github.com/users/bjjiangfs/followers", "following_url": "https://api.github.com/users/bjjiangfs/following{/other_user}", "gists_url": "https://api.github.com/users/bjjiangfs/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjjiangfs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjjiangfs/subscriptions", "organizations_url": "https://api.github.com/users/bjjiangfs/orgs", "repos_url": "https://api.github.com/users/bjjiangfs/repos", "events_url": "https://api.github.com/users/bjjiangfs/events{/privacy}", "received_events_url": "https://api.github.com/users/bjjiangfs/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-14T03:21:27Z", "updated_at": "2017-06-20T16:33:47Z", "closed_at": "2017-06-20T16:33:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am trying to retrieve connected components from a graph, but when g.connectedComponents() is executed, the program starts to give NullPointerException. My test data is pretty small which contains only 12 nodes and some edges (no orphan nodes). The final result seems correct, but those exceptions really bother me. Would you please give me some ideas how to get rid of them? Thanks!\r\n\r\n(More details can be found in my post stackoverflow https://stackoverflow.com/questions/44512219/weird-javanullpointerexception-while-using-graphframes-for-connected-components)\r\n\r\n`ERROR LiveListenerBus: Listener JobProgressListener threw an exception java.lang.NullPointerException at org.apache.spark.ui.jobs.JobProgressListener$$anonfun$onTaskEnd$1.apply(JobProgressListener.scala:361) at org.apache.spark.ui.jobs.JobProgressListener$$anonfun$onTaskEnd$1.apply(JobProgressListener.scala:360) at scala.collection.immutable.List.foreach(List.scala:318) at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32) at scala.collection.mutable.ListBuffer.foreach(ListBuffer.scala:45) at org.apache.spark.ui.jobs.JobProgressListener.onTaskEnd(JobProgressListener.scala:360) at org.apache.spark.scheduler.SparkListenerBus$class.onPostEvent(SparkListenerBus.scala:42) at org.apache.spark.scheduler.LiveListenerBus.onPostEvent(LiveListenerBus.scala:31) at org.apache.spark.scheduler.LiveListenerBus.onPostEvent(LiveListenerBus.scala:31) at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:55) at org.apache.spark.util.AsynchronousListenerBus.postToAll(AsynchronousListenerBus.scala:37) at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(AsynchronousListenerBus.scala:80) at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(AsynchronousListenerBus.scala:65) at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(AsynchronousListenerBus.scala:65) at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1.apply$mcV$sp(AsynchronousListenerBus.scala:64) at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1183) at org.apache.spark.util.AsynchronousListenerBus$$anon$1.run(AsynchronousListenerBus.scala:63)`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/213", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/213/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/213/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/213/events", "html_url": "https://github.com/graphframes/graphframes/issues/213", "id": 235632289, "node_id": "MDU6SXNzdWUyMzU2MzIyODk=", "number": 213, "title": "Allow users to set intermediate storage level in CC", "user": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-13T17:39:40Z", "updated_at": "2017-06-14T19:48:31Z", "closed_at": "2017-06-14T19:48:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "This would help users test different storage settings for performance tuning.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/209", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/209/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/209/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/209/events", "html_url": "https://github.com/graphframes/graphframes/issues/209", "id": 235580246, "node_id": "MDU6SXNzdWUyMzU1ODAyNDY=", "number": 209, "title": "Missing Python files in GraphFrames 0.5.0 jar", "user": {"login": "paulovn", "id": 2182574, "node_id": "MDQ6VXNlcjIxODI1NzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2182574?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulovn", "html_url": "https://github.com/paulovn", "followers_url": "https://api.github.com/users/paulovn/followers", "following_url": "https://api.github.com/users/paulovn/following{/other_user}", "gists_url": "https://api.github.com/users/paulovn/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulovn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulovn/subscriptions", "organizations_url": "https://api.github.com/users/paulovn/orgs", "repos_url": "https://api.github.com/users/paulovn/repos", "events_url": "https://api.github.com/users/paulovn/events{/privacy}", "received_events_url": "https://api.github.com/users/paulovn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-06-13T14:46:36Z", "updated_at": "2017-08-26T09:53:11Z", "closed_at": "2017-06-21T01:46:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "The GraphFrames JAR for the 0.5.0 version seems to lack a couple of Python files that are in the source package:\r\n\r\n    graphframes/lib/__init__.py\r\n    graphframes/lib/aggregate_messages.py\r\n\r\nAs such, the `AggregateMessages` class is not available. Trying to load the Python examples also fails, since they contain an import \r\n\r\n    from graphframes.lib import AggregateMessages as AM\r\n\r\n... which produces an exception.\r\n\r\nI've tested the JAR as downloaded automatically by Spark (`graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar`). I also downloaded manually a couple of other versions from the Maven repository and they seem to have all the same problem (I didn't check all of them).\r\n\r\nApparently, when building the jarfile the subdirectory `python/graphframes/lib` gets excluded.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/203", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/203/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/203/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/203/events", "html_url": "https://github.com/graphframes/graphframes/issues/203", "id": 233954342, "node_id": "MDU6SXNzdWUyMzM5NTQzNDI=", "number": 203, "title": "Update ConnectedComponent.symmetrize once we remove Spark 1.6 support", "user": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-06-06T16:42:31Z", "updated_at": "2017-06-11T07:58:40Z", "closed_at": "2017-06-11T07:58:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The current implementation (https://github.com/graphframes/graphframes/blob/master/src/main/scala/org/graphframes/lib/ConnectedComponents.scala#L170) requires two passes over the edges, mainly to have the same code to support both Spark 1.6 and 2.x. Once we removed Spark 1.6 support (#193), we should optimize the implementation to speed-up CC.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/194", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/194/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/194/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/194/events", "html_url": "https://github.com/graphframes/graphframes/issues/194", "id": 227852170, "node_id": "MDU6SXNzdWUyMjc4NTIxNzA=", "number": 194, "title": "Slow connected component checkpoint interval test", "user": {"login": "phi-dbq", "id": 28275034, "node_id": "MDQ6VXNlcjI4Mjc1MDM0", "avatar_url": "https://avatars0.githubusercontent.com/u/28275034?v=4", "gravatar_id": "", "url": "https://api.github.com/users/phi-dbq", "html_url": "https://github.com/phi-dbq", "followers_url": "https://api.github.com/users/phi-dbq/followers", "following_url": "https://api.github.com/users/phi-dbq/following{/other_user}", "gists_url": "https://api.github.com/users/phi-dbq/gists{/gist_id}", "starred_url": "https://api.github.com/users/phi-dbq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/phi-dbq/subscriptions", "organizations_url": "https://api.github.com/users/phi-dbq/orgs", "repos_url": "https://api.github.com/users/phi-dbq/repos", "events_url": "https://api.github.com/users/phi-dbq/events{/privacy}", "received_events_url": "https://api.github.com/users/phi-dbq/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-05-11T01:12:25Z", "updated_at": "2017-06-13T17:32:11Z", "closed_at": "2017-06-13T17:32:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "On a fairly recent MacBook Pro laptop and on the Travis CI, the [connected component check interval test](https://github.com/graphframes/graphframes/blob/master/src/test/scala/org/graphframes/lib/ConnectedComponentsSuite.scala#L161) takes very long time to finish.\r\n\r\n- with `-Dspark.version=1.6.3 -Dscala.version=2.10.6`\r\n  - checkpoint interval (9 minutes, 53 seconds)\r\n- with `-Dspark.version=2.1.1 -Dscala.version=2.10.6`\r\n  - checkpoint interval (3 minutes, 12 seconds)\r\n\r\n\r\nThese has caused CI to time-out for certain build variants. \r\nWe should investigate this issue. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/193", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/193/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/193/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/193/events", "html_url": "https://github.com/graphframes/graphframes/issues/193", "id": 227827756, "node_id": "MDU6SXNzdWUyMjc4Mjc3NTY=", "number": 193, "title": "Remove Apache Spark 1.6 support", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2017-05-10T22:25:08Z", "updated_at": "2017-06-11T07:59:04Z", "closed_at": "2017-06-11T07:59:04Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I'd like to remove 1.6 support\r\n* I have not heard any complaints about not publishing a 1.6 version of the latest GraphFrames release.\r\n* It is causing complications for https://github.com/graphframes/graphframes/issues/159  (where tests are suddenly much slower, though I'm not sure why yet).\r\n* Later version of Spark are consistently better for GraphFrames b/c of DataFrame performance improvements", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/184", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/184/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/184/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/184/events", "html_url": "https://github.com/graphframes/graphframes/issues/184", "id": 222902391, "node_id": "MDU6SXNzdWUyMjI5MDIzOTE=", "number": 184, "title": "Add wrapper for GraphX parallelized personalized PageRank", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-04-19T23:31:32Z", "updated_at": "2018-05-21T17:02:07Z", "closed_at": "2018-05-21T17:02:01Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "GraphX added parallelized personalized PageRank in Spark 2.1.  It'd be nice to add a wrapper for that in GraphFrames.  If you're interested in working on this, please state the proposed API before you begin implementation.  Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/177", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/177/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/177/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/177/events", "html_url": "https://github.com/graphframes/graphframes/issues/177", "id": 214521084, "node_id": "MDU6SXNzdWUyMTQ1MjEwODQ=", "number": 177, "title": "Incorrect results for in and out degree count", "user": {"login": "maver1ck", "id": 4006010, "node_id": "MDQ6VXNlcjQwMDYwMTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/4006010?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maver1ck", "html_url": "https://github.com/maver1ck", "followers_url": "https://api.github.com/users/maver1ck/followers", "following_url": "https://api.github.com/users/maver1ck/following{/other_user}", "gists_url": "https://api.github.com/users/maver1ck/gists{/gist_id}", "starred_url": "https://api.github.com/users/maver1ck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maver1ck/subscriptions", "organizations_url": "https://api.github.com/users/maver1ck/orgs", "repos_url": "https://api.github.com/users/maver1ck/repos", "events_url": "https://api.github.com/users/maver1ck/events{/privacy}", "received_events_url": "https://api.github.com/users/maver1ck/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-03-15T20:48:59Z", "updated_at": "2017-03-27T17:57:28Z", "closed_at": "2017-03-27T17:57:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI have following problem.\r\nI tried to do the filtering based on vertices and then run inDegree method but unfortunately this method is using only edges to calculate in-degree count.\r\n\r\nSample from QuickStart:\r\n```\r\n# Create a Vertex DataFrame with unique ID column \"id\"\r\nv = sqlContext.createDataFrame([\r\n  (\"a\", \"Alice\", 34),\r\n  (\"b\", \"Bob\", 36),\r\n  (\"c\", \"Charlie\", 30),\r\n], [\"id\", \"name\", \"age\"])\r\n# Create an Edge DataFrame with \"src\" and \"dst\" columns\r\ne = sqlContext.createDataFrame([\r\n  (\"a\", \"b\", \"friend\"),\r\n  (\"b\", \"c\", \"follow\"),\r\n  (\"c\", \"b\", \"follow\"),\r\n], [\"src\", \"dst\", \"relationship\"])\r\n# Create a GraphFrame\r\nfrom graphframes import *\r\ng = GraphFrame(v, e)\r\n\r\n# Query: Get in-degree of each vertex.\r\ng.inDegrees.show()\r\n+---+--------+\r\n| id|inDegree|\r\n+---+--------+\r\n|  c|       1|\r\n|  b|       2|\r\n+---+--------+\r\n```\r\n\r\nWith the filtering:\r\n```\r\ng2 = GraphFrame(v.filter(\"id != 'b'\"), e)\r\ng2.inDegrees.show()\r\n+---+--------+\r\n| id|inDegree|\r\n+---+--------+\r\n|  c|       1|\r\n|  b|       2|\r\n+---+--------+\r\n\r\n```\r\nNothing changed.\r\nIs it proper behaviour ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/175", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/175/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/175/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/175/events", "html_url": "https://github.com/graphframes/graphframes/issues/175", "id": 210131700, "node_id": "MDU6SXNzdWUyMTAxMzE3MDA=", "number": 175, "title": "Checkpoint to s3 not working", "user": {"login": "mavencode01", "id": 542912, "node_id": "MDQ6VXNlcjU0MjkxMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/542912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mavencode01", "html_url": "https://github.com/mavencode01", "followers_url": "https://api.github.com/users/mavencode01/followers", "following_url": "https://api.github.com/users/mavencode01/following{/other_user}", "gists_url": "https://api.github.com/users/mavencode01/gists{/gist_id}", "starred_url": "https://api.github.com/users/mavencode01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mavencode01/subscriptions", "organizations_url": "https://api.github.com/users/mavencode01/orgs", "repos_url": "https://api.github.com/users/mavencode01/repos", "events_url": "https://api.github.com/users/mavencode01/events{/privacy}", "received_events_url": "https://api.github.com/users/mavencode01/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-02-24T19:06:28Z", "updated_at": "2017-02-27T00:59:58Z", "closed_at": "2017-02-27T00:59:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to deploy my job to aws EMR and using s3 as my checkpoint dir but I'm getting an exception using s3. \r\n\r\n\tjava.lang.IllegalArgumentException: Wrong FS: s3://spark-jobs/supercluster-checkpoint/f9d90be3-bb3e-4a7f-8009-37bb4d697f67/connected-components-e7bf178a/2, expected: hdfs://ip-172-18-13-6.ec2.internal:8020\r\n\t\tat org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:652)\r\n\t\tat org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194)\r\n\t\tat org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106)\r\n\t\tat org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:707)\r\n\t\tat org.apache.hadoop.hdfs.DistributedFileSystem$14.doCall(DistributedFileSystem.java:703)\r\n\t\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\r\n\t\tat org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:703)\r\n\t\tat org.graphframes.lib.ConnectedComponents$.org$graphframes$lib$ConnectedComponents$$run(ConnectedComponents.scala:340)\r\n\t\tat org.graphframes.lib.ConnectedComponents.run(ConnectedComponents.scala:139)\r\n\t\tat com.sonatype.aname.sparkjob.SuperClusterV2$.main(SuperClusterV2.scala:87)\r\n\t\tat com.sonatype.aname.sparkjob.SuperClusterV2.main(SuperClusterV2.scala)\r\n\t\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\t\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\t\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\t\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\t\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:637)\r\n\r\n\r\nIs it possible to use s3 as Checkpoint directory ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/171", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/171/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/171/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/171/events", "html_url": "https://github.com/graphframes/graphframes/issues/171", "id": 206783814, "node_id": "MDU6SXNzdWUyMDY3ODM4MTQ=", "number": 171, "title": "GraphFrame solely from edge DataFrame", "user": {"login": "mtoto", "id": 10297043, "node_id": "MDQ6VXNlcjEwMjk3MDQz", "avatar_url": "https://avatars2.githubusercontent.com/u/10297043?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mtoto", "html_url": "https://github.com/mtoto", "followers_url": "https://api.github.com/users/mtoto/followers", "following_url": "https://api.github.com/users/mtoto/following{/other_user}", "gists_url": "https://api.github.com/users/mtoto/gists{/gist_id}", "starred_url": "https://api.github.com/users/mtoto/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mtoto/subscriptions", "organizations_url": "https://api.github.com/users/mtoto/orgs", "repos_url": "https://api.github.com/users/mtoto/repos", "events_url": "https://api.github.com/users/mtoto/events{/privacy}", "received_events_url": "https://api.github.com/users/mtoto/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-10T12:25:23Z", "updated_at": "2017-06-21T04:04:17Z", "closed_at": "2017-06-21T04:04:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "According to the documentation: \r\n\r\n_\"A GraphFrame can also be constructed from a single DataFrame containing edge information. The vertices will be inferred from the sources and destinations of the edges.\"_\r\n\r\nIs this correct and if so how can this be achieved?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/170", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/170/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/170/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/170/events", "html_url": "https://github.com/graphframes/graphframes/issues/170", "id": 206155737, "node_id": "MDU6SXNzdWUyMDYxNTU3Mzc=", "number": 170, "title": "Add BeliefPropagation Example to Python", "user": {"login": "hughchristensen", "id": 11336132, "node_id": "MDQ6VXNlcjExMzM2MTMy", "avatar_url": "https://avatars0.githubusercontent.com/u/11336132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hughchristensen", "html_url": "https://github.com/hughchristensen", "followers_url": "https://api.github.com/users/hughchristensen/followers", "following_url": "https://api.github.com/users/hughchristensen/following{/other_user}", "gists_url": "https://api.github.com/users/hughchristensen/gists{/gist_id}", "starred_url": "https://api.github.com/users/hughchristensen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hughchristensen/subscriptions", "organizations_url": "https://api.github.com/users/hughchristensen/orgs", "repos_url": "https://api.github.com/users/hughchristensen/repos", "events_url": "https://api.github.com/users/hughchristensen/events{/privacy}", "received_events_url": "https://api.github.com/users/hughchristensen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-02-08T10:29:49Z", "updated_at": "2017-04-26T19:23:46Z", "closed_at": "2017-04-26T19:23:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/graphframes/graphframes/issues/57 is now in review. \r\n\r\nThis ticket is to add BeliefPropagation API to Python\r\n\r\n* https://github.com/graphframes/graphframes/blob/master/src/main/scala/org/graphframes/examples/BeliefPropagation.scala\r\n\r\nMyself and @tsivula will be working on this.\r\n\r\n@thunterdb @jkbradley @qingpeng @mengxr @felixcheung Does anyone have any helpful input/ experiences here? Thank you. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/165", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/165/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/165/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/165/events", "html_url": "https://github.com/graphframes/graphframes/issues/165", "id": 199696176, "node_id": "MDU6SXNzdWUxOTk2OTYxNzY=", "number": 165, "title": "Test `named edges` breaks codegen with Spark 2.1", "user": {"login": "thunterdb", "id": 7594753, "node_id": "MDQ6VXNlcjc1OTQ3NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7594753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thunterdb", "html_url": "https://github.com/thunterdb", "followers_url": "https://api.github.com/users/thunterdb/followers", "following_url": "https://api.github.com/users/thunterdb/following{/other_user}", "gists_url": "https://api.github.com/users/thunterdb/gists{/gist_id}", "starred_url": "https://api.github.com/users/thunterdb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thunterdb/subscriptions", "organizations_url": "https://api.github.com/users/thunterdb/orgs", "repos_url": "https://api.github.com/users/thunterdb/repos", "events_url": "https://api.github.com/users/thunterdb/events{/privacy}", "received_events_url": "https://api.github.com/users/thunterdb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 314294549, "node_id": "MDU6TGFiZWwzMTQyOTQ1NDk=", "url": "https://api.github.com/repos/graphframes/graphframes/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-01-09T23:53:59Z", "updated_at": "2017-03-27T22:00:02Z", "closed_at": "2017-03-27T22:00:02Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Here is the stack trace:\r\n\r\n```\r\n16/12/30 07:06:33 WARN WholeStageCodegenExec: Whole-stage codegen disabled for this plan:\r\n *HashAggregate(keys=[e#18378, v#18381], functions=[], output=[e#18378, v#18381])\r\n+- *BroadcastHashJoin [coalesce(e#18378, [0,0,]), coalesce(v#18381, [0,,])], [coalesce(e#18417, [0,0,]), coalesce(v#18419, [0,,])], LeftAnti, BuildRight, ((e#18378 <=> e#18417) && (v#18381 <=> v#18419))\r\n   :- *BroadcastHashJoin [e#18378.dst], [v#18381.id], LeftOuter, BuildRight\r\n   :  :- LocalTableScan [e#18378]\r\n   :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<id:bigint,attr:string,gender:string>, false].id))\r\n   :     +- LocalTableScan [v#18381]\r\n   +- BroadcastExchange HashedRelationBroadcastMode(List(coalesce(input[0, struct<src:bigint,dst:bigint,relationship:string>, false], [0,0,]), coalesce(input[1, struct<id:bigint,attr:string,gender:string>, true], [0,,])))\r\n      +- *Project [e#18417, v#18419]\r\n         +- *BroadcastHashJoin [v#18419.id], [__tmp-1042178570564257691#18396.src], Inner, BuildRight\r\n            :- *BroadcastHashJoin [e#18417.dst], [v#18419.id], LeftOuter, BuildRight\r\n            :  :- LocalTableScan [e#18417]\r\n            :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<id:bigint,attr:string,gender:string>, false].id))\r\n            :     +- LocalTableScan [v#18419]\r\n            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<src:bigint,dst:bigint,relationship:string>, false].src))\r\n               +- LocalTableScan [__tmp-1042178570564257691#18396]\r\n```\r\n\r\nand the complete message:\r\n\r\n```\r\n16/12/30 07:06:33 ERROR CodeGenerator: failed to compile: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 472, Column 36: Expression \"inputadapter_value\" is not an rvalue\r\n/* 001 */ public Object generate(Object[] references) {\r\n/* 002 */   return new GeneratedIterator(references);\r\n/* 003 */ }\r\n/* 004 */\r\n/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {\r\n/* 006 */   private Object[] references;\r\n/* 007 */   private scala.collection.Iterator[] inputs;\r\n/* 008 */   private boolean agg_initAgg;\r\n/* 009 */   private org.apache.spark.sql.execution.aggregate.HashAggregateExec agg_plan;\r\n/* 010 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap;\r\n/* 011 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter;\r\n/* 012 */   private org.apache.spark.unsafe.KVIterator agg_mapIter;\r\n/* 013 */   private org.apache.spark.sql.execution.metric.SQLMetric agg_peakMemory;\r\n/* 014 */   private org.apache.spark.sql.execution.metric.SQLMetric agg_spillSize;\r\n/* 015 */   private scala.collection.Iterator inputadapter_input;\r\n/* 016 */   private org.apache.spark.broadcast.TorrentBroadcast bhj_broadcast;\r\n/* 017 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation;\r\n/* 018 */   private org.apache.spark.sql.execution.metric.SQLMetric bhj_numOutputRows;\r\n/* 019 */   private UnsafeRow bhj_result;\r\n/* 020 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder bhj_holder;\r\n/* 021 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter;\r\n/* 022 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter1;\r\n/* 023 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter2;\r\n/* 024 */   private org.apache.spark.broadcast.TorrentBroadcast bhj_broadcast1;\r\n/* 025 */   private org.apache.spark.sql.execution.joins.UnsafeHashedRelation bhj_relation1;\r\n/* 026 */   private UnsafeRow bhj_result1;\r\n/* 027 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder bhj_holder1;\r\n/* 028 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter3;\r\n/* 029 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter4;\r\n/* 030 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter5;\r\n/* 031 */   private org.apache.spark.sql.execution.metric.SQLMetric bhj_numOutputRows1;\r\n/* 032 */   private UnsafeRow bhj_result2;\r\n/* 033 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder bhj_holder2;\r\n/* 034 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter6;\r\n/* 035 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter7;\r\n/* 036 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter bhj_rowWriter8;\r\n/* 037 */   private UnsafeRow agg_result;\r\n/* 038 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder agg_holder;\r\n/* 039 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter agg_rowWriter;\r\n/* 040 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter agg_rowWriter1;\r\n/* 041 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter agg_rowWriter2;\r\n/* 042 */   private int agg_value4;\r\n/* 043 */   private UnsafeRow agg_result1;\r\n/* 044 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder agg_holder1;\r\n/* 045 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter agg_rowWriter3;\r\n/* 046 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter agg_rowWriter4;\r\n/* 047 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter agg_rowWriter5;\r\n/* 048 */   private org.apache.spark.sql.execution.metric.SQLMetric wholestagecodegen_numOutputRows;\r\n/* 049 */   private org.apache.spark.sql.execution.metric.SQLMetric wholestagecodegen_aggTime;\r\n/* 050 */\r\n/* 051 */   public GeneratedIterator(Object[] references) {\r\n/* 052 */     this.references = references;\r\n/* 053 */   }\r\n/* 054 */\r\n/* 055 */   public void init(int index, scala.collection.Iterator[] inputs) {\r\n/* 056 */     partitionIndex = index;\r\n/* 057 */     this.inputs = inputs;\r\n/* 058 */     wholestagecodegen_init_0();\r\n/* 059 */     wholestagecodegen_init_1();\r\n/* 060 */     wholestagecodegen_init_2();\r\n/* 061 */     wholestagecodegen_init_3();\r\n/* 062 */\r\n/* 063 */   }\r\n/* 064 */\r\n/* 065 */   private void wholestagecodegen_init_0() {\r\n/* 066 */     agg_initAgg = false;\r\n/* 067 */     this.agg_plan = (org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0];\r\n/* 068 */\r\n/* 069 */     this.agg_peakMemory = (org.apache.spark.sql.execution.metric.SQLMetric) references[1];\r\n/* 070 */     this.agg_spillSize = (org.apache.spark.sql.execution.metric.SQLMetric) references[2];\r\n/* 071 */     inputadapter_input = inputs[0];\r\n/* 072 */     this.bhj_broadcast = (org.apache.spark.broadcast.TorrentBroadcast) references[3];\r\n/* 073 */\r\n/* 074 */     bhj_relation = ((org.apache.spark.sql.execution.joins.LongHashedRelation) bhj_broadcast.value()).asReadOnlyCopy();\r\n/* 075 */     incPeakExecutionMemory(bhj_relation.estimatedSize());\r\n/* 076 */\r\n/* 077 */     this.bhj_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[4];\r\n/* 078 */     bhj_result = new UnsafeRow(2);\r\n/* 079 */     this.bhj_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(bhj_result, 64);\r\n/* 080 */     this.bhj_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder, 2);\r\n/* 081 */     this.bhj_rowWriter1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder, 3);\r\n/* 082 */     this.bhj_rowWriter2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder, 3);\r\n/* 083 */\r\n/* 084 */   }\r\n/* 085 */\r\n/* 086 */   private void wholestagecodegen_init_3() {\r\n/* 087 */     this.agg_rowWriter5 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(agg_holder1, 3);\r\n/* 088 */     this.wholestagecodegen_numOutputRows = (org.apache.spark.sql.execution.metric.SQLMetric) references[9];\r\n/* 089 */     this.wholestagecodegen_aggTime = (org.apache.spark.sql.execution.metric.SQLMetric) references[10];\r\n/* 090 */\r\n/* 091 */   }\r\n/* 092 */\r\n/* 093 */   private void agg_doAggregateWithKeys() throws java.io.IOException {\r\n/* 094 */     agg_hashMap = agg_plan.createHashMap();\r\n/* 095 */\r\n/* 096 */     while (inputadapter_input.hasNext()) {\r\n/* 097 */       InternalRow inputadapter_row = (InternalRow) inputadapter_input.next();\r\n/* 098 */       InternalRow inputadapter_value = inputadapter_row.getStruct(0, 3);\r\n/* 099 */\r\n/* 100 */       // generate join key for stream side\r\n/* 101 */\r\n/* 102 */       boolean bhj_isNull = false;\r\n/* 103 */\r\n/* 104 */       long bhj_value = -1L;\r\n/* 105 */\r\n/* 106 */       bhj_value = inputadapter_value.getLong(1);\r\n/* 107 */       // find matches from HashedRelation\r\n/* 108 */       UnsafeRow bhj_matched = false ? null: (UnsafeRow)bhj_relation.getValue(bhj_value);\r\n/* 109 */       final boolean bhj_conditionPassed = true;\r\n/* 110 */       if (!bhj_conditionPassed) {\r\n/* 111 */         bhj_matched = null;\r\n/* 112 */         // reset the variables those are already evaluated.\r\n/* 113 */\r\n/* 114 */       }\r\n/* 115 */       bhj_numOutputRows.add(1);\r\n/* 116 */\r\n/* 117 */       boolean bhj_isNull3 = true;\r\n/* 118 */       InternalRow bhj_value3 = null;\r\n/* 119 */       if (bhj_matched != null) {\r\n/* 120 */         InternalRow bhj_value2 = bhj_matched.getStruct(0, 3);\r\n/* 121 */         bhj_isNull3 = false;\r\n/* 122 */         bhj_value3 = bhj_value2;\r\n/* 123 */       }\r\n/* 124 */\r\n/* 125 */       // generate join key for stream side\r\n/* 126 */\r\n/* 127 */       bhj_holder1.reset();\r\n/* 128 */\r\n/* 129 */       bhj_rowWriter3.zeroOutNullBytes();\r\n/* 130 */\r\n/* 131 */       boolean bhj_isNull6 = false;\r\n/* 132 */       InternalRow bhj_value6 = inputadapter_value;\r\n/* 133 */       if (bhj_isNull6) {\r\n/* 134 */         Object bhj_obj = ((Expression) references[6]).eval(null);\r\n/* 135 */         InternalRow bhj_value8 = (InternalRow) bhj_obj;\r\n/* 136 */         if (!false) {\r\n/* 137 */           bhj_isNull6 = false;\r\n/* 138 */           bhj_value6 = bhj_value8;\r\n/* 139 */         }\r\n/* 140 */       }\r\n/* 141 */       if (bhj_isNull6) {\r\n/* 142 */         bhj_rowWriter3.setNullAt(0);\r\n/* 143 */       } else {\r\n/* 144 */         // Remember the current cursor so that we can calculate how many bytes are\r\n/* 145 */         // written later.\r\n/* 146 */         final int bhj_tmpCursor8 = bhj_holder1.cursor;\r\n/* 147 */\r\n/* 148 */         if (bhj_value6 instanceof UnsafeRow) {\r\n/* 149 */           final int bhj_sizeInBytes2 = ((UnsafeRow) bhj_value6).getSizeInBytes();\r\n/* 150 */           // grow the global buffer before writing data.\r\n/* 151 */           bhj_holder1.grow(bhj_sizeInBytes2);\r\n/* 152 */           ((UnsafeRow) bhj_value6).writeToMemory(bhj_holder1.buffer, bhj_holder1.cursor);\r\n/* 153 */           bhj_holder1.cursor += bhj_sizeInBytes2;\r\n/* 154 */\r\n/* 155 */         } else {\r\n/* 156 */           bhj_rowWriter4.reset();\r\n/* 157 */\r\n/* 158 */           final long bhj_fieldName6 = bhj_value6.getLong(0);\r\n/* 159 */           if (bhj_value6.isNullAt(0)) {\r\n/* 160 */             bhj_rowWriter4.setNullAt(0);\r\n/* 161 */           } else {\r\n/* 162 */             bhj_rowWriter4.write(0, bhj_fieldName6);\r\n/* 163 */           }\r\n/* 164 */\r\n/* 165 */           final long bhj_fieldName7 = bhj_value6.getLong(1);\r\n/* 166 */           if (bhj_value6.isNullAt(1)) {\r\n/* 167 */             bhj_rowWriter4.setNullAt(1);\r\n/* 168 */           } else {\r\n/* 169 */             bhj_rowWriter4.write(1, bhj_fieldName7);\r\n/* 170 */           }\r\n/* 171 */\r\n/* 172 */           final UTF8String bhj_fieldName8 = bhj_value6.getUTF8String(2);\r\n/* 173 */           if (bhj_value6.isNullAt(2)) {\r\n/* 174 */             bhj_rowWriter4.setNullAt(2);\r\n/* 175 */           } else {\r\n/* 176 */             bhj_rowWriter4.write(2, bhj_fieldName8);\r\n/* 177 */           }\r\n/* 178 */         }\r\n/* 179 */\r\n/* 180 */         bhj_rowWriter3.setOffsetAndSize(0, bhj_tmpCursor8, bhj_holder1.cursor - bhj_tmpCursor8);\r\n/* 181 */       }\r\n/* 182 */\r\n/* 183 */       boolean bhj_isNull9 = bhj_isNull3;\r\n/* 184 */       InternalRow bhj_value9 = bhj_value3;\r\n/* 185 */       if (bhj_isNull9) {\r\n/* 186 */         Object bhj_obj1 = ((Expression) references[7]).eval(null);\r\n/* 187 */         InternalRow bhj_value11 = (InternalRow) bhj_obj1;\r\n/* 188 */         if (!false) {\r\n/* 189 */           bhj_isNull9 = false;\r\n/* 190 */           bhj_value9 = bhj_value11;\r\n/* 191 */         }\r\n/* 192 */       }\r\n/* 193 */       if (bhj_isNull9) {\r\n/* 194 */         bhj_rowWriter3.setNullAt(1);\r\n/* 195 */       } else {\r\n/* 196 */         // Remember the current cursor so that we can calculate how many bytes are\r\n/* 197 */         // written later.\r\n/* 198 */         final int bhj_tmpCursor12 = bhj_holder1.cursor;\r\n/* 199 */\r\n/* 200 */         if (bhj_value9 instanceof UnsafeRow) {\r\n/* 201 */           final int bhj_sizeInBytes3 = ((UnsafeRow) bhj_value9).getSizeInBytes();\r\n/* 202 */           // grow the global buffer before writing data.\r\n/* 203 */           bhj_holder1.grow(bhj_sizeInBytes3);\r\n/* 204 */           ((UnsafeRow) bhj_value9).writeToMemory(bhj_holder1.buffer, bhj_holder1.cursor);\r\n/* 205 */           bhj_holder1.cursor += bhj_sizeInBytes3;\r\n/* 206 */\r\n/* 207 */         } else {\r\n/* 208 */           bhj_rowWriter5.reset();\r\n/* 209 */\r\n/* 210 */           final long bhj_fieldName9 = bhj_value9.getLong(0);\r\n/* 211 */           if (bhj_value9.isNullAt(0)) {\r\n/* 212 */             bhj_rowWriter5.setNullAt(0);\r\n/* 213 */           } else {\r\n/* 214 */             bhj_rowWriter5.write(0, bhj_fieldName9);\r\n/* 215 */           }\r\n/* 216 */\r\n/* 217 */           final UTF8String bhj_fieldName10 = bhj_value9.getUTF8String(1);\r\n/* 218 */           if (bhj_value9.isNullAt(1)) {\r\n/* 219 */             bhj_rowWriter5.setNullAt(1);\r\n/* 220 */           } else {\r\n/* 221 */             bhj_rowWriter5.write(1, bhj_fieldName10);\r\n/* 222 */           }\r\n/* 223 */\r\n/* 224 */           final UTF8String bhj_fieldName11 = bhj_value9.getUTF8String(2);\r\n/* 225 */           if (bhj_value9.isNullAt(2)) {\r\n/* 226 */             bhj_rowWriter5.setNullAt(2);\r\n/* 227 */           } else {\r\n/* 228 */             bhj_rowWriter5.write(2, bhj_fieldName11);\r\n/* 229 */           }\r\n/* 230 */         }\r\n/* 231 */\r\n/* 232 */         bhj_rowWriter3.setOffsetAndSize(1, bhj_tmpCursor12, bhj_holder1.cursor - bhj_tmpCursor12);\r\n/* 233 */       }\r\n/* 234 */       bhj_result1.setTotalSize(bhj_holder1.totalSize());\r\n/* 235 */\r\n/* 236 */       // Check if the key has nulls.\r\n/* 237 */       if (!(bhj_result1.anyNull())) {\r\n/* 238 */         // Check if the HashedRelation exists.\r\n/* 239 */         scala.collection.Iterator bhj_matches = (scala.collection.Iterator)bhj_relation1.get(bhj_result1);\r\n/* 240 */         if (bhj_matches != null) {\r\n/* 241 */           // Evaluate the condition.\r\n/* 242 */           boolean bhj_found = false;\r\n/* 243 */           while (!bhj_found && bhj_matches.hasNext()) {\r\n/* 244 */             UnsafeRow bhj_matched1 = (UnsafeRow) bhj_matches.next();\r\n/* 245 */\r\n/* 246 */             boolean bhj_isNull13 = true;\r\n/* 247 */             InternalRow bhj_value13 = null;\r\n/* 248 */             if (bhj_matched1 != null) {\r\n/* 249 */               InternalRow bhj_value12 = bhj_matched1.getStruct(0, 3);\r\n/* 250 */               bhj_isNull13 = false;\r\n/* 251 */               bhj_value13 = bhj_value12;\r\n/* 252 */             }\r\n/* 253 */             boolean bhj_isNull15 = true;\r\n/* 254 */             InternalRow bhj_value15 = null;\r\n/* 255 */             if (bhj_matched1 != null) {\r\n/* 256 */               boolean bhj_isNull14 = bhj_matched1.isNullAt(1);\r\n/* 257 */               InternalRow bhj_value14 = bhj_isNull14 ? null : (bhj_matched1.getStruct(1, 3));\r\n/* 258 */               bhj_isNull15 = bhj_isNull14;\r\n/* 259 */               bhj_value15 = bhj_value14;\r\n/* 260 */             }\r\n/* 261 */\r\n/* 262 */             boolean bhj_value17 = (false && bhj_isNull13) ||\r\n/* 263 */             (!false && !bhj_isNull13 && this.bhj_compareStruct(inputadapter_value, bhj_value13) == 0);\r\n/* 264 */             boolean bhj_value16 = false;\r\n/* 265 */\r\n/* 266 */             if (bhj_value17) {\r\n/* 267 */               boolean bhj_value23 = (bhj_isNull3 && bhj_isNull15) ||\r\n/* 268 */               (!bhj_isNull3 && !bhj_isNull15 && this.bhj_compareStruct1(bhj_value3, bhj_value15) == 0);\r\n/* 269 */               bhj_value16 = bhj_value23;\r\n/* 270 */             }\r\n/* 271 */             if (false || !bhj_value16) continue;\r\n/* 272 */\r\n/* 273 */             bhj_found = true;\r\n/* 274 */           }\r\n/* 275 */           if (bhj_found) continue;\r\n/* 276 */         }\r\n/* 277 */       }\r\n/* 278 */       bhj_numOutputRows1.add(1);\r\n/* 279 */\r\n/* 280 */       UnsafeRow agg_unsafeRowAggBuffer = null;\r\n/* 281 */\r\n/* 282 */       UnsafeRow agg_fastAggBuffer = null;\r\n/* 283 */\r\n/* 284 */       if (agg_fastAggBuffer == null) {\r\n/* 285 */         // generate grouping key\r\n/* 286 */         agg_holder.reset();\r\n/* 287 */\r\n/* 288 */         agg_rowWriter.zeroOutNullBytes();\r\n/* 289 */\r\n/* 290 */         // Remember the current cursor so that we can calculate how many bytes are\r\n/* 291 */         // written later.\r\n/* 292 */         final int agg_tmpCursor = agg_holder.cursor;\r\n/* 293 */\r\n/* 294 */         if (inputadapter_value instanceof UnsafeRow) {\r\n/* 295 */           final int agg_sizeInBytes = ((UnsafeRow) inputadapter_value).getSizeInBytes();\r\n/* 296 */           // grow the global buffer before writing data.\r\n/* 297 */           agg_holder.grow(agg_sizeInBytes);\r\n/* 298 */           ((UnsafeRow) inputadapter_value).writeToMemory(agg_holder.buffer, agg_holder.cursor);\r\n/* 299 */           agg_holder.cursor += agg_sizeInBytes;\r\n/* 300 */\r\n/* 301 */         } else {\r\n/* 302 */           agg_rowWriter1.reset();\r\n/* 303 */\r\n/* 304 */           final long agg_fieldName = inputadapter_value.getLong(0);\r\n/* 305 */           if (inputadapter_value.isNullAt(0)) {\r\n/* 306 */             agg_rowWriter1.setNullAt(0);\r\n/* 307 */           } else {\r\n/* 308 */             agg_rowWriter1.write(0, agg_fieldName);\r\n/* 309 */           }\r\n/* 310 */\r\n/* 311 */           final long agg_fieldName1 = inputadapter_value.getLong(1);\r\n/* 312 */           if (inputadapter_value.isNullAt(1)) {\r\n/* 313 */             agg_rowWriter1.setNullAt(1);\r\n/* 314 */           } else {\r\n/* 315 */             agg_rowWriter1.write(1, agg_fieldName1);\r\n/* 316 */           }\r\n/* 317 */\r\n/* 318 */           final UTF8String agg_fieldName2 = inputadapter_value.getUTF8String(2);\r\n/* 319 */           if (inputadapter_value.isNullAt(2)) {\r\n/* 320 */             agg_rowWriter1.setNullAt(2);\r\n/* 321 */           } else {\r\n/* 322 */             agg_rowWriter1.write(2, agg_fieldName2);\r\n/* 323 */           }\r\n/* 324 */         }\r\n/* 325 */\r\n/* 326 */         agg_rowWriter.setOffsetAndSize(0, agg_tmpCursor, agg_holder.cursor - agg_tmpCursor);\r\n/* 327 */\r\n/* 328 */         if (bhj_isNull3) {\r\n/* 329 */           agg_rowWriter.setNullAt(1);\r\n/* 330 */         } else {\r\n/* 331 */           // Remember the current cursor so that we can calculate how many bytes are\r\n/* 332 */           // written later.\r\n/* 333 */           final int agg_tmpCursor4 = agg_holder.cursor;\r\n/* 334 */\r\n/* 335 */           if (bhj_value3 instanceof UnsafeRow) {\r\n/* 336 */             final int agg_sizeInBytes1 = ((UnsafeRow) bhj_value3).getSizeInBytes();\r\n/* 337 */             // grow the global buffer before writing data.\r\n/* 338 */             agg_holder.grow(agg_sizeInBytes1);\r\n/* 339 */             ((UnsafeRow) bhj_value3).writeToMemory(agg_holder.buffer, agg_holder.cursor);\r\n/* 340 */             agg_holder.cursor += agg_sizeInBytes1;\r\n/* 341 */\r\n/* 342 */           } else {\r\n/* 343 */             agg_rowWriter2.reset();\r\n/* 344 */\r\n/* 345 */             final long agg_fieldName3 = bhj_value3.getLong(0);\r\n/* 346 */             if (bhj_value3.isNullAt(0)) {\r\n/* 347 */               agg_rowWriter2.setNullAt(0);\r\n/* 348 */             } else {\r\n/* 349 */               agg_rowWriter2.write(0, agg_fieldName3);\r\n/* 350 */             }\r\n/* 351 */\r\n/* 352 */             final UTF8String agg_fieldName4 = bhj_value3.getUTF8String(1);\r\n/* 353 */             if (bhj_value3.isNullAt(1)) {\r\n/* 354 */               agg_rowWriter2.setNullAt(1);\r\n/* 355 */             } else {\r\n/* 356 */               agg_rowWriter2.write(1, agg_fieldName4);\r\n/* 357 */             }\r\n/* 358 */\r\n/* 359 */             final UTF8String agg_fieldName5 = bhj_value3.getUTF8String(2);\r\n/* 360 */             if (bhj_value3.isNullAt(2)) {\r\n/* 361 */               agg_rowWriter2.setNullAt(2);\r\n/* 362 */             } else {\r\n/* 363 */               agg_rowWriter2.write(2, agg_fieldName5);\r\n/* 364 */             }\r\n/* 365 */           }\r\n/* 366 */\r\n/* 367 */           agg_rowWriter.setOffsetAndSize(1, agg_tmpCursor4, agg_holder.cursor - agg_tmpCursor4);\r\n/* 368 */         }\r\n/* 369 */         agg_result.setTotalSize(agg_holder.totalSize());\r\n/* 370 */         agg_value4 = 42;\r\n/* 371 */\r\n/* 372 */         final long agg_element = inputadapter_value.getLong(0);\r\n/* 373 */         agg_value4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashLong(agg_element, agg_value4);\r\n/* 374 */\r\n/* 375 */         final long agg_element1 = inputadapter_value.getLong(1);\r\n/* 376 */         agg_value4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashLong(agg_element1, agg_value4);\r\n/* 377 */\r\n/* 378 */         if (!inputadapter_value.isNullAt(2)) {\r\n/* 379 */           final UTF8String agg_element2 = inputadapter_value.getUTF8String(2);\r\n/* 380 */           agg_value4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(agg_element2.getBaseObject(), agg_element2.getBaseOffset(), agg_element2.numBytes(), agg_value4);\r\n/* 381 */\r\n/* 382 */         }\r\n/* 383 */\r\n/* 384 */         if (!bhj_isNull3) {\r\n/* 385 */           final long agg_element3 = bhj_value3.getLong(0);\r\n/* 386 */           agg_value4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashLong(agg_element3, agg_value4);\r\n/* 387 */\r\n/* 388 */           if (!bhj_value3.isNullAt(1)) {\r\n/* 389 */             final UTF8String agg_element4 = bhj_value3.getUTF8String(1);\r\n/* 390 */             agg_value4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(agg_element4.getBaseObject(), agg_element4.getBaseOffset(), agg_element4.numBytes(), agg_value4);\r\n/* 391 */\r\n/* 392 */           }\r\n/* 393 */\r\n/* 394 */           if (!bhj_value3.isNullAt(2)) {\r\n/* 395 */             final UTF8String agg_element5 = bhj_value3.getUTF8String(2);\r\n/* 396 */             agg_value4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(agg_element5.getBaseObject(), agg_element5.getBaseOffset(), agg_element5.numBytes(), agg_value4);\r\n/* 397 */\r\n/* 398 */           }\r\n/* 399 */\r\n/* 400 */         }\r\n/* 401 */         if (true) {\r\n/* 402 */           // try to get the buffer from hash map\r\n/* 403 */           agg_unsafeRowAggBuffer =\r\n/* 404 */           agg_hashMap.getAggregationBufferFromUnsafeRow(agg_result, agg_value4);\r\n/* 405 */         }\r\n/* 406 */         if (agg_unsafeRowAggBuffer == null) {\r\n/* 407 */           if (agg_sorter == null) {\r\n/* 408 */             agg_sorter = agg_hashMap.destructAndCreateExternalSorter();\r\n/* 409 */           } else {\r\n/* 410 */             agg_sorter.merge(agg_hashMap.destructAndCreateExternalSorter());\r\n/* 411 */           }\r\n/* 412 */\r\n/* 413 */           // the hash map had be spilled, it should have enough memory now,\r\n/* 414 */           // try  to allocate buffer again.\r\n/* 415 */           agg_unsafeRowAggBuffer =\r\n/* 416 */           agg_hashMap.getAggregationBufferFromUnsafeRow(agg_result, agg_value4);\r\n/* 417 */           if (agg_unsafeRowAggBuffer == null) {\r\n/* 418 */             // failed to allocate the first page\r\n/* 419 */             throw new OutOfMemoryError(\"No enough memory for aggregation\");\r\n/* 420 */           }\r\n/* 421 */         }\r\n/* 422 */       }\r\n/* 423 */\r\n/* 424 */       if (agg_fastAggBuffer != null) {\r\n/* 425 */         // update fast row\r\n/* 426 */\r\n/* 427 */       } else {\r\n/* 428 */         // update unsafe row\r\n/* 429 */\r\n/* 430 */         // common sub-expressions\r\n/* 431 */\r\n/* 432 */         // evaluate aggregate function\r\n/* 433 */\r\n/* 434 */         // update unsafe row buffer\r\n/* 435 */\r\n/* 436 */       }\r\n/* 437 */       if (shouldStop()) return;\r\n/* 438 */     }\r\n/* 439 */\r\n/* 440 */     agg_mapIter = agg_plan.finishAggregate(agg_hashMap, agg_sorter, agg_peakMemory, agg_spillSize);\r\n/* 441 */   }\r\n/* 442 */\r\n/* 443 */   private void wholestagecodegen_init_2() {\r\n/* 444 */     this.bhj_rowWriter7 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder2, 3);\r\n/* 445 */     this.bhj_rowWriter8 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder2, 3);\r\n/* 446 */     agg_result = new UnsafeRow(2);\r\n/* 447 */     this.agg_holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(agg_result, 64);\r\n/* 448 */     this.agg_rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(agg_holder, 2);\r\n/* 449 */     this.agg_rowWriter1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(agg_holder, 3);\r\n/* 450 */     this.agg_rowWriter2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(agg_holder, 3);\r\n/* 451 */\r\n/* 452 */     agg_result1 = new UnsafeRow(2);\r\n/* 453 */     this.agg_holder1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(agg_result1, 64);\r\n/* 454 */     this.agg_rowWriter3 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(agg_holder1, 2);\r\n/* 455 */     this.agg_rowWriter4 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(agg_holder1, 3);\r\n/* 456 */\r\n/* 457 */   }\r\n/* 458 */\r\n/* 459 */   public int bhj_compareStruct(InternalRow a, InternalRow b) {\r\n/* 460 */     // when comparing unsafe rows, try equals first as it compares the binary directly\r\n/* 461 */     // which is very fast.\r\n/* 462 */     if (a instanceof UnsafeRow && b instanceof UnsafeRow && a.equals(b)) {\r\n/* 463 */       return 0;\r\n/* 464 */     }\r\n/* 465 */     InternalRow i = null;\r\n/* 466 */\r\n/* 467 */     i = a;\r\n/* 468 */     boolean bhj_isNullA;\r\n/* 469 */     long bhj_primitiveA;\r\n/* 470 */     {\r\n/* 471 */       bhj_isNullA = false;\r\n/* 472 */       bhj_primitiveA = inputadapter_value;\r\n/* 473 */     }\r\n/* 474 */     i = b;\r\n/* 475 */     boolean bhj_isNullB;\r\n/* 476 */     long bhj_primitiveB;\r\n/* 477 */     {\r\n/* 478 */       bhj_isNullB = false;\r\n/* 479 */       bhj_primitiveB = inputadapter_value;\r\n/* 480 */     }\r\n/* 481 */     if (bhj_isNullA && bhj_isNullB) {\r\n/* 482 */       // Nothing\r\n/* 483 */     } else if (bhj_isNullA) {\r\n/* 484 */       return -1;\r\n/* 485 */     } else if (bhj_isNullB) {\r\n/* 486 */       return 1;\r\n/* 487 */     } else {\r\n/* 488 */       int comp = (bhj_primitiveA > bhj_primitiveB ? 1 : bhj_primitiveA < bhj_primitiveB ? -1 : 0);\r\n/* 489 */       if (comp != 0) {\r\n/* 490 */         return comp;\r\n/* 491 */       }\r\n/* 492 */     }\r\n/* 493 */\r\n/* 494 */     i = a;\r\n/* 495 */     boolean bhj_isNullA1;\r\n/* 496 */     long bhj_primitiveA1;\r\n/* 497 */     {\r\n/* 498 */       bhj_isNullA1 = bhj_isNull3;\r\n/* 499 */       bhj_primitiveA1 = bhj_value3;\r\n/* 500 */     }\r\n/* 501 */     i = b;\r\n/* 502 */     boolean bhj_isNullB1;\r\n/* 503 */     long bhj_primitiveB1;\r\n/* 504 */     {\r\n/* 505 */       bhj_isNullB1 = bhj_isNull3;\r\n/* 506 */       bhj_primitiveB1 = bhj_value3;\r\n/* 507 */     }\r\n/* 508 */     if (bhj_isNullA1 && bhj_isNullB1) {\r\n/* 509 */       // Nothing\r\n/* 510 */     } else if (bhj_isNullA1) {\r\n/* 511 */       return -1;\r\n/* 512 */     } else if (bhj_isNullB1) {\r\n/* 513 */       return 1;\r\n/* 514 */     } else {\r\n/* 515 */       int comp = (bhj_primitiveA1 > bhj_primitiveB1 ? 1 : bhj_primitiveA1 < bhj_primitiveB1 ? -1 : 0);\r\n/* 516 */       if (comp != 0) {\r\n/* 517 */         return comp;\r\n/* 518 */       }\r\n/* 519 */     }\r\n/* 520 */\r\n/* 521 */     i = a;\r\n/* 522 */     boolean bhj_isNullA2;\r\n/* 523 */     UTF8String bhj_primitiveA2;\r\n/* 524 */     {\r\n/* 525 */       bhj_isNullA2 = bhj_isNull13;\r\n/* 526 */       bhj_primitiveA2 = bhj_value13;\r\n/* 527 */     }\r\n/* 528 */     i = b;\r\n/* 529 */     boolean bhj_isNullB2;\r\n/* 530 */     UTF8String bhj_primitiveB2;\r\n/* 531 */     {\r\n/* 532 */       bhj_isNullB2 = bhj_isNull13;\r\n/* 533 */       bhj_primitiveB2 = bhj_value13;\r\n/* 534 */     }\r\n/* 535 */     if (bhj_isNullA2 && bhj_isNullB2) {\r\n/* 536 */       // Nothing\r\n/* 537 */     } else if (bhj_isNullA2) {\r\n/* 538 */       return -1;\r\n/* 539 */     } else if (bhj_isNullB2) {\r\n/* 540 */       return 1;\r\n/* 541 */     } else {\r\n/* 542 */       int comp = bhj_primitiveA2.compare(bhj_primitiveB2);\r\n/* 543 */       if (comp != 0) {\r\n/* 544 */         return comp;\r\n/* 545 */       }\r\n/* 546 */     }\r\n/* 547 */\r\n/* 548 */     return 0;\r\n/* 549 */   }\r\n/* 550 */\r\n/* 551 */   private void wholestagecodegen_init_1() {\r\n/* 552 */     this.bhj_broadcast1 = (org.apache.spark.broadcast.TorrentBroadcast) references[5];\r\n/* 553 */\r\n/* 554 */     bhj_relation1 = ((org.apache.spark.sql.execution.joins.UnsafeHashedRelation) bhj_broadcast1.value()).asReadOnlyCopy();\r\n/* 555 */     incPeakExecutionMemory(bhj_relation1.estimatedSize());\r\n/* 556 */\r\n/* 557 */     bhj_result1 = new UnsafeRow(2);\r\n/* 558 */     this.bhj_holder1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(bhj_result1, 64);\r\n/* 559 */     this.bhj_rowWriter3 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder1, 2);\r\n/* 560 */     this.bhj_rowWriter4 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder1, 3);\r\n/* 561 */     this.bhj_rowWriter5 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder1, 3);\r\n/* 562 */     this.bhj_numOutputRows1 = (org.apache.spark.sql.execution.metric.SQLMetric) references[8];\r\n/* 563 */     bhj_result2 = new UnsafeRow(2);\r\n/* 564 */     this.bhj_holder2 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(bhj_result2, 64);\r\n/* 565 */     this.bhj_rowWriter6 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(bhj_holder2, 2);\r\n/* 566 */\r\n/* 567 */   }\r\n/* 568 */\r\n/* 569 */   public int bhj_compareStruct1(InternalRow a, InternalRow b) {\r\n/* 570 */     // when comparing unsafe rows, try equals first as it compares the binary directly\r\n/* 571 */     // which is very fast.\r\n/* 572 */     if (a instanceof UnsafeRow && b instanceof UnsafeRow && a.equals(b)) {\r\n/* 573 */       return 0;\r\n/* 574 */     }\r\n/* 575 */     InternalRow i = null;\r\n/* 576 */\r\n/* 577 */     i = a;\r\n/* 578 */     boolean bhj_isNullA3;\r\n/* 579 */     long bhj_primitiveA3;\r\n/* 580 */     {\r\n/* 581 */       bhj_isNullA3 = false;\r\n/* 582 */       bhj_primitiveA3 = inputadapter_value;\r\n/* 583 */     }\r\n/* 584 */     i = b;\r\n/* 585 */     boolean bhj_isNullB3;\r\n/* 586 */     long bhj_primitiveB3;\r\n/* 587 */     {\r\n/* 588 */       bhj_isNullB3 = false;\r\n/* 589 */       bhj_primitiveB3 = inputadapter_value;\r\n/* 590 */     }\r\n/* 591 */     if (bhj_isNullA3 && bhj_isNullB3) {\r\n/* 592 */       // Nothing\r\n/* 593 */     } else if (bhj_isNullA3) {\r\n/* 594 */       return -1;\r\n/* 595 */     } else if (bhj_isNullB3) {\r\n/* 596 */       return 1;\r\n/* 597 */     } else {\r\n/* 598 */       int comp = (bhj_primitiveA3 > bhj_primitiveB3 ? 1 : bhj_primitiveA3 < bhj_primitiveB3 ? -1 : 0);\r\n/* 599 */       if (comp != 0) {\r\n/* 600 */         return comp;\r\n/* 601 */       }\r\n/* 602 */     }\r\n/* 603 */\r\n/* 604 */     i = a;\r\n/* 605 */     boolean bhj_isNullA4;\r\n/* 606 */     UTF8String bhj_primitiveA4;\r\n/* 607 */     {\r\n/* 608 */       bhj_isNullA4 = bhj_isNull3;\r\n/* 609 */       bhj_primitiveA4 = bhj_value3;\r\n/* 610 */     }\r\n/* 611 */     i = b;\r\n/* 612 */     boolean bhj_isNullB4;\r\n/* 613 */     UTF8String bhj_primitiveB4;\r\n/* 614 */     {\r\n/* 615 */       bhj_isNullB4 = bhj_isNull3;\r\n/* 616 */       bhj_primitiveB4 = bhj_value3;\r\n/* 617 */     }\r\n/* 618 */     if (bhj_isNullA4 && bhj_isNullB4) {\r\n/* 619 */       // Nothing\r\n/* 620 */     } else if (bhj_isNullA4) {\r\n/* 621 */       return -1;\r\n/* 622 */     } else if (bhj_isNullB4) {\r\n/* 623 */       return 1;\r\n/* 624 */     } else {\r\n/* 625 */       int comp = bhj_primitiveA4.compare(bhj_primitiveB4);\r\n/* 626 */       if (comp != 0) {\r\n/* 627 */         return comp;\r\n/* 628 */       }\r\n/* 629 */     }\r\n/* 630 */\r\n/* 631 */     i = a;\r\n/* 632 */     boolean bhj_isNullA5;\r\n/* 633 */     UTF8String bhj_primitiveA5;\r\n/* 634 */     {\r\n/* 635 */       bhj_isNullA5 = bhj_isNull13;\r\n/* 636 */       bhj_primitiveA5 = bhj_value13;\r\n/* 637 */     }\r\n/* 638 */     i = b;\r\n/* 639 */     boolean bhj_isNullB5;\r\n/* 640 */     UTF8String bhj_primitiveB5;\r\n/* 641 */     {\r\n/* 642 */       bhj_isNullB5 = bhj_isNull13;\r\n/* 643 */       bhj_primitiveB5 = bhj_value13;\r\n/* 644 */     }\r\n/* 645 */     if (bhj_isNullA5 && bhj_isNullB5) {\r\n/* 646 */       // Nothing\r\n/* 647 */     } else if (bhj_isNullA5) {\r\n/* 648 */       return -1;\r\n/* 649 */     } else if (bhj_isNullB5) {\r\n/* 650 */       return 1;\r\n/* 651 */     } else {\r\n/* 652 */       int comp = bhj_primitiveA5.compare(bhj_primitiveB5);\r\n/* 653 */       if (comp != 0) {\r\n/* 654 */         return comp;\r\n/* 655 */       }\r\n/* 656 */     }\r\n/* 657 */\r\n/* 658 */     return 0;\r\n/* 659 */   }\r\n/* 660 */\r\n/* 661 */   protected void processNext() throws java.io.IOException {\r\n/* 662 */     if (!agg_initAgg) {\r\n/* 663 */       agg_initAgg = true;\r\n/* 664 */       long wholestagecodegen_beforeAgg = System.nanoTime();\r\n/* 665 */       agg_doAggregateWithKeys();\r\n/* 666 */       wholestagecodegen_aggTime.add((System.nanoTime() - wholestagecodegen_beforeAgg) / 1000000);\r\n/* 667 */     }\r\n/* 668 */\r\n/* 669 */     // output the result\r\n/* 670 */\r\n/* 671 */     while (agg_mapIter.next()) {\r\n/* 672 */       wholestagecodegen_numOutputRows.add(1);\r\n/* 673 */       UnsafeRow agg_aggKey = (UnsafeRow) agg_mapIter.getKey();\r\n/* 674 */       UnsafeRow agg_aggBuffer = (UnsafeRow) agg_mapIter.getValue();\r\n/* 675 */\r\n/* 676 */       InternalRow agg_value7 = agg_aggKey.getStruct(0, 3);\r\n/* 677 */       boolean agg_isNull8 = agg_aggKey.isNullAt(1);\r\n/* 678 */       InternalRow agg_value8 = agg_isNull8 ? null : (agg_aggKey.getStruct(1, 3));\r\n/* 679 */       agg_holder1.reset();\r\n/* 680 */\r\n/* 681 */       agg_rowWriter3.zeroOutNullBytes();\r\n/* 682 */\r\n/* 683 */       // Remember the current cursor so that we can calculate how many bytes are\r\n/* 684 */       // written later.\r\n/* 685 */       final int agg_tmpCursor8 = agg_holder1.cursor;\r\n/* 686 */\r\n/* 687 */       if (agg_value7 instanceof UnsafeRow) {\r\n/* 688 */         final int agg_sizeInBytes2 = ((UnsafeRow) agg_value7).getSizeInBytes();\r\n/* 689 */         // grow the global buffer before writing data.\r\n/* 690 */         agg_holder1.grow(agg_sizeInBytes2);\r\n/* 691 */         ((UnsafeRow) agg_value7).writeToMemory(agg_holder1.buffer, agg_holder1.cursor);\r\n/* 692 */         agg_holder1.cursor += agg_sizeInBytes2;\r\n/* 693 */\r\n/* 694 */       } else {\r\n/* 695 */         agg_rowWriter4.reset();\r\n/* 696 */\r\n/* 697 */         final long agg_fieldName6 = agg_value7.getLong(0);\r\n/* 698 */         if (agg_value7.isNullAt(0)) {\r\n/* 699 */           agg_rowWriter4.setNullAt(0);\r\n/* 700 */         } else {\r\n/* 701 */           agg_rowWriter4.write(0, agg_fieldName6);\r\n/* 702 */         }\r\n/* 703 */\r\n/* 704 */         final long agg_fieldName7 = agg_value7.getLong(1);\r\n/* 705 */         if (agg_value7.isNullAt(1)) {\r\n/* 706 */           agg_rowWriter4.setNullAt(1);\r\n/* 707 */         } else {\r\n/* 708 */           agg_rowWriter4.write(1, agg_fieldName7);\r\n/* 709 */         }\r\n/* 710 */\r\n/* 711 */         final UTF8String agg_fieldName8 = agg_value7.getUTF8String(2);\r\n/* 712 */         if (agg_value7.isNullAt(2)) {\r\n/* 713 */           agg_rowWriter4.setNullAt(2);\r\n/* 714 */         } else {\r\n/* 715 */           agg_rowWriter4.write(2, agg_fieldName8);\r\n/* 716 */         }\r\n/* 717 */       }\r\n/* 718 */\r\n/* 719 */       agg_rowWriter3.setOffsetAndSize(0, agg_tmpCursor8, agg_holder1.cursor - agg_tmpCursor8);\r\n/* 720 */\r\n/* 721 */       if (agg_isNull8) {\r\n/* 722 */         agg_rowWriter3.setNullAt(1);\r\n/* 723 */       } else {\r\n/* 724 */         // Remember the current cursor so that we can calculate how many bytes are\r\n/* 725 */         // written later.\r\n/* 726 */         final int agg_tmpCursor12 = agg_holder1.cursor;\r\n/* 727 */\r\n/* 728 */         if (agg_value8 instanceof UnsafeRow) {\r\n/* 729 */           final int agg_sizeInBytes3 = ((UnsafeRow) agg_value8).getSizeInBytes();\r\n/* 730 */           // grow the global buffer before writing data.\r\n/* 731 */           agg_holder1.grow(agg_sizeInBytes3);\r\n/* 732 */           ((UnsafeRow) agg_value8).writeToMemory(agg_holder1.buffer, agg_holder1.cursor);\r\n/* 733 */           agg_holder1.cursor += agg_sizeInBytes3;\r\n/* 734 */\r\n/* 735 */         } else {\r\n/* 736 */           agg_rowWriter5.reset();\r\n/* 737 */\r\n/* 738 */           final long agg_fieldName9 = agg_value8.getLong(0);\r\n/* 739 */           if (agg_value8.isNullAt(0)) {\r\n/* 740 */             agg_rowWriter5.setNullAt(0);\r\n/* 741 */           } else {\r\n/* 742 */             agg_rowWriter5.write(0, agg_fieldName9);\r\n/* 743 */           }\r\n/* 744 */\r\n/* 745 */           final UTF8String agg_fieldName10 = agg_value8.getUTF8String(1);\r\n/* 746 */           if (agg_value8.isNullAt(1)) {\r\n/* 747 */             agg_rowWriter5.setNullAt(1);\r\n/* 748 */           } else {\r\n/* 749 */             agg_rowWriter5.write(1, agg_fieldName10);\r\n/* 750 */           }\r\n/* 751 */\r\n/* 752 */           final UTF8String agg_fieldName11 = agg_value8.getUTF8String(2);\r\n/* 753 */           if (agg_value8.isNullAt(2)) {\r\n/* 754 */             agg_rowWriter5.setNullAt(2);\r\n/* 755 */           } else {\r\n/* 756 */             agg_rowWriter5.write(2, agg_fieldName11);\r\n/* 757 */           }\r\n/* 758 */         }\r\n/* 759 */\r\n/* 760 */         agg_rowWriter3.setOffsetAndSize(1, agg_tmpCursor12, agg_holder1.cursor - agg_tmpCursor12);\r\n/* 761 */       }\r\n/* 762 */       agg_result1.setTotalSize(agg_holder1.totalSize());\r\n/* 763 */       append(agg_result1);\r\n/* 764 */\r\n/* 765 */       if (shouldStop()) return;\r\n/* 766 */     }\r\n/* 767 */\r\n/* 768 */     agg_mapIter.close();\r\n/* 769 */     if (agg_sorter == null) {\r\n/* 770 */       agg_hashMap.free();\r\n/* 771 */     }\r\n/* 772 */   }\r\n/* 773 */ }\r\norg.codehaus.commons.compiler.CompileException: File 'generated.java', Line 472, Column 36: Expression \"inputadapter_value\" is not an rvalue\r\n\tat org.codehaus.janino.UnitCompiler.compileError(UnitCompiler.java:11004)\r\n\tat org.codehaus.janino.UnitCompiler.toRvalueOrCompileException(UnitCompiler.java:6639)\r\n\tat org.codehaus.janino.UnitCompiler.getConstantValue2(UnitCompiler.java:5001)\r\n\tat org.codehaus.janino.UnitCompiler.access$10500(UnitCompiler.java:206)\r\n\tat org.codehaus.janino.UnitCompiler$13.visitAmbiguousName(UnitCompiler.java:4984)\r\n\tat org.codehaus.janino.Java$AmbiguousName.accept(Java.java:3633)\r\n\tat org.codehaus.janino.Java$Lvalue.accept(Java.java:3563)\r\n\tat org.codehaus.janino.UnitCompiler.getConstantValue(UnitCompiler.java:4956)\r\n\tat org.codehaus.janino.UnitCompiler.compileGetValue(UnitCompiler.java:4925)\r\n\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:3189)\r\n\tat org.codehaus.janino.UnitCompiler.access$5100(UnitCompiler.java:206)\r\n\tat org.codehaus.janino.UnitCompiler$9.visitAssignment(UnitCompiler.java:3143)\r\n\tat org.codehaus.janino.UnitCompiler$9.visitAssignment(UnitCompiler.java:3139)\r\n\tat org.codehaus.janino.Java$Assignment.accept(Java.java:3847)\r\n\tat org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:3139)\r\n\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2112)\r\n\tat org.codehaus.janino.UnitCompiler.access$1700(UnitCompiler.java:206)\r\n\tat org.codehaus.janino.UnitCompiler$6.visitExpressionStatement(UnitCompiler.java:1377)\r\n\tat org.codehaus.janino.UnitCompiler$6.visitExpressionStatement(UnitCompiler.java:1370)\r\n\tat org.codehaus.janino.Java$ExpressionStatement.accept(Java.java:2558)\r\n\tat org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1370)\r\n\tat org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1450)\r\n\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1436)\r\n\tat org.codehaus.janino.UnitCompiler.access$1600(UnitCompiler.java:206)\r\n\tat org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1376)\r\n\tat org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1370)\r\n\tat org.codehaus.janino.Java$Block.accept(Java.java:2471)\r\n\tat org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1370)\r\n\tat org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1450)\r\n\tat org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:2811)\r\n\tat org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1262)\r\n\tat org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1234)\r\n\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:538)\r\n\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:890)\r\n\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:894)\r\n\tat org.codehaus.janino.UnitCompiler.access$600(UnitCompiler.java:206)\r\n\tat org.codehaus.janino.UnitCompiler$2.visitMemberClassDeclaration(UnitCompiler.java:377)\r\n\tat org.codehaus.janino.UnitCompiler$2.visitMemberClassDeclaration(UnitCompiler.java:369)\r\n\tat org.codehaus.janino.Java$MemberClassDeclaration.accept(Java.java:1128)\r\n\tat org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:369)\r\n\tat org.codehaus.janino.UnitCompiler.compileDeclaredMemberTypes(UnitCompiler.java:1209)\r\n\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:564)\r\n\tat org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:420)\r\n\tat org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:206)\r\n\tat org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:374)\r\n\tat org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:369)\r\n\tat org.codehaus.janino.Java$AbstractPackageMemberClassDeclaration.accept(Java.java:1309)\r\n\tat org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:369)\r\n\tat org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:345)\r\n\tat org.codehaus.janino.SimpleCompiler.compileToClassLoader(SimpleCompiler.java:396)\r\n\tat org.codehaus.janino.ClassBodyEvaluator.compileToClass(ClassBodyEvaluator.java:311)\r\n\tat org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:229)\r\n\tat org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:196)\r\n\tat org.codehaus.commons.compiler.Cookable.cook(Cookable.java:91)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:935)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:998)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:995)\r\n\tat org.spark_project.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)\r\n\tat org.spark_project.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)\r\n\tat org.spark_project.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)\r\n\tat org.spark_project.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)\r\n\tat org.spark_project.guava.cache.LocalCache.get(LocalCache.java:4000)\r\n\tat org.spark_project.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)\r\n\tat org.spark_project.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:890)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:357)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.prepareShuffleDependency(ShuffleExchange.scala:85)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:121)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:112)\r\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.doExecute(ShuffleExchange.scala:112)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\r\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:235)\r\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:368)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\r\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:225)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:272)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\r\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$collect$1.apply(Dataset.scala:2375)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$collect$1.apply(Dataset.scala:2375)\r\n\tat org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2778)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2375)\r\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:2351)\r\n\tat org.graphframes.PatternMatchSuite$$anonfun$6.apply$mcV$sp(PatternMatchSuite.scala:103)\r\n\tat org.graphframes.PatternMatchSuite$$anonfun$6.apply(PatternMatchSuite.scala:99)\r\n\tat org.graphframes.PatternMatchSuite$$anonfun$6.apply(PatternMatchSuite.scala:99)\r\n\tat org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)\r\n\tat org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)\r\n\tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\r\n\tat org.scalatest.Transformer.apply(Transformer.scala:22)\r\n\tat org.scalatest.Transformer.apply(Transformer.scala:20)\r\n\tat org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)\r\n\tat org.graphframes.SparkFunSuite.withFixture(SparkFunSuite.scala:40)\r\n\tat org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)\r\n\tat org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)\r\n\tat org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)\r\n\tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\r\n\tat org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)\r\n\tat org.scalatest.FunSuite.runTest(FunSuite.scala:1555)\r\n\tat org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)\r\n\tat org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)\r\n\tat org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)\r\n\tat org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)\r\n\tat scala.collection.immutable.List.foreach(List.scala:381)\r\n\tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\r\n\tat org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)\r\n\tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)\r\n\tat org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)\r\n\tat org.scalatest.FunSuite.runTests(FunSuite.scala:1555)\r\n\tat org.scalatest.Suite$class.run(Suite.scala:1424)\r\n\tat org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)\r\n\tat org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)\r\n\tat org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)\r\n\tat org.scalatest.SuperEngine.runImpl(Engine.scala:545)\r\n\tat org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)\r\n\tat org.graphframes.PatternMatchSuite.org$scalatest$BeforeAndAfterAll$$super$run(PatternMatchSuite.scala:25)\r\n\tat org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)\r\n\tat org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)\r\n\tat org.graphframes.PatternMatchSuite.run(PatternMatchSuite.scala:25)\r\n\tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:357)\r\n\tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:502)\r\n\tat sbt.ForkMain$Run$2.call(ForkMain.java:294)\r\n\tat sbt.ForkMain$Run$2.call(ForkMain.java:284)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/160", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/160/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/160/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/160/events", "html_url": "https://github.com/graphframes/graphframes/issues/160", "id": 199104854, "node_id": "MDU6SXNzdWUxOTkxMDQ4NTQ=", "number": 160, "title": "ConnectedComponents checkpointing should construct FileSystem using Path", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/graphframes/graphframes/milestones/2", "html_url": "https://github.com/graphframes/graphframes/milestone/2", "labels_url": "https://api.github.com/repos/graphframes/graphframes/milestones/2/labels", "id": 2241469, "node_id": "MDk6TWlsZXN0b25lMjI0MTQ2OQ==", "number": 2, "title": "0.3.1", "description": "", "creator": {"login": "thunterdb", "id": 7594753, "node_id": "MDQ6VXNlcjc1OTQ3NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7594753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thunterdb", "html_url": "https://github.com/thunterdb", "followers_url": "https://api.github.com/users/thunterdb/followers", "following_url": "https://api.github.com/users/thunterdb/following{/other_user}", "gists_url": "https://api.github.com/users/thunterdb/gists{/gist_id}", "starred_url": "https://api.github.com/users/thunterdb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thunterdb/subscriptions", "organizations_url": "https://api.github.com/users/thunterdb/orgs", "repos_url": "https://api.github.com/users/thunterdb/repos", "events_url": "https://api.github.com/users/thunterdb/events{/privacy}", "received_events_url": "https://api.github.com/users/thunterdb/received_events", "type": "User", "site_admin": false}, "open_issues": 6, "closed_issues": 3, "state": "open", "created_at": "2017-01-10T17:35:54Z", "updated_at": "2019-01-07T15:55:30Z", "due_on": null, "closed_at": null}, "comments": 0, "created_at": "2017-01-06T01:43:30Z", "updated_at": "2017-01-17T22:46:07Z", "closed_at": "2017-01-17T22:46:07Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "See https://www.mail-archive.com/user@spark.apache.org/msg60669.html for the original bug report.  I recommend we modify FileSystem constructors to take Path + hadoop config, rather than only the hadoop config.  That should be more robust AFAIK.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/157", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/157/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/157/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/157/events", "html_url": "https://github.com/graphframes/graphframes/issues/157", "id": 198211038, "node_id": "MDU6SXNzdWUxOTgyMTEwMzg=", "number": 157, "title": "GraphFrames package for Spark 2.1", "user": {"login": "nchammas", "id": 1039369, "node_id": "MDQ6VXNlcjEwMzkzNjk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1039369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nchammas", "html_url": "https://github.com/nchammas", "followers_url": "https://api.github.com/users/nchammas/followers", "following_url": "https://api.github.com/users/nchammas/following{/other_user}", "gists_url": "https://api.github.com/users/nchammas/gists{/gist_id}", "starred_url": "https://api.github.com/users/nchammas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nchammas/subscriptions", "organizations_url": "https://api.github.com/users/nchammas/orgs", "repos_url": "https://api.github.com/users/nchammas/repos", "events_url": "https://api.github.com/users/nchammas/events{/privacy}", "received_events_url": "https://api.github.com/users/nchammas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/graphframes/graphframes/milestones/2", "html_url": "https://github.com/graphframes/graphframes/milestone/2", "labels_url": "https://api.github.com/repos/graphframes/graphframes/milestones/2/labels", "id": 2241469, "node_id": "MDk6TWlsZXN0b25lMjI0MTQ2OQ==", "number": 2, "title": "0.3.1", "description": "", "creator": {"login": "thunterdb", "id": 7594753, "node_id": "MDQ6VXNlcjc1OTQ3NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7594753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thunterdb", "html_url": "https://github.com/thunterdb", "followers_url": "https://api.github.com/users/thunterdb/followers", "following_url": "https://api.github.com/users/thunterdb/following{/other_user}", "gists_url": "https://api.github.com/users/thunterdb/gists{/gist_id}", "starred_url": "https://api.github.com/users/thunterdb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thunterdb/subscriptions", "organizations_url": "https://api.github.com/users/thunterdb/orgs", "repos_url": "https://api.github.com/users/thunterdb/repos", "events_url": "https://api.github.com/users/thunterdb/events{/privacy}", "received_events_url": "https://api.github.com/users/thunterdb/received_events", "type": "User", "site_admin": false}, "open_issues": 6, "closed_issues": 3, "state": "open", "created_at": "2017-01-10T17:35:54Z", "updated_at": "2019-01-07T15:55:30Z", "due_on": null, "closed_at": null}, "comments": 11, "created_at": "2016-12-31T01:20:56Z", "updated_at": "2017-05-10T17:49:07Z", "closed_at": "2017-05-10T17:49:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Is it safe/correct to use the GraphFrames package built for Spark 2.0 with Spark 2.1?\r\n\r\nIf not, I guess consider this issue a placeholder for creating a GraphFrames package built for Spark 2.1.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/149", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/149/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/149/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/149/events", "html_url": "https://github.com/graphframes/graphframes/issues/149", "id": 195602846, "node_id": "MDU6SXNzdWUxOTU2MDI4NDY=", "number": 149, "title": "Make graphx to graphframe converters public", "user": {"login": "lewisc", "id": 436131, "node_id": "MDQ6VXNlcjQzNjEzMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/436131?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lewisc", "html_url": "https://github.com/lewisc", "followers_url": "https://api.github.com/users/lewisc/followers", "following_url": "https://api.github.com/users/lewisc/following{/other_user}", "gists_url": "https://api.github.com/users/lewisc/gists{/gist_id}", "starred_url": "https://api.github.com/users/lewisc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lewisc/subscriptions", "organizations_url": "https://api.github.com/users/lewisc/orgs", "repos_url": "https://api.github.com/users/lewisc/repos", "events_url": "https://api.github.com/users/lewisc/events{/privacy}", "received_events_url": "https://api.github.com/users/lewisc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-12-14T18:03:08Z", "updated_at": "2017-01-10T17:53:31Z", "closed_at": "2017-01-10T17:53:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The graphx to graphframe (and vice versa) conversion logic is hidden behind a private tag. Is there a specific reason for this or could these be made public?\r\n\r\nI would be willing to make the changes (and also possibly add some tests to cover the code?) if that's acceptably by the project.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/146", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/146/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/146/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/146/events", "html_url": "https://github.com/graphframes/graphframes/issues/146", "id": 193242773, "node_id": "MDU6SXNzdWUxOTMyNDI3NzM=", "number": 146, "title": "GraphFrames 0.3.0 java.lang.IncompatibleClassChangeError", "user": {"login": "michaelqiu94", "id": 11432805, "node_id": "MDQ6VXNlcjExNDMyODA1", "avatar_url": "https://avatars2.githubusercontent.com/u/11432805?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelqiu94", "html_url": "https://github.com/michaelqiu94", "followers_url": "https://api.github.com/users/michaelqiu94/followers", "following_url": "https://api.github.com/users/michaelqiu94/following{/other_user}", "gists_url": "https://api.github.com/users/michaelqiu94/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelqiu94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelqiu94/subscriptions", "organizations_url": "https://api.github.com/users/michaelqiu94/orgs", "repos_url": "https://api.github.com/users/michaelqiu94/repos", "events_url": "https://api.github.com/users/michaelqiu94/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelqiu94/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2016-12-02T23:25:40Z", "updated_at": "2018-08-07T15:26:00Z", "closed_at": "2017-01-05T00:30:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using GraphFrames 0.3.0, and whenever I try to load/create any kind of GraphFrame, I get this error:\r\n\r\nException in thread \"main\" java.lang.IncompatibleClassChangeError: Implementing class\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:73)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:368)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:362)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:361)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:73)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:368)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:362)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:361)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\r\nI even tried loading an example GraphFrame from import org.graphframes.examples, and same result.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/142", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/142/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/142/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/142/events", "html_url": "https://github.com/graphframes/graphframes/issues/142", "id": 188925992, "node_id": "MDU6SXNzdWUxODg5MjU5OTI=", "number": 142, "title": "Update graphframes.github.io for v0.3.0", "user": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "thunterdb", "id": 7594753, "node_id": "MDQ6VXNlcjc1OTQ3NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7594753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thunterdb", "html_url": "https://github.com/thunterdb", "followers_url": "https://api.github.com/users/thunterdb/followers", "following_url": "https://api.github.com/users/thunterdb/following{/other_user}", "gists_url": "https://api.github.com/users/thunterdb/gists{/gist_id}", "starred_url": "https://api.github.com/users/thunterdb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thunterdb/subscriptions", "organizations_url": "https://api.github.com/users/thunterdb/orgs", "repos_url": "https://api.github.com/users/thunterdb/repos", "events_url": "https://api.github.com/users/thunterdb/events{/privacy}", "received_events_url": "https://api.github.com/users/thunterdb/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "thunterdb", "id": 7594753, "node_id": "MDQ6VXNlcjc1OTQ3NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7594753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thunterdb", "html_url": "https://github.com/thunterdb", "followers_url": "https://api.github.com/users/thunterdb/followers", "following_url": "https://api.github.com/users/thunterdb/following{/other_user}", "gists_url": "https://api.github.com/users/thunterdb/gists{/gist_id}", "starred_url": "https://api.github.com/users/thunterdb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thunterdb/subscriptions", "organizations_url": "https://api.github.com/users/thunterdb/orgs", "repos_url": "https://api.github.com/users/thunterdb/repos", "events_url": "https://api.github.com/users/thunterdb/events{/privacy}", "received_events_url": "https://api.github.com/users/thunterdb/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2016-11-12T18:14:01Z", "updated_at": "2016-11-16T18:21:48Z", "closed_at": "2016-11-16T18:21:48Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I tried to update graphframes.github.io but got this error from `PRODUCTION=1 jekyll build`:\r\n\r\n~~~\r\n# Sphinx version: 1.2.3\r\n# Python version: 2.7.9\r\n# Docutils version: 0.12 release\r\n# Jinja2 version: 2.7.3\r\n# Loaded extensions:\r\n#   underscores from /Users/meng/src/graphframes/python/docs/underscores.pyc\r\n#   epytext from /Users/meng/src/graphframes/python/docs/epytext.pyc\r\n#   sphinx.ext.autodoc from /Users/meng/anaconda/lib/python2.7/site-packages/sphinx/ext/autodoc.pyc\r\n#   sphinx.ext.viewcode from /Users/meng/anaconda/lib/python2.7/site-packages/sphinx/ext/viewcode.pyc\r\n#   sphinx.ext.oldcmarkup from /Users/meng/anaconda/lib/python2.7/site-packages/sphinx/ext/oldcmarkup.pyc\r\nTraceback (most recent call last):\r\n  File \"/Users/meng/anaconda/lib/python2.7/site-packages/sphinx/cmdline.py\", line 254, in main\r\n    app.build(force_all, filenames)\r\n  File \"/Users/meng/anaconda/lib/python2.7/site-packages/sphinx/application.py\", line 229, in build\r\n    self.emit('build-finished', None)\r\n  File \"/Users/meng/anaconda/lib/python2.7/site-packages/sphinx/application.py\", line 408, in emit\r\n    results.append(callback(self, *args))\r\n  File \"/Users/meng/src/graphframes/python/docs/underscores.py\", line 63, in move_private_folders\r\n    shutil.move(join(item), join(item[1:]))\r\n  File \"/Users/meng/anaconda/lib/python2.7/shutil.py\", line 292, in move\r\n    raise Error, \"Destination path '%s' already exists\" % real_dst\r\nError: Destination path '/Users/meng/src/graphframes/python/docs/_build/html/modules/_modules' already exists\r\n~~~\r\n\r\ncc: @thunterdb ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/139", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/139/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/139/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/139/events", "html_url": "https://github.com/graphframes/graphframes/issues/139", "id": 188798369, "node_id": "MDU6SXNzdWUxODg3OTgzNjk=", "number": 139, "title": "Set up integration with scoverage and codecov", "user": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 314294551, "node_id": "MDU6TGFiZWwzMTQyOTQ1NTE=", "url": "https://api.github.com/repos/graphframes/graphframes/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 314294552, "node_id": "MDU6TGFiZWwzMTQyOTQ1NTI=", "url": "https://api.github.com/repos/graphframes/graphframes/labels/help%20wanted", "name": "help wanted", "color": "159818", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-11-11T16:32:34Z", "updated_at": "2016-11-11T22:17:17Z", "closed_at": "2016-11-11T22:17:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "so we can measure the test coverage.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/134", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/134/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/134/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/134/events", "html_url": "https://github.com/graphframes/graphframes/issues/134", "id": 188496740, "node_id": "MDU6SXNzdWUxODg0OTY3NDA=", "number": 134, "title": "Graphframe connected component bug", "user": {"login": "mavencode01", "id": 542912, "node_id": "MDQ6VXNlcjU0MjkxMg==", "avatar_url": "https://avatars0.githubusercontent.com/u/542912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mavencode01", "html_url": "https://github.com/mavencode01", "followers_url": "https://api.github.com/users/mavencode01/followers", "following_url": "https://api.github.com/users/mavencode01/following{/other_user}", "gists_url": "https://api.github.com/users/mavencode01/gists{/gist_id}", "starred_url": "https://api.github.com/users/mavencode01/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mavencode01/subscriptions", "organizations_url": "https://api.github.com/users/mavencode01/orgs", "repos_url": "https://api.github.com/users/mavencode01/repos", "events_url": "https://api.github.com/users/mavencode01/events{/privacy}", "received_events_url": "https://api.github.com/users/mavencode01/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 314294549, "node_id": "MDU6TGFiZWwzMTQyOTQ1NDk=", "url": "https://api.github.com/repos/graphframes/graphframes/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-11-10T12:32:51Z", "updated_at": "2016-12-12T18:00:22Z", "closed_at": "2016-11-12T03:08:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Moving the issue here, \r\nI'm trying to cluster a hierarchical dataset. This works fine for small dataset, I could cluster the data into separate clusters.\r\n\r\nHowever, for large hierarchical dataset (about 1.60million vertices) the result seems wrong. \r\nThe resulting clusters from connected component have many intersections. This should not be the case. I expect the hierarchical dataset to be clustered into separate smaller clusters.\r\n\r\n\t...\r\n\tval vertices = universe.map(u => (u.id, u.username, u.age, u.gamescore))\r\n\t                          .toDF(\"id\", \"username\", \"age\",\"gamescore\")\r\n\t                          .alias(\"v\")\r\n\r\n\r\n\tval lookup = sparkSession.sparkContext.broadcast(universeMap.rdd.collectAsMap())\r\n\r\n\r\n\tdef buildEdges(src: String, dest: String) = {\r\n\t    Edge(lookup.value.get(src).get, lookup.value.get(dest).get, 0)\r\n\t}\r\n\r\n\r\n\tval edges  =  dataset.mapPartitions(_.map(s => buildEdges(s.username1, s.username2)))\r\n\t                                      .toDF(\"src\", \"dst\", \"default\")\r\n\r\n\tval graph = GraphFrame(vertices, edges)\r\n\r\n\tval cc = graph.connectedComponents.run().select(\"id\", \"component\")\r\nDo some validation test\r\n\r\n    Select id, count(component) \r\n    group by id\r\n\r\nI expect each `id `to belong to one cluster/component and count = 1 instead id belong to multiple clusters/component.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/124", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/124/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/124/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/124/events", "html_url": "https://github.com/graphframes/graphframes/issues/124", "id": 186955863, "node_id": "MDU6SXNzdWUxODY5NTU4NjM=", "number": 124, "title": "Connected Components: checkpoint interval param", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-11-03T00:33:13Z", "updated_at": "2016-11-07T18:34:34Z", "closed_at": "2016-11-07T18:34:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Add configurable checkpoint interval for new CC implementation", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/123", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/123/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/123/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/123/events", "html_url": "https://github.com/graphframes/graphframes/issues/123", "id": 186955796, "node_id": "MDU6SXNzdWUxODY5NTU3OTY=", "number": 123, "title": "Connected Components: Python API for new implementation", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2016-11-03T00:32:39Z", "updated_at": "2016-11-10T06:32:06Z", "closed_at": "2016-11-10T06:32:06Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Need to add params to fully support new implementation", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/122", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/122/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/122/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/122/events", "html_url": "https://github.com/graphframes/graphframes/issues/122", "id": 186955727, "node_id": "MDU6SXNzdWUxODY5NTU3Mjc=", "number": 122, "title": "Connected Components: support legacy GraphX implementation", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-11-03T00:32:00Z", "updated_at": "2016-11-05T01:55:25Z", "closed_at": "2016-11-05T01:55:25Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Add option to use GraphX instead of new CC implementation", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/121", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/121/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/121/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/121/events", "html_url": "https://github.com/graphframes/graphframes/issues/121", "id": 186955611, "node_id": "MDU6SXNzdWUxODY5NTU2MTE=", "number": 121, "title": "Connected Components: improve unit tests", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2016-11-03T00:30:55Z", "updated_at": "2016-11-10T06:33:13Z", "closed_at": "2016-11-10T06:33:13Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We should improve unit test coverage for CC before we release the new version.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/118", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/118/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/118/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/118/events", "html_url": "https://github.com/graphframes/graphframes/issues/118", "id": 184291301, "node_id": "MDU6SXNzdWUxODQyOTEzMDE=", "number": 118, "title": "Motif resulting in empty DataFrame", "user": {"login": "michaelqiu94", "id": 11432805, "node_id": "MDQ6VXNlcjExNDMyODA1", "avatar_url": "https://avatars2.githubusercontent.com/u/11432805?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelqiu94", "html_url": "https://github.com/michaelqiu94", "followers_url": "https://api.github.com/users/michaelqiu94/followers", "following_url": "https://api.github.com/users/michaelqiu94/following{/other_user}", "gists_url": "https://api.github.com/users/michaelqiu94/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelqiu94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelqiu94/subscriptions", "organizations_url": "https://api.github.com/users/michaelqiu94/orgs", "repos_url": "https://api.github.com/users/michaelqiu94/repos", "events_url": "https://api.github.com/users/michaelqiu94/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelqiu94/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-10-20T17:26:53Z", "updated_at": "2016-10-20T18:04:48Z", "closed_at": "2016-10-20T18:04:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\n   I am trying to use the motif functionality within Graphframes. I tried a bunch of different different motifs, including those in the user guide, on a variety of different GraphFrames, but to no avail. I even tried the simple motif \"(a)-[e]->(b)\", but the resulting DataFrame was empty. If I am understanding this correctly, it should return all a,e, and b such that a has an edge to b. This was the command that I used.\n\ng.find(\"(a)-[e]->(b)\")\n\nThanks!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/117", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/117/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/117/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/117/events", "html_url": "https://github.com/graphframes/graphframes/issues/117", "id": 183765335, "node_id": "MDU6SXNzdWUxODM3NjUzMzU=", "number": 117, "title": "More scalable connected components implementation", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2016-10-18T18:24:21Z", "updated_at": "2016-11-10T06:33:24Z", "closed_at": "2016-11-10T06:33:24Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "There have been many reports of the connected components algorithm in GraphX and GraphFrames not scaling.  @mengxr has a prototype of a better algorithm.  This issue is for tracking adding it to GraphFrames master.\r\n\r\nSubtasks:\r\n- [x] Implementation: #119\r\n- [x] Improved unit tests: #121\r\n- [x] GraphX legacy support: #122\r\n- [x] Python API: #123\r\n- [x] (optional) checkpoint interval param: #124\r\n- [x] handle skewness in assigning long IDs", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/116", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/116/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/116/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/116/events", "html_url": "https://github.com/graphframes/graphframes/issues/116", "id": 183578041, "node_id": "MDU6SXNzdWUxODM1NzgwNDE=", "number": 116, "title": "connectedComponents() raises lots of warnings that say \"block locks were not released by TID = ...\"", "user": {"login": "nchammas", "id": 1039369, "node_id": "MDQ6VXNlcjEwMzkzNjk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1039369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nchammas", "html_url": "https://github.com/nchammas", "followers_url": "https://api.github.com/users/nchammas/followers", "following_url": "https://api.github.com/users/nchammas/following{/other_user}", "gists_url": "https://api.github.com/users/nchammas/gists{/gist_id}", "starred_url": "https://api.github.com/users/nchammas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nchammas/subscriptions", "organizations_url": "https://api.github.com/users/nchammas/orgs", "repos_url": "https://api.github.com/users/nchammas/repos", "events_url": "https://api.github.com/users/nchammas/events{/privacy}", "received_events_url": "https://api.github.com/users/nchammas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2016-10-18T02:55:39Z", "updated_at": "2017-03-27T22:00:44Z", "closed_at": "2017-03-27T22:00:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Trying to run a simple `connectedComponents()` analysis on an example dataset, even the one from the [quick start](http://graphframes.github.io/quick-start.html), yields a flurry of warnings (several dozen?) like this:\n\n```\n16/10/17 22:45:40 WARN Executor: 1 block locks were not released by TID = 358:\n[rdd_95_5]\n16/10/17 22:45:40 WARN Executor: 1 block locks were not released by TID = 353:\n[rdd_95_0]\n16/10/17 22:45:40 WARN Executor: 1 block locks were not released by TID = 359:\n[rdd_95_6]\n...\n```\n\nAnd this is for a graph with literally 3-4 vertices and edges.\n\nIs this an issue? Would it cause performance issues at scale? ([Here's a related question on Stack Overflow](http://stackoverflow.com/q/40007941/877069).)\n\nI'm running Python 2.7, Spark 2.0.1, and GraphFrames 0.2.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/114", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/114/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/114/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/114/events", "html_url": "https://github.com/graphframes/graphframes/issues/114", "id": 182337103, "node_id": "MDU6SXNzdWUxODIzMzcxMDM=", "number": 114, "title": "SLF4J Logging Error", "user": {"login": "michaelqiu94", "id": 11432805, "node_id": "MDQ6VXNlcjExNDMyODA1", "avatar_url": "https://avatars2.githubusercontent.com/u/11432805?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelqiu94", "html_url": "https://github.com/michaelqiu94", "followers_url": "https://api.github.com/users/michaelqiu94/followers", "following_url": "https://api.github.com/users/michaelqiu94/following{/other_user}", "gists_url": "https://api.github.com/users/michaelqiu94/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelqiu94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelqiu94/subscriptions", "organizations_url": "https://api.github.com/users/michaelqiu94/orgs", "repos_url": "https://api.github.com/users/michaelqiu94/repos", "events_url": "https://api.github.com/users/michaelqiu94/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelqiu94/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-10-11T18:22:23Z", "updated_at": "2016-10-20T17:20:57Z", "closed_at": "2016-10-20T17:20:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\n    I tried creating a graph frame, but it gave me this ClassDefNotFound error:\n\njava.lang.NoClassDefFoundError: com/typesafe/scalalogging/slf4j/LazyLogging\n\nI am using GraphFrames 0.2.0 for Spark 2.0 and Scala 2.11. Any ideas what could be causing this? Thanks!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/111", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/111/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/111/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/111/events", "html_url": "https://github.com/graphframes/graphframes/issues/111", "id": 180680191, "node_id": "MDU6SXNzdWUxODA2ODAxOTE=", "number": 111, "title": "Heterogeneous vertices?", "user": {"login": "OneCricketeer", "id": 1930631, "node_id": "MDQ6VXNlcjE5MzA2MzE=", "avatar_url": "https://avatars0.githubusercontent.com/u/1930631?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OneCricketeer", "html_url": "https://github.com/OneCricketeer", "followers_url": "https://api.github.com/users/OneCricketeer/followers", "following_url": "https://api.github.com/users/OneCricketeer/following{/other_user}", "gists_url": "https://api.github.com/users/OneCricketeer/gists{/gist_id}", "starred_url": "https://api.github.com/users/OneCricketeer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OneCricketeer/subscriptions", "organizations_url": "https://api.github.com/users/OneCricketeer/orgs", "repos_url": "https://api.github.com/users/OneCricketeer/repos", "events_url": "https://api.github.com/users/OneCricketeer/events{/privacy}", "received_events_url": "https://api.github.com/users/OneCricketeer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-10-03T16:07:35Z", "updated_at": "2017-01-10T22:34:37Z", "closed_at": "2017-01-10T17:32:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\nval v = sqlContext.createDataFrame(List(\n  (\"a\", \"Alice\", 34),\n  (\"b\", \"Bob\", 36),\n  (\"c\", \"Charlie\", 30)\n)).toDF(\"id\", \"name\", \"age\")\n```\n\nWhat if I wanted to say, for example, that these people work at a company? Say we didn't care about the \"age\" of the company, just who the employees are. \n\nSo how would this data be added as a Vertex, or is it even possible?\n\n```\n(\"companyA\", \"Foobar, Inc.\")\n```\n\nThe edge is straightforward \n\n```\n(\"a\", \"companyA\", \"works_at\")\n```\n\n---\n\nTo clarify, this isn't possible because the Company has no \"age\", so the schema can't be applied\n\n```\nval v = sqlContext.createDataFrame(List(\n  (\"a\", \"Alice\", 34),\n  (\"b\", \"Bob\", 36),\n  (\"c\", \"Charlie\", 30),\n  (\"companyA\", \"FooBar, Inc.\")\n)).toDF(\"id\", \"name\", \"age\")\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/110", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/110/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/110/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/110/events", "html_url": "https://github.com/graphframes/graphframes/issues/110", "id": 180122043, "node_id": "MDU6SXNzdWUxODAxMjIwNDM=", "number": 110, "title": "(another?) invalid dependency", "user": {"login": "sbromberger", "id": 941359, "node_id": "MDQ6VXNlcjk0MTM1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/941359?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sbromberger", "html_url": "https://github.com/sbromberger", "followers_url": "https://api.github.com/users/sbromberger/followers", "following_url": "https://api.github.com/users/sbromberger/following{/other_user}", "gists_url": "https://api.github.com/users/sbromberger/gists{/gist_id}", "starred_url": "https://api.github.com/users/sbromberger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sbromberger/subscriptions", "organizations_url": "https://api.github.com/users/sbromberger/orgs", "repos_url": "https://api.github.com/users/sbromberger/repos", "events_url": "https://api.github.com/users/sbromberger/events{/privacy}", "received_events_url": "https://api.github.com/users/sbromberger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-09-29T18:11:33Z", "updated_at": "2016-09-29T18:49:05Z", "closed_at": "2016-09-29T18:49:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment**\n- scala 2.11.8\n- spark-core 2.0.0\n- spark-sql 2.11\n- graphframes 0.2.0-spark2.0-s_2.11\n\nIn addition to the logging dependency error in #109, we're getting\n\n```\nError:scalac: missing or invalid dependency detected while loading class file 'GraphFrame.class'.\nCould not access type DataFrame in package org.apache.spark.sql.package,\nbecause it (or its dependencies) are missing. Check your build definition for\nmissing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)\nA full rebuild may help if 'GraphFrame.class' was compiled against an incompatible version of org.apache.spark.sql.package.\n```\n\nAny ideas? It appears that our DataFrame class is in `org.apache.spark.sql`, not `org.apache.spark.sql.package` (which doesn't appear to exist).\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/109", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/109/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/109/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/109/events", "html_url": "https://github.com/graphframes/graphframes/issues/109", "id": 176958250, "node_id": "MDU6SXNzdWUxNzY5NTgyNTA=", "number": 109, "title": "invalid dependency when converting from Graphx", "user": {"login": "srooznow", "id": 11358914, "node_id": "MDQ6VXNlcjExMzU4OTE0", "avatar_url": "https://avatars0.githubusercontent.com/u/11358914?v=4", "gravatar_id": "", "url": "https://api.github.com/users/srooznow", "html_url": "https://github.com/srooznow", "followers_url": "https://api.github.com/users/srooznow/followers", "following_url": "https://api.github.com/users/srooznow/following{/other_user}", "gists_url": "https://api.github.com/users/srooznow/gists{/gist_id}", "starred_url": "https://api.github.com/users/srooznow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/srooznow/subscriptions", "organizations_url": "https://api.github.com/users/srooznow/orgs", "repos_url": "https://api.github.com/users/srooznow/repos", "events_url": "https://api.github.com/users/srooznow/events{/privacy}", "received_events_url": "https://api.github.com/users/srooznow/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2016-09-14T16:39:47Z", "updated_at": "2016-10-05T23:30:37Z", "closed_at": "2016-10-03T23:56:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "scala version 2.11.7\nspark-2.0.0-bin-hadoop2.7\ngraphframes-0.2.0-spark2.0-s_2.11.jar\n\n```\n$ ./bin/spark-shell --master local[4] --jars /Downloads/graphframes-0.2.0-spark2.0-s_2.11.jar\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel).\n16/09/14 09:29:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n16/09/14 09:29:38 WARN SparkContext: Use an existing SparkContext, some configuration may not take effect.\nSpark context Web UI available at http://10.0.1.26:4040\nSpark context available as 'sc' (master = local[4], app id = local-1473870577895).\nSpark session available as 'spark'.\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.0.0\n      /_/\n\nUsing Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_66)\nType in expressions to have them evaluated.\nType :help for more information.\n\nscala> import org.graphframes._\nimport org.graphframes._\n\nscala> import org.apache.spark.graphx._\nimport org.apache.spark.graphx._\n\nscala> import org.apache.spark.graphx.util.GraphGenerators\nimport org.apache.spark.graphx.util.GraphGenerators\n\nscala> import org.apache.spark.rdd.RDD\nimport org.apache.spark.rdd.RDD\n\nscala> val myVertices = sc.makeRDD(Array((1L, \"Ann\"),(2L, \"Bill\"),(3L, \"Charles\"),(4L, \"Diane\"),(5L, \"Went to gym this morning\")))\nmyVertices: org.apache.spark.rdd.RDD[(Long, String)] = ParallelCollectionRDD[0] at makeRDD at <console>:32\n\nscala> val myEdges = sc.makeRDD(Array(Edge(1L, 2L, \"is-friends-with\"),Edge(2L, 3L, \"is-friends-with\"),Edge(3L, 4L, \"is-friends-with\"),Edge(4L, 5L, \"Likes-status\"),Edge(3L, 5L, \"Wrote-status\")))\nmyEdges: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[String]] = ParallelCollectionRDD[1] at makeRDD at <console>:32\n\nscala> val myGraph = Graph(myVertices, myEdges)\nmyGraph: org.apache.spark.graphx.Graph[String,String] = org.apache.spark.graphx.impl.GraphImpl@38f3dbbf\n\nscala> val gf = GraphFrame.fromGraphX(myGraph)\nerror: missing or invalid dependency detected while loading class file 'Logging.class'.\nCould not access term typesafe in package com,\nbecause it (or its dependencies) are missing. Check your build definition for\nmissing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)\nA full rebuild may help if 'Logging.class' was compiled against an incompatible version of com.\nerror: missing or invalid dependency detected while loading class file 'Logging.class'.\nCould not access term scalalogging in value com.typesafe,\nbecause it (or its dependencies) are missing. Check your build definition for\nmissing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)\nA full rebuild may help if 'Logging.class' was compiled against an incompatible version of com.typesafe.\nerror: missing or invalid dependency detected while loading class file 'Logging.class'.\nCould not access type LazyLogging in value com.slf4j,\nbecause it (or its dependencies) are missing. Check your build definition for\nmissing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.)\nA full rebuild may help if 'Logging.class' was compiled against an incompatible version of com.slf4j.\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/95", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/95/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/95/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/95/events", "html_url": "https://github.com/graphframes/graphframes/issues/95", "id": 166210417, "node_id": "MDU6SXNzdWUxNjYyMTA0MTc=", "number": 95, "title": "Publish graphframes for Spark 2.0", "user": {"login": "thunterdb", "id": 7594753, "node_id": "MDQ6VXNlcjc1OTQ3NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7594753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thunterdb", "html_url": "https://github.com/thunterdb", "followers_url": "https://api.github.com/users/thunterdb/followers", "following_url": "https://api.github.com/users/thunterdb/following{/other_user}", "gists_url": "https://api.github.com/users/thunterdb/gists{/gist_id}", "starred_url": "https://api.github.com/users/thunterdb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thunterdb/subscriptions", "organizations_url": "https://api.github.com/users/thunterdb/orgs", "repos_url": "https://api.github.com/users/thunterdb/repos", "events_url": "https://api.github.com/users/thunterdb/events{/privacy}", "received_events_url": "https://api.github.com/users/thunterdb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-07-18T22:42:28Z", "updated_at": "2016-08-15T15:46:06Z", "closed_at": "2016-08-15T15:46:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "GraphFrames will be published for Spark 2.0. This will be the first version that officially supports scala 2.10 and scala 2.11 .\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/94", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/94/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/94/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/94/events", "html_url": "https://github.com/graphframes/graphframes/issues/94", "id": 166101186, "node_id": "MDU6SXNzdWUxNjYxMDExODY=", "number": 94, "title": "Mistake in Documentation ", "user": {"login": "nadav-grossaug", "id": 8099763, "node_id": "MDQ6VXNlcjgwOTk3NjM=", "avatar_url": "https://avatars1.githubusercontent.com/u/8099763?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nadav-grossaug", "html_url": "https://github.com/nadav-grossaug", "followers_url": "https://api.github.com/users/nadav-grossaug/followers", "following_url": "https://api.github.com/users/nadav-grossaug/following{/other_user}", "gists_url": "https://api.github.com/users/nadav-grossaug/gists{/gist_id}", "starred_url": "https://api.github.com/users/nadav-grossaug/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nadav-grossaug/subscriptions", "organizations_url": "https://api.github.com/users/nadav-grossaug/orgs", "repos_url": "https://api.github.com/users/nadav-grossaug/repos", "events_url": "https://api.github.com/users/nadav-grossaug/events{/privacy}", "received_events_url": "https://api.github.com/users/nadav-grossaug/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-07-18T14:04:48Z", "updated_at": "2016-08-16T18:29:27Z", "closed_at": "2016-08-16T18:29:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "in http://graphframes.github.io/api/python/graphframes.html#graphframes.GraphFrame\n\nDocumentation states:\n\nconnectedComponents()\nComputes the connected components of the graph.\n\nSee Scala documentation for more details.\n\nReturns:    GraphFrame with new vertices column \u201ccomponent\u201d\n\n**should be:**  Returns: DataFrame with new vertices column \u201ccomponent\u201d (as is in Scala) \n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/93", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/93/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/93/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/93/events", "html_url": "https://github.com/graphframes/graphframes/issues/93", "id": 164213113, "node_id": "MDU6SXNzdWUxNjQyMTMxMTM=", "number": 93, "title": "some problems when using graphframe API find()", "user": {"login": "summershenshen", "id": 12892438, "node_id": "MDQ6VXNlcjEyODkyNDM4", "avatar_url": "https://avatars0.githubusercontent.com/u/12892438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/summershenshen", "html_url": "https://github.com/summershenshen", "followers_url": "https://api.github.com/users/summershenshen/followers", "following_url": "https://api.github.com/users/summershenshen/following{/other_user}", "gists_url": "https://api.github.com/users/summershenshen/gists{/gist_id}", "starred_url": "https://api.github.com/users/summershenshen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/summershenshen/subscriptions", "organizations_url": "https://api.github.com/users/summershenshen/orgs", "repos_url": "https://api.github.com/users/summershenshen/repos", "events_url": "https://api.github.com/users/summershenshen/events{/privacy}", "received_events_url": "https://api.github.com/users/summershenshen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-07-07T01:58:12Z", "updated_at": "2016-09-28T23:33:48Z", "closed_at": "2016-09-28T23:33:48Z", "author_association": "NONE", "active_lock_reason": null, "body": " When I use graphframes API find, I meet up with some problems. For example, graphframes g, var motif=g.find((a)-[e1]->(b);(a)-[e2]->(d);(c)-[e3]->(b);(c)-[e4]->(d)),I can get a dataframe as a result. But in the result vertex a and vertex c may be the same, if I want all the vertexes which have different names are different vertexes,except I can use motif=motif.filter(\"XXX\"),what other methods can I use?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/91", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/91/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/91/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/91/events", "html_url": "https://github.com/graphframes/graphframes/issues/91", "id": 161244765, "node_id": "MDU6SXNzdWUxNjEyNDQ3NjU=", "number": 91, "title": "Graphframes => Apache Spark 2.0 Compatible", "user": {"login": "anabranch", "id": 1642503, "node_id": "MDQ6VXNlcjE2NDI1MDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1642503?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anabranch", "html_url": "https://github.com/anabranch", "followers_url": "https://api.github.com/users/anabranch/followers", "following_url": "https://api.github.com/users/anabranch/following{/other_user}", "gists_url": "https://api.github.com/users/anabranch/gists{/gist_id}", "starred_url": "https://api.github.com/users/anabranch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anabranch/subscriptions", "organizations_url": "https://api.github.com/users/anabranch/orgs", "repos_url": "https://api.github.com/users/anabranch/repos", "events_url": "https://api.github.com/users/anabranch/events{/privacy}", "received_events_url": "https://api.github.com/users/anabranch/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-06-20T17:03:00Z", "updated_at": "2016-08-16T18:30:24Z", "closed_at": "2016-08-16T18:30:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm playing around with getting this set up. It seems like there are some pretty significant code changes, not just remove `.map` on DataFrames.\n\nQuestions:\n[ ] What framework should we use for logging internally since `org.apache.spark.Logging` no longer exists?\n\nTasks:\n[ ] Fix LogInfo\n[ ] Fix Logging\n[ ] Fix `.map` calls\n[ ] Fix `callUDF` calls.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/87", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/87/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/87/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/87/events", "html_url": "https://github.com/graphframes/graphframes/issues/87", "id": 156955277, "node_id": "MDU6SXNzdWUxNTY5NTUyNzc=", "number": 87, "title": "release graphframes for scala 2.11", "user": {"login": "jexp", "id": 67427, "node_id": "MDQ6VXNlcjY3NDI3", "avatar_url": "https://avatars1.githubusercontent.com/u/67427?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jexp", "html_url": "https://github.com/jexp", "followers_url": "https://api.github.com/users/jexp/followers", "following_url": "https://api.github.com/users/jexp/following{/other_user}", "gists_url": "https://api.github.com/users/jexp/gists{/gist_id}", "starred_url": "https://api.github.com/users/jexp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jexp/subscriptions", "organizations_url": "https://api.github.com/users/jexp/orgs", "repos_url": "https://api.github.com/users/jexp/repos", "events_url": "https://api.github.com/users/jexp/events{/privacy}", "received_events_url": "https://api.github.com/users/jexp/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-05-26T10:43:06Z", "updated_at": "2017-02-03T11:25:12Z", "closed_at": "2016-08-16T18:30:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Currently graphframes is only released for Scala 2.10\n\nIt would be cool if like for the other spark components there could also be a release for Scala 2.11\n\nThanks a lot.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/85", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/85/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/85/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/85/events", "html_url": "https://github.com/graphframes/graphframes/issues/85", "id": 156246252, "node_id": "MDU6SXNzdWUxNTYyNDYyNTI=", "number": 85, "title": "How to use is with python3?", "user": {"login": "ibaihuo", "id": 4654046, "node_id": "MDQ6VXNlcjQ2NTQwNDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/4654046?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibaihuo", "html_url": "https://github.com/ibaihuo", "followers_url": "https://api.github.com/users/ibaihuo/followers", "following_url": "https://api.github.com/users/ibaihuo/following{/other_user}", "gists_url": "https://api.github.com/users/ibaihuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibaihuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibaihuo/subscriptions", "organizations_url": "https://api.github.com/users/ibaihuo/orgs", "repos_url": "https://api.github.com/users/ibaihuo/repos", "events_url": "https://api.github.com/users/ibaihuo/events{/privacy}", "received_events_url": "https://api.github.com/users/ibaihuo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/graphframes/graphframes/milestones/2", "html_url": "https://github.com/graphframes/graphframes/milestone/2", "labels_url": "https://api.github.com/repos/graphframes/graphframes/milestones/2/labels", "id": 2241469, "node_id": "MDk6TWlsZXN0b25lMjI0MTQ2OQ==", "number": 2, "title": "0.3.1", "description": "", "creator": {"login": "thunterdb", "id": 7594753, "node_id": "MDQ6VXNlcjc1OTQ3NTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7594753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thunterdb", "html_url": "https://github.com/thunterdb", "followers_url": "https://api.github.com/users/thunterdb/followers", "following_url": "https://api.github.com/users/thunterdb/following{/other_user}", "gists_url": "https://api.github.com/users/thunterdb/gists{/gist_id}", "starred_url": "https://api.github.com/users/thunterdb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thunterdb/subscriptions", "organizations_url": "https://api.github.com/users/thunterdb/orgs", "repos_url": "https://api.github.com/users/thunterdb/repos", "events_url": "https://api.github.com/users/thunterdb/events{/privacy}", "received_events_url": "https://api.github.com/users/thunterdb/received_events", "type": "User", "site_admin": false}, "open_issues": 6, "closed_issues": 3, "state": "open", "created_at": "2017-01-10T17:35:54Z", "updated_at": "2019-01-07T15:55:30Z", "due_on": null, "closed_at": null}, "comments": 10, "created_at": "2016-05-23T10:14:47Z", "updated_at": "2017-01-24T22:39:21Z", "closed_at": "2016-11-11T17:12:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I runt this import with pyspark with python3.51, it errors:\n\n> from graphframes import *\n> ZipImportError: can't find module 'graphframes'\n\nbut is success in pyspark with python 2.7.1\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/83", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/83/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/83/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/83/events", "html_url": "https://github.com/graphframes/graphframes/issues/83", "id": 154957425, "node_id": "MDU6SXNzdWUxNTQ5NTc0MjU=", "number": 83, "title": "Update link to graphframes on homepage", "user": {"login": "shagunsodhani", "id": 1321193, "node_id": "MDQ6VXNlcjEzMjExOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shagunsodhani", "html_url": "https://github.com/shagunsodhani", "followers_url": "https://api.github.com/users/shagunsodhani/followers", "following_url": "https://api.github.com/users/shagunsodhani/following{/other_user}", "gists_url": "https://api.github.com/users/shagunsodhani/gists{/gist_id}", "starred_url": "https://api.github.com/users/shagunsodhani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shagunsodhani/subscriptions", "organizations_url": "https://api.github.com/users/shagunsodhani/orgs", "repos_url": "https://api.github.com/users/shagunsodhani/repos", "events_url": "https://api.github.com/users/shagunsodhani/events{/privacy}", "received_events_url": "https://api.github.com/users/shagunsodhani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-05-16T04:12:55Z", "updated_at": "2016-05-17T15:40:04Z", "closed_at": "2016-05-17T15:40:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Update the link to graphframes in the `Downloading` section of the [homepage](http://graphframes.github.io/)\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/81", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/81/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/81/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/81/events", "html_url": "https://github.com/graphframes/graphframes/issues/81", "id": 153331201, "node_id": "MDU6SXNzdWUxNTMzMzEyMDE=", "number": 81, "title": "Will GraphFrames become part of Spark?", "user": {"login": "nchammas", "id": 1039369, "node_id": "MDQ6VXNlcjEwMzkzNjk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1039369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nchammas", "html_url": "https://github.com/nchammas", "followers_url": "https://api.github.com/users/nchammas/followers", "following_url": "https://api.github.com/users/nchammas/following{/other_user}", "gists_url": "https://api.github.com/users/nchammas/gists{/gist_id}", "starred_url": "https://api.github.com/users/nchammas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nchammas/subscriptions", "organizations_url": "https://api.github.com/users/nchammas/orgs", "repos_url": "https://api.github.com/users/nchammas/repos", "events_url": "https://api.github.com/users/nchammas/events{/privacy}", "received_events_url": "https://api.github.com/users/nchammas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-05-05T21:32:48Z", "updated_at": "2016-09-28T23:26:50Z", "closed_at": "2016-09-28T23:26:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "DataFrames are becoming increasingly central to Spark, so it raises the question: Will GraphFrames become part of the main Spark project, alongside GraphX, or will it continue as a separate library?\n\nI think a line in the README commenting on this would be helpful.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/80", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/80/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/80/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/80/events", "html_url": "https://github.com/graphframes/graphframes/issues/80", "id": 149905306, "node_id": "MDU6SXNzdWUxNDk5MDUzMDY=", "number": 80, "title": "log4j.properties file ignored", "user": {"login": "daradib", "id": 1525041, "node_id": "MDQ6VXNlcjE1MjUwNDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1525041?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daradib", "html_url": "https://github.com/daradib", "followers_url": "https://api.github.com/users/daradib/followers", "following_url": "https://api.github.com/users/daradib/following{/other_user}", "gists_url": "https://api.github.com/users/daradib/gists{/gist_id}", "starred_url": "https://api.github.com/users/daradib/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daradib/subscriptions", "organizations_url": "https://api.github.com/users/daradib/orgs", "repos_url": "https://api.github.com/users/daradib/repos", "events_url": "https://api.github.com/users/daradib/events{/privacy}", "received_events_url": "https://api.github.com/users/daradib/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 314294549, "node_id": "MDU6TGFiZWwzMTQyOTQ1NDk=", "url": "https://api.github.com/repos/graphframes/graphframes/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-04-20T22:31:47Z", "updated_at": "2016-09-28T23:41:03Z", "closed_at": "2016-09-28T23:41:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "When GraphFrames jar/package is loaded, Spark will ignore `log4j.properties` in `SPARK_CONF_DIR`. Perhaps `src/main/resources/log4j.properties` is overriding it?\n\n@thunterdb seems to be working on a solution in #55.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/79", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/79/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/79/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/79/events", "html_url": "https://github.com/graphframes/graphframes/issues/79", "id": 149250800, "node_id": "MDU6SXNzdWUxNDkyNTA4MDA=", "number": 79, "title": "Number of Connected Components", "user": {"login": "georgeha", "id": 1215400, "node_id": "MDQ6VXNlcjEyMTU0MDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1215400?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgeha", "html_url": "https://github.com/georgeha", "followers_url": "https://api.github.com/users/georgeha/followers", "following_url": "https://api.github.com/users/georgeha/following{/other_user}", "gists_url": "https://api.github.com/users/georgeha/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgeha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgeha/subscriptions", "organizations_url": "https://api.github.com/users/georgeha/orgs", "repos_url": "https://api.github.com/users/georgeha/repos", "events_url": "https://api.github.com/users/georgeha/events{/privacy}", "received_events_url": "https://api.github.com/users/georgeha/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2016-04-18T19:38:38Z", "updated_at": "2016-10-18T20:07:43Z", "closed_at": "2016-04-18T19:44:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, \n\nhow large can a Graphframe be in order to calculate its connected components? I need to scale for thousand of edges in very strong machines.\n\nThanks\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/71", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/71/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/71/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/71/events", "html_url": "https://github.com/graphframes/graphframes/issues/71", "id": 142902633, "node_id": "MDU6SXNzdWUxNDI5MDI2MzM=", "number": 71, "title": "Scala documentation out of date", "user": {"login": "pmcb55", "id": 961445, "node_id": "MDQ6VXNlcjk2MTQ0NQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/961445?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pmcb55", "html_url": "https://github.com/pmcb55", "followers_url": "https://api.github.com/users/pmcb55/followers", "following_url": "https://api.github.com/users/pmcb55/following{/other_user}", "gists_url": "https://api.github.com/users/pmcb55/gists{/gist_id}", "starred_url": "https://api.github.com/users/pmcb55/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pmcb55/subscriptions", "organizations_url": "https://api.github.com/users/pmcb55/orgs", "repos_url": "https://api.github.com/users/pmcb55/repos", "events_url": "https://api.github.com/users/pmcb55/events{/privacy}", "received_events_url": "https://api.github.com/users/pmcb55/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-03-23T09:02:09Z", "updated_at": "2016-04-04T01:14:38Z", "closed_at": "2016-04-04T01:14:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "The Scala example seems a little out-of-date, as it calls the 'numIter()' method on PageRank, when in fact that method seems to be now called 'maxIter()', i.e. change this:\n\n`val results = g.pageRank.resetProbability(0.01).numIter(20).run()`\n\n...to this:\n\n`val results = g.pageRank.resetProbability(0.01).maxIter(20).run()`\n\nAlso when running this example by cutting-and-pasting into 'spark-shell', I needed to manually import the GraphFrames class before instantiating 'g', i.e.:\n\n`import org.graphframes.GraphFrame`\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/68", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/68/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/68/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/68/events", "html_url": "https://github.com/graphframes/graphframes/issues/68", "id": 142455293, "node_id": "MDU6SXNzdWUxNDI0NTUyOTM=", "number": 68, "title": "Get all neighbors ", "user": {"login": "tartavull", "id": 4648166, "node_id": "MDQ6VXNlcjQ2NDgxNjY=", "avatar_url": "https://avatars2.githubusercontent.com/u/4648166?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tartavull", "html_url": "https://github.com/tartavull", "followers_url": "https://api.github.com/users/tartavull/followers", "following_url": "https://api.github.com/users/tartavull/following{/other_user}", "gists_url": "https://api.github.com/users/tartavull/gists{/gist_id}", "starred_url": "https://api.github.com/users/tartavull/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tartavull/subscriptions", "organizations_url": "https://api.github.com/users/tartavull/orgs", "repos_url": "https://api.github.com/users/tartavull/repos", "events_url": "https://api.github.com/users/tartavull/events{/privacy}", "received_events_url": "https://api.github.com/users/tartavull/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-03-21T20:06:12Z", "updated_at": "2016-03-21T20:06:31Z", "closed_at": "2016-03-21T20:06:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there any method similar to degrees(), which can be access using the python api, to not only get the number of edges but the id of them?\n\nThank you!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/67", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/67/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/67/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/67/events", "html_url": "https://github.com/graphframes/graphframes/issues/67", "id": 142452126, "node_id": "MDU6SXNzdWUxNDI0NTIxMjY=", "number": 67, "title": "Get all neighbors ", "user": {"login": "tartavull", "id": 4648166, "node_id": "MDQ6VXNlcjQ2NDgxNjY=", "avatar_url": "https://avatars2.githubusercontent.com/u/4648166?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tartavull", "html_url": "https://github.com/tartavull", "followers_url": "https://api.github.com/users/tartavull/followers", "following_url": "https://api.github.com/users/tartavull/following{/other_user}", "gists_url": "https://api.github.com/users/tartavull/gists{/gist_id}", "starred_url": "https://api.github.com/users/tartavull/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tartavull/subscriptions", "organizations_url": "https://api.github.com/users/tartavull/orgs", "repos_url": "https://api.github.com/users/tartavull/repos", "events_url": "https://api.github.com/users/tartavull/events{/privacy}", "received_events_url": "https://api.github.com/users/tartavull/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-03-21T19:51:11Z", "updated_at": "2016-03-29T20:12:35Z", "closed_at": "2016-03-29T20:12:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there any method similar to degrees(), which can be access using the python api, to not only get the number of edges but the id of them?\n\nThank you!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/65", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/65/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/65/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/65/events", "html_url": "https://github.com/graphframes/graphframes/issues/65", "id": 141464529, "node_id": "MDU6SXNzdWUxNDE0NjQ1Mjk=", "number": 65, "title": "motif finding should avoid name conflict when matching with anonymous edge", "user": {"login": "felixcheung", "id": 8969467, "node_id": "MDQ6VXNlcjg5Njk0Njc=", "avatar_url": "https://avatars3.githubusercontent.com/u/8969467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/felixcheung", "html_url": "https://github.com/felixcheung", "followers_url": "https://api.github.com/users/felixcheung/followers", "following_url": "https://api.github.com/users/felixcheung/following{/other_user}", "gists_url": "https://api.github.com/users/felixcheung/gists{/gist_id}", "starred_url": "https://api.github.com/users/felixcheung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/felixcheung/subscriptions", "organizations_url": "https://api.github.com/users/felixcheung/orgs", "repos_url": "https://api.github.com/users/felixcheung/repos", "events_url": "https://api.github.com/users/felixcheung/events{/privacy}", "received_events_url": "https://api.github.com/users/felixcheung/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-03-17T02:54:27Z", "updated_at": "2016-03-21T18:38:41Z", "closed_at": "2016-03-21T18:38:41Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently it is using `__tmp` as column name which could theoretically conflict with an actual column with that name.\nSee #50\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/64", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/64/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/64/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/64/events", "html_url": "https://github.com/graphframes/graphframes/issues/64", "id": 141425779, "node_id": "MDU6SXNzdWUxNDE0MjU3Nzk=", "number": 64, "title": "Add cache(), persist() methods", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-03-16T22:54:38Z", "updated_at": "2016-07-18T23:34:21Z", "closed_at": "2016-07-18T23:34:21Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "They should just call cache() and persist() on both DataFrames.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/61", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/61/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/61/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/61/events", "html_url": "https://github.com/graphframes/graphframes/issues/61", "id": 140273402, "node_id": "MDU6SXNzdWUxNDAyNzM0MDI=", "number": 61, "title": "Add triplets to Python GraphFrame", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-03-11T19:41:53Z", "updated_at": "2016-03-14T18:29:50Z", "closed_at": "2016-03-14T18:29:50Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Missing triplets method.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/59", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/59/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/59/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/59/events", "html_url": "https://github.com/graphframes/graphframes/issues/59", "id": 139970776, "node_id": "MDU6SXNzdWUxMzk5NzA3NzY=", "number": 59, "title": "Add merge PR script to squash commits before merge", "user": {"login": "mengxr", "id": 829644, "node_id": "MDQ6VXNlcjgyOTY0NA==", "avatar_url": "https://avatars2.githubusercontent.com/u/829644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mengxr", "html_url": "https://github.com/mengxr", "followers_url": "https://api.github.com/users/mengxr/followers", "following_url": "https://api.github.com/users/mengxr/following{/other_user}", "gists_url": "https://api.github.com/users/mengxr/gists{/gist_id}", "starred_url": "https://api.github.com/users/mengxr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mengxr/subscriptions", "organizations_url": "https://api.github.com/users/mengxr/orgs", "repos_url": "https://api.github.com/users/mengxr/repos", "events_url": "https://api.github.com/users/mengxr/events{/privacy}", "received_events_url": "https://api.github.com/users/mengxr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 314294555, "node_id": "MDU6TGFiZWwzMTQyOTQ1NTU=", "url": "https://api.github.com/repos/graphframes/graphframes/labels/wontfix", "name": "wontfix", "color": "ffffff", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-03-10T18:19:59Z", "updated_at": "2016-11-11T16:36:12Z", "closed_at": "2016-11-11T16:35:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Similar to Spark and some other projects like Redshift Data Source for Spark, we can add `dev/merge_pr.py` to squash commits before merge.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/57", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/57/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/57/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/57/events", "html_url": "https://github.com/graphframes/graphframes/issues/57", "id": 139784530, "node_id": "MDU6SXNzdWUxMzk3ODQ1MzA=", "number": 57, "title": "Add aggregateMessages API to Python", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2016-03-10T04:57:33Z", "updated_at": "2017-04-26T19:23:40Z", "closed_at": "2017-04-26T19:23:40Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It should mimic the Scala API and will likely need to be re-implemented in Python, following the Scala implementation.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/56", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/56/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/56/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/56/events", "html_url": "https://github.com/graphframes/graphframes/issues/56", "id": 139133498, "node_id": "MDU6SXNzdWUxMzkxMzM0OTg=", "number": 56, "title": "Py4JJavaError: An error occurred while calling o57.find.", "user": {"login": "napsternxg", "id": 112678, "node_id": "MDQ6VXNlcjExMjY3OA==", "avatar_url": "https://avatars0.githubusercontent.com/u/112678?v=4", "gravatar_id": "", "url": "https://api.github.com/users/napsternxg", "html_url": "https://github.com/napsternxg", "followers_url": "https://api.github.com/users/napsternxg/followers", "following_url": "https://api.github.com/users/napsternxg/following{/other_user}", "gists_url": "https://api.github.com/users/napsternxg/gists{/gist_id}", "starred_url": "https://api.github.com/users/napsternxg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/napsternxg/subscriptions", "organizations_url": "https://api.github.com/users/napsternxg/orgs", "repos_url": "https://api.github.com/users/napsternxg/repos", "events_url": "https://api.github.com/users/napsternxg/events{/privacy}", "received_events_url": "https://api.github.com/users/napsternxg/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2016-03-08T00:09:38Z", "updated_at": "2016-09-26T18:43:38Z", "closed_at": "2016-03-10T04:59:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using `graphframes:graphframes:0.1.0-spark1.6` from the **pyspark** interface with **current master build of Spark**. I get the following error when I am trying to use the `g.find` functions and other functions as shown in the example notebook at: http://go.databricks.com/hubfs/notebooks/3-GraphFrames-User-Guide-python.html\n\n```\nIn [16]: motifs = g.find(\"(a)-[e]->(b); (b)-[e2]->(a)\")\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-16-ac1d920bb1a7> in <module>()\n----> 1 motifs = g.find(\"(a)-[e]->(b); (b)-[e2]->(a)\")\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in find(self, pattern)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o57.find.\n: java.lang.NoSuchMethodError: scala.collection.immutable.$colon$colon.hd$1()Ljava/lang/Object;\n        at org.graphframes.GraphFrame.findSimple(GraphFrame.scala:370)\n        at org.graphframes.GraphFrame.find(GraphFrame.scala:263)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\nIn [17]: %cpaste\nPasting code; enter '--' alone on the line to stop or use Ctrl-D.\n:paths = g.find(\"(a)-[e]->(b)\")\\\n:  .filter(\"e.relationship = 'follow'\")\\\n:  .filter(\"a.age < b.age\")\n:# The `paths` variable contains the vertex information, which we can extract:\n:e2 = paths.select(\"e.src\", \"e.dst\", \"e.relationship\")\n:\n:# In Spark 1.5+, the user may simplify the previous call to:\n:# val e2 = paths.select(\"e.*\")\n:\n:# Construct the subgraph\n:g2 = GraphFrame(g.vertices, e2)\n:--\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-17-7411759ff966> in <module>()\n----> 1 paths = g.find(\"(a)-[e]->(b)\")  .filter(\"e.relationship = 'follow'\")  .filter(\"a.age < b.age\")\n      2 # The `paths` variable contains the vertex information, which we can extract:\n      3 e2 = paths.select(\"e.src\", \"e.dst\", \"e.relationship\")\n      4 \n      5 # In Spark 1.5+, the user may simplify the previous call to:\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in find(self, pattern)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o57.find.\n: java.lang.NoSuchMethodError: scala.collection.immutable.$colon$colon.hd$1()Ljava/lang/Object;\n        at org.graphframes.GraphFrame.findSimple(GraphFrame.scala:370)\n        at org.graphframes.GraphFrame.find(GraphFrame.scala:263)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n```\n\nAlso, when using the function BFS, ConnectedComponents, LabelPropagation, triangleCount, shortestPaths, pageRank, stronglyConnectedComponents, I get the following errors about the Methods not implemented. \n\n```\nIn [18]: paths = g.bfs(\"name = 'Esther'\", \"age < 32\")\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-18-90070d1d699a> in <module>()\n----> 1 paths = g.bfs(\"name = 'Esther'\", \"age < 32\")\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in bfs(self, fromExpr, toExpr, edgeFilter, maxPathLength)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o101.run.\n: java.lang.NoSuchMethodError: scala.collection.immutable.$colon$colon.hd$1()Ljava/lang/Object;\n        at org.graphframes.GraphFrame.findSimple(GraphFrame.scala:370)\n        at org.graphframes.GraphFrame.find(GraphFrame.scala:263)\n        at org.graphframes.lib.BFS$.org$graphframes$lib$BFS$$run(BFS.scala:159)\n        at org.graphframes.lib.BFS.run(BFS.scala:126)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n\nIn [19]: %cpaste\nPasting code; enter '--' alone on the line to stop or use Ctrl-D.\n:filteredPaths = g.bfs(\n:  fromExpr = \"name = 'Esther'\",\n:  toExpr = \"age < 32\",\n:  edgeFilter = \"relationship != 'friend'\",\n:  maxPathLength = 3)\n:--\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-19-9a217d29ca2a> in <module>()\n      3   toExpr = \"age < 32\",\n      4   edgeFilter = \"relationship != 'friend'\",\n----> 5   maxPathLength = 3)\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in bfs(self, fromExpr, toExpr, edgeFilter, maxPathLength)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o122.run.\n: java.lang.NoSuchMethodError: scala.collection.immutable.$colon$colon.hd$1()Ljava/lang/Object;\n        at org.graphframes.GraphFrame.findSimple(GraphFrame.scala:370)\n        at org.graphframes.GraphFrame.find(GraphFrame.scala:263)\n        at org.graphframes.lib.BFS$.org$graphframes$lib$BFS$$run(BFS.scala:159)\n        at org.graphframes.lib.BFS.run(BFS.scala:126)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n\nIn [20]: result = g.connectedComponents()\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-20-7eb76cabdc93> in <module>()\n----> 1 result = g.connectedComponents()\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in connectedComponents(self)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o141.run.\n: java.lang.NoSuchMethodError: org.apache.spark.sql.DataFrame.map(Lscala/Function1;Lscala/reflect/ClassTag;)Lorg/apache/spark/rdd/RDD;\n        at org.graphframes.GraphFrame.toGraphX(GraphFrame.scala:136)\n        at org.graphframes.GraphFrame.cachedGraphX$lzycompute(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedGraphX(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX$lzycompute(GraphFrame.scala:432)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX(GraphFrame.scala:431)\n        at org.graphframes.lib.ConnectedComponents$.run(ConnectedComponents.scala:50)\n        at org.graphframes.lib.ConnectedComponents.run(ConnectedComponents.scala:43)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n\nIn [21]: g.vertices\nOut[21]: DataFrame[id: string, name: string, age: bigint]\n\nIn [22]: g.vertices.show()\n+---+-------+---+\n| id|   name|age|\n+---+-------+---+\n|  a|  Alice| 34|\n|  b|    Bob| 36|\n|  c|Charlie| 30|\n|  d|  David| 29|\n|  e| Esther| 32|\n|  f|  Fanny| 36|\n|  g|  Gabby| 60|\n+---+-------+---+\n\n\nIn [23]: result = g.stronglyConnectedComponents(maxIter=10)\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-23-9cbad8f66c11> in <module>()\n----> 1 result = g.stronglyConnectedComponents(maxIter=10)\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in stronglyConnectedComponents(self, maxIter)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o163.run.\n: java.lang.NoSuchMethodError: org.apache.spark.sql.DataFrame.map(Lscala/Function1;Lscala/reflect/ClassTag;)Lorg/apache/spark/rdd/RDD;\n        at org.graphframes.GraphFrame.toGraphX(GraphFrame.scala:136)\n        at org.graphframes.GraphFrame.cachedGraphX$lzycompute(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedGraphX(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX$lzycompute(GraphFrame.scala:432)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX(GraphFrame.scala:431)\n        at org.graphframes.lib.StronglyConnectedComponents$.org$graphframes$lib$StronglyConnectedComponents$$run(StronglyConnectedComponents.scala:52)\n        at org.graphframes.lib.StronglyConnectedComponents.run(StronglyConnectedComponents.scala:44)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n\nIn [24]: result = g.labelPropagation(maxIter=5)\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-24-d841648f0e34> in <module>()\n----> 1 result = g.labelPropagation(maxIter=5)\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in labelPropagation(self, maxIter)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o185.run.\n: java.lang.NoSuchMethodError: org.apache.spark.sql.DataFrame.map(Lscala/Function1;Lscala/reflect/ClassTag;)Lorg/apache/spark/rdd/RDD;\n        at org.graphframes.GraphFrame.toGraphX(GraphFrame.scala:136)\n        at org.graphframes.GraphFrame.cachedGraphX$lzycompute(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedGraphX(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX$lzycompute(GraphFrame.scala:432)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX(GraphFrame.scala:431)\n        at org.graphframes.lib.LabelPropagation$.org$graphframes$lib$LabelPropagation$$run(LabelPropagation.scala:63)\n        at org.graphframes.lib.LabelPropagation.run(LabelPropagation.scala:54)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n\nIn [25]: results = g.pageRank(resetProbability=0.15, tol=0.01)\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-25-7ba4099c0dbc> in <module>()\n----> 1 results = g.pageRank(resetProbability=0.15, tol=0.01)\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in pageRank(self, resetProbability, sourceId, maxIter, tol)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o208.run.\n: java.lang.NoSuchMethodError: org.apache.spark.sql.DataFrame.map(Lscala/Function1;Lscala/reflect/ClassTag;)Lorg/apache/spark/rdd/RDD;\n        at org.graphframes.GraphFrame.toGraphX(GraphFrame.scala:136)\n        at org.graphframes.GraphFrame.cachedGraphX$lzycompute(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedGraphX(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX$lzycompute(GraphFrame.scala:432)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX(GraphFrame.scala:431)\n        at org.graphframes.lib.PageRank$.runUntilConvergence(PageRank.scala:153)\n        at org.graphframes.lib.PageRank.run(PageRank.scala:102)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n\nIn [26]: results = g.shortestPaths(landmarks=[\"a\", \"d\"])\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-26-05cc91bf2d89> in <module>()\n----> 1 results = g.shortestPaths(landmarks=[\"a\", \"d\"])\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in shortestPaths(self, landmarks)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o231.run.\n: java.lang.NoSuchMethodError: org.apache.spark.sql.DataFrame.map(Lscala/Function1;Lscala/reflect/ClassTag;)Lorg/apache/spark/rdd/RDD;\n        at org.graphframes.GraphFrame.toGraphX(GraphFrame.scala:136)\n        at org.graphframes.GraphFrame.cachedGraphX$lzycompute(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedGraphX(GraphFrame.scala:438)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX$lzycompute(GraphFrame.scala:432)\n        at org.graphframes.GraphFrame.cachedTopologyGraphX(GraphFrame.scala:431)\n        at org.graphframes.lib.ShortestPaths$.org$graphframes$lib$ShortestPaths$$run(ShortestPaths.scala:69)\n        at org.graphframes.lib.ShortestPaths.run(ShortestPaths.scala:59)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n\nIn [27]: results = g.triangleCount()\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n<ipython-input-27-8e965378aa62> in <module>()\n----> 1 results = g.triangleCount()\n\n/content/tmp/spark-e344f1b3-a40f-488a-9cef-57049b7b3a04/userFiles-54d9528e-17fa-4a53-907e-dc4eca1da328/graphframes_graphframes-0.1.0-spark1.6.jar/graphframes/graphframe.pyc in triangleCount(self)\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n    833         answer = self.gateway_client.send_command(command)\n    834         return_value = get_return_value(\n--> 835             answer, self.gateway_client, self.target_id, self.name)\n    836 \n    837         for temp_arg in temp_args:\n\n/content/SOFTWARE/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)\n     43     def deco(*a, **kw):\n     44         try:\n---> 45             return f(*a, **kw)\n     46         except py4j.protocol.Py4JJavaError as e:\n     47             s = e.java_exception.toString()\n\n/content/SOFTWARE/spark/python/lib/py4j-0.9.1-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    308                 raise Py4JJavaError(\n    309                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 310                     format(target_id, \".\", name), value)\n    311             else:\n    312                 raise Py4JError(\n\nPy4JJavaError: An error occurred while calling o252.run.\n: java.lang.NoSuchMethodError: scala.collection.immutable.$colon$colon.hd$1()Ljava/lang/Object;\n        at org.graphframes.GraphFrame.findSimple(GraphFrame.scala:370)\n        at org.graphframes.GraphFrame.find(GraphFrame.scala:263)\n        at org.graphframes.lib.TriangleCount$.org$graphframes$lib$TriangleCount$$run(TriangleCount.scala:58)\n        at org.graphframes.lib.TriangleCount.run(TriangleCount.scala:39)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n        at py4j.Gateway.invoke(Gateway.java:290)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:209)\n        at java.lang.Thread.run(Thread.java:745)\n\n\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/54", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/54/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/54/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/54/events", "html_url": "https://github.com/graphframes/graphframes/issues/54", "id": 138728483, "node_id": "MDU6SXNzdWUxMzg3Mjg0ODM=", "number": 54, "title": "Maven Repository?", "user": {"login": "anand-singh", "id": 4903911, "node_id": "MDQ6VXNlcjQ5MDM5MTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/4903911?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anand-singh", "html_url": "https://github.com/anand-singh", "followers_url": "https://api.github.com/users/anand-singh/followers", "following_url": "https://api.github.com/users/anand-singh/following{/other_user}", "gists_url": "https://api.github.com/users/anand-singh/gists{/gist_id}", "starred_url": "https://api.github.com/users/anand-singh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anand-singh/subscriptions", "organizations_url": "https://api.github.com/users/anand-singh/orgs", "repos_url": "https://api.github.com/users/anand-singh/repos", "events_url": "https://api.github.com/users/anand-singh/events{/privacy}", "received_events_url": "https://api.github.com/users/anand-singh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-03-05T22:17:03Z", "updated_at": "2016-05-19T17:17:56Z", "closed_at": "2016-03-07T23:11:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/graphframes/graphframes/issues/45", "repository_url": "https://api.github.com/repos/graphframes/graphframes", "labels_url": "https://api.github.com/repos/graphframes/graphframes/issues/45/labels{/name}", "comments_url": "https://api.github.com/repos/graphframes/graphframes/issues/45/comments", "events_url": "https://api.github.com/repos/graphframes/graphframes/issues/45/events", "html_url": "https://github.com/graphframes/graphframes/issues/45", "id": 137642529, "node_id": "MDU6SXNzdWUxMzc2NDI1Mjk=", "number": 45, "title": "Sort columns from motif finding", "user": {"login": "jkbradley", "id": 5084283, "node_id": "MDQ6VXNlcjUwODQyODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5084283?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jkbradley", "html_url": "https://github.com/jkbradley", "followers_url": "https://api.github.com/users/jkbradley/followers", "following_url": "https://api.github.com/users/jkbradley/following{/other_user}", "gists_url": "https://api.github.com/users/jkbradley/gists{/gist_id}", "starred_url": "https://api.github.com/users/jkbradley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jkbradley/subscriptions", "organizations_url": "https://api.github.com/users/jkbradley/orgs", "repos_url": "https://api.github.com/users/jkbradley/repos", "events_url": "https://api.github.com/users/jkbradley/events{/privacy}", "received_events_url": "https://api.github.com/users/jkbradley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-03-01T17:52:59Z", "updated_at": "2016-03-16T21:31:27Z", "closed_at": "2016-03-16T21:31:27Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Motif finding outputs columns in an arbitrary order, but we should sort the columns to match the order of vertices and edges specified in the motif.  That way, if a user writes \"(a)-[e]->(b); (b)-[e2]->(c)\", then the output columns will be ordered as expected: a, e, b, e2, c.\n", "performed_via_github_app": null, "score": 1.0}]}