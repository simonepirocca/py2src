{"total_count": 783, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/horovod/horovod/issues/2188", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2188/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2188/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2188/events", "html_url": "https://github.com/horovod/horovod/issues/2188", "id": 680863323, "node_id": "MDU6SXNzdWU2ODA4NjMzMjM=", "number": 2188, "title": "some question to start tensorflow_synthetic_benchmark.py", "user": {"login": "DeruiLiu", "id": 32285152, "node_id": "MDQ6VXNlcjMyMjg1MTUy", "avatar_url": "https://avatars3.githubusercontent.com/u/32285152?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeruiLiu", "html_url": "https://github.com/DeruiLiu", "followers_url": "https://api.github.com/users/DeruiLiu/followers", "following_url": "https://api.github.com/users/DeruiLiu/following{/other_user}", "gists_url": "https://api.github.com/users/DeruiLiu/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeruiLiu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeruiLiu/subscriptions", "organizations_url": "https://api.github.com/users/DeruiLiu/orgs", "repos_url": "https://api.github.com/users/DeruiLiu/repos", "events_url": "https://api.github.com/users/DeruiLiu/events{/privacy}", "received_events_url": "https://api.github.com/users/DeruiLiu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-18T09:56:53Z", "updated_at": "2020-08-19T07:26:09Z", "closed_at": "2020-08-19T07:26:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow)\r\n2. Framework version:1.10\r\n3. Horovod version:0.19.5\r\n4. MPI version:4.0.3rc4\r\n5. CUDA version:9.0\r\n6. NCCL version:2.3\r\n7. Python version:2.7.12\r\n8. OS and version:ubuntu16.04\r\n9. GCC version:4.9.4\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\nwhen i use start code to run tensorflow_synthetic_benchmark.py as below, it all report the same error, can anyone help me?\r\n1.horovodrun -np 2 -H 172.168.30.26:1,172.168.30.25:1 python2 /root/ldr/horovod/examples/tensorflow_synthetic_benchmark.py\r\n2.mpirun -np 2 -H 172.168.30.26:1,172.168.30.25:1 -bind-to none -map-by slot -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x NCCL_IB_DISABLE=0 -x NCCL_IB_HCA=mlx5_1:1 -x NCCL_IB_GID_INDEX=3 -x NCCL_IB_CUDA_SUPPORT=1 -x NCCL_IB_TC=106 -mca pml ob1 -mca btl ^openib  python2 /root/ldr/horovod/examples/tensorflow_synthetic_benchmark.py --model VGG16 --num-iters 10 --batch-size 64\r\n\r\nthe error is:\r\n*****************************************************************************\r\n\r\nroot@s36-2288H-V5:~/ldr# ./hdrun.sh\r\n  File \"/root/ldr/horovod/examples/tensorflow_synthetic_benchmark.py\", line 85\r\n    print(s, end='\\n' if nl else '')\r\n                ^\r\nSyntaxError: invalid syntax\r\n\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n\r\nmpirun detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. The first process to do so was:\r\n\r\n  Process name: [[39179,1],1]\r\n  Exit code:    1\r\n\r\n\r\n************************************************************************\r\nbut i run tensorflow/benchmark\uff0cit success\u3002\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2161", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2161/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2161/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2161/events", "html_url": "https://github.com/horovod/horovod/issues/2161", "id": 673229440, "node_id": "MDU6SXNzdWU2NzMyMjk0NDA=", "number": 2161, "title": "`horovodrun --check-build` raise `queue.Empty` error", "user": {"login": "firejq", "id": 14916943, "node_id": "MDQ6VXNlcjE0OTE2OTQz", "avatar_url": "https://avatars2.githubusercontent.com/u/14916943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/firejq", "html_url": "https://github.com/firejq", "followers_url": "https://api.github.com/users/firejq/followers", "following_url": "https://api.github.com/users/firejq/following{/other_user}", "gists_url": "https://api.github.com/users/firejq/gists{/gist_id}", "starred_url": "https://api.github.com/users/firejq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/firejq/subscriptions", "organizations_url": "https://api.github.com/users/firejq/orgs", "repos_url": "https://api.github.com/users/firejq/repos", "events_url": "https://api.github.com/users/firejq/events{/privacy}", "received_events_url": "https://api.github.com/users/firejq/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-05T03:42:51Z", "updated_at": "2020-08-05T13:14:40Z", "closed_at": "2020-08-05T13:14:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.13.1\r\n3. Horovod version: 0.19.5\r\n4. MPI version: 2.0.2\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7\r\n7. Python version: 3.6.4\r\n8. OS and version: CentOS 7\r\n9. GCC version: 4.8.5\r\n\r\nWhen I run `horovodrun --check-build`, it raise a error:\r\n```\r\n$horovodrun --check-build --verbose\r\n\r\nChecking whether extension tensorflow was built.\r\nWARNING: Logging before InitGoogleLogging() is written to STDERR\r\nF0805 11:30:01.824879 82359 allocator_registry.cc:52] New registration for AllocatorFactory with name=DefaultCPUAllocator priority=100 at location tensorflow/core/framework/allocator.cc:216 conflicts with previous registration at location tensorflow/core/framework/allocator.cc:216\r\n*** Check failure stack trace: ***\r\nTraceback (most recent call last):\r\n  File \"/dockerdata/my_app/bin/horovodrun\", line 4, in <module>\r\n    __import__('pkg_resources').run_script('horovod==0.19.5', 'horovodrun')\r\n  File \"/dockerdata/my_app/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 658, in run_script\r\n    self.require(requires)[0].run_script(script_name, ns)\r\n  File \"/dockerdata/my_app/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 1438, in run_script\r\n    exec(code, namespace, namespace)\r\n  File \"/dockerdata/my_app/lib/python3.6/site-packages/horovod-0.19.5-py3.6-linux-x86_64.egg/EGG-INFO/scripts/horovodrun\", line 21, in <module>\r\n    run_commandline()\r\n  File \"/dockerdata/my_app/lib/python3.6/site-packages/horovod-0.19.5-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 723, in run_commandline\r\n    _run(args)\r\n  File \"/dockerdata/my_app/lib/python3.6/site-packages/horovod-0.19.5-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 549, in _run\r\n    check_build(args.verbose)\r\n  File \"/dockerdata/my_app/lib/python3.6/site-packages/horovod-0.19.5-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 139, in check_build\r\n    tensorflow=get_check(extension_available('tensorflow', verbose=verbose)),\r\n  File \"/dockerdata/my_app/lib/python3.6/site-packages/horovod-0.19.5-py3.6-linux-x86_64.egg/horovod/common/util.py\", line 105, in extension_available\r\n    ext_base_name, available_fn, 'built', verbose) or False\r\n  File \"/dockerdata/my_app/lib/python3.6/site-packages/horovod-0.19.5-py3.6-linux-x86_64.egg/horovod/common/util.py\", line 99, in _check_extension_lambda\r\n    return queue.get_nowait()\r\n  File \"/dockerdata/my_app/lib/python3.6/multiprocessing/queues.py\", line 126, in get_nowait\r\n    return self.get(False)\r\n  File \"/dockerdata/my_app/lib/python3.6/multiprocessing/queues.py\", line 107, in get\r\n    raise Empty\r\nqueue.Empty\r\n```\r\n\r\nCould anyone give some suggestions to solve this problem? Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2152", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2152/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2152/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2152/events", "html_url": "https://github.com/horovod/horovod/issues/2152", "id": 669365070, "node_id": "MDU6SXNzdWU2NjkzNjUwNzA=", "number": 2152, "title": "We cannot run examples using horovod:latest docker image.", "user": {"login": "workingloong", "id": 18071380, "node_id": "MDQ6VXNlcjE4MDcxMzgw", "avatar_url": "https://avatars1.githubusercontent.com/u/18071380?v=4", "gravatar_id": "", "url": "https://api.github.com/users/workingloong", "html_url": "https://github.com/workingloong", "followers_url": "https://api.github.com/users/workingloong/followers", "following_url": "https://api.github.com/users/workingloong/following{/other_user}", "gists_url": "https://api.github.com/users/workingloong/gists{/gist_id}", "starred_url": "https://api.github.com/users/workingloong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/workingloong/subscriptions", "organizations_url": "https://api.github.com/users/workingloong/orgs", "repos_url": "https://api.github.com/users/workingloong/repos", "events_url": "https://api.github.com/users/workingloong/events{/privacy}", "received_events_url": "https://api.github.com/users/workingloong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-31T03:08:54Z", "updated_at": "2020-08-02T09:17:25Z", "closed_at": "2020-08-02T09:17:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.1.0\r\n3. Horovod version: 0.19.5\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. Spark / PySpark version:\r\n9. OS and version:\r\n10. GCC version:\r\n\r\n**Bug report:**\r\nThe TensorFlow APIs in examples are deprecated by TensorFlow 2.1.0, such as `tf.train.AdamOptimizer`. However, the [docker file](https://github.com/horovod/horovod/blob/master/Dockerfile.cpu) set the TF-2.1.0. So, we cannot run the examples in the docker container using this image.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2148", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2148/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2148/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2148/events", "html_url": "https://github.com/horovod/horovod/issues/2148", "id": 667479663, "node_id": "MDU6SXNzdWU2Njc0Nzk2NjM=", "number": 2148, "title": "Add Gloo support for All-to-All", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/1", "html_url": "https://github.com/horovod/horovod/milestone/1", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/1/labels", "id": 5343023, "node_id": "MDk6TWlsZXN0b25lNTM0MzAyMw==", "number": 1, "title": "0.20.0", "description": "Elastic mode (autoscaling, fault tolerance)", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 7, "closed_issues": 11, "state": "open", "created_at": "2020-04-23T23:49:44Z", "updated_at": "2020-08-17T21:54:52Z", "due_on": null, "closed_at": null}, "comments": 1, "created_at": "2020-07-29T01:22:57Z", "updated_at": "2020-08-11T01:54:01Z", "closed_at": "2020-08-11T01:54:01Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "#2143 adds MPI and NCCL support for all-to-all.  Gloo recently added an op for all-to-all, but our current submodule ref is behind.  We should update Gloo to the latest master, then add support for Gloo when using all-to-all.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2142", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2142/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2142/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2142/events", "html_url": "https://github.com/horovod/horovod/issues/2142", "id": 665842828, "node_id": "MDU6SXNzdWU2NjU4NDI4Mjg=", "number": 2142, "title": "Logging doesn't work correctly", "user": {"login": "abcinje", "id": 33629617, "node_id": "MDQ6VXNlcjMzNjI5NjE3", "avatar_url": "https://avatars0.githubusercontent.com/u/33629617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abcinje", "html_url": "https://github.com/abcinje", "followers_url": "https://api.github.com/users/abcinje/followers", "following_url": "https://api.github.com/users/abcinje/following{/other_user}", "gists_url": "https://api.github.com/users/abcinje/gists{/gist_id}", "starred_url": "https://api.github.com/users/abcinje/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abcinje/subscriptions", "organizations_url": "https://api.github.com/users/abcinje/orgs", "repos_url": "https://api.github.com/users/abcinje/repos", "events_url": "https://api.github.com/users/abcinje/events{/privacy}", "received_events_url": "https://api.github.com/users/abcinje/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-26T19:16:29Z", "updated_at": "2020-07-28T03:20:31Z", "closed_at": "2020-07-28T03:20:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Pytorch\r\n2. Framework version: 1.4.0\r\n3. Horovod version: 0.19.2\r\n4. MPI version: 4.0.0\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.6.9\r\n8. OS and version: \r\n9. GCC version:\r\n\r\nHello.\r\n\r\nI found that logging macro sometimes doesn't work correctly.\r\nSpecifically, logged messages are mixed up when running applications using multiple nodes.\r\nWhen logging, I set the log level as **TRACE**.\r\nThe following is an example I have gotten.\r\n```\r\n[1,2]<stdout>:[[1,3]<stdout>:[2020-07-22 14:10:47.953428: T horovod/common/controller.cc:758] Created response of size 2048\r\n```\r\nIt has to be two seperated messages starting with [1,2] and [1,3].\r\nBut I doubt that using multiple nodes is the cause of the issue as getting the following log\r\n```\r\n[1,1]<stdout>:[[1,1]<stdout>:2020-07-22 14:10:48. 87263: T horovod/common/operations.cc:589] [1]: Performing allreduce.layer4.0.downsample.0.weight\r\n```\r\nIn this case, the ranks of two mixed messages are same.\r\n\r\nBTW, how can I avoid this problem when logging?\r\nIf it is actually a problem, it should be changed into an atomic operation...?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2138", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2138/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2138/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2138/events", "html_url": "https://github.com/horovod/horovod/issues/2138", "id": 664671362, "node_id": "MDU6SXNzdWU2NjQ2NzEzNjI=", "number": 2138, "title": "Trying to install Horovod from a fresh conda environment (with tensorflow) and nothing seems to work", "user": {"login": "illumidas-agn", "id": 17356818, "node_id": "MDQ6VXNlcjE3MzU2ODE4", "avatar_url": "https://avatars0.githubusercontent.com/u/17356818?v=4", "gravatar_id": "", "url": "https://api.github.com/users/illumidas-agn", "html_url": "https://github.com/illumidas-agn", "followers_url": "https://api.github.com/users/illumidas-agn/followers", "following_url": "https://api.github.com/users/illumidas-agn/following{/other_user}", "gists_url": "https://api.github.com/users/illumidas-agn/gists{/gist_id}", "starred_url": "https://api.github.com/users/illumidas-agn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/illumidas-agn/subscriptions", "organizations_url": "https://api.github.com/users/illumidas-agn/orgs", "repos_url": "https://api.github.com/users/illumidas-agn/repos", "events_url": "https://api.github.com/users/illumidas-agn/events{/privacy}", "received_events_url": "https://api.github.com/users/illumidas-agn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 73, "created_at": "2020-07-23T18:11:11Z", "updated_at": "2020-08-06T17:12:32Z", "closed_at": "2020-08-06T17:12:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow)\r\n2. Framework version:\r\n3. Horovod version: 0.19.5\r\n4. MPI version: -\r\n5. CUDA version: -\r\n6. NCCL version: -\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu\r\n9. GCC version: -\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nLooked through all the available open questions. Currently trying to run go-explore (https://github.com/uber-research/go-explore/tree/master/policy_based) and I have only managed to make horovod work once for whatever reason. \r\n\r\nI need it built with tensorflow (aka horovod.tensorflow) and when I try to force the tensorflow flag during installation I get a 10 page log dump which is hard to discern what it actually needs. \r\n\r\nHow do I get horovod running?\r\n\r\nIm not sure what im doing wrong, I've tried everything else\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2137", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2137/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2137/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2137/events", "html_url": "https://github.com/horovod/horovod/issues/2137", "id": 664668243, "node_id": "MDU6SXNzdWU2NjQ2NjgyNDM=", "number": 2137, "title": "libgcc_s.so.1 must be installed for pthread_cancel to work", "user": {"login": "collinabidi", "id": 29078081, "node_id": "MDQ6VXNlcjI5MDc4MDgx", "avatar_url": "https://avatars3.githubusercontent.com/u/29078081?v=4", "gravatar_id": "", "url": "https://api.github.com/users/collinabidi", "html_url": "https://github.com/collinabidi", "followers_url": "https://api.github.com/users/collinabidi/followers", "following_url": "https://api.github.com/users/collinabidi/following{/other_user}", "gists_url": "https://api.github.com/users/collinabidi/gists{/gist_id}", "starred_url": "https://api.github.com/users/collinabidi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/collinabidi/subscriptions", "organizations_url": "https://api.github.com/users/collinabidi/orgs", "repos_url": "https://api.github.com/users/collinabidi/repos", "events_url": "https://api.github.com/users/collinabidi/events{/privacy}", "received_events_url": "https://api.github.com/users/collinabidi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-07-23T18:05:27Z", "updated_at": "2020-07-24T22:37:04Z", "closed_at": "2020-07-24T22:37:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework:: Pytorch\r\n2. Framework version: 1.5.1\r\n3. Horovod version: 0.19.2\r\n4. MPI version: OpenMPI 4.0.3\r\n5. CUDA version: NA\r\n6. NCCL version: NA\r\n7. Python version: 3.7.0\r\n8. OS and version: Red Hat Enterprise Linux 7\r\n9. GCC version: 8.2.0 / 4.8.5 (See below)\r\n\r\n**Your question:**\r\n\r\nHi there. I'm attempting to install Horovod from source on a Red Hat cluster for distributed CPU learning. I have a couple of questions about installation process. I'm currently attempting to follow the [steps from this issue](https://github.com/horovod/horovod/issues/155) but I don't think my errors are related to this.\r\n\r\nQuestion 1. **How do I tell Horovod to use the correct gcc/g++?**\r\n\r\n_Relevant Information_\r\nI use the following commands to install Horovod:\r\n```\r\nHOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_MPI=1 HOROVOD_WITHOUT_GLOO=1 HOROVOD_BUILD_ARCH_FLAGS=-L  HOROVOD_CPU_OPERATIONS=MPI HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITHOUT_MXNET=1  python setup.py clean\r\n```\r\nfollowed by\r\n```\r\nHOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_MPI=1 HOROVOD_WITHOUT_GLOO=1 HOROVOD_BUILD_ARCH_FLAGS=-L  HOROVOD_CPU_OPERATIONS=MPI HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITHOUT_MXNET=1  python setup.py install\r\n```\r\nI get the following warnings when compiling:\r\n![warnings](https://user-images.githubusercontent.com/29078081/88320434-95278f00-cceb-11ea-8109-5cd3eb7b3252.PNG)\r\n\r\nIt seems like the ```gcc``` and ```g++``` versions used by Horovod (4.8.5) do not match the ones that I load in my virtual environment (8.2.0).\r\n```which gcc``` and ```which g++``` both do see the correct versions 8.2.0 for both. It therefore seems that Horovod is using ```\\usr\\bin\\gcc``` and ```\\usr\\bin\\g++``` though (which output version 4.8.5), even though I've explicitly loaded the correct ones using ```module load gcc/8.2.0```.\r\n\r\nQuestion 2. **How do I fix** ```libgcc_s.so.1 must be installed for pthread_cancel to work```?\r\n\r\n_Relevant Information_\r\nI've followed the install steps, troubleshooting guide, and looked at several previous issues, but I always end up with the above error when attempting ```horovodrun --check-build```.\r\n\r\nThis seems like an issue with PATH, so I found where ```libgcc_s.so.1``` resides (/usr/lib/) and put it at the front of my PATH variable. I then appended to my ```LD_LIBRARY_PATH``` just to be sure.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2126", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2126/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2126/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2126/events", "html_url": "https://github.com/horovod/horovod/issues/2126", "id": 663452074, "node_id": "MDU6SXNzdWU2NjM0NTIwNzQ=", "number": 2126, "title": "Horovod deadlock in fork-path model", "user": {"login": "shinleylee", "id": 25567460, "node_id": "MDQ6VXNlcjI1NTY3NDYw", "avatar_url": "https://avatars0.githubusercontent.com/u/25567460?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shinleylee", "html_url": "https://github.com/shinleylee", "followers_url": "https://api.github.com/users/shinleylee/followers", "following_url": "https://api.github.com/users/shinleylee/following{/other_user}", "gists_url": "https://api.github.com/users/shinleylee/gists{/gist_id}", "starred_url": "https://api.github.com/users/shinleylee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shinleylee/subscriptions", "organizations_url": "https://api.github.com/users/shinleylee/orgs", "repos_url": "https://api.github.com/users/shinleylee/repos", "events_url": "https://api.github.com/users/shinleylee/events{/privacy}", "received_events_url": "https://api.github.com/users/shinleylee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-22T03:49:09Z", "updated_at": "2020-07-24T13:50:08Z", "closed_at": "2020-07-24T13:50:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "Sagemaker: 5 * ml.m5.4xlarge\uff0c kernel: tensorflow_p36\r\n**Environment:**\r\n1. Framework: TensorFlow.keras\r\n2. Framework version: 2.0.0\r\n3. Horovod version: 0.18.2\r\n4. MPI version: mpi4py 3.0.3\r\n7. Python version: 3.6\r\n\r\n**Bug report:**\r\nWhen training a model with a fork path (in the attached graph, feature1 was embedded by two layer separately and multiplied at last after distinct processes), and a deadlock emerged right at the forked tensor, leading to a failure in training.\r\nlog\uff1a\r\n```\r\n[1,0]<stderr>:INFO:tensorflow:hvd.rank: 0, train_row_number: 1729685\r\n[1,0]<stderr>:INFO:tensorflow:hvd.rank: 0, validation_row_number: 1235605\r\n[1,1]<stderr>:INFO:tensorflow:hvd.rank: 1, train_row_number: 1729868\r\n[1,1]<stderr>:INFO:tensorflow:hvd.rank: 1, validation_row_number: 1235605\r\n[1,4]<stderr>:INFO:tensorflow:hvd.rank: 4, train_row_number: 1729977\r\n[1,4]<stderr>:INFO:tensorflow:hvd.rank: 4, validation_row_number: 1235605\r\n[1,2]<stderr>:INFO:tensorflow:hvd.rank: 2, train_row_number: 1729496\r\n[1,2]<stderr>:INFO:tensorflow:hvd.rank: 2, validation_row_number: 1235605\r\n[1,3]<stderr>:INFO:tensorflow:hvd.rank: 3, train_row_number: 1730209\r\n[1,3]<stderr>:INFO:tensorflow:hvd.rank: 3, validation_row_number: 1235605\r\n[1,0]<stderr>:INFO:tensorflow:hvd.rank: 0, steps per epoch: 844\r\n[1,0]<stderr>:INFO:tensorflow:hvd.rank: 0, steps in validation: 604\r\n[1,1]<stderr>:INFO:tensorflow:hvd.rank: 1, steps per epoch: 844\r\n[1,1]<stderr>:INFO:tensorflow:hvd.rank: 1, steps in validation: 604\r\n[1,4]<stderr>:INFO:tensorflow:hvd.rank: 4, steps per epoch: 844\r\n[1,4]<stderr>:INFO:tensorflow:hvd.rank: 4, steps in validation: 604\r\n[1,0]<stdout>:Epoch 1/6\r\n[1,2]<stderr>:INFO:tensorflow:hvd.rank: 2, steps per epoch: 844\r\n[1,2]<stderr>:INFO:tensorflow:hvd.rank: 2, steps in validation: 604\r\n[1,3]<stderr>:INFO:tensorflow:hvd.rank: 3, steps per epoch: 844\r\n[1,3]<stderr>:INFO:tensorflow:hvd.rank: 3, steps in validation: 604\r\n[ip-10-0-222-34.ec2.internal:00114] 4 more processes have sent help message help-orte-odls-default.txt / memory not bound\r\n[ip-10-0-222-34.ec2.internal:00114] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\r\n[1,0]<stderr>:[2020-07-15 08:18:52.425933: W horovod/common/stall_inspector.cc:105] One or more tensors were submitted to be reduced, gathered or \r\n    broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are \r\n    trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. \r\n[1,0]<stderr>:Stalled ranks:\r\n[1,0]<stderr>:0: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_factor_embedding_lookup_grad_Reshape_1_0]\r\n[1,0]<stderr>:1: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_factor_embedding_lookup_grad_Reshape_1_0]\r\n[1,0]<stderr>:2: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_factor_embedding_lookup_grad_Reshape_1_0]\r\n[1,0]<stderr>:3: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_embedding_embedding_lookup_grad_Reshape_1_0]\r\n[1,0]<stderr>:4: [training/Adam_Allreduce/HorovodAllgather_training_Adam_gradients_gradients_feature1_factor_embedding_lookup_grad_Reshape_1_0]\r\n```\r\n\r\nThe steps were consistent between workers (batch size 2048).\r\nCPU, Memory, Disk Utilization were healthy.\r\nA minimun model to reproduce this deadlock is here:\r\n![model](https://user-images.githubusercontent.com/25567460/88131605-f5e19980-cc0f-11ea-8a35-4305993d40e0.png)\r\n\r\nThe data is unlikely to be provided, but feature1 can be regarded as week_of_day indexes for instance. And feature2 can be regarded as is_weekend.\r\nDoes anyone have any ideas how this come?\r\n(If more information needed pls let me know)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2125", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2125/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2125/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2125/events", "html_url": "https://github.com/horovod/horovod/issues/2125", "id": 663435369, "node_id": "MDU6SXNzdWU2NjM0MzUzNjk=", "number": 2125, "title": "How can I use elastic horovod", "user": {"login": "jiaqianjing", "id": 16071449, "node_id": "MDQ6VXNlcjE2MDcxNDQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/16071449?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiaqianjing", "html_url": "https://github.com/jiaqianjing", "followers_url": "https://api.github.com/users/jiaqianjing/followers", "following_url": "https://api.github.com/users/jiaqianjing/following{/other_user}", "gists_url": "https://api.github.com/users/jiaqianjing/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiaqianjing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiaqianjing/subscriptions", "organizations_url": "https://api.github.com/users/jiaqianjing/orgs", "repos_url": "https://api.github.com/users/jiaqianjing/repos", "events_url": "https://api.github.com/users/jiaqianjing/events{/privacy}", "received_events_url": "https://api.github.com/users/jiaqianjing/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-22T02:56:56Z", "updated_at": "2020-07-22T13:08:00Z", "closed_at": "2020-07-22T03:22:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Your question:**\r\nHow can I use [elastic horovod](https://horovod.readthedocs.io/en/latest/elastic_include.html)?\r\nFollowing this guidance (https://github.com/horovod/horovod/blob/master/docs/docker.rst), I found that the installed version of horovod is 0.19.5.\r\nWhen I build horovod from source code of master branch, I found that the version of horovod is 0.19.2.\r\n\r\n\r\nNone of these meet the requirements of the  elastic horovod version.\r\n![image](https://user-images.githubusercontent.com/16071449/88129180-0b53c500-cc0a-11ea-98ed-67034c4cf09d.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2117", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2117/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2117/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2117/events", "html_url": "https://github.com/horovod/horovod/issues/2117", "id": 659809736, "node_id": "MDU6SXNzdWU2NTk4MDk3MzY=", "number": 2117, "title": "Horovodrun give me Permission denied (publickey,password)", "user": {"login": "zhenhuahu", "id": 11988890, "node_id": "MDQ6VXNlcjExOTg4ODkw", "avatar_url": "https://avatars3.githubusercontent.com/u/11988890?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhenhuahu", "html_url": "https://github.com/zhenhuahu", "followers_url": "https://api.github.com/users/zhenhuahu/followers", "following_url": "https://api.github.com/users/zhenhuahu/following{/other_user}", "gists_url": "https://api.github.com/users/zhenhuahu/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhenhuahu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhenhuahu/subscriptions", "organizations_url": "https://api.github.com/users/zhenhuahu/orgs", "repos_url": "https://api.github.com/users/zhenhuahu/repos", "events_url": "https://api.github.com/users/zhenhuahu/events{/privacy}", "received_events_url": "https://api.github.com/users/zhenhuahu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-18T01:45:54Z", "updated_at": "2020-07-18T02:47:30Z", "closed_at": "2020-07-18T02:47:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi. We are trying to use Hovorod to run distributed jobs, but got the 'Permission denied (publickey,password)' error. We followed the guide on https://horovod.readthedocs.io/en/stable/running_include.html and set up passwordless authentication between the host and each nodes (also between each node). But we still got this error. In setting up passwordless authentication we used the sudo account. But somehow the output becomes 'root@xxxx: Permission denied (publickey,password).' It seems that it uses root account by default. Is there any way we can fix this? \r\n\r\nI read the posts on https://github.com/horovod/horovod/issues/467, https://github.com/horovod/horovod/issues/1627, and https://github.com/horovod/horovod/issues/110 but they are not very helpful. \r\n\r\nThe last few lines of the output are\r\nFiltering local host names.\r\nRemote host found: server1-0\r\nChecking ssh on all remote hosts.\r\nssh not successful for host server1-0:\r\nWarning: Permanently added 'x.x.x.x' (ECDSA) to the list of known hosts.\r\nPermission denied, please try again.\r\nPermission denied, please try again.\r\nroot@x.x.x.x: Permission denied (publickey,password).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2114", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2114/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2114/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2114/events", "html_url": "https://github.com/horovod/horovod/issues/2114", "id": 658353518, "node_id": "MDU6SXNzdWU2NTgzNTM1MTg=", "number": 2114, "title": "Broadcasting to all processes not only tensors", "user": {"login": "P-Light", "id": 23196111, "node_id": "MDQ6VXNlcjIzMTk2MTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/23196111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/P-Light", "html_url": "https://github.com/P-Light", "followers_url": "https://api.github.com/users/P-Light/followers", "following_url": "https://api.github.com/users/P-Light/following{/other_user}", "gists_url": "https://api.github.com/users/P-Light/gists{/gist_id}", "starred_url": "https://api.github.com/users/P-Light/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/P-Light/subscriptions", "organizations_url": "https://api.github.com/users/P-Light/orgs", "repos_url": "https://api.github.com/users/P-Light/repos", "events_url": "https://api.github.com/users/P-Light/events{/privacy}", "received_events_url": "https://api.github.com/users/P-Light/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-16T16:25:04Z", "updated_at": "2020-07-20T09:50:24Z", "closed_at": "2020-07-20T09:50:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\nI resume training and start from  epoch = n > 0. On the master process it is possible to set  start epoch = n, while slave process needs to get start epoch value from the master. \r\n\r\n**Describe the solution you'd like**\r\nImplement horovod.broadcast() for objects like int, float, list, etc.\r\n\r\n**Describe alternatives you've considered**\r\nNow I'm using this workaround:\r\n`self.start_epoch = hvd.allreduce(\r\n                                    torch.IntTensor(\r\n                                        [self.start_epoch]),\r\n                                    op=hvd.Sum,\r\n                                    ).tolist()[0]`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2110", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2110/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2110/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2110/events", "html_url": "https://github.com/horovod/horovod/issues/2110", "id": 657806870, "node_id": "MDU6SXNzdWU2NTc4MDY4NzA=", "number": 2110, "title": "Error in computing gradients when using allgather", "user": {"login": "hoyden", "id": 18378559, "node_id": "MDQ6VXNlcjE4Mzc4NTU5", "avatar_url": "https://avatars0.githubusercontent.com/u/18378559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hoyden", "html_url": "https://github.com/hoyden", "followers_url": "https://api.github.com/users/hoyden/followers", "following_url": "https://api.github.com/users/hoyden/following{/other_user}", "gists_url": "https://api.github.com/users/hoyden/gists{/gist_id}", "starred_url": "https://api.github.com/users/hoyden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hoyden/subscriptions", "organizations_url": "https://api.github.com/users/hoyden/orgs", "repos_url": "https://api.github.com/users/hoyden/repos", "events_url": "https://api.github.com/users/hoyden/events{/privacy}", "received_events_url": "https://api.github.com/users/hoyden/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-16T03:07:22Z", "updated_at": "2020-07-21T12:58:02Z", "closed_at": "2020-07-21T03:24:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 2.0\r\n3. Horovod version:  0.18.2\r\n\r\nI am trying to get the median of a tensor computed across all batches and all processes. However, I got an error TypeError: Expected int32, got None of type 'NoneType' instead.It seems that computing gradients does not work well with horovod's allgather operation. A simple illustration of what I would like to achieve is as follows:\r\n\r\n>with tf.GradientTape() as tape: \r\n&ensp;&ensp;&ensp;&ensp;my_tensor = compute_my_tensor() \r\n&ensp;&ensp;&ensp;&ensp;gathered_my_tensor = hvd.allgather(my_tensor)  \r\n&ensp;&ensp;&ensp;&ensp;median = get_median(gathered_my_tensor)\r\n&ensp;&ensp;&ensp;&ensp;loss = get_loss(my_tensor, median, training=True)\r\ntape = hvd.DistributedGradientTape(tape)\r\ngrads = tape.gradient(loss, trainable_variables)\r\noptimizer.apply_gradients(zip(grads, trainable_variables))\r\n\r\nBTW, when I use eager mode of tensorflow, there will be no error\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2108", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2108/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2108/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2108/events", "html_url": "https://github.com/horovod/horovod/issues/2108", "id": 657070519, "node_id": "MDU6SXNzdWU2NTcwNzA1MTk=", "number": 2108, "title": "Error while trying to use gradient compression", "user": {"login": "anweshpanda", "id": 60091167, "node_id": "MDQ6VXNlcjYwMDkxMTY3", "avatar_url": "https://avatars0.githubusercontent.com/u/60091167?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anweshpanda", "html_url": "https://github.com/anweshpanda", "followers_url": "https://api.github.com/users/anweshpanda/followers", "following_url": "https://api.github.com/users/anweshpanda/following{/other_user}", "gists_url": "https://api.github.com/users/anweshpanda/gists{/gist_id}", "starred_url": "https://api.github.com/users/anweshpanda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anweshpanda/subscriptions", "organizations_url": "https://api.github.com/users/anweshpanda/orgs", "repos_url": "https://api.github.com/users/anweshpanda/repos", "events_url": "https://api.github.com/users/anweshpanda/events{/privacy}", "received_events_url": "https://api.github.com/users/anweshpanda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-15T05:26:01Z", "updated_at": "2020-07-18T16:39:29Z", "closed_at": "2020-07-18T16:39:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi\r\nI am using horovod with pytorch. With the given mnist example if I am using compression fp16 instead of none , I am getting the following error\r\n-------------------------------------------------------------------------\r\n[1,0]<stderr>:terminate called after throwing an instance of 'c10::Error'\r\n[1,0]<stderr>:  what():  \"div_cpu\" not implemented for 'Half' (operator() at /opt/anaconda/conda-bld/pytorch-base_1588647739240/work/build/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp.AVX.cpp:95)\r\n[1,0]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x6d (0x7fa324a9bd2d in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libc10.so)\r\n[1,0]<stderr>:frame #1: <unknown function> + 0x20ba455 (0x7fa2e7882455 in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\n[1,0]<stderr>:frame #2: <unknown function> + 0x10e9633 (0x7fa2e68b1633 in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\n[1,0]<stderr>:frame #3: at::native::div_out(at::Tensor&, at::Tensor const&, at::Tensor const&) + 0x5f (0x7fa2e68a9d1f in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\n[1,0]<stderr>:frame #4: <unknown function> + 0x152c260 (0x7fa2e6cf4260 in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\n[1,0]<stderr>:frame #5: at::Tensor::div_(at::Tensor const&) const + 0x110 (0x7fa2e68b4620 in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\n[1,0]<stderr>:frame #6: at::native::div_(at::Tensor&, c10::Scalar) + 0x46 (0x7fa2e68ab7c6 in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\n[1,0]<stderr>:frame #7: <unknown function> + 0x16bc55c (0x7fa2e6e8455c in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\n[1,0]<stderr>:frame #8: <unknown function> + 0x32d0fd1 (0x7fa2e8a98fd1 in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so)\r\n[1,0]<stderr>:frame #9: <unknown function> + 0xbacfa (0x7fa283289cfa in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so)\r\n[1,0]<stderr>:frame #10: <unknown function> + 0xaf07b (0x7fa28327e07b in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so)\r\n[1,0]<stderr>:frame #11: <unknown function> + 0x5d35b (0x7fa28322c35b in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so)\r\n[1,0]<stderr>:frame #12: <unknown function> + 0xc819d (0x7fa32418019d in /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/../../../../libstdc++.so.6)\r\n[1,0]<stderr>:frame #13: <unknown function> + 0x84f9 (0x7fa32bad04f9 in /lib64/libpthread.so.0)\r\n[1,0]<stderr>:frame #14: clone + 0x3f (0x7fa32b808f2f in /lib64/libc.so.6)\r\n[1,0]<stderr>:\r\n[1,0]<stderr>:[login1:32123] *** Process received signal ***\r\n[1,0]<stderr>:[login1:32123] Signal: Aborted (6)\r\n[1,0]<stderr>:[login1:32123] Signal code:  (-6)\r\n[1,0]<stderr>:[login1:32123] [ 0] /lib64/libpthread.so.0(+0x132d0)[0x7fa32badb2d0]\r\n[1,0]<stderr>:[login1:32123] [ 1] /lib64/libc.so.6(gsignal+0x110)[0x7fa32b746520]\r\n[1,0]<stderr>:[login1:32123] [ 2] /lib64/libc.so.6(abort+0x151)[0x7fa32b747b01]\r\n[1,0]<stderr>:[login1:32123] [ 3] /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/../../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xbc)[0x7fa32416584a]\r\n[1,0]<stderr>:[login1:32123] [ 4] /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/../../../../libstdc++.so.6(+0xabf47)[0x7fa324163f47]\r\n[1,0]<stderr>:[login1:32123] [ 5] /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/../../../../libstdc++.so.6(+0xabf7d)[0x7fa324163f7d]\r\n[1,0]<stderr>:[login1:32123] [ 6] /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/../../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7fa32416415a]\r\n[1,0]<stderr>:[login1:32123] [ 7] /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so(+0x20ba4d0)[0x7fa2e78824d0]\r\n[1,0]<stderr>:[login1:32123] [ 8] /home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torch/lib/libtorch.so(+0x10e9633)[0x7fa2e68b1633]\r\n-------------------------------------------------------------------------------------------------------------------\r\nI am running my code on multiple CPUs... Any suggestion how to get rid of the error will be of great help...", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2104", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2104/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2104/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2104/events", "html_url": "https://github.com/horovod/horovod/issues/2104", "id": 656636054, "node_id": "MDU6SXNzdWU2NTY2MzYwNTQ=", "number": 2104, "title": "Format Data for Horovod.Spark", "user": {"login": "aliatprotopia", "id": 67888876, "node_id": "MDQ6VXNlcjY3ODg4ODc2", "avatar_url": "https://avatars1.githubusercontent.com/u/67888876?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aliatprotopia", "html_url": "https://github.com/aliatprotopia", "followers_url": "https://api.github.com/users/aliatprotopia/followers", "following_url": "https://api.github.com/users/aliatprotopia/following{/other_user}", "gists_url": "https://api.github.com/users/aliatprotopia/gists{/gist_id}", "starred_url": "https://api.github.com/users/aliatprotopia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aliatprotopia/subscriptions", "organizations_url": "https://api.github.com/users/aliatprotopia/orgs", "repos_url": "https://api.github.com/users/aliatprotopia/repos", "events_url": "https://api.github.com/users/aliatprotopia/events{/privacy}", "received_events_url": "https://api.github.com/users/aliatprotopia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-07-14T13:59:58Z", "updated_at": "2020-07-16T23:18:17Z", "closed_at": "2020-07-16T22:50:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) TF/Keras\r\n2. Framework version: 2.2.0\r\n3. Horovod version: 0.19.5\r\n4. MPI version: Gloo\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.7\r\n8. OS and version: Amazon Linux 2\r\n9. GCC version: 4.8\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? No\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? Yes\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? N/A\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Your question:**\r\nI am trying to use `hvd.KerasEstimator().fit(train_dataset)` and I am very confused as of how I should format my `train_dataset`. I have my data stored as standard parquet with two columns `image` and `label`. `Image` is a `list(list(list))` and `label` is a `list` such that if I apply `np.array`, it gives the right dimensions for my network.\r\n\r\nThe RDD below has the correct `(input, label)-pair` for training, but Horovod does not accept RDD, how should I correctly convert this to Dataframe for training?\r\n`spark.read.parquet('\\path').rdd.map(lambda data: (np.array(data['image']), np.array(data['label'])))`\r\n\r\nI have tried many code snippets with `petastorm`'s `unischema ` with no success.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2103", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2103/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2103/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2103/events", "html_url": "https://github.com/horovod/horovod/issues/2103", "id": 656334336, "node_id": "MDU6SXNzdWU2NTYzMzQzMzY=", "number": 2103, "title": "CIFAR scaling efficiency", "user": {"login": "mreso", "id": 13337103, "node_id": "MDQ6VXNlcjEzMzM3MTAz", "avatar_url": "https://avatars1.githubusercontent.com/u/13337103?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mreso", "html_url": "https://github.com/mreso", "followers_url": "https://api.github.com/users/mreso/followers", "following_url": "https://api.github.com/users/mreso/following{/other_user}", "gists_url": "https://api.github.com/users/mreso/gists{/gist_id}", "starred_url": "https://api.github.com/users/mreso/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mreso/subscriptions", "organizations_url": "https://api.github.com/users/mreso/orgs", "repos_url": "https://api.github.com/users/mreso/repos", "events_url": "https://api.github.com/users/mreso/events{/privacy}", "received_events_url": "https://api.github.com/users/mreso/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-14T05:22:11Z", "updated_at": "2020-07-17T18:30:51Z", "closed_at": "2020-07-17T18:30:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.4.0\r\n3. Horovod version: 0.19.1\r\n4. MPI version: 4.0.0\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.4.8-1\r\n7. Python version: 3.6\r\n8. OS and version: ubuntu18.04\r\n9. GCC version: 4.8\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nHi,\r\n\r\nI am trying to figure out why the training with pytorch + horovod is not scaling well in my project.\r\nTo debug the issue I broke it down to a basic example with docker and the CIFAR10 dataset.\r\nMy environment consist of 3 nodes with 6 K80 gpus each.\r\nRunning the synthetic pytorch and tensorflow benchmarks scales with 88% efficiency up to all 18 gpus but running the CIFAR example gives me merely 58%.\r\n\r\nI start my master node with:\r\n```docker run -ti --rm --network=host --ipc=host -v \"/mnt/nfs/:/app\" -v /mnt/nfs/ssh:/root/.ssh horovod/horovod:0.19.1-tf2.1.0-torch1.4.0-mxnet1.6.0-py3.6-gpu horovodrun -np 18 -H 192.168.2.1:6,192.168.2.2:6,192.168.2.3:6 -p 12345 python /app/pytorch_hvd_cifar10.py --batch-size 128```\r\n\r\nAnd my worker nodes with:\r\n```docker run -ti --rm --network=host --ipc=host -v \"/mnt/nfs/:/app\" -v /mnt/nfs/ssh:/root/.ssh horovod/horovod:0.19.1-tf2.1.0-torch1.4.0-mxnet1.6.0-py3.6-gpu bash -c \"/usr/sbin/sshd -p 12345; sleep infinity\"```\r\n\r\nMy training script is the python_mnist.py example with minor modifications to use CIFAR10 and for timing the training which gives me these throughput values:\r\n\r\n```\r\nnum gpus: images / sec\r\n1:    510.9\r\n6:    410.1\r\n12:   330.2\r\n18:   298.5\r\n```\r\n\r\nAny ideas why it is scaling so badly?\r\n\r\n\r\npytorch_hvd_cifar10.py:\r\n```\r\nimport argparse\r\nimport time\r\nimport numpy as np\r\nimport torch.multiprocessing as mp\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\nfrom torchvision import datasets, transforms\r\nimport torch.utils.data.distributed\r\nimport horovod.torch as hvd\r\nfrom torchvision import models\r\n\r\n# Training settings\r\nparser = argparse.ArgumentParser(description='PyTorch CIFAR Example')\r\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\r\n                    help='input batch size for training (default: 64)')\r\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\r\n                    help='input batch size for testing (default: 1000)')\r\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\r\n                    help='number of epochs to train (default: 10)')\r\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\r\n                    help='learning rate (default: 0.01)')\r\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\r\n                    help='SGD momentum (default: 0.5)')\r\nparser.add_argument('--no-cuda', action='store_true', default=False,\r\n                    help='disables CUDA training')\r\nparser.add_argument('--seed', type=int, default=42, metavar='S',\r\n                    help='random seed (default: 42)')\r\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\r\n                    help='how many batches to wait before logging training status')\r\nparser.add_argument('--fp16-allreduce', action='store_true', default=False,\r\n                    help='use fp16 compression during allreduce')\r\nparser.add_argument('--use-adasum', action='store_true', default=False,\r\n                    help='use adasum algorithm to do reduction')\r\n\r\ndef train(epoch):\r\n    model.train()\r\n    # Horovod: set epoch to sampler for shuffling.\r\n    train_sampler.set_epoch(epoch)\r\n    for batch_idx, (data, target) in enumerate(train_loader):\r\n        if args.cuda:\r\n            data, target = data.cuda(), target.cuda()\r\n        optimizer.zero_grad()\r\n        output = model(data)\r\n        loss = F.cross_entropy(output, target)\r\n        loss.backward()\r\n        optimizer.step()\r\n        if batch_idx % args.log_interval == 0:\r\n            # Horovod: use train_sampler to determine the number of examples in\r\n            # this worker's partition.\r\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n                epoch, batch_idx * len(data), len(train_sampler),\r\n                100. * batch_idx / len(train_loader), loss.item()))\r\n\r\n\r\ndef metric_average(val, name):\r\n    tensor = torch.tensor(val)\r\n    avg_tensor = hvd.allreduce(tensor, name=name)\r\n    return avg_tensor.item()\r\n\r\n\r\ndef test():\r\n    model.eval()\r\n    test_loss = 0.\r\n    test_accuracy = 0.\r\n    for data, target in test_loader:\r\n        if args.cuda:\r\n            data, target = data.cuda(), target.cuda()\r\n        output = model(data)\r\n        # sum up batch loss\r\n\r\n        test_loss += F.cross_entropy(output, target, size_average=False).item()\r\n        # get the index of the max log-probability\r\n        pred = output.data.max(1, keepdim=True)[1]\r\n        test_accuracy += pred.eq(target.data.view_as(pred)).cpu().float().sum()\r\n\r\n    # Horovod: use test_sampler to determine the number of examples in\r\n    # this worker's partition.\r\n    test_loss /= len(test_sampler)\r\n    test_accuracy /= len(test_sampler)\r\n\r\n    # Horovod: average metric values across workers.\r\n    test_loss = metric_average(test_loss, 'avg_loss')\r\n    test_accuracy = metric_average(test_accuracy, 'avg_accuracy')\r\n\r\n    # Horovod: print output only on first rank.\r\n    if hvd.rank() == 0:\r\n        print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\r\n            test_loss, 100. * test_accuracy))\r\n\r\n\r\nif __name__ == '__main__':\r\n    args = parser.parse_args()\r\n    args.cuda = not args.no_cuda and torch.cuda.is_available()\r\n\r\n    # Horovod: initialize library.\r\n    hvd.init()\r\n    torch.manual_seed(args.seed)\r\n\r\n    if args.cuda:\r\n        # Horovod: pin GPU to local rank.\r\n        torch.cuda.set_device(hvd.local_rank())\r\n        torch.cuda.manual_seed(args.seed)\r\n\r\n\r\n    # Horovod: limit # of CPU threads to be used per worker.\r\n    torch.set_num_threads(1)\r\n\r\n    kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\r\n    # When supported, use 'forkserver' to spawn dataloader workers instead of 'fork' to prevent\r\n    # issues with Infiniband implementations that are not fork-safe\r\n    if (kwargs.get('num_workers', 0) > 0 and hasattr(mp, '_supports_context') and\r\n            mp._supports_context and 'forkserver' in mp.get_all_start_methods()):\r\n        kwargs['multiprocessing_context'] = 'forkserver'\r\n\r\n    train_dataset = \\\r\n        datasets.CIFAR10('/app/data-%d' % hvd.rank(), train=True, download=True,\r\n                       transform=transforms.Compose([\r\n                       transforms.ToTensor(),\r\n                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n                                            std=[0.229, 0.224, 0.225])\r\n                       ]))\r\n    # Horovod: use DistributedSampler to partition the training data.\r\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\r\n        train_dataset, num_replicas=hvd.size(), rank=hvd.rank())\r\n    train_loader = torch.utils.data.DataLoader(\r\n        train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs)\r\n\r\n    test_dataset = \\\r\n        datasets.CIFAR10('/app/data-%d' % hvd.rank(), train=False, transform=transforms.Compose([\r\n            transforms.ToTensor(),\r\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n                                 std=[0.229, 0.224, 0.225])\r\n        ]))\r\n    # Horovod: use DistributedSampler to partition the test data.\r\n    test_sampler = torch.utils.data.distributed.DistributedSampler(\r\n        test_dataset, num_replicas=hvd.size(), rank=hvd.rank())\r\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size,\r\n                                              sampler=test_sampler, **kwargs)\r\n\r\n    model = models.resnet18()\r\n\r\n    # By default, Adasum doesn't need scaling up learning rate.\r\n    lr_scaler = hvd.size() if not args.use_adasum else 1\r\n\r\n    if args.cuda:\r\n        # Move model to GPU.\r\n        model.cuda()\r\n        # If using GPU Adasum allreduce, scale learning rate by local_size.\r\n        if args.use_adasum and hvd.nccl_built():\r\n            lr_scaler = hvd.local_size()\r\n\r\n    # Horovod: scale learning rate by lr_scaler.\r\n    optimizer = optim.SGD(model.parameters(), lr=args.lr * lr_scaler,\r\n                          momentum=args.momentum)\r\n\r\n    # Horovod: broadcast parameters & optimizer state.\r\n    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\r\n\r\n    # Horovod: (optional) compression algorithm.\r\n    compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\r\n\r\n    # Horovod: wrap optimizer with DistributedOptimizer.\r\n    optimizer = hvd.DistributedOptimizer(optimizer,\r\n                                         named_parameters=model.named_parameters(),\r\n                                         compression=compression,\r\n                                         op=hvd.Adasum if args.use_adasum else hvd.Average)\r\n\r\n    img_per_secs = []\r\n    for epoch in range(1, args.epochs + 1):\r\n        start_time = time.time()\r\n        train(epoch)\r\n        epoch_time = time.time() - start_time\r\n        img_per_secs.append(len(train_dataset)/epoch_time)\r\n        if hvd.rank() == 0:\r\n            print('Average samples/sec: {}'.format(img_per_secs[-1]))\r\n        test()\r\n    mean_img_per_secs= np.mean(img_per_secs)\r\n    if hvd.rank() == 0:\r\n        print('Average samples/sec: {}'.format(mean_img_per_secs))\r\n        print('Average samples/sec per gpu: {}'.format(mean_img_per_secs/hvd.size()))\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2090", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2090/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2090/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2090/events", "html_url": "https://github.com/horovod/horovod/issues/2090", "id": 654387460, "node_id": "MDU6SXNzdWU2NTQzODc0NjA=", "number": 2090, "title": "ValueError: Process number should not be larger than total available slots.", "user": {"login": "vinhdiesal", "id": 47830328, "node_id": "MDQ6VXNlcjQ3ODMwMzI4", "avatar_url": "https://avatars2.githubusercontent.com/u/47830328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vinhdiesal", "html_url": "https://github.com/vinhdiesal", "followers_url": "https://api.github.com/users/vinhdiesal/followers", "following_url": "https://api.github.com/users/vinhdiesal/following{/other_user}", "gists_url": "https://api.github.com/users/vinhdiesal/gists{/gist_id}", "starred_url": "https://api.github.com/users/vinhdiesal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vinhdiesal/subscriptions", "organizations_url": "https://api.github.com/users/vinhdiesal/orgs", "repos_url": "https://api.github.com/users/vinhdiesal/repos", "events_url": "https://api.github.com/users/vinhdiesal/events{/privacy}", "received_events_url": "https://api.github.com/users/vinhdiesal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-09T22:32:00Z", "updated_at": "2020-07-14T19:52:44Z", "closed_at": "2020-07-14T19:52:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have installed the GPU version of horovod with NCCL 2 on my local machines. \r\n\r\nWhen I run the following command in the terminal:\r\n`horovodrun -np 4 -H localhost:0 192.168.1.191:2 192.168.1.119:2 python Convolution\\ Network\\ MNIST.py`\r\n\r\n`192.168.1.191` and `192.168.1.119` have 2 NVIDIA GPUs each which is why the :2.\r\n\r\nI get the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/vinhdiesal/anaconda3/bin/horovodrun\", line 21, in <module>\r\n    run_commandline()\r\n  File \"/home/vinhdiesal/anaconda3/lib/python3.7/site-packages/horovod/run/runner.py\", line 723, in run_commandline\r\n    _run(args)\r\n  File \"/home/vinhdiesal/anaconda3/lib/python3.7/site-packages/horovod/run/runner.py\", line 656, in _run\r\n    _launch_job(args, remote_host_names, settings, nics, command)\r\n  File \"/home/vinhdiesal/anaconda3/lib/python3.7/site-packages/horovod/run/runner.py\", line 717, in _launch_job\r\n    args.verbose)\r\n  File \"/home/vinhdiesal/anaconda3/lib/python3.7/site-packages/horovod/run/runner.py\", line 694, in run_controller\r\n    gloo_run()\r\n  File \"/home/vinhdiesal/anaconda3/lib/python3.7/site-packages/horovod/run/runner.py\", line 706, in gloo_run_fn\r\n    gloo_run(settings, remote_host_names, nics, env, driver_ip, command)\r\n  File \"/home/vinhdiesal/anaconda3/lib/python3.7/site-packages/horovod/run/gloo_run.py\", line 312, in gloo_run\r\n    launch_gloo(command, exec_command, settings, nics, env, server_ip)\r\n  File \"/home/vinhdiesal/anaconda3/lib/python3.7/site-packages/horovod/run/gloo_run.py\", line 250, in launch_gloo\r\n    host_alloc_plan = _allocate(settings.hosts, settings.num_proc)\r\n  File \"/home/vinhdiesal/anaconda3/lib/python3.7/site-packages/horovod/run/gloo_run.py\", line 103, in _allocate\r\n    raise ValueError(\"Process number should not be larger than \"\r\nValueError: Process number should not be larger than total available slots.\r\n```\r\nI attached the python script which tests out MNIST.\r\n[Convolution Network MNIST.py.zip](https://github.com/horovod/horovod/files/4899826/Convolution.Network.MNIST.py.zip)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2089", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2089/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2089/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2089/events", "html_url": "https://github.com/horovod/horovod/issues/2089", "id": 654223460, "node_id": "MDU6SXNzdWU2NTQyMjM0NjA=", "number": 2089, "title": "SSH Issues - Username ", "user": {"login": "vinhdiesal", "id": 47830328, "node_id": "MDQ6VXNlcjQ3ODMwMzI4", "avatar_url": "https://avatars2.githubusercontent.com/u/47830328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vinhdiesal", "html_url": "https://github.com/vinhdiesal", "followers_url": "https://api.github.com/users/vinhdiesal/followers", "following_url": "https://api.github.com/users/vinhdiesal/following{/other_user}", "gists_url": "https://api.github.com/users/vinhdiesal/gists{/gist_id}", "starred_url": "https://api.github.com/users/vinhdiesal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vinhdiesal/subscriptions", "organizations_url": "https://api.github.com/users/vinhdiesal/orgs", "repos_url": "https://api.github.com/users/vinhdiesal/repos", "events_url": "https://api.github.com/users/vinhdiesal/events{/privacy}", "received_events_url": "https://api.github.com/users/vinhdiesal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-09T17:19:03Z", "updated_at": "2020-07-09T20:59:19Z", "closed_at": "2020-07-09T20:59:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "I want to create a `horovod` job on three machines at `192.168.1.119`, `192.168.1.191` and `192.168.1.119`, however in order for the computer to connect via SSH, you need the username which is `vinhdiesal`. \r\nHowever, `horovodrun` doesn't provide the option to specify a username. I tried the following command which errors out:\r\n`horovodrun -np -4 -H localhost vinhdiesal@192.168.1.191 vinhdiesal@192.168.1.119 python tensorflow.py` which provides error because it needs to be in the `worker:2` format. \r\n\r\nAlso is there a way to run the tensorflow model using `horovod` inside `jupyter notebook`. I'm trying to experiment `horovod` with packages like `DASK` for distributed machine learning. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2084", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2084/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2084/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2084/events", "html_url": "https://github.com/horovod/horovod/issues/2084", "id": 653608601, "node_id": "MDU6SXNzdWU2NTM2MDg2MDE=", "number": 2084, "title": "Conda environment.yml location", "user": {"login": "vfdev-5", "id": 2459423, "node_id": "MDQ6VXNlcjI0NTk0MjM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2459423?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vfdev-5", "html_url": "https://github.com/vfdev-5", "followers_url": "https://api.github.com/users/vfdev-5/followers", "following_url": "https://api.github.com/users/vfdev-5/following{/other_user}", "gists_url": "https://api.github.com/users/vfdev-5/gists{/gist_id}", "starred_url": "https://api.github.com/users/vfdev-5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vfdev-5/subscriptions", "organizations_url": "https://api.github.com/users/vfdev-5/orgs", "repos_url": "https://api.github.com/users/vfdev-5/repos", "events_url": "https://api.github.com/users/vfdev-5/events{/privacy}", "received_events_url": "https://api.github.com/users/vfdev-5/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-08T21:27:55Z", "updated_at": "2020-07-26T18:05:32Z", "closed_at": "2020-07-26T18:05:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "\r\n**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? No\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? No\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Your question:**\r\n\r\nAccording to the docs: https://github.com/horovod/horovod/blob/master/docs/conda.rst#dependencies\r\n\r\n> Below are the core required dependencies. The complete `environment.yml` file is available on GitHub.\r\n\r\nBut I can not find this complete `environment.yml`. Could you please indicate its location. Thanks.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2080", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2080/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2080/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2080/events", "html_url": "https://github.com/horovod/horovod/issues/2080", "id": 652129326, "node_id": "MDU6SXNzdWU2NTIxMjkzMjY=", "number": 2080, "title": "Horovod Controller ", "user": {"login": "jackygit-alt", "id": 26292265, "node_id": "MDQ6VXNlcjI2MjkyMjY1", "avatar_url": "https://avatars3.githubusercontent.com/u/26292265?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jackygit-alt", "html_url": "https://github.com/jackygit-alt", "followers_url": "https://api.github.com/users/jackygit-alt/followers", "following_url": "https://api.github.com/users/jackygit-alt/following{/other_user}", "gists_url": "https://api.github.com/users/jackygit-alt/gists{/gist_id}", "starred_url": "https://api.github.com/users/jackygit-alt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jackygit-alt/subscriptions", "organizations_url": "https://api.github.com/users/jackygit-alt/orgs", "repos_url": "https://api.github.com/users/jackygit-alt/repos", "events_url": "https://api.github.com/users/jackygit-alt/events{/privacy}", "received_events_url": "https://api.github.com/users/jackygit-alt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-07T08:45:35Z", "updated_at": "2020-07-16T03:33:47Z", "closed_at": "2020-07-16T03:33:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a question about horovod controller logics. \r\nSupposed we have two ranks, `rank0` and `rank1`, one tensor `tensor0`, in the last cycle, `tensor0` is ready at `rank0`, but unready at `rank1`, in this situation, we should try to process this `tensor0` request message again in next cycle. In the next cycle, if we again push another ready `tensor 0` request message to `tensor_queue_` at `rank0`, and `tensor0` is still unready at `rank1`. According to this controller logic, because we already have two `tensor0` request message at `rank0`, so when we call `IncrementTensorCount(message, state.joined_size);` at `rank0`, it returns `true`, that means `tensor0` is ready at all ranks, but it's incorrect in this special case. \r\nThat makes confused, is it a bug or something else?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2074", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2074/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2074/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2074/events", "html_url": "https://github.com/horovod/horovod/issues/2074", "id": 649856326, "node_id": "MDU6SXNzdWU2NDk4NTYzMjY=", "number": 2074, "title": "CUDA error: device not ready", "user": {"login": "zanonShao", "id": 19763498, "node_id": "MDQ6VXNlcjE5NzYzNDk4", "avatar_url": "https://avatars0.githubusercontent.com/u/19763498?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zanonShao", "html_url": "https://github.com/zanonShao", "followers_url": "https://api.github.com/users/zanonShao/followers", "following_url": "https://api.github.com/users/zanonShao/following{/other_user}", "gists_url": "https://api.github.com/users/zanonShao/gists{/gist_id}", "starred_url": "https://api.github.com/users/zanonShao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zanonShao/subscriptions", "organizations_url": "https://api.github.com/users/zanonShao/orgs", "repos_url": "https://api.github.com/users/zanonShao/repos", "events_url": "https://api.github.com/users/zanonShao/events{/privacy}", "received_events_url": "https://api.github.com/users/zanonShao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-02T11:27:20Z", "updated_at": "2020-07-04T14:08:37Z", "closed_at": "2020-07-02T13:47:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version:1.5.0\r\n3. Horovod version:0.19.2\r\n4. MPI version:1.0\r\n5. CUDA version:10.2.89\r\n6. NCCL version:2.6.4.1\r\n7. Python version:3.7\r\n8. OS and version:Ubuntu 16.04.6 LTS\r\n9. GCC version:gxx_linux-64  7.3.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n\r\n**Your question:**\r\nWhen I use horovod to run programs like\uff1a\r\n`CUDA_VISIBLE_DEVICES=0,2 horovodrun -np 2 -H localhost:2 python xxxx.py`\r\nThere will be a mistake like this\uff1a\r\n```\r\n[1,1]<stderr>:terminate called after throwing an instance of 'c10::Error'\r\n[1,1]<stderr>:  what():  CUDA error: device not ready (Ready at horovod/torch/ready_event.cc:92)\r\n[1,1]<stderr>:frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x4e (0x7fd94bc2eb5e in /data/shaozl/anaconda3/envs/pytorch/lib/pyth\r\non3.7/site-packages/torch/lib/libc10.so)\r\n[1,1]<stderr>:frame #1: horovod::torch::TorchReadyEvent::Ready() const + 0x11b (0x7fd939fa283b in /data/shaozl/anaconda3/envs/pytorch/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so)\r\n[1,1]<stderr>:frame #2: <unknown function> + 0x75f64 (0x7fd939f0ff64 in /data/shaozl/anaconda3/envs/pytorch/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so)\r\n[1,1]<stderr>:frame #3: <unknown function> + 0xc819d (0x7fd97f29c19d in /data/shaozl/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/lib/../../../.././libstdc++.so.6)\r\n[1,1]<stderr>:frame #4: <unknown function> + 0x76db (0x7fd9a0e5a6db in /lib/x86_64-linux-gnu/libpthread.so.0)\r\n[1,1]<stderr>:frame #5: clone + 0x3f (0x7fd9a0b8388f in /lib/x86_64-linux-gnu/libc.so.6)\r\n```\r\nThis problem 100% appear in the case of 2 gpus\uff0cand  50% probability appearing of 1 gpu\u3002\r\n\r\nAnd I also tried the official _minist_ code on Pytorch\uff0cthis problem will also appear.  The difference is that in _minist_  sometimes this problem will not occur with 2 gpus.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2072", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2072/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2072/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2072/events", "html_url": "https://github.com/horovod/horovod/issues/2072", "id": 649323298, "node_id": "MDU6SXNzdWU2NDkzMjMyOTg=", "number": 2072, "title": "Horovod not recognizing multiple GPUs on Databricks", "user": {"login": "mbluestone", "id": 20776591, "node_id": "MDQ6VXNlcjIwNzc2NTkx", "avatar_url": "https://avatars3.githubusercontent.com/u/20776591?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mbluestone", "html_url": "https://github.com/mbluestone", "followers_url": "https://api.github.com/users/mbluestone/followers", "following_url": "https://api.github.com/users/mbluestone/following{/other_user}", "gists_url": "https://api.github.com/users/mbluestone/gists{/gist_id}", "starred_url": "https://api.github.com/users/mbluestone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mbluestone/subscriptions", "organizations_url": "https://api.github.com/users/mbluestone/orgs", "repos_url": "https://api.github.com/users/mbluestone/repos", "events_url": "https://api.github.com/users/mbluestone/events{/privacy}", "received_events_url": "https://api.github.com/users/mbluestone/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-01T21:11:05Z", "updated_at": "2020-07-08T13:46:04Z", "closed_at": "2020-07-08T13:46:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.5.0\r\n3. Horovod version: 0.19.1\r\n4. MPI version: mpirun (Open MPI) 3.0.0\r\n5. CUDA version: 10.1 \r\n6. NCCL version: 2.7.3\r\n7. Python version: 3.7.6\r\n8. OS and version: Ubuntu 18.04.4 LTS\r\n9. GCC version: 7.5.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? It seems to be similar to issue #604 which hasn't been resolved.\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? NA\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? NA\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Yes\r\n\r\n**Your question:**\r\nI am running Horovod on Databricks Runtime 7.0 ML with 3 Standard_NC24 GPU worker instances and it seems like not all GPUs that are available are being utilized. There are 4 GPUs on each worker, so 12 GPUs in total.\r\n\r\nI have been running tests using the following code:\r\n```\r\nimport horovod.torch as hvd\r\nfrom sparkdl import HorovodRunner\r\n\r\ndef test_fn():\r\n    hvd.init()\r\n    print(hvd.local_rank())\r\n        \r\nhr = HorovodRunner(np=8)\r\nhr.run(test_fn)\r\n```\r\n\r\nAt one point, the output of this code was:\r\n\r\n```\r\n[1,3]<stdout>:1\r\n[1,0]<stdout>:0\r\n[1,1]<stdout>:0\r\n[1,5]<stdout>:2\r\n[1,7]<stdout>:3\r\n[1,4]<stdout>:2\r\n[1,2]<stdout>:1\r\n[1,6]<stdout>:3\r\n```\r\n\r\nI then restarted the cluster and the output was:\r\n```\r\n[1,6]<stdout>:2\r\n[1,0]<stdout>:0\r\n[1,3]<stdout>:1\r\n[1,7]<stdout>:2\r\n[1,4]<stdout>:1\r\n[1,1]<stdout>:0\r\n[1,2]<stdout>:0\r\n[1,5]<stdout>:1\r\n```\r\n\r\nHow come Horovod isn't picking up all of the GPUs available and is doubling/tripling up processes on a few GPUs? Am I doing something wrong here? Is this an issue with HorovodRunner from sparkdl?\r\n\r\nI've tried manually reinstalling Horovod but that doesn't seem to change anything. Any help is greatly appreciated!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2071", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2071/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2071/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2071/events", "html_url": "https://github.com/horovod/horovod/issues/2071", "id": 648683085, "node_id": "MDU6SXNzdWU2NDg2ODMwODU=", "number": 2071, "title": "question on horovod workflow", "user": {"login": "mmmeee1111", "id": 53326730, "node_id": "MDQ6VXNlcjUzMzI2NzMw", "avatar_url": "https://avatars3.githubusercontent.com/u/53326730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mmmeee1111", "html_url": "https://github.com/mmmeee1111", "followers_url": "https://api.github.com/users/mmmeee1111/followers", "following_url": "https://api.github.com/users/mmmeee1111/following{/other_user}", "gists_url": "https://api.github.com/users/mmmeee1111/gists{/gist_id}", "starred_url": "https://api.github.com/users/mmmeee1111/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mmmeee1111/subscriptions", "organizations_url": "https://api.github.com/users/mmmeee1111/orgs", "repos_url": "https://api.github.com/users/mmmeee1111/repos", "events_url": "https://api.github.com/users/mmmeee1111/events{/privacy}", "received_events_url": "https://api.github.com/users/mmmeee1111/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-01T05:25:56Z", "updated_at": "2020-07-06T22:16:07Z", "closed_at": "2020-07-06T22:16:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nHi Horovod experts,\r\n\r\nI am looking into horovod code. For tensorflow, EnqueueTensorAllReduce is for framework plugins. in the operation.cc file, EnqueueTensorAllReduce  pushes tensor and message into the tensor_table and queue. If my understanding is correct, RunLoopOnce will perform MPI operations and put back the response. Can you please help me understand the logic behind this? My question is how the RunLoopOnce is informed to perform the Allreduce when the tensor is ready.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2066", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2066/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2066/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2066/events", "html_url": "https://github.com/horovod/horovod/issues/2066", "id": 646944393, "node_id": "MDU6SXNzdWU2NDY5NDQzOTM=", "number": 2066, "title": "Sync Batch Norm for Tensorflow", "user": {"login": "Trampeye", "id": 26067407, "node_id": "MDQ6VXNlcjI2MDY3NDA3", "avatar_url": "https://avatars0.githubusercontent.com/u/26067407?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Trampeye", "html_url": "https://github.com/Trampeye", "followers_url": "https://api.github.com/users/Trampeye/followers", "following_url": "https://api.github.com/users/Trampeye/following{/other_user}", "gists_url": "https://api.github.com/users/Trampeye/gists{/gist_id}", "starred_url": "https://api.github.com/users/Trampeye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Trampeye/subscriptions", "organizations_url": "https://api.github.com/users/Trampeye/orgs", "repos_url": "https://api.github.com/users/Trampeye/repos", "events_url": "https://api.github.com/users/Trampeye/events{/privacy}", "received_events_url": "https://api.github.com/users/Trampeye/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-28T15:16:45Z", "updated_at": "2020-07-13T20:24:20Z", "closed_at": "2020-07-13T20:24:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nAre there Sync Batch Norm implementations for tensorflow in horovod ?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2065", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2065/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2065/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2065/events", "html_url": "https://github.com/horovod/horovod/issues/2065", "id": 646760865, "node_id": "MDU6SXNzdWU2NDY3NjA4NjU=", "number": 2065, "title": "Fix SparkTests.test_get_available_devices", "user": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-06-27T20:46:03Z", "updated_at": "2020-06-29T20:52:55Z", "closed_at": "2020-06-29T20:52:55Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "We can't move from Spark 3.0.0-dev2 to the 3.0.0 release because test `SparkTests.test_get_available_devices` breaks. Fix the test and move to Spark 3.0.0 again (see #2064). I have raised [Jira ticket SPARK-32120](https://issues.apache.org/jira/browse/SPARK-32120) to see if this is a bug or a new feature in 3.0.0 release.\r\n\r\nThat test might have been fixed by https://github.com/horovod/horovod/pull/2063#issuecomment-650811959.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2055", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2055/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2055/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2055/events", "html_url": "https://github.com/horovod/horovod/issues/2055", "id": 644205279, "node_id": "MDU6SXNzdWU2NDQyMDUyNzk=", "number": 2055, "title": "PyTorch and MXNet unit tests are missing absolute values", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-23T23:12:51Z", "updated_at": "2020-07-18T01:54:23Z", "closed_at": "2020-07-18T01:54:23Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Unit tests that compare \"actual\" and \"expected\" tensors use a pattern of subtracting one tensor from the other and taking the max values:\r\n\r\n```\r\nmax_difference = actual.data.sub(expected).max()\r\n```\r\n\r\nThis difference is then compared against a threshold (for floating point values):\r\n\r\n```\r\nassert max_difference <= threshold, 'hvd.allreduce produces incorrect results'\r\n```\r\n\r\nHowever, because this value does not take the absolute value, it is possible that all values are negative, and the \"max value\" reported is also negative, resulting in the test passing when it should fail.\r\n\r\ncc @romerojosh ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2047", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2047/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2047/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2047/events", "html_url": "https://github.com/horovod/horovod/issues/2047", "id": 642898133, "node_id": "MDU6SXNzdWU2NDI4OTgxMzM=", "number": 2047, "title": "The loss values from different GPUs are the same", "user": {"login": "yianzhongguo", "id": 30361876, "node_id": "MDQ6VXNlcjMwMzYxODc2", "avatar_url": "https://avatars0.githubusercontent.com/u/30361876?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yianzhongguo", "html_url": "https://github.com/yianzhongguo", "followers_url": "https://api.github.com/users/yianzhongguo/followers", "following_url": "https://api.github.com/users/yianzhongguo/following{/other_user}", "gists_url": "https://api.github.com/users/yianzhongguo/gists{/gist_id}", "starred_url": "https://api.github.com/users/yianzhongguo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yianzhongguo/subscriptions", "organizations_url": "https://api.github.com/users/yianzhongguo/orgs", "repos_url": "https://api.github.com/users/yianzhongguo/repos", "events_url": "https://api.github.com/users/yianzhongguo/events{/privacy}", "received_events_url": "https://api.github.com/users/yianzhongguo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-22T09:13:53Z", "updated_at": "2020-06-22T12:48:52Z", "closed_at": "2020-06-22T12:48:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\nI can use Horovod normally. However, today I find the outputs from all the GPUs are all the same. Since the inputs are different and the initializaions of the model are random, I should get different outputs for different GPUs. I don't know the reason and do you meet with it and is it normal?\r\n![loss_output](https://user-images.githubusercontent.com/30361876/85270348-bbb79780-b4ab-11ea-9010-11dc0b94b581.png)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2046", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2046/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2046/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2046/events", "html_url": "https://github.com/horovod/horovod/issues/2046", "id": 642878410, "node_id": "MDU6SXNzdWU2NDI4Nzg0MTA=", "number": 2046, "title": "The loss values from all the GPUs are the same", "user": {"login": "yianzhongguo", "id": 30361876, "node_id": "MDQ6VXNlcjMwMzYxODc2", "avatar_url": "https://avatars0.githubusercontent.com/u/30361876?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yianzhongguo", "html_url": "https://github.com/yianzhongguo", "followers_url": "https://api.github.com/users/yianzhongguo/followers", "following_url": "https://api.github.com/users/yianzhongguo/following{/other_user}", "gists_url": "https://api.github.com/users/yianzhongguo/gists{/gist_id}", "starred_url": "https://api.github.com/users/yianzhongguo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yianzhongguo/subscriptions", "organizations_url": "https://api.github.com/users/yianzhongguo/orgs", "repos_url": "https://api.github.com/users/yianzhongguo/repos", "events_url": "https://api.github.com/users/yianzhongguo/events{/privacy}", "received_events_url": "https://api.github.com/users/yianzhongguo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-22T08:46:07Z", "updated_at": "2020-06-22T09:09:46Z", "closed_at": "2020-06-22T08:53:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\nI can use Horovod normally. However, today I find the outputs from all the GPUs are all the same. Since the inputs are different and the initializaions of the model are random, I should get different outputs for different GPUs.  I don't know the reason and do you meet with it?\r\n![loss_output](https://user-images.githubusercontent.com/30361876/85269736-e35a3000-b4aa-11ea-8e00-cdf55cbf83c6.png)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2043", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2043/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2043/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2043/events", "html_url": "https://github.com/horovod/horovod/issues/2043", "id": 642307216, "node_id": "MDU6SXNzdWU2NDIzMDcyMTY=", "number": 2043, "title": "horovodrun and mpirun both do not work, ", "user": {"login": "wacoder", "id": 10132576, "node_id": "MDQ6VXNlcjEwMTMyNTc2", "avatar_url": "https://avatars2.githubusercontent.com/u/10132576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wacoder", "html_url": "https://github.com/wacoder", "followers_url": "https://api.github.com/users/wacoder/followers", "following_url": "https://api.github.com/users/wacoder/following{/other_user}", "gists_url": "https://api.github.com/users/wacoder/gists{/gist_id}", "starred_url": "https://api.github.com/users/wacoder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wacoder/subscriptions", "organizations_url": "https://api.github.com/users/wacoder/orgs", "repos_url": "https://api.github.com/users/wacoder/repos", "events_url": "https://api.github.com/users/wacoder/events{/privacy}", "received_events_url": "https://api.github.com/users/wacoder/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-20T04:35:06Z", "updated_at": "2020-06-30T20:26:50Z", "closed_at": "2020-06-30T20:26:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Your question:**\r\nPlease ask your question here.\r\nI am using docker on two machines. I am able to ssh from container(host1) to container(host2), and from container(host2) to container(host1). \r\n\r\nThen I run the command \r\n` horovodrun --verbose -np 2 -H 10.64.0.218:1,10.64.59.23:1 -p 12345 python horovod_sample.py `\r\nThe error shows as following: \r\n![image](https://user-images.githubusercontent.com/10132576/85191191-f216cc00-b28b-11ea-95e2-da5dcfc09948.jpeg)\r\n\r\nThen I use mpirun following tutorial: \r\n`mpirun -np 2 -H 10.64.0.218:1,10.64.59.23:1 -v --allow-run-as-root  -bind-to non-map-by slot  -mca plm_rsh_args \"-p 12345 -vvv\" -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -mca pml ob1 -mca btl ^openib python horovod_sample.py `\r\n\r\nIt  shows \r\n\r\n```\r\nOpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n  7 Dec 2017\r\ndebug1: Reading configuration data /root/.ssh/config\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\r\ndebug2: resolving \"10.64.59.23\" port 12345\r\ndebug2: ssh_connect_direct: needpriv 0\r\ndebug1: Connecting to 10.64.59.23 [10.64.59.23] port 12345.\r\ndebug1: Connection established.\r\ndebug1: permanently_set_uid: 0/0\r\ndebug1: identity file /root/.ssh/id_rsa type 0\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /root/.ssh/id_rsa-cert type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /root/.ssh/id_dsa type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /root/.ssh/id_dsa-cert type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /root/.ssh/id_ecdsa type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /root/.ssh/id_ecdsa-cert type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /root/.ssh/id_ed25519 type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /root/.ssh/id_ed25519-cert type -1\r\ndebug1: Local version string SSH-2.0-OpenSSH_7.6p1 Ubuntu-4ubuntu0.3\r\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_7.6p1 Ubuntu-4ubuntu0.3\r\ndebug1: match: OpenSSH_7.6p1 Ubuntu-4ubuntu0.3 pat OpenSSH* compat 0x04000000\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: Authenticating to 10.64.59.23:12345 as 'root'\r\ndebug3: put_host_port: [10.64.59.23]:12345\r\ndebug3: hostkeys_foreach: reading file \"/root/.ssh/known_hosts\"\r\ndebug3: record_hostkey: found key type ECDSA in file /root/.ssh/known_hosts:1\r\ndebug3: load_hostkeys: loaded 1 keys from [10.64.59.23]:12345\r\ndebug3: order_hostkeyalgs: prefer hostkeyalgs: ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521\r\ndebug3: send packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT sent\r\ndebug3: receive packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT received\r\ndebug2: local client KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha256,diffie-hellman-group14-sha1,ext-info-c\r\ndebug2: host key algorithms: ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519-cert-v01@openssh.com,ssh-rsa-cert-v01@openssh.com,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsa\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: none,zlib@openssh.com,zlib\r\ndebug2: compression stoc: none,zlib@openssh.com,zlib\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug2: peer server KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256,diffie-hellman-group14-sha1\r\ndebug2: host key algorithms: ssh-rsa,rsa-sha2-512,rsa-sha2-256,ecdsa-sha2-nistp256,ssh-ed25519\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: none,zlib@openssh.com\r\ndebug2: compression stoc: none,zlib@openssh.com\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug1: kex: algorithm: curve25519-sha256\r\ndebug1: kex: host key algorithm: ecdsa-sha2-nistp256\r\ndebug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: none\r\ndebug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: none\r\ndebug3: send packet: type 30\r\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\r\ndebug3: receive packet: type 31\r\ndebug1: Server host key: ecdsa-sha2-nistp256 SHA256:W/xqSKaO9x7xOfgQjc6vok8JINzPZI/NMYp11cQyymY\r\ndebug3: put_host_port: [10.64.59.23]:12345\r\ndebug3: put_host_port: [10.64.59.23]:12345\r\ndebug3: hostkeys_foreach: reading file \"/root/.ssh/known_hosts\"\r\ndebug3: record_hostkey: found key type ECDSA in file /root/.ssh/known_hosts:1\r\ndebug3: load_hostkeys: loaded 1 keys from [10.64.59.23]:12345\r\ndebug3: hostkeys_foreach: reading file \"/root/.ssh/known_hosts\"\r\ndebug3: record_hostkey: found key type ECDSA in file /root/.ssh/known_hosts:1\r\ndebug3: load_hostkeys: loaded 1 keys from [10.64.59.23]:12345\r\ndebug1: Host '[10.64.59.23]:12345' is known and matches the ECDSA host key.\r\ndebug1: Found key in /root/.ssh/known_hosts:1\r\ndebug3: send packet: type 21\r\ndebug2: set_newkeys: mode 1\r\ndebug1: rekey after 134217728 blocks\r\ndebug1: SSH2_MSG_NEWKEYS sent\r\ndebug1: expecting SSH2_MSG_NEWKEYS\r\ndebug3: receive packet: type 21\r\ndebug1: SSH2_MSG_NEWKEYS received\r\ndebug2: set_newkeys: mode 0\r\ndebug1: rekey after 134217728 blocks\r\ndebug2: key: /root/.ssh/id_rsa (0x5633d4322200)\r\ndebug2: key: /root/.ssh/id_dsa ((nil))\r\ndebug2: key: /root/.ssh/id_ecdsa ((nil))\r\ndebug2: key: /root/.ssh/id_ed25519 ((nil))\r\ndebug3: send packet: type 5\r\ndebug3: receive packet: type 7\r\ndebug1: SSH2_MSG_EXT_INFO received\r\ndebug1: kex_input_ext_info: server-sig-algs=<ssh-ed25519,ssh-rsa,rsa-sha2-256,rsa-sha2-512,ssh-dss,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521>\r\ndebug3: receive packet: type 6\r\ndebug2: service_accept: ssh-userauth\r\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\r\ndebug3: send packet: type 50\r\ndebug3: receive packet: type 51\r\ndebug1: Authentications that can continue: publickey,password\r\ndebug3: start over, passed a different list publickey,password\r\ndebug3: preferred gssapi-keyex,gssapi-with-mic,publickey,keyboard-interactive,password\r\ndebug3: authmethod_lookup publickey\r\ndebug3: remaining preferred: keyboard-interactive,password\r\ndebug3: authmethod_is_enabled publickey\r\ndebug1: Next authentication method: publickey\r\ndebug1: Offering public key: RSA SHA256:6c0laZXc4T1I/eyt3+XkXgTfNQqyRMLKnn4Jf/wVHT4 /root/.ssh/id_rsa\r\ndebug3: send_pubkey_test\r\ndebug3: send packet: type 50\r\ndebug2: we sent a publickey packet, wait for reply\r\ndebug3: receive packet: type 60\r\ndebug1: Server accepts key: pkalg rsa-sha2-512 blen 279\r\ndebug2: input_userauth_pk_ok: fp SHA256:6c0laZXc4T1I/eyt3+XkXgTfNQqyRMLKnn4Jf/wVHT4\r\ndebug3: sign_and_send_pubkey: RSA SHA256:6c0laZXc4T1I/eyt3+XkXgTfNQqyRMLKnn4Jf/wVHT4\r\ndebug3: send packet: type 50\r\ndebug3: receive packet: type 52\r\ndebug1: Authentication succeeded (publickey).\r\nAuthenticated to 10.64.59.23 ([10.64.59.23]:12345).\r\ndebug2: fd 4 setting O_NONBLOCK\r\ndebug1: channel 0: new [client-session]\r\ndebug3: ssh_session2_open: channel_new: 0\r\ndebug2: channel 0: send open\r\ndebug3: send packet: type 90\r\ndebug1: Requesting no-more-sessions@openssh.com\r\ndebug3: send packet: type 80\r\ndebug1: Entering interactive session.\r\ndebug1: pledge: network\r\ndebug3: receive packet: type 80\r\ndebug1: client_input_global_request: rtype hostkeys-00@openssh.com want_reply 0\r\ndebug3: receive packet: type 91\r\ndebug2: channel_input_open_confirmation: channel 0: callback start\r\ndebug2: fd 3 setting TCP_NODELAY\r\ndebug3: ssh_packet_set_tos: set IP_TOS 0x08\r\ndebug2: client_session2_setup: id 0\r\ndebug1: Sending environment.\r\ndebug3: Ignored env CUDNN_VERSION\r\ndebug3: Ignored env LD_LIBRARY_PATH\r\ndebug3: Ignored env HOSTNAME\r\ndebug3: Ignored env NVIDIA_VISIBLE_DEVICES\r\ndebug3: Ignored env NCCL_VERSION\r\ndebug3: Ignored env PWD\r\ndebug3: Ignored env HOME\r\ndebug3: Ignored env PYTORCH_VERSION\r\ndebug3: Ignored env LIBRARY_PATH\r\ndebug3: Ignored env TORCHVISION_VERSION\r\ndebug3: Ignored env TERM\r\ndebug3: Ignored env OPENCV_VERSION\r\ndebug3: Ignored env CUDA_PKG_VERSION\r\ndebug3: Ignored env CUDA_VERSION\r\ndebug3: Ignored env NVIDIA_DRIVER_CAPABILITIES\r\ndebug3: Ignored env PYTHON_VERSION\r\ndebug3: Ignored env SHLVL\r\ndebug3: Ignored env NVIDIA_REQUIRE_CUDA\r\ndebug3: Ignored env PATH\r\ndebug3: Ignored env _\r\ndebug3: Ignored env OLDPWD\r\ndebug3: Ignored env OMPI_MCA_plm_rsh_args\r\ndebug3: Ignored env OMPI_MCA_pml\r\ndebug3: Ignored env OMPI_MCA_btl\r\ndebug3: Ignored env IPATH_NO_BACKTRACE\r\ndebug3: Ignored env HFI_NO_BACKTRACE\r\ndebug3: Ignored env OMPI_MCA_hwloc_base_binding_policy\r\ndebug3: Ignored env OMPI_MCA_rmaps_base_mapping_policy\r\ndebug3: Ignored env PMIX_MCA_mca_base_component_show_load_errors\r\ndebug1: Sending command:     PATH=/usr/local/bin:$PATH ; export PATH ; LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH ; export LD_LIBRARY_PATH ; DYLD_LIBRARY_PATH=/usr/local/lib:$DYLD_LIBRARY_PATH ; export DYLD_LIBRARY_PATH ;   /usr/local/bin/orted -mca ess \"env\" -mca ess_base_jobid \"2117599232\" -mca ess_base_vpid 1 -mca ess_base_num_procs \"2\" -mca orte_node_regex \"psfwnezg[1:3],[2:10].64.59.23@0(2)\" -mca orte_hnp_uri \"2117599232.0;tcp://10.64.0.218,172.17.0.1,172.18.0.1:37988\" -mca pml \"ob1\" -mca btl \"^openib\" -mca plm \"rsh\" --tree-spawn -mca orte_parent_uri \"2117599232.0;tcp://10.64.0.218,172.17.0.1,172.18.0.1:37988\" -mca plm_rsh_args \"-p 12345 -vvv\" -mca hwloc_base_binding_policy \"none\" -mca rmaps_base_mapping_policy \"slot\" -mca pmix \"^s1,s2,cray,isolated\"\r\ndebug2: channel 0: request exec confirm 1\r\ndebug3: send packet: type 98\r\ndebug2: channel_input_open_confirmation: channel 0: callback done\r\ndebug2: channel 0: open confirm rwindow 0 rmax 32768\r\ndebug2: channel 0: rcvd adjust 2097152\r\ndebug3: receive packet: type 99\r\ndebug2: channel_input_status_confirm: type 99 id 0\r\ndebug2: exec request accepted on channel 0\r\ndebug2: channel 0: read<=0 rfd 4 len 0\r\ndebug2: channel 0: read failed\r\ndebug2: channel 0: close_read\r\ndebug2: channel 0: input open -> drain\r\ndebug2: channel 0: ibuf empty\r\ndebug2: channel 0: send eof\r\ndebug3: send packet: type 96\r\ndebug2: channel 0: input drain -> closed\r\n\r\n------------------------------------------------------------\r\nA process or daemon was unable to complete a TCP connection\r\nto another process:\r\n  Local host:    psxi1mzh8\r\n  Remote host:   psfwnezg3\r\nThis is usually caused by a firewall on the remote host. Please\r\ncheck that any firewall (e.g., iptables) has been disabled and\r\ntry again.\r\n------------------------------------------------------------\r\ndebug3: receive packet: type 98\r\ndebug1: client_input_channel_req: channel 0 rtype exit-status reply 0\r\ndebug3: receive packet: type 96\r\ndebug2: channel 0: rcvd eof\r\ndebug2: channel 0: output open -> drain\r\ndebug2: channel 0: obuf empty\r\ndebug2: channel 0: close_write\r\ndebug2: channel 0: output drain -> closed\r\ndebug3: receive packet: type 97\r\ndebug2: channel 0: rcvd close\r\ndebug3: channel 0: will not send data after close\r\ndebug2: channel 0: almost dead\r\ndebug2: channel 0: gc: notify user\r\ndebug2: channel 0: gc: user detached\r\ndebug2: channel 0: send close\r\ndebug3: send packet: type 97\r\ndebug2: channel 0: is dead\r\ndebug2: channel 0: garbage collecting\r\ndebug1: channel 0: free: client-session, nchannels 1\r\ndebug3: channel 0: status: The following connections are open:\r\n  #0 client-session (t4 r0 i3/0 o3/0 fd -1/-1 cc -1)\r\n\r\ndebug3: send packet: type 1\r\ndebug1: fd 0 clearing O_NONBLOCK\r\nTransferred: sent 3424, received 2948 bytes, in 130.4 seconds\r\nBytes per second: sent 26.3, received 22.6\r\ndebug1: Exit status 1\r\n--------------------------------------------------------------------------\r\nORTE was unable to reliably start one or more daemons.\r\nThis usually is caused by:\r\n\r\n* not finding the required libraries and/or binaries on\r\n  one or more nodes. Please check your PATH and LD_LIBRARY_PATH\r\n  settings, or configure OMPI with --enable-orterun-prefix-by-default\r\n\r\n* lack of authority to execute on one or more specified nodes.\r\n  Please verify your allocation and authorities.\r\n\r\n* the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base).\r\n  Please check with your sys admin to determine the correct location to use.\r\n\r\n*  compilation of the orted with dynamic libraries when static are required\r\n  (e.g., on Cray). Please check your configure cmd line and consider using\r\n  one of the contrib/platform definitions for your system type.\r\n\r\n* an inability to create a connection back to mpirun due to a\r\n  lack of common network interfaces and/or no route found between\r\n  them. Please check network connectivity (including firewalls\r\n  and network routing requirements).\r\n--------------------------------------------------------------------------\r\n```\r\n  Local host:    psxi1mzh8 (this is host 2)\r\n  Remote host:   psfwnezg3 (this is host1)\r\nBut I can ssh from host2 to host1 passwordless. Really appreciated if could provide some help. \r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2037", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2037/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2037/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2037/events", "html_url": "https://github.com/horovod/horovod/issues/2037", "id": 641763424, "node_id": "MDU6SXNzdWU2NDE3NjM0MjQ=", "number": 2037, "title": "Running horovod.spark.run with env=os.environ fails", "user": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2020-06-19T07:20:23Z", "updated_at": "2020-06-19T17:23:09Z", "closed_at": "2020-06-19T17:23:09Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Example:\r\n\r\n    horovod.spark.run(fn, num_proc=2, env=os.environ)\r\n\r\nThat `env` is an object, not a dictionary. It cannot be pickled:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"horovod/run/common/util/tiny_shell_exec.py\", line 32, in execute\r\n    exit_code = safe_shell_exec.execute(command, env=env, stdout=output, stderr=output)\r\n  File \"horovod/run/common/util/safe_shell_exec.py\", line 183, in execute\r\n    middleman.start()\r\n  File \"multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"multiprocessing/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"multiprocessing/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nAttributeError: Can't pickle local object '_createenviron.<locals>.encode'\r\n```\r\n\r\nIt works with\r\n\r\n    horovod.spark.run(fn, num_proc=2, env=os.environ.copy())\r\n\r\nThe `run` function needs to copy `env` itself first.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2033", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2033/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2033/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2033/events", "html_url": "https://github.com/horovod/horovod/issues/2033", "id": 640934130, "node_id": "MDU6SXNzdWU2NDA5MzQxMzA=", "number": 2033, "title": "Horovod spark raise error No module named 'pyspark'", "user": {"login": "WeichenXu123", "id": 19235986, "node_id": "MDQ6VXNlcjE5MjM1OTg2", "avatar_url": "https://avatars0.githubusercontent.com/u/19235986?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WeichenXu123", "html_url": "https://github.com/WeichenXu123", "followers_url": "https://api.github.com/users/WeichenXu123/followers", "following_url": "https://api.github.com/users/WeichenXu123/following{/other_user}", "gists_url": "https://api.github.com/users/WeichenXu123/gists{/gist_id}", "starred_url": "https://api.github.com/users/WeichenXu123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WeichenXu123/subscriptions", "organizations_url": "https://api.github.com/users/WeichenXu123/orgs", "repos_url": "https://api.github.com/users/WeichenXu123/repos", "events_url": "https://api.github.com/users/WeichenXu123/events{/privacy}", "received_events_url": "https://api.github.com/users/WeichenXu123/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-06-18T06:03:19Z", "updated_at": "2020-06-22T13:04:09Z", "closed_at": "2020-06-22T13:03:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Tensorflow\r\n2. Framework version: \r\n3. Horovod version: Horovod >= 0.19.2\r\n4. MPI version: N/A\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.7\r\n8. Spark / PySpark version: spark 2.6 (Note: Download spark tarball and deploy spark in a separate directory instead of install pyspark into python site-packages)\r\n9. OS and version: N/A\r\n10. GCC version: N/A\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\n**Reproduce steps**\r\n```\r\n# Note, don't install pyspark by \"pip\", if already install pyspark by \"pip\", uninstall it first.\r\n# Install horovod >= 0.19.2\r\npip3.7 install --no-cache-dir --force-reinstall horovod==0.19.4\r\n\r\n# Uninstall pyspark (if needed)\r\npip3.7 uninstall pyspark\r\n\r\n# Download and untar spark tarball\r\nwget http://apache.mirrors.hoobly.com/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz\r\ntar -xf spark-3.0.0-preview2-bin-hadoop2.7.tgz\r\ncd spark-3.0.0-preview2-bin-hadoop2.7\r\n\r\n# enter pyspark REPL shell\r\nPYSPARK_PYTHON=python3.7 bin/pyspark\r\n```\r\n\r\nNow run test code in pyspark REPL shell:\r\n~~~python\r\nimport numpy as np\r\nimport horovod.tensorflow.keras as hvd\r\nimport horovod.spark\r\ndef test_tensorflow():\r\n  hvd.init()\r\n  gathered = hvd.allgather([hvd.rank()])\r\n  assert np.allclose(gathered, list(range(hvd.size())))\r\n  return hvd.rank()\r\nranks = horovod.spark.run(test_tensorflow, num_proc=2)\r\n~~~\r\n\r\nWill get error like:\r\n```\r\n  File \"/usr/lib/python3.7/runpy.py\", line 183, in _run_module_as_main\r\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\r\n  File \"/usr/lib/python3.7/runpy.py\", line 109, in _get_module_details\r\n    __import__(pkg_name)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/__init__.py\", line 18, in <module>\r\n    from .runner import run\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 20, in <module>\r\n    import pyspark\r\nModuleNotFoundError: No module named 'pyspark'\r\n--------------------------------------------------------------------------\r\nORTE was unable to reliably start one or more daemons.\r\nThis usually is caused by:\r\n...\r\n--------------------------------------------------------------------------\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.7/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 100, in run_spark\r\n    result = procs.mapPartitionsWithIndex(_make_mapper(driver.addresses(), settings, use_gloo)).collect()\r\n  File \"/home/weichen.xu/spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/rdd.py\", line 889, in collect\r\n    sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())\r\n  File \"/home/weichen.xu/spark-3.0.0-preview2-bin-hadoop2.7/python/lib/py4j-0.10.8.1-src.zip/py4j/java_gateway.py\", line 1286, in __call__\r\n    answer, self.gateway_client, self.target_id, self.name)\r\n  File \"/home/weichen.xu/spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 98, in deco\r\n    return f(*a, **kw)\r\n  File \"/home/weichen.xu/spark-3.0.0-preview2-bin-hadoop2.7/python/lib/py4j-0.10.8.1-src.zip/py4j/protocol.py\", line 328, in get_return_value\r\n    format(target_id, \".\", name), value)\r\npy4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\r\n: org.apache.spark.SparkException: Job 0 cancelled part of cancelled job group horovod.spark.run.0\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1989)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1924)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleJobGroupCancelled$4(DAGScheduler.scala:937)\r\n\tat scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)\r\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:936)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2175)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2155)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2144)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:758)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2116)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2137)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2156)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2181)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:168)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 227, in run\r\n    _launch_job(use_mpi, use_gloo, settings, driver, env, stdout, stderr)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 123, in _launch_job\r\n    settings.verbose)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/run/runner.py\", line 686, in run_controller\r\n    mpi_run()\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/runner.py\", line 121, in <lambda>\r\n    use_mpi, lambda: mpi_run(settings, nics, driver, env, stdout, stderr),\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/spark/mpi_run.py\", line 54, in mpi_run\r\n    hr_mpi_run(settings, nics, env, command, stdout=stdout, stderr=stderr)\r\n  File \"/home/weichen.xu/.local/lib/python3.7/site-packages/horovod/run/mpi_run.py\", line 201, in mpi_run\r\n    raise RuntimeError(\"mpirun failed with exit code {exit_code}\".format(exit_code=exit_code))\r\nRuntimeError: mpirun failed with exit code 1\r\n>>> 20/06/18 05:40:55 WARN PythonRunner: Incomplete task 0.0 in stage 0 (TID 0) interrupted: Attempting to kill Python Worker\r\n20/06/18 05:40:55 WARN PythonRunner: Incomplete task 1.0 in stage 0 (TID 1) interrupted: Attempting to kill Python Worker\r\n20/06/18 05:40:56 WARN TaskSetManager: Lost task 1.0 in stage 0.0 (TID 1, ip-10-20-4-87.us-west-2.compute.internal, executor driver): TaskKilled (Stage cancelled)\r\n20/06/18 05:40:56 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, ip-10-20-4-87.us-west-2.compute.internal, executor driver): TaskKilled (Stage cancelled)\r\n```\r\n\r\nI made some investigation, and already confirmed that this bug was introduced in https://github.com/horovod/horovod/pull/1839\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2029", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2029/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2029/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2029/events", "html_url": "https://github.com/horovod/horovod/issues/2029", "id": 639170627, "node_id": "MDU6SXNzdWU2MzkxNzA2Mjc=", "number": 2029, "title": "hvd.keras_estimator.fit() throws Py4JJavaError caused by java.io.IOException", "user": {"login": "orwa-te", "id": 32763039, "node_id": "MDQ6VXNlcjMyNzYzMDM5", "avatar_url": "https://avatars2.githubusercontent.com/u/32763039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/orwa-te", "html_url": "https://github.com/orwa-te", "followers_url": "https://api.github.com/users/orwa-te/followers", "following_url": "https://api.github.com/users/orwa-te/following{/other_user}", "gists_url": "https://api.github.com/users/orwa-te/gists{/gist_id}", "starred_url": "https://api.github.com/users/orwa-te/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/orwa-te/subscriptions", "organizations_url": "https://api.github.com/users/orwa-te/orgs", "repos_url": "https://api.github.com/users/orwa-te/repos", "events_url": "https://api.github.com/users/orwa-te/events{/privacy}", "received_events_url": "https://api.github.com/users/orwa-te/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-06-15T21:19:32Z", "updated_at": "2020-06-19T16:32:49Z", "closed_at": "2020-06-19T16:32:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): Tensorflow\r\n2. Framework version: 2.1.0\r\n3. Horovod version: 0.19.4\r\n4. MPI version: 4.0.3\r\n5. CUDA version: None\r\n6. NCCL version: None\r\n7. Python version: 3.7.0\r\n8. OS and version: Ubuntu 20\r\n9. GCC version: 9.3.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nI am trying to execute the example linked at [keras_spark_mnist.py](https://github.com/horovod/horovod/blob/master/examples/keras_spark_mnist.py) on my standalone Spark cluster which is an only single machine with 10 GB Ram and has one worker on the same machine.\r\nAfter a few seconds of execution, I get an error at line 114 \"**keras_model = keras_estimator.fit(train_df).setOutputCols(['label_prob'])**\" described below:\r\n\r\n\"Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob. : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 4 times, most recent failure: Lost task 0.3 in stage 4.0 (TID 9, 192.168.198.131, executor 0): java.io.IOException: Cannot run program \"python\": error=2, No such file or directory\"\r\n\r\nWhat could be the problem? How do I solve it?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2028", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2028/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2028/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2028/events", "html_url": "https://github.com/horovod/horovod/issues/2028", "id": 638656609, "node_id": "MDU6SXNzdWU2Mzg2NTY2MDk=", "number": 2028, "title": "more GPUs are used than specified", "user": {"login": "ChenYang-ChenYang", "id": 9147691, "node_id": "MDQ6VXNlcjkxNDc2OTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/9147691?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChenYang-ChenYang", "html_url": "https://github.com/ChenYang-ChenYang", "followers_url": "https://api.github.com/users/ChenYang-ChenYang/followers", "following_url": "https://api.github.com/users/ChenYang-ChenYang/following{/other_user}", "gists_url": "https://api.github.com/users/ChenYang-ChenYang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChenYang-ChenYang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChenYang-ChenYang/subscriptions", "organizations_url": "https://api.github.com/users/ChenYang-ChenYang/orgs", "repos_url": "https://api.github.com/users/ChenYang-ChenYang/repos", "events_url": "https://api.github.com/users/ChenYang-ChenYang/events{/privacy}", "received_events_url": "https://api.github.com/users/ChenYang-ChenYang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-15T08:39:12Z", "updated_at": "2020-06-16T02:48:59Z", "closed_at": "2020-06-16T02:48:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "horovod version: 0.19.4\r\nNCCL\uff1a2.7.3\r\nOpen MPI: 4.0.3\r\nTensorflow: 1.13.1\r\n\r\nI have a server with 4 Nvidia GPUs. I ran following command to try to use the first 2 GPUs: \r\nhorovodrun -np 2 -H localhost:2 python examples/tensorflow_mnist.py\r\n\r\nBut all the 4 GPUs are used when I ran nvidia-smi. Each GPU have two lines and the GPU 0, 1 used more memory than others, 643MiB in two lines. I checked \"ps -aef |grep python\", there are two python tensorflow_mnist.py processes only.\r\nI think the correct result should be only GPU 0 and 1 are used and each has one line in the nvidia-smi. How to resolve it?\r\n\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n.......\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     35165      C   python                                       643MiB |\r\n|    0     35166      C   python                                       135MiB |\r\n|    1     35165      C   python                                       135MiB |\r\n|    1     35166      C   python                                       643MiB |\r\n|    2     35165      C   python                                       135MiB |\r\n|    2     35166      C   python                                       135MiB |\r\n|    3     35165      C   python                                       135MiB |\r\n|    3     35166      C   python                                       135MiB |\r\n+-----------------------------------------------------------------------------+\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2025", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2025/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2025/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2025/events", "html_url": "https://github.com/horovod/horovod/issues/2025", "id": 638563192, "node_id": "MDU6SXNzdWU2Mzg1NjMxOTI=", "number": 2025, "title": "Horovod Gradient Compression", "user": {"login": "vineeths96", "id": 50873201, "node_id": "MDQ6VXNlcjUwODczMjAx", "avatar_url": "https://avatars3.githubusercontent.com/u/50873201?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vineeths96", "html_url": "https://github.com/vineeths96", "followers_url": "https://api.github.com/users/vineeths96/followers", "following_url": "https://api.github.com/users/vineeths96/following{/other_user}", "gists_url": "https://api.github.com/users/vineeths96/gists{/gist_id}", "starred_url": "https://api.github.com/users/vineeths96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vineeths96/subscriptions", "organizations_url": "https://api.github.com/users/vineeths96/orgs", "repos_url": "https://api.github.com/users/vineeths96/repos", "events_url": "https://api.github.com/users/vineeths96/events{/privacy}", "received_events_url": "https://api.github.com/users/vineeths96/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-15T05:46:54Z", "updated_at": "2020-07-19T11:28:27Z", "closed_at": "2020-07-19T11:28:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a question about how the gradient compression is performed within Horovod. As mentioned in the source code [here](https://github.com/horovod/horovod/blob/master/horovod/tensorflow/compression.py),  we need to inherit the base compressor class and override `compress` and `decompress` functions.\r\n\r\nWhat my doubt is that in which order the operations are performed. More specifically, is the order as shown below?\r\n\r\n1. Calculate gradient on *each worker*.\r\n2. Compress the gradients at *each worker*.\r\n3. Communicate the gradients (compressed) to all workers.\r\n4. Decompress the collection of gradients *at each worker*\r\n5. Perform an `all_reduce` of gradients and update the parameters.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2021", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2021/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2021/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2021/events", "html_url": "https://github.com/horovod/horovod/issues/2021", "id": 637410975, "node_id": "MDU6SXNzdWU2Mzc0MTA5NzU=", "number": 2021, "title": "ImportError : Undefined Symbol.", "user": {"login": "KevvinHoo", "id": 23524621, "node_id": "MDQ6VXNlcjIzNTI0NjIx", "avatar_url": "https://avatars3.githubusercontent.com/u/23524621?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KevvinHoo", "html_url": "https://github.com/KevvinHoo", "followers_url": "https://api.github.com/users/KevvinHoo/followers", "following_url": "https://api.github.com/users/KevvinHoo/following{/other_user}", "gists_url": "https://api.github.com/users/KevvinHoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/KevvinHoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KevvinHoo/subscriptions", "organizations_url": "https://api.github.com/users/KevvinHoo/orgs", "repos_url": "https://api.github.com/users/KevvinHoo/repos", "events_url": "https://api.github.com/users/KevvinHoo/events{/privacy}", "received_events_url": "https://api.github.com/users/KevvinHoo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-12T00:53:03Z", "updated_at": "2020-06-16T07:44:15Z", "closed_at": "2020-06-16T07:44:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version:1.4.0\r\n3. Horovod version:0.18.2\r\n4. MPI version:3.1.4\r\n5. CUDA version:10.0.130\r\n6. NCCL version:2.4.6\r\n7. Python version:3.7\r\n8. OS and version: CentOS\r\n9. GCC version:5.5.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc] (https://github.com/horovod/horovod/blob/master/docs/running.rst)?Yes\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?Yes\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?Yes\r\n\r\n**Your question:**\r\nWhen I have installed the Horovod and get started with an example program, then have an error below:\r\n```\r\nTraceback (most recent call last):\r\n  File \"trainer.py\", line 16, in <module>\r\n    import horovod.torch as hvd\r\n  File \"/GPUFS/nudt_chkwu_2/.conda/envs/Horovod/lib/python3.7/site-packages/horovod/torch/__init__.py\", line 35, in <module>\r\n    from horovod.torch.mpi_ops import allreduce, allreduce_async, allreduce_, allreduce_async_\r\n  File \"/GPUFS/nudt_chkwu_2/.conda/envs/Horovod/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 28, in <module>\r\n    from horovod.torch import mpi_lib_v2 as mpi_lib\r\nImportError: /GPUFS/nudt_chkwu_2/.conda/envs/Horovod/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so: undefined symbol: _ZN6caffe26detail37_typeMetaDataInstance_preallocated_32E\r\n\r\n```\r\nand the `ldd ...mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so` print that,\r\n```\r\n$ldd /GPUFS/nudt_chkwu_2/.conda/envs/Horovod/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so \r\n        linux-vdso.so.1 =>  (0x00007ffdb5b91000)\r\n        libcudart.so.10.0 => not found\r\n        libmpi.so.40 => /app/MPI/openmpi/3.1.4-icc-18.0.1/lib/libmpi.so.40 (0x00002b2a9ec9a000)\r\n        libstdc++.so.6 => /GPUFS/app_GPU/application/anaconda3/5.3.1/envs/HOROVOD/lib/libstdc++.so.6 (0x00002b2a94a43000)\r\n        libm.so.6 => /lib64/libm.so.6 (0x00002b2a9efd4000)\r\n        libgcc_s.so.1 => /GPUFS/app_GPU/application/anaconda3/5.3.1/envs/HOROVOD/lib/libgcc_s.so.1 (0x00002b2a94bb8000)\r\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00002b2a9f2d6000)\r\n        libc.so.6 => /lib64/libc.so.6 (0x00002b2a9f4f2000)\r\n        /lib64/ld-linux-x86-64.so.2 (0x00002b2a94a09000)\r\n        libopen-rte.so.40 => /app/MPI/openmpi/3.1.4-icc-18.0.1/lib/libopen-rte.so.40 (0x00002b2a9f8bf000)\r\n        libopen-pal.so.40 => /app/MPI/openmpi/3.1.4-icc-18.0.1/lib/libopen-pal.so.40 (0x00002b2a9fb91000)\r\n        librt.so.1 => /lib64/librt.so.1 (0x00002b2a9fee7000)\r\n        libutil.so.1 => /lib64/libutil.so.1 (0x00002b2aa00ef000)\r\n        libz.so.1 => /lib64/libz.so.1 (0x00002b2aa02f2000)\r\n        libdl.so.2 => /lib64/libdl.so.2 (0x00002b2aa0508000)\r\n```\r\nAny help is appreciated! Thanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2016", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2016/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2016/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2016/events", "html_url": "https://github.com/horovod/horovod/issues/2016", "id": 636294310, "node_id": "MDU6SXNzdWU2MzYyOTQzMTA=", "number": 2016, "title": "How to evaluate the model when use MonitoredTrainingSession of tensorflow to train", "user": {"login": "yianzhongguo", "id": 30361876, "node_id": "MDQ6VXNlcjMwMzYxODc2", "avatar_url": "https://avatars0.githubusercontent.com/u/30361876?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yianzhongguo", "html_url": "https://github.com/yianzhongguo", "followers_url": "https://api.github.com/users/yianzhongguo/followers", "following_url": "https://api.github.com/users/yianzhongguo/following{/other_user}", "gists_url": "https://api.github.com/users/yianzhongguo/gists{/gist_id}", "starred_url": "https://api.github.com/users/yianzhongguo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yianzhongguo/subscriptions", "organizations_url": "https://api.github.com/users/yianzhongguo/orgs", "repos_url": "https://api.github.com/users/yianzhongguo/repos", "events_url": "https://api.github.com/users/yianzhongguo/events{/privacy}", "received_events_url": "https://api.github.com/users/yianzhongguo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-10T14:27:38Z", "updated_at": "2020-06-12T07:02:58Z", "closed_at": "2020-06-12T07:02:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\nHow to evaluate the model after I use MonitoredTrainingSession of tensorflow to train it? \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2015", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2015/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2015/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2015/events", "html_url": "https://github.com/horovod/horovod/issues/2015", "id": 635755719, "node_id": "MDU6SXNzdWU2MzU3NTU3MTk=", "number": 2015, "title": "Hit Gloo exception when we scale up to 50+ nodes", "user": {"login": "aaron276h", "id": 5969899, "node_id": "MDQ6VXNlcjU5Njk4OTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5969899?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaron276h", "html_url": "https://github.com/aaron276h", "followers_url": "https://api.github.com/users/aaron276h/followers", "following_url": "https://api.github.com/users/aaron276h/following{/other_user}", "gists_url": "https://api.github.com/users/aaron276h/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaron276h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaron276h/subscriptions", "organizations_url": "https://api.github.com/users/aaron276h/orgs", "repos_url": "https://api.github.com/users/aaron276h/repos", "events_url": "https://api.github.com/users/aaron276h/events{/privacy}", "received_events_url": "https://api.github.com/users/aaron276h/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-09T21:01:53Z", "updated_at": "2020-06-17T16:46:21Z", "closed_at": "2020-06-17T16:46:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Tensorflow \r\n2. Framework version: 1.14 \r\n3. Horovod version: 0.19.3\r\n4. MPI version: N/A\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu 18.04\r\n9. GCC version: 4.8\r\n\r\n**Bug report:**\r\nWhen we scale up to 50+ machines we get the following exception from GLOO when running the same exact code that runs correctly at lower number of machines. \r\n\r\n\r\n```\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:terminate called after throwing an instance of 'gloo::IoException'\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:  what():  [horovod/common/gloo/http_store.cc:53] [horovod/common/gloo/http_store.cc:53] Wait timeout for key(s): 0\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** Received signal 6 ***\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** BEGIN MANGLED STACK TRACE ***\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so.1(+0xfed8db)[0x7f994dcc18db]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libpthread.so.0(+0x12890)[0x7f99e8a40890]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(gsignal+0xc7)[0x7f99e867be97]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(abort+0x141)[0x7f99e867d801]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xbc)[0x7f99e591484a]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(+0xabf47)[0x7f99e5912f47]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(+0xabf7d)[0x7f99e5912f7d]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(__cxa_rethrow+0x0)[0x7f99e591315a]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common9HTTPStore4waitERKSt6vectorISsSaISsEERKNSt6chrono8durationIlSt5ratioILl1ELl1000EEEE+0x8c9)[0x7f9914455f39]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0xf8ee6)[0x7f99144bfee6]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common10RendezvousERKSsPKciiiRSt10shared_ptrIN4gloo9transport6DeviceEENSt6chrono8durationIlSt5ratioILl1ELl1000EEEE+0x3ed)[0x7f991444f08d]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common11GlooContext10InitializeERKSs+0x3f1)[0x7f991444fa31]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x54cb3)[0x7f991441bcb3]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/opt/conda/bin/../lib/libstdc++.so.6(+0xc8421)[0x7f99e592f421]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libpthread.so.0(+0x76db)[0x7f99e8a356db]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(clone+0x3f)[0x7f99e875e88f]\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** END MANGLED STACK TRACE ***\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** Begin stack trace ***\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\ttensorflow::CurrentStackTrace()\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\tgsignal\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\tabort\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t__gnu_cxx::__verbose_terminate_handler()\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t__cxa_rethrow\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\thorovod::common::HTTPStore::wait(std::vector<std::string, std::allocator<std::string> > const&, std::chrono::duration<long, std::ratio<1l, 1000l> > const&)\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\thorovod::common::Rendezvous(std::string const&, char const*, int, int, int, std::shared_ptr<gloo::transport::Device>&, std::chrono::duration<long, std::ratio<1l, 1000l> >)\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\thorovod::common::GlooContext::Initialize(std::string const&)\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\t\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:\tclone\r\n[2020-06-09T20:10:40Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:40 2020[1]<stderr>:*** End stack trace ***\r\n[2020-06-09T20:10:41Z] cf108822 [RUNNING] ||  Tue Jun  9 20:10:41 2020[1]<stderr>:Aborted (core dumped)\r\n[2020-06-09T20:10:41Z] cf108822 [RUNNING] ||  Process 1 exit with status code 134.\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2013", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2013/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2013/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2013/events", "html_url": "https://github.com/horovod/horovod/issues/2013", "id": 635187043, "node_id": "MDU6SXNzdWU2MzUxODcwNDM=", "number": 2013, "title": "How should I use Horovod if I change the compression strategy during training\uff1f", "user": {"login": "KevvinHoo", "id": 23524621, "node_id": "MDQ6VXNlcjIzNTI0NjIx", "avatar_url": "https://avatars3.githubusercontent.com/u/23524621?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KevvinHoo", "html_url": "https://github.com/KevvinHoo", "followers_url": "https://api.github.com/users/KevvinHoo/followers", "following_url": "https://api.github.com/users/KevvinHoo/following{/other_user}", "gists_url": "https://api.github.com/users/KevvinHoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/KevvinHoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KevvinHoo/subscriptions", "organizations_url": "https://api.github.com/users/KevvinHoo/orgs", "repos_url": "https://api.github.com/users/KevvinHoo/repos", "events_url": "https://api.github.com/users/KevvinHoo/events{/privacy}", "received_events_url": "https://api.github.com/users/KevvinHoo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 728479138, "node_id": "MDU6TGFiZWw3Mjg0NzkxMzg=", "url": "https://api.github.com/repos/horovod/horovod/labels/contribution%20welcome", "name": "contribution welcome", "color": "138e05", "default": false, "description": null}, {"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-09T07:37:55Z", "updated_at": "2020-06-15T02:00:17Z", "closed_at": "2020-06-15T02:00:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.5\r\n3. Horovod version: 0.18.2\r\n4. MPI version:mvapich2/2.3.2\r\n5. CUDA version: 10.0.130\r\n6. NCCL version:2.4.6\r\n7. Python version: 3.6\r\n8. OS and version: Linux 3.10.0\r\n9. GCC version: 4.8.5\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nHow should I use Horovod if I change the compression strategy during training?\r\nI will change the compression during the training process. In this case, how should I use Horovod\uff1f The pseudo-code is shown below\uff1a\r\n```\r\ncompression = hvd.Compression.fp16\r\n\r\noptimizer = hvd.DistributedOptimizer(optimizer,\r\n                                         named_parameters=model.named_parameters(),\r\n                                         compression=compression,\r\n                                         op=hvd.Adasum if args.use_adasum else hvd.Average)\r\n\r\nfor epoch in range(0,100):\r\n      if epoch > 50:\r\n             compression = hvd.Compression.none\r\n             How to apply that compression above to the DistributedOptimizer?\r\n\r\n      train()\r\n      test()\r\n\r\n      .....\r\n\r\n```\r\n\r\nAnyone could help me to solve this problem? Appreciate for your help!!!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2011", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2011/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2011/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2011/events", "html_url": "https://github.com/horovod/horovod/issues/2011", "id": 631222604, "node_id": "MDU6SXNzdWU2MzEyMjI2MDQ=", "number": 2011, "title": "Consistent way to check if horovod is shutdown ?", "user": {"login": "vfdev-5", "id": 2459423, "node_id": "MDQ6VXNlcjI0NTk0MjM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2459423?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vfdev-5", "html_url": "https://github.com/vfdev-5", "followers_url": "https://api.github.com/users/vfdev-5/followers", "following_url": "https://api.github.com/users/vfdev-5/following{/other_user}", "gists_url": "https://api.github.com/users/vfdev-5/gists{/gist_id}", "starred_url": "https://api.github.com/users/vfdev-5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vfdev-5/subscriptions", "organizations_url": "https://api.github.com/users/vfdev-5/orgs", "repos_url": "https://api.github.com/users/vfdev-5/repos", "events_url": "https://api.github.com/users/vfdev-5/events{/privacy}", "received_events_url": "https://api.github.com/users/vfdev-5/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 728479138, "node_id": "MDU6TGFiZWw3Mjg0NzkxMzg=", "url": "https://api.github.com/repos/horovod/horovod/labels/contribution%20welcome", "name": "contribution welcome", "color": "138e05", "default": false, "description": null}, {"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-05T00:11:15Z", "updated_at": "2020-07-03T22:37:39Z", "closed_at": "2020-07-03T22:37:39Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.4\r\n3. Horovod version: '0.19.3'\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\n\r\nIs there a consistent way to check if horovod is shutdown ?\r\nFor example,\r\n```python\r\nimport horovod.torch as hvd\r\n# hvd.rank() => raises ValueError: Horovod has not been initialized; use hvd.init().\r\nhvd.init()\r\nhvd.rank()  # for example gives 0\r\nhvd.shutdown()\r\nhvd.rank()  # still gives 0, however horovod is shutdown and I would expect the same behaviour as before init()\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2006", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2006/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2006/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2006/events", "html_url": "https://github.com/horovod/horovod/issues/2006", "id": 629769406, "node_id": "MDU6SXNzdWU2Mjk3Njk0MDY=", "number": 2006, "title": "Getting different results from using mpirun & horovodrun", "user": {"login": "jasonliu747", "id": 24452340, "node_id": "MDQ6VXNlcjI0NDUyMzQw", "avatar_url": "https://avatars2.githubusercontent.com/u/24452340?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasonliu747", "html_url": "https://github.com/jasonliu747", "followers_url": "https://api.github.com/users/jasonliu747/followers", "following_url": "https://api.github.com/users/jasonliu747/following{/other_user}", "gists_url": "https://api.github.com/users/jasonliu747/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasonliu747/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasonliu747/subscriptions", "organizations_url": "https://api.github.com/users/jasonliu747/orgs", "repos_url": "https://api.github.com/users/jasonliu747/repos", "events_url": "https://api.github.com/users/jasonliu747/events{/privacy}", "received_events_url": "https://api.github.com/users/jasonliu747/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-03T07:40:30Z", "updated_at": "2020-06-16T02:37:59Z", "closed_at": "2020-06-16T02:37:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.5.0\r\n3. Horovod version: 1.9.4\r\n4. MPI version: 4.0.0\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7-1+cuda10.0\r\n7. Python version: 3.6\r\n8. OS and version: 18.04.1-Ubuntu\r\n9. GCC version: 7.5.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nWhen using mpirun, everything is alright. But when I wanna try the --autotune function, I changed my command to horovodrun, it simply didn't work anymore. Here are my commands, please do help me take a look.\r\n\r\n`mpirun --allow-run-as-root -np 32 \r\n       -mca pml ob1 \r\n       -mca btl ^openib \r\n       -bind-to none \r\n       -map-by slot \r\n       -x NCCL_IB_DISABLE=1 \r\n       -x NCCL_SOCKET_IFNAME=eth0 \r\n       -x LD_LIBRARY_PATH \r\n       ./run_dcv_20200603152206.sh`\r\n\r\n`horovodrun -np 32\r\n       --mpi-args=\"--allow-run-as-root -x NCCL_IB_DISABLE=1 -x NCCL_SOCKET_IFNAME=eth0 -x LD_LIBRARY_PATH\"\r\n       --binding-args=\"-bind-to none -map-by slot\"\r\n       ./run_dcv_20200603152206.sh`\r\n\r\nThe only difference I can tell from logs is when using mpirun, it will call `kubectl exec` at the beginning. But when using horovodrun, it would go straight to `make -C dcv clean`.\r\n![image](https://user-images.githubusercontent.com/24452340/83609183-7ab91b00-a5b0-11ea-9dd2-903b6ef6b86c.png)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2002", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2002/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2002/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2002/events", "html_url": "https://github.com/horovod/horovod/issues/2002", "id": 628327835, "node_id": "MDU6SXNzdWU2MjgzMjc4MzU=", "number": 2002, "title": "Horovod 19.2 cannot run mpirun --version", "user": {"login": "matthewc-gr", "id": 65709533, "node_id": "MDQ6VXNlcjY1NzA5NTMz", "avatar_url": "https://avatars1.githubusercontent.com/u/65709533?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthewc-gr", "html_url": "https://github.com/matthewc-gr", "followers_url": "https://api.github.com/users/matthewc-gr/followers", "following_url": "https://api.github.com/users/matthewc-gr/following{/other_user}", "gists_url": "https://api.github.com/users/matthewc-gr/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthewc-gr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthewc-gr/subscriptions", "organizations_url": "https://api.github.com/users/matthewc-gr/orgs", "repos_url": "https://api.github.com/users/matthewc-gr/repos", "events_url": "https://api.github.com/users/matthewc-gr/events{/privacy}", "received_events_url": "https://api.github.com/users/matthewc-gr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 730732849, "node_id": "MDU6TGFiZWw3MzA3MzI4NDk=", "url": "https://api.github.com/repos/horovod/horovod/labels/update%20docs", "name": "update docs", "color": "78ed92", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 15, "created_at": "2020-06-01T10:27:57Z", "updated_at": "2020-06-04T20:34:45Z", "closed_at": "2020-06-04T20:34:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "We've just upgraded our horovod version from 0.19.1 to 0.19.2 and we get the below runtime exception while training using Tensorflow 2.2.0. (We also see this in 0.19.4)\r\n\r\nWe are using spark to schedule horovod jobs using horovod.spark.run and the exception bubbles up from spark. \r\n\r\nDependencies:\r\n```\r\nhorovod==0.19.2\r\ntensorflow==2.2.0 \r\n```\r\n\r\nException:\r\n```\r\nWas unable to run mpirun --version:\r\nTraceback (most recent call last):\r\n  File \"/tmp/spark-b145d01d-da23-4170-89f3-430afe3d3eca/sample_train_tfrecord.py\", line 173, in <module>\r\n    trainer.train(train_fn)\r\n  File \"/home/matthewc/ml_working_dir/devlibs/mariana/mariana/mariana_trainer.py\", line 253, in train\r\n    env=env, )\r\n  File \"/home/matthewc/horovod-env/venv/lib/python3.6/site-packages/horovod/spark/runner.py\", line 221, in run\r\n    _launch_job(use_mpi, use_gloo, settings, driver, env, stdout, stderr)\r\n  File \"/home/matthewc/horovod-env/venv/lib/python3.6/site-packages/horovod/spark/runner.py\", line 128, in _launch_job\r\n    settings.verbose)\r\n  File \"/home/matthewc/horovod-env/venv/lib/python3.6/site-packages/horovod/run/runner.py\", line 692, in run_controller\r\n    mpi_run()\r\n  File \"/home/matthewc/horovod-env/venv/lib/python3.6/site-packages/horovod/spark/runner.py\", line 126, in <lambda>\r\n    use_mpi, lambda: mpi_run(settings, nics, driver, env, stdout, stderr),\r\n  File \"/home/matthewc/horovod-env/venv/lib/python3.6/site-packages/horovod/spark/mpi_run.py\", line 53, in mpi_run\r\n    hr_mpi_run(settings, nics, env, command, stdout=stdout, stderr=stderr)\r\n  File \"/home/matthewc/horovod-env/venv/lib/python3.6/site-packages/horovod/run/mpi_run.py\", line 143, in mpi_run\r\n    raise Exception(_MPI_NOT_FOUND_ERROR_MSG)\r\nException: horovod does not find an installed MPI.\r\nChoose one of:\r\n1. Install Open MPI 4.0.0+ or IBM Spectrum MPI or MPICH and re-install Horovod (use --no-cache-dir pip option).\r\n2. Run distributed training script using the standard way provided by your MPI distribution (usually mpirun, srun, or jsrun).\r\n3. Use built-in gloo option (horovodrun --gloo ...).\r\n```\r\n\r\nmpirun is on the path and I can call mpirun --version fine on the edge node. \r\n```\r\n mpirun --version\r\nmpirun (Open MPI) 4.0.1\r\n\r\nReport bugs to http://www.open-mpi.org/community/help/\r\n```\r\n\r\nIt also looks like the horovod install has mpi as an available controller\r\n\r\n```\r\nhorovodrun --check-build\r\nHorovod v0.19.4:\r\nAvailable Frameworks:\r\n    [X] TensorFlow\r\n    [ ] PyTorch\r\n    [ ] MXNet\r\nAvailable Controllers:\r\n    [X] MPI\r\n    [X] Gloo\r\nAvailable Tensor Operations:\r\n    [ ] NCCL\r\n    [ ] DDL\r\n    [ ] CCL\r\n    [X] MPI\r\n    [X] Gloo\r\n```\r\n\r\n\r\nAny ideas to what is going on here?\r\n\r\nThanks,\r\n\r\nMatt", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2001", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2001/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2001/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2001/events", "html_url": "https://github.com/horovod/horovod/issues/2001", "id": 628165141, "node_id": "MDU6SXNzdWU2MjgxNjUxNDE=", "number": 2001, "title": "Exception: `apply_gradients()` was called without a call to `get_gradients()` or `_aggregate_gradients`. If you're using TensorFlow 2.0, please specify `experimental_run_tf_function=False` in `compile()`.", "user": {"login": "javacom", "id": 417020, "node_id": "MDQ6VXNlcjQxNzAyMA==", "avatar_url": "https://avatars0.githubusercontent.com/u/417020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/javacom", "html_url": "https://github.com/javacom", "followers_url": "https://api.github.com/users/javacom/followers", "following_url": "https://api.github.com/users/javacom/following{/other_user}", "gists_url": "https://api.github.com/users/javacom/gists{/gist_id}", "starred_url": "https://api.github.com/users/javacom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/javacom/subscriptions", "organizations_url": "https://api.github.com/users/javacom/orgs", "repos_url": "https://api.github.com/users/javacom/repos", "events_url": "https://api.github.com/users/javacom/events{/privacy}", "received_events_url": "https://api.github.com/users/javacom/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-01T05:33:32Z", "updated_at": "2020-06-02T04:32:44Z", "closed_at": "2020-06-02T04:32:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) tensoflow\r\n2. Framework version: tensorflow 2.1\r\n3. Horovod version: 0.19.3\r\n4. MPI version: 3.1.3\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: Python 3.7.3\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? not  about hang\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? not docker\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? yes\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nI try to convert a sklearn logistic regression sample to run on horovod, but there is no sample for this type of conversion and I follow the guideline to add horovod code as below.\r\n\r\nMy question is how to apply experimental_run_tf_function=False in compile() for this code ?\r\n\r\n```\r\nfrom tensorflow.keras.datasets import fashion_mnist\r\nfrom sklearn.model_selection import train_test_split\r\nimport tensorflow as tf\r\nimport horovod.tensorflow as hvd\r\n\r\n# Horovod: initialize Horovod.\r\nhvd.init()\r\n\r\n# Horovod: pin GPU to be used to process local rank (one GPU per process)\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\nif gpus:\r\n    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\r\n\r\n\r\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\r\nx_train, x_test = x_train/255., x_test/255.\r\n\r\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15)\r\nx_train = tf.reshape(x_train, shape=(-1, 784))\r\nx_test  = tf.reshape(x_test, shape=(-1, 784))\r\n\r\nweights = tf.Variable(tf.random.normal(shape=(784, 10), dtype=tf.float64))\r\nbiases  = tf.Variable(tf.random.normal(shape=(10,), dtype=tf.float64))\r\n\r\ndef logistic_regression(x):\r\n    lr = tf.add(tf.matmul(x, weights), biases)\r\n    #return tf.nn.sigmoid(lr)\r\n    return lr\r\n\r\n\r\ndef cross_entropy(y_true, y_pred):\r\n    y_true = tf.one_hot(y_true, 10)\r\n    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\r\n    return tf.reduce_mean(loss)\r\n\r\ndef accuracy(y_true, y_pred):\r\n    y_true = tf.cast(y_true, dtype=tf.int32)\r\n    preds = tf.cast(tf.argmax(y_pred, axis=1), dtype=tf.int32)\r\n    preds = tf.equal(y_true, preds)\r\n    return tf.reduce_mean(tf.cast(preds, dtype=tf.float32))\r\n\r\ndef grad(x, y):\r\n    with tf.GradientTape() as tape:\r\n        y_pred = logistic_regression(x)\r\n        loss_val = cross_entropy(y, y_pred)\r\n\r\n\r\nn_batches = 10000\r\nlearning_rate = 0.01\r\nbatch_size = 128\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\ndataset = dataset.repeat().shuffle(x_train.shape[0]).batch(batch_size)\r\n\r\noptimizer = tf.optimizers.SGD(learning_rate)\r\n\r\n# Horovod: adjust learning rate based on number of GPUs.\r\nscaled_lr = 0.001 * hvd.size()\r\nopt = tf.optimizers.Adam(scaled_lr)\r\n\r\n# Horovod: add Horovod DistributedOptimizer.\r\nopt = hvd.DistributedOptimizer(opt)\r\n\r\n@tf.function\r\ndef training_step(batch_xs, batch_ys, first_batch):\r\n    with tf.GradientTape() as tape:\r\n        y_pred = logistic_regression(batch_xs)\r\n        loss_val = cross_entropy(batch_ys, y_pred)\r\n        acc = accuracy(batch_ys, y_pred)\r\n        \r\n    # Horovod: add Horovod Distributed GradientTape.\r\n    tape = hvd.DistributedGradientTape(tape)\r\n    grads = tape.gradient(loss_val, [weights, biases])\r\n    opt.apply_gradients(zip(grads, [weights, biases]), experimental_run_tf_function=False)\r\n# << - error here\r\n# << - error here and how to add experimental_run_tf_function=False ??\r\n\r\n    # Horovod: broadcast initial variable states from rank 0 to all other processes.\r\n    # This is necessary to ensure consistent initialization of all workers when\r\n    # training is started with random weights or restored from a checkpoint.\r\n    #\r\n    # Note: broadcast should be done after the first gradient step to ensure optimizer\r\n    # initialization.\r\n    if first_batch:\r\n        hvd.broadcast_variables([weights, biases], root_rank=0)\r\n        hvd.broadcast_variables(opt.variables(), root_rank=0)\r\n\r\n    return loss_val\r\n\r\nfor batch, (batch_xs, batch_ys) in enumerate(dataset.take(n_batches), 1):\r\n    loss_value = training_step(batch_xs, batch_ys, batch == 0)\r\n\r\n    if batch % 10 == 0 and hvd.local_rank() == 0:\r\n        print('Step #%d\\tLoss: %.6f' % (batch, loss_value))\r\n\r\n\r\n\r\n\r\n\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/2000", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/2000/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/2000/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/2000/events", "html_url": "https://github.com/horovod/horovod/issues/2000", "id": 627523991, "node_id": "MDU6SXNzdWU2Mjc1MjM5OTE=", "number": 2000, "title": "pyarrow 0.17 changed hdfs.connect api to remove driver parameter", "user": {"login": "tgravescs", "id": 4563792, "node_id": "MDQ6VXNlcjQ1NjM3OTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/4563792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgravescs", "html_url": "https://github.com/tgravescs", "followers_url": "https://api.github.com/users/tgravescs/followers", "following_url": "https://api.github.com/users/tgravescs/following{/other_user}", "gists_url": "https://api.github.com/users/tgravescs/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgravescs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgravescs/subscriptions", "organizations_url": "https://api.github.com/users/tgravescs/orgs", "repos_url": "https://api.github.com/users/tgravescs/repos", "events_url": "https://api.github.com/users/tgravescs/events{/privacy}", "received_events_url": "https://api.github.com/users/tgravescs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2020-05-29T20:35:30Z", "updated_at": "2020-06-02T17:21:09Z", "closed_at": "2020-06-02T17:21:09Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Keras Estimator example\r\n2. Framework version:\r\n3. Horovod version:  master branch\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nTrying to run with the latest horovod code with pyarrow 0.17.1 against HDFS for the working directory and it fails with:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"keras_spark_rossmann_estimator.py\", line 408, in <module>\r\n    store = Store.create(args.work_dir)\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 141, in create\r\n    return HDFSStore(prefix_path, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 337, in __init__\r\n    self._hdfs = self._get_filesystem_fn()()\r\n  File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 416, in fn\r\n    return pa.hdfs.connect(**hdfs_kwargs)\r\nTypeError: connect() got an unexpected keyword argument 'driver'\r\n```\r\n\r\nIt looks like pyarrow removed that parameter with commit:\r\nhttps://github.com/apache/arrow/commit/4e53749097ba687afd5e000067925def2e2802c9#diff-72abd78694ddde2b1a059b194978b77b\r\n\r\nNote I called it like:\r\npython keras_spark_rossmann_estimator.py --num-proc 2 --batch-size 1000 --epochs 2 --master spark://3ee9bf36f06b:7077 --work-dir hdfs:///rossmann\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1998", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1998/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1998/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1998/events", "html_url": "https://github.com/horovod/horovod/issues/1998", "id": 627085309, "node_id": "MDU6SXNzdWU2MjcwODUzMDk=", "number": 1998, "title": "How to split my tensor when doing Allreduce?", "user": {"login": "ExcellentHunter", "id": 37994949, "node_id": "MDQ6VXNlcjM3OTk0OTQ5", "avatar_url": "https://avatars0.githubusercontent.com/u/37994949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ExcellentHunter", "html_url": "https://github.com/ExcellentHunter", "followers_url": "https://api.github.com/users/ExcellentHunter/followers", "following_url": "https://api.github.com/users/ExcellentHunter/following{/other_user}", "gists_url": "https://api.github.com/users/ExcellentHunter/gists{/gist_id}", "starred_url": "https://api.github.com/users/ExcellentHunter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ExcellentHunter/subscriptions", "organizations_url": "https://api.github.com/users/ExcellentHunter/orgs", "repos_url": "https://api.github.com/users/ExcellentHunter/repos", "events_url": "https://api.github.com/users/ExcellentHunter/events{/privacy}", "received_events_url": "https://api.github.com/users/ExcellentHunter/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-29T08:11:36Z", "updated_at": "2020-06-08T11:28:10Z", "closed_at": "2020-06-08T11:28:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: TensorFlow-1.10\r\n3. Horovod version: Horovod-r0.17.1\r\n4. Python version: Python2.7\r\n\r\n**My question:**\r\nHello~ This is the timeline of my work,I set HOROVOD_NUM_NCCL_STREAMS=4.However,there is a big tensor need to do ALLREDUCE in _pid = 569_.It took too much time. Although other _pid_ has already done ALLREDUCE, they should wait for _pid = 569_.So i want to ask if Horovod could check the size of each tensor and split the big tensor into multiple small tensors automatically when doing ALLREDUCE.\r\n![image](https://user-images.githubusercontent.com/37994949/83236004-639bb700-a1c5-11ea-8491-f0f80918efe5.png)\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1997", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1997/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1997/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1997/events", "html_url": "https://github.com/horovod/horovod/issues/1997", "id": 626984059, "node_id": "MDU6SXNzdWU2MjY5ODQwNTk=", "number": 1997, "title": "Timeline show NEGOTIATE_BROADCAST Did Not Finish", "user": {"login": "jmsking", "id": 4349983, "node_id": "MDQ6VXNlcjQzNDk5ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4349983?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jmsking", "html_url": "https://github.com/jmsking", "followers_url": "https://api.github.com/users/jmsking/followers", "following_url": "https://api.github.com/users/jmsking/following{/other_user}", "gists_url": "https://api.github.com/users/jmsking/gists{/gist_id}", "starred_url": "https://api.github.com/users/jmsking/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jmsking/subscriptions", "organizations_url": "https://api.github.com/users/jmsking/orgs", "repos_url": "https://api.github.com/users/jmsking/repos", "events_url": "https://api.github.com/users/jmsking/events{/privacy}", "received_events_url": "https://api.github.com/users/jmsking/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-29T04:12:50Z", "updated_at": "2020-05-29T11:22:51Z", "closed_at": "2020-05-29T11:22:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Pytorch\r\n2. Framework version: 1.4.0+cu100\r\n3. Horovod version: 0.19.2\r\n4. MPI version: \r\n5. CUDA version: cu100\r\n6. NCCL version:\r\n7. Python version: 3.6\r\n8. OS and version: ubuntu 18\r\n9. GCC version: 7\r\n\r\n**Bug report:**\r\nI train a simple CNN model with MNIST data in k8s cluster. and my k8s info as follows:\r\ntotal nodes: 3, 2 for GPU node and 1 for CPU node\r\nand GPU nodes each have 8 gpu.\r\nwhen i create a mpijob, run command like:\r\n```mpirun -np 16 --allow-run-as-root -bind-to none -map-by slot -x LD_LIBRARY_PATH -x PATH -mca pml ob1 -mca btl ^openib -x HOROVOD_TIMELINE=/mnt/timeline.json python /mnt/horovod_pytorch.py```\r\nand i open the generated timeline.json with chrome://tracing, the picture is:\r\n![image](https://user-images.githubusercontent.com/4349983/83220133-cfb9f300-a1a4-11ea-8c58-466af6c44547.png)\r\nand i execute ```nvidia-smi`` in each GPU node, i found there only 13 processes running, and i don't know where are the other 3 processes?\r\nAnd i also found because the process will download the MNIST data from network, and i print the log, there are only 13 processes have download MNIST success\u3002\r\nAnd the container logs as follows:\r\n![image](https://user-images.githubusercontent.com/4349983/83220471-a2217980-a1a5-11ea-891c-00b0c48b3998.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1981", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1981/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1981/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1981/events", "html_url": "https://github.com/horovod/horovod/issues/1981", "id": 624725869, "node_id": "MDU6SXNzdWU2MjQ3MjU4Njk=", "number": 1981, "title": "How to set \"batch size\"", "user": {"login": "lovejing0306", "id": 14770340, "node_id": "MDQ6VXNlcjE0NzcwMzQw", "avatar_url": "https://avatars2.githubusercontent.com/u/14770340?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lovejing0306", "html_url": "https://github.com/lovejing0306", "followers_url": "https://api.github.com/users/lovejing0306/followers", "following_url": "https://api.github.com/users/lovejing0306/following{/other_user}", "gists_url": "https://api.github.com/users/lovejing0306/gists{/gist_id}", "starred_url": "https://api.github.com/users/lovejing0306/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lovejing0306/subscriptions", "organizations_url": "https://api.github.com/users/lovejing0306/orgs", "repos_url": "https://api.github.com/users/lovejing0306/repos", "events_url": "https://api.github.com/users/lovejing0306/events{/privacy}", "received_events_url": "https://api.github.com/users/lovejing0306/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-26T09:09:18Z", "updated_at": "2020-05-27T02:31:12Z", "closed_at": "2020-05-27T02:31:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: TensorFlow2.2\r\n3. Horovod version: v0.19.2\r\n\r\n**Your question:**\r\nIn horovod, the \"batch size\" is for single gpu or multi gpu. \r\nthanks. \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1978", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1978/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1978/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1978/events", "html_url": "https://github.com/horovod/horovod/issues/1978", "id": 623599994, "node_id": "MDU6SXNzdWU2MjM1OTk5OTQ=", "number": 1978, "title": "[common_runtime/scoped_allocator_mgr.cc:81] Failed to find instance 32581 in container 6 on /job:localhost/replica:0/task:0/device:CPU:0", "user": {"login": "sunnyWangGirl", "id": 38651094, "node_id": "MDQ6VXNlcjM4NjUxMDk0", "avatar_url": "https://avatars3.githubusercontent.com/u/38651094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sunnyWangGirl", "html_url": "https://github.com/sunnyWangGirl", "followers_url": "https://api.github.com/users/sunnyWangGirl/followers", "following_url": "https://api.github.com/users/sunnyWangGirl/following{/other_user}", "gists_url": "https://api.github.com/users/sunnyWangGirl/gists{/gist_id}", "starred_url": "https://api.github.com/users/sunnyWangGirl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sunnyWangGirl/subscriptions", "organizations_url": "https://api.github.com/users/sunnyWangGirl/orgs", "repos_url": "https://api.github.com/users/sunnyWangGirl/repos", "events_url": "https://api.github.com/users/sunnyWangGirl/events{/privacy}", "received_events_url": "https://api.github.com/users/sunnyWangGirl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-23T07:18:36Z", "updated_at": "2020-05-27T10:12:19Z", "closed_at": "2020-05-27T10:12:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\nTensorflow-cpu 1.8.0\r\n2. Framework version:\r\n1.8.0\r\n3. Horovod version:\r\n0.19.2\r\n4. MPI version:\r\nopenmpi3.1.2\r\n5. CUDA version:\r\nnone\r\n6. NCCL version:\r\nnone\r\n7. Python version:\r\nnone\r\n8. OS and version:\r\nubuntu14.04  and ubuntu16.04\r\n9. GCC version:\r\n4.9.4\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? \r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? yes\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nHello,everyone.I want to run horovod in two servers without gpu(only cpu).I install horovod in physical machine not in Docker.I Just run command as follows.\r\nserver1:ubuntu14.04,its name:PowerEdge-R630,tensorflow1.8.0 in anaconda3,horovod0.19.2\r\nserver2:ubuntu16.04,its name: PowerEdge-R220,tensorflow1.8.0 in anaconda3,horovod0.19.2\r\n\r\n` mpirun -np 2     -H server1:1,server2:1     -bind-to none -map-by slot     -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH     -mca pml ob1 -mca btl ^openib     -mca btl_tcp_if_include 10.108.63.77/22     /home/ipoc345/anaconda3/envs/figtensorflow/bin/python ~/myshare/untitled/horovod_demo.py`\r\n\r\nbut error occurs.\r\n\r\n>  INFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2020-05-23 02:45:02.835756: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nINFO:tensorflow:Restoring parameters from ./checkpoints/model.ckpt-1\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Graph was finalized.\r\n2020-05-23 14:44:52.471384: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\n2020-05-23 14:44:56.654525: F tensorflow/core/common_runtime/scoped_allocator_mgr.cc:81] Failed to find instance 32581 in container 6 on /job:localhost/replica:0/task:0/device:CPU:0\r\n[ipoc345-PowerEdge-R630:77232] *** Process received signal ***\r\n[ipoc345-PowerEdge-R630:77232] Signal: Aborted (6)\r\n[ipoc345-PowerEdge-R630:77232] Signal code:  (-6)\r\n[ipoc345-PowerEdge-R630:77232] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x10340)[0x7f456ab3b340]\r\n[ipoc345-PowerEdge-R630:77232] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x39)[0x7f4569e86f79]\r\n[ipoc345-PowerEdge-R630:77232] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x148)[0x7f4569e8a388]\r\n[ipoc345-PowerEdge-R630:77232] [ 3] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x3be2954)[0x7f45558ef954]\r\n[ipoc345-PowerEdge-R630:77232] [ 4] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x910018)[0x7f4551940018]\r\n[ipoc345-PowerEdge-R630:77232] [ 5] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow16ThreadPoolDevice18GetScopedAllocatorENS_19AllocatorAttributesEx+0x32)[0x7f45519492f2]\r\n[ipoc345-PowerEdge-R630:77232] [ 6] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow15OpKernelContext13get_allocatorENS_19AllocatorAttributesE+0x37)[0x7f4551459b37]\r\n[ipoc345-PowerEdge-R630:77232] [ 7] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow15OpKernelContext15allocate_tensorENS_8DataTypeERKNS_11TensorShapeEPNS_6TensorENS_19AllocatorAttributesERKNS_20AllocationAttributesE+0x48)[0x7f4551459fd8]\r\n[ipoc345-PowerEdge-R630:77232] [ 8] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow15OpKernelContext19allocate_persistentENS_8DataTypeERKNS_11TensorShapeEPNS_16PersistentTensorEPPNS_6TensorENS_19AllocatorAttributesE+0x80)[0x7f455145a630]\r\n[ipoc345-PowerEdge-R630:77232] [ 9] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/horovod/tensorflow/mpi_lib.cpython-35m-x86_64-linux-gnu.so(+0x8cf57)[0x7f4549c02f57]\r\n[ipoc345-PowerEdge-R630:77232] [10] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/horovod/tensorflow/mpi_lib.cpython-35m-x86_64-linux-gnu.so(_ZN7horovod6common19FusionBufferManager16InitializeBufferEliSt10shared_ptrINS0_9OpContextEEiSt8functionIFvvEES7_+0x10c)[0x7f4549ba958c]\r\n[ipoc345-PowerEdge-R630:77232] [11] /home/ipoc345/anaconda3/envs/figtensorflow/lib/python3.5/site-packages/horovod/tensorflow/mpi_lib.cpython-35m-x86_64-linux-gnu.so(+0x4411c)[0x7f4549bba11c]\r\n[ipoc345-PowerEdge-R630:77232] [12] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x9de9e)[0x7f4550d83e9e]\r\n[ipoc345-PowerEdge-R630:77232] [13] /lib/x86_64-linux-gnu/libpthread.so.0(+0x8182)[0x7f456ab33182]\r\n[ipoc345-PowerEdge-R630:77232] [14] /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f4569f4b30d]\r\n[ipoc345-PowerEdge-R630:77232] *** End of error message ***\r\nAn MPI communication peer process has unexpectedly disconnected.  This\r\nusually indicates a failure in the peer process (e.g., a crash or\r\notherwise exiting without calling MPI_FINALIZE first).\r\nAlthough this local MPI process will likely now behave unpredictably\r\n(it may even hang or crash), the root cause of this problem is the\r\nfailure of the peer -- that is what you need to investigate.  For\r\nexample, there may be a core file that you can examine.  More\r\ngenerally: such peer hangups are frequently caused by application bugs\r\nor other external events.\r\n      Local host: PowerEdge-R220\r\n      Local PID:  31080\r\n      Peer host:  (null)\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\nmpirun noticed that process rank 1 with PID 77232 on node server1 exited on signal 6 (Aborted).\r\n\r\n\r\nI found this error is \r\n`2020-05-23 14:44:56.654525: F tensorflow/core/common_runtime/scoped_allocator_mgr.cc:81] Failed to find instance 32581 in container 6 on /job:localhost/replica:0/task:0/device:CPU:0`\r\nI am new for horovod.I have no idea how to solve this problem.I just wanna run horovod in two servers in only-cpu.PPPlease help me.\r\n\r\nthe code I run is listed below\r\n[https://github.com/horovod/horovod/blob/master/examples/tensorflow_mnist.py](url),but remove\r\n`config.gpu_options.allow_growth = True\r\n  config.gpu_options.visible_device_list = str(hvd.local_rank())`\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1973", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1973/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1973/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1973/events", "html_url": "https://github.com/horovod/horovod/issues/1973", "id": 622475335, "node_id": "MDU6SXNzdWU2MjI0NzUzMzU=", "number": 1973, "title": "Comparison with pytorch self distributed training", "user": {"login": "songtaoshi", "id": 20240391, "node_id": "MDQ6VXNlcjIwMjQwMzkx", "avatar_url": "https://avatars3.githubusercontent.com/u/20240391?v=4", "gravatar_id": "", "url": "https://api.github.com/users/songtaoshi", "html_url": "https://github.com/songtaoshi", "followers_url": "https://api.github.com/users/songtaoshi/followers", "following_url": "https://api.github.com/users/songtaoshi/following{/other_user}", "gists_url": "https://api.github.com/users/songtaoshi/gists{/gist_id}", "starred_url": "https://api.github.com/users/songtaoshi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/songtaoshi/subscriptions", "organizations_url": "https://api.github.com/users/songtaoshi/orgs", "repos_url": "https://api.github.com/users/songtaoshi/repos", "events_url": "https://api.github.com/users/songtaoshi/events{/privacy}", "received_events_url": "https://api.github.com/users/songtaoshi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-21T12:45:36Z", "updated_at": "2020-05-30T08:20:50Z", "closed_at": "2020-05-30T08:20:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I am a little confused about the benchmark comparison with pytorch self distributed training.  \r\nBecause recently I am surveying the best practice for distributed training and I see horovod, but I do not know what the superior in effect and speed with pytorch self distributed training. And I know your horovod is very concise for using. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1969", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1969/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1969/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1969/events", "html_url": "https://github.com/horovod/horovod/issues/1969", "id": 622017625, "node_id": "MDU6SXNzdWU2MjIwMTc2MjU=", "number": 1969, "title": "When network interface isn't specified, task processes fail to connect to driver.", "user": {"login": "aaron276h", "id": 5969899, "node_id": "MDQ6VXNlcjU5Njk4OTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5969899?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaron276h", "html_url": "https://github.com/aaron276h", "followers_url": "https://api.github.com/users/aaron276h/followers", "following_url": "https://api.github.com/users/aaron276h/following{/other_user}", "gists_url": "https://api.github.com/users/aaron276h/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaron276h/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaron276h/subscriptions", "organizations_url": "https://api.github.com/users/aaron276h/orgs", "repos_url": "https://api.github.com/users/aaron276h/repos", "events_url": "https://api.github.com/users/aaron276h/events{/privacy}", "received_events_url": "https://api.github.com/users/aaron276h/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, {"login": "EnricoMi", "id": 44700269, "node_id": "MDQ6VXNlcjQ0NzAwMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/44700269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EnricoMi", "html_url": "https://github.com/EnricoMi", "followers_url": "https://api.github.com/users/EnricoMi/followers", "following_url": "https://api.github.com/users/EnricoMi/following{/other_user}", "gists_url": "https://api.github.com/users/EnricoMi/gists{/gist_id}", "starred_url": "https://api.github.com/users/EnricoMi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EnricoMi/subscriptions", "organizations_url": "https://api.github.com/users/EnricoMi/orgs", "repos_url": "https://api.github.com/users/EnricoMi/repos", "events_url": "https://api.github.com/users/EnricoMi/events{/privacy}", "received_events_url": "https://api.github.com/users/EnricoMi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2020-05-20T19:05:51Z", "updated_at": "2020-05-22T19:22:20Z", "closed_at": "2020-05-22T12:55:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet): N/A\r\n2. Framework version: N/A\r\n3. Horovod version: 0.19.2\r\n4. MPI version: N/A (Using Gloo Controller)\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.6.10\r\n8. OS and version: Ubuntu 18.04\r\n9. GCC version: 4.8\r\n\r\n\r\n**Bug report:**\r\n\r\nWhen running multi-machine and not specifying a network interface, task processes fail to connect to driver. Note: using a GLOO controller.\r\n\r\nStack trace:\r\n\r\n```\r\nroot@ip-172-31-37-52:/# horovodrun -np 2 -H localhost:1,172.31.35.37:1 -p 12345 --verbose ls\r\nFiltering local host names.\r\nRemote host found: 172.31.35.37\r\nChecking ssh on all remote hosts.\r\nSSH was successful into all the remote hosts.\r\nTesting interfaces on all the hosts.\r\nLaunched horovod server.\r\nAttempted to launch horovod task servers.\r\nWaiting for the hosts to acknowledge.\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('127.0.0.1', 37436)\r\nException happened during processing of request from ('172.31.37.52', 52632)\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 52636)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nTraceback (most recent call last):\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 55358)\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 52642)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\nException happened during processing of request from ('127.0.0.1', 37442)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\nstruct.error: unpack requires a buffer of 4 bytes\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n----------------------------------------\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 55364)\r\n----------------------------------------\r\nException happened during processing of request from ('127.0.0.1', 37448)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n----------------------------------------\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.37.52', 55368)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.35.37', 39790)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.35.37', 39796)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n----------------------------------------\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\nException happened during processing of request from ('172.31.35.37', 39798)\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 654, in process_request_thread\r\n    self.finish_request(request, client_address)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 364, in finish_request\r\n    self.RequestHandlerClass(request, client_address, self)\r\n  File \"/opt/conda/lib/python3.6/socketserver.py\", line 724, in __init__\r\n    self.handle()\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 105, in handle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 79, in read\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nstruct.error: unpack requires a buffer of 4 bytes\r\n----------------------------------------\r\nLaunching horovod task function was not successful:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/task_fn.py\", line 67, in <module>\r\n    _task_fn(index, driver_addresses, settings)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/task_fn.py\", line 27, in _task_fn\r\n    driver_addresses, settings.key, settings.verbose)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/driver/driver_service.py\", line 44, in __init__\r\n    match_intf=match_intf)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/service/driver_service.py\", line 159, in __init__\r\n    match_intf=match_intf)\r\n  File \"/opt/conda/lib/python3.6/site-packages/horovod/run/common/util/network.py\", line 172, in __init__\r\n    'Linux.'.format(service_name=service_name, addresses=addresses))\r\nhorovod.run.common.util.network.NoValidAddressesFound: Horovod was unable to connect to horovod driver service on any of the following addresses: {'lo': [('127.0.0.1', 4548)], 'ens3': [('172.31.37.52', 4548)], 'docker0': [('172.17.0.1', 4548)]}.\r\n\r\nOne possible cause of this problem is that horovod currently requires every host to have at least one routable network interface with the same name across all of the hosts. You can run \"ifconfig -a\" on every host and check for the common routable interface. To fix the problem, you can rename interfaces on Linux.\r\n```\r\n\r\nWhen a network interface is specified, everything works as expected:\r\n```\r\nroot@ip-172-31-37-52:/# horovodrun -np 2 -H localhost:1,172.31.35.37:1 -p 12345 --network-interface ens3 ls\r\nWed May 20 19:01:46 2020[0]<stdout>:bin\r\nWed May 20 19:01:46 2020[0]<stdout>:boot\r\n.....\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1963", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1963/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1963/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1963/events", "html_url": "https://github.com/horovod/horovod/issues/1963", "id": 620579078, "node_id": "MDU6SXNzdWU2MjA1NzkwNzg=", "number": 1963, "title": "[Bug Report] `python setup.py install` is broken", "user": {"login": "DEKHTIARJonathan", "id": 10923599, "node_id": "MDQ6VXNlcjEwOTIzNTk5", "avatar_url": "https://avatars2.githubusercontent.com/u/10923599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DEKHTIARJonathan", "html_url": "https://github.com/DEKHTIARJonathan", "followers_url": "https://api.github.com/users/DEKHTIARJonathan/followers", "following_url": "https://api.github.com/users/DEKHTIARJonathan/following{/other_user}", "gists_url": "https://api.github.com/users/DEKHTIARJonathan/gists{/gist_id}", "starred_url": "https://api.github.com/users/DEKHTIARJonathan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DEKHTIARJonathan/subscriptions", "organizations_url": "https://api.github.com/users/DEKHTIARJonathan/orgs", "repos_url": "https://api.github.com/users/DEKHTIARJonathan/repos", "events_url": "https://api.github.com/users/DEKHTIARJonathan/events{/privacy}", "received_events_url": "https://api.github.com/users/DEKHTIARJonathan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-19T00:04:19Z", "updated_at": "2020-05-29T19:39:55Z", "closed_at": "2020-05-29T19:39:29Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When installing Horovod from source, it seems that one of the \"common routes\" is broken:\r\n\r\n**Building as follows will generate an impressive number of issues at execution:**\r\n```\r\nexport HOROVOD_GPU_ALLREDUCE=NCCL\r\nexport HOROVOD_GPU_BROADCAST=NCCL\r\nexport HOROVOD_NCCL_INCLUDE=/usr/include\r\nexport HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu\r\nexport HOROVOD_NCCL_LINK=SHARED\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\nexport HOROVOD_WITH_MPI=1\r\nexport HOROVOD_BUILD_ARCH_FLAGS=\"-march=sandybridge -mtune=broadwell\"\r\npip uninstall horovod -y\r\npython setup.py clean\r\npython setup.py install\r\npython setup.py clean\r\n```\r\n\r\n**However, building as follows perfectly works:**\r\n```\r\nexport HOROVOD_GPU_ALLREDUCE=NCCL\r\nexport HOROVOD_GPU_BROADCAST=NCCL\r\nexport HOROVOD_NCCL_INCLUDE=/usr/include\r\nexport HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu\r\nexport HOROVOD_NCCL_LINK=SHARED\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\nexport HOROVOD_WITH_MPI=1\r\nexport HOROVOD_BUILD_ARCH_FLAGS=\"-march=sandybridge -mtune=broadwell\"\r\npip uninstall horovod -y\r\nrm -rf dist/*\r\npython setup.py sdist\r\npip install --no-cache --no-cache-dir dist/horovod-*.tar.gz\r\npython setup.py clean\r\n```\r\n\r\n---------------------------\r\n\r\nError Log:\r\n\r\n```\r\n2020-05-18 23:42:11.081786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/tiny_shell_exec.py\", line 33, in execute\r\n    exit_code = safe_shell_exec.execute(command, stdout=output, stderr=output)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/safe_shell_exec.py\", line 175, in execute\r\n    middleman.start()\r\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"/usr/lib/python3.6/multiprocessing/spawn.py\", line 172, in get_preparation_data\r\n    main_mod_name = getattr(main_module.__spec__, \"name\", None)\r\nAttributeError: module '__main__' has no attribute '__spec__'\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/tiny_shell_exec.py\", line 33, in execute\r\n    exit_code = safe_shell_exec.execute(command, stdout=output, stderr=output)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/safe_shell_exec.py\", line 175, in execute\r\n    middleman.start()\r\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"/usr/lib/python3.6/multiprocessing/spawn.py\", line 172, in get_preparation_data\r\n    main_mod_name = getattr(main_module.__spec__, \"name\", None)\r\nAttributeError: module '__main__' has no attribute '__spec__'\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/tiny_shell_exec.py\", line 33, in execute\r\n    exit_code = safe_shell_exec.execute(command, stdout=output, stderr=output)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/common/util/safe_shell_exec.py\", line 175, in execute\r\n    middleman.start()\r\n  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 42, in _launch\r\n    prep_data = spawn.get_preparation_data(process_obj._name)\r\n  File \"/usr/lib/python3.6/multiprocessing/spawn.py\", line 172, in get_preparation_data\r\n    main_mod_name = getattr(main_module.__spec__, \"name\", None)\r\nAttributeError: module '__main__' has no attribute '__spec__'\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/horovodrun\", line 4, in <module>\r\n    __import__('pkg_resources').run_script('horovod==0.19.2', 'horovodrun')\r\n  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 667, in run_script\r\n    self.require(requires)[0].run_script(script_name, ns)\r\n  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 1464, in run_script\r\n    exec(code, namespace, namespace)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/EGG-INFO/scripts/horovodrun\", line 21, in <module>\r\n    run_commandline()\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 723, in run_commandline\r\n    _run(args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 656, in _run\r\n    _launch_job(args, remote_host_names, settings, nics, command)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 717, in _launch_job\r\n    args.verbose)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 692, in run_controller\r\n    mpi_run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/runner.py\", line 709, in mpi_run_fn\r\n    mpi_run(settings, nics, env, command)\r\n  File \"/usr/local/lib/python3.6/dist-packages/horovod-0.19.2-py3.6-linux-x86_64.egg/horovod/run/mpi_run.py\", line 143, in mpi_run\r\n    raise Exception(_MPI_NOT_FOUND_ERROR_MSG)\r\nException: horovod does not find an installed MPI.\r\n\r\nChoose one of:\r\n1. Install Open MPI 4.0.0+ or IBM Spectrum MPI or MPICH and re-install Horovod (use --no-cache-dir pip option).\r\n2. Run distributed training script using the standard way provided by your MPI distribution (usually mpirun, srun, or jsrun).\r\n3. Use built-in gloo option (horovodrun --gloo ...).\r\n```\r\n\r\n@tgaddair FYI ;) ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1961", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1961/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1961/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1961/events", "html_url": "https://github.com/horovod/horovod/issues/1961", "id": 620144389, "node_id": "MDU6SXNzdWU2MjAxNDQzODk=", "number": 1961, "title": "run yolo3(tf.keras implemented) with cpu, after first epoch, the process will exist.", "user": {"login": "836304831", "id": 8056281, "node_id": "MDQ6VXNlcjgwNTYyODE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8056281?v=4", "gravatar_id": "", "url": "https://api.github.com/users/836304831", "html_url": "https://github.com/836304831", "followers_url": "https://api.github.com/users/836304831/followers", "following_url": "https://api.github.com/users/836304831/following{/other_user}", "gists_url": "https://api.github.com/users/836304831/gists{/gist_id}", "starred_url": "https://api.github.com/users/836304831/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/836304831/subscriptions", "organizations_url": "https://api.github.com/users/836304831/orgs", "repos_url": "https://api.github.com/users/836304831/repos", "events_url": "https://api.github.com/users/836304831/events{/privacy}", "received_events_url": "https://api.github.com/users/836304831/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-18T11:50:01Z", "updated_at": "2020-06-30T11:18:07Z", "closed_at": "2020-06-30T11:18:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)Tensorflow\r\n2. Framework version:1.12.0\r\n3. Horovod version:0.19.0\r\n4. MPI version:4.0.0\r\n5. CUDA version:None\r\n6. NCCL version:None\r\n7. Python version:3.6.9\r\n8. OS and version: ubuntu18.04\r\n9. GCC version: 7.5.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\n\r\nrun examples is ok\uff1a\r\n`horovodrun -np 2 -H localhost:2 python tensorflow_keras_mnist.py`\r\n\r\nbut when run yolo3\uff0cafter first epoch\uff0c the process will exist\uff0c error as\uff1a\r\n![image](https://user-images.githubusercontent.com/8056281/82209940-be6d1d00-9940-11ea-9b89-72333174148e.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1955", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1955/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1955/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1955/events", "html_url": "https://github.com/horovod/horovod/issues/1955", "id": 619320689, "node_id": "MDU6SXNzdWU2MTkzMjA2ODk=", "number": 1955, "title": "Account for dynamic world size when averaging gradients in TensorFlow", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 1988239761, "node_id": "MDU6TGFiZWwxOTg4MjM5NzYx", "url": "https://api.github.com/repos/horovod/horovod/labels/elastic", "name": "elastic", "color": "40ce63", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/1", "html_url": "https://github.com/horovod/horovod/milestone/1", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/1/labels", "id": 5343023, "node_id": "MDk6TWlsZXN0b25lNTM0MzAyMw==", "number": 1, "title": "0.20.0", "description": "Elastic mode (autoscaling, fault tolerance)", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 7, "closed_issues": 11, "state": "open", "created_at": "2020-04-23T23:49:44Z", "updated_at": "2020-08-17T21:54:52Z", "due_on": null, "closed_at": null}, "comments": 0, "created_at": "2020-05-15T23:16:09Z", "updated_at": "2020-06-18T16:30:36Z", "closed_at": "2020-06-18T16:30:36Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Currently, the TensorFlow graph is constructed with the world size embedded as a constant tensor.  When running in elastic mode, this results in problems with averaging as the size is not updated as workers are added / removed.\r\n\r\n#357 provides an implementation of size ops that account for dynamic world sizes.  We should rebase and merge in this change to fix this.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1947", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1947/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1947/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1947/events", "html_url": "https://github.com/horovod/horovod/issues/1947", "id": 616995592, "node_id": "MDU6SXNzdWU2MTY5OTU1OTI=", "number": 1947, "title": "Add reset limit when running in elastic mode", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1988239761, "node_id": "MDU6TGFiZWwxOTg4MjM5NzYx", "url": "https://api.github.com/repos/horovod/horovod/labels/elastic", "name": "elastic", "color": "40ce63", "default": false, "description": ""}, {"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/1", "html_url": "https://github.com/horovod/horovod/milestone/1", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/1/labels", "id": 5343023, "node_id": "MDk6TWlsZXN0b25lNTM0MzAyMw==", "number": 1, "title": "0.20.0", "description": "Elastic mode (autoscaling, fault tolerance)", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 7, "closed_issues": 11, "state": "open", "created_at": "2020-04-23T23:49:44Z", "updated_at": "2020-08-17T21:54:52Z", "due_on": null, "closed_at": null}, "comments": 0, "created_at": "2020-05-12T22:11:42Z", "updated_at": "2020-06-25T18:41:05Z", "closed_at": "2020-06-25T18:41:05Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "The user should be able to optionally specify a hard limit on the number of reset events that can occur, with an optional sliding window.\r\n\r\nFor example:\r\n\r\n```\r\nhorovodrun --reset-limit 3\r\n```\r\n\r\nOr:\r\n\r\n```\r\nhorovodrun --reset-limit 3 --reset-limit-window-duration 60\r\n```\r\n\r\nIn the latter case, we will only fail of there are 3 reset events in a minute (60 seconds), while in the former, we will fail if we ever see 3 reset events over the lifetime of the job.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1943", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1943/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1943/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1943/events", "html_url": "https://github.com/horovod/horovod/issues/1943", "id": 615746947, "node_id": "MDU6SXNzdWU2MTU3NDY5NDc=", "number": 1943, "title": "Add NCCLAllgather feature", "user": {"login": "Richie-yan", "id": 41471499, "node_id": "MDQ6VXNlcjQxNDcxNDk5", "avatar_url": "https://avatars0.githubusercontent.com/u/41471499?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Richie-yan", "html_url": "https://github.com/Richie-yan", "followers_url": "https://api.github.com/users/Richie-yan/followers", "following_url": "https://api.github.com/users/Richie-yan/following{/other_user}", "gists_url": "https://api.github.com/users/Richie-yan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Richie-yan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Richie-yan/subscriptions", "organizations_url": "https://api.github.com/users/Richie-yan/orgs", "repos_url": "https://api.github.com/users/Richie-yan/repos", "events_url": "https://api.github.com/users/Richie-yan/events{/privacy}", "received_events_url": "https://api.github.com/users/Richie-yan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "Richie-yan", "id": 41471499, "node_id": "MDQ6VXNlcjQxNDcxNDk5", "avatar_url": "https://avatars0.githubusercontent.com/u/41471499?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Richie-yan", "html_url": "https://github.com/Richie-yan", "followers_url": "https://api.github.com/users/Richie-yan/followers", "following_url": "https://api.github.com/users/Richie-yan/following{/other_user}", "gists_url": "https://api.github.com/users/Richie-yan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Richie-yan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Richie-yan/subscriptions", "organizations_url": "https://api.github.com/users/Richie-yan/orgs", "repos_url": "https://api.github.com/users/Richie-yan/repos", "events_url": "https://api.github.com/users/Richie-yan/events{/privacy}", "received_events_url": "https://api.github.com/users/Richie-yan/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Richie-yan", "id": 41471499, "node_id": "MDQ6VXNlcjQxNDcxNDk5", "avatar_url": "https://avatars0.githubusercontent.com/u/41471499?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Richie-yan", "html_url": "https://github.com/Richie-yan", "followers_url": "https://api.github.com/users/Richie-yan/followers", "following_url": "https://api.github.com/users/Richie-yan/following{/other_user}", "gists_url": "https://api.github.com/users/Richie-yan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Richie-yan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Richie-yan/subscriptions", "organizations_url": "https://api.github.com/users/Richie-yan/orgs", "repos_url": "https://api.github.com/users/Richie-yan/repos", "events_url": "https://api.github.com/users/Richie-yan/events{/privacy}", "received_events_url": "https://api.github.com/users/Richie-yan/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/1", "html_url": "https://github.com/horovod/horovod/milestone/1", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/1/labels", "id": 5343023, "node_id": "MDk6TWlsZXN0b25lNTM0MzAyMw==", "number": 1, "title": "0.20.0", "description": "Elastic mode (autoscaling, fault tolerance)", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 7, "closed_issues": 11, "state": "open", "created_at": "2020-04-23T23:49:44Z", "updated_at": "2020-08-17T21:54:52Z", "due_on": null, "closed_at": null}, "comments": 6, "created_at": "2020-05-11T09:48:43Z", "updated_at": "2020-05-17T22:39:41Z", "closed_at": "2020-05-17T22:39:41Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Horovod currently supports allgather functions such as mpi allgather and mpi gpu allgather, and lacks nccl allgather. Recently, I'm using horovod to train a visual model. The model will execute allgather once at each step. Now I use MPI_Allgather on CPU. I implemented a simple NCCL_Allgather on GPU in the source code, and the performance has been greatly improved.So this issue plans to provide an ncclallgather implementation.\r\nTwo points were found during the implementation process:\r\n1. The ncclAllGather native interface does not support the case where the first dimension is different;\r\n2. For the test of allgather in the test_tensorflow.py script, why does it appear as hvd.allgather on the same gpu device if there is a gpu in the current environment? (For example: test_horovod_allgather function, because if tf.device () is not used artificially, tensorflow will use a GPU for calculation by default)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1940", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1940/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1940/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1940/events", "html_url": "https://github.com/horovod/horovod/issues/1940", "id": 613863631, "node_id": "MDU6SXNzdWU2MTM4NjM2MzE=", "number": 1940, "title": "How does broadcast_parameters() work?", "user": {"login": "abcinje", "id": 33629617, "node_id": "MDQ6VXNlcjMzNjI5NjE3", "avatar_url": "https://avatars0.githubusercontent.com/u/33629617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abcinje", "html_url": "https://github.com/abcinje", "followers_url": "https://api.github.com/users/abcinje/followers", "following_url": "https://api.github.com/users/abcinje/following{/other_user}", "gists_url": "https://api.github.com/users/abcinje/gists{/gist_id}", "starred_url": "https://api.github.com/users/abcinje/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abcinje/subscriptions", "organizations_url": "https://api.github.com/users/abcinje/orgs", "repos_url": "https://api.github.com/users/abcinje/repos", "events_url": "https://api.github.com/users/abcinje/events{/privacy}", "received_events_url": "https://api.github.com/users/abcinje/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-07T08:15:07Z", "updated_at": "2020-05-22T06:05:53Z", "closed_at": "2020-05-22T06:05:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "### **Framework: PyTorch**\r\n\r\nHello.\r\n\r\nI wonder how `broadcast_parameters()` works when using Horovod with PyTorch.\r\nThe function is defined [here](https://github.com/horovod/horovod/blob/master/horovod/torch/__init__.py#L452).\r\n\r\nLooking at `pytorch_mnist.py` in `examples` directory, the function is called [here](https://github.com/horovod/horovod/blob/master/examples/pytorch_mnist.py#L173).\r\nAnd the first argument, `model.state_dict()` has an OrderedDict type.\r\n\r\nIs it possible that the others except the root node update their parameters when passing an object with that type? I thought that the first argument should be `model` or something else, and there should be an update process such as `model.load_state_dict()`.\r\n\r\nI think I've missed something. When do the other nodes initialize their parameters?\r\n\r\nThanks in advance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1937", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1937/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1937/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1937/events", "html_url": "https://github.com/horovod/horovod/issues/1937", "id": 612643397, "node_id": "MDU6SXNzdWU2MTI2NDMzOTc=", "number": 1937, "title": "Error while trying to install in virtual environment", "user": {"login": "anweshpanda", "id": 60091167, "node_id": "MDQ6VXNlcjYwMDkxMTY3", "avatar_url": "https://avatars0.githubusercontent.com/u/60091167?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anweshpanda", "html_url": "https://github.com/anweshpanda", "followers_url": "https://api.github.com/users/anweshpanda/followers", "following_url": "https://api.github.com/users/anweshpanda/following{/other_user}", "gists_url": "https://api.github.com/users/anweshpanda/gists{/gist_id}", "starred_url": "https://api.github.com/users/anweshpanda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anweshpanda/subscriptions", "organizations_url": "https://api.github.com/users/anweshpanda/orgs", "repos_url": "https://api.github.com/users/anweshpanda/repos", "events_url": "https://api.github.com/users/anweshpanda/events{/privacy}", "received_events_url": "https://api.github.com/users/anweshpanda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-05T14:23:43Z", "updated_at": "2020-05-11T14:14:13Z", "closed_at": "2020-05-11T14:14:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI am trying to install horovod with tensorflow 1.14 in virtual environment. I am following the instructions from the link below\r\nhttps://horovod.readthedocs.io/en/latest/contributors_include.html\r\n----------------------------------------------------------------------------------------------------------------\r\nBut while executing  the command : HOROVOD_WITH_TENSORFLOW=1 python setup.py install \r\nI am getting the following error\r\n-------------------------------------------------------------------------------------------------------------------------\r\nERROR: Command errored out with exit status 1:\r\n   command: /mnt/lustre/cds/cdsanwesk/env/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-wheel-io6xod58/psutil/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-wheel-io6xod58/psutil/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-1xwa_d5j\r\n       cwd: /tmp/pip-wheel-io6xod58/psutil/\r\n  Complete output (46 lines):\r\n  No supported cpu target is set, CRAY_CPU_TARGET=x86-64 will be used.\r\n  Load a valid targeting module or set CRAY_CPU_TARGET\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.6\r\n  creating build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_psosx.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_pssunos.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_pslinux.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_psaix.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/__init__.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_psposix.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_common.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_compat.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_psbsd.py -> build/lib.linux-x86_64-3.6/psutil\r\n  copying psutil/_pswindows.py -> build/lib.linux-x86_64-3.6/psutil\r\n  creating build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/runner.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_contracts.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/__main__.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_linux.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_process.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_osx.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_memory_leaks.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/__init__.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_sunos.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_misc.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_windows.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_posix.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_unicode.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_connections.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_bsd.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_system.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  copying psutil/tests/test_aix.py -> build/lib.linux-x86_64-3.6/psutil/tests\r\n  running build_ext\r\n  building 'psutil._psutil_linux' extension\r\n  creating build/temp.linux-x86_64-3.6\r\n  creating build/temp.linux-x86_64-3.6/psutil\r\n  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -fstack-clash-protection -g -DOPENSSL_LOAD_CONF -fwrapv -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -fstack-clash-protection -g -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -fstack-clash-protection -g -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_SIZEOF_PID_T=4 -DPSUTIL_VERSION=570 -DPSUTIL_LINUX=1 -I/mnt/lustre/cds/cdsanwesk/env/include -I/usr/include/python3.6m -c psutil/_psutil_common.c -o build/temp.linux-x86_64-3.6/psutil/_psutil_common.o\r\n  psutil/_psutil_common.c:9:10: fatal error: Python.h: No such file or directory\r\n   #include <Python.h>\r\n            ^~~~~~~~~~\r\n  compilation terminated.\r\n  error: command 'gcc' failed with exit status 1\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for psutil\r\nERROR: Failed to build one or more wheels\r\nTraceback (most recent call last):\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/setuptools/installer.py\", line 128, in fetch_build_egg\r\n    subprocess.check_call(cmd)\r\n  File \"/usr/lib64/python3.6/subprocess.py\", line 311, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['/mnt/lustre/cds/cdsanwesk/env/bin/python', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmps6ts_v7e', '--quiet', 'psutil']' returned non-zero exit status 1.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 1633, in <module>\r\n    scripts=['bin/horovodrun'])\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/setuptools/__init__.py\", line 143, in setup\r\n    _install_setup_requires(attrs)\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/setuptools/__init__.py\", line 138, in _install_setup_requires\r\n    dist.fetch_build_eggs(dist.setup_requires)\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/setuptools/dist.py\", line 698, in fetch_build_eggs\r\n    replace_conflicting=True,\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/pkg_resources/__init__.py\", line 783, in resolve\r\n    replace_conflicting=replace_conflicting\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/pkg_resources/__init__.py\", line 1066, in best_match\r\n    return self.obtain(req, installer)\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/pkg_resources/__init__.py\", line 1078, in obtain\r\n    return installer(requirement)\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/setuptools/dist.py\", line 754, in fetch_build_egg\r\n    return fetch_build_egg(self, req)\r\n  File \"/mnt/lustre/cds/cdsanwesk/env/lib64/python3.6/site-packages/setuptools/installer.py\", line 130, in fetch_build_egg\r\n    raise DistutilsError(str(e))\r\ndistutils.errors.DistutilsError: Command '['/mnt/lustre/cds/cdsanwesk/env/bin/python', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmps6ts_v7e', '--quiet', 'psutil']' returned non-zero exit status 1.\r\n-------------------------------------------------------------------------------------------------------------------------------\r\nI tried but could not find a solution for virtual environmment specifically. \r\nCan someone please help..?? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1934", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1934/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1934/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1934/events", "html_url": "https://github.com/horovod/horovod/issues/1934", "id": 612010991, "node_id": "MDU6SXNzdWU2MTIwMTA5OTE=", "number": 1934, "title": "Can't find routable network interface when using Horovod Docker on two machines", "user": {"login": "Inception95", "id": 56369917, "node_id": "MDQ6VXNlcjU2MzY5OTE3", "avatar_url": "https://avatars3.githubusercontent.com/u/56369917?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Inception95", "html_url": "https://github.com/Inception95", "followers_url": "https://api.github.com/users/Inception95/followers", "following_url": "https://api.github.com/users/Inception95/following{/other_user}", "gists_url": "https://api.github.com/users/Inception95/gists{/gist_id}", "starred_url": "https://api.github.com/users/Inception95/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Inception95/subscriptions", "organizations_url": "https://api.github.com/users/Inception95/orgs", "repos_url": "https://api.github.com/users/Inception95/repos", "events_url": "https://api.github.com/users/Inception95/events{/privacy}", "received_events_url": "https://api.github.com/users/Inception95/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-05-04T16:36:22Z", "updated_at": "2020-05-11T17:32:47Z", "closed_at": "2020-05-11T17:32:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Keras\r\n2. Framework version: 2.3.1 (TensorFlow 1.14.0 backend)\r\n3. Horovod version: 0.18.2\r\n4. MPI version: 1.10.2\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.8\r\n7. Python version: 3.6.8\r\n8. OS and version: Ubuntu 18.04 (Docker), Ubuntu 16.04 (Host)\r\n9. GCC version: \r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\nYes, similar issue: https://github.com/horovod/horovod/issues/1068, tried to add --start-timeout 300 but still didn't work.\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\nYes, but my passwordless ssh between the two machines is fine.\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\nYes, I followed this site to run training script.\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\nI checked but no.\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nHi, thanks for your great contribution!\r\n\r\nI used to use Horovod training image classification task on two machines with 16 GPUs (CentOS 7), now I try to do it on Ubuntu but failed. I am using Horovod Docker to run the task, when I run the task on one machine using Docker, it went well, but when running it on two machines (already set the passwordless ssh), it shows:\r\n\r\n`horovod.run.common.util.network was unable to connect to horovodrun driver on any of the following address.`\r\n\r\nThe command I used inside the docker after set the worker \"sleep infinitely\" and open the 12345 port is: \r\n`horovodrun --verbose -np 2 -H localhost:1,worker-ip:1 --start-timeout 300 -p 12345 python keras_mnist.py`\r\n\r\nit shows:\r\n```\r\nFiltering local host names.\r\nRemote host found: worker-ip\r\nChecking ssh on all remote hosts.\r\nSSH was successful into all the remote hosts.\r\nTesting interfaces on all the hosts.\r\nLanuched horovodrun server.\r\nAttempted to launch horovod task servers.\r\nWaiting for the hosts to acknowledge.\r\n```\r\n\r\nNow it just hangs here for about 10 mins, but firstly it shows:\r\nhorovod.run.common.util.network was unable to connect to horovodrun driver on any of the following address.\r\none possible caused of this problem is that horovodrun currently requires every host to have at least one routable network interfaces with the same name across all of the hosts. You can run \"ifconfig -a\" on every host and check for the common routable interface.\r\n\r\nI ran the \"ifconfig -a\" on two machines and their interfaces have the same name (I trained on the aws instances and asked the support center to check the network status, it seems fine). I also try to reproduce this training on CentOS instances but this problem shows again.\r\n\r\nIs there any possible reasons to my situation? Thanks in advance!\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1932", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1932/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1932/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1932/events", "html_url": "https://github.com/horovod/horovod/issues/1932", "id": 611391460, "node_id": "MDU6SXNzdWU2MTEzOTE0NjA=", "number": 1932, "title": "Out of resource error while running horovod ", "user": {"login": "Vidyaranya", "id": 6431354, "node_id": "MDQ6VXNlcjY0MzEzNTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/6431354?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Vidyaranya", "html_url": "https://github.com/Vidyaranya", "followers_url": "https://api.github.com/users/Vidyaranya/followers", "following_url": "https://api.github.com/users/Vidyaranya/following{/other_user}", "gists_url": "https://api.github.com/users/Vidyaranya/gists{/gist_id}", "starred_url": "https://api.github.com/users/Vidyaranya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Vidyaranya/subscriptions", "organizations_url": "https://api.github.com/users/Vidyaranya/orgs", "repos_url": "https://api.github.com/users/Vidyaranya/repos", "events_url": "https://api.github.com/users/Vidyaranya/events{/privacy}", "received_events_url": "https://api.github.com/users/Vidyaranya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-03T11:33:19Z", "updated_at": "2020-05-10T10:53:53Z", "closed_at": "2020-05-10T10:53:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\nI used singularity to run and hence I used a dockerfile\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Tensorflow\r\n2. Framework version: 1.11.0\r\n3. Horovod version:\r\n4. MPI version: 3.1.2\r\n5. CUDA version: 9.0\r\n6. NCCL version: 2.3.5-2+cuda9.0\r\n7. Python version: 2.7\r\n8. OS and version: ubuntu16.04\r\n9. GCC version: 5.5.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nWhen I run horovod using mpirun command\r\n\r\n```\r\nmpirun -v -np 1 -bind-to none -map-by slot  -x LD_LIBRARY_PATH -x PATH   -mca btl vader,self,tcp,openib,smcuda -mca pml ob1 -mca oob_tcp_if_include enp1s0f1,enp1s0f0   -x NCCL_SOCKET_IFNAME=^lo,docker0  singularity exec --nv horovod.sif run_code.sh \r\n```\r\nthe code fails at hvd.init() with the following error:\r\n\r\n```[dgj318:64919] PMIX ERROR: OUT-OF-RESOURCE in file client/pmix_client.c at line 228\r\n[dgj318:64919] OPAL ERROR: Error in file pmix2x_client.c at line 109\r\n*** An error occurred in MPI_Init_thread\r\n*** on a NULL communicator\r\n*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,\r\n***    and potentially your MPI job)\r\n[dgj318:64919] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!\r\n```\r\n\r\nI use slurm to schedule my jobs on HPC cluster and as you see, I use singularity. I used the keras_mnist example. Interestingly, the same command and code worked on a different HPC cluster and failing on this.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1931", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1931/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1931/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1931/events", "html_url": "https://github.com/horovod/horovod/issues/1931", "id": 611334499, "node_id": "MDU6SXNzdWU2MTEzMzQ0OTk=", "number": 1931, "title": "How to use timeline log for horovod", "user": {"login": "kingwales1", "id": 63086433, "node_id": "MDQ6VXNlcjYzMDg2NDMz", "avatar_url": "https://avatars3.githubusercontent.com/u/63086433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kingwales1", "html_url": "https://github.com/kingwales1", "followers_url": "https://api.github.com/users/kingwales1/followers", "following_url": "https://api.github.com/users/kingwales1/following{/other_user}", "gists_url": "https://api.github.com/users/kingwales1/gists{/gist_id}", "starred_url": "https://api.github.com/users/kingwales1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kingwales1/subscriptions", "organizations_url": "https://api.github.com/users/kingwales1/orgs", "repos_url": "https://api.github.com/users/kingwales1/repos", "events_url": "https://api.github.com/users/kingwales1/events{/privacy}", "received_events_url": "https://api.github.com/users/kingwales1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-03T05:11:42Z", "updated_at": "2020-05-23T03:45:57Z", "closed_at": "2020-05-23T03:45:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version: Tensorflow 2.1.0\r\n3. Horovod version: 0.19\r\n4. MPI version: 4.01\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.7\r\n8. OS and version: Ubuntu 16.04\r\n9. GCC version: 8.1.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nI am using timeline to help me understand the training in a distributed fashion. I have two questions.\r\n\r\n1. if we add the [cycle marker](https://horovod.readthedocs.io/en/latest/timeline_include.html), it means that we can record multiple steps for the training?\r\n\r\n2. Can we track the computation time using the timeline? For me, besides the communication time, I want to analyze the computation time for each worker before doing the Allreduce. I think is the time between starting the computation and NEGOTIATE_ALLREDUCE ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1930", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1930/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1930/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1930/events", "html_url": "https://github.com/horovod/horovod/issues/1930", "id": 611290304, "node_id": "MDU6SXNzdWU2MTEyOTAzMDQ=", "number": 1930, "title": "CNN model trained on distributed deep learning lose generalization", "user": {"login": "zfan2016", "id": 38844172, "node_id": "MDQ6VXNlcjM4ODQ0MTcy", "avatar_url": "https://avatars3.githubusercontent.com/u/38844172?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zfan2016", "html_url": "https://github.com/zfan2016", "followers_url": "https://api.github.com/users/zfan2016/followers", "following_url": "https://api.github.com/users/zfan2016/following{/other_user}", "gists_url": "https://api.github.com/users/zfan2016/gists{/gist_id}", "starred_url": "https://api.github.com/users/zfan2016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zfan2016/subscriptions", "organizations_url": "https://api.github.com/users/zfan2016/orgs", "repos_url": "https://api.github.com/users/zfan2016/repos", "events_url": "https://api.github.com/users/zfan2016/events{/privacy}", "received_events_url": "https://api.github.com/users/zfan2016/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-02T22:50:09Z", "updated_at": "2020-05-03T01:37:24Z", "closed_at": "2020-05-03T01:37:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n Framework: Keras backend with TensorFlow\r\n\r\nFor a binary classification task, I trained a CNN model using both a single GPU with keras backend with tensorflow, and multiple GPUs through distributed learning with Horovod and still keras backend with tensorflow.\r\nIn the first case, I firstly loaded both validation and training datasets before training.\r\nIn the later case, I loaded both validation and training data through data-generator.\r\nFor both cases, the training/validation/testing datasets and model architecture are exactly same, and I got similar validation accuracy of ~ 0.89\r\nThen I loaded the best model got from the two cases to evaluate accuracy on my testing dataset loaded directly without using data-generator. the model trained using single GPU has testing accuracy close to validation accuracy, but the model trained through distributed learning with horovod has testing accuracy of 0.5\r\nWhat are the possible mistakes I made during distributed learning such that the model got through distributed learning does NOT have any generalization ability? I want to use distributed learning to train larger training datasets.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1929", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1929/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1929/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1929/events", "html_url": "https://github.com/horovod/horovod/issues/1929", "id": 611270639, "node_id": "MDU6SXNzdWU2MTEyNzA2Mzk=", "number": 1929, "title": "Proposal: Drop Python 2 support in v0.20.0", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/1", "html_url": "https://github.com/horovod/horovod/milestone/1", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/1/labels", "id": 5343023, "node_id": "MDk6TWlsZXN0b25lNTM0MzAyMw==", "number": 1, "title": "0.20.0", "description": "Elastic mode (autoscaling, fault tolerance)", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 7, "closed_issues": 11, "state": "open", "created_at": "2020-04-23T23:49:44Z", "updated_at": "2020-08-17T21:54:52Z", "due_on": null, "closed_at": null}, "comments": 6, "created_at": "2020-05-02T20:46:07Z", "updated_at": "2020-05-15T23:06:33Z", "closed_at": "2020-05-15T23:06:33Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "At this point, most frameworks in our ecosystem have dropped Python 2 support, so it makes sense for us to consider doing the same.  \r\n\r\nAlready, a number of our more recent features (elastic mode, synchronized batch normalization) are Python 3 only.\r\n\r\nWe still officially maintain support for Python 2 for all legacy code paths, but there are a number of reasons to consider dropping this:\r\n\r\n1. Running Python 2 unit tests cost money to run in the cloud, and since we have nearly 1:1 Python 2 to Python 3 test coverage, this nearly doubles our cloud bill for CPU tests.\r\n2. As new versions of Python continue to be released, it becomes a challenge to just maintain mutual compatibility between Python 3.6 (our earliest supported version of Python 3) and newer versions (python 3.8, which recently changes the default multiprocessing run mode, see #1891). \r\n3. Maintaining feature parity becomes a challenge, as a number of basic things supported natively in Python 3 require elaborate workarounds for Python 2 (for example, multiprocessing barrier).\r\n\r\nAdditionally, users who need to use Python 2 can continue to use older versions of Horovod.  As TensorFlow and PyTorch should not be releasing new Python 2 versions of their libraries, this shouldn't be an issue for users who are stuck using Python 2.\r\n\r\nWhat does dropping Python 2 support mean?\r\n\r\n1. No more Python 2 tests in Buildkite.\r\n2. No more Python 2 Docker images or PyPi packages.\r\n3. No more system version checks to perform different logic for Python 2 vs Python 3.\r\n4. No more dependency on `six`, replace all usages with native Python 3 equivalents.\r\n5. No more doc references to Python 2, or unit test exclusions based on Python 2.\r\n\r\nTSC members, please review and provide your feedback:\r\n\r\n@alsrgv @nvcastet @romerojosh @EnricoMi @karakusc @apeforest ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1928", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1928/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1928/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1928/events", "html_url": "https://github.com/horovod/horovod/issues/1928", "id": 611105857, "node_id": "MDU6SXNzdWU2MTExMDU4NTc=", "number": 1928, "title": "Which  g++ version support horovod with tensorflow 2.1?", "user": {"login": "kingwales1", "id": 63086433, "node_id": "MDQ6VXNlcjYzMDg2NDMz", "avatar_url": "https://avatars3.githubusercontent.com/u/63086433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kingwales1", "html_url": "https://github.com/kingwales1", "followers_url": "https://api.github.com/users/kingwales1/followers", "following_url": "https://api.github.com/users/kingwales1/following{/other_user}", "gists_url": "https://api.github.com/users/kingwales1/gists{/gist_id}", "starred_url": "https://api.github.com/users/kingwales1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kingwales1/subscriptions", "organizations_url": "https://api.github.com/users/kingwales1/orgs", "repos_url": "https://api.github.com/users/kingwales1/repos", "events_url": "https://api.github.com/users/kingwales1/events{/privacy}", "received_events_url": "https://api.github.com/users/kingwales1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-02T04:37:25Z", "updated_at": "2020-05-02T14:42:43Z", "closed_at": "2020-05-02T14:42:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version: tf 2.1\r\n3. Horovod version: 0.19\r\n4. MPI version: 4.01\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.7\r\n8. OS and version: Ubuntu 16.04\r\n9. GCC version: 5.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nI want to mention an old issue like [this](https://github.com/horovod/horovod/issues/1334).  It happens again. Though I use $pip show tensorflow to prove that I have tf 2.1.0 installed. I tried the solution mentioned by Alex. But still got this issue: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\r\n\r\nThen I tried to use:\r\n$HOROVOD_NCCL_HOME=/usr/local/nccl_2.6.4 HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL HOROVOD_WITH_TENSORFLOW=1 pip install --no-cache-dir horovod. \r\n\r\nBut I got these errors related to the compiler. My current g++ and gcc is 5.4.0. Which version of g++ should I use? Anybody can help me?\r\n\r\n\r\n--------------------------------------------------------------------------------------------------\r\nERROR: Command errored out with exit status 1:\r\n   command: /root/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-m4s7np5b/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-m4s7np5b/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-8jc9ukzh --python-tag cp37\r\n       cwd: /tmp/pip-install-m4s7np5b/horovod/\r\n  Complete output (133 lines):\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.7\r\n  creating build/lib.linux-x86_64-3.7/horovod\r\n  copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n  creating build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n  copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  running build_ext\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lcudart -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.so\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/nccl_2.6.4/include -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_nccl.cc -o build/temp.linux-x86_64-3.7/test_compile/test_nccl.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_nccl.o -L/usr/local/nccl_2.6.4/lib -L/usr/local/nccl_2.6.4/lib64 -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lnccl_static -o build/temp.linux-x86_64-3.7/test_compile/test_nccl.so\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  2020-05-02 00:15:39.821934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n  2020-05-02 00:15:39.823448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n  INFO: Compiler /usr/bin/g++ (version 5.4.0 20160609) is not usable for this TensorFlow installation. Require g++ (version >=7.3.1 20180303, <999).\r\n  INFO: Compiler /usr/bin/g++-5 (version 5.4.0 20160609) is not usable for this TensorFlow installation. Require g++ (version >=7.3.1 20180303, <999).\r\n  error: Could not find compiler compatible with this TensorFlow installation.\r\n  Please check the Horovod website for recommended compiler versions.\r\n  To force a specific compiler version, set CC and CXX environment variables.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\nInstalling collected packages: horovod\r\n  Running setup.py install for horovod ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /root/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-m4s7np5b/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-m4s7np5b/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-c6tui4nq/install-record.txt --single-version-externally-managed --compile\r\n         cwd: /tmp/pip-install-m4s7np5b/horovod/\r\n    Complete output (134 lines):\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.7\r\n    creating build/lib.linux-x86_64-3.7/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n    creating build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    running build_ext\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lcudart -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.so\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/nccl_2.6.4/include -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_nccl.cc -o build/temp.linux-x86_64-3.7/test_compile/test_nccl.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_nccl.o -L/usr/local/nccl_2.6.4/lib -L/usr/local/nccl_2.6.4/lib64 -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lnccl_static -o build/temp.linux-x86_64-3.7/test_compile/test_nccl.so\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lcudart -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.so\r\n    2020-05-02 00:15:44.150133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n    2020-05-02 00:15:44.151602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n    INFO: Compiler /usr/bin/g++ (version 5.4.0 20160609) is not usable for this TensorFlow installation. Require g++ (version >=7.3.1 20180303, <999).\r\n    INFO: Compiler /usr/bin/g++-5 (version 5.4.0 20160609) is not usable for this TensorFlow installation. Require g++ (version >=7.3.1 20180303, <999).\r\n    error: Could not find compiler compatible with this TensorFlow installation.\r\n    Please check the Horovod website for recommended compiler versions.\r\n    To force a specific compiler version, set CC and CXX environment variables.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /root/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-m4s7np5b/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-m4s7np5b/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-c6tui4nq/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\r\n(base) root@server:~# gcc --version\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n(base) root@server:~# g++ --version\r\ng++ (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n(base) root@server:~# pip show tensorflow\r\nName: tensorflow\r\nVersion: 2.1.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /root/anaconda3/lib/python3.7/site-packages\r\nRequires: gast, wrapt, scipy, tensorboard, tensorflow-estimator, opt-einsum, grpcio, google-pasta, absl-py, astor, keras-preprocessing, numpy, wheel, keras-applications, termcolor, six, protobuf\r\nRequired-by:\r\n(base) root@server:~# HOROVOD_NCCL_HOME=/usr/local/nccl_2.6.4 HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL HOROVOD_WITH_TENSORFLOW=1 pip install --no-cache-dir git+https://github.com/horovod/horovod\r\nCollecting git+https://github.com/horovod/horovod\r\n  Cloning https://github.com/horovod/horovod to /tmp/pip-req-build-cdye0jjm\r\n  Running command git clone -q https://github.com/horovod/horovod /tmp/pip-req-build-cdye0jjm\r\n  Running command git submodule update --init --recursive -q\r\nRequirement already satisfied: cloudpickle in ./anaconda3/lib/python3.7/site-packages (from horovod==0.19.1) (1.2.2)\r\nRequirement already satisfied: psutil in ./anaconda3/lib/python3.7/site-packages (from horovod==0.19.1) (5.6.3)\r\nRequirement already satisfied: pyyaml in ./anaconda3/lib/python3.7/site-packages (from horovod==0.19.1) (5.1.2)\r\nRequirement already satisfied: six in ./anaconda3/lib/python3.7/site-packages (from horovod==0.19.1) (1.12.0)\r\nRequirement already satisfied: cffi>=1.4.0 in ./anaconda3/lib/python3.7/site-packages (from horovod==0.19.1) (1.12.3)\r\nRequirement already satisfied: pycparser in ./anaconda3/lib/python3.7/site-packages (from cffi>=1.4.0->horovod==0.19.1) (2.19)\r\nBuilding wheels for collected packages: horovod\r\n  Building wheel for horovod (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /root/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-cdye0jjm/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-cdye0jjm/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-8xy87924 --python-tag cp37\r\n       cwd: /tmp/pip-req-build-cdye0jjm/\r\n  Complete output (143 lines):\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.7\r\n  creating build/lib.linux-x86_64-3.7/horovod\r\n  copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n  creating build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/runner.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/js_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/runner.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/sync_batch_norm.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/lsf.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n  copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/tiny_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/gloo_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  running build_ext\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O3 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O3 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lcudart -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.so\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O3 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/nccl_2.6.4/include -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_nccl.cc -o build/temp.linux-x86_64-3.7/test_compile/test_nccl.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_nccl.o -L/usr/local/nccl_2.6.4/lib -L/usr/local/nccl_2.6.4/lib64 -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lnccl_static -o build/temp.linux-x86_64-3.7/test_compile/test_nccl.so\r\n  gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O3 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lcudart -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.so\r\n  2020-05-02 00:20:34.372283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n  2020-05-02 00:20:34.373906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n  INFO: Compiler /usr/bin/g++ (version 5.4.0 20160609) is not usable for this TensorFlow installation. Require g++ (version >=7.3.1 20180303, <999).\r\n  INFO: Compiler /usr/bin/g++-5 (version 5.4.0 20160609) is not usable for this TensorFlow installation. Require g++ (version >=7.3.1 20180303, <999).\r\n  error: Could not find compiler compatible with this TensorFlow installation.\r\n  Please check the Horovod website for recommended compiler versions.\r\n  To force a specific compiler version, set CC and CXX environment variables.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\nInstalling collected packages: horovod\r\n  Running setup.py install for horovod ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /root/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-cdye0jjm/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-cdye0jjm/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-mkj4yd9t/install-record.txt --single-version-externally-managed --compile\r\n         cwd: /tmp/pip-req-build-cdye0jjm/\r\n    Complete output (142 lines):\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.7\r\n    creating build/lib.linux-x86_64-3.7/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n    creating build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/runner.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/js_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/runner.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/sync_batch_norm.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/lsf.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/tiny_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/gloo_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    running build_ext\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O3 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O3 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lcudart -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.so\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O3 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/nccl_2.6.4/include -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_nccl.cc -o build/temp.linux-x86_64-3.7/test_compile/test_nccl.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /root/anaconda3/compiler_compat -L/root/anaconda3/lib -Wl,-rpath=/root/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_nccl.o -L/usr/local/nccl_2.6.4/lib -L/usr/local/nccl_2.6.4/lib64 -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lnccl_static -o build/temp.linux-x86_64-3.7/test_compile/test_nccl.so\r\n    gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O3 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/cuda/include -I/root/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cuda.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    2020-05-02 00:20:38.702184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n    2020-05-02 00:20:38.703723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n    INFO: Compiler /usr/bin/g++ (version 5.4.0 20160609) is not usable for this TensorFlow installation. Require g++ (version >=7.3.1 20180303, <999).\r\n    INFO: Compiler /usr/bin/g++-5 (version 5.4.0 20160609) is not usable for this TensorFlow installation. Require g++ (version >=7.3.1 20180303, <999).\r\n    error: Could not find compiler compatible with this TensorFlow installation.\r\n    Please check the Horovod website for recommended compiler versions.\r\n    To force a specific compiler version, set CC and CXX environment variables.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /root/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-cdye0jjm/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-cdye0jjm/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-mkj4yd9t/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1924", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1924/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1924/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1924/events", "html_url": "https://github.com/horovod/horovod/issues/1924", "id": 609545987, "node_id": "MDU6SXNzdWU2MDk1NDU5ODc=", "number": 1924, "title": " support for xPU ", "user": {"login": "wuchangping", "id": 29653216, "node_id": "MDQ6VXNlcjI5NjUzMjE2", "avatar_url": "https://avatars1.githubusercontent.com/u/29653216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wuchangping", "html_url": "https://github.com/wuchangping", "followers_url": "https://api.github.com/users/wuchangping/followers", "following_url": "https://api.github.com/users/wuchangping/following{/other_user}", "gists_url": "https://api.github.com/users/wuchangping/gists{/gist_id}", "starred_url": "https://api.github.com/users/wuchangping/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wuchangping/subscriptions", "organizations_url": "https://api.github.com/users/wuchangping/orgs", "repos_url": "https://api.github.com/users/wuchangping/repos", "events_url": "https://api.github.com/users/wuchangping/events{/privacy}", "received_events_url": "https://api.github.com/users/wuchangping/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-30T03:46:22Z", "updated_at": "2020-07-20T02:22:24Z", "closed_at": "2020-07-20T02:22:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Dear,\r\nIs there any plan for adding the addons or contrib folder  and MACRO XPU to support xPU, for example: Google TPU, or xxxx xPU, or any other deep learning processors?\r\n\r\n\r\n\r\nJeff Wu", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1921", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1921/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1921/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1921/events", "html_url": "https://github.com/horovod/horovod/issues/1921", "id": 608786301, "node_id": "MDU6SXNzdWU2MDg3ODYzMDE=", "number": 1921, "title": "Keras LR callbacks have unintended behavior when resuming from checkpoint", "user": {"login": "sparticlesteve", "id": 6074319, "node_id": "MDQ6VXNlcjYwNzQzMTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/6074319?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sparticlesteve", "html_url": "https://github.com/sparticlesteve", "followers_url": "https://api.github.com/users/sparticlesteve/followers", "following_url": "https://api.github.com/users/sparticlesteve/following{/other_user}", "gists_url": "https://api.github.com/users/sparticlesteve/gists{/gist_id}", "starred_url": "https://api.github.com/users/sparticlesteve/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sparticlesteve/subscriptions", "organizations_url": "https://api.github.com/users/sparticlesteve/orgs", "repos_url": "https://api.github.com/users/sparticlesteve/repos", "events_url": "https://api.github.com/users/sparticlesteve/events{/privacy}", "received_events_url": "https://api.github.com/users/sparticlesteve/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/2", "html_url": "https://github.com/horovod/horovod/milestone/2", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/2/labels", "id": 5346062, "node_id": "MDk6TWlsZXN0b25lNTM0NjA2Mg==", "number": 2, "title": "0.19.2", "description": "Bugfix release, LSF support, last release with Python 2 support.", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "closed", "created_at": "2020-04-24T16:27:59Z", "updated_at": "2020-05-13T20:31:31Z", "due_on": "2020-05-08T07:00:00Z", "closed_at": "2020-05-13T20:31:31Z"}, "comments": 10, "created_at": "2020-04-29T05:22:41Z", "updated_at": "2020-05-04T15:46:41Z", "closed_at": "2020-05-04T14:53:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: tf.keras\r\n2. Framework version: TF 1.15.0\r\n3. Horovod version: 0.19.0\r\n4. MPI version: cray-mpich/7.7.10\r\n5. CUDA version: n/a\r\n6. NCCL version: n/a\r\n7. Python version: 3.7.4\r\n8. OS and version: Cray linux based on SLES 15\r\n9. GCC version: 7.3.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? n/a\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? n/a\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? yes\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nThere is a problem with the Keras learning rate callbacks (inheriting from `LearningRateScheduleCallbackImpl`) as implemented when using checkpoints and resuming training. This class pulls the `initial_lr` from the model optimizer in `on_train_begin`:\r\nhttps://github.com/horovod/horovod/blob/d1b13ec131af22b31d0ba999dae15a29991cfeae/horovod/_keras/callbacks.py#L137\r\nAll LR (and momentum) modifications are done with respect to that initial learning rate and the current epoch (or batch). However, if one is writing a checkpoint, the current modified learning rate and momentum are written to the checkpoint file. Then, upon loading that checkpoint and resuming training with the LR callback, it pulls the _modified_ LR as its new `initial_lr`. Unless the user takes care to reset the optimizer's LR (and momentum) after loading from checkpoint and before training, the original schedule applied will not produce the intended schedule. The Keras Imagenet resnet50 example is affected by this, for instance:\r\nhttps://github.com/horovod/horovod/blob/master/examples/keras_imagenet_resnet50.py\r\n\r\nIn contrast, the LR scheduler in Keras (and tf.keras) is implemented such that modifications depend on the _current_ learning rate. This slightly different approach is therefore not affected by the checkpoint resume issue. It doesn't have any momentum correction, though.\r\nhttps://github.com/tensorflow/tensorflow/blob/bab74a15d9ad6bb9066b3e31d601d6a45b1cb221/tensorflow/python/keras/callbacks.py#L1349\r\n\r\nI think there are a couple of possible reasonable solutions. One is to change the multiplier logic to match that of the Keras LR scheduler so that the new LR is a result of the multiplier times the current LR. This logic change would likely break folks' code, though. Another possible solution is to allow (or require!) the user to set the initial LR in the callback constructor. This way I can ensure that it is always set to the correct, intended value. Finally, as I alluded to above, the user can reset their optimizer LR (and appropriately scale the momentum) after loading from checkpoint and before training. However, I consider this a workaround rather than a solution.\r\n\r\nI'm hoping I explained it clearly enough that I don't need a MWE, but I can provide one if required.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1920", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1920/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1920/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1920/events", "html_url": "https://github.com/horovod/horovod/issues/1920", "id": 608766715, "node_id": "MDU6SXNzdWU2MDg3NjY3MTU=", "number": 1920, "title": "hvd.load_model not properly wrapping optimizer in tf.keras 1.15", "user": {"login": "sparticlesteve", "id": 6074319, "node_id": "MDQ6VXNlcjYwNzQzMTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/6074319?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sparticlesteve", "html_url": "https://github.com/sparticlesteve", "followers_url": "https://api.github.com/users/sparticlesteve/followers", "following_url": "https://api.github.com/users/sparticlesteve/following{/other_user}", "gists_url": "https://api.github.com/users/sparticlesteve/gists{/gist_id}", "starred_url": "https://api.github.com/users/sparticlesteve/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sparticlesteve/subscriptions", "organizations_url": "https://api.github.com/users/sparticlesteve/orgs", "repos_url": "https://api.github.com/users/sparticlesteve/repos", "events_url": "https://api.github.com/users/sparticlesteve/events{/privacy}", "received_events_url": "https://api.github.com/users/sparticlesteve/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/2", "html_url": "https://github.com/horovod/horovod/milestone/2", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/2/labels", "id": 5346062, "node_id": "MDk6TWlsZXN0b25lNTM0NjA2Mg==", "number": 2, "title": "0.19.2", "description": "Bugfix release, LSF support, last release with Python 2 support.", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "closed", "created_at": "2020-04-24T16:27:59Z", "updated_at": "2020-05-13T20:31:31Z", "due_on": "2020-05-08T07:00:00Z", "closed_at": "2020-05-13T20:31:31Z"}, "comments": 3, "created_at": "2020-04-29T04:20:51Z", "updated_at": "2020-05-05T17:26:16Z", "closed_at": "2020-05-05T17:26:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: tf.keras\r\n2. Framework version: TF 1.15.0\r\n3. Horovod version: 0.19.0\r\n4. MPI version: cray-mpich/7.7.10\r\n5. CUDA version: n/a\r\n6. NCCL version: n/a\r\n7. Python version: 3.7.4\r\n8. OS and version: Cray linux based on SLES 15\r\n9. GCC version: 7.3.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Oui\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? n/a\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? n/a\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? Oui oui\r\n\r\n**Bug report:**\r\nPlease describe erroneous behavior you're observing and steps to reproduce it.\r\n\r\nI've been noticing bad training results when resuming from checkpoint with `hvd.load_model`. I tracked it down to diverging worker models, and noticed that my model optimizers from `hvd.load_model` were not properly wrapped in the horovod DistributedOptimizer. I believe it's a bug in this logic that determines all optimizer classes to wrap right here:\r\nhttps://github.com/horovod/horovod/blob/d1b13ec131af22b31d0ba999dae15a29991cfeae/horovod/_keras/__init__.py#L113\r\n\r\nThis part:\r\n\r\n    horovod_objects = {\r\n        subclass.__name__.lower(): wrap_optimizer(subclass)\r\n        for subclass in keras.optimizers.Optimizer.__subclasses__()\r\n        if subclass.__module__ == keras.optimizers.Optimizer.__module__\r\n    }\r\n\r\nThis check on the subclass module matching Optimizer module doesn't work in TF 1.15. E.g., for the SGD optimizer, the class module (the LHS) is actually\r\n\r\n    In [9]: tensorflow.python.keras.optimizer_v2.gradient_descent.SGD.__module__\r\n    Out[9]: 'tensorflow.python.keras.optimizer_v2.gradient_descent'\r\n\r\nwhereas the RHS is\r\n\r\n    In [10]: tf.keras.optimizers.Optimizer.__module__\r\n    Out[10]: 'tensorflow.python.keras.optimizer_v2.optimizer_v2\u2019\r\n\r\nI have for now implemented a workaround in my code that just removes the module equality comparison and confirm that my optimizers are correctly being wrapped in DistributedOptimizer.\r\n\r\nI don't have a suggestion for how to fix this in Horovod. Presumably the module paths are inconsistent across Keras and TF versions :(", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1914", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1914/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1914/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1914/events", "html_url": "https://github.com/horovod/horovod/issues/1914", "id": 607506075, "node_id": "MDU6SXNzdWU2MDc1MDYwNzU=", "number": 1914, "title": "How to use multi-gpu for training on one node.", "user": {"login": "Danliran", "id": 38999651, "node_id": "MDQ6VXNlcjM4OTk5NjUx", "avatar_url": "https://avatars2.githubusercontent.com/u/38999651?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Danliran", "html_url": "https://github.com/Danliran", "followers_url": "https://api.github.com/users/Danliran/followers", "following_url": "https://api.github.com/users/Danliran/following{/other_user}", "gists_url": "https://api.github.com/users/Danliran/gists{/gist_id}", "starred_url": "https://api.github.com/users/Danliran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Danliran/subscriptions", "organizations_url": "https://api.github.com/users/Danliran/orgs", "repos_url": "https://api.github.com/users/Danliran/repos", "events_url": "https://api.github.com/users/Danliran/events{/privacy}", "received_events_url": "https://api.github.com/users/Danliran/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-04-27T12:24:32Z", "updated_at": "2020-05-14T02:35:46Z", "closed_at": "2020-04-28T09:07:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) pytorch\r\n2. Framework version: 1.2.0\r\n3. Horovod version: 0.19.1\r\n4. MPI version:4.0.3rc4\r\n5. CUDA version:10.2\r\n6. NCCL version:2.4.8\r\n7. Python version:3.6\r\n8. OS and version:ubuntu18.04\r\n9. GCC version:9.3\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?no\r\n2. If your question is about hang, did you read [this doc] (https://github.com/horovod/horovod/blob/master/docs/running.rst)? no hang\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)? no docker\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? yes\r\n\r\n**Your question:**\r\n\r\nOne node with 2 GP. when i set -np 2, but two processor run the same GPU, another one is idel.\r\nHow to use both gpu for training?\r\n\r\ncommand:\r\n(py1.2gpu) root@taishan:~/py/horovod-master/examples# horovodrun -np 2 -H localhost:2 python pytorch_synthetic_benchmark.py\r\n[1,0]<stdout>:taishan:60096:60247 [0] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0>\r\n[1,0]<stdout>:taishan:60096:60247 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n[1,0]<stdout>:taishan:60096:60247 [0] NCCL INFO NET/IB : No device found.\r\n[1,0]<stdout>:taishan:60096:60247 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0>\r\n[1,0]<stdout>:NCCL version 2.4.8+cuda10.1\r\n[1,0]<stdout>:taishan:60096:60247 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff\r\n[1,0]<stdout>:taishan:60096:60247 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees enabled up to size -2\r\n[1,0]<stdout>:taishan:60096:60247 [0] NCCL INFO comm 0xfffeac02d2e0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n[1,0]<stdout>:Model: resnet50\r\n[1,0]<stdout>:Batch size: 32\r\n[1,0]<stdout>:Number of GPUs: 1\r\n[1,0]<stdout>:Running warmup...\r\n[1,1]<stdout>:taishan:60097:60248 [0] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0>\r\n[1,1]<stdout>:taishan:60097:60248 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n[1,1]<stdout>:taishan:60097:60248 [0] NCCL INFO NET/IB : No device found.\r\n[1,1]<stdout>:taishan:60097:60248 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0>\r\n[1,1]<stdout>:NCCL version 2.4.8+cuda10.1\r\n[1,1]<stdout>:taishan:60097:60248 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff\r\n[1,1]<stdout>:taishan:60097:60248 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees enabled up to size -2\r\n[1,1]<stdout>:taishan:60097:60248 [0] NCCL INFO comm 0xfffed802d0e0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n[1,1]<stdout>:Model: resnet50\r\n[1,1]<stdout>:Batch size: 32\r\n[1,1]<stdout>:Number of GPUs: 1\r\n[1,1]<stdout>:Running warmup...\r\n[1,0]<stdout>:Running benchmark...\r\n[1,1]<stdout>:Running benchmark...\r\n[1,0]<stdout>:Iter #0: 51.4 img/sec per GPU\r\n[1,1]<stdout>:Iter #0: 51.0 img/sec per GPU\r\n\r\n\r\n\r\n|   0  Tesla T4            Off  | 00000000:02:00.0 Off |                    0 |\r\n| N/A   52C    P0    26W /  70W |   1927MiB / 15109MiB |     17%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla T4            Off  | 00000000:04:00.0 Off |                    0 |\r\n| N/A   51C    P0    27W /  70W |      3MiB / 15109MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU                  PID   Type   Process name                  GPU Memory |\r\n|                                                                  Usage      |\r\n|============================================\r\n|    0                63107      C   python                            973MiB |\r\n|    0                63108      C   python                            953MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\n      ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1910", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1910/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1910/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1910/events", "html_url": "https://github.com/horovod/horovod/issues/1910", "id": 606941040, "node_id": "MDU6SXNzdWU2MDY5NDEwNDA=", "number": 1910, "title": "Installation issue with MXNet built from source - No such file or dictionary <dmlc/base.h>", "user": {"login": "shuo-ouyang", "id": 24750212, "node_id": "MDQ6VXNlcjI0NzUwMjEy", "avatar_url": "https://avatars3.githubusercontent.com/u/24750212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shuo-ouyang", "html_url": "https://github.com/shuo-ouyang", "followers_url": "https://api.github.com/users/shuo-ouyang/followers", "following_url": "https://api.github.com/users/shuo-ouyang/following{/other_user}", "gists_url": "https://api.github.com/users/shuo-ouyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/shuo-ouyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shuo-ouyang/subscriptions", "organizations_url": "https://api.github.com/users/shuo-ouyang/orgs", "repos_url": "https://api.github.com/users/shuo-ouyang/repos", "events_url": "https://api.github.com/users/shuo-ouyang/events{/privacy}", "received_events_url": "https://api.github.com/users/shuo-ouyang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-26T07:10:34Z", "updated_at": "2020-05-17T08:59:15Z", "closed_at": "2020-05-17T08:59:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: MXNet\r\n2. Framework version: 1.4.0\r\n3. Horovod version: 0.19\r\n4. MPI version: openmpi-2.1.6\r\n5. CUDA version: CUDA 8.0\r\n6. NCCL version: None\r\n7. Python version: 2.7.9\r\n8. OS and version: centos 7.6\r\n9. GCC version: 4.8.5\r\n\r\n**Your question:**\r\n\r\nHi, I am installing horovod for mxnet, which is built from source, using `pip install horovod-0.19.1.tar.gz` on my private cluster, and I get following error during installation. The issue can be partially sovled by changing relative path `dmlc/base.h` to absolute path `../../3rdparty/dmlc-core/include/dmlc/base.h`, but there are too many headers to change it manually one by one. Are there any approachs to cope with it?\r\n\r\n```\r\nIn file included from horovod/mxnet/mpi_ops.h:19:0,\r\n                     from horovod/mxnet/mpi_ops.cc:20:\r\n    /PARA/mxnet-1.4.0/python/mxnet/../../include/mxnet/base.h:32:23: fatal error: dmlc/base.h: No such file or directory\r\n     #include \"dmlc/base.h\"\r\n                           ^\r\n    compilation terminated.\r\n    error: command 'gcc' failed with exit status 1\r\n    \r\n    ----------------------------------------\r\nCommand \"/WORK/app/Python/2.7.9-fPIC/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-req-build-YJNzVX/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-uKO7cH/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-req-build-YJNzVX/\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1907", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1907/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1907/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1907/events", "html_url": "https://github.com/horovod/horovod/issues/1907", "id": 606558351, "node_id": "MDU6SXNzdWU2MDY1NTgzNTE=", "number": 1907, "title": "Elastic mode to enable fault tolerance and auto-scaling", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1988239761, "node_id": "MDU6TGFiZWwxOTg4MjM5NzYx", "url": "https://api.github.com/repos/horovod/horovod/labels/elastic", "name": "elastic", "color": "40ce63", "default": false, "description": ""}, {"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/1", "html_url": "https://github.com/horovod/horovod/milestone/1", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/1/labels", "id": 5343023, "node_id": "MDk6TWlsZXN0b25lNTM0MzAyMw==", "number": 1, "title": "0.20.0", "description": "Elastic mode (autoscaling, fault tolerance)", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 7, "closed_issues": 11, "state": "open", "created_at": "2020-04-23T23:49:44Z", "updated_at": "2020-08-17T21:54:52Z", "due_on": null, "closed_at": null}, "comments": 0, "created_at": "2020-04-24T20:16:07Z", "updated_at": "2020-05-15T16:04:06Z", "closed_at": "2020-05-15T16:04:06Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "[RFC](https://docs.google.com/document/d/15ZoHA5AeSI_boeyIBapg9WPXKrYXMRvPytPzQWTCTn4/edit?usp=sharing)\r\n\r\nThis feature covers the bare-metal implementation of a fault tolerant and auto-scaling capability / API for Horovod built on top of the Gloo controller.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1905", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1905/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1905/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1905/events", "html_url": "https://github.com/horovod/horovod/issues/1905", "id": 605942959, "node_id": "MDU6SXNzdWU2MDU5NDI5NTk=", "number": 1905, "title": "gcc error", "user": {"login": "joadiazcr", "id": 12650044, "node_id": "MDQ6VXNlcjEyNjUwMDQ0", "avatar_url": "https://avatars0.githubusercontent.com/u/12650044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joadiazcr", "html_url": "https://github.com/joadiazcr", "followers_url": "https://api.github.com/users/joadiazcr/followers", "following_url": "https://api.github.com/users/joadiazcr/following{/other_user}", "gists_url": "https://api.github.com/users/joadiazcr/gists{/gist_id}", "starred_url": "https://api.github.com/users/joadiazcr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joadiazcr/subscriptions", "organizations_url": "https://api.github.com/users/joadiazcr/orgs", "repos_url": "https://api.github.com/users/joadiazcr/repos", "events_url": "https://api.github.com/users/joadiazcr/events{/privacy}", "received_events_url": "https://api.github.com/users/joadiazcr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-04-23T23:46:05Z", "updated_at": "2020-04-24T20:17:16Z", "closed_at": "2020-04-24T20:17:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "While installing horovod with \r\n\r\nHOROVOD_WITH_TENSORFLOW=1 pip install horovod[tensorflow,keras]\r\n\r\nI am getting a long error that ends with:\r\n\r\nerror: command '/usr/bin/gcc' failed with exit status 1\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-mhz8vk74/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-mhz8vk74/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-33ieci1w/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/simulations/.local/include/python3.6m/horovod Check the logs for full command output.\r\n\r\nI think this is because I am not using the correct gcc version, which should be 4.8.5 (I have this version installed, but when I  do \"gcc -v\" I get gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) \r\n). How can I  solve this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1903", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1903/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1903/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1903/events", "html_url": "https://github.com/horovod/horovod/issues/1903", "id": 605894277, "node_id": "MDU6SXNzdWU2MDU4OTQyNzc=", "number": 1903, "title": "Catch KeyboardInterrupt", "user": {"login": "jchwenger", "id": 34098722, "node_id": "MDQ6VXNlcjM0MDk4NzIy", "avatar_url": "https://avatars1.githubusercontent.com/u/34098722?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jchwenger", "html_url": "https://github.com/jchwenger", "followers_url": "https://api.github.com/users/jchwenger/followers", "following_url": "https://api.github.com/users/jchwenger/following{/other_user}", "gists_url": "https://api.github.com/users/jchwenger/gists{/gist_id}", "starred_url": "https://api.github.com/users/jchwenger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jchwenger/subscriptions", "organizations_url": "https://api.github.com/users/jchwenger/orgs", "repos_url": "https://api.github.com/users/jchwenger/repos", "events_url": "https://api.github.com/users/jchwenger/events{/privacy}", "received_events_url": "https://api.github.com/users/jchwenger/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-23T21:43:51Z", "updated_at": "2020-04-28T21:54:25Z", "closed_at": "2020-04-28T21:54:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI'm working on distributing openAI's TF 1.14 gpt-2 code on several GPUs, working fine so far, except I can't preserve this handy feature to save the model on keyboard interrupt:\r\n```\r\ntry:\r\n    # the training loop\r\nexcept KeyboardInterrupt:\r\n   if hvd.rank() == 0:\r\n      save()\r\n```\r\nI would do it only on rank 0, but nothing happens, no exception at all (I also tried `except Exception as e:` to see if I could print it). I'm assuming this is because the horovod/mpi wrapper is the one receiving the signal, and then shutting down the python process in some other way . Is there a straightforward way to do this ? \r\n\r\nHorovod version: 0.19.1, \r\nmpirun (Open MPI): 4.0.3\r\nCUDA Version 10.1.243\r\nnccl: libnccl2=2.4.8-1+cuda10.1 libnccl-dev=2.4.8-1+cuda10.10.1\r\ngcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n\r\n(installed using [the recommended steps](https://github.com/horovod/horovod#install))\r\n\r\nMany thanks in advance!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1898", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1898/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1898/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1898/events", "html_url": "https://github.com/horovod/horovod/issues/1898", "id": 605508820, "node_id": "MDU6SXNzdWU2MDU1MDg4MjA=", "number": 1898, "title": "Hard Torchvision Dependency", "user": {"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-04-23T12:54:35Z", "updated_at": "2020-04-23T20:38:32Z", "closed_at": "2020-04-23T20:38:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \r\nwe're trying to build a docker image for lightning, which also installs horovod as an extra dependency.\r\n\r\nWe noted that in https://github.com/horovod/horovod/blob/master/setup.py#L1578 you have a hard torch vision dependency.\r\n\r\nWe don't want a hard dependency on torch vision, since guys doing NLP or other stuff don't need it. \r\n\r\nSo I just wanted to ask, whether you need a hard dependency on it and why?\r\n\r\nBest,\r\nJustus\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1897", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1897/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1897/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1897/events", "html_url": "https://github.com/horovod/horovod/issues/1897", "id": 604694187, "node_id": "MDU6SXNzdWU2MDQ2OTQxODc=", "number": 1897, "title": "gluon.Trainer restore parameters", "user": {"login": "feevos", "id": 14290519, "node_id": "MDQ6VXNlcjE0MjkwNTE5", "avatar_url": "https://avatars0.githubusercontent.com/u/14290519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/feevos", "html_url": "https://github.com/feevos", "followers_url": "https://api.github.com/users/feevos/followers", "following_url": "https://api.github.com/users/feevos/following{/other_user}", "gists_url": "https://api.github.com/users/feevos/gists{/gist_id}", "starred_url": "https://api.github.com/users/feevos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/feevos/subscriptions", "organizations_url": "https://api.github.com/users/feevos/orgs", "repos_url": "https://api.github.com/users/feevos/repos", "events_url": "https://api.github.com/users/feevos/events{/privacy}", "received_events_url": "https://api.github.com/users/feevos/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-22T11:50:08Z", "updated_at": "2020-04-25T10:46:46Z", "closed_at": "2020-04-25T10:46:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Dear all, \r\n\r\nhow can I restore gluon.Trainer parameters from a saved state? I cannot find anything in the documentation. I have seen corresponding functions from pytorch, but I am not sure how to translate it (if possible) to mxnet. When I tried to load states from all nodes, it didn't work. \r\n\r\nAny help most appreciated. \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1893", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1893/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1893/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1893/events", "html_url": "https://github.com/horovod/horovod/issues/1893", "id": 603856692, "node_id": "MDU6SXNzdWU2MDM4NTY2OTI=", "number": 1893, "title": "Horovod hangs when running examples on a machine with 4 GPUs", "user": {"login": "sixindang", "id": 64068325, "node_id": "MDQ6VXNlcjY0MDY4MzI1", "avatar_url": "https://avatars3.githubusercontent.com/u/64068325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sixindang", "html_url": "https://github.com/sixindang", "followers_url": "https://api.github.com/users/sixindang/followers", "following_url": "https://api.github.com/users/sixindang/following{/other_user}", "gists_url": "https://api.github.com/users/sixindang/gists{/gist_id}", "starred_url": "https://api.github.com/users/sixindang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sixindang/subscriptions", "organizations_url": "https://api.github.com/users/sixindang/orgs", "repos_url": "https://api.github.com/users/sixindang/repos", "events_url": "https://api.github.com/users/sixindang/events{/privacy}", "received_events_url": "https://api.github.com/users/sixindang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-21T09:39:08Z", "updated_at": "2020-04-27T03:12:30Z", "closed_at": "2020-04-27T03:12:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras)\r\n2. Framework version: TensorFlow 2.1.0; Keras 2.3.1\r\n3. Horovod version: 0.19.1\r\n4. MPI version: 4.0.1\r\n5. CUDA version: 10.1.243\r\n6. NCCL version: 2.6.4\r\n7. Python version: 3.6.8\r\n8. OS and version: centos 8.0\r\n9. GCC version: 8.3.1\r\n\r\n\r\n**Your question:**\r\nHi,\r\nI have a cluster with 4 machines (each with 4 GPUs). I am trying to execute an Horovod example on one of the machines. \r\nI used this command to run the example:\r\n`horovodrun -np 4 -H localhost:4 python3 tensorflow2_keras_mnist.py`\r\nThe outputs of terminal are:\r\n\r\n![error](https://user-images.githubusercontent.com/64068325/79849467-1887ca80-83f5-11ea-8d26-9a25ea7529e4.jpg)\r\nThen I checked the GPUs with 'nvidia-smi -l' and found \"No running processes\".\r\n<img width=\"734\" alt=\"error_nvidia-smi\" src=\"https://user-images.githubusercontent.com/64068325/79849743-79af9e00-83f5-11ea-97a2-c320b67d1ca6.png\">\r\nI displayed the Linux processes with 'top' and found some processes running.\r\n<img width=\"960\" alt=\"error_top\" src=\"https://user-images.githubusercontent.com/64068325/79850435-7ec11d00-83f6-11ea-99b2-3a4418d9c575.png\">\r\nThere are not errors and outputs, the program just hangs. Can you please tell me what is wrong and how to fix it.\r\nThank you!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1892", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1892/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1892/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1892/events", "html_url": "https://github.com/horovod/horovod/issues/1892", "id": 603666740, "node_id": "MDU6SXNzdWU2MDM2NjY3NDA=", "number": 1892, "title": "horovod running on remote host", "user": {"login": "kmtaotao", "id": 8569634, "node_id": "MDQ6VXNlcjg1Njk2MzQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/8569634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmtaotao", "html_url": "https://github.com/kmtaotao", "followers_url": "https://api.github.com/users/kmtaotao/followers", "following_url": "https://api.github.com/users/kmtaotao/following{/other_user}", "gists_url": "https://api.github.com/users/kmtaotao/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmtaotao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmtaotao/subscriptions", "organizations_url": "https://api.github.com/users/kmtaotao/orgs", "repos_url": "https://api.github.com/users/kmtaotao/repos", "events_url": "https://api.github.com/users/kmtaotao/events{/privacy}", "received_events_url": "https://api.github.com/users/kmtaotao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-21T02:54:53Z", "updated_at": "2020-04-24T03:41:43Z", "closed_at": "2020-04-24T03:41:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\nwhen I run the horovod on remote server with same network interface and SSH connected properly, I receive the error message:\r\nFiltering local host names.\r\nRemote host found: 192.168.1.178\r\nChecking ssh on all remote hosts.\r\nSSH was successful into all the remote hosts.\r\nTesting interfaces on all the hosts.\r\nLaunched horovodrun server.\r\nAttempted to launch horovod task servers.\r\nWaiting for the hosts to acknowledge.\r\nLaunching horovodrun task function was not successful:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/tao/.virtualenvs/dl4cv/lib/python3.6/site-packages/horovod/run/task_fn.py\", line 67, in <module>\r\n    _task_fn(index, driver_addresses, settings)\r\n  File \"/home/tao/.virtualenvs/dl4cv/lib/python3.6/site-packages/horovod/run/task_fn.py\", line 24, in _task_fn\r\n    task = task_service.HorovodRunTaskService(index, settings.key, settings.nics)\r\nAttributeError: 'Settings' object has no attribute 'nics'", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1891", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1891/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1891/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1891/events", "html_url": "https://github.com/horovod/horovod/issues/1891", "id": 603596230, "node_id": "MDU6SXNzdWU2MDM1OTYyMzA=", "number": 1891, "title": "Python 3.8 incompatibility with nccl_built check", "user": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/horovod/horovod/milestones/2", "html_url": "https://github.com/horovod/horovod/milestone/2", "labels_url": "https://api.github.com/repos/horovod/horovod/milestones/2/labels", "id": 5346062, "node_id": "MDk6TWlsZXN0b25lNTM0NjA2Mg==", "number": 2, "title": "0.19.2", "description": "Bugfix release, LSF support, last release with Python 2 support.", "creator": {"login": "tgaddair", "id": 1742912, "node_id": "MDQ6VXNlcjE3NDI5MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1742912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgaddair", "html_url": "https://github.com/tgaddair", "followers_url": "https://api.github.com/users/tgaddair/followers", "following_url": "https://api.github.com/users/tgaddair/following{/other_user}", "gists_url": "https://api.github.com/users/tgaddair/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgaddair/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgaddair/subscriptions", "organizations_url": "https://api.github.com/users/tgaddair/orgs", "repos_url": "https://api.github.com/users/tgaddair/repos", "events_url": "https://api.github.com/users/tgaddair/events{/privacy}", "received_events_url": "https://api.github.com/users/tgaddair/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 7, "state": "closed", "created_at": "2020-04-24T16:27:59Z", "updated_at": "2020-05-13T20:31:31Z", "due_on": "2020-05-08T07:00:00Z", "closed_at": "2020-05-13T20:31:31Z"}, "comments": 0, "created_at": "2020-04-20T23:21:31Z", "updated_at": "2020-05-04T16:59:30Z", "closed_at": "2020-05-04T16:59:30Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "See: https://github.com/huge-success/sanic/issues/1774\r\n\r\n```\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/site-packages/horovod/common/util.py:110: in wrapper\r\n    retval = f(*args, **kwargs)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/site-packages/horovod/common/util.py:151: in nccl_built\r\n    result = _check_extension_lambda(\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/site-packages/horovod/common/util.py:90: in _check_extension_lambda\r\n    p.start()\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/process.py:121: in start\r\n    self._popen = self._Popen(self)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/context.py:224: in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/context.py:283: in _Popen\r\n    return Popen(process_obj)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/popen_spawn_posix.py:32: in __init__\r\n    super().__init__(process_obj)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/popen_fork.py:19: in __init__\r\n    self._launch(process_obj)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/popen_spawn_posix.py:47: in _launch\r\n    reduction.dump(process_obj, fp)\r\n/Users/runner/hostedtoolcache/Python/3.8.2/x64/lib/python3.8/multiprocessing/reduction.py:60: in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nE   AttributeError: Can't pickle local object '_check_extension_lambda.<locals>._target_fn'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1889", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1889/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1889/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1889/events", "html_url": "https://github.com/horovod/horovod/issues/1889", "id": 602993174, "node_id": "MDU6SXNzdWU2MDI5OTMxNzQ=", "number": 1889, "title": "error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.", "user": {"login": "Alwaysproblem", "id": 31947147, "node_id": "MDQ6VXNlcjMxOTQ3MTQ3", "avatar_url": "https://avatars1.githubusercontent.com/u/31947147?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alwaysproblem", "html_url": "https://github.com/Alwaysproblem", "followers_url": "https://api.github.com/users/Alwaysproblem/followers", "following_url": "https://api.github.com/users/Alwaysproblem/following{/other_user}", "gists_url": "https://api.github.com/users/Alwaysproblem/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alwaysproblem/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alwaysproblem/subscriptions", "organizations_url": "https://api.github.com/users/Alwaysproblem/orgs", "repos_url": "https://api.github.com/users/Alwaysproblem/repos", "events_url": "https://api.github.com/users/Alwaysproblem/events{/privacy}", "received_events_url": "https://api.github.com/users/Alwaysproblem/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-20T06:59:33Z", "updated_at": "2020-04-28T06:17:01Z", "closed_at": "2020-04-28T06:17:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) tensorflow \r\n2. Framework version: 2.1\r\n3. Horovod version: 0.19\r\n4. MPI version: 1.6.5\r\n5. CUDA version: \r\n6. NCCL version:\r\n7. Python version: 3.7.6\r\n8. OS and version: Ubuntu 14.04 LTS\r\n9. GCC version: g++ (Ubuntu 4.9.4-2ubuntu1~14.04.1) 4.9.4\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? Yes\r\n2. If your question is about hang, did you read [this doc]  NO (https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc]NO (https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide]Yes (https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nCPU version, How can I fix this probelm ? I am the new guy of horovod.\r\nInstall error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\r\n\r\n(/home/sdev/yongxi/hvd) sdev@n-profile-user-profile-v3-03:~/yongxi$ pip install horovod\r\nCollecting horovod\r\n  Using cached horovod-0.19.1.tar.gz (2.9 MB)\r\nRequirement already satisfied: cloudpickle in /home/sdev/anaconda3/lib/python3.7/site-packages (from horovod) (1.3.0)\r\nRequirement already satisfied: psutil in /home/sdev/anaconda3/lib/python3.7/site-packages (from horovod) (5.7.0)\r\nRequirement already satisfied: pyyaml in /home/sdev/anaconda3/lib/python3.7/site-packages (from horovod) (5.3.1)\r\nRequirement already satisfied: six in /home/sdev/anaconda3/lib/python3.7/site-packages (from horovod) (1.14.0)\r\nRequirement already satisfied: cffi>=1.4.0 in /home/sdev/anaconda3/lib/python3.7/site-packages (from horovod) (1.14.0)\r\nRequirement already satisfied: pycparser in /home/sdev/anaconda3/lib/python3.7/site-packages (from cffi>=1.4.0->horovod) (2.20)\r\nBuilding wheels for collected packages: horovod\r\n  Building wheel for horovod (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /home/sdev/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-9h3yaayn/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-9h3yaayn/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-8_1ze6oe\r\n       cwd: /tmp/pip-install-9h3yaayn/horovod/\r\n  Complete output (241 lines):\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.7\r\n  creating build/lib.linux-x86_64-3.7/horovod\r\n  copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  creating build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n  copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  running build_ext\r\n  gcc -pthread -B /home/sdev/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/home/sdev/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /home/sdev/anaconda3/compiler_compat -L/home/sdev/anaconda3/lib -Wl,-rpath=/home/sdev/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n  gcc -pthread -B /home/sdev/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/sdev/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n  cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n  gcc -pthread -shared -B /home/sdev/anaconda3/compiler_compat -L/home/sdev/anaconda3/lib -Wl,-rpath=/home/sdev/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n  INFO: Unable to build TensorFlow plugin, will skip it.\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 75, in check_tf_version\r\n      import tensorflow as tf\r\n  ModuleNotFoundError: No module named 'tensorflow'\r\n  \r\n  During handling of the above exception, another exception occurred:\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1466, in build_extensions\r\n      build_tf_extension(self, options)\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 931, in build_tf_extension\r\n      check_tf_version()\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 82, in check_tf_version\r\n      'import tensorflow failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n  distutils.errors.DistutilsPlatformError: import tensorflow failed, is it installed?\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 75, in check_tf_version\r\n      import tensorflow as tf\r\n  ModuleNotFoundError: No module named 'tensorflow'\r\n  \r\n  \r\n  INFO: Unable to build PyTorch plugin, will skip it.\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1132, in check_torch_version\r\n      import torch\r\n  ModuleNotFoundError: No module named 'torch'\r\n  \r\n  During handling of the above exception, another exception occurred:\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1478, in build_extensions\r\n      torch_version = check_torch_version()\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1139, in check_torch_version\r\n      'import torch failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n  distutils.errors.DistutilsPlatformError: import torch failed, is it installed?\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1132, in check_torch_version\r\n      import torch\r\n  ModuleNotFoundError: No module named 'torch'\r\n  \r\n  \r\n  -- The CXX compiler identification is GNU 4.9.4\r\n  -- The C compiler identification is GNU 4.9.4\r\n  -- Check for working CXX compiler: /usr/bin/c++\r\n  -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - done\r\n  -- Check for working C compiler: /usr/bin/cc\r\n  -- Check for working C compiler: /usr/bin/cc -- works\r\n  -- Detecting C compiler ABI info\r\n  -- Detecting C compiler ABI info - done\r\n  -- Found MPI_C: /usr/lib/libmpi.so;/usr/lib/x86_64-linux-gnu/libdl.so;/usr/lib/x86_64-linux-gnu/libhwloc.so\r\n  -- Found MPI_CXX: /usr/lib/libmpi_cxx.so;/usr/lib/libmpi.so;/usr/lib/x86_64-linux-gnu/libdl.so;/usr/lib/x86_64-linux-gnu/libhwloc.so\r\n  -- MPI include path: /usr/lib/openmpi/include/usr/lib/openmpi/include/openmpi\r\n  -- MPI libraries: /usr/lib/libmpi_cxx.so/usr/lib/libmpi.so/usr/lib/x86_64-linux-gnu/libdl.so/usr/lib/x86_64-linux-gnu/libhwloc.so\r\n  -- Configuring done\r\n  -- Generating done\r\n  -- Build files have been written to: /tmp/pip-install-9h3yaayn/horovod/build/temp.linux-x86_64-3.7/gloo/mxnet\r\n  Scanning dependencies of target gloo\r\n  [  3%] [  6%] [  9%] [ 12%] Building CXX object gloo/CMakeFiles/gloo.dir/allgather.cc.o\r\n  Building CXX object gloo/CMakeFiles/gloo.dir/allreduce.cc.o\r\n  Building CXX object gloo/CMakeFiles/gloo.dir/algorithm.cc.o\r\n  Building CXX object gloo/CMakeFiles/gloo.dir/allgatherv.cc.o\r\n  [ 15%] [ 18%] Building CXX object gloo/CMakeFiles/gloo.dir/allreduce_local.cc.o\r\n  Building CXX object gloo/CMakeFiles/gloo.dir/barrier.cc.o\r\n  [ 21%] Building CXX object gloo/CMakeFiles/gloo.dir/broadcast.cc.o\r\n  [ 25%] Building CXX object gloo/CMakeFiles/gloo.dir/context.cc.o\r\n  [ 28%] Building CXX object gloo/CMakeFiles/gloo.dir/gather.cc.o\r\n  [ 31%] Building CXX object gloo/CMakeFiles/gloo.dir/reduce.cc.o\r\n  [ 34%] Building CXX object gloo/CMakeFiles/gloo.dir/scatter.cc.o\r\n  [ 37%] Building CXX object gloo/CMakeFiles/gloo.dir/types.cc.o\r\n  [ 40%] Building CXX object gloo/CMakeFiles/gloo.dir/common/logging.cc.o\r\n  [ 43%] Building CXX object gloo/CMakeFiles/gloo.dir/common/linux.cc.o\r\n  [ 46%] Building CXX object gloo/CMakeFiles/gloo.dir/mpi/context.cc.o\r\n  [ 50%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/context.cc.o\r\n  [ 53%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/file_store.cc.o\r\n  [ 56%] [ 59%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/prefix_store.cc.o\r\n  Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/hash_store.cc.o\r\n  [ 62%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/store.cc.o\r\n  [ 65%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/address.cc.o\r\n  [ 68%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/buffer.cc.o\r\n  [ 71%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/context.cc.o\r\n  [ 75%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/device.cc.o\r\n  [ 78%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/pair.cc.o\r\n  [ 81%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/unbound_buffer.cc.o\r\n  [ 84%] [ 87%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/address.cc.o\r\n  Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/buffer.cc.o\r\n  [ 90%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/context.cc.o\r\n  [ 93%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/device.cc.o\r\n  [ 96%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/pair.cc.o\r\n  [100%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/unbound_buffer.cc.o\r\n  Linking CXX static library /tmp/pip-install-9h3yaayn/horovod/build/temp.linux-x86_64-3.7/lib/mxnet/libgloo.a\r\n  [100%] Built target gloo\r\n  INFO: Unable to build MXNet plugin, will skip it.\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 91, in check_mx_version\r\n      import mxnet as mx\r\n  ModuleNotFoundError: No module named 'mxnet'\r\n  \r\n  During handling of the above exception, another exception occurred:\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1494, in build_extensions\r\n      build_mx_extension(self, options)\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1080, in build_mx_extension\r\n      check_mx_version()\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 98, in check_mx_version\r\n      'import mxnet failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n  distutils.errors.DistutilsPlatformError: import mxnet failed, is it installed?\r\n  \r\n  Traceback (most recent call last):\r\n    File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 91, in check_mx_version\r\n      import mxnet as mx\r\n  ModuleNotFoundError: No module named 'mxnet'\r\n  \r\n  \r\n  error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\nInstalling collected packages: horovod\r\n    Running setup.py install for horovod ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /home/sdev/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-9h3yaayn/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-9h3yaayn/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-_jr6gkff/install-record.txt --single-version-externally-managed --compile --install-headers /home/sdev/anaconda3/include/python3.7m/horovod\r\n         cwd: /tmp/pip-install-9h3yaayn/horovod/\r\n    Complete output (241 lines):\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.7\r\n    creating build/lib.linux-x86_64-3.7/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    creating build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    running build_ext\r\n    gcc -pthread -B /home/sdev/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mf16c -mavx -mfma -I/home/sdev/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /home/sdev/anaconda3/compiler_compat -L/home/sdev/anaconda3/lib -Wl,-rpath=/home/sdev/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.so\r\n    gcc -pthread -B /home/sdev/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/sdev/anaconda3/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o\r\n    cc1plus: warning: command line option \u2018-Wstrict-prototypes\u2019 is valid for C/ObjC but not for C++\r\n    gcc -pthread -shared -B /home/sdev/anaconda3/compiler_compat -L/home/sdev/anaconda3/lib -Wl,-rpath=/home/sdev/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.7/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.7/test_compile/test_link_flags.so\r\n    INFO: Unable to build TensorFlow plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 75, in check_tf_version\r\n        import tensorflow as tf\r\n    ModuleNotFoundError: No module named 'tensorflow'\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1466, in build_extensions\r\n        build_tf_extension(self, options)\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 931, in build_tf_extension\r\n        check_tf_version()\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 82, in check_tf_version\r\n        'import tensorflow failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n    distutils.errors.DistutilsPlatformError: import tensorflow failed, is it installed?\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 75, in check_tf_version\r\n        import tensorflow as tf\r\n    ModuleNotFoundError: No module named 'tensorflow'\r\n    \r\n    \r\n    INFO: Unable to build PyTorch plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1132, in check_torch_version\r\n        import torch\r\n    ModuleNotFoundError: No module named 'torch'\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1478, in build_extensions\r\n        torch_version = check_torch_version()\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1139, in check_torch_version\r\n        'import torch failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n    distutils.errors.DistutilsPlatformError: import torch failed, is it installed?\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1132, in check_torch_version\r\n        import torch\r\n    ModuleNotFoundError: No module named 'torch'\r\n    \r\n    \r\n    -- The CXX compiler identification is GNU 4.9.4\r\n    -- The C compiler identification is GNU 4.9.4\r\n    -- Check for working CXX compiler: /usr/bin/c++\r\n    -- Check for working CXX compiler: /usr/bin/c++ -- works\r\n    -- Detecting CXX compiler ABI info\r\n    -- Detecting CXX compiler ABI info - done\r\n    -- Check for working C compiler: /usr/bin/cc\r\n    -- Check for working C compiler: /usr/bin/cc -- works\r\n    -- Detecting C compiler ABI info\r\n    -- Detecting C compiler ABI info - done\r\n    -- Found MPI_C: /usr/lib/libmpi.so;/usr/lib/x86_64-linux-gnu/libdl.so;/usr/lib/x86_64-linux-gnu/libhwloc.so\r\n    -- Found MPI_CXX: /usr/lib/libmpi_cxx.so;/usr/lib/libmpi.so;/usr/lib/x86_64-linux-gnu/libdl.so;/usr/lib/x86_64-linux-gnu/libhwloc.so\r\n    -- MPI include path: /usr/lib/openmpi/include/usr/lib/openmpi/include/openmpi\r\n    -- MPI libraries: /usr/lib/libmpi_cxx.so/usr/lib/libmpi.so/usr/lib/x86_64-linux-gnu/libdl.so/usr/lib/x86_64-linux-gnu/libhwloc.so\r\n    -- Configuring done\r\n    -- Generating done\r\n    -- Build files have been written to: /tmp/pip-install-9h3yaayn/horovod/build/temp.linux-x86_64-3.7/gloo/mxnet\r\n    Scanning dependencies of target gloo\r\n    [  3%] [  6%] [  9%] [ 12%] Building CXX object gloo/CMakeFiles/gloo.dir/allgatherv.cc.o\r\n    Building CXX object gloo/CMakeFiles/gloo.dir/algorithm.cc.o\r\n    Building CXX object gloo/CMakeFiles/gloo.dir/allreduce.cc.o\r\n    Building CXX object gloo/CMakeFiles/gloo.dir/allgather.cc.o\r\n    [ 15%] Building CXX object gloo/CMakeFiles/gloo.dir/allreduce_local.cc.o\r\n    [ 18%] Building CXX object gloo/CMakeFiles/gloo.dir/barrier.cc.o\r\n    [ 21%] Building CXX object gloo/CMakeFiles/gloo.dir/broadcast.cc.o\r\n    [ 25%] Building CXX object gloo/CMakeFiles/gloo.dir/context.cc.o\r\n    [ 28%] Building CXX object gloo/CMakeFiles/gloo.dir/gather.cc.o\r\n    [ 31%] Building CXX object gloo/CMakeFiles/gloo.dir/reduce.cc.o\r\n    [ 34%] Building CXX object gloo/CMakeFiles/gloo.dir/scatter.cc.o\r\n    [ 37%] Building CXX object gloo/CMakeFiles/gloo.dir/types.cc.o\r\n    [ 40%] Building CXX object gloo/CMakeFiles/gloo.dir/common/logging.cc.o\r\n    [ 43%] Building CXX object gloo/CMakeFiles/gloo.dir/common/linux.cc.o\r\n    [ 46%] Building CXX object gloo/CMakeFiles/gloo.dir/mpi/context.cc.o\r\n    [ 50%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/context.cc.o\r\n    [ 53%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/file_store.cc.o\r\n    [ 56%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/hash_store.cc.o\r\n    [ 59%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/prefix_store.cc.o\r\n    [ 62%] Building CXX object gloo/CMakeFiles/gloo.dir/rendezvous/store.cc.o\r\n    [ 65%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/address.cc.o\r\n    [ 68%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/buffer.cc.o\r\n    [ 71%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/context.cc.o\r\n    [ 75%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/device.cc.o\r\n    [ 78%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/pair.cc.o\r\n    [ 81%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/unbound_buffer.cc.o\r\n    [ 84%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/address.cc.o\r\n    [ 87%] [ 90%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/buffer.cc.o\r\n    Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/context.cc.o\r\n    [ 93%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/device.cc.o\r\n    [ 96%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/pair.cc.o\r\n    [100%] Building CXX object gloo/CMakeFiles/gloo.dir/transport/tcp/unbound_buffer.cc.o\r\n    Linking CXX static library /tmp/pip-install-9h3yaayn/horovod/build/temp.linux-x86_64-3.7/lib/mxnet/libgloo.a\r\n    [100%] Built target gloo\r\n    INFO: Unable to build MXNet plugin, will skip it.\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 91, in check_mx_version\r\n        import mxnet as mx\r\n    ModuleNotFoundError: No module named 'mxnet'\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1494, in build_extensions\r\n        build_mx_extension(self, options)\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 1080, in build_mx_extension\r\n        check_mx_version()\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 98, in check_mx_version\r\n        'import mxnet failed, is it installed?\\n\\n%s' % traceback.format_exc())\r\n    distutils.errors.DistutilsPlatformError: import mxnet failed, is it installed?\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/tmp/pip-install-9h3yaayn/horovod/setup.py\", line 91, in check_mx_version\r\n        import mxnet as mx\r\n    ModuleNotFoundError: No module named 'mxnet'\r\n    \r\n    \r\n    error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /home/sdev/anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-9h3yaayn/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-9h3yaayn/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-_jr6gkff/install-record.txt --single-version-externally-managed --compile --install-headers /home/sdev/anaconda3/include/python3.7m/horovod Check the logs for full command output.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1888", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1888/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1888/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1888/events", "html_url": "https://github.com/horovod/horovod/issues/1888", "id": 602608391, "node_id": "MDU6SXNzdWU2MDI2MDgzOTE=", "number": 1888, "title": "Questions about lr_scheduler of Pytorch and logging", "user": {"login": "Snowdar", "id": 61218724, "node_id": "MDQ6VXNlcjYxMjE4NzI0", "avatar_url": "https://avatars2.githubusercontent.com/u/61218724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Snowdar", "html_url": "https://github.com/Snowdar", "followers_url": "https://api.github.com/users/Snowdar/followers", "following_url": "https://api.github.com/users/Snowdar/following{/other_user}", "gists_url": "https://api.github.com/users/Snowdar/gists{/gist_id}", "starred_url": "https://api.github.com/users/Snowdar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Snowdar/subscriptions", "organizations_url": "https://api.github.com/users/Snowdar/orgs", "repos_url": "https://api.github.com/users/Snowdar/repos", "events_url": "https://api.github.com/users/Snowdar/events{/privacy}", "received_events_url": "https://api.github.com/users/Snowdar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-04-19T03:18:36Z", "updated_at": "2020-04-19T03:35:25Z", "closed_at": "2020-04-19T03:35:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I have two questions when using horovod:\r\n(1) How to use lr_scheduler after replacing torch.optim.optimizer with hvd.DistributedOptimizer?\r\n(2) Why print information by <stderr> type and there seems a cache when using logging.info?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1886", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1886/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1886/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1886/events", "html_url": "https://github.com/horovod/horovod/issues/1886", "id": 602474343, "node_id": "MDU6SXNzdWU2MDI0NzQzNDM=", "number": 1886, "title": "Multiple processes on a single GPU in Horovod? ", "user": {"login": "guoyuanxiong", "id": 28615500, "node_id": "MDQ6VXNlcjI4NjE1NTAw", "avatar_url": "https://avatars1.githubusercontent.com/u/28615500?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guoyuanxiong", "html_url": "https://github.com/guoyuanxiong", "followers_url": "https://api.github.com/users/guoyuanxiong/followers", "following_url": "https://api.github.com/users/guoyuanxiong/following{/other_user}", "gists_url": "https://api.github.com/users/guoyuanxiong/gists{/gist_id}", "starred_url": "https://api.github.com/users/guoyuanxiong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guoyuanxiong/subscriptions", "organizations_url": "https://api.github.com/users/guoyuanxiong/orgs", "repos_url": "https://api.github.com/users/guoyuanxiong/repos", "events_url": "https://api.github.com/users/guoyuanxiong/events{/privacy}", "received_events_url": "https://api.github.com/users/guoyuanxiong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-18T14:36:06Z", "updated_at": "2020-07-16T21:10:58Z", "closed_at": "2020-04-23T01:09:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nI am trying to run a distributed learning algorithm with 8 workers on a 4-GPU machine. Is it possible to allocate two processes to a single GPU in Horovod? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1885", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1885/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1885/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1885/events", "html_url": "https://github.com/horovod/horovod/issues/1885", "id": 602418075, "node_id": "MDU6SXNzdWU2MDI0MTgwNzU=", "number": 1885, "title": "speed plunges when training locally", "user": {"login": "vycezhong", "id": 25879526, "node_id": "MDQ6VXNlcjI1ODc5NTI2", "avatar_url": "https://avatars3.githubusercontent.com/u/25879526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vycezhong", "html_url": "https://github.com/vycezhong", "followers_url": "https://api.github.com/users/vycezhong/followers", "following_url": "https://api.github.com/users/vycezhong/following{/other_user}", "gists_url": "https://api.github.com/users/vycezhong/gists{/gist_id}", "starred_url": "https://api.github.com/users/vycezhong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vycezhong/subscriptions", "organizations_url": "https://api.github.com/users/vycezhong/orgs", "repos_url": "https://api.github.com/users/vycezhong/repos", "events_url": "https://api.github.com/users/vycezhong/events{/privacy}", "received_events_url": "https://api.github.com/users/vycezhong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-18T09:23:15Z", "updated_at": "2020-04-25T08:16:53Z", "closed_at": "2020-04-25T08:16:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework:  mxnet-cu102 \r\n2. Framework version: 1.6.0\r\n3. Horovod version: 0.19.1\r\n4. MPI version: 3.1.0 \r\n5. CUDA version: 10.2\r\n6. NCCL version: 2.5.6\r\n7. Python version: 3.6\r\n8. OS and version: ubuntu18.04lts\r\n9. GCC version: 7.5.0\r\n\r\nHW: p3.16xlarge \r\n\r\n**Bug report:**\r\n\r\n```sh\r\nhorovodrun -np 8 -H localhost:8 python ~/repos/horovod/examples/mxnet_imagenet_resnet50.py --model resnet50_v2 --mode gluon --rec-train ~/data/ILSVRC2012/train.rec --rec-train-idx ~/data/ILSVRC2012/train.idx --rec-val ~/data/ILSVRC2012/val.rec --rec-val-idx ~/data/ILSVRC2012/val.idx --use-rec --batch-size 64 --num-epochs 120 --data-nthreads 2 --warmup-epochs 5 --lr 0.05 --lr-mode step --log-interval 1\r\n```\r\nAt first everything worked well. but later GPUs run so slow that i thought they did not run at all. I set `log-interval` to 1 and found it did run at an extremely slow speed, around 70img/s. \r\n\r\n![image](https://user-images.githubusercontent.com/25879526/79633480-6d7ad500-8198-11ea-941c-36d03e8a5434.png)\r\n\r\n[full log](https://github.com/horovod/horovod/files/4496373/hvd.log) can be found here.\r\n \r\n___\r\n\r\nBTW, I did not observe this phenomenon when training distributedly with 8 x p3.16xlarge. hvd can reach the speed of ~15000img/s. that's about 68% scaling efficiency. is that reasonable?  \r\n```sh\r\nhorovodrun -np 64 -H xxx:8 xxx:8 xxx:8 xxx:8 xxx:8 xxx:8 xxx:8 xxx:8  python ~/repos/horovod/examples/mxnet_imagenet_resnet50.py --model resnet50_v2 --mode gluon --rec-train ~/data/ILSVRC2012/train.rec --rec-train-idx ~/data/ILSVRC2012/train.idx --rec-val ~/data/ILSVRC2012/val.rec --rec-val-idx ~/data/ILSVRC2012/val.idx --use-rec --batch-size 64 --num-epochs 120 --data-nthreads 2 --warmup-epochs 5 --lr 0.05 --lr-mode step --log-interval 50\r\n```\r\n\r\nmy installation:\r\n```sh\r\nHOROVOD_NCCL_INCLUDE=/usr/local/cuda-10.2/include HOROVOD_NCCL_LIB=/usr/local/cuda-10.2/lib HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL pip install --no-cache-dir horovod\r\n```\r\n\r\ni found similar issue #824 but in my case the data is just on each server's ssd. \r\n \r\n```sh\r\nubuntu@ip-xxx:~$ df -h\r\nFilesystem      Size  Used Avail Use% Mounted on\r\nudev            241G     0  241G   0% /dev\r\ntmpfs            49G  1.1M   49G   1% /run\r\n/dev/xvda1      993G  383G  611G  39% /\r\ntmpfs           241G  1.1G  240G   1% /dev/shm\r\ntmpfs           5.0M     0  5.0M   0% /run/lock\r\ntmpfs           241G     0  241G   0% /sys/fs/cgroup\r\n/dev/loop0       18M   18M     0 100% /snap/amazon-ssm-agent/1480\r\n/dev/loop2       94M   94M     0 100% /snap/core/8935\r\n/dev/loop1       18M   18M     0 100% /snap/amazon-ssm-agent/1566\r\n/dev/loop3       92M   92M     0 100% /snap/core/8689\r\ntmpfs            49G     0   49G   0% /run/user/1000\r\n```\r\n\r\nthe data path is /home/ubuntu/data, which is on /dev/xvda1. \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1865", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1865/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1865/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1865/events", "html_url": "https://github.com/horovod/horovod/issues/1865", "id": 598415395, "node_id": "MDU6SXNzdWU1OTg0MTUzOTU=", "number": 1865, "title": "Deprecation warning due to invalid escape sequences in Python 3.7", "user": {"login": "tirkarthi", "id": 3972343, "node_id": "MDQ6VXNlcjM5NzIzNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3972343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tirkarthi", "html_url": "https://github.com/tirkarthi", "followers_url": "https://api.github.com/users/tirkarthi/followers", "following_url": "https://api.github.com/users/tirkarthi/following{/other_user}", "gists_url": "https://api.github.com/users/tirkarthi/gists{/gist_id}", "starred_url": "https://api.github.com/users/tirkarthi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tirkarthi/subscriptions", "organizations_url": "https://api.github.com/users/tirkarthi/orgs", "repos_url": "https://api.github.com/users/tirkarthi/repos", "events_url": "https://api.github.com/users/tirkarthi/events{/privacy}", "received_events_url": "https://api.github.com/users/tirkarthi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 728479138, "node_id": "MDU6TGFiZWw3Mjg0NzkxMzg=", "url": "https://api.github.com/repos/horovod/horovod/labels/contribution%20welcome", "name": "contribution welcome", "color": "138e05", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-12T05:34:44Z", "updated_at": "2020-04-15T18:12:28Z", "closed_at": "2020-04-15T18:12:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.7\r\n8. OS and version: Linux Ubuntu 18.04\r\n9. GCC version:\r\n\r\n**Bug report:**\r\n\r\nDeprecation warnings are raised due to invalid escape sequences. This can be fixed by using raw strings or escaping the literals.\r\n\r\n```\r\nfind . -iname '*.py' | grep -Ev 'example|utl|samples' | xargs -P 4 -I{} python3.8 -Wall -m py_compile {} \r\n./setup.py:1008: DeprecationWarning: invalid escape sequence \\d\r\n  m = re.match('^(\\d+)(?:\\.(\\d+))?(?:\\.(\\d+))?(?:\\.(\\d+))?', version_str)\r\n./test/test_run.py:332: DeprecationWarning: invalid escape sequence \\.\r\n  exception = 'Neither MPI nor Gloo support has been built\\. Try reinstalling Horovod ensuring that ' \\\r\n./test/test_run.py:333: DeprecationWarning: invalid escape sequence \\(\r\n  'either MPI is installed \\(MPI\\) or CMake is installed \\(Gloo\\)\\.'\r\n./test/test_run.py:322: DeprecationWarning: invalid escape sequence \\.\r\n  exception = '^MPI support has not been built\\.  If this is not expected, ensure MPI is installed ' \\\r\n./test/test_run.py:323: DeprecationWarning: invalid escape sequence \\.\r\n  'and reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error\\.$'\r\n./test/test_run.py:312: DeprecationWarning: invalid escape sequence \\.\r\n  exception = '^MPI support has not been built\\.  If this is not expected, ensure MPI is installed ' \\\r\n./test/test_run.py:313: DeprecationWarning: invalid escape sequence \\.\r\n  'and reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error\\.$'\r\n./test/test_run.py:306: DeprecationWarning: invalid escape sequence \\.\r\n  exception = '^Gloo support has not been built\\.  If this is not expected, ensure CMake is installed ' \\\r\n./test/test_run.py:307: DeprecationWarning: invalid escape sequence \\.\r\n  'and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error\\.$'\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1857", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1857/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1857/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1857/events", "html_url": "https://github.com/horovod/horovod/issues/1857", "id": 597244381, "node_id": "MDU6SXNzdWU1OTcyNDQzODE=", "number": 1857, "title": "When/Why to distribute the epochs?", "user": {"login": "SriramAvatar", "id": 16073195, "node_id": "MDQ6VXNlcjE2MDczMTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/16073195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SriramAvatar", "html_url": "https://github.com/SriramAvatar", "followers_url": "https://api.github.com/users/SriramAvatar/followers", "following_url": "https://api.github.com/users/SriramAvatar/following{/other_user}", "gists_url": "https://api.github.com/users/SriramAvatar/gists{/gist_id}", "starred_url": "https://api.github.com/users/SriramAvatar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SriramAvatar/subscriptions", "organizations_url": "https://api.github.com/users/SriramAvatar/orgs", "repos_url": "https://api.github.com/users/SriramAvatar/repos", "events_url": "https://api.github.com/users/SriramAvatar/events{/privacy}", "received_events_url": "https://api.github.com/users/SriramAvatar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-09T12:23:10Z", "updated_at": "2020-04-16T06:48:49Z", "closed_at": "2020-04-16T06:48:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "** Epochs :**\r\n As I understand, horovod does a training based on data parallelism, every node trains on the different set of data. When a node trains on a subset of data, I assume all the epochs should happen on the same node. \r\nI see in some samples that the epochs are distributed too. Why is this?\r\n\r\n`# Horovod: adjust number of epochs based on number of GPUs.#Check\r\nhvd_epochs = int(math.ceil(param_epochs/ hvd.size()))`\r\n\r\nWhen will one distribute the epochs and not? May be I am missing some fundamental concept. Thanks for explaining.\r\n\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1853", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1853/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1853/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1853/events", "html_url": "https://github.com/horovod/horovod/issues/1853", "id": 596695463, "node_id": "MDU6SXNzdWU1OTY2OTU0NjM=", "number": 1853, "title": "Typo in install documentation?", "user": {"login": "chaaland", "id": 5944266, "node_id": "MDQ6VXNlcjU5NDQyNjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/5944266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chaaland", "html_url": "https://github.com/chaaland", "followers_url": "https://api.github.com/users/chaaland/followers", "following_url": "https://api.github.com/users/chaaland/following{/other_user}", "gists_url": "https://api.github.com/users/chaaland/gists{/gist_id}", "starred_url": "https://api.github.com/users/chaaland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chaaland/subscriptions", "organizations_url": "https://api.github.com/users/chaaland/orgs", "repos_url": "https://api.github.com/users/chaaland/repos", "events_url": "https://api.github.com/users/chaaland/events{/privacy}", "received_events_url": "https://api.github.com/users/chaaland/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 730732849, "node_id": "MDU6TGFiZWw3MzA3MzI4NDk=", "url": "https://api.github.com/repos/horovod/horovod/labels/update%20docs", "name": "update docs", "color": "78ed92", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-08T16:11:42Z", "updated_at": "2020-04-08T23:59:31Z", "closed_at": "2020-04-08T23:59:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nIn horovod/docs/install there are several references to variables of the form `HOROVOOD_WITHOUT_*`. Is the double O intended?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1851", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1851/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1851/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1851/events", "html_url": "https://github.com/horovod/horovod/issues/1851", "id": 596525497, "node_id": "MDU6SXNzdWU1OTY1MjU0OTc=", "number": 1851, "title": "Docker example fails", "user": {"login": "ilmarkov", "id": 8823584, "node_id": "MDQ6VXNlcjg4MjM1ODQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/8823584?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilmarkov", "html_url": "https://github.com/ilmarkov", "followers_url": "https://api.github.com/users/ilmarkov/followers", "following_url": "https://api.github.com/users/ilmarkov/following{/other_user}", "gists_url": "https://api.github.com/users/ilmarkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilmarkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilmarkov/subscriptions", "organizations_url": "https://api.github.com/users/ilmarkov/orgs", "repos_url": "https://api.github.com/users/ilmarkov/repos", "events_url": "https://api.github.com/users/ilmarkov/events{/privacy}", "received_events_url": "https://api.github.com/users/ilmarkov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "abditag2", "id": 2999450, "node_id": "MDQ6VXNlcjI5OTk0NTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2999450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abditag2", "html_url": "https://github.com/abditag2", "followers_url": "https://api.github.com/users/abditag2/followers", "following_url": "https://api.github.com/users/abditag2/following{/other_user}", "gists_url": "https://api.github.com/users/abditag2/gists{/gist_id}", "starred_url": "https://api.github.com/users/abditag2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abditag2/subscriptions", "organizations_url": "https://api.github.com/users/abditag2/orgs", "repos_url": "https://api.github.com/users/abditag2/repos", "events_url": "https://api.github.com/users/abditag2/events{/privacy}", "received_events_url": "https://api.github.com/users/abditag2/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-04-08T12:02:30Z", "updated_at": "2020-04-23T23:25:58Z", "closed_at": "2020-04-23T23:25:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Any of frameworks\r\n2. Framework version:\r\n3. Horovod version: 0.19.1\r\n4. MPI version: 3.0.0\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.4.7-1+cuda10.0\r\n7. Python version: 2.7\r\n8. OS and version: ubuntu16.04\r\n9. GCC version: g++-2.8\r\n\r\n**Bug report:**\r\n\r\nI build a docker image of the latest horovod sources from Dockerfile.test.gpu with a slight addition to support ssh (took a couple of lines installing OpenSSH-server from Dockerfile.gpu).\r\nRunning training on a single node inside a docker container worked perfectly.\r\nThen started 2 containers on separate machines following instructions in [documentation](https://github.com/horovod/horovod/blob/master/docs/docker.rst#running-on-multiple-machines). Passwordless ssh was established.\r\n\r\nThe issues are two-fold.\r\nThe first one looked like a typo [here](https://github.com/horovod/horovod/blob/master/horovod/run/driver/driver_service.py#L148). \"Settings doesn't have attribute nic\". There must be \"nics\".\r\n\r\nWhen I fixed it, the second problem came out.\r\nI'm trying to on host1 with following line:\r\n` horovodrun -np 4 -H localhost:2,host2:2 -p 1234 python pytorch_synthetic_benchmark.py`\r\nIt looks similar to issues #975, #971. Though, the error messages says it can't connect not to remote servers but to localhost:\r\n`horovod.run.common.util.network.NoValidAddressesFound: Horovod was unable to connect to horovod driver service on any of the following addresses: {'lo': [('127.0.0.1', 18524)], 'docker0': [('localhost_int_ip', 18524)], 'eno1': [('localhost_ip, 18524)]}.`\r\nAnd following error traceback:\r\n```\r\n self.RequestHandlerClass(request, client_address, self)\r\n  File \"/usr/lib/python2.7/SocketServer.py\", line 652, in __init__\r\n    self.handle()\r\n  File \"/usr/local/lib/python2.7/dist-packages/horovod/run/common/util/network.py\", line 107, in h$ndle\r\n    req = server._wire.read(self.rfile)\r\n  File \"/usr/local/lib/python2.7/dist-packages/horovod/run/common/util/network.py\", line 80, in re$d\r\n    message_len = struct.unpack('i', rfile.read(4))[0]\r\nerror: unpack requires a string argument of length 4\r\n```\r\nWhen I try to run the following way:\r\n` horovodrun -np 4 -H host1:2,host2:2 -p 1234 python pytorch_synthetic_benchmark.py`\r\nIt fails with following error:\r\n`ssh: connect to host host1 port 1234: Connection refused`. Though, documentation doesn't state \r\nto run ssh in container starting the training. When I start `sshd` on host1 the problem described above comes out.\r\n\r\nBuilding docker image not from sources, but using Dockerfile.gpu, everything works fine. So there must be a problem with a current version.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1850", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1850/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1850/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1850/events", "html_url": "https://github.com/horovod/horovod/issues/1850", "id": 596477586, "node_id": "MDU6SXNzdWU1OTY0Nzc1ODY=", "number": 1850, "title": "ORTE does not know how to route a message to the specified daemon", "user": {"login": "MenglingD", "id": 9418558, "node_id": "MDQ6VXNlcjk0MTg1NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/9418558?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MenglingD", "html_url": "https://github.com/MenglingD", "followers_url": "https://api.github.com/users/MenglingD/followers", "following_url": "https://api.github.com/users/MenglingD/following{/other_user}", "gists_url": "https://api.github.com/users/MenglingD/gists{/gist_id}", "starred_url": "https://api.github.com/users/MenglingD/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MenglingD/subscriptions", "organizations_url": "https://api.github.com/users/MenglingD/orgs", "repos_url": "https://api.github.com/users/MenglingD/repos", "events_url": "https://api.github.com/users/MenglingD/events{/privacy}", "received_events_url": "https://api.github.com/users/MenglingD/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-08T10:34:25Z", "updated_at": "2020-07-10T04:49:58Z", "closed_at": "2020-04-10T09:00:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) mxnet\r\n2. Framework version: 1.6.0\r\n3. Horovod version: 0.19.0\r\n4. MPI version: 4.0.1\r\n5. CUDA version: 10.0.130\r\n6. NCCL version: 2.4.8\r\n7. Python version: 3.6.9\r\n8. OS and version: ubuntu18.04\r\n9. GCC version: 7.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n[https://github.com/horovod/horovod/issues/504](https://github.com/horovod/horovod/issues/504)\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\n\r\nI got the same situation with mpirun prompt: ORTE does not know how to route a message to the specified daemon\uff0clike issue: [https://github.com/horovod/horovod/issues/504](https://github.com/horovod/horovod/issues/504)\r\n\r\nThe training enviroment is based on docker in k8s\uff0cand all nodes can connected each other with ssh which allows passwordless authentication. And I have already check the connection between all nodes manually in master-node, even the connection between worker-nodes.\r\n\r\nBy the way, I run horovod with open mpi\uff0cand the [Hangs due to non-routed network interfaces](https://horovod.readthedocs.io/en/latest/mpirun.html) is handle by specify the network interfaces\uff0cthe startup command is :\r\n```bash\r\nmpirun --allow-run-as-root --np 160 \\\r\n    --hostfile /tmp/hostfile \\\r\n    -bind-to none -map-by slot \\\r\n    -x NCCL_IB_DISABLE=1 \\\r\n    -x NCCL_DEBUG=INFO \\\r\n    -x PYTHONPATH=/opt/incubator-mxnet/python \\\r\n    -x MXNET_CUDNN_AUTOTUNE_DEFAULT=0 \\\r\n    -x NCCL_SOCKET_IFNAME=eth0 -mca pml ob1 \\\r\n    -mca btl ^openib -mca btl_tcp_if_include eth0 python3 tools/train_softmax.py --network resnet18_v2 --dummy-data --horovod  --epochs 5 --save-prefix models/resnet50_v2_dummy --sw-dir logs_sw --num-classes 1000 --batch-size 40960 --dtype float32 2>&1 | tee /mnt/save/logs/vc-hvd-resnet18-v2-lbs256-float32-np160.log\r\n```\r\nIn addition, the eth0 is the only network interface that can find in container except `lo`, and I have tried replace the `eth0` with `docker0`, but I got the same error output:\r\n```bash\r\nWarning: Permanently added 'vc-hvd-resnet18-v2-lbs256-float32-np160-mpiworker-7.vc-hvd-resnet18-v2-lbs256-float32-np160,192.168.216.45' (ECDSA) to the list of known hosts.\r\nWarning: Permanently added 'vc-hvd-resnet18-v2-lbs256-float32-np160-mpiworker-10.vc-hvd-resnet18-v2-lbs256-float32-np160,192.168.58.40' (ECDSA) to the list of known hosts.\r\n--------------------------------------------------------------------------\r\nORTE has lost communication with a remote daemon.\r\n\r\n  HNP daemon   : [[55929,0],0] on node vc-hvd-resnet18-v2-lbs256-float32-np160-mpimaster-0\r\n  Remote daemon: [[55929,0],11] on node vc-hvd-resnet18-v2-lbs256-float32-np160-mpiworker-10\r\n\r\nThis is usually due to either a failure of the TCP network\r\nconnection to the node, or possibly an internal failure of\r\nthe daemon itself. We cannot recover from this failure, and\r\ntherefore will terminate the job.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nORTE does not know how to route a message to the specified daemon\r\nlocated on the indicated node:\r\n\r\n  my node:   vc-hvd-resnet18-v2-lbs256-float32-np160-mpimaster-0\r\n  target node:  vc-hvd-resnet18-v2-lbs256-float32-np160-mpiworker-0\r\n\r\nThis is usually an internal programming error that should be\r\nreported to the developers. In the meantime, a workaround may\r\nbe to set the MCA param routed=direct on the command line or\r\nin your environment. We apologize for the problem.\r\n--------------------------------------------------------------------------\r\n[vc-hvd-resnet18-v2-lbs256-float32-np160-mpimaster-0:02871] 18 more processes have sent help message help-errmgr-base.txt / no-path\r\n[vc-hvd-resnet18-v2-lbs256-float32-np160-mpimaster-0:02871] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\r\n```\r\nWhat surprised me is that the training program can corrected start and execute when the number of node is less\uff0cbut the process of training is always stuck when the number of node more.\r\n\r\nThe error information seems to imply that the part of nodes can not connected, but I have checked all connection between all nodes like said above. \r\n\r\nSo is there anyone can do me a  favour\uff0cor some advice to dive the reason of this situation?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1843", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1843/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1843/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1843/events", "html_url": "https://github.com/horovod/horovod/issues/1843", "id": 593534090, "node_id": "MDU6SXNzdWU1OTM1MzQwOTA=", "number": 1843, "title": "Running tensorflow 2 official models with horovod", "user": {"login": "kingwales1", "id": 63086433, "node_id": "MDQ6VXNlcjYzMDg2NDMz", "avatar_url": "https://avatars3.githubusercontent.com/u/63086433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kingwales1", "html_url": "https://github.com/kingwales1", "followers_url": "https://api.github.com/users/kingwales1/followers", "following_url": "https://api.github.com/users/kingwales1/following{/other_user}", "gists_url": "https://api.github.com/users/kingwales1/gists{/gist_id}", "starred_url": "https://api.github.com/users/kingwales1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kingwales1/subscriptions", "organizations_url": "https://api.github.com/users/kingwales1/orgs", "repos_url": "https://api.github.com/users/kingwales1/repos", "events_url": "https://api.github.com/users/kingwales1/events{/privacy}", "received_events_url": "https://api.github.com/users/kingwales1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-03T17:31:06Z", "updated_at": "2020-05-23T03:50:14Z", "closed_at": "2020-05-23T03:50:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) Tensorflow\r\n2. Framework version: 2.0\r\n3. Horovod version: latest\r\n4. MPI version: 4.0\r\n5. CUDA version: 10.1\r\n6. NCCL version:\r\n7. Python version: 3.7\r\n8. OS and version: Ubuntu 16.04\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nI have successfully set up the distributed environment and run the example with Horovod. And I also know that if I want to run the benchmark on TensorFlow 1 in a distributed setup, e.g. 4 nodes, following the tutorial, the submission should be:\r\n\r\n$ horovodrun -np 16 -H server1:4,server2:4,server3:4,server4:4 \\\r\n    python scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \\\r\n        --model resnet101 \\\r\n        --batch_size 64 \\\r\n        --variable_update horovod \\\r\n        --data_dir /path/to/imagenet/tfrecords \\\r\n        --data_name imagenet \\\r\n        --num_batches=2000\r\n\r\nBut now I want to run the TensorFlow 2 [official models](https://github.com/tensorflow/models), for example BERT model. What command should I use? is it the same as tensorflow 1? Does horovod support the tensorflow 2 official models?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1842", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1842/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1842/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1842/events", "html_url": "https://github.com/horovod/horovod/issues/1842", "id": 593250876, "node_id": "MDU6SXNzdWU1OTMyNTA4NzY=", "number": 1842, "title": "Horovod with Tensorflow", "user": {"login": "Victorsoukhov", "id": 11825470, "node_id": "MDQ6VXNlcjExODI1NDcw", "avatar_url": "https://avatars2.githubusercontent.com/u/11825470?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Victorsoukhov", "html_url": "https://github.com/Victorsoukhov", "followers_url": "https://api.github.com/users/Victorsoukhov/followers", "following_url": "https://api.github.com/users/Victorsoukhov/following{/other_user}", "gists_url": "https://api.github.com/users/Victorsoukhov/gists{/gist_id}", "starred_url": "https://api.github.com/users/Victorsoukhov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Victorsoukhov/subscriptions", "organizations_url": "https://api.github.com/users/Victorsoukhov/orgs", "repos_url": "https://api.github.com/users/Victorsoukhov/repos", "events_url": "https://api.github.com/users/Victorsoukhov/events{/privacy}", "received_events_url": "https://api.github.com/users/Victorsoukhov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}, {"id": 730732849, "node_id": "MDU6TGFiZWw3MzA3MzI4NDk=", "url": "https://api.github.com/repos/horovod/horovod/labels/update%20docs", "name": "update docs", "color": "78ed92", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-03T09:35:07Z", "updated_at": "2020-04-08T23:59:31Z", "closed_at": "2020-04-08T23:59:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\nDocumentation information\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nPlease ask your question here.\r\nThere is no information on the link https://github.com/horovod/horovod/blob/master/docs/tensorflow.rst\r\n\r\nPlease Provide.\r\n\r\nThank you!\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1841", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1841/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1841/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1841/events", "html_url": "https://github.com/horovod/horovod/issues/1841", "id": 592750110, "node_id": "MDU6SXNzdWU1OTI3NTAxMTA=", "number": 1841, "title": "Dataset distribution", "user": {"login": "anweshpanda", "id": 60091167, "node_id": "MDQ6VXNlcjYwMDkxMTY3", "avatar_url": "https://avatars0.githubusercontent.com/u/60091167?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anweshpanda", "html_url": "https://github.com/anweshpanda", "followers_url": "https://api.github.com/users/anweshpanda/followers", "following_url": "https://api.github.com/users/anweshpanda/following{/other_user}", "gists_url": "https://api.github.com/users/anweshpanda/gists{/gist_id}", "starred_url": "https://api.github.com/users/anweshpanda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anweshpanda/subscriptions", "organizations_url": "https://api.github.com/users/anweshpanda/orgs", "repos_url": "https://api.github.com/users/anweshpanda/repos", "events_url": "https://api.github.com/users/anweshpanda/events{/privacy}", "received_events_url": "https://api.github.com/users/anweshpanda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-02T16:09:32Z", "updated_at": "2020-04-15T18:15:23Z", "closed_at": "2020-04-15T18:15:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi\r\nI have my own dataset and I am using horovod with pytorch. I want to distribute my dataset among all the processors uniformly so that I can do distributed training. So can anyone please help , how can I do that?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1840", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1840/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1840/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1840/events", "html_url": "https://github.com/horovod/horovod/issues/1840", "id": 592656892, "node_id": "MDU6SXNzdWU1OTI2NTY4OTI=", "number": 1840, "title": "load and pre-process training data when doing the sync of weight", "user": {"login": "Leslie-Fang", "id": 16850179, "node_id": "MDQ6VXNlcjE2ODUwMTc5", "avatar_url": "https://avatars2.githubusercontent.com/u/16850179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Leslie-Fang", "html_url": "https://github.com/Leslie-Fang", "followers_url": "https://api.github.com/users/Leslie-Fang/followers", "following_url": "https://api.github.com/users/Leslie-Fang/following{/other_user}", "gists_url": "https://api.github.com/users/Leslie-Fang/gists{/gist_id}", "starred_url": "https://api.github.com/users/Leslie-Fang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Leslie-Fang/subscriptions", "organizations_url": "https://api.github.com/users/Leslie-Fang/orgs", "repos_url": "https://api.github.com/users/Leslie-Fang/repos", "events_url": "https://api.github.com/users/Leslie-Fang/events{/privacy}", "received_events_url": "https://api.github.com/users/Leslie-Fang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-02T14:01:41Z", "updated_at": "2020-04-03T01:38:24Z", "closed_at": "2020-04-03T01:38:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi All, I am using horovod with TF. Since my dataset is little bit larger. When I am using horovod to do the training among the CPU cluster. After each training step, horovod would sync the data among the system with ring-allreduce. \r\nMy question is that, is it possible for the worker to load and pre-process the training data for next step when sync the weights of current training step among the worker.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1838", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1838/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1838/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1838/events", "html_url": "https://github.com/horovod/horovod/issues/1838", "id": 591776438, "node_id": "MDU6SXNzdWU1OTE3NzY0Mzg=", "number": 1838, "title": "cuda runtime error - device not ready", "user": {"login": "rudvlf0413", "id": 6302455, "node_id": "MDQ6VXNlcjYzMDI0NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/6302455?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rudvlf0413", "html_url": "https://github.com/rudvlf0413", "followers_url": "https://api.github.com/users/rudvlf0413/followers", "following_url": "https://api.github.com/users/rudvlf0413/following{/other_user}", "gists_url": "https://api.github.com/users/rudvlf0413/gists{/gist_id}", "starred_url": "https://api.github.com/users/rudvlf0413/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rudvlf0413/subscriptions", "organizations_url": "https://api.github.com/users/rudvlf0413/orgs", "repos_url": "https://api.github.com/users/rudvlf0413/repos", "events_url": "https://api.github.com/users/rudvlf0413/events{/privacy}", "received_events_url": "https://api.github.com/users/rudvlf0413/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-01T09:40:28Z", "updated_at": "2020-07-08T11:28:57Z", "closed_at": "2020-07-08T10:36:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: PyTorch\r\n2. Framework version: 1.4\r\n3. Horovod version: 0.19.1\r\n4. MPI version: OpenMPI 4.0.2\r\n5. CUDA version: 10.1\r\n6. NCCL version: 2.6\r\n7. Python version: 3.7.7\r\n8. OS and version: \r\n9. GCC version:\r\n\r\nI got an error link:\r\nTHCudaCheck FAIL file=horovod/torch/ready_event.cc line=94 error=600 : device not ready\r\n\r\nAnd the full logs are:\r\n\r\n```\r\n[1,1]<stderr>:THCudaCheck FAIL file=horovod/torch/ready_event.cc line=94 error=600 : device not ready\r\n[1,1]<stderr>:terminate called after throwing an instance of 'std::runtime_error'\r\n[1,1]<stderr>:  what():  [1,1]<stderr>:cuda runtime error (600) : device not ready at horovod/torch/ready_event.cc:94\r\n[1,1]<stderr>:[davian-black:20982] *** Process received signal ***\r\n[1,1]<stderr>:[davian-black:20982] Signal: Aborted (6)\r\n[1,1]<stderr>:[davian-black:20982] Signal code:  (-6)\r\n[1,1]<stderr>:[davian-black:20982] [ 0] [1,1]<stderr>:/lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7f13a97ed390]\r\n[1,1]<stderr>:[davian-black:20982] [ 1] [1,1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38)[0x7f13a9447428]\r\n[1,1]<stderr>:[davian-black:20982] [ 2] [1,1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(abort+0x16a)[0x7f13a944902a]\r\n[1,1]<stderr>:[davian-black:20982] [ 3] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/torch/../../../libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xbc)[0x7f139a2e384a]\r\n[1,1]<stderr>:[davian-black:20982] [ 4] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/torch/../../../libstdc++.so.6(+0xabf47)[0x7f139a2e1f47]\r\n[1,1]<stderr>:[davian-black:20982] [ 5] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/torch/../../../libstdc++.so.6(+0xabf7d)[0x7f139a2e1f7d]\r\n[1,1]<stderr>:[davian-black:20982] [ 6] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/torch/../../../libstdc++.so.6(__cxa_rethrow+0x0)[0x7f139a2e215a]\r\n[1,1]<stderr>:[davian-black:20982] [ 7] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch.so(+0x1c4c0b7)[0x7f136c2140b7]\r\n[1,1]<stderr>:[davian-black:20982] [ 8] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch.so(+0x1c4c31f)[0x7f136c21431f]\r\n[1,1]<stderr>:[davian-black:20982] [ 9] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch.so(__THCudaCheck+0x3b)[0x7f136e82f5cb]\r\n[1,1]<stderr>:[davian-black:20982] [10] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so(_ZNK7horovod5torch15TorchReadyEvent5ReadyEv+0x29)[0x7f133fa7a3a9]\r\n[1,1]<stderr>:[davian-black:20982] [11] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/horovod/torch/mpi_lib_v2.cpython-37m-x86_64-linux-gnu.so(+0x7a9cc)[0x7f133f9f69cc]\r\n[1,1]<stderr>:[davian-black:20982] [12] [1,1]<stderr>:/home/rudvlf0413/anaconda3/lib/python3.7/site-packages/torch/../../../libstdc++.so.6(+0xc819d)[0x7f139a2fe19d]\r\n[1,1]<stderr>:[davian-black:20982] [13] /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba)[0x7f13a97e36ba]\r\n[1,1]<stderr>:[davian-black:20982] [14] [1,1]<stderr>:/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f13a951941d]\r\n[1,1]<stderr>:[davian-black:20982] *** End of error message ***\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun noticed that process rank 1 with PID 0 on node davian-black exited on signal 6 (Aborted).\r\n```\r\n\r\n\r\nI don't know how to solve this problem... Do you know how to solve?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1834", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1834/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1834/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1834/events", "html_url": "https://github.com/horovod/horovod/issues/1834", "id": 590054135, "node_id": "MDU6SXNzdWU1OTAwNTQxMzU=", "number": 1834, "title": "Error while trying to run on more than 4 CPU cores", "user": {"login": "anweshpanda", "id": 60091167, "node_id": "MDQ6VXNlcjYwMDkxMTY3", "avatar_url": "https://avatars0.githubusercontent.com/u/60091167?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anweshpanda", "html_url": "https://github.com/anweshpanda", "followers_url": "https://api.github.com/users/anweshpanda/followers", "following_url": "https://api.github.com/users/anweshpanda/following{/other_user}", "gists_url": "https://api.github.com/users/anweshpanda/gists{/gist_id}", "starred_url": "https://api.github.com/users/anweshpanda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anweshpanda/subscriptions", "organizations_url": "https://api.github.com/users/anweshpanda/orgs", "repos_url": "https://api.github.com/users/anweshpanda/repos", "events_url": "https://api.github.com/users/anweshpanda/events{/privacy}", "received_events_url": "https://api.github.com/users/anweshpanda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-03-30T07:21:30Z", "updated_at": "2020-03-31T17:41:26Z", "closed_at": "2020-03-31T17:41:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi\r\nI am using horovod with pytorch and trying to run the pytorch_mnist.py which is an example given .\r\nI am able to run in successfully for number of cpu cores<=4 by using the command :\r\nhorovodrun -np 4   python pytorch_mnist.py\r\nHowever while trying to run on more than 4 cpu cores I am getting the following error:\r\n```\r\n\r\n2020-03-30 12:44:09.734470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\n2020-03-30 12:44:11.967031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7\r\n2020-03-30 12:44:11.970411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.7\r\n[1,4]<stdout>:Using downloaded and verified file: data-4/MNIST/raw/train-images-idx3-ubyte.gz\r\n[1,4]<stdout>:Extracting data-4/MNIST/raw/train-images-idx3-ubyte.gz to data-4/MNIST/raw\r\n[1,0]<stderr>:Traceback (most recent call last):\r\n[1,0]<stderr>:  File \"pytorch_mnist.py\", line 127, in <module>\r\n[1,0]<stderr>:    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n[1,0]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/__init__.py\", line 470, in broadcast_parameters\r\n[1,0]<stderr>:    handle = broadcast_async_(p, root_rank, name)\r\n[1,0]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 433, in broadcast_async_\r\n[1,0]<stderr>:    return _broadcast_async(tensor, tensor, root_rank, name)\r\n[1,0]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 343, in _broadcast_async\r\n[1,0]<stderr>:    tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\n[1,0]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[1,1]<stderr>:Traceback (most recent call last):\r\n[1,1]<stderr>:  File \"pytorch_mnist.py\", line 127, in <module>\r\n[1,1]<stderr>:    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n[1,1]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/__init__.py\", line 470, in broadcast_parameters\r\n[1,1]<stderr>:    handle = broadcast_async_(p, root_rank, name)\r\n[1,1]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 433, in broadcast_async_\r\n[1,1]<stderr>:    return _broadcast_async(tensor, tensor, root_rank, name)\r\n[1,1]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 343, in _broadcast_async\r\n[1,1]<stderr>:    tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\n[1,1]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[1,2]<stderr>:Traceback (most recent call last):\r\n[1,2]<stderr>:  File \"pytorch_mnist.py\", line 127, in <module>\r\n[1,2]<stderr>:    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n[1,2]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/__init__.py\", line 470, in broadcast_parameters\r\n[1,2]<stderr>:    handle = broadcast_async_(p, root_rank, name)\r\n[1,2]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 433, in broadcast_async_\r\n[1,2]<stderr>:    return _broadcast_async(tensor, tensor, root_rank, name)\r\n[1,2]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 343, in _broadcast_async\r\n[1,2]<stderr>:    tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\n[1,2]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[1,3]<stderr>:Traceback (most recent call last):\r\n[1,3]<stderr>:  File \"pytorch_mnist.py\", line 127, in <module>\r\n[1,3]<stderr>:    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\r\n[1,3]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/__init__.py\", line 470, in broadcast_parameters\r\n[1,3]<stderr>:    handle = broadcast_async_(p, root_rank, name)\r\n[1,3]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 433, in broadcast_async_\r\n[1,3]<stderr>:    return _broadcast_async(tensor, tensor, root_rank, name)\r\n[1,3]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/horovod/torch/mpi_ops.py\", line 343, in _broadcast_async\r\n[1,3]<stderr>:    tensor, output, root_rank, name.encode() if name is not None else _NULL)\r\n[1,3]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\r\n[1,4]<stderr>:Traceback (most recent call last):\r\n[1,4]<stderr>:  File \"pytorch_mnist.py\", line 71, in <module>\r\n[1,4]<stderr>:    transforms.Normalize((0.1307,), (0.3081,))\r\n[1,4]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torchvision/datasets/mnist.py\", line 68, in __init__\r\n[1,4]<stderr>:    self.download()\r\n[1,4]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torchvision/datasets/mnist.py\", line 135, in download\r\n[1,4]<stderr>:    download_and_extract_archive(url, download_root=self.raw_folder, filename=filename)\r\n[1,4]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torchvision/datasets/utils.py\", line 252, in download_and_extract_archive\r\n[1,4]<stderr>:    extract_archive(archive, extract_root, remove_finished)\r\n[1,4]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/site-packages/torchvision/datasets/utils.py\", line 229, in extract_archive\r\n[1,4]<stderr>:    out_f.write(zip_f.read())\r\n[1,4]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/gzip.py\", line 287, in read\r\n[1,4]<stderr>:    return self._buffer.read(size)\r\n[1,4]<stderr>:  File \"/home/mas/20/cdsanwesk/miniconda3/envs/fresh_env/lib/python3.7/gzip.py\", line 493, in read\r\n[1,4]<stderr>:    raise EOFError(\"Compressed file ended before the \"\r\n[1,4]<stderr>:EOFError: Compressed file ended before the end-of-stream marker was reached\r\n--------------------------------------------------------------------------\r\nPrimary job  terminated normally, but 1 process returned\r\na non-zero exit code. Per user-direction, the job has been aborted.\r\n--------------------------------------------------------------------------\r\n--------------------------------------------------------------------------\r\nmpirun detected that one or more processes exited with non-zero status, thus causing\r\nthe job to be terminated. The first process to do so was:\r\n\r\n  Process name: [[42246,1],1]\r\n  Exit code:    1\r\n--------------------------------------------------------------------------\r\n\r\n```\r\n\r\nCan anyone please help?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1832", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1832/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1832/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1832/events", "html_url": "https://github.com/horovod/horovod/issues/1832", "id": 589232287, "node_id": "MDU6SXNzdWU1ODkyMzIyODc=", "number": 1832, "title": "Unable to build Horovod without CUDA support", "user": {"login": "adamjstewart", "id": 12021217, "node_id": "MDQ6VXNlcjEyMDIxMjE3", "avatar_url": "https://avatars2.githubusercontent.com/u/12021217?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adamjstewart", "html_url": "https://github.com/adamjstewart", "followers_url": "https://api.github.com/users/adamjstewart/followers", "following_url": "https://api.github.com/users/adamjstewart/following{/other_user}", "gists_url": "https://api.github.com/users/adamjstewart/gists{/gist_id}", "starred_url": "https://api.github.com/users/adamjstewart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adamjstewart/subscriptions", "organizations_url": "https://api.github.com/users/adamjstewart/orgs", "repos_url": "https://api.github.com/users/adamjstewart/repos", "events_url": "https://api.github.com/users/adamjstewart/events{/privacy}", "received_events_url": "https://api.github.com/users/adamjstewart/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-03-27T15:56:45Z", "updated_at": "2020-03-30T20:17:12Z", "closed_at": "2020-03-30T20:17:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n\r\n1. Framework: Tensorflow\r\n2. Framework version: 2.1.0\r\n3. Horovod version: 0.19.1, master\r\n4. MPI version: OpenMPI 3.1.5\r\n5. CUDA version: N/A\r\n6. NCCL version: N/A\r\n7. Python version: 3.7.6\r\n8. OS and version: macOS 10.15.3\r\n9. GCC version: Clang 11.0.3\r\n\r\n**Bug report:**\r\n\r\nI'm trying to build Horovod on my laptop, which does not have CUDA support, but the installation fails with the following error message:\r\n```\r\nbuild/temp.macosx-10.15.3-x86_64-3.7/test_compile/test_cuda.cc:1:10: fatal error: 'cuda_runtime.h' file not found\r\n#include <cuda_runtime.h>\r\n         ^~~~~~~~~~~~~~~~\r\n1 error generated.\r\nerror: CUDA library was not found (see error above).\r\nPlease specify correct CUDA location with the HOROVOD_CUDA_HOME environment variable or combination of HOROVOD_CUDA_INCLUDE and HOROVOD_CUDA_LIB environment variables.\r\n\r\nHOROVOD_CUDA_HOME - path where CUDA include and lib directories can be found\r\nHOROVOD_CUDA_INCLUDE - path to CUDA include directory\r\nHOROVOD_CUDA_LIB - path to CUDA lib directory\r\n```\r\nIs it not possible to build Horovod without CUDA support?\r\n\r\nHere is my build log and environment:\r\n\r\n* [spack-build-out.txt](https://github.com/horovod/horovod/files/4394576/spack-build-out.txt)\r\n* [spack-build-env.txt](https://github.com/horovod/horovod/files/4394577/spack-build-env.txt)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1825", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1825/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1825/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1825/events", "html_url": "https://github.com/horovod/horovod/issues/1825", "id": 588518897, "node_id": "MDU6SXNzdWU1ODg1MTg4OTc=", "number": 1825, "title": "Horovod in GPU-CPU nodes", "user": {"login": "pattasiago", "id": 9504969, "node_id": "MDQ6VXNlcjk1MDQ5Njk=", "avatar_url": "https://avatars3.githubusercontent.com/u/9504969?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pattasiago", "html_url": "https://github.com/pattasiago", "followers_url": "https://api.github.com/users/pattasiago/followers", "following_url": "https://api.github.com/users/pattasiago/following{/other_user}", "gists_url": "https://api.github.com/users/pattasiago/gists{/gist_id}", "starred_url": "https://api.github.com/users/pattasiago/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pattasiago/subscriptions", "organizations_url": "https://api.github.com/users/pattasiago/orgs", "repos_url": "https://api.github.com/users/pattasiago/repos", "events_url": "https://api.github.com/users/pattasiago/events{/privacy}", "received_events_url": "https://api.github.com/users/pattasiago/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-26T15:42:03Z", "updated_at": "2020-03-26T19:35:34Z", "closed_at": "2020-03-26T19:35:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is it possible to distribute pytorch/tensorflow training in heterogeneous nodes, i.e, for 2 nodes, one using cpu and the other one using gpu.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1823", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1823/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1823/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1823/events", "html_url": "https://github.com/horovod/horovod/issues/1823", "id": 588488801, "node_id": "MDU6SXNzdWU1ODg0ODg4MDE=", "number": 1823, "title": "error while trying to install horovod in conda", "user": {"login": "anweshpanda", "id": 60091167, "node_id": "MDQ6VXNlcjYwMDkxMTY3", "avatar_url": "https://avatars0.githubusercontent.com/u/60091167?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anweshpanda", "html_url": "https://github.com/anweshpanda", "followers_url": "https://api.github.com/users/anweshpanda/followers", "following_url": "https://api.github.com/users/anweshpanda/following{/other_user}", "gists_url": "https://api.github.com/users/anweshpanda/gists{/gist_id}", "starred_url": "https://api.github.com/users/anweshpanda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anweshpanda/subscriptions", "organizations_url": "https://api.github.com/users/anweshpanda/orgs", "repos_url": "https://api.github.com/users/anweshpanda/repos", "events_url": "https://api.github.com/users/anweshpanda/events{/privacy}", "received_events_url": "https://api.github.com/users/anweshpanda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-26T15:02:09Z", "updated_at": "2020-03-31T13:31:31Z", "closed_at": "2020-03-27T12:31:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "So I am trying to install horovod using the command pip install horovod and getting the following error. Can anyone please help?\r\n\r\n\r\n\r\nCollecting horovod\r\n  Using cached horovod-0.19.1.tar.gz (2.9 MB)\r\nRequirement already satisfied: cloudpickle in /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/lib/python3.7/site-packages (from horovod) (1.3.0)\r\nRequirement already satisfied: psutil in /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/lib/python3.7/site-packages (from horovod) (5.7.0)\r\nRequirement already satisfied: pyyaml in /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/lib/python3.7/site-packages (from horovod) (5.3.1)\r\nRequirement already satisfied: six in /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/lib/python3.7/site-packages (from horovod) (1.14.0)\r\nRequirement already satisfied: cffi>=1.4.0 in /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/lib/python3.7/site-packages (from horovod) (1.14.0)\r\nRequirement already satisfied: pycparser in /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/lib/python3.7/site-packages (from cffi>=1.4.0->horovod) (2.20)\r\nBuilding wheels for collected packages: horovod\r\n  Building wheel for horovod (setup.py) ... error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-nl555q7w/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-nl555q7w/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-zjuvfsbg\r\n       cwd: /tmp/pip-install-nl555q7w/horovod/\r\n  Complete output (121 lines):\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-3.7\r\n  creating build/lib.linux-x86_64-3.7/horovod\r\n  copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark\r\n  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n  creating build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n  creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n  creating build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n  creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n  creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n  copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n  creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n  running build_ext\r\n  /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/x86_64-conda_cos6-linux-gnu-cc -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mavx -I/home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  x86_64-conda_cos6-linux-gnu-cc: error trying to exec 'cc1plus': execvp: No such file or directory\r\n  /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/x86_64-conda_cos6-linux-gnu-cc -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -stdlib=libc++ -mavx -I/home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  x86_64-conda_cos6-linux-gnu-cc: error: unrecognized command line option '-stdlib=libc++'\r\n  /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/x86_64-conda_cos6-linux-gnu-cc -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -I/home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  x86_64-conda_cos6-linux-gnu-cc: error trying to exec 'cc1plus': execvp: No such file or directory\r\n  /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/x86_64-conda_cos6-linux-gnu-cc -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -stdlib=libc++ -I/home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n  x86_64-conda_cos6-linux-gnu-cc: error: unrecognized command line option '-stdlib=libc++'\r\n  error: Unable to determine C++ compilation flags (see error above).\r\n  ----------------------------------------\r\n  ERROR: Failed building wheel for horovod\r\n  Running setup.py clean for horovod\r\nFailed to build horovod\r\nInstalling collected packages: horovod\r\n    Running setup.py install for horovod ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-nl555q7w/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-nl555q7w/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-acljuvoa/install-record.txt --single-version-externally-managed --compile --install-headers /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m/horovod\r\n         cwd: /tmp/pip-install-nl555q7w/horovod/\r\n    Complete output (121 lines):\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.7\r\n    creating build/lib.linux-x86_64-3.7/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.7/horovod\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark\r\n    creating build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run\r\n    creating build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.7/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.7/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/tensorflow/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/task\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/http\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/driver\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.7/horovod/run/common/service\r\n    running build_ext\r\n    /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/x86_64-conda_cos6-linux-gnu-cc -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -mavx -I/home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    x86_64-conda_cos6-linux-gnu-cc: error trying to exec 'cc1plus': execvp: No such file or directory\r\n    /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/x86_64-conda_cos6-linux-gnu-cc -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -stdlib=libc++ -mavx -I/home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    x86_64-conda_cos6-linux-gnu-cc: error: unrecognized command line option '-stdlib=libc++'\r\n    /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/x86_64-conda_cos6-linux-gnu-cc -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -I/home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    x86_64-conda_cos6-linux-gnu-cc: error trying to exec 'cc1plus': execvp: No such file or directory\r\n    /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/x86_64-conda_cos6-linux-gnu-cc -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -Wstrict-prototypes -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -stdlib=libc++ -I/home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m -c build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.7/test_compile/test_cpp_flags.o\r\n    x86_64-conda_cos6-linux-gnu-cc: error: unrecognized command line option '-stdlib=libc++'\r\n    error: Unable to determine C++ compilation flags (see error above).\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-nl555q7w/horovod/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-nl555q7w/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-acljuvoa/install-record.txt --single-version-externally-managed --compile --install-headers /home/mas/20/cdsanwesk/miniconda3/envs/horovod_new/include/python3.7m/horovod Check the logs for full command output.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1821", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1821/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1821/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1821/events", "html_url": "https://github.com/horovod/horovod/issues/1821", "id": 588299188, "node_id": "MDU6SXNzdWU1ODgyOTkxODg=", "number": 1821, "title": "horovod cannot be use with nohup?", "user": {"login": "KangGrandesty", "id": 19343603, "node_id": "MDQ6VXNlcjE5MzQzNjAz", "avatar_url": "https://avatars0.githubusercontent.com/u/19343603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KangGrandesty", "html_url": "https://github.com/KangGrandesty", "followers_url": "https://api.github.com/users/KangGrandesty/followers", "following_url": "https://api.github.com/users/KangGrandesty/following{/other_user}", "gists_url": "https://api.github.com/users/KangGrandesty/gists{/gist_id}", "starred_url": "https://api.github.com/users/KangGrandesty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KangGrandesty/subscriptions", "organizations_url": "https://api.github.com/users/KangGrandesty/orgs", "repos_url": "https://api.github.com/users/KangGrandesty/repos", "events_url": "https://api.github.com/users/KangGrandesty/events{/privacy}", "received_events_url": "https://api.github.com/users/KangGrandesty/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-26T10:06:56Z", "updated_at": "2020-04-01T00:43:24Z", "closed_at": "2020-04-01T00:43:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: TensorFlow\r\n2. Framework version: 1.15.0\r\n3. Horovod version: 0.19.1\r\n4. MPI version: 4.0.3\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.5.6\r\n7. Python version: 3.6\r\n8. OS and version: ubuntu 16.04\r\n9. GCC version: 5.4.0\r\n\r\n**Question:**\r\n\r\nThis is my script:\r\n\r\n```shell\r\n#!/bin/bash\r\n\r\nmkdir -p mnist_convnet_model\r\nCUDA_VISIBLE_DEVICES=\"0,1\"\r\n# tensorflow_mnist_estimator.py is horovod official example\r\nnohup horovodrun -np 2 -H localhost:2 python -u ./tensorflow_mnist_estimator.py \\\r\n1>./mnist_convnet_model/1.log \\\r\n2>./mnist_convnet_model/2.log &\r\n\r\nsleep 3\r\n\r\ntail -f ./mnist_convnet_model/2.log\r\n```\r\n\r\nI run it in a SSH terminal, and everything goes well.\r\nBut, when I press `Ctrl + c` to kill `tail` process, I find **the training process was killed,too**.\r\n\r\nShouldn't horovod be use with nohup?\r\nOr,how can I run horovod as a  back process?\r\n\r\nThanks.\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1819", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1819/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1819/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1819/events", "html_url": "https://github.com/horovod/horovod/issues/1819", "id": 587935099, "node_id": "MDU6SXNzdWU1ODc5MzUwOTk=", "number": 1819, "title": "Request: Add Horovod to PyTorch container", "user": {"login": "jarednielsen", "id": 4564897, "node_id": "MDQ6VXNlcjQ1NjQ4OTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/4564897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jarednielsen", "html_url": "https://github.com/jarednielsen", "followers_url": "https://api.github.com/users/jarednielsen/followers", "following_url": "https://api.github.com/users/jarednielsen/following{/other_user}", "gists_url": "https://api.github.com/users/jarednielsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/jarednielsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jarednielsen/subscriptions", "organizations_url": "https://api.github.com/users/jarednielsen/orgs", "repos_url": "https://api.github.com/users/jarednielsen/repos", "events_url": "https://api.github.com/users/jarednielsen/events{/privacy}", "received_events_url": "https://api.github.com/users/jarednielsen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452434, "node_id": "MDU6TGFiZWw2NjU0NTI0MzQ=", "url": "https://api.github.com/repos/horovod/horovod/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-25T19:24:03Z", "updated_at": "2020-03-25T19:25:02Z", "closed_at": "2020-03-25T19:25:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "I use Horovod to train PyTorch distributed models. Currently I have to install it manually, would love it it came built-in and optimized. Others do the same, see for example #1706 .\r\n\r\n**Describe the solution you'd like**\r\nAdd \r\n```code\r\nRUN HOROVOD_NCCL_LINK=SHARED HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu HOROVOD_NCCL_INCLUDE=/usr/include HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL HOROVOD_WITH_PYTORCH=1 \\\r\n    pip install --no-cache-dir --upgrade horovod\r\n```\r\nto the PyTorch Dockerfile `nvcr.io/nvidia/pytorch:20.03-py3`. Thank you!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1816", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1816/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1816/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1816/events", "html_url": "https://github.com/horovod/horovod/issues/1816", "id": 586683173, "node_id": "MDU6SXNzdWU1ODY2ODMxNzM=", "number": 1816, "title": "Can I specify multiple CPUs and memory?", "user": {"login": "pratzz", "id": 10550923, "node_id": "MDQ6VXNlcjEwNTUwOTIz", "avatar_url": "https://avatars0.githubusercontent.com/u/10550923?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pratzz", "html_url": "https://github.com/pratzz", "followers_url": "https://api.github.com/users/pratzz/followers", "following_url": "https://api.github.com/users/pratzz/following{/other_user}", "gists_url": "https://api.github.com/users/pratzz/gists{/gist_id}", "starred_url": "https://api.github.com/users/pratzz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pratzz/subscriptions", "organizations_url": "https://api.github.com/users/pratzz/orgs", "repos_url": "https://api.github.com/users/pratzz/repos", "events_url": "https://api.github.com/users/pratzz/events{/privacy}", "received_events_url": "https://api.github.com/users/pratzz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-24T04:28:44Z", "updated_at": "2020-04-02T11:49:51Z", "closed_at": "2020-04-02T11:49:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\n\r\nCan I specify number of CPUs and memory to be used? If yes, how? I saw docs stating either number of processes or number of GPUs, can I specify both? Basically I am looking for a multi node multi CPU multi GPU deployment.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1812", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1812/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1812/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1812/events", "html_url": "https://github.com/horovod/horovod/issues/1812", "id": 585964594, "node_id": "MDU6SXNzdWU1ODU5NjQ1OTQ=", "number": 1812, "title": "Horovod synthetic benchmarks example command exec fail", "user": {"login": "zhiyuone", "id": 9315872, "node_id": "MDQ6VXNlcjkzMTU4NzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/9315872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhiyuone", "html_url": "https://github.com/zhiyuone", "followers_url": "https://api.github.com/users/zhiyuone/followers", "following_url": "https://api.github.com/users/zhiyuone/following{/other_user}", "gists_url": "https://api.github.com/users/zhiyuone/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhiyuone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhiyuone/subscriptions", "organizations_url": "https://api.github.com/users/zhiyuone/orgs", "repos_url": "https://api.github.com/users/zhiyuone/repos", "events_url": "https://api.github.com/users/zhiyuone/events{/privacy}", "received_events_url": "https://api.github.com/users/zhiyuone/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 730732849, "node_id": "MDU6TGFiZWw3MzA3MzI4NDk=", "url": "https://api.github.com/repos/horovod/horovod/labels/update%20docs", "name": "update docs", "color": "78ed92", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-23T06:28:08Z", "updated_at": "2020-03-24T00:11:01Z", "closed_at": "2020-03-24T00:11:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n0.19.1\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version:\r\n8. OS and version:\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nrun example command\r\nhttps://horovod.readthedocs.io/en/latest/benchmarks.html#horovod-synthetic-benchmarks\r\n>$ horovodrun -np 4 server1:2,server2:2 \\\r\n    python --fp16-allreduce tensorflow2_synthetic_benchmark.py\r\n\r\nwith error occur\r\n>mpirun was unable to find the specified executable file, and therefore\r\ndid not launch the job.  This error was first reported for process\r\nrank 0; it may have occurred for other processes as well.\r\nNOTE: A common cause for this error is misspelling a mpirun command\r\n      line parameter option (remember that mpirun interprets the first\r\n      unrecognized command line token as the executable).\r\n\r\nis lack `-H` flag before hosts?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1802", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1802/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1802/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1802/events", "html_url": "https://github.com/horovod/horovod/issues/1802", "id": 584247941, "node_id": "MDU6SXNzdWU1ODQyNDc5NDE=", "number": 1802, "title": "Runtime Error: hvd.broadcast_global_variables() does not support eager execution", "user": {"login": "yurinishikawa", "id": 19642252, "node_id": "MDQ6VXNlcjE5NjQyMjUy", "avatar_url": "https://avatars2.githubusercontent.com/u/19642252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yurinishikawa", "html_url": "https://github.com/yurinishikawa", "followers_url": "https://api.github.com/users/yurinishikawa/followers", "following_url": "https://api.github.com/users/yurinishikawa/following{/other_user}", "gists_url": "https://api.github.com/users/yurinishikawa/gists{/gist_id}", "starred_url": "https://api.github.com/users/yurinishikawa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yurinishikawa/subscriptions", "organizations_url": "https://api.github.com/users/yurinishikawa/orgs", "repos_url": "https://api.github.com/users/yurinishikawa/repos", "events_url": "https://api.github.com/users/yurinishikawa/events{/privacy}", "received_events_url": "https://api.github.com/users/yurinishikawa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-03-19T08:36:11Z", "updated_at": "2020-06-30T03:13:11Z", "closed_at": "2020-03-21T05:22:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: Keras\r\n2. Framework version: 2.3.1 (Backend: TensorFlow 2.0.1)\r\n3. Horovod version: 0.19.1\r\n4. MPI version: OpenMPI 2.1.6\r\n5. CUDA version: 10.0.130.1 \r\n6. NCCL version: 2.5.6-1\r\n7. Python version: 3.6.5\r\n8. OS and version: CentOS 7.5.1804\r\n9. GCC version: 7.4.0\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?  -- yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)? \r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)? --yes\r\n\r\n**Your question:**\r\n\r\nHi.  I am trying to run [examples/keras_mnist.py](examples/keras_mnist.py) using TF2.0 backend.  \r\nI am having trouble with the following error:\r\n\r\n```\r\nRuntimeError: hvd.broadcast_global_variables() does not support eager execution. \r\nPlease use `hvd.broadcast_variables(<model/optimizer variables>)` instead.\r\n```\r\n\r\nI looked into [examples/tensorflow2_keras.py](examples/tensorflow2_keras.py) (which works fine), but it imports `tf.keras` and `horovod.tensorflow.keras`.  I am currently trying to apply Horovod to my code written in standalone Keras (which requires TF2.0 backend), so I want to run [examples/keras_mnist.py](examples/keras_mnist.py) without any error.\r\n\r\nI also noticed that `experimental_run_tf_function=False` was set in [ examples/tensorflow2_keras.py](examples/tensorflow2_keras.py).  \r\nWhen I set that option in [examples/keras_mnist.py](examples/keras_mnist.py), it returns:\r\n\r\n```\r\nValueError: Session keyword arguments are not support during eager execution. \r\nYou passed: {'experimental_run_tf_function': False}\r\n```\r\n\r\nThe training starts when I remove `hvd.callbacks.BroadcastGlobalVariablesCallback(0)` from callback, but I think it is not recommended due to my understanding.  I appreciate your help in advance!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1798", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1798/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1798/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1798/events", "html_url": "https://github.com/horovod/horovod/issues/1798", "id": 583443755, "node_id": "MDU6SXNzdWU1ODM0NDM3NTU=", "number": 1798, "title": "When build docker container with ubuntu16.04 install horovod failed with error code -4", "user": {"login": "JuZhengHub", "id": 37337576, "node_id": "MDQ6VXNlcjM3MzM3NTc2", "avatar_url": "https://avatars3.githubusercontent.com/u/37337576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JuZhengHub", "html_url": "https://github.com/JuZhengHub", "followers_url": "https://api.github.com/users/JuZhengHub/followers", "following_url": "https://api.github.com/users/JuZhengHub/following{/other_user}", "gists_url": "https://api.github.com/users/JuZhengHub/gists{/gist_id}", "starred_url": "https://api.github.com/users/JuZhengHub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JuZhengHub/subscriptions", "organizations_url": "https://api.github.com/users/JuZhengHub/orgs", "repos_url": "https://api.github.com/users/JuZhengHub/repos", "events_url": "https://api.github.com/users/JuZhengHub/events{/privacy}", "received_events_url": "https://api.github.com/users/JuZhengHub/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452437, "node_id": "MDU6TGFiZWw2NjU0NTI0Mzc=", "url": "https://api.github.com/repos/horovod/horovod/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-18T03:47:15Z", "updated_at": "2020-03-19T02:33:30Z", "closed_at": "2020-03-19T02:33:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet) TensorFlow\r\n2. Framework version: tensorflow-gpu==1.14.0\r\n3. Horovod version: latest\r\n4. MPI version: 3.1.5\r\n5. CUDA version: 10.0\r\n6. NCCL version: 2.5.6\r\n7. Python version: 3.5\r\n8. OS and version: ubuntu16.04\r\n9. GCC version: g++ 5.6\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before? yes\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Your question:**\r\nI am trying to build container with \"nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\"\r\nchose tensorflow version 1.14.0 \r\nrefer to \"Dockerfile-gpu\" on github\r\nfound openmpi-4.0.x cannot compile passed on ubuntu16.04 ,so change to openmpi-3.1.5 and compile passed\r\n\r\nbut when i try to install horovod by follow command some error happened:\r\n\r\nRUN ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs && \\\r\n      HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_MXNET=1 \\\r\n          \u00a6python3 -m pip install --no-cache-dir horovod && \\\r\n      ldconfig\r\n---------------------------------------------------------------------\r\nError message(failed with error code -4) (but i cannot find any useful error message.....):\r\n\r\nStep 9/11 : RUN ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs &&     HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_GPU_BROADCAST=NCCL HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_MXNET=1          python3 -m pip install --no-cache-dir horovod &&     ldconfig\r\n ---> Running in 569e38897ff5\r\nCollecting horovod\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c0/31/dae1f224a284ccaf0fd700565a53658bfba9c3d5964719305953e72a11e0/horovod-0.19.1.tar.gz (2.9MB)\r\nCollecting cloudpickle (from horovod)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ea/0b/189cd3c19faf362ff2df5f301456c6cf8571ef6684644cfdfdbff293825c/cloudpickle-1.3.0-py2.py3-none-any.whl\r\nCollecting psutil (from horovod)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c4/b8/3512f0e93e0db23a71d82485ba256071ebef99b227351f0f5540f744af41/psutil-5.7.0.tar.gz (449kB)\r\nRequirement already satisfied (use --upgrade to upgrade): pyyaml in /usr/local/lib/python3.5/dist-packages (from horovod)\r\nRequirement already satisfied (use --upgrade to upgrade): six in /usr/local/lib/python3.5/dist-packages (from horovod)\r\nCollecting cffi>=1.4.0 (from horovod)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d6/7f/7acc85c478f5056b98c9961a31697b1e53fbec158ee5f723097e1c355660/cffi-1.14.0-cp35-cp35m-manylinux1_x86_64.whl (399kB)\r\nCollecting pycparser (from cffi>=1.4.0->horovod)\r\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/e7/d9c3a176ca4b02024debf82342dab36efadfc5776f9c8db077e8f6e71821/pycparser-2.20-py2.py3-none-any.whl (112kB)\r\nInstalling collected packages: cloudpickle, psutil, pycparser, cffi, horovod\r\n  Running setup.py install for psutil: started\r\n    Running setup.py install for psutil: finished with status 'done'\r\n  Running setup.py install for horovod: started\r\n    Running setup.py install for horovod: finished with status 'error'\r\n    Complete output from command /usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-_8yka3m6/horovod/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record /tmp/pip-l0nal9cq-record/install-record.txt --single-version-externally-managed --compile:\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build/lib.linux-x86_64-3.5\r\n    creating build/lib.linux-x86_64-3.5/horovod\r\n    copying horovod/__init__.py -> build/lib.linux-x86_64-3.5/horovod\r\n    creating build/lib.linux-x86_64-3.5/horovod/run\r\n    copying horovod/run/mpi_run.py -> build/lib.linux-x86_64-3.5/horovod/run\r\n    copying horovod/run/run.py -> build/lib.linux-x86_64-3.5/horovod/run\r\n    copying horovod/run/gloo_run.py -> build/lib.linux-x86_64-3.5/horovod/run\r\n    copying horovod/run/run_task.py -> build/lib.linux-x86_64-3.5/horovod/run\r\n    copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.5/horovod/run\r\n    copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.5/horovod/run\r\n    creating build/lib.linux-x86_64-3.5/horovod/tensorflow\r\n    copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.5/horovod/tensorflow\r\n    copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.5/horovod/tensorflow\r\n    copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.5/horovod/tensorflow\r\n    copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.5/horovod/tensorflow\r\n    creating build/lib.linux-x86_64-3.5/horovod/torch\r\n    copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.5/horovod/torch\r\n    copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.5/horovod/torch\r\n    copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.5/horovod/torch\r\n    creating build/lib.linux-x86_64-3.5/horovod/spark\r\n    copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.5/horovod/spark\r\n    creating build/lib.linux-x86_64-3.5/horovod/common\r\n    copying horovod/common/util.py -> build/lib.linux-x86_64-3.5/horovod/common\r\n    copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.5/horovod/common\r\n    copying horovod/common/basics.py -> build/lib.linux-x86_64-3.5/horovod/common\r\n    creating build/lib.linux-x86_64-3.5/horovod/keras\r\n    copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.5/horovod/keras\r\n    copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.5/horovod/keras\r\n    creating build/lib.linux-x86_64-3.5/horovod/_keras\r\n    copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.5/horovod/_keras\r\n    copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.5/horovod/_keras\r\n    creating build/lib.linux-x86_64-3.5/horovod/mxnet\r\n    copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.5/horovod/mxnet\r\n    copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.5/horovod/mxnet\r\n    creating build/lib.linux-x86_64-3.5/horovod/run/http\r\n    copying horovod/run/http/http_server.py -> build/lib.linux-x86_64-3.5/horovod/run/http\r\n    copying horovod/run/http/__init__.py -> build/lib.linux-x86_64-3.5/horovod/run/http\r\n    copying horovod/run/http/http_client.py -> build/lib.linux-x86_64-3.5/horovod/run/http\r\n    creating build/lib.linux-x86_64-3.5/horovod/run/task\r\n    copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.5/horovod/run/task\r\n    copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.5/horovod/run/task\r\n    creating build/lib.linux-x86_64-3.5/horovod/run/common\r\n    copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.5/horovod/run/common\r\n    creating build/lib.linux-x86_64-3.5/horovod/run/driver\r\n    copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.5/horovod/run/driver\r\n    copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.5/horovod/run/driver\r\n    creating build/lib.linux-x86_64-3.5/horovod/run/util\r\n    copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.5/horovod/run/util\r\n    copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.5/horovod/run/util\r\n    copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.5/horovod/run/util\r\n    copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.5/horovod/run/util\r\n    creating build/lib.linux-x86_64-3.5/horovod/run/common/service\r\n    copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.5/horovod/run/common/service\r\n    copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.5/horovod/run/common/service\r\n    copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.5/horovod/run/common/service\r\n    creating build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/config_parser.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/env.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/settings.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.5/horovod/run/common/util\r\n    creating build/lib.linux-x86_64-3.5/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.5/horovod/tensorflow/keras\r\n    copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.5/horovod/tensorflow/keras\r\n    creating build/lib.linux-x86_64-3.5/horovod/torch/mpi_lib\r\n    copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.5/horovod/torch/mpi_lib\r\n    creating build/lib.linux-x86_64-3.5/horovod/torch/mpi_lib_impl\r\n    copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.5/horovod/torch/mpi_lib_impl\r\n    creating build/lib.linux-x86_64-3.5/horovod/spark/task\r\n    copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.5/horovod/spark/task\r\n    copying horovod/spark/task/task_info.py -> build/lib.linux-x86_64-3.5/horovod/spark/task\r\n    copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.5/horovod/spark/task\r\n    copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.5/horovod/spark/task\r\n    creating build/lib.linux-x86_64-3.5/horovod/spark/torch\r\n    copying horovod/spark/torch/estimator.py -> build/lib.linux-x86_64-3.5/horovod/spark/torch\r\n    copying horovod/spark/torch/remote.py -> build/lib.linux-x86_64-3.5/horovod/spark/torch\r\n    copying horovod/spark/torch/util.py -> build/lib.linux-x86_64-3.5/horovod/spark/torch\r\n    copying horovod/spark/torch/__init__.py -> build/lib.linux-x86_64-3.5/horovod/spark/torch\r\n    creating build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/_namedtuple_fix.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/estimator.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/cache.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/params.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/store.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/util.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/__init__.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/backend.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/constants.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    copying horovod/spark/common/serialization.py -> build/lib.linux-x86_64-3.5/horovod/spark/common\r\n    creating build/lib.linux-x86_64-3.5/horovod/spark/keras\r\n    copying horovod/spark/keras/bare.py -> build/lib.linux-x86_64-3.5/horovod/spark/keras\r\n    copying horovod/spark/keras/estimator.py -> build/lib.linux-x86_64-3.5/horovod/spark/keras\r\n    copying horovod/spark/keras/optimizer.py -> build/lib.linux-x86_64-3.5/horovod/spark/keras\r\n    copying horovod/spark/keras/remote.py -> build/lib.linux-x86_64-3.5/horovod/spark/keras\r\n    copying horovod/spark/keras/util.py -> build/lib.linux-x86_64-3.5/horovod/spark/keras\r\n    copying horovod/spark/keras/__init__.py -> build/lib.linux-x86_64-3.5/horovod/spark/keras\r\n    copying horovod/spark/keras/tensorflow.py -> build/lib.linux-x86_64-3.5/horovod/spark/keras\r\n    creating build/lib.linux-x86_64-3.5/horovod/spark/driver\r\n    copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.5/horovod/spark/driver\r\n    copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.5/horovod/spark/driver\r\n    copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.5/horovod/spark/driver\r\n    copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.5/horovod/spark/driver\r\n    running build_ext\r\n    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -I/usr/include/python3.5m -c build/temp.linux-x86_64-3.5/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.5/test_compile/test_cpp_flags.o\r\n    cc1plus: warning: command line option '-Wstrict-prototypes' is valid for C/ObjC but not for C++\r\n    x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.5/test_compile/test_cpp_flags.o -o build/temp.linux-x86_64-3.5/test_compile/test_cpp_flags.so\r\n    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.5m -c build/temp.linux-x86_64-3.5/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.5/test_compile/test_link_flags.o\r\n    cc1plus: warning: command line option '-Wstrict-prototypes' is valid for C/ObjC but not for C++\r\n    x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.5/test_compile/test_link_flags.o -o build/temp.linux-x86_64-3.5/test_compile/test_link_flags.so\r\n    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -I/usr/local/cuda/include -I/usr/include/python3.5m -c build/temp.linux-x86_64-3.5/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.5/test_compile/test_cuda.o\r\n    cc1plus: warning: command line option '-Wstrict-prototypes' is valid for C/ObjC but not for C++\r\n    x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.5/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lcudart -o build/temp.linux-x86_64-3.5/test_compile/test_cuda.so\r\n    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -I/usr/local/cuda/include -I/usr/include/python3.5m -c build/temp.linux-x86_64-3.5/test_compile/test_nccl.cc -o build/temp.linux-x86_64-3.5/test_compile/test_nccl.o\r\n    cc1plus: warning: command line option '-Wstrict-prototypes' is valid for C/ObjC but not for C++\r\n    x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.5/test_compile/test_nccl.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lnccl_static -o build/temp.linux-x86_64-3.5/test_compile/test_nccl.so\r\n    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -std=c++11 -fPIC -O2 -Wall -fassociative-math -ffast-math -ftree-vectorize -funsafe-math-optimizations -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi -I/usr/local/cuda/include -I/usr/include/python3.5m -c build/temp.linux-x86_64-3.5/test_compile/test_cuda.cc -o build/temp.linux-x86_64-3.5/test_compile/test_cuda.o\r\n    cc1plus: warning: command line option '-Wstrict-prototypes' is valid for C/ObjC but not for C++\r\n    x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.5/test_compile/test_cuda.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -lcudart -o build/temp.linux-x86_64-3.5/test_compile/test_cuda.so\r\n    \r\n    ----------------------------------------\r\n\u001b[91mCommand \"/usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-_8yka3m6/horovod/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\\r\\n', '\\n'), __file__, 'exec'))\" install --record /tmp/pip-l0nal9cq-record/install-record.txt --single-version-externally-managed --compile\" **failed with error code -4 i**n /tmp/pip-build-_8yka3m6/horovod/\r\n-------------------------------------------------------------------------------------------------------\r\n\r\nwithin this error message i canno figure out what error happened , could anyone meet this error or can help to fix this ,thank u ~\r\n\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1794", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1794/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1794/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1794/events", "html_url": "https://github.com/horovod/horovod/issues/1794", "id": 581977286, "node_id": "MDU6SXNzdWU1ODE5NzcyODY=", "number": 1794, "title": "Is this a bug", "user": {"login": "chengdianxuezi", "id": 10277403, "node_id": "MDQ6VXNlcjEwMjc3NDAz", "avatar_url": "https://avatars1.githubusercontent.com/u/10277403?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chengdianxuezi", "html_url": "https://github.com/chengdianxuezi", "followers_url": "https://api.github.com/users/chengdianxuezi/followers", "following_url": "https://api.github.com/users/chengdianxuezi/following{/other_user}", "gists_url": "https://api.github.com/users/chengdianxuezi/gists{/gist_id}", "starred_url": "https://api.github.com/users/chengdianxuezi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chengdianxuezi/subscriptions", "organizations_url": "https://api.github.com/users/chengdianxuezi/orgs", "repos_url": "https://api.github.com/users/chengdianxuezi/repos", "events_url": "https://api.github.com/users/chengdianxuezi/events{/privacy}", "received_events_url": "https://api.github.com/users/chengdianxuezi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-16T03:37:23Z", "updated_at": "2020-03-16T06:43:21Z", "closed_at": "2020-03-16T06:43:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/horovod/horovod/blob/52cff13dc3c4be7b6d02757855172add04a9968b/horovod/common/gloo/gloo_context.cc#L148\r\nlocal_rank and cross_rank \uff0cThese two variables are reversed\r\n  local_ctx = Rendezvous(HOROVOD_GLOO_LOCAL_PREFIX + std::to_string(local_rank),\r\n                         rendezvous_addr_env, rendezvous_port,\r\n                         local_rank, local_size, dev, timeout);", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/horovod/horovod/issues/1791", "repository_url": "https://api.github.com/repos/horovod/horovod", "labels_url": "https://api.github.com/repos/horovod/horovod/issues/1791/labels{/name}", "comments_url": "https://api.github.com/repos/horovod/horovod/issues/1791/comments", "events_url": "https://api.github.com/repos/horovod/horovod/issues/1791/events", "html_url": "https://github.com/horovod/horovod/issues/1791", "id": 580609317, "node_id": "MDU6SXNzdWU1ODA2MDkzMTc=", "number": 1791, "title": "Dockerfile needs to be updated", "user": {"login": "abcinje", "id": 33629617, "node_id": "MDQ6VXNlcjMzNjI5NjE3", "avatar_url": "https://avatars0.githubusercontent.com/u/33629617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abcinje", "html_url": "https://github.com/abcinje", "followers_url": "https://api.github.com/users/abcinje/followers", "following_url": "https://api.github.com/users/abcinje/following{/other_user}", "gists_url": "https://api.github.com/users/abcinje/gists{/gist_id}", "starred_url": "https://api.github.com/users/abcinje/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abcinje/subscriptions", "organizations_url": "https://api.github.com/users/abcinje/orgs", "repos_url": "https://api.github.com/users/abcinje/repos", "events_url": "https://api.github.com/users/abcinje/events{/privacy}", "received_events_url": "https://api.github.com/users/abcinje/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 665452432, "node_id": "MDU6TGFiZWw2NjU0NTI0MzI=", "url": "https://api.github.com/repos/horovod/horovod/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-13T13:42:49Z", "updated_at": "2020-03-13T17:01:00Z", "closed_at": "2020-03-13T17:01:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment:**\r\n1. Framework: (TensorFlow, Keras, PyTorch, MXNet)\r\n2. Framework version:\r\n3. Horovod version:\r\n4. MPI version:\r\n5. CUDA version:\r\n6. NCCL version:\r\n7. Python version: 3.6\r\n8. OS and version: Ubuntu 18.04.4\r\n9. GCC version:\r\n\r\n**Checklist:**\r\n1. Did you search issues to find if somebody asked this question before?\r\n2. If your question is about hang, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/running.rst)?\r\n3. If your question is about docker, did you read [this doc](https://github.com/horovod/horovod/blob/master/docs/docker.rst)?\r\n4. Did you check if you question is answered in the [troubleshooting guide](https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst)?\r\n\r\n**Bug report:**\r\nPlease describe errorneous behavior you're observing and steps to reproduce it.\r\n\r\nHello. I've followed the instructions in the [docker guide](https://github.com/horovod/horovod/blob/master/docs/docker.rst).\r\nWhile building Horovod in docker by running\r\n```\r\n$ docker build -t horovod:latest horovod-docker-gpu\r\n```\r\nI've got the following error\r\n![bug](https://user-images.githubusercontent.com/33629617/76625760-4ae31400-657b-11ea-9e6e-8c28ef3ec12c.PNG)\r\n\r\nAs a workaround, I added an argument to `get_supported()` function like:\r\n```\r\nw.get_supported('.')\r\n```\r\nAnd it worked well.", "performed_via_github_app": null, "score": 1.0}]}