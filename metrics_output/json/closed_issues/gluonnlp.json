{"total_count": 257, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1303", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1303/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1303/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1303/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1303", "id": 681444364, "node_id": "MDU6SXNzdWU2ODE0NDQzNjQ=", "number": 1303, "title": "FP16 and FP32 gives different results since GluonNLP 0.7", "user": {"login": "davisliang", "id": 12505988, "node_id": "MDQ6VXNlcjEyNTA1OTg4", "avatar_url": "https://avatars1.githubusercontent.com/u/12505988?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davisliang", "html_url": "https://github.com/davisliang", "followers_url": "https://api.github.com/users/davisliang/followers", "following_url": "https://api.github.com/users/davisliang/following{/other_user}", "gists_url": "https://api.github.com/users/davisliang/gists{/gist_id}", "starred_url": "https://api.github.com/users/davisliang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davisliang/subscriptions", "organizations_url": "https://api.github.com/users/davisliang/orgs", "repos_url": "https://api.github.com/users/davisliang/repos", "events_url": "https://api.github.com/users/davisliang/events{/privacy}", "received_events_url": "https://api.github.com/users/davisliang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-19T00:14:53Z", "updated_at": "2020-08-19T00:30:55Z", "closed_at": "2020-08-19T00:30:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nDoing a forward pass with BERT-base (using the same parameters) on fp16 gives very different results from fp32. This is the case for GluonNLP beyond 0.6.0.\r\n\r\n### Error Message\r\nfrom float32:\r\n```\r\n[[[-0.14241205  0.13353725 -0.12907065 ... -0.35967964 -0.05622258\r\n    0.36050138]\r\n  [-0.350648    0.10419771  0.6244457  ... -0.17610289  0.48340237\r\n    0.06443504]\r\n  [-0.24513094 -0.15731683  0.69451946 ... -0.5654467  -0.0894002\r\n   -0.18564378]\r\n  [-0.82478666 -0.9119223  -0.65607107 ...  0.50742483 -0.19388783\r\n   -0.16587636]\r\n  [ 0.8766523   0.03524842 -0.12331446 ...  0.2720161  -0.6369005\r\n   -0.1585012 ]]]\r\n<NDArray 1x5x768 @gpu(0)>\r\n```\r\n\r\nfrom float16:\r\n```\r\n[[[-0.4473   0.03326 -0.06555 ... -0.4893  -0.1052   0.5503 ]\r\n  [-0.9287  -0.04443  0.9863  ... -0.7188  -0.1516   0.0721 ]\r\n  [-0.6553  -0.2798   0.6636  ... -0.526   -0.5      0.03748]\r\n  [-0.726   -0.81    -0.05014 ...  0.2372  -0.447    0.04047]\r\n  [-1.035   -0.578    0.5273  ... -0.4065  -0.3872   0.5005 ]]]\r\n<NDArray 1x5x768 @gpu(0)>\r\n```\r\n\r\n## To Reproduce\r\n(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n```python\r\n#float32\r\nimport gluonnlp as nlp; import mxnet as mx;\r\nmodel, vocab = nlp.model.get_model('bert_12_768_12', dataset_name='book_corpus_wiki_en_uncased', use_classifier=False, use_decoder=False, ctx=mx.gpu(0));\r\ntokenizer = nlp.data.BERTTokenizer(vocab, lower=True);\r\ntransform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=512, pair=False, pad=False);\r\nsample = transform(['Hello world!']);\r\n\r\nmodel.cast('float32')\r\n\r\nwords, valid_len, segments = mx.nd.array([sample[0]]).as_in_context(mx.gpu(0)), \\\r\n                                            mx.nd.array([sample[1]]).as_in_context(mx.gpu(0)).astype('float32'), \\\r\n                                            mx.nd.array([sample[2]]).as_in_context(mx.gpu(0)).astype('float32')\r\nseq_encoding, cls_encoding = model(words, segments, valid_len);\r\n```\r\n\r\n```python\r\n# float16\r\nimport gluonnlp as nlp; import mxnet as mx;\r\nmodel, vocab = nlp.model.get_model('bert_12_768_12', dataset_name='book_corpus_wiki_en_uncased', use_classifier=False, use_decoder=False, ctx=mx.gpu(0));\r\ntokenizer = nlp.data.BERTTokenizer(vocab, lower=True);\r\ntransform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=512, pair=False, pad=False);\r\nsample = transform(['Hello world!']);\r\n\r\nmodel.cast('float16')\r\n\r\nwords, valid_len, segments = mx.nd.array([sample[0]]).as_in_context(mx.gpu(0)), \\\r\n                                            mx.nd.array([sample[1]]).as_in_context(mx.gpu(0)).astype('float16'), \\\r\n                                            mx.nd.array([sample[2]]).as_in_context(mx.gpu(0)).astype('float16')\r\nseq_encoding, cls_encoding = model(words, segments, valid_len);\r\n```\r\n\r\n## What have you tried to solve it?\r\n1. Tried it on various gluonnlp versions. 0.6.0 does not have this bug. 0.7.0+ does.\r\n2.\r\n\r\n## Environment\r\nJust your average EC2 machine with `pip install mxnet-cu102`\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1295", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1295/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1295/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1295/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1295", "id": 676921975, "node_id": "MDU6SXNzdWU2NzY5MjE5NzU=", "number": 1295, "title": "`pip install --upgrade mxnet>=1.6.0` will not work", "user": {"login": "StevenJokes", "id": 25657787, "node_id": "MDQ6VXNlcjI1NjU3Nzg3", "avatar_url": "https://avatars3.githubusercontent.com/u/25657787?v=4", "gravatar_id": "", "url": "https://api.github.com/users/StevenJokes", "html_url": "https://github.com/StevenJokes", "followers_url": "https://api.github.com/users/StevenJokes/followers", "following_url": "https://api.github.com/users/StevenJokes/following{/other_user}", "gists_url": "https://api.github.com/users/StevenJokes/gists{/gist_id}", "starred_url": "https://api.github.com/users/StevenJokes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/StevenJokes/subscriptions", "organizations_url": "https://api.github.com/users/StevenJokes/orgs", "repos_url": "https://api.github.com/users/StevenJokes/repos", "events_url": "https://api.github.com/users/StevenJokes/events{/privacy}", "received_events_url": "https://api.github.com/users/StevenJokes/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-11T14:25:28Z", "updated_at": "2020-08-11T14:26:00Z", "closed_at": "2020-08-11T14:26:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n(A clear and concise description of what the bug is.)\r\nhttps://github.com/d2l-ai/d2l-en/issues/1324\r\n\r\n### Error Message\r\n(Paste the complete error message, including stack trace.)\r\n\r\n## To Reproduce\r\n(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n1.\r\n2.\r\n\r\n## What have you tried to solve it?\r\n\r\n1.\r\n2.\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1294", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1294/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1294/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1294/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1294", "id": 676470007, "node_id": "MDU6SXNzdWU2NzY0NzAwMDc=", "number": 1294, "title": "GluonNLP 0.8 BERT output is different from GluonNLP 0.9 ", "user": {"login": "davisliang", "id": 12505988, "node_id": "MDQ6VXNlcjEyNTA1OTg4", "avatar_url": "https://avatars1.githubusercontent.com/u/12505988?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davisliang", "html_url": "https://github.com/davisliang", "followers_url": "https://api.github.com/users/davisliang/followers", "following_url": "https://api.github.com/users/davisliang/following{/other_user}", "gists_url": "https://api.github.com/users/davisliang/gists{/gist_id}", "starred_url": "https://api.github.com/users/davisliang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davisliang/subscriptions", "organizations_url": "https://api.github.com/users/davisliang/orgs", "repos_url": "https://api.github.com/users/davisliang/repos", "events_url": "https://api.github.com/users/davisliang/events{/privacy}", "received_events_url": "https://api.github.com/users/davisliang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-10T23:11:14Z", "updated_at": "2020-08-13T01:20:04Z", "closed_at": "2020-08-13T01:20:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nUsing the same BERT model parameters, GluonNLP0.8 and GluonNLP0.9 output drastically different encoder representations. Tested on both MxNet1.5, MxNet1.6.\r\n\r\n### Error Message\r\nGluonNLP 0.8 output:\r\n[[[-0.14241228  0.13353696 -0.12907042 ... -0.3596797  -0.05622234\r\n    0.36050126]\r\n  [-0.3506479   0.10419717  0.62444484 ... -0.17610289  0.48340234\r\n    0.06443496]\r\n  [-0.24513118 -0.15731761  0.69451797 ... -0.5654461  -0.08939961\r\n   -0.18564416]\r\n  [-0.824786   -0.9119225  -0.65607095 ...  0.50742507 -0.19388743\r\n   -0.1658766 ]\r\n  [ 0.87665254  0.03524816 -0.12331399 ...  0.2720159  -0.63690007\r\n   -0.15850069]]]\r\n<NDArray 1x5x768 @cpu(0)>\r\n\r\nGluonNLP 0.9 output:\r\n[[[-0.8164635  -0.18977094 -0.44616854 ... -0.9124998   0.02381709\r\n    0.5544555 ]\r\n  [-1.0949776  -0.41612968  0.5249134  ... -0.706112    0.14636786\r\n   -0.38614586]\r\n  [-0.8410385  -0.45054507  0.3945069  ... -0.9239115  -0.3351414\r\n    0.05241004]\r\n  [-0.8435936  -1.2706859  -0.5667961  ... -0.40249282 -0.1447221\r\n   -0.12529008]\r\n  [ 0.75693136 -1.1236286  -0.2741627  ...  0.08363507 -0.71608377\r\n    0.29923674]]]\r\n<NDArray 1x5x768 @cpu(0)>\r\n\r\n## To Reproduce\r\nFirst, install the packages:\r\n!pip install mxnet-cu102\r\n!pip install gluonnlp==0.9.1\r\n!pip install gluonnlp==0.8\r\n\r\n```\r\nimport gluonnlp as nlp; import mxnet as mx;\r\nmodel, vocab = nlp.model.get_model('bert_12_768_12', dataset_name='book_corpus_wiki_en_uncased', use_classifier=False, use_decoder=False);\r\ntokenizer = nlp.data.BERTTokenizer(vocab, lower=True);\r\ntransform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=512, pair=False, pad=False);\r\nsample = transform(['Hello world!']);\r\nwords, valid_len, segments = mx.nd.array([sample[0]]), mx.nd.array([sample[1]]), mx.nd.array([sample[2]]);\r\nseq_encoding, cls_encoding = model(words, segments, valid_len);\r\n\r\nprint(seq_encoding)\r\n```\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n1. Install the package (either GluonNLP 0.8 or 0.9, as detailed in To Reproduce)\r\n2. Run the example code snippet, taken from the GluonNLP BERT tutorial\r\n\r\n## What have you tried to solve it?\r\n\r\n1. I hypothesized there might be something different in the handing of parameters but it doesn't seem like it.\r\n2. I hypothesized there might be something different with tokenization and transformations but it doesn't seem like that's the issue either.\r\n\r\n## Environment\r\nAny EC2\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1243", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1243/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1243/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1243/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1243", "id": 636008531, "node_id": "MDU6SXNzdWU2MzYwMDg1MzE=", "number": 1243, "title": "[Numpy Refactor] [Installation] Add Official Dockerfile support", "user": {"login": "sxjscience", "id": 5178350, "node_id": "MDQ6VXNlcjUxNzgzNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5178350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sxjscience", "html_url": "https://github.com/sxjscience", "followers_url": "https://api.github.com/users/sxjscience/followers", "following_url": "https://api.github.com/users/sxjscience/following{/other_user}", "gists_url": "https://api.github.com/users/sxjscience/gists{/gist_id}", "starred_url": "https://api.github.com/users/sxjscience/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sxjscience/subscriptions", "organizations_url": "https://api.github.com/users/sxjscience/orgs", "repos_url": "https://api.github.com/users/sxjscience/repos", "events_url": "https://api.github.com/users/sxjscience/events{/privacy}", "received_events_url": "https://api.github.com/users/sxjscience/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 1689031381, "node_id": "MDU6TGFiZWwxNjg5MDMxMzgx", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/numpyrefactor", "name": "numpyrefactor", "color": "2f38ed", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-10T07:36:19Z", "updated_at": "2020-08-20T16:23:41Z", "closed_at": "2020-08-20T16:23:41Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "As in AllenNLP, the user is able to build the docker: https://github.com/allenai/allennlp/#installing-using-docker\r\n\r\nWe should offer something similar to the user.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1239", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1239/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1239/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1239/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1239", "id": 634321267, "node_id": "MDU6SXNzdWU2MzQzMjEyNjc=", "number": 1239, "title": "BPE's  default alpha with sentencepiece ", "user": {"login": "haven-jeon", "id": 957840, "node_id": "MDQ6VXNlcjk1Nzg0MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/957840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haven-jeon", "html_url": "https://github.com/haven-jeon", "followers_url": "https://api.github.com/users/haven-jeon/followers", "following_url": "https://api.github.com/users/haven-jeon/following{/other_user}", "gists_url": "https://api.github.com/users/haven-jeon/gists{/gist_id}", "starred_url": "https://api.github.com/users/haven-jeon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haven-jeon/subscriptions", "organizations_url": "https://api.github.com/users/haven-jeon/orgs", "repos_url": "https://api.github.com/users/haven-jeon/repos", "events_url": "https://api.github.com/users/haven-jeon/events{/privacy}", "received_events_url": "https://api.github.com/users/haven-jeon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 890393505, "node_id": "MDU6TGFiZWw4OTAzOTM1MDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-08T07:55:52Z", "updated_at": "2020-07-12T01:09:44Z", "closed_at": "2020-07-12T01:09:44Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Description\r\nAs BPE-dropout is applied to sentencepiece recently, it can be tokenized based on sampling.\r\nalpha = 1 is for optimally training not for inference.\r\n\r\nDefault `alpha=1` isn't appropriate because most users and models provided by gluonnlp expect to deterministically tokenize.\r\n\r\nhttps://github.com/google/sentencepiece/issues/371\r\n\r\n## To Reproduce\r\n```\r\npath = gluon.utils.download('https://kobert.blob.core.windows.net/models/kogpt2/tokenizer/kogpt2_news_wiki_ko_cased_818bfa919d.spiece')\r\ntok = nlp.data.SentencepieceTokenizer(path)\r\ntok('\uc548\ub155\ud558\uc138\uc694.')  \r\n['\u2581', '\uc548', '\ub155', '\ud558', '\uc138', '\uc694', '.']\r\ntok = nlp.data.SentencepieceTokenizer(path, 0, 0.5)                                                                                                                                              \r\ntok('\uc548\ub155\ud558\uc138\uc694.')                                                                                                                                                                               \r\n['\u2581', '\uc548', '\ub155', '\ud558', '\uc138\uc694', '.']\r\ntok('\uc548\ub155\ud558\uc138\uc694.')                                                                                                                                                                               \r\n['\u2581\uc548', '\ub155', '\ud558', '\uc138\uc694', '.']\r\ntok('\uc548\ub155\ud558\uc138\uc694.')                                                                                                                                                                               \r\n['\u2581\uc548\ub155', '\ud558', '\uc138\uc694', '.']\r\ntok('\uc548\ub155\ud558\uc138\uc694.')                     \r\ntok = nlp.data.SentencepieceTokenizer(path, num_best=0, alpha=0)\r\ntok('\uc548\ub155\ud558\uc138\uc694.')                                                                                                                                                                               \r\n['\u2581\uc548\ub155\ud558\uc138\uc694', '.']\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1238", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1238/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1238/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1238/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1238", "id": 630132128, "node_id": "MDU6SXNzdWU2MzAxMzIxMjg=", "number": 1238, "title": "loading the pre-trained BERT with (pretrained=True) crashing", "user": {"login": "Hildweig", "id": 34550304, "node_id": "MDQ6VXNlcjM0NTUwMzA0", "avatar_url": "https://avatars0.githubusercontent.com/u/34550304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hildweig", "html_url": "https://github.com/Hildweig", "followers_url": "https://api.github.com/users/Hildweig/followers", "following_url": "https://api.github.com/users/Hildweig/following{/other_user}", "gists_url": "https://api.github.com/users/Hildweig/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hildweig/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hildweig/subscriptions", "organizations_url": "https://api.github.com/users/Hildweig/orgs", "repos_url": "https://api.github.com/users/Hildweig/repos", "events_url": "https://api.github.com/users/Hildweig/events{/privacy}", "received_events_url": "https://api.github.com/users/Hildweig/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-03T16:11:28Z", "updated_at": "2020-06-05T11:51:38Z", "closed_at": "2020-06-05T11:51:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI am trying to do this tutorial https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html\r\nand whenever I arrive to the 3rd cell I get a crash in collab.\r\n### Error Message\r\n\r\nTimestamp | Level | Message\r\n-- | -- | --\r\nJun 3, 2020, 2:28:19 PM | WARNING | WARNING:root:kernel ad3dbdee-4b57-493d-bf27-40be9330ee20 restarted\r\nJun 3, 2020, 2:28:19 PM | INFO | KernelRestarter: restarting kernel (1/5), keep random ports\r\nJun 3, 2020, 2:28:18 PM | WARNING | [bt] (1) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(mxnet::CopyFromTo(mxnet::NDArray const&, mxnet::NDArray const&, int, bool)+0x6db) [0x7faa2db0f28b]\r\n\r\n\r\n## To Reproduce\r\n!pip install --pre --upgrade mxnet\r\n!pip install gluonnlp\r\n\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\n\r\nimport io\r\nimport random\r\nimport numpy as np\r\nimport mxnet as mx\r\nimport gluonnlp as nlp\r\nfrom gluonnlp.calibration import BertLayerCollector\r\n# this notebook assumes that all required scripts are already\r\n# downloaded from the corresponding tutorial webpage on http://gluon-nlp.mxnet.io\r\n%cd /content/sentence_embedding #this one contains the bert file of the tutorial\r\nfrom bert import data\r\nnlp.utils.check_version('0.8.1')\r\nnp.random.seed(100)\r\nrandom.seed(100)\r\nmx.random.seed(10000)\r\n# change `ctx` to `mx.cpu()` if no GPU is available.\r\ntry:\r\n    ctx = mx.gpu(0)\r\nexcept:\r\n    ctx = mx.cpu()\r\n### Steps to reproduce\r\nafter doing those up: the one that makes it crash is this one\r\n\r\nbert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\r\n                                             dataset_name='book_corpus_wiki_en_uncased',\r\n                                             pretrained=True, ctx=ctx, use_pooler=True,\r\n                                             use_decoder=False, use_classifier=False)\r\n\r\n## What have you tried to solve it?\r\n\r\n1. I tried to replace it with this one : \r\nbert_base, vocabulary = nlp.model.bert.get_bert_model(model_name='bert_12_768_12',\r\n                                                      dataset_name='book_corpus_wiki_en_uncased', \r\n                                                      pretrained=True,\r\n                                                      ctx=ctx,\r\n                                                      use_pooler=True,\r\n                                                      use_decoder=False,\r\n                                                      use_classifier=False)\r\n\r\n2. Also tried to remove some parameters and I realized that it crashes when pretrained = True, still I need it to be like that.\r\n\r\n## Environment\r\n----------Python Info----------\r\nVersion      : 3.6.9\r\nCompiler     : GCC 8.4.0\r\nBuild        : ('default', 'Apr 18 2020 01:56:04')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.3.1\r\nDirectory    : /usr/local/lib/python3.6/dist-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.6.0\r\nDirectory    : /usr/local/lib/python3.6/dist-packages/mxnet\r\nNum GPUs     : 0\r\nCommit Hash   : 6eec9da55c5096079355d1f1a5fa58dcf35d6752\r\n----------System Info----------\r\nPlatform     : Linux-4.19.104+-x86_64-with-Ubuntu-18.04-bionic\r\nsystem       : Linux\r\nnode         : a7a11b36dda7\r\nrelease      : 4.19.104+\r\nversion      : #1 SMP Wed Feb 19 05:26:34 PST 2020\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              2\r\nOn-line CPU(s) list: 0,1\r\nThread(s) per core:  2\r\nCore(s) per socket:  1\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               63\r\nModel name:          Intel(R) Xeon(R) CPU @ 2.30GHz\r\nStepping:            0\r\nCPU MHz:             2300.000\r\nBogoMIPS:            4600.00\r\nHypervisor vendor:   KVM\r\nVirtualization type: full\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            46080K\r\nNUMA node0 CPU(s):   0,1\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0029 sec, LOAD: 0.6395 sec.\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0029 sec, LOAD: 0.5304 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.1030 sec, LOAD: 0.4462 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.0337 sec, LOAD: 0.3244 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0170 sec, LOAD: 0.2023 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0310 sec, LOAD: 0.6803 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0088 sec, LOAD: 0.3790 sec.\r\nError open Conda: https://repo.continuum.io/pkgs/free/, HTTP Error 403: Forbidden, DNS finished in 0.010742664337158203 sec.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1234", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1234/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1234/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1234/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1234", "id": 625275680, "node_id": "MDU6SXNzdWU2MjUyNzU2ODA=", "number": 1234, "title": "Is decoder.decode_seq() in gluonnlp 0.8.3 replaced by decoder() in 0.9 ?", "user": {"login": "chenjunweii", "id": 27069126, "node_id": "MDQ6VXNlcjI3MDY5MTI2", "avatar_url": "https://avatars2.githubusercontent.com/u/27069126?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenjunweii", "html_url": "https://github.com/chenjunweii", "followers_url": "https://api.github.com/users/chenjunweii/followers", "following_url": "https://api.github.com/users/chenjunweii/following{/other_user}", "gists_url": "https://api.github.com/users/chenjunweii/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenjunweii/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenjunweii/subscriptions", "organizations_url": "https://api.github.com/users/chenjunweii/orgs", "repos_url": "https://api.github.com/users/chenjunweii/repos", "events_url": "https://api.github.com/users/chenjunweii/events{/privacy}", "received_events_url": "https://api.github.com/users/chenjunweii/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-27T00:04:00Z", "updated_at": "2020-05-27T01:23:38Z", "closed_at": "2020-05-27T01:23:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a code written before 0.9, and I use `Transormer.decoder.decode_seq` as teacher forcing to finetune BERT, after upgrading to 0.9, `deocder.decode_seq()` seems replaced by `decoder()`, am I Wrong ?\r\n\r\nbut the finetuning never converge after upgrading from version 0.8.3 to 0.9 and replacing `decode_seq() `with` decoder()`\r\n\r\nBut if I change back to 0.8.3 with `decode_seq()` the code works perfectly, loss function decrease very stable, and text generate by beam search is also correct, any idea ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1233", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1233/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1233/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1233/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1233", "id": 620449662, "node_id": "MDU6SXNzdWU2MjA0NDk2NjI=", "number": 1233, "title": "TypeError: can't pickle SwigPyObject objects when pickling SentencepieceTokenizer", "user": {"login": "DushyantaDhyani", "id": 2116331, "node_id": "MDQ6VXNlcjIxMTYzMzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/2116331?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DushyantaDhyani", "html_url": "https://github.com/DushyantaDhyani", "followers_url": "https://api.github.com/users/DushyantaDhyani/followers", "following_url": "https://api.github.com/users/DushyantaDhyani/following{/other_user}", "gists_url": "https://api.github.com/users/DushyantaDhyani/gists{/gist_id}", "starred_url": "https://api.github.com/users/DushyantaDhyani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DushyantaDhyani/subscriptions", "organizations_url": "https://api.github.com/users/DushyantaDhyani/orgs", "repos_url": "https://api.github.com/users/DushyantaDhyani/repos", "events_url": "https://api.github.com/users/DushyantaDhyani/events{/privacy}", "received_events_url": "https://api.github.com/users/DushyantaDhyani/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-18T19:24:42Z", "updated_at": "2020-07-30T08:01:31Z", "closed_at": "2020-07-30T08:01:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nAs stated [here](https://github.com/google/sentencepiece/issues/387) , pickling sentencepiece tokenizer returns an error.\r\n\r\n### Error Message\r\n`Traceback (most recent call last):\r\n  File \"tokenizer_repro.py\", line 10, in <module>\r\n    pickle.dump(tokenizer, writer)\r\nTypeError: can't pickle SwigPyObject objects`\r\n\r\n## To Reproduce\r\n```\r\nfrom gluonnlp.data import SentencepieceTokenizer\r\nfrom mxnet import gluon\r\nimport pickle\r\nurl = \"http://repo.mxnet.io/gluon/dataset/vocab/test-0690baed.bpe\"\r\nf = gluon.utils.download(url, overwrite=True)\r\ntokenizer = SentencepieceTokenizer(f)\r\nwith open(\"sptokenizer.pickle\", \"wb\") as writer:\r\n    pickle.dump(tokenizer, writer)\r\n```\r\n\r\n\r\n## What have you tried to solve it?\r\nAs mentioned in the issue above, changing `_SentencepieceProcessor` as below fixes the issue\r\n\r\n```\r\nclass _SentencepieceProcessor:\r\n    def __init__(self, path):\r\n        try:\r\n            import sentencepiece\r\n        except ImportError:\r\n            raise ImportError(\r\n                'sentencepiece is not installed. You must install sentencepiece '\r\n                'in order to use the Sentencepiece tokenizer and detokenizer. '\r\n                'You can refer to the official installation guide '\r\n                'in https://github.com/google/sentencepiece#installation')\r\n        self._vocab_file = path\r\n        self._processor = sentencepiece.SentencePieceProcessor()\r\n        self._processor.Load(path)\r\n\r\n    def __len__(self):\r\n        return len(self._processor)\r\n\r\n    @property\r\n    def tokens(self):\r\n        return [self._processor.id_to_piece(i) for i in range(len(self))]\r\n\r\n    def __getstate__(self):\r\n        state = self.__dict__.copy()\r\n        state[\"_processor\"] = None\r\n        state[\"_vocab_file\"] = None\r\n        return state, self._vocab_file\r\n\r\n    def __setstate__(self, d):\r\n        self.__dict__, self.vocab_file = d\r\n        self._processor = sentencepiece.SentencePieceProcessor()\r\n        self._processor.Load(self.vocab_file)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1221", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1221/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1221/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1221/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1221", "id": 612631452, "node_id": "MDU6SXNzdWU2MTI2MzE0NTI=", "number": 1221, "title": "albert model requested!", "user": {"login": "lilongyue", "id": 3581832, "node_id": "MDQ6VXNlcjM1ODE4MzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3581832?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lilongyue", "html_url": "https://github.com/lilongyue", "followers_url": "https://api.github.com/users/lilongyue/followers", "following_url": "https://api.github.com/users/lilongyue/following{/other_user}", "gists_url": "https://api.github.com/users/lilongyue/gists{/gist_id}", "starred_url": "https://api.github.com/users/lilongyue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lilongyue/subscriptions", "organizations_url": "https://api.github.com/users/lilongyue/orgs", "repos_url": "https://api.github.com/users/lilongyue/repos", "events_url": "https://api.github.com/users/lilongyue/events{/privacy}", "received_events_url": "https://api.github.com/users/lilongyue/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-05T14:07:34Z", "updated_at": "2020-07-19T21:49:27Z", "closed_at": "2020-07-19T21:49:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nalbert model size is pretty small and interesting. \r\nA mxnet based pretraining implementation should be helpful to alot of people!\r\n## References\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1220", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1220/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1220/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1220/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1220", "id": 611531896, "node_id": "MDU6SXNzdWU2MTE1MzE4OTY=", "number": 1220, "title": "BeamSearchSampler failing with mx.numpy input", "user": {"login": "pasmargo", "id": 7614942, "node_id": "MDQ6VXNlcjc2MTQ5NDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7614942?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pasmargo", "html_url": "https://github.com/pasmargo", "followers_url": "https://api.github.com/users/pasmargo/followers", "following_url": "https://api.github.com/users/pasmargo/following{/other_user}", "gists_url": "https://api.github.com/users/pasmargo/gists{/gist_id}", "starred_url": "https://api.github.com/users/pasmargo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pasmargo/subscriptions", "organizations_url": "https://api.github.com/users/pasmargo/orgs", "repos_url": "https://api.github.com/users/pasmargo/repos", "events_url": "https://api.github.com/users/pasmargo/events{/privacy}", "received_events_url": "https://api.github.com/users/pasmargo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-03T23:21:33Z", "updated_at": "2020-07-19T21:51:46Z", "closed_at": "2020-07-19T21:51:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nI follow [the instructions to generate sequences with Beam Search](https://gluon-nlp.mxnet.io/examples/sequence_sampling/sequence_sampling.html) and it works correctly when the input is an mx.nd object. However, I get an error message when the input is an mx.numpy object.\r\n\r\nWith the original line, it works correctly:\r\n```\r\ninputs = mx.nd.full(shape=(1,), ctx=ctx, val=bos_ids[-1])\r\n```\r\n\r\nWith this other line, it makes the sampler fail:\r\n```\r\ninputs = mx.numpy.full((1,), bos_ids[-1], ctx=ctx)\r\n```\r\n\r\n### Error Message\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-18-711d82cb4e91> in <module>()\r\n----> 1 generate_sequences(beam_sampler, inputs, begin_states, 5)\r\n\r\n<ipython-input-17-c4c52c7fd9b6> in generate_sequences(sampler, inputs, begin_states, num_print_outcomes)\r\n      1 def generate_sequences(sampler, inputs, begin_states, num_print_outcomes):\r\n      2 \r\n----> 3     samples, scores, valid_lengths = sampler(inputs, begin_states)\r\n      4     samples = samples[0].asnumpy()\r\n      5     scores = scores[0].asnumpy()\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/model/sequence_sampler.py in __call__(self, inputs, states)\r\n    525                                       state_info=state_info)\r\n    526         step_input = _expand_to_beam_size(inputs, beam_size=beam_size,\r\n--> 527                                           batch_size=batch_size).astype(np.int32)\r\n    528         # All beams are initialized to alive\r\n    529         # Generated samples are initialized to be the inputs\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/model/sequence_sampler.py in _expand_to_beam_size(data, beam_size, batch_size, state_info)\r\n    199         new_shape[batch_axis] = batch_size * beam_size\r\n    200         new_shape = tuple(new_shape)\r\n--> 201         return data.expand_dims(batch_axis+1)\\\r\n    202                    .broadcast_axes(axis=batch_axis+1, size=beam_size)\\\r\n    203                    .reshape(new_shape)\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/numpy/multiarray.py in expand_dims(self, *args, **kwargs)\r\n   1435         this array as data.\r\n   1436         \"\"\"\r\n-> 1437         raise AttributeError('mxnet.numpy.ndarray object has no attribute expand_dims')\r\n   1438 \r\n   1439     def tile(self, *args, **kwargs):\r\n\r\nAttributeError: mxnet.numpy.ndarray object has no attribute expand_dims\r\n```\r\n\r\n## To Reproduce\r\n\r\nUse the code for the sequence generation using Beam Search in this link:\r\n\r\nhttps://gluon-nlp.mxnet.io/examples/sequence_sampling/sequence_sampling.html\r\n\r\nAnd substitute the line\r\n\r\n```\r\ninputs = mx.nd.full(shape=(1,), ctx=ctx, val=bos_ids[-1])\r\n```\r\n\r\nwith\r\n\r\n```\r\ninputs = mx.numpy.full((1,), bos_ids[-1], ctx=ctx)\r\n```\r\n\r\n## What have you tried to solve it?\r\n\r\n1. I tried to convert the mx.numpy input to mx.nd with `.as_nd_ndarray()`. It gets passed that error, but then Gluon Blocks requires all outputs to be mx.numpy and it fails in an old reshape method (mx.numpy should not have a named shape argument):\r\n\r\n```\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/model/sequence_sampler.py in hybrid_forward(self, F, samples, valid_length, outputs, scores, beam_alive_mask, states)\r\n    418         beam_size = self._beam_size\r\n    419         # outputs: (batch_size, beam_size, vocab_size)\r\n--> 420         outputs = outputs.reshape(shape=(-4, -1, beam_size, 0))\r\n    421         if self._top_k:\r\n    422             ranks = outputs.argsort(is_ascend=False, dtype='int32')\r\n```\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n```\r\n# paste outputs here\r\n```\r\n----------Python Info----------\r\nVersion      : 3.6.5\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Apr 29 2018 16:14:56')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 10.0.1\r\nDirectory    : /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.6.0\r\nDirectory    : /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet\r\nNum GPUs     : 1\r\nCommit Hash   : 6eec9da55c5096079355d1f1a5fa58dcf35d6752\r\n----------System Info----------\r\nPlatform     : Linux-4.14.171-105.231.amzn1.x86_64-x86_64-with-glibc2.9\r\nsystem       : Linux\r\nnode         : ip-172-16-83-169\r\nrelease      : 4.14.171-105.231.amzn1.x86_64\r\nversion      : #1 SMP Thu Feb 27 23:49:15 UTC 2020\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    2\r\nCore(s) per socket:    2\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2701.008\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.14\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-3\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0022 sec, LOAD: 0.4192 sec.\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0005 sec, LOAD: 0.3731 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0927 sec, LOAD: 0.0981 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.0303 sec, LOAD: 0.0695 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0307 sec, LOAD: 0.1809 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0259 sec, LOAD: 0.3750 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0034 sec, LOAD: 0.0990 sec.\r\nError open Conda: https://repo.continuum.io/pkgs/free/, HTTP Error 403: Forbidden, DNS finished in 0.003132343292236328 sec.\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1218", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1218/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1218/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1218/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1218", "id": 611404527, "node_id": "MDU6SXNzdWU2MTE0MDQ1Mjc=", "number": 1218, "title": "Deprecation warning due to invalid escape sequences", "user": {"login": "tirkarthi", "id": 3972343, "node_id": "MDQ6VXNlcjM5NzIzNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3972343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tirkarthi", "html_url": "https://github.com/tirkarthi", "followers_url": "https://api.github.com/users/tirkarthi/followers", "following_url": "https://api.github.com/users/tirkarthi/following{/other_user}", "gists_url": "https://api.github.com/users/tirkarthi/gists{/gist_id}", "starred_url": "https://api.github.com/users/tirkarthi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tirkarthi/subscriptions", "organizations_url": "https://api.github.com/users/tirkarthi/orgs", "repos_url": "https://api.github.com/users/tirkarthi/repos", "events_url": "https://api.github.com/users/tirkarthi/events{/privacy}", "received_events_url": "https://api.github.com/users/tirkarthi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-03T12:35:38Z", "updated_at": "2020-05-04T18:55:39Z", "closed_at": "2020-05-04T18:55:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nDeprecation warning due to invalid escape sequences. Using raw strings or escaping them again helps in resolving this. Check https://github.com/asottile/pyupgrade/ for automatic fix of this.\r\n\r\n## To Reproduce\r\n\r\n```\r\nfind . -iname '*.py' | grep -Ev 'rdf4|doc|benchmark|tool' | xargs -P4 -I{} python3.8 -Wall -m py_compile {}\r\n./ci/batch/submit-job.py:95: DeprecationWarning: invalid escape sequence \\-\r\n  jobName = re.sub('[^A-Za-z0-9_\\-]', '', args.name)[:128]  # Enforce AWS Batch jobName rules\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1217", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1217/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1217/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1217/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1217", "id": 611165099, "node_id": "MDU6SXNzdWU2MTExNjUwOTk=", "number": 1217, "title": "TextCNN rand model downloads pretrained vectors even if not needed", "user": {"login": "avinashsai", "id": 22453634, "node_id": "MDQ6VXNlcjIyNDUzNjM0", "avatar_url": "https://avatars0.githubusercontent.com/u/22453634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/avinashsai", "html_url": "https://github.com/avinashsai", "followers_url": "https://api.github.com/users/avinashsai/followers", "following_url": "https://api.github.com/users/avinashsai/following{/other_user}", "gists_url": "https://api.github.com/users/avinashsai/gists{/gist_id}", "starred_url": "https://api.github.com/users/avinashsai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/avinashsai/subscriptions", "organizations_url": "https://api.github.com/users/avinashsai/orgs", "repos_url": "https://api.github.com/users/avinashsai/repos", "events_url": "https://api.github.com/users/avinashsai/events{/privacy}", "received_events_url": "https://api.github.com/users/avinashsai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 963101581, "node_id": "MDU6TGFiZWw5NjMxMDE1ODE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/discussion", "name": "discussion", "color": "c5def5", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-02T11:30:29Z", "updated_at": "2020-05-07T19:00:44Z", "closed_at": "2020-05-07T19:00:43Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "1. TextCNN rand model downloads pretrained word vectors even if not needed. rand model initializes word vectors randomly and updates in the training process. So, I think there is not need to download word vectors for this model. \r\n\r\n2. There should be a flag passed to ```_build_vocab```  function representing the type of model. If the model is other than rand, then pretrained vectors should be downloaded.\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1206", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1206/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1206/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1206/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1206", "id": 602417670, "node_id": "MDU6SXNzdWU2MDI0MTc2NzA=", "number": 1206, "title": "Load custom pre-trained Fasttext model", "user": {"login": "Avi197", "id": 22101554, "node_id": "MDQ6VXNlcjIyMTAxNTU0", "avatar_url": "https://avatars2.githubusercontent.com/u/22101554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Avi197", "html_url": "https://github.com/Avi197", "followers_url": "https://api.github.com/users/Avi197/followers", "following_url": "https://api.github.com/users/Avi197/following{/other_user}", "gists_url": "https://api.github.com/users/Avi197/gists{/gist_id}", "starred_url": "https://api.github.com/users/Avi197/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Avi197/subscriptions", "organizations_url": "https://api.github.com/users/Avi197/orgs", "repos_url": "https://api.github.com/users/Avi197/repos", "events_url": "https://api.github.com/users/Avi197/events{/privacy}", "received_events_url": "https://api.github.com/users/Avi197/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-18T09:20:40Z", "updated_at": "2020-04-18T22:29:18Z", "closed_at": "2020-04-18T22:28:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Does gluon-nlp support custom pre-trained Fasttext model? I want to use a few functions of gluon but i don't want to train a new model\r\n\r\nThanks in advance", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1205", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1205/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1205/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1205/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1205", "id": 601742534, "node_id": "MDU6SXNzdWU2MDE3NDI1MzQ=", "number": 1205, "title": "Can't reproduce the accuracy with pre-trained Large Scale Word Language Model (gbw dataset) ", "user": {"login": "ciyongch", "id": 17443780, "node_id": "MDQ6VXNlcjE3NDQzNzgw", "avatar_url": "https://avatars2.githubusercontent.com/u/17443780?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ciyongch", "html_url": "https://github.com/ciyongch", "followers_url": "https://api.github.com/users/ciyongch/followers", "following_url": "https://api.github.com/users/ciyongch/following{/other_user}", "gists_url": "https://api.github.com/users/ciyongch/gists{/gist_id}", "starred_url": "https://api.github.com/users/ciyongch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ciyongch/subscriptions", "organizations_url": "https://api.github.com/users/ciyongch/orgs", "repos_url": "https://api.github.com/users/ciyongch/repos", "events_url": "https://api.github.com/users/ciyongch/events{/privacy}", "received_events_url": "https://api.github.com/users/ciyongch/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-04-17T06:46:07Z", "updated_at": "2020-07-20T02:14:46Z", "closed_at": "2020-07-19T21:51:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nCan't reproduce the same accuracy with pre-trained Large Scale Word Language Model based on gbw dataset, following the [guideline](https://gluon-nlp.mxnet.io/examples/language_model/language_model.html).\r\nThe accuracy given in [tutorial](https://gluon-nlp.mxnet.io/model_zoo/language_model/index.html#large-scale-word-language-model) is:\r\n  `[1] LSTM-2048-512 (Test PPL 43.62)`\r\n\r\nWhat I got is:\r\n  `Best validation loss 9.40, val ppl 12130.84`\r\n  `Best test loss 9.42, test ppl 12303.21`\r\n\r\n@eric-haibin-lin \r\n### Error Message\r\n```\r\nBigRNN(\r\n  (embedding): HybridSequential(\r\n    (0): Embedding(793471 -> 512, float32)\r\n    (1): Dropout(p = 0.1, axes=())\r\n  )\r\n  (encoder): HybridSequentialRNNCell(\r\n  (0): LSTMPCell(512 -> 8192 -> 512)\r\n  (1): DropoutCell(rate=0.1, axes=())\r\n  )\r\n  (decoder): Dense(512 -> 793471, linear)\r\n)\r\nVocab(size=793471, unk=\"<unk>\", reserved=\"['<pad>', '<eos>']\")\r\nBest validation loss 9.40, val ppl 12130.84\r\nBest test loss 9.42, test ppl 12303.21\r\n```\r\n\r\n## To Reproduce\r\nRun the script [awd_lstm.py](https://gist.github.com/ciyongch/d975fa0df3d6e3b76efa0f2c2ce427ca) with MXNet master branch.\r\n\r\n### Steps to reproduce\r\n`python awd_lstm.py`\r\n\r\n\r\n## What have you tried to solve it?\r\nNone\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n----------Python Info----------\r\nVersion      : 3.7.5\r\nCompiler     : GCC 7.3.0\r\nBuild        : ('default', 'Oct 25 2019 15:51:11')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.3.1\r\nDirectory    : /home/ciyong/miniconda3/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 2.0.0\r\nDirectory    : /tmp/mxnet/incubator-mxnet/python/mxnet\r\nNum GPUs     : 0\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\nPlatform     : Linux-3.10.0-957.el7.x86_64-x86_64-with-centos-7.6.1810-Core\r\nsystem       : Linux\r\nnode         : mlt2-clx094\r\nrelease      : 3.10.0-957.el7.x86_64\r\nversion      : #1 SMP Thu Nov 8 23:39:32 UTC 2018\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                112\r\nOn-line CPU(s) list:   0-111\r\nThread(s) per core:    2\r\nCore(s) per socket:    28\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 85\r\nModel name:            Intel(R) Xeon(R) Platinum 8280L CPU @ 2.70GHz\r\nStepping:              7\r\nCPU MHz:               3310.070\r\nCPU max MHz:           4000.0000\r\nCPU min MHz:           1000.0000\r\nBogoMIPS:              5400.00\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              1024K\r\nL3 cache:              39424K\r\nNUMA node0 CPU(s):     0-27,56-83\r\nNUMA node1 CPU(s):     28-55,84-111\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni spec_ctrl intel_stibp flush_l1d arch_capabilities\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0103 sec, LOAD: 2.1315 sec.\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0013 sec, LOAD: 1.9952 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0066 sec, LOAD: 2.3918 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.1313 sec, LOAD: 0.5946 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0058 sec, LOAD: 0.7973 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 5.7738 sec, LOAD: 2.1621 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0015 sec, LOAD: 11.5346 sec.\r\nError open Conda: https://repo.continuum.io/pkgs/free/, HTTP Error 403: Forbidden, DNS finished in 0.010091543197631836 sec.\r\n\r\n\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1204", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1204/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1204/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1204/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1204", "id": 599441869, "node_id": "MDU6SXNzdWU1OTk0NDE4Njk=", "number": 1204, "title": "BERT fine-tuning on SQuAD 1.1 doesn't converge", "user": {"login": "TaoLv", "id": 22437510, "node_id": "MDQ6VXNlcjIyNDM3NTEw", "avatar_url": "https://avatars2.githubusercontent.com/u/22437510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TaoLv", "html_url": "https://github.com/TaoLv", "followers_url": "https://api.github.com/users/TaoLv/followers", "following_url": "https://api.github.com/users/TaoLv/following{/other_user}", "gists_url": "https://api.github.com/users/TaoLv/gists{/gist_id}", "starred_url": "https://api.github.com/users/TaoLv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TaoLv/subscriptions", "organizations_url": "https://api.github.com/users/TaoLv/orgs", "repos_url": "https://api.github.com/users/TaoLv/repos", "events_url": "https://api.github.com/users/TaoLv/events{/privacy}", "received_events_url": "https://api.github.com/users/TaoLv/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-04-14T09:51:44Z", "updated_at": "2020-05-08T16:53:33Z", "closed_at": "2020-05-08T16:53:33Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Description\r\n\r\n\r\n```\r\nNFO:gluonnlp:10:28:18 Namespace(accumulate=None, batch_size=12, bert_dataset='book_corpus_wiki_en_uncased', bert_model='bert_12_768_12', calib_mode='customize', comm_backend=None, debug=False, deploy=False, doc_stride=128, dtype='float32', epochs=2, gpu=True, log_interval=50, lr=3e-05, max_answer_length=30, max_query_length=64, max_seq_length=384, model_parameters=None, model_prefix=None, n_best_size=20, null_score_diff_threshold=0.0, num_calib_batches=10, only_calibration=False, only_predict=False, optimizer='adam', output_dir='./output_dir', pretrained_bert_parameters=None, quantized_dtype='auto', round_to=None, sentencepiece=None, test_batch_size=24, training_steps=None, uncased=True, version_2=False, warmup_ratio=0.1)\r\nINFO:gluonnlp:10:28:25 Loading train data...\r\nINFO:gluonnlp:10:28:26 Number of records in Train data:87599\r\nINFO:gluonnlp:10:29:04 The number of examples after preprocessing:88641\r\nDone! Transform dataset costs 37.85 seconds.\r\nINFO:gluonnlp:10:29:04 Start Training\r\nINFO:gluonnlp:10:29:19 Batch: 49/7387, Loss=5.7366, lr=0.0000010 Thoughput=41.72 samples/s\r\nINFO:gluonnlp:10:29:32 Batch: 99/7387, Loss=5.6931, lr=0.0000020 Thoughput=45.47 samples/s\r\nINFO:gluonnlp:10:29:44 Batch: 149/7387, Loss=5.4705, lr=0.0000030 Thoughput=48.23 samples/s\r\nINFO:gluonnlp:10:29:57 Batch: 199/7387, Loss=5.3252, lr=0.0000041 Thoughput=47.67 samples/s\r\nINFO:gluonnlp:10:30:10 Batch: 249/7387, Loss=5.0779, lr=0.0000051 Thoughput=46.84 samples/s\r\nINFO:gluonnlp:10:30:22 Batch: 299/7387, Loss=4.8238, lr=0.0000061 Thoughput=47.40 samples/s\r\nINFO:gluonnlp:10:30:35 Batch: 349/7387, Loss=4.5862, lr=0.0000071 Thoughput=46.46 samples/s\r\nINFO:gluonnlp:10:30:48 Batch: 399/7387, Loss=4.2767, lr=0.0000081 Thoughput=47.08 samples/s\r\nINFO:gluonnlp:10:31:01 Batch: 449/7387, Loss=4.1058, lr=0.0000091 Thoughput=46.85 samples/s\r\nINFO:gluonnlp:10:31:13 Batch: 499/7387, Loss=4.0107, lr=0.0000102 Thoughput=48.32 samples/s\r\nINFO:gluonnlp:10:31:26 Batch: 549/7387, Loss=3.8868, lr=0.0000112 Thoughput=48.08 samples/s\r\nINFO:gluonnlp:10:31:39 Batch: 599/7387, Loss=3.7927, lr=0.0000122 Thoughput=46.52 samples/s\r\nINFO:gluonnlp:10:31:51 Batch: 649/7387, Loss=3.6045, lr=0.0000132 Thoughput=48.48 samples/s\r\nINFO:gluonnlp:10:32:04 Batch: 699/7387, Loss=3.3329, lr=0.0000142 Thoughput=45.18 samples/s\r\nINFO:gluonnlp:10:32:18 Batch: 749/7387, Loss=3.1370, lr=0.0000152 Thoughput=43.95 samples/s\r\nINFO:gluonnlp:10:32:31 Batch: 799/7387, Loss=2.9287, lr=0.0000162 Thoughput=45.27 samples/s\r\nINFO:gluonnlp:10:32:45 Batch: 849/7387, Loss=2.9110, lr=0.0000173 Thoughput=44.93 samples/s\r\nINFO:gluonnlp:10:32:59 Batch: 899/7387, Loss=2.7632, lr=0.0000183 Thoughput=41.90 samples/s\r\nINFO:gluonnlp:10:33:12 Batch: 949/7387, Loss=2.7786, lr=0.0000193 Thoughput=45.55 samples/s\r\nINFO:gluonnlp:10:33:25 Batch: 999/7387, Loss=2.8667, lr=0.0000203 Thoughput=45.36 samples/s\r\nINFO:gluonnlp:10:33:39 Batch: 1049/7387, Loss=2.7649, lr=0.0000213 Thoughput=43.45 samples/s\r\nINFO:gluonnlp:10:33:52 Batch: 1099/7387, Loss=2.7784, lr=0.0000223 Thoughput=46.00 samples/s\r\nINFO:gluonnlp:10:34:06 Batch: 1149/7387, Loss=2.6492, lr=0.0000234 Thoughput=44.58 samples/s\r\nINFO:gluonnlp:10:34:19 Batch: 1199/7387, Loss=2.7466, lr=0.0000244 Thoughput=43.60 samples/s\r\nINFO:gluonnlp:10:34:33 Batch: 1249/7387, Loss=2.7283, lr=0.0000254 Thoughput=44.27 samples/s\r\nINFO:gluonnlp:10:34:47 Batch: 1299/7387, Loss=2.6654, lr=0.0000264 Thoughput=43.96 samples/s\r\nINFO:gluonnlp:10:35:00 Batch: 1349/7387, Loss=2.7920, lr=0.0000274 Thoughput=44.62 samples/s\r\nINFO:gluonnlp:10:35:14 Batch: 1399/7387, Loss=2.8768, lr=0.0000284 Thoughput=43.34 samples/s\r\nINFO:gluonnlp:10:35:28 Batch: 1449/7387, Loss=2.8342, lr=0.0000295 Thoughput=41.64 samples/s\r\nINFO:gluonnlp:10:35:42 Batch: 1499/7387, Loss=2.9186, lr=0.0000299 Thoughput=44.33 samples/s\r\nINFO:gluonnlp:10:35:56 Batch: 1549/7387, Loss=2.8817, lr=0.0000298 Thoughput=41.69 samples/s\r\nINFO:gluonnlp:10:36:10 Batch: 1599/7387, Loss=3.0527, lr=0.0000297 Thoughput=44.38 samples/s\r\nINFO:gluonnlp:10:36:23 Batch: 1649/7387, Loss=3.1255, lr=0.0000296 Thoughput=44.45 samples/s\r\nINFO:gluonnlp:10:36:37 Batch: 1699/7387, Loss=3.1396, lr=0.0000295 Thoughput=43.95 samples/s\r\nINFO:gluonnlp:10:36:51 Batch: 1749/7387, Loss=3.3614, lr=0.0000294 Thoughput=42.61 samples/s\r\nINFO:gluonnlp:10:37:05 Batch: 1799/7387, Loss=3.3383, lr=0.0000293 Thoughput=42.46 samples/s\r\nINFO:gluonnlp:10:37:19 Batch: 1849/7387, Loss=3.4652, lr=0.0000292 Thoughput=44.64 samples/s\r\nINFO:gluonnlp:10:37:32 Batch: 1899/7387, Loss=3.3199, lr=0.0000290 Thoughput=44.89 samples/s\r\nINFO:gluonnlp:10:37:46 Batch: 1949/7387, Loss=3.5690, lr=0.0000289 Thoughput=41.94 samples/s\r\nINFO:gluonnlp:10:38:00 Batch: 1999/7387, Loss=3.5586, lr=0.0000288 Thoughput=44.53 samples/s\r\nINFO:gluonnlp:10:38:14 Batch: 2049/7387, Loss=3.7966, lr=0.0000287 Thoughput=42.84 samples/s\r\nINFO:gluonnlp:10:38:27 Batch: 2099/7387, Loss=3.5441, lr=0.0000286 Thoughput=45.42 samples/s\r\nINFO:gluonnlp:10:38:41 Batch: 2149/7387, Loss=3.7021, lr=0.0000285 Thoughput=43.08 samples/s\r\nINFO:gluonnlp:10:38:54 Batch: 2199/7387, Loss=3.7285, lr=0.0000284 Thoughput=44.25 samples/s\r\nINFO:gluonnlp:10:39:08 Batch: 2249/7387, Loss=3.8293, lr=0.0000283 Thoughput=43.60 samples/s\r\nINFO:gluonnlp:10:39:22 Batch: 2299/7387, Loss=3.8185, lr=0.0000281 Thoughput=44.31 samples/s\r\nINFO:gluonnlp:10:39:35 Batch: 2349/7387, Loss=3.8284, lr=0.0000280 Thoughput=44.55 samples/s\r\nINFO:gluonnlp:10:39:49 Batch: 2399/7387, Loss=4.0185, lr=0.0000279 Thoughput=42.95 samples/s\r\nINFO:gluonnlp:10:40:04 Batch: 2449/7387, Loss=3.9258, lr=0.0000278 Thoughput=41.74 samples/s\r\nINFO:gluonnlp:10:40:17 Batch: 2499/7387, Loss=3.9495, lr=0.0000277 Thoughput=45.10 samples/s\r\nINFO:gluonnlp:10:40:31 Batch: 2549/7387, Loss=3.9302, lr=0.0000276 Thoughput=43.96 samples/s\r\nINFO:gluonnlp:10:40:44 Batch: 2599/7387, Loss=3.9502, lr=0.0000275 Thoughput=45.95 samples/s\r\nINFO:gluonnlp:10:40:57 Batch: 2649/7387, Loss=3.9685, lr=0.0000274 Thoughput=44.44 samples/s\r\nINFO:gluonnlp:10:41:10 Batch: 2699/7387, Loss=4.0349, lr=0.0000272 Thoughput=45.72 samples/s\r\nINFO:gluonnlp:10:41:24 Batch: 2749/7387, Loss=4.0281, lr=0.0000271 Thoughput=44.21 samples/s\r\nINFO:gluonnlp:10:41:37 Batch: 2799/7387, Loss=3.9801, lr=0.0000270 Thoughput=44.92 samples/s\r\nINFO:gluonnlp:10:41:50 Batch: 2849/7387, Loss=3.9873, lr=0.0000269 Thoughput=45.49 samples/s\r\nINFO:gluonnlp:10:42:04 Batch: 2899/7387, Loss=4.1328, lr=0.0000268 Thoughput=43.60 samples/s\r\nINFO:gluonnlp:10:42:17 Batch: 2949/7387, Loss=4.0381, lr=0.0000267 Thoughput=46.05 samples/s\r\nINFO:gluonnlp:10:42:30 Batch: 2999/7387, Loss=3.9962, lr=0.0000266 Thoughput=45.34 samples/s\r\nINFO:gluonnlp:10:42:44 Batch: 3049/7387, Loss=4.0731, lr=0.0000265 Thoughput=44.03 samples/s\r\nINFO:gluonnlp:10:42:57 Batch: 3099/7387, Loss=4.1017, lr=0.0000263 Thoughput=44.74 samples/s\r\nINFO:gluonnlp:10:43:11 Batch: 3149/7387, Loss=3.9907, lr=0.0000262 Thoughput=44.34 samples/s\r\nINFO:gluonnlp:10:43:24 Batch: 3199/7387, Loss=4.0384, lr=0.0000261 Thoughput=45.02 samples/s\r\nINFO:gluonnlp:10:43:38 Batch: 3249/7387, Loss=4.0809, lr=0.0000260 Thoughput=42.78 samples/s\r\nINFO:gluonnlp:10:43:52 Batch: 3299/7387, Loss=3.9960, lr=0.0000259 Thoughput=44.90 samples/s\r\nINFO:gluonnlp:10:44:05 Batch: 3349/7387, Loss=4.0318, lr=0.0000258 Thoughput=44.17 samples/s\r\nINFO:gluonnlp:10:44:19 Batch: 3399/7387, Loss=4.0101, lr=0.0000257 Thoughput=44.25 samples/s\r\nINFO:gluonnlp:10:44:33 Batch: 3449/7387, Loss=4.0862, lr=0.0000255 Thoughput=43.34 samples/s\r\nINFO:gluonnlp:10:44:46 Batch: 3499/7387, Loss=4.0828, lr=0.0000254 Thoughput=43.57 samples/s\r\nINFO:gluonnlp:10:45:00 Batch: 3549/7387, Loss=4.1510, lr=0.0000253 Thoughput=45.25 samples/s\r\nINFO:gluonnlp:10:45:12 Batch: 3599/7387, Loss=4.0614, lr=0.0000252 Thoughput=46.77 samples/s\r\nINFO:gluonnlp:10:45:27 Batch: 3649/7387, Loss=4.0762, lr=0.0000251 Thoughput=41.75 samples/s\r\nINFO:gluonnlp:10:45:40 Batch: 3699/7387, Loss=4.0421, lr=0.0000250 Thoughput=45.71 samples/s\r\nINFO:gluonnlp:10:45:53 Batch: 3749/7387, Loss=4.1429, lr=0.0000249 Thoughput=44.66 samples/s\r\nINFO:gluonnlp:10:46:07 Batch: 3799/7387, Loss=4.0960, lr=0.0000248 Thoughput=45.11 samples/s\r\nINFO:gluonnlp:10:46:21 Batch: 3849/7387, Loss=4.1295, lr=0.0000246 Thoughput=40.82 samples/s\r\nINFO:gluonnlp:10:46:35 Batch: 3899/7387, Loss=4.0449, lr=0.0000245 Thoughput=45.64 samples/s\r\nINFO:gluonnlp:10:46:48 Batch: 3949/7387, Loss=4.0744, lr=0.0000244 Thoughput=43.96 samples/s\r\nINFO:gluonnlp:10:47:01 Batch: 3999/7387, Loss=4.0502, lr=0.0000243 Thoughput=45.63 samples/s\r\nINFO:gluonnlp:10:47:15 Batch: 4049/7387, Loss=4.1235, lr=0.0000242 Thoughput=45.42 samples/s\r\nINFO:gluonnlp:10:47:28 Batch: 4099/7387, Loss=4.1194, lr=0.0000241 Thoughput=44.43 samples/s\r\nINFO:gluonnlp:10:47:42 Batch: 4149/7387, Loss=4.1620, lr=0.0000240 Thoughput=43.85 samples/s\r\nINFO:gluonnlp:10:47:56 Batch: 4199/7387, Loss=4.1474, lr=0.0000239 Thoughput=42.49 samples/s\r\nINFO:gluonnlp:10:48:09 Batch: 4249/7387, Loss=4.1311, lr=0.0000237 Thoughput=44.33 samples/s\r\nINFO:gluonnlp:10:48:23 Batch: 4299/7387, Loss=4.1637, lr=0.0000236 Thoughput=44.21 samples/s\r\nINFO:gluonnlp:10:48:36 Batch: 4349/7387, Loss=4.1676, lr=0.0000235 Thoughput=44.64 samples/s\r\nINFO:gluonnlp:10:48:50 Batch: 4399/7387, Loss=4.0311, lr=0.0000234 Thoughput=45.67 samples/s\r\nINFO:gluonnlp:10:49:03 Batch: 4449/7387, Loss=4.1035, lr=0.0000233 Thoughput=45.05 samples/s\r\nINFO:gluonnlp:10:49:17 Batch: 4499/7387, Loss=4.1394, lr=0.0000232 Thoughput=43.84 samples/s\r\nINFO:gluonnlp:10:49:30 Batch: 4549/7387, Loss=4.1112, lr=0.0000231 Thoughput=45.08 samples/s\r\nINFO:gluonnlp:10:49:43 Batch: 4599/7387, Loss=4.1363, lr=0.0000230 Thoughput=44.49 samples/s\r\nINFO:gluonnlp:10:49:57 Batch: 4649/7387, Loss=4.0765, lr=0.0000228 Thoughput=44.56 samples/s\r\nINFO:gluonnlp:10:50:10 Batch: 4699/7387, Loss=4.1965, lr=0.0000227 Thoughput=45.77 samples/s\r\nINFO:gluonnlp:10:50:24 Batch: 4749/7387, Loss=4.1263, lr=0.0000226 Thoughput=42.68 samples/s\r\nINFO:gluonnlp:10:50:37 Batch: 4799/7387, Loss=4.0919, lr=0.0000225 Thoughput=46.86 samples/s\r\nINFO:gluonnlp:10:50:51 Batch: 4849/7387, Loss=4.2508, lr=0.0000224 Thoughput=43.28 samples/s\r\nINFO:gluonnlp:10:51:05 Batch: 4899/7387, Loss=4.2040, lr=0.0000223 Thoughput=42.47 samples/s\r\nINFO:gluonnlp:10:51:18 Batch: 4949/7387, Loss=4.1226, lr=0.0000222 Thoughput=46.83 samples/s\r\nINFO:gluonnlp:10:51:31 Batch: 4999/7387, Loss=4.1356, lr=0.0000221 Thoughput=44.62 samples/s\r\nINFO:gluonnlp:10:51:45 Batch: 5049/7387, Loss=4.1283, lr=0.0000219 Thoughput=43.60 samples/s\r\nINFO:gluonnlp:10:51:58 Batch: 5099/7387, Loss=4.2041, lr=0.0000218 Thoughput=44.99 samples/s\r\nINFO:gluonnlp:10:52:12 Batch: 5149/7387, Loss=4.1447, lr=0.0000217 Thoughput=44.54 samples/s\r\nINFO:gluonnlp:10:52:25 Batch: 5199/7387, Loss=4.1981, lr=0.0000216 Thoughput=44.35 samples/s\r\nINFO:gluonnlp:10:52:39 Batch: 5249/7387, Loss=4.1360, lr=0.0000215 Thoughput=44.51 samples/s\r\nINFO:gluonnlp:10:52:52 Batch: 5299/7387, Loss=4.2430, lr=0.0000214 Thoughput=43.69 samples/s\r\nINFO:gluonnlp:10:53:06 Batch: 5349/7387, Loss=4.1508, lr=0.0000213 Thoughput=44.36 samples/s\r\nINFO:gluonnlp:10:53:19 Batch: 5399/7387, Loss=4.0919, lr=0.0000211 Thoughput=44.89 samples/s\r\nINFO:gluonnlp:10:53:33 Batch: 5449/7387, Loss=4.2194, lr=0.0000210 Thoughput=44.67 samples/s\r\nINFO:gluonnlp:10:53:46 Batch: 5499/7387, Loss=4.1684, lr=0.0000209 Thoughput=45.08 samples/s\r\nINFO:gluonnlp:10:53:59 Batch: 5549/7387, Loss=4.1586, lr=0.0000208 Thoughput=44.64 samples/s\r\nINFO:gluonnlp:10:54:13 Batch: 5599/7387, Loss=4.1701, lr=0.0000207 Thoughput=44.25 samples/s\r\nINFO:gluonnlp:10:54:26 Batch: 5649/7387, Loss=4.2287, lr=0.0000206 Thoughput=45.33 samples/s\r\nINFO:gluonnlp:10:54:40 Batch: 5699/7387, Loss=4.1584, lr=0.0000205 Thoughput=44.12 samples/s\r\nINFO:gluonnlp:10:54:53 Batch: 5749/7387, Loss=4.1876, lr=0.0000204 Thoughput=45.88 samples/s\r\nINFO:gluonnlp:10:55:06 Batch: 5799/7387, Loss=4.2106, lr=0.0000202 Thoughput=45.62 samples/s\r\nINFO:gluonnlp:10:55:21 Batch: 5849/7387, Loss=4.1353, lr=0.0000201 Thoughput=39.74 samples/s\r\nINFO:gluonnlp:10:55:34 Batch: 5899/7387, Loss=4.1966, lr=0.0000200 Thoughput=45.22 samples/s\r\nINFO:gluonnlp:10:55:48 Batch: 5949/7387, Loss=4.1623, lr=0.0000199 Thoughput=44.90 samples/s\r\nINFO:gluonnlp:10:56:01 Batch: 5999/7387, Loss=4.1149, lr=0.0000198 Thoughput=46.68 samples/s\r\nINFO:gluonnlp:10:56:14 Batch: 6049/7387, Loss=4.1312, lr=0.0000197 Thoughput=44.63 samples/s\r\nINFO:gluonnlp:10:56:27 Batch: 6099/7387, Loss=4.1174, lr=0.0000196 Thoughput=46.13 samples/s\r\nINFO:gluonnlp:10:56:40 Batch: 6149/7387, Loss=4.1856, lr=0.0000195 Thoughput=45.87 samples/s\r\nINFO:gluonnlp:10:56:53 Batch: 6199/7387, Loss=4.0843, lr=0.0000193 Thoughput=47.09 samples/s\r\nINFO:gluonnlp:10:57:07 Batch: 6249/7387, Loss=4.1435, lr=0.0000192 Thoughput=43.75 samples/s\r\nINFO:gluonnlp:10:57:20 Batch: 6299/7387, Loss=4.1400, lr=0.0000191 Thoughput=44.17 samples/s\r\nINFO:gluonnlp:10:57:34 Batch: 6349/7387, Loss=4.1790, lr=0.0000190 Thoughput=42.81 samples/s\r\nINFO:gluonnlp:10:57:48 Batch: 6399/7387, Loss=4.1604, lr=0.0000189 Thoughput=44.76 samples/s\r\nINFO:gluonnlp:10:58:01 Batch: 6449/7387, Loss=4.1715, lr=0.0000188 Thoughput=44.97 samples/s\r\nINFO:gluonnlp:10:58:14 Batch: 6499/7387, Loss=4.0780, lr=0.0000187 Thoughput=44.98 samples/s\r\nINFO:gluonnlp:10:58:28 Batch: 6549/7387, Loss=4.2045, lr=0.0000186 Thoughput=45.08 samples/s\r\nINFO:gluonnlp:10:58:42 Batch: 6599/7387, Loss=4.0806, lr=0.0000184 Thoughput=41.89 samples/s\r\nINFO:gluonnlp:10:58:56 Batch: 6649/7387, Loss=4.1759, lr=0.0000183 Thoughput=41.65 samples/s\r\nINFO:gluonnlp:10:59:10 Batch: 6699/7387, Loss=4.1486, lr=0.0000182 Thoughput=43.76 samples/s\r\nINFO:gluonnlp:10:59:23 Batch: 6749/7387, Loss=4.1671, lr=0.0000181 Thoughput=44.89 samples/s\r\nINFO:gluonnlp:10:59:36 Batch: 6799/7387, Loss=4.1012, lr=0.0000180 Thoughput=46.14 samples/s\r\nINFO:gluonnlp:10:59:50 Batch: 6849/7387, Loss=4.1678, lr=0.0000179 Thoughput=45.07 samples/s\r\nINFO:gluonnlp:11:00:03 Batch: 6899/7387, Loss=4.1457, lr=0.0000178 Thoughput=45.28 samples/s\r\nINFO:gluonnlp:11:00:17 Batch: 6949/7387, Loss=4.2047, lr=0.0000177 Thoughput=42.11 samples/s\r\nINFO:gluonnlp:11:00:30 Batch: 6999/7387, Loss=4.1246, lr=0.0000175 Thoughput=46.11 samples/s\r\nINFO:gluonnlp:11:00:44 Batch: 7049/7387, Loss=4.1637, lr=0.0000174 Thoughput=45.06 samples/s\r\nINFO:gluonnlp:11:00:57 Batch: 7099/7387, Loss=4.2105, lr=0.0000173 Thoughput=43.85 samples/s\r\nINFO:gluonnlp:11:01:10 Batch: 7149/7387, Loss=4.0982, lr=0.0000172 Thoughput=46.40 samples/s\r\nINFO:gluonnlp:11:01:23 Batch: 7199/7387, Loss=4.2186, lr=0.0000171 Thoughput=47.99 samples/s\r\nINFO:gluonnlp:11:01:36 Batch: 7249/7387, Loss=4.1285, lr=0.0000170 Thoughput=45.24 samples/s\r\nINFO:gluonnlp:11:01:50 Batch: 7299/7387, Loss=4.1594, lr=0.0000169 Thoughput=44.19 samples/s\r\nINFO:gluonnlp:11:02:03 Batch: 7349/7387, Loss=4.0565, lr=0.0000167 Thoughput=45.46 samples/s\r\nINFO:gluonnlp:11:02:12 Finish training step: 7387\r\nINFO:gluonnlp:11:02:12 Time cost=1987.69 s, Thoughput=44.60 samples/s\r\nINFO:gluonnlp:11:02:16 Batch: 12/7387, Loss=4.0776, lr=0.0000166 Thoughput=45.75 samples/s\r\nINFO:gluonnlp:11:02:30 Batch: 62/7387, Loss=4.0591, lr=0.0000165 Thoughput=43.75 samples/s\r\nINFO:gluonnlp:11:02:43 Batch: 112/7387, Loss=4.0958, lr=0.0000164 Thoughput=43.51 samples/s\r\nINFO:gluonnlp:11:02:56 Batch: 162/7387, Loss=4.0935, lr=0.0000163 Thoughput=45.73 samples/s\r\nINFO:gluonnlp:11:03:10 Batch: 212/7387, Loss=4.1058, lr=0.0000162 Thoughput=43.64 samples/s\r\nINFO:gluonnlp:11:03:24 Batch: 262/7387, Loss=4.1321, lr=0.0000161 Thoughput=44.69 samples/s\r\nINFO:gluonnlp:11:03:37 Batch: 312/7387, Loss=4.0636, lr=0.0000160 Thoughput=45.16 samples/s\r\nINFO:gluonnlp:11:03:51 Batch: 362/7387, Loss=4.1577, lr=0.0000158 Thoughput=41.34 samples/s\r\nINFO:gluonnlp:11:04:05 Batch: 412/7387, Loss=4.1470, lr=0.0000157 Thoughput=43.45 samples/s\r\nINFO:gluonnlp:11:04:18 Batch: 462/7387, Loss=4.1421, lr=0.0000156 Thoughput=46.59 samples/s\r\nINFO:gluonnlp:11:04:31 Batch: 512/7387, Loss=4.0959, lr=0.0000155 Thoughput=46.75 samples/s\r\nINFO:gluonnlp:11:04:44 Batch: 562/7387, Loss=4.1666, lr=0.0000154 Thoughput=46.41 samples/s\r\nINFO:gluonnlp:11:04:58 Batch: 612/7387, Loss=4.1476, lr=0.0000153 Thoughput=43.52 samples/s\r\nINFO:gluonnlp:11:05:11 Batch: 662/7387, Loss=4.1270, lr=0.0000152 Thoughput=45.24 samples/s\r\nINFO:gluonnlp:11:05:25 Batch: 712/7387, Loss=4.1495, lr=0.0000151 Thoughput=42.43 samples/s\r\nINFO:gluonnlp:11:05:39 Batch: 762/7387, Loss=4.1315, lr=0.0000149 Thoughput=42.86 samples/s\r\nINFO:gluonnlp:11:05:52 Batch: 812/7387, Loss=4.2071, lr=0.0000148 Thoughput=45.86 samples/s\r\nINFO:gluonnlp:11:06:05 Batch: 862/7387, Loss=4.0890, lr=0.0000147 Thoughput=46.23 samples/s\r\nINFO:gluonnlp:11:06:19 Batch: 912/7387, Loss=4.1006, lr=0.0000146 Thoughput=44.46 samples/s\r\nINFO:gluonnlp:11:06:32 Batch: 962/7387, Loss=4.0869, lr=0.0000145 Thoughput=45.78 samples/s\r\nINFO:gluonnlp:11:06:45 Batch: 1012/7387, Loss=4.0929, lr=0.0000144 Thoughput=46.82 samples/s\r\nINFO:gluonnlp:11:06:58 Batch: 1062/7387, Loss=4.0652, lr=0.0000143 Thoughput=45.73 samples/s\r\nINFO:gluonnlp:11:07:11 Batch: 1112/7387, Loss=4.1306, lr=0.0000142 Thoughput=43.72 samples/s\r\nINFO:gluonnlp:11:07:25 Batch: 1162/7387, Loss=4.1885, lr=0.0000140 Thoughput=44.05 samples/s\r\nINFO:gluonnlp:11:07:39 Batch: 1212/7387, Loss=4.1907, lr=0.0000139 Thoughput=42.50 samples/s\r\nINFO:gluonnlp:11:07:53 Batch: 1262/7387, Loss=4.0502, lr=0.0000138 Thoughput=42.38 samples/s\r\nINFO:gluonnlp:11:08:07 Batch: 1312/7387, Loss=4.1771, lr=0.0000137 Thoughput=43.80 samples/s\r\nINFO:gluonnlp:11:08:21 Batch: 1362/7387, Loss=4.1444, lr=0.0000136 Thoughput=43.93 samples/s\r\nINFO:gluonnlp:11:08:34 Batch: 1412/7387, Loss=4.1231, lr=0.0000135 Thoughput=46.40 samples/s\r\nINFO:gluonnlp:11:08:47 Batch: 1462/7387, Loss=4.1259, lr=0.0000134 Thoughput=44.89 samples/s\r\nINFO:gluonnlp:11:09:01 Batch: 1512/7387, Loss=4.0674, lr=0.0000133 Thoughput=43.95 samples/s\r\nINFO:gluonnlp:11:09:14 Batch: 1562/7387, Loss=4.1281, lr=0.0000131 Thoughput=44.46 samples/s\r\nINFO:gluonnlp:11:09:28 Batch: 1612/7387, Loss=4.0987, lr=0.0000130 Thoughput=44.48 samples/s\r\nINFO:gluonnlp:11:09:42 Batch: 1662/7387, Loss=4.2103, lr=0.0000129 Thoughput=41.33 samples/s\r\nINFO:gluonnlp:11:09:55 Batch: 1712/7387, Loss=4.0690, lr=0.0000128 Thoughput=47.13 samples/s\r\nINFO:gluonnlp:11:10:09 Batch: 1762/7387, Loss=4.1266, lr=0.0000127 Thoughput=43.28 samples/s\r\nINFO:gluonnlp:11:10:22 Batch: 1812/7387, Loss=4.1022, lr=0.0000126 Thoughput=46.63 samples/s\r\nINFO:gluonnlp:11:10:35 Batch: 1862/7387, Loss=4.0887, lr=0.0000125 Thoughput=43.36 samples/s\r\nINFO:gluonnlp:11:10:49 Batch: 1912/7387, Loss=4.1930, lr=0.0000123 Thoughput=43.75 samples/s\r\nINFO:gluonnlp:11:11:02 Batch: 1962/7387, Loss=4.0607, lr=0.0000122 Thoughput=45.23 samples/s\r\nINFO:gluonnlp:11:11:16 Batch: 2012/7387, Loss=4.1371, lr=0.0000121 Thoughput=43.70 samples/s\r\nINFO:gluonnlp:11:11:30 Batch: 2062/7387, Loss=4.1286, lr=0.0000120 Thoughput=43.74 samples/s\r\nINFO:gluonnlp:11:11:43 Batch: 2112/7387, Loss=4.0778, lr=0.0000119 Thoughput=44.38 samples/s\r\nINFO:gluonnlp:11:11:57 Batch: 2162/7387, Loss=4.0880, lr=0.0000118 Thoughput=44.37 samples/s\r\nINFO:gluonnlp:11:12:10 Batch: 2212/7387, Loss=4.1034, lr=0.0000117 Thoughput=44.49 samples/s\r\nINFO:gluonnlp:11:12:24 Batch: 2262/7387, Loss=4.1207, lr=0.0000116 Thoughput=44.37 samples/s\r\nINFO:gluonnlp:11:12:37 Batch: 2312/7387, Loss=4.0498, lr=0.0000114 Thoughput=45.33 samples/s\r\nINFO:gluonnlp:11:12:50 Batch: 2362/7387, Loss=4.1283, lr=0.0000113 Thoughput=45.50 samples/s\r\nINFO:gluonnlp:11:13:04 Batch: 2412/7387, Loss=4.0925, lr=0.0000112 Thoughput=43.62 samples/s\r\nINFO:gluonnlp:11:13:18 Batch: 2462/7387, Loss=4.1359, lr=0.0000111 Thoughput=43.71 samples/s\r\nINFO:gluonnlp:11:13:31 Batch: 2512/7387, Loss=4.1376, lr=0.0000110 Thoughput=43.78 samples/s\r\nINFO:gluonnlp:11:13:45 Batch: 2562/7387, Loss=4.1093, lr=0.0000109 Thoughput=44.49 samples/s\r\nINFO:gluonnlp:11:13:58 Batch: 2612/7387, Loss=4.2317, lr=0.0000108 Thoughput=45.39 samples/s\r\nINFO:gluonnlp:11:14:12 Batch: 2662/7387, Loss=4.1057, lr=0.0000107 Thoughput=44.15 samples/s\r\nINFO:gluonnlp:11:14:25 Batch: 2712/7387, Loss=4.1259, lr=0.0000105 Thoughput=44.01 samples/s\r\nINFO:gluonnlp:11:14:40 Batch: 2762/7387, Loss=4.1273, lr=0.0000104 Thoughput=42.33 samples/s\r\nINFO:gluonnlp:11:14:53 Batch: 2812/7387, Loss=4.1457, lr=0.0000103 Thoughput=43.42 samples/s\r\nINFO:gluonnlp:11:15:07 Batch: 2862/7387, Loss=4.0793, lr=0.0000102 Thoughput=45.70 samples/s\r\nINFO:gluonnlp:11:15:19 Batch: 2912/7387, Loss=4.0774, lr=0.0000101 Thoughput=46.38 samples/s\r\nINFO:gluonnlp:11:15:34 Batch: 2962/7387, Loss=4.1106, lr=0.0000100 Thoughput=42.38 samples/s\r\nINFO:gluonnlp:11:15:47 Batch: 3012/7387, Loss=4.1557, lr=0.0000099 Thoughput=45.78 samples/s\r\nINFO:gluonnlp:11:16:00 Batch: 3062/7387, Loss=4.1707, lr=0.0000098 Thoughput=43.96 samples/s\r\nINFO:gluonnlp:11:16:14 Batch: 3112/7387, Loss=4.1613, lr=0.0000096 Thoughput=44.49 samples/s\r\nINFO:gluonnlp:11:16:27 Batch: 3162/7387, Loss=4.1119, lr=0.0000095 Thoughput=46.41 samples/s\r\nINFO:gluonnlp:11:16:40 Batch: 3212/7387, Loss=4.1192, lr=0.0000094 Thoughput=44.79 samples/s\r\nINFO:gluonnlp:11:16:54 Batch: 3262/7387, Loss=4.0926, lr=0.0000093 Thoughput=43.16 samples/s\r\nINFO:gluonnlp:11:17:07 Batch: 3312/7387, Loss=4.0888, lr=0.0000092 Thoughput=45.24 samples/s\r\nINFO:gluonnlp:11:17:21 Batch: 3362/7387, Loss=4.0483, lr=0.0000091 Thoughput=43.18 samples/s\r\nINFO:gluonnlp:11:17:35 Batch: 3412/7387, Loss=4.1036, lr=0.0000090 Thoughput=44.04 samples/s\r\nINFO:gluonnlp:11:17:48 Batch: 3462/7387, Loss=4.1874, lr=0.0000089 Thoughput=44.49 samples/s\r\nINFO:gluonnlp:11:18:01 Batch: 3512/7387, Loss=4.0687, lr=0.0000087 Thoughput=46.69 samples/s\r\nINFO:gluonnlp:11:18:15 Batch: 3562/7387, Loss=4.0894, lr=0.0000086 Thoughput=44.96 samples/s\r\nINFO:gluonnlp:11:18:28 Batch: 3612/7387, Loss=4.1437, lr=0.0000085 Thoughput=43.31 samples/s\r\nINFO:gluonnlp:11:18:43 Batch: 3662/7387, Loss=4.0851, lr=0.0000084 Thoughput=41.41 samples/s\r\nINFO:gluonnlp:11:18:55 Batch: 3712/7387, Loss=4.1065, lr=0.0000083 Thoughput=48.17 samples/s\r\nINFO:gluonnlp:11:19:09 Batch: 3762/7387, Loss=4.1050, lr=0.0000082 Thoughput=45.42 samples/s\r\nINFO:gluonnlp:11:19:21 Batch: 3812/7387, Loss=4.0368, lr=0.0000081 Thoughput=46.93 samples/s\r\nINFO:gluonnlp:11:19:34 Batch: 3862/7387, Loss=4.0824, lr=0.0000079 Thoughput=46.24 samples/s\r\nINFO:gluonnlp:11:19:48 Batch: 3912/7387, Loss=4.1474, lr=0.0000078 Thoughput=42.87 samples/s\r\nINFO:gluonnlp:11:20:02 Batch: 3962/7387, Loss=4.0872, lr=0.0000077 Thoughput=44.41 samples/s\r\nINFO:gluonnlp:11:20:15 Batch: 4012/7387, Loss=4.1012, lr=0.0000076 Thoughput=43.96 samples/s\r\nINFO:gluonnlp:11:20:28 Batch: 4062/7387, Loss=4.1431, lr=0.0000075 Thoughput=46.53 samples/s\r\nINFO:gluonnlp:11:20:42 Batch: 4112/7387, Loss=4.0852, lr=0.0000074 Thoughput=45.31 samples/s\r\nINFO:gluonnlp:11:20:55 Batch: 4162/7387, Loss=4.1129, lr=0.0000073 Thoughput=43.51 samples/s\r\nINFO:gluonnlp:11:21:08 Batch: 4212/7387, Loss=4.0370, lr=0.0000072 Thoughput=46.17 samples/s\r\nINFO:gluonnlp:11:21:21 Batch: 4262/7387, Loss=4.1498, lr=0.0000070 Thoughput=46.75 samples/s\r\nINFO:gluonnlp:11:21:35 Batch: 4312/7387, Loss=4.1244, lr=0.0000069 Thoughput=43.76 samples/s\r\nINFO:gluonnlp:11:21:48 Batch: 4362/7387, Loss=4.0967, lr=0.0000068 Thoughput=45.27 samples/s\r\nINFO:gluonnlp:11:22:01 Batch: 4412/7387, Loss=4.0400, lr=0.0000067 Thoughput=46.72 samples/s\r\nINFO:gluonnlp:11:22:14 Batch: 4462/7387, Loss=4.1163, lr=0.0000066 Thoughput=44.57 samples/s\r\nINFO:gluonnlp:11:22:28 Batch: 4512/7387, Loss=4.1048, lr=0.0000065 Thoughput=45.02 samples/s\r\nINFO:gluonnlp:11:22:41 Batch: 4562/7387, Loss=4.0797, lr=0.0000064 Thoughput=45.47 samples/s\r\nINFO:gluonnlp:11:22:55 Batch: 4612/7387, Loss=4.0614, lr=0.0000063 Thoughput=43.93 samples/s\r\nINFO:gluonnlp:11:23:08 Batch: 4662/7387, Loss=4.1530, lr=0.0000061 Thoughput=46.30 samples/s\r\nINFO:gluonnlp:11:23:21 Batch: 4712/7387, Loss=4.0868, lr=0.0000060 Thoughput=45.81 samples/s\r\nINFO:gluonnlp:11:23:34 Batch: 4762/7387, Loss=4.0923, lr=0.0000059 Thoughput=44.20 samples/s\r\nINFO:gluonnlp:11:23:47 Batch: 4812/7387, Loss=4.0161, lr=0.0000058 Thoughput=46.52 samples/s\r\nINFO:gluonnlp:11:24:00 Batch: 4862/7387, Loss=4.0832, lr=0.0000057 Thoughput=45.71 samples/s\r\nINFO:gluonnlp:11:24:13 Batch: 4912/7387, Loss=4.1316, lr=0.0000056 Thoughput=47.06 samples/s\r\nINFO:gluonnlp:11:24:27 Batch: 4962/7387, Loss=4.1091, lr=0.0000055 Thoughput=44.09 samples/s\r\nINFO:gluonnlp:11:24:40 Batch: 5012/7387, Loss=4.0840, lr=0.0000054 Thoughput=45.39 samples/s\r\nINFO:gluonnlp:11:24:53 Batch: 5062/7387, Loss=4.1174, lr=0.0000052 Thoughput=44.24 samples/s\r\nINFO:gluonnlp:11:25:07 Batch: 5112/7387, Loss=4.0487, lr=0.0000051 Thoughput=44.90 samples/s\r\nINFO:gluonnlp:11:25:20 Batch: 5162/7387, Loss=4.1211, lr=0.0000050 Thoughput=44.33 samples/s\r\nINFO:gluonnlp:11:25:34 Batch: 5212/7387, Loss=4.1463, lr=0.0000049 Thoughput=45.15 samples/s\r\nINFO:gluonnlp:11:25:47 Batch: 5262/7387, Loss=4.0731, lr=0.0000048 Thoughput=43.85 samples/s\r\nINFO:gluonnlp:11:26:00 Batch: 5312/7387, Loss=4.1587, lr=0.0000047 Thoughput=45.70 samples/s\r\nINFO:gluonnlp:11:26:14 Batch: 5362/7387, Loss=4.0584, lr=0.0000046 Thoughput=45.49 samples/s\r\nINFO:gluonnlp:11:26:26 Batch: 5412/7387, Loss=4.0978, lr=0.0000045 Thoughput=47.34 samples/s\r\nINFO:gluonnlp:11:26:40 Batch: 5462/7387, Loss=4.1306, lr=0.0000043 Thoughput=44.27 samples/s\r\nINFO:gluonnlp:11:26:53 Batch: 5512/7387, Loss=4.0910, lr=0.0000042 Thoughput=44.97 samples/s\r\nINFO:gluonnlp:11:27:06 Batch: 5562/7387, Loss=4.0427, lr=0.0000041 Thoughput=46.23 samples/s\r\nINFO:gluonnlp:11:27:19 Batch: 5612/7387, Loss=4.0804, lr=0.0000040 Thoughput=45.94 samples/s\r\nINFO:gluonnlp:11:27:33 Batch: 5662/7387, Loss=4.0750, lr=0.0000039 Thoughput=44.74 samples/s\r\nINFO:gluonnlp:11:27:46 Batch: 5712/7387, Loss=4.1347, lr=0.0000038 Thoughput=45.34 samples/s\r\nINFO:gluonnlp:11:27:59 Batch: 5762/7387, Loss=4.1372, lr=0.0000037 Thoughput=45.17 samples/s\r\nINFO:gluonnlp:11:28:13 Batch: 5812/7387, Loss=4.0193, lr=0.0000035 Thoughput=43.86 samples/s\r\nINFO:gluonnlp:11:28:27 Batch: 5862/7387, Loss=4.2086, lr=0.0000034 Thoughput=43.70 samples/s\r\nINFO:gluonnlp:11:28:40 Batch: 5912/7387, Loss=4.1591, lr=0.0000033 Thoughput=45.01 samples/s\r\nINFO:gluonnlp:11:28:54 Batch: 5962/7387, Loss=4.1108, lr=0.0000032 Thoughput=44.07 samples/s\r\nINFO:gluonnlp:11:29:07 Batch: 6012/7387, Loss=4.1279, lr=0.0000031 Thoughput=46.01 samples/s\r\nINFO:gluonnlp:11:29:20 Batch: 6062/7387, Loss=4.1495, lr=0.0000030 Thoughput=44.55 samples/s\r\nINFO:gluonnlp:11:29:33 Batch: 6112/7387, Loss=4.1213, lr=0.0000029 Thoughput=44.86 samples/s\r\nINFO:gluonnlp:11:29:46 Batch: 6162/7387, Loss=4.0740, lr=0.0000028 Thoughput=46.45 samples/s\r\nINFO:gluonnlp:11:30:00 Batch: 6212/7387, Loss=4.1713, lr=0.0000026 Thoughput=43.52 samples/s\r\nINFO:gluonnlp:11:30:14 Batch: 6262/7387, Loss=4.1564, lr=0.0000025 Thoughput=43.98 samples/s\r\nINFO:gluonnlp:11:30:27 Batch: 6312/7387, Loss=4.0892, lr=0.0000024 Thoughput=45.32 samples/s\r\nINFO:gluonnlp:11:30:40 Batch: 6362/7387, Loss=4.0660, lr=0.0000023 Thoughput=46.31 samples/s\r\nINFO:gluonnlp:11:30:53 Batch: 6412/7387, Loss=4.0736, lr=0.0000022 Thoughput=46.32 samples/s\r\nINFO:gluonnlp:11:31:06 Batch: 6462/7387, Loss=4.0536, lr=0.0000021 Thoughput=44.83 samples/s\r\nINFO:gluonnlp:11:31:20 Batch: 6512/7387, Loss=4.2200, lr=0.0000020 Thoughput=43.86 samples/s\r\nINFO:gluonnlp:11:31:33 Batch: 6562/7387, Loss=4.1070, lr=0.0000019 Thoughput=45.22 samples/s\r\nINFO:gluonnlp:11:31:46 Batch: 6612/7387, Loss=4.0595, lr=0.0000017 Thoughput=46.24 samples/s\r\nINFO:gluonnlp:11:32:00 Batch: 6662/7387, Loss=4.1146, lr=0.0000016 Thoughput=44.01 samples/s\r\nINFO:gluonnlp:11:32:13 Batch: 6712/7387, Loss=4.1076, lr=0.0000015 Thoughput=46.55 samples/s\r\nINFO:gluonnlp:11:32:26 Batch: 6762/7387, Loss=4.1171, lr=0.0000014 Thoughput=46.89 samples/s\r\nINFO:gluonnlp:11:32:39 Batch: 6812/7387, Loss=4.0516, lr=0.0000013 Thoughput=45.68 samples/s\r\nINFO:gluonnlp:11:32:52 Batch: 6862/7387, Loss=4.0758, lr=0.0000012 Thoughput=44.23 samples/s\r\nINFO:gluonnlp:11:33:05 Batch: 6912/7387, Loss=4.0915, lr=0.0000011 Thoughput=45.50 samples/s\r\nINFO:gluonnlp:11:33:19 Batch: 6962/7387, Loss=4.1415, lr=0.0000010 Thoughput=44.48 samples/s\r\nINFO:gluonnlp:11:33:32 Batch: 7012/7387, Loss=4.0714, lr=0.0000008 Thoughput=46.97 samples/s\r\nINFO:gluonnlp:11:33:45 Batch: 7062/7387, Loss=4.0710, lr=0.0000007 Thoughput=45.87 samples/s\r\nINFO:gluonnlp:11:33:58 Batch: 7112/7387, Loss=4.0817, lr=0.0000006 Thoughput=45.07 samples/s\r\nINFO:gluonnlp:11:34:12 Batch: 7162/7387, Loss=4.0979, lr=0.0000005 Thoughput=44.60 samples/s\r\nINFO:gluonnlp:11:34:24 Batch: 7212/7387, Loss=4.1037, lr=0.0000004 Thoughput=46.83 samples/s\r\nINFO:gluonnlp:11:34:39 Batch: 7262/7387, Loss=4.0831, lr=0.0000003 Thoughput=41.88 samples/s\r\nINFO:gluonnlp:11:34:52 Batch: 7312/7387, Loss=4.0656, lr=0.0000002 Thoughput=44.57 samples/s\r\nINFO:gluonnlp:11:35:05 Batch: 7362/7387, Loss=4.0253, lr=0.0000001 Thoughput=45.51 samples/s\r\nINFO:gluonnlp:11:35:12 Finish training step: 14773\r\nINFO:gluonnlp:11:35:12 Time cost=3967.29 s, Thoughput=44.68 samples/s\r\nINFO:gluonnlp:11:35:15 Loading dev data...\r\nINFO:gluonnlp:11:35:15 Number of records in dev data:10570\r\nDone! Transform dataset costs 4.27 seconds.\r\nINFO:gluonnlp:11:35:24 The number of examples after preprocessing:10833\r\nDone! Transform dataset costs 4.35 seconds.\r\nINFO:gluonnlp:11:35:24 start prediction\r\nINFO:gluonnlp:11:36:25 Time cost=60.60 s, Thoughput=178.75 samples/s\r\nINFO:gluonnlp:11:36:25 Get prediction results...\r\nINFO:gluonnlp:11:36:54 {'exact_match': 5.931882686849574, 'f1': 13.615304984378835}\r\n```\r\n\r\n### Error Message\r\n(Paste the complete error message, including stack trace.)\r\n\r\n## To Reproduce\r\n`python finetune_squad.py --optimizer adam --batch_size 12 --lr 3e-5 --epochs 2 --gpu`\r\n\r\n## What have you tried to solve it?\r\nNone\r\n\r\n## Environment\r\n```\r\n$ pip list\r\nPackage     Version\r\n----------- -------------------\r\ncertifi     2019.11.28\r\nchardet     3.0.4\r\nCython      0.29.16\r\ngluonnlp    0.9.1\r\ngraphviz    0.8.4\r\nidna        2.8\r\nmxnet-cu100 1.6.0b20200302\r\nnumpy       1.18.1\r\npackaging   20.3\r\npip         19.3.1\r\npyparsing   2.4.7\r\nrequests    2.22.0\r\nsetuptools  44.0.0.post20200106\r\nsix         1.14.0\r\nurllib3     1.25.7\r\nwheel       0.33.6\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1202", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1202/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1202/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1202/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1202", "id": 598282538, "node_id": "MDU6SXNzdWU1OTgyODI1Mzg=", "number": 1202, "title": "Prediction on the fasttext text classification model trained on yelp review polarity dataset", "user": {"login": "SamanwaySadhu", "id": 24360328, "node_id": "MDQ6VXNlcjI0MzYwMzI4", "avatar_url": "https://avatars3.githubusercontent.com/u/24360328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SamanwaySadhu", "html_url": "https://github.com/SamanwaySadhu", "followers_url": "https://api.github.com/users/SamanwaySadhu/followers", "following_url": "https://api.github.com/users/SamanwaySadhu/following{/other_user}", "gists_url": "https://api.github.com/users/SamanwaySadhu/gists{/gist_id}", "starred_url": "https://api.github.com/users/SamanwaySadhu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SamanwaySadhu/subscriptions", "organizations_url": "https://api.github.com/users/SamanwaySadhu/orgs", "repos_url": "https://api.github.com/users/SamanwaySadhu/repos", "events_url": "https://api.github.com/users/SamanwaySadhu/events{/privacy}", "received_events_url": "https://api.github.com/users/SamanwaySadhu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-11T14:57:25Z", "updated_at": "2020-07-19T21:47:43Z", "closed_at": "2020-07-19T21:47:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI am trying to run a prediction on the Fast-text Word N-gram model trained with Yelp review data set. I am getting this error message below. The rest of entire training process is working fine. I have run for only one epoch and a truncated version of the data-set for quicker reproduction purposes. Can't figure out how to solve it.\r\n\r\n### Error Message\r\nINFO:root:Ngrams range for the training run : 1\r\nINFO:root:Loading Training data\r\nINFO:root:Opening file yelp_review_polarity/train_m.csv for reading input\r\nINFO:root:Loading Test data\r\nINFO:root:Opening file yelp_review_polarity/test_m.csv for reading input\r\nINFO:root:Vocabulary size: 298608\r\nINFO:root:Training data converting to sequences...\r\nINFO:root:Done! Sequence conversion Time=4.39s, #Sentences=56294\r\nINFO:root:Done! Sequence conversion Time=2.81s, #Sentences=3749\r\nINFO:root:Encoding labels\r\nINFO:root:Label mapping:{'1': 0, '2': 1}\r\nINFO:root:Done! Preprocessing Time=0.39s, #Sentences=56294\r\nINFO:root:Done! Preprocessing Time=0.16s, #Sentences=3749\r\nINFO:root:Number of labels: 2\r\nINFO:root:Initializing network\r\nINFO:root:Running Training on ctx:gpu(0)\r\nINFO:root:Embedding Matrix Length:298608\r\nINFO:root:Number of output units in the last layer :1\r\nINFO:root:Network initialized\r\nINFO:root:Changing the loss function to sigmoid since its Binary Classification\r\nINFO:root:Loss function for training:SigmoidBinaryCrossEntropyLoss(batch_axis=0, w=None)\r\nINFO:root:Starting Training!\r\nINFO:root:Training on 56294 samples and testing on 3749 samples\r\nINFO:root:Number of batches for each epoch : 3518.375, Display cadence: 352\r\nINFO:root:Epoch : 0, Batches complete :0\r\nINFO:root:Epoch : 0, Batches complete :352\r\nINFO:root:Epoch : 0, Batches complete :704\r\nINFO:root:Epoch : 0, Batches complete :1056\r\nINFO:root:Epoch : 0, Batches complete :1408\r\nINFO:root:Epoch : 0, Batches complete :1760\r\nINFO:root:Epoch : 0, Batches complete :2112\r\nINFO:root:Epoch complete :0, Computing Accuracy\r\nINFO:root:Epochs completed : 0 Test Accuracy: 0.9007735396105628, Test Loss: 0.3058077375582877\r\nTraceback (most recent call last):\r\n  File \"fasttext_word_ngram.py\", line 424, in <module>\r\n    train(arguments)\r\n  File \"fasttext_word_ngram.py\", line 418, in train\r\n    logging.info(net(mx.nd.reshape(mx.nd.array(train_vocab[['This', 'movie', 'is', 'awful']], ctx=ctx)), mx.nd.array([4], ctx=ctx)).sigmoid())\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 693, in __call__\r\n    out = self.forward(*args)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 1148, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 1020, in _call_cached_op\r\n    out = self._cached_op(*cargs)\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\", line 170, in __call__\r\n    ctypes.byref(out_stypes)))\r\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/mxnet/base.py\", line 255, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: Error in operator fasttextclassificationmodel0_meanpoolinglayer0_sequencemask0: [16:12:08] include/mxnet/./tuple.h:220: Check failed: i >= 0 && i < ndim(): index = 1 must be in range [0, -1)\r\nStack trace:\r\n  [bt] (0) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x6b8b5b) [0x7fbc32edfb5b]\r\n  [bt] (1) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f8c14b) [0x7fbc367b314b]\r\n  [bt] (2) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f8da35) [0x7fbc367b4a35]\r\n  [bt] (3) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3a8feb0) [0x7fbc362b6eb0]\r\n  [bt] (4) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x382fe3c) [0x7fbc36056e3c]\r\n  [bt] (5) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x383367a) [0x7fbc3605a67a]\r\n  [bt] (6) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x386e5bf) [0x7fbc360955bf]\r\n  [bt] (7) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::SetForwardGraph(mxnet::CachedOp::GraphInfo*, bool, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x4ac) [0x7fbc3609870c]\r\n  [bt] (8) /home/ubuntu/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::DynamicForward(mxnet::Context const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, bool)+0x108) [0x7fbc360aa508]\r\n\r\n## To Reproduce\r\nJust added this line at the end of the train function. It is inspired from the sentiment analysis tutorial where prediction was being done in a similar way.\r\n\r\nlogging.info(net(mx.nd.reshape(mx.nd.array(train_vocab[['This', 'movie', 'is', 'awful']], ctx=ctx), shape=(-1, 1)), mx.nd.array([4], ctx=ctx)).sigmoid())", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1201", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1201/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1201/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1201/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1201", "id": 597470353, "node_id": "MDU6SXNzdWU1OTc0NzAzNTM=", "number": 1201, "title": "gluonnlp on Cuda 10 cannot import name 'replace_file'", "user": {"login": "ktoetotam", "id": 4871359, "node_id": "MDQ6VXNlcjQ4NzEzNTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/4871359?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktoetotam", "html_url": "https://github.com/ktoetotam", "followers_url": "https://api.github.com/users/ktoetotam/followers", "following_url": "https://api.github.com/users/ktoetotam/following{/other_user}", "gists_url": "https://api.github.com/users/ktoetotam/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktoetotam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktoetotam/subscriptions", "organizations_url": "https://api.github.com/users/ktoetotam/orgs", "repos_url": "https://api.github.com/users/ktoetotam/repos", "events_url": "https://api.github.com/users/ktoetotam/events{/privacy}", "received_events_url": "https://api.github.com/users/ktoetotam/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-09T18:26:19Z", "updated_at": "2020-06-21T20:19:20Z", "closed_at": "2020-04-15T02:04:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to run gluonnlp on cuda 10. I have installed the following package:\r\n\r\nmxnet-cu100              1.6.0b20191102 \r\n\r\nhttps://pypi.org/project/mxnet-cu100mkl/#history\r\n\r\nAs it seems like the only one that has mxnet 1.6.0 and supports cuda 10. I have no possibility to upgrade to cuda 10.1 which has the official release for mxnet 1.6.0\r\n\r\nThe error I get looks like I am still on mxnet 1.5.0 but:\r\n\r\n```\r\nimport mxnet as mx\r\nprint(mx.__version__)\r\n\r\n1.6.0\r\n```\r\n\r\nIt looks like the pre-release is not compatible? Do you know of any way to use gluonnlp on cuda 10.0? I cannot neither downgrade nor upgrade the cuda version. \r\n\r\nThe original error is:\r\n\r\n```\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-2-12f1dea70852> in <module>\r\n     13 from mxnet import gluon, autograd\r\n     14 from mxnet.gluon.utils import download\r\n---> 15 import gluonnlp as nlp\r\n     16 nlp.utils.check_version('0.7.0')\r\n\r\n~/.local/lib/python3.6/site-packages/gluonnlp/__init__.py in <module>\r\n     23 \r\n     24 from . import loss\r\n---> 25 from . import data\r\n     26 from . import embedding\r\n     27 from . import model\r\n\r\n~/.local/lib/python3.6/site-packages/gluonnlp/data/__init__.py in <module>\r\n     21 import os\r\n     22 \r\n---> 23 from . import (batchify, candidate_sampler, conll, corpora, dataloader,\r\n     24                dataset, question_answering, registry, sampler, sentiment,\r\n     25                stream, super_glue, transforms, translation, utils,\r\n\r\n~/.local/lib/python3.6/site-packages/gluonnlp/data/question_answering.py in <module>\r\n     29 \r\n     30 from mxnet.gluon.data import ArrayDataset\r\n---> 31 from mxnet.gluon.utils import download, check_sha1, _get_repo_file_url, replace_file\r\n     32 from .registry import register\r\n     33 from ..base import get_home_dir\r\n\r\nImportError: cannot import name 'replace_file'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1199", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1199/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1199/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1199/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1199", "id": 596653999, "node_id": "MDU6SXNzdWU1OTY2NTM5OTk=", "number": 1199, "title": "surrogate for F.contrib.arange_like?", "user": {"login": "yezqNLP", "id": 35182031, "node_id": "MDQ6VXNlcjM1MTgyMDMx", "avatar_url": "https://avatars3.githubusercontent.com/u/35182031?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yezqNLP", "html_url": "https://github.com/yezqNLP", "followers_url": "https://api.github.com/users/yezqNLP/followers", "following_url": "https://api.github.com/users/yezqNLP/following{/other_user}", "gists_url": "https://api.github.com/users/yezqNLP/gists{/gist_id}", "starred_url": "https://api.github.com/users/yezqNLP/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yezqNLP/subscriptions", "organizations_url": "https://api.github.com/users/yezqNLP/orgs", "repos_url": "https://api.github.com/users/yezqNLP/repos", "events_url": "https://api.github.com/users/yezqNLP/events{/privacy}", "received_events_url": "https://api.github.com/users/yezqNLP/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-08T15:12:29Z", "updated_at": "2020-04-09T06:23:56Z", "closed_at": "2020-04-09T06:23:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "The following line in transformer encoder use `F.contrib.arange_like`, which depends on mxnet>=1.6.0. \r\nhttps://github.com/dmlc/gluon-nlp/blob/3f7465ab5d0f926c2c6f424644daaa30668570ba/src/gluonnlp/model/transformer.py#L397\r\nAnd for some reason I only have installed mxnet-cu100=1.5.1, so I wrote a line to for surrogate this line:\r\n`steps = nd.array(range(inputs.shape[1]))`. And the code can run successfully. However I am new to mxnet and I wonder is it ok? would it have some unexpected effects?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1190", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1190/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1190/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1190/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1190", "id": 585185254, "node_id": "MDU6SXNzdWU1ODUxODUyNTQ=", "number": 1190, "title": "MXNet Nightly Builds Moved to S3", "user": {"login": "szha", "id": 2626883, "node_id": "MDQ6VXNlcjI2MjY4ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2626883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szha", "html_url": "https://github.com/szha", "followers_url": "https://api.github.com/users/szha/followers", "following_url": "https://api.github.com/users/szha/following{/other_user}", "gists_url": "https://api.github.com/users/szha/gists{/gist_id}", "starred_url": "https://api.github.com/users/szha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szha/subscriptions", "organizations_url": "https://api.github.com/users/szha/orgs", "repos_url": "https://api.github.com/users/szha/repos", "events_url": "https://api.github.com/users/szha/events{/privacy}", "received_events_url": "https://api.github.com/users/szha/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-20T16:25:46Z", "updated_at": "2020-04-30T18:58:16Z", "closed_at": "2020-04-30T18:58:16Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Hi,\r\n\r\nMXNet nightly builds have been moved from PyPI to S3 (https://github.com/pypa/pypi-support/issues/243). If this project requires the nightly builds for CI validation, please make sure that your CI pipeline now takes the nightly builds from https://dist.mxnet.io/python. Furthermore, as MXNet [1.7](https://github.com/apache/incubator-mxnet/issues/16864) and [2.0](https://github.com/apache/incubator-mxnet/issues/16167) are currently in progress simultaneously, we are releasing nightly builds for both 1.x and 2.x. Take `mxnet-cu102` for example:\r\n\r\nIf you need the nightly builds for 1.x:\r\n```\r\npip install --pre \"mxnet-cu102<2\" -f https://dist.mxnet.io/python\r\n```\r\n\r\nIf you need the nightly builds for 2.x:\r\n```\r\npip install --pre \"mxnet-cu102>=2\" -f https://dist.mxnet.io/python\r\n```\r\n\r\nFeel free to close this issue if the necessary changes have been made, or If the project doesn't rely on MXNet nightly builds. Thanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1189", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1189/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1189/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1189/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1189", "id": 584800271, "node_id": "MDU6SXNzdWU1ODQ4MDAyNzE=", "number": 1189, "title": "Dataset loader bug", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-20T02:08:15Z", "updated_at": "2020-07-19T21:48:38Z", "closed_at": "2020-07-19T21:48:37Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n[1,215]<stderr>:Exception in thread Thread-24:\r\n[1,215]<stderr>:Traceback (most recent call last):\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n[1,215]<stderr>:    self.run()\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n[1,215]<stderr>:    self._target(*self._args, **self._kwargs)\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 463, in _handle_results\r\n[1,215]<stderr>:    task = get()\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\r\n[1,215]<stderr>:    return _ForkingPickler.loads(buf.getbuffer())\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 881, in RebuildProxy\r\n[1,215]<stderr>:    return func(token, serializer, incref=incref, **kwds)\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 731, in __init__\r\n[1,215]<stderr>:    self._incref()\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 786, in _incref\r\n[1,215]<stderr>:    dispatch(conn, None, 'incref', (self._id,))\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 82, in dispatch\r\n[1,215]<stderr>:    raise convert_to_error(kind, result)\r\n[1,215]<stderr>:multiprocessing.managers.RemoteError:\r\n[1,215]<stderr>:---------------------------------------------------------------------------\r\n[1,215]<stderr>:Traceback (most recent call last):\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 195, in handle_request\r\n[1,215]<stderr>:    result = func(c, *args, **kwds)\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 408, in incref\r\n[1,215]<stderr>:    raise ke\r\n[1,215]<stderr>:  File \"/usr/lib/python3.6/multiprocessing/managers.py\", line 395, in incref\r\n[1,215]<stderr>:    self.id_to_refcount[ident] += 1\r\n[1,215]<stderr>:KeyError: '7f87ac13a5f8'\r\n[1,215]<stderr>:---------------------------------------------------------------------------\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1185", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1185/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1185/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1185/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1185", "id": 582786284, "node_id": "MDU6SXNzdWU1ODI3ODYyODQ=", "number": 1185, "title": "The frequent failure of CI for gpu-doc", "user": {"login": "chenw23", "id": 31835051, "node_id": "MDQ6VXNlcjMxODM1MDUx", "avatar_url": "https://avatars2.githubusercontent.com/u/31835051?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chenw23", "html_url": "https://github.com/chenw23", "followers_url": "https://api.github.com/users/chenw23/followers", "following_url": "https://api.github.com/users/chenw23/following{/other_user}", "gists_url": "https://api.github.com/users/chenw23/gists{/gist_id}", "starred_url": "https://api.github.com/users/chenw23/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chenw23/subscriptions", "organizations_url": "https://api.github.com/users/chenw23/orgs", "repos_url": "https://api.github.com/users/chenw23/repos", "events_url": "https://api.github.com/users/chenw23/events{/privacy}", "received_events_url": "https://api.github.com/users/chenw23/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-03-17T06:30:24Z", "updated_at": "2020-03-26T17:07:40Z", "closed_at": "2020-03-26T17:07:40Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Description\r\nThe CI for gpu-doc seems to be failing more frequent recently. As I look into the errors, they appear to be some specific place, see error message below.\r\n\r\n### Error Message\r\nPlease see these CI errors.\r\n\r\nIt seems that there are three types of errors and these errors repeat randomly:\r\n- wheel file cannot be downloaded\r\n- python file existence error\r\n- some baidu API error\r\n\r\nhttps://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-1184/2/pipeline/\r\n\r\nhttps://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-1179/4/pipeline/ \r\n\r\nhttps://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-1180/2/pipeline/\r\n\r\nhttps://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-1180/3/pipeline/\r\n\r\nhttps://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-1180/6/pipeline/\r\n\r\nhttps://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-1180/7/pipeline/\r\n\r\nhttps://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-1180/8/pipeline/\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n1. It seems that these errors have no relationship with what codes I commit. So they can be reproduced randomly.\r\n2.\r\n\r\n## What have you tried to solve it?\r\n\r\n1.\r\n2.\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1182", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1182/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1182/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1182/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1182", "id": 580049050, "node_id": "MDU6SXNzdWU1ODAwNDkwNTA=", "number": 1182, "title": "Slack invite link is no longer active", "user": {"login": "Defunctionalize", "id": 2494198, "node_id": "MDQ6VXNlcjI0OTQxOTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/2494198?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Defunctionalize", "html_url": "https://github.com/Defunctionalize", "followers_url": "https://api.github.com/users/Defunctionalize/followers", "following_url": "https://api.github.com/users/Defunctionalize/following{/other_user}", "gists_url": "https://api.github.com/users/Defunctionalize/gists{/gist_id}", "starred_url": "https://api.github.com/users/Defunctionalize/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Defunctionalize/subscriptions", "organizations_url": "https://api.github.com/users/Defunctionalize/orgs", "repos_url": "https://api.github.com/users/Defunctionalize/repos", "events_url": "https://api.github.com/users/Defunctionalize/events{/privacy}", "received_events_url": "https://api.github.com/users/Defunctionalize/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-12T16:10:33Z", "updated_at": "2020-03-28T05:04:52Z", "closed_at": "2020-03-28T05:04:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Looking to join the community, it appears that #356 did not permanently resolve the problem", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1178", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1178/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1178/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1178/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1178", "id": 571210099, "node_id": "MDU6SXNzdWU1NzEyMTAwOTk=", "number": 1178, "title": "gluonnlp==v0.9.0.post0 throws an error during import", "user": {"login": "josesho", "id": 12838917, "node_id": "MDQ6VXNlcjEyODM4OTE3", "avatar_url": "https://avatars0.githubusercontent.com/u/12838917?v=4", "gravatar_id": "", "url": "https://api.github.com/users/josesho", "html_url": "https://github.com/josesho", "followers_url": "https://api.github.com/users/josesho/followers", "following_url": "https://api.github.com/users/josesho/following{/other_user}", "gists_url": "https://api.github.com/users/josesho/gists{/gist_id}", "starred_url": "https://api.github.com/users/josesho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/josesho/subscriptions", "organizations_url": "https://api.github.com/users/josesho/orgs", "repos_url": "https://api.github.com/users/josesho/repos", "events_url": "https://api.github.com/users/josesho/events{/privacy}", "received_events_url": "https://api.github.com/users/josesho/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-02-26T10:01:03Z", "updated_at": "2020-03-05T18:16:02Z", "closed_at": "2020-02-26T17:39:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n`v0.9.0.post0` of `gluonnlp` throws an error during import\r\n\r\n### Error Message\r\n```shell\r\n/usr/local/lib/python3.6/dist-packages/gluonnlp/__init__.py in <module>()\r\n     23 \r\n     24 from . import loss\r\n---> 25 from . import data\r\n     26 from . import embedding\r\n     27 from . import model\r\n\r\n/usr/local/lib/python3.6/dist-packages/gluonnlp/data/__init__.py in <module>()\r\n     21 import os\r\n     22 \r\n---> 23 from . import (batchify, candidate_sampler, conll, corpora, dataloader,\r\n     24                dataset, question_answering, registry, sampler, sentiment,\r\n     25                stream, super_glue, transforms, translation, utils,\r\n\r\n/usr/local/lib/python3.6/dist-packages/gluonnlp/data/question_answering.py in <module>()\r\n     29 \r\n     30 from mxnet.gluon.data import ArrayDataset\r\n---> 31 from mxnet.gluon.utils import download, check_sha1, _get_repo_file_url, replace_file\r\n     32 from .registry import register\r\n     33 from ..base import get_home_dir\r\n\r\nImportError: cannot import name 'replace_file'\r\n\r\n```\r\n\r\n## To Reproduce\r\n\r\n### Steps to reproduce\r\n```python\r\nimport gluonnlp\r\n```\r\n\r\n\r\n## Environment\r\n\r\n```shell\r\n----------Python Info----------\r\nVersion      : 3.6.9\r\nCompiler     : GCC 8.3.0\r\nBuild        : ('default', 'Nov  7 2019 10:44:02')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.3.1\r\nDirectory    : /usr/local/lib/python3.6/dist-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.1\r\nDirectory    : /usr/local/lib/python3.6/dist-packages/mxnet\r\nNum GPUs     : 0\r\nCommit Hash   : c9818480680f84daa6e281a974ab263691302ba8\r\n----------System Info----------\r\nPlatform     : Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\r\nsystem       : Linux\r\nnode         : 2e2fd7c1be9b\r\nrelease      : 4.14.137+\r\nversion      : #1 SMP Thu Aug 8 02:47:02 PDT 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              2\r\nOn-line CPU(s) list: 0,1\r\nThread(s) per core:  2\r\nCore(s) per socket:  1\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               79\r\nModel name:          Intel(R) Xeon(R) CPU @ 2.20GHz\r\nStepping:            0\r\nCPU MHz:             2200.000\r\nBogoMIPS:            4400.00\r\nHypervisor vendor:   KVM\r\nVirtualization type: full\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            56320K\r\nNUMA node0 CPU(s):   0,1\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0022 sec, LOAD: 0.9448 sec.\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0012 sec, LOAD: 0.5968 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0906 sec, LOAD: 0.3803 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.0190 sec, LOAD: 0.0715 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0116 sec, LOAD: 0.0995 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0593 sec, LOAD: 0.1349 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0099 sec, LOAD: 0.3061 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0404 sec, LOAD: 0.0670 sec.\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1173", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1173/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1173/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1173/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1173", "id": 569683521, "node_id": "MDU6SXNzdWU1Njk2ODM1MjE=", "number": 1173, "title": "BERT lr scheduler ", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 890393504, "node_id": "MDU6TGFiZWw4OTAzOTM1MDQ=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/help%20wanted", "name": "help wanted", "color": "b0f22e", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-24T07:42:15Z", "updated_at": "2020-07-14T05:12:05Z", "closed_at": "2020-07-14T05:12:05Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We can move the lr scheduling logic https://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/finetune_classifier.py#L565-L571 for BERT to a LRScheduler API implementing the `mxnet.lr_scheduler.LRScheduler` API", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1170", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1170/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1170/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1170/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1170", "id": 569677563, "node_id": "MDU6SXNzdWU1Njk2Nzc1NjM=", "number": 1170, "title": "logging utils", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 890393504, "node_id": "MDU6TGFiZWw4OTAzOTM1MDQ=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/help%20wanted", "name": "help wanted", "color": "b0f22e", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-24T07:25:37Z", "updated_at": "2020-07-31T04:08:16Z", "closed_at": "2020-07-31T04:08:16Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/finetune_classifier.py#L191-L204\r\nThese common logging util function can be simplied as gluonnlp.util.set_logger(filename, level=INFO)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1161", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1161/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1161/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1161/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1161", "id": 566601283, "node_id": "MDU6SXNzdWU1NjY2MDEyODM=", "number": 1161, "title": "BUG in Quick Example of Website", "user": {"login": "szhengac", "id": 3960020, "node_id": "MDQ6VXNlcjM5NjAwMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/3960020?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szhengac", "html_url": "https://github.com/szhengac", "followers_url": "https://api.github.com/users/szhengac/followers", "following_url": "https://api.github.com/users/szhengac/following{/other_user}", "gists_url": "https://api.github.com/users/szhengac/gists{/gist_id}", "starred_url": "https://api.github.com/users/szhengac/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szhengac/subscriptions", "organizations_url": "https://api.github.com/users/szhengac/orgs", "repos_url": "https://api.github.com/users/szhengac/repos", "events_url": "https://api.github.com/users/szhengac/events{/privacy}", "received_events_url": "https://api.github.com/users/szhengac/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-18T02:11:11Z", "updated_at": "2020-02-18T18:35:24Z", "closed_at": "2020-02-18T18:35:24Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The quick example in https://gluon-nlp.mxnet.io/ is not runnable. In particular, it outputs `ModuleNotFoundError: No module named 'mxnet'`. \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1158", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1158/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1158/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1158/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1158", "id": 565002606, "node_id": "MDU6SXNzdWU1NjUwMDI2MDY=", "number": 1158, "title": "Vocab produces non-deterministic vocab in py3.5", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-02-13T23:05:37Z", "updated_at": "2020-02-22T07:45:24Z", "closed_at": "2020-02-22T07:45:24Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Description\r\nThe special token IDs are registered in a non-deterministic order. Probably gluonnlp need some overhaul of all dict usages", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1142", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1142/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1142/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1142/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1142", "id": 561765749, "node_id": "MDU6SXNzdWU1NjE3NjU3NDk=", "number": 1142, "title": "packaging is a required dependency", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-02-07T17:13:47Z", "updated_at": "2020-02-22T17:42:50Z", "closed_at": "2020-02-22T17:42:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```\r\n2020-02-07 04:15:34,466 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     import gluonnlp as nlp\r\n2020-02-07 04:15:34,466 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File \"/usr/local/lib/python3.6/site-packages/gluonnlp/__init__.py\", line 49, in <module>\r\n2020-02-07 04:15:34,466 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     utils.version.check_version('1.6.0', warning_only=True, library=mxnet)\r\n2020-02-07 04:15:34,466 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File \"/usr/local/lib/python3.6/site-packages/gluonnlp/utils/version.py\", line 43, in check_version\r\n2020-02-07 04:15:34,466 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     from packaging.version import parse\r\n2020-02-07 04:15:34,467 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'packaging'\r\n```\r\n\r\nCC @eric-haibin-lin ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1141", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1141/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1141/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1141/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1141", "id": 561229610, "node_id": "MDU6SXNzdWU1NjEyMjk2MTA=", "number": 1141, "title": "Incorrect install from source instructions on gluonnlp website ", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-02-06T19:45:26Z", "updated_at": "2020-02-10T18:09:38Z", "closed_at": "2020-02-10T18:09:38Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://gluon-nlp.mxnet.io/master/install/install-more.html\r\n\r\n```\r\npip install --pre --upgrade mxnet\r\ngit clone https://github.com/dmlc/gluon-nlp\r\ncd gluon-nlp && python setup.py install --user\r\n```\r\n\r\nThis does not clone the master branch of gluonnlp. The MXNet version is also not up-to-date", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1139", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1139/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1139/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1139/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1139", "id": 560546858, "node_id": "MDU6SXNzdWU1NjA1NDY4NTg=", "number": 1139, "title": "Docker container for GluonNLP", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-05T18:19:31Z", "updated_at": "2020-08-20T16:23:21Z", "closed_at": "2020-08-20T16:23:21Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Looking at nvidia's [NGC container and their examples](https://github.com/NVIDIA/DeepLearningExamples/blob/master/MxNet/Classification/RN50v1.5/README.md#quick-start-guide), they made it really easy to run their example code and reproduce the environment and experiments. Having one for GluonNLP will make it easier for users", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1134", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1134/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1134/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1134/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1134", "id": 558536581, "node_id": "MDU6SXNzdWU1NTg1MzY1ODE=", "number": 1134, "title": "Cannot reproduce BERT MRPC accuracy on mxnet1.6.0rc1&2", "user": {"login": "xinyu-intel", "id": 17897736, "node_id": "MDQ6VXNlcjE3ODk3NzM2", "avatar_url": "https://avatars2.githubusercontent.com/u/17897736?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xinyu-intel", "html_url": "https://github.com/xinyu-intel", "followers_url": "https://api.github.com/users/xinyu-intel/followers", "following_url": "https://api.github.com/users/xinyu-intel/following{/other_user}", "gists_url": "https://api.github.com/users/xinyu-intel/gists{/gist_id}", "starred_url": "https://api.github.com/users/xinyu-intel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xinyu-intel/subscriptions", "organizations_url": "https://api.github.com/users/xinyu-intel/orgs", "repos_url": "https://api.github.com/users/xinyu-intel/repos", "events_url": "https://api.github.com/users/xinyu-intel/events{/privacy}", "received_events_url": "https://api.github.com/users/xinyu-intel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-02-01T12:51:20Z", "updated_at": "2020-02-03T12:41:03Z", "closed_at": "2020-02-03T12:41:03Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Cannot the [reported accuracy](https://github.com/dmlc/gluon-nlp/commit/5fe8d7b7f5770d82e4f3bfb489a67999d9442ce6#diff-4aa9944e2504738fdac28fee1d391628R124) with the master branch of GluonNLP and a pre-release build of MXNet.\r\n\r\n## Build MXNet:\r\n```\r\ngit checkout 1.6.0.rc2 #(or rc1)\r\n    make \\\r\n        DEV=0                                     \\\r\n        ENABLE_TESTCOVERAGE=0                     \\\r\n        USE_BLAS=openblas                         \\\r\n        USE_MKLDNN=0                              \\\r\n        USE_CUDA=1                                \\\r\n        USE_CUDA_PATH=/usr/local/cuda             \\\r\n        USE_CUDNN=1                               \\\r\n        USE_CPP_PACKAGE=0                         \\\r\n        USE_DIST_KVSTORE=1                        \\\r\n        USE_SIGNAL_HANDLER=1                      \\\r\n        -j$(nproc)\r\n```\r\n\r\n## finetune log\r\n```\r\nroot@04056391b12a:/workspace/gluon-nlp/scripts/bert# python3 finetune_classifier.py --batch_size 32 --lr 2e-5 --epochs 5 --gpu 0 --seed 27 --task_name MRPC --warmup_ratio 0.1\r\nINFO:root:20:37:55 Namespace(accumulate=None, batch_size=32, bert_dataset='book_corpus_wiki_en_uncased', bert_model='bert_12_768_12', dev_batch_size=8, dtype='float32', early_stop=None, epochs=5, epsilon=1e-06, gpu=0, log_interval=10, lr=2e-05, max_len=128, model_parameters=None, only_inference=False, optimizer='bertadam', output_dir='./output_dir', pretrained_bert_parameters=None, seed=27, task_name='MRPC', training_steps=None, warmup_ratio=0.1)\r\nINFO:root:20:38:01 processing dataset...\r\nINFO:root:20:38:04 Now we are doing BERT classification training on gpu(0)!\r\nINFO:root:20:38:04 training steps=573\r\nINFO:root:20:38:07 [Epoch 1 Batch 10/119] loss=0.6059, lr=0.0000032, metrics:accuracy:0.7125,f1:0.8321\r\nINFO:root:20:38:08 [Epoch 1 Batch 20/119] loss=0.6329, lr=0.0000067, metrics:accuracy:0.6969,f1:0.8210\r\nINFO:root:20:38:10 [Epoch 1 Batch 30/119] loss=0.5927, lr=0.0000102, metrics:accuracy:0.7010,f1:0.8225\r\nINFO:root:20:38:11 [Epoch 1 Batch 40/119] loss=0.6142, lr=0.0000137, metrics:accuracy:0.6938,f1:0.8111\r\nINFO:root:20:38:12 [Epoch 1 Batch 50/119] loss=0.6124, lr=0.0000172, metrics:accuracy:0.6900,f1:0.7995\r\nINFO:root:20:38:14 [Epoch 1 Batch 60/119] loss=0.5779, lr=0.0000199, metrics:accuracy:0.6983,f1:0.8040\r\nINFO:root:20:38:15 [Epoch 1 Batch 70/119] loss=0.5541, lr=0.0000195, metrics:accuracy:0.7019,f1:0.8050\r\nINFO:root:20:38:17 [Epoch 1 Batch 80/119] loss=0.5493, lr=0.0000191, metrics:accuracy:0.7078,f1:0.8065\r\nINFO:root:20:38:18 [Epoch 1 Batch 90/119] loss=0.5324, lr=0.0000188, metrics:accuracy:0.7127,f1:0.8088\r\nINFO:root:20:38:20 [Epoch 1 Batch 100/119] loss=0.4922, lr=0.0000184, metrics:accuracy:0.7190,f1:0.8111\r\nINFO:root:20:38:21 [Epoch 1 Batch 110/119] loss=0.4427, lr=0.0000180, metrics:accuracy:0.7272,f1:0.8162\r\nINFO:root:20:38:23 Now we are doing evaluation on dev with gpu(0).\r\nINFO:root:20:38:23 [Batch 10/51] loss=0.4181, metrics:accuracy:0.8250,f1:0.8852\r\nINFO:root:20:38:23 [Batch 20/51] loss=0.5037, metrics:accuracy:0.8187,f1:0.8816\r\nINFO:root:20:38:24 [Batch 30/51] loss=0.4967, metrics:accuracy:0.8000,f1:0.8717\r\nINFO:root:20:38:24 [Batch 40/51] loss=0.4722, metrics:accuracy:0.8000,f1:0.8704\r\nINFO:root:20:38:25 [Batch 50/51] loss=0.5662, metrics:accuracy:0.7850,f1:0.8613\r\nINFO:root:20:38:25 validation metrics:accuracy:0.7868,f1:0.8621\r\nINFO:root:20:38:25 Time cost=1.77s, throughput=229.98 samples/s\r\nINFO:root:20:38:26 params saved in: ./output_dir/model_bert_MRPC_0.params\r\nINFO:root:20:38:26 Time cost=22.49s\r\nINFO:root:20:38:28 [Epoch 2 Batch 10/119] loss=0.3253, lr=0.0000172, metrics:accuracy:0.8688,f1:0.8966\r\nINFO:root:20:38:29 [Epoch 2 Batch 20/119] loss=0.3138, lr=0.0000169, metrics:accuracy:0.8719,f1:0.9042\r\nINFO:root:20:38:31 [Epoch 2 Batch 30/119] loss=0.2757, lr=0.0000165, metrics:accuracy:0.8797,f1:0.9104\r\nINFO:root:20:38:32 [Epoch 2 Batch 40/119] loss=0.2706, lr=0.0000161, metrics:accuracy:0.8833,f1:0.9130\r\nINFO:root:20:38:34 [Epoch 2 Batch 50/119] loss=0.2650, lr=0.0000157, metrics:accuracy:0.8866,f1:0.9145\r\nINFO:root:20:38:35 [Epoch 2 Batch 60/119] loss=0.2459, lr=0.0000153, metrics:accuracy:0.8889,f1:0.9178\r\nINFO:root:20:38:37 [Epoch 2 Batch 70/119] loss=0.2139, lr=0.0000149, metrics:accuracy:0.8950,f1:0.9225\r\nINFO:root:20:38:38 [Epoch 2 Batch 80/119] loss=0.2327, lr=0.0000145, metrics:accuracy:0.8956,f1:0.9231\r\nINFO:root:20:38:40 [Epoch 2 Batch 90/119] loss=0.2622, lr=0.0000141, metrics:accuracy:0.8933,f1:0.9215\r\nINFO:root:20:38:41 [Epoch 2 Batch 100/119] loss=0.2276, lr=0.0000138, metrics:accuracy:0.8954,f1:0.9233\r\nINFO:root:20:38:43 [Epoch 2 Batch 110/119] loss=0.2377, lr=0.0000134, metrics:accuracy:0.8962,f1:0.9232\r\nINFO:root:20:38:44 Now we are doing evaluation on dev with gpu(0).\r\nINFO:root:20:38:44 [Batch 10/51] loss=0.3335, metrics:accuracy:0.8750,f1:0.9153\r\nINFO:root:20:38:45 [Batch 20/51] loss=0.3119, metrics:accuracy:0.8812,f1:0.9191\r\nINFO:root:20:38:45 [Batch 30/51] loss=0.4895, metrics:accuracy:0.8542,f1:0.8997\r\nINFO:root:20:38:45 [Batch 40/51] loss=0.4089, metrics:accuracy:0.8531,f1:0.8976\r\nINFO:root:20:38:46 [Batch 50/51] loss=0.3950, metrics:accuracy:0.8550,f1:0.8990\r\nINFO:root:20:38:46 validation metrics:accuracy:0.8554,f1:0.8991\r\nINFO:root:20:38:46 Time cost=1.74s, throughput=234.35 samples/s\r\nINFO:root:20:38:47 params saved in: ./output_dir/model_bert_MRPC_1.params\r\nINFO:root:20:38:47 Time cost=21.17s\r\nINFO:root:20:38:49 [Epoch 3 Batch 10/119] loss=0.1351, lr=0.0000126, metrics:accuracy:0.9643,f1:0.9744\r\nINFO:root:20:38:50 [Epoch 3 Batch 20/119] loss=0.1336, lr=0.0000122, metrics:accuracy:0.9634,f1:0.9736\r\nINFO:root:20:38:52 [Epoch 3 Batch 30/119] loss=0.0653, lr=0.0000119, metrics:accuracy:0.9672,f1:0.9763\r\nINFO:root:20:38:53 [Epoch 3 Batch 40/119] loss=0.1611, lr=0.0000115, metrics:accuracy:0.9593,f1:0.9702\r\nINFO:root:20:38:55 [Epoch 3 Batch 50/119] loss=0.0723, lr=0.0000111, metrics:accuracy:0.9632,f1:0.9731\r\nINFO:root:20:38:56 [Epoch 3 Batch 60/119] loss=0.0905, lr=0.0000107, metrics:accuracy:0.9642,f1:0.9740\r\nINFO:root:20:38:58 [Epoch 3 Batch 70/119] loss=0.0998, lr=0.0000103, metrics:accuracy:0.9649,f1:0.9742\r\nINFO:root:20:39:00 [Epoch 3 Batch 80/119] loss=0.1052, lr=0.0000099, metrics:accuracy:0.9658,f1:0.9746\r\nINFO:root:20:39:01 [Epoch 3 Batch 90/119] loss=0.1333, lr=0.0000095, metrics:accuracy:0.9654,f1:0.9744\r\nINFO:root:20:39:02 [Epoch 3 Batch 100/119] loss=0.1174, lr=0.0000091, metrics:accuracy:0.9658,f1:0.9746\r\nINFO:root:20:39:04 [Epoch 3 Batch 110/119] loss=0.0648, lr=0.0000088, metrics:accuracy:0.9670,f1:0.9755\r\nINFO:root:20:39:05 Now we are doing evaluation on dev with gpu(0).\r\nINFO:root:20:39:06 [Batch 10/51] loss=0.4370, metrics:accuracy:0.8750,f1:0.9123\r\nINFO:root:20:39:06 [Batch 20/51] loss=0.5114, metrics:accuracy:0.8875,f1:0.9217\r\nINFO:root:20:39:06 [Batch 30/51] loss=0.6030, metrics:accuracy:0.8625,f1:0.9054\r\nINFO:root:20:39:07 [Batch 40/51] loss=0.5415, metrics:accuracy:0.8688,f1:0.9091\r\nINFO:root:20:39:07 [Batch 50/51] loss=0.5222, metrics:accuracy:0.8675,f1:0.9081\r\nINFO:root:20:39:07 validation metrics:accuracy:0.8701,f1:0.9097\r\nINFO:root:20:39:07 Time cost=1.72s, throughput=237.49 samples/s\r\nINFO:root:20:39:08 params saved in: ./output_dir/model_bert_MRPC_2.params\r\nINFO:root:20:39:08 Time cost=21.12s\r\nINFO:root:20:39:10 [Epoch 4 Batch 10/119] loss=0.0717, lr=0.0000080, metrics:accuracy:0.9773,f1:0.9825\r\nINFO:root:20:39:11 [Epoch 4 Batch 20/119] loss=0.0759, lr=0.0000076, metrics:accuracy:0.9761,f1:0.9827\r\nINFO:root:20:39:13 [Epoch 4 Batch 30/119] loss=0.0419, lr=0.0000072, metrics:accuracy:0.9781,f1:0.9844\r\nINFO:root:20:39:15 [Epoch 4 Batch 40/119] loss=0.0484, lr=0.0000069, metrics:accuracy:0.9801,f1:0.9853\r\nINFO:root:20:39:16 [Epoch 4 Batch 50/119] loss=0.0318, lr=0.0000065, metrics:accuracy:0.9823,f1:0.9871\r\nINFO:root:20:39:18 [Epoch 4 Batch 60/119] loss=0.0364, lr=0.0000061, metrics:accuracy:0.9837,f1:0.9881\r\nINFO:root:20:39:20 [Epoch 4 Batch 70/119] loss=0.0524, lr=0.0000057, metrics:accuracy:0.9843,f1:0.9887\r\nINFO:root:20:39:21 [Epoch 4 Batch 80/119] loss=0.0461, lr=0.0000053, metrics:accuracy:0.9847,f1:0.9889\r\nINFO:root:20:39:23 [Epoch 4 Batch 90/119] loss=0.0142, lr=0.0000049, metrics:accuracy:0.9856,f1:0.9896\r\nINFO:root:20:39:24 [Epoch 4 Batch 100/119] loss=0.0698, lr=0.0000045, metrics:accuracy:0.9858,f1:0.9896\r\nINFO:root:20:39:26 [Epoch 4 Batch 110/119] loss=0.0215, lr=0.0000041, metrics:accuracy:0.9868,f1:0.9903\r\nINFO:root:20:39:27 Now we are doing evaluation on dev with gpu(0).\r\nINFO:root:20:39:27 [Batch 10/51] loss=0.4604, metrics:accuracy:0.8875,f1:0.9204\r\nINFO:root:20:39:28 [Batch 20/51] loss=0.4895, metrics:accuracy:0.8875,f1:0.9204\r\nINFO:root:20:39:28 [Batch 30/51] loss=0.8420, metrics:accuracy:0.8583,f1:0.9000\r\nINFO:root:20:39:29 [Batch 40/51] loss=0.5393, metrics:accuracy:0.8625,f1:0.9022\r\nINFO:root:20:39:29 [Batch 50/51] loss=0.5371, metrics:accuracy:0.8675,f1:0.9059\r\nINFO:root:20:39:29 validation metrics:accuracy:0.8676,f1:0.9056\r\nINFO:root:20:39:29 Time cost=1.78s, throughput=228.63 samples/s\r\nINFO:root:20:39:30 params saved in: ./output_dir/model_bert_MRPC_3.params\r\nINFO:root:20:39:30 Time cost=21.96s\r\nINFO:root:20:39:32 [Epoch 5 Batch 10/119] loss=0.0172, lr=0.0000034, metrics:accuracy:0.9938,f1:0.9950\r\nINFO:root:20:39:33 [Epoch 5 Batch 20/119] loss=0.0403, lr=0.0000030, metrics:accuracy:0.9906,f1:0.9927\r\nINFO:root:20:39:35 [Epoch 5 Batch 30/119] loss=0.0427, lr=0.0000026, metrics:accuracy:0.9917,f1:0.9936\r\nINFO:root:20:39:36 [Epoch 5 Batch 40/119] loss=0.0460, lr=0.0000022, metrics:accuracy:0.9913,f1:0.9934\r\nINFO:root:20:39:38 [Epoch 5 Batch 50/119] loss=0.0076, lr=0.0000019, metrics:accuracy:0.9924,f1:0.9942\r\nINFO:root:20:39:40 [Epoch 5 Batch 60/119] loss=0.0457, lr=0.0000015, metrics:accuracy:0.9921,f1:0.9941\r\nINFO:root:20:39:41 [Epoch 5 Batch 70/119] loss=0.0045, lr=0.0000011, metrics:accuracy:0.9932,f1:0.9949\r\nINFO:root:20:39:42 [Epoch 5 Batch 80/119] loss=0.0227, lr=0.0000007, metrics:accuracy:0.9931,f1:0.9948\r\nINFO:root:20:39:44 [Epoch 5 Batch 90/119] loss=0.0273, lr=0.0000003, metrics:accuracy:0.9931,f1:0.9948\r\nINFO:root:20:39:45 Finish training step: 573\r\nINFO:root:20:39:45 Now we are doing evaluation on dev with gpu(0).\r\nINFO:root:20:39:45 [Batch 10/51] loss=0.5129, metrics:accuracy:0.8750,f1:0.9123\r\nINFO:root:20:39:46 [Batch 20/51] loss=0.5087, metrics:accuracy:0.8812,f1:0.9170\r\nINFO:root:20:39:46 [Batch 30/51] loss=0.8643, metrics:accuracy:0.8542,f1:0.8980\r\nINFO:root:20:39:47 [Batch 40/51] loss=0.5841, metrics:accuracy:0.8594,f1:0.9007\r\nINFO:root:20:39:47 [Batch 50/51] loss=0.6210, metrics:accuracy:0.8625,f1:0.9030\r\nINFO:root:20:39:47 validation metrics:accuracy:0.8627,f1:0.9028\r\nINFO:root:20:39:47 Time cost=1.72s, throughput=236.88 samples/s\r\nINFO:root:20:39:48 params saved in: ./output_dir/model_bert_MRPC_4.params\r\nINFO:root:20:39:48 Time cost=17.98s\r\nINFO:root:20:39:49 Best model at epoch 2. Validation metrics:accuracy:0.8701,f1:0.9097\r\nINFO:root:20:39:49 Now we are doing testing on test with gpu(0).\r\nINFO:root:20:39:56 Time cost=6.93s, throughput=249.47 samples/s\r\n```\r\n\r\n@TaoLv @eric-haibin-lin @zburning", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1132", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1132/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1132/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1132/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1132", "id": 557976813, "node_id": "MDU6SXNzdWU1NTc5NzY4MTM=", "number": 1132, "title": "Include padding to fixed length in nlp.data.batchify", "user": {"login": "zburning", "id": 26197318, "node_id": "MDQ6VXNlcjI2MTk3MzE4", "avatar_url": "https://avatars1.githubusercontent.com/u/26197318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zburning", "html_url": "https://github.com/zburning", "followers_url": "https://api.github.com/users/zburning/followers", "following_url": "https://api.github.com/users/zburning/following{/other_user}", "gists_url": "https://api.github.com/users/zburning/gists{/gist_id}", "starred_url": "https://api.github.com/users/zburning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zburning/subscriptions", "organizations_url": "https://api.github.com/users/zburning/orgs", "repos_url": "https://api.github.com/users/zburning/repos", "events_url": "https://api.github.com/users/zburning/events{/privacy}", "received_events_url": "https://api.github.com/users/zburning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-31T08:06:38Z", "updated_at": "2020-02-04T13:18:02Z", "closed_at": "2020-02-04T13:18:02Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nSometimes we need to pad sequences to a fixed length for latency evaluation.\r\nDoes it make sense to include such a feature in nlp.data.batchify.Pad() or a new batchify API?\r\n\r\n## References\r\n- list reference and related literature\r\n- list known implementations\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1129", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1129/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1129/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1129/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1129", "id": 557203801, "node_id": "MDU6SXNzdWU1NTcyMDM4MDE=", "number": 1129, "title": "Remove mutable_args restriction in get_model API ", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 890393505, "node_id": "MDU6TGFiZWw4OTAzOTM1MDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-01-30T00:48:29Z", "updated_at": "2020-08-11T06:04:52Z", "closed_at": "2020-08-11T06:04:52Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I think we can remove the check of `mutable_args` in the get_model API for BERT, GPT, Language model and transformer. We can introduce a separate flag \"allow_override\" if users want to override any configuration. Otherwise overriding any configuration is forbidden. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1125", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1125/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1125/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1125/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1125", "id": 552029216, "node_id": "MDU6SXNzdWU1NTIwMjkyMTY=", "number": 1125, "title": "Provide evaluation instructions for BERT SQuAD 2.0", "user": {"login": "TaoLv", "id": 22437510, "node_id": "MDQ6VXNlcjIyNDM3NTEw", "avatar_url": "https://avatars2.githubusercontent.com/u/22437510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TaoLv", "html_url": "https://github.com/TaoLv", "followers_url": "https://api.github.com/users/TaoLv/followers", "following_url": "https://api.github.com/users/TaoLv/following{/other_user}", "gists_url": "https://api.github.com/users/TaoLv/gists{/gist_id}", "starred_url": "https://api.github.com/users/TaoLv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TaoLv/subscriptions", "organizations_url": "https://api.github.com/users/TaoLv/orgs", "repos_url": "https://api.github.com/users/TaoLv/repos", "events_url": "https://api.github.com/users/TaoLv/events{/privacy}", "received_events_url": "https://api.github.com/users/TaoLv/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": {"login": "zburning", "id": 26197318, "node_id": "MDQ6VXNlcjI2MTk3MzE4", "avatar_url": "https://avatars1.githubusercontent.com/u/26197318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zburning", "html_url": "https://github.com/zburning", "followers_url": "https://api.github.com/users/zburning/followers", "following_url": "https://api.github.com/users/zburning/following{/other_user}", "gists_url": "https://api.github.com/users/zburning/gists{/gist_id}", "starred_url": "https://api.github.com/users/zburning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zburning/subscriptions", "organizations_url": "https://api.github.com/users/zburning/orgs", "repos_url": "https://api.github.com/users/zburning/repos", "events_url": "https://api.github.com/users/zburning/events{/privacy}", "received_events_url": "https://api.github.com/users/zburning/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zburning", "id": 26197318, "node_id": "MDQ6VXNlcjI2MTk3MzE4", "avatar_url": "https://avatars1.githubusercontent.com/u/26197318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zburning", "html_url": "https://github.com/zburning", "followers_url": "https://api.github.com/users/zburning/followers", "following_url": "https://api.github.com/users/zburning/following{/other_user}", "gists_url": "https://api.github.com/users/zburning/gists{/gist_id}", "starred_url": "https://api.github.com/users/zburning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zburning/subscriptions", "organizations_url": "https://api.github.com/users/zburning/orgs", "repos_url": "https://api.github.com/users/zburning/repos", "events_url": "https://api.github.com/users/zburning/events{/privacy}", "received_events_url": "https://api.github.com/users/zburning/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-01-20T02:09:56Z", "updated_at": "2020-01-20T19:05:28Z", "closed_at": "2020-01-20T06:26:37Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Description\r\nThe fine-tuning process doesn't print the evaluation accuracy of BERT SQuAD 2.0.\r\n\r\n```\r\nINFO:gluonnlp:23:25:18 Time cost=19445.62 s, Thoughput=14.84 samples/s\r\nINFO:gluonnlp:23:25:33 Loading dev data...\r\nINFO:gluonnlp:23:25:33 Number of records in dev data:11873\r\nINFO:gluonnlp:23:26:43 The number of examples after preprocessing:13600\r\nDone! Transform dataset costs 11.57 seconds.\r\nINFO:gluonnlp:23:26:43 start prediction\r\nINFO:gluonnlp:23:30:07 Time cost=203.42 s, Thoughput=66.86 samples/s\r\nINFO:gluonnlp:23:30:07 Get prediction results...\r\nINFO:gluonnlp:23:31:27 Please run evaluate-v2.0.py to get evaluation results for SQuAD 2.0\r\n```\r\n\r\nWhere  can I find the evaluate-v2.0.py?\r\n\r\n### Error Message\r\nNone\r\n\r\n## To Reproduce\r\n\r\n```\r\npython finetune_squad.py --optimizer adam --batch_size 8  --lr 3e-5 --epochs 2 --bert_model bert_24_1024_16 --version_2 --max_seq_length 256 --gpu 0  --null_score_diff_threshold -2.0\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1112", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1112/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1112/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1112/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1112", "id": 550343980, "node_id": "MDU6SXNzdWU1NTAzNDM5ODA=", "number": 1112, "title": "Website and scripts/machine_translation/inference_transformer.py recommend different pretrained weights", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-01-15T18:03:51Z", "updated_at": "2020-01-16T10:37:00Z", "closed_at": "2020-01-16T10:37:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nhttps://github.com/dmlc/gluon-nlp/blame/3ce9995329fb0d18787019df541d4f229d7c9ded/scripts/machine_translation/inference_transformer.py#L169\r\n\r\nuses `transformer_en_de_512_WMT2014-97ffd554a.zip`. But the [website](https://gluon-nlp.mxnet.io/master/model_zoo/machine_translation/index.html) recommends `transformer_en_de_512_WMT2014-e25287c5.zip`.\r\n\r\nFor consistency's sake we should use the same file on both sites.\r\n\r\nThanks @JulianSlzr for noting the issue in https://github.com/dmlc/gluon-nlp/issues/1038\r\n\r\n\r\n@ciyongch @pengxin99 @eric-haibin-lin could you advise about why https://github.com/dmlc/gluon-nlp/pull/852 introduced the new parameter file?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1110", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1110/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1110/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1110/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1110", "id": 549857214, "node_id": "MDU6SXNzdWU1NDk4NTcyMTQ=", "number": 1110, "title": "[reproducibility] add util function to enhance reproducibility", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-01-14T22:32:43Z", "updated_at": "2020-02-18T17:04:49Z", "closed_at": "2020-02-18T17:04:49Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "There are a few seeds that may lead to nondeterministic training loss: \r\n```\r\nrandom.seed(seed)\r\nmx.random.seed(seed)\r\nnumpy.random.seed(seed)\r\n```\r\nSometimes our users miss one of them. Shall we add an API `gluonnlp.utils.seed` to set the seed for all of them? \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1102", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1102/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1102/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1102/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1102", "id": 546681711, "node_id": "MDU6SXNzdWU1NDY2ODE3MTE=", "number": 1102, "title": "Log average loss metric of training GNMT", "user": {"login": "liuzh91", "id": 12567586, "node_id": "MDQ6VXNlcjEyNTY3NTg2", "avatar_url": "https://avatars3.githubusercontent.com/u/12567586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liuzh91", "html_url": "https://github.com/liuzh91", "followers_url": "https://api.github.com/users/liuzh91/followers", "following_url": "https://api.github.com/users/liuzh91/following{/other_user}", "gists_url": "https://api.github.com/users/liuzh91/gists{/gist_id}", "starred_url": "https://api.github.com/users/liuzh91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liuzh91/subscriptions", "organizations_url": "https://api.github.com/users/liuzh91/orgs", "repos_url": "https://api.github.com/users/liuzh91/repos", "events_url": "https://api.github.com/users/liuzh91/events{/privacy}", "received_events_url": "https://api.github.com/users/liuzh91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-08T07:03:27Z", "updated_at": "2020-01-10T02:46:03Z", "closed_at": "2020-01-10T02:46:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nCurrent `log_avg_loss` in the `train_gnmt.py` script is incorrect.\r\n```python\r\nwith mx.autograd.record():\r\n        out, _ = model(src_seq, tgt_seq[:, :-1], src_valid_length, tgt_valid_length - 1)\r\n        loss = loss_function(out, tgt_seq[:, 1:], tgt_valid_length - 1).mean()\r\n        loss = loss * (tgt_seq.shape[1] - 1) / (tgt_valid_length - 1).mean()\r\n        loss.backward()\r\nstep_loss = loss.asscalar()\r\nlog_avg_loss += step_loss\r\nlog_avg_gnorm += gnorm\r\n```\r\n\r\n`log_avg_loss` sums up averaged losses from different batches. It is divided by `args.log_interval` to compute the loss during the interval. It is inconsistent with the loss metric used in `train_transformer` script. In the latter script, losses and valid lengths during the interval are summed up separately. The average loss is computed from `interval_loss/interval_valid_length`.\r\n\r\nAlthough these two computations are similar, I think it will be better to unify them in training scripts.\r\n\r\n## Log Message\r\nI print out the log message here:\r\n```\r\n2020-01-08 07:00:24,259 - root - [Epoch 0 Batch 100/1043] loss=6.2948, ppl=541.7368, gnorm=0.7030, throughput=36.26K wps, wc=606.57K\r\n2020-01-08 07:00:37,441 - root - [Epoch 0 Batch 200/1043] loss=5.7232, ppl=305.8789, gnorm=0.3394, throughput=44.32K wps, wc=584.18K\r\n2020-01-08 07:00:50,411 - root - [Epoch 0 Batch 300/1043] loss=5.2613, ppl=192.7247, gnorm=0.3442, throughput=45.71K wps, wc=592.78K\r\n2020-01-08 07:01:03,364 - root - [Epoch 0 Batch 400/1043] loss=4.9213, ppl=137.1854, gnorm=0.3193, throughput=44.10K wps, wc=571.26K\r\n2020-01-08 07:01:16,174 - root - [Epoch 0 Batch 500/1043] loss=4.6531, ppl=104.9109, gnorm=0.3304, throughput=43.29K wps, wc=554.48K\r\n2020-01-08 07:01:28,367 - root - [Epoch 0 Batch 600/1043] loss=4.4185, ppl=82.9729, gnorm=0.3167, throughput=44.80K wps, wc=546.26K\r\n2020-01-08 07:01:41,019 - root - [Epoch 0 Batch 700/1043] loss=4.3236, ppl=75.4571, gnorm=0.3128, throughput=44.82K wps, wc=566.96K\r\n2020-01-08 07:01:53,287 - root - [Epoch 0 Batch 800/1043] loss=4.2010, ppl=66.7544, gnorm=0.3120, throughput=44.95K wps, wc=551.40K\r\n2020-01-08 07:02:06,260 - root - [Epoch 0 Batch 900/1043] loss=4.0903, ppl=59.7581, gnorm=0.3177, throughput=44.53K wps, wc=577.61K\r\n2020-01-08 07:02:19,849 - root - [Epoch 0 Batch 1000/1043] loss=4.0345, ppl=56.5169, gnorm=0.3055, throughput=43.28K wps, wc=588.16K\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1094", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1094/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1094/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1094/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1094", "id": 545579227, "node_id": "MDU6SXNzdWU1NDU1NzkyMjc=", "number": 1094, "title": "Add length normalized loss metrics in API", "user": {"login": "liuzh91", "id": 12567586, "node_id": "MDQ6VXNlcjEyNTY3NTg2", "avatar_url": "https://avatars3.githubusercontent.com/u/12567586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liuzh91", "html_url": "https://github.com/liuzh91", "followers_url": "https://api.github.com/users/liuzh91/followers", "following_url": "https://api.github.com/users/liuzh91/following{/other_user}", "gists_url": "https://api.github.com/users/liuzh91/gists{/gist_id}", "starred_url": "https://api.github.com/users/liuzh91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liuzh91/subscriptions", "organizations_url": "https://api.github.com/users/liuzh91/orgs", "repos_url": "https://api.github.com/users/liuzh91/repos", "events_url": "https://api.github.com/users/liuzh91/events{/privacy}", "received_events_url": "https://api.github.com/users/liuzh91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-01-06T07:18:17Z", "updated_at": "2020-01-22T06:55:49Z", "closed_at": "2020-01-22T06:55:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nIn typical machine translation tasks, training/validation metric loss is computed using some loss function normalized by the length of target sequence. For example, in `train_gnmt.py`, the metric is computed with the following code:\r\n\r\n```python\r\nloss = loss_function(out, tgt_seq[:, 1:], tgt_valid_length - 1).mean()\r\nloss = loss * (tgt_seq.shape[1] - 1) / (tgt_valid_length - 1).mean()\r\n```\r\nCurrent Mxnet `metric.loss` does not support length normalization. It will be great to add length normalized metric in the api.\r\n\r\n## References\r\n- https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py#L1661\r\n- https://github.com/dmlc/gluon-nlp/blob/master/scripts/machine_translation/train_gnmt.py\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1088", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1088/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1088/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1088/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1088", "id": 545076351, "node_id": "MDU6SXNzdWU1NDUwNzYzNTE=", "number": 1088, "title": "Considering adding exclude_from_weight_decay or specified decay parameter list to bertadam(or other related optimizers)?", "user": {"login": "zburning", "id": 26197318, "node_id": "MDQ6VXNlcjI2MTk3MzE4", "avatar_url": "https://avatars1.githubusercontent.com/u/26197318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zburning", "html_url": "https://github.com/zburning", "followers_url": "https://api.github.com/users/zburning/followers", "following_url": "https://api.github.com/users/zburning/following{/other_user}", "gists_url": "https://api.github.com/users/zburning/gists{/gist_id}", "starred_url": "https://api.github.com/users/zburning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zburning/subscriptions", "organizations_url": "https://api.github.com/users/zburning/orgs", "repos_url": "https://api.github.com/users/zburning/repos", "events_url": "https://api.github.com/users/zburning/events{/privacy}", "received_events_url": "https://api.github.com/users/zburning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-01-03T17:03:34Z", "updated_at": "2020-01-04T16:11:50Z", "closed_at": "2020-01-04T16:11:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nFor bert-style model training, usually we will need to use weight decay. But we may not want to include some parameters to weight decay, e.g. layernorm. \r\nFor example, in [BERT](https://github.com/google-research/bert/blob/cc7051dc592802f501e8a6f71f8fb3cf9de95dc9/optimization.py#L65), they have a argument exclude_from_weight_decay. In the current [tensorflow](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/contrib/opt/python/training/weight_decay_optimizers.py#L108), they implement a DecoupledWeightDecayExtension class to inherit from and specified it as decay_var_list.\r\nI did not see if we have such a choice, do you guys think it is necessary do add it?\r\n\r\n\r\n\r\n## References\r\n- list reference and related literature\r\n- list known implementations\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1086", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1086/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1086/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1086/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1086", "id": 544896415, "node_id": "MDU6SXNzdWU1NDQ4OTY0MTU=", "number": 1086, "title": "Conflict between weight tied and weight sharing", "user": {"login": "liuzh91", "id": 12567586, "node_id": "MDQ6VXNlcjEyNTY3NTg2", "avatar_url": "https://avatars3.githubusercontent.com/u/12567586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liuzh91", "html_url": "https://github.com/liuzh91", "followers_url": "https://api.github.com/users/liuzh91/followers", "following_url": "https://api.github.com/users/liuzh91/following{/other_user}", "gists_url": "https://api.github.com/users/liuzh91/gists{/gist_id}", "starred_url": "https://api.github.com/users/liuzh91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liuzh91/subscriptions", "organizations_url": "https://api.github.com/users/liuzh91/orgs", "repos_url": "https://api.github.com/users/liuzh91/repos", "events_url": "https://api.github.com/users/liuzh91/events{/privacy}", "received_events_url": "https://api.github.com/users/liuzh91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-01-03T08:23:43Z", "updated_at": "2020-01-10T02:46:26Z", "closed_at": "2020-01-10T02:46:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nThis bug is the same as https://github.com/apache/incubator-mxnet/issues/17184 It is an error introduced in gluonnlp models instead of mxnet side, so I move the issue here.\r\n\r\nWe experience some weight initialization error when we use weight sharing and weight tied simultaneously. We share weights between `model` and `model_eval`. The code is shown below:\r\n\r\n```python\r\nmodel = nlp.model.train.AWDRNN(args.model, len(vocab), args.emsize, args.nhid, args.nlayers,\r\n                               args.tied, args.dropout, args.weight_dropout,\r\n                               args.dropout_h, args.dropout_i, args.dropout_e)\r\nmodel_eval = nlp.model.AWDRNN(args.model, len(vocab), args.emsize, args.nhid, args.nlayers,\r\n                              args.tied, args.dropout, args.weight_dropout,\r\n                              args.dropout_h, args.dropout_i, args.dropout_e,\r\n                              params=model.collect_params())\r\n\r\nmodel.initialize(mx.init.Xavier(), ctx=context)\r\n\r\nmodel.hybridize(static_alloc=True)\r\n\r\nprint(model)\r\n\r\ndef check_initialized(net):\r\n    params = net.collect_params()\r\n    for param in params:\r\n        try:\r\n            params[param].list_ctx()\r\n        except RuntimeError:\r\n            return False\r\n    return True\r\n\r\nprint(check_initialized(model))\r\nprint(check_initialized(model_eval))\r\n```\r\n\r\n### Log Message\r\nIf `args.tied` is set `True`, we get the following log message:\r\n```python\r\nTrue\r\nFalse\r\n```\r\nIf we turn off `args.tied`, the initialization works correctly.\r\n\r\n### To Reproduce\r\n(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\r\nThe file can be found in (https://github.com/dmlc/gluon-nlp/blob/v0.8.x/scripts/language_model/word_language_model.py). To reproduce the above message, you may need to replace line 153 onward  with the above code snippet. Run the following command:\r\n\r\n```\r\npython -m pdb word_language_model.py --tied --dropout_e=0\r\n```\r\nYou will encounter the above error.\r\n\r\n## What have you tried to solve it?\r\n\r\nThe parameter that not initialized properly is the parameter `awdrnn0_hybridsequential0_embedding0_bias`. It is the weight used in the decoder of AWDRNN.  After some investigation, we found it is the tied weights introducing this error:\r\n\r\n```python\r\n    if self._tie_weights:\r\n         output.add(nn.Dense(self._vocab_size, flatten=False,\r\n                             params=self.embedding[0].params))\r\n```\r\n\r\nI print some debug information which may be helpful here:\r\n```\r\n(Pdb) model_eval.decoder[0]._params['awdrnn0_hybridsequential0_embedding0_bias'].list_ctx()\r\n*** RuntimeError: Parameter 'awdrnn0_hybridsequential0_embedding0_bias' has not been initialized\r\n```\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1085", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1085/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1085/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1085/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1085", "id": 543089562, "node_id": "MDU6SXNzdWU1NDMwODk1NjI=", "number": 1085, "title": "Different tensor contexts in nlp.optimizer.lamb", "user": {"login": "zburning", "id": 26197318, "node_id": "MDQ6VXNlcjI2MTk3MzE4", "avatar_url": "https://avatars1.githubusercontent.com/u/26197318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zburning", "html_url": "https://github.com/zburning", "followers_url": "https://api.github.com/users/zburning/followers", "following_url": "https://api.github.com/users/zburning/following{/other_user}", "gists_url": "https://api.github.com/users/zburning/gists{/gist_id}", "starred_url": "https://api.github.com/users/zburning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zburning/subscriptions", "organizations_url": "https://api.github.com/users/zburning/orgs", "repos_url": "https://api.github.com/users/zburning/repos", "events_url": "https://api.github.com/users/zburning/events{/privacy}", "received_events_url": "https://api.github.com/users/zburning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-12-28T07:49:23Z", "updated_at": "2020-01-16T22:51:29Z", "closed_at": "2020-01-16T22:50:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nIn the update() function in lamb.py:\r\n\r\n```\r\n# preprocess grad\r\n   grad *= self.rescale_grad\r\n   if self.clip_gradient is not None:\r\n       grad = clip(grad, -self.clip_gradient, self.clip_gradient)\r\n```\r\nThe rescale_grad should be as_in_context(grad.context)? Otherwise it will raise illegal memory access in multi-gpu training\r\n\r\n\r\n### Error Message\r\n(Paste the complete error message, including stack trace.)\r\n\r\n## To Reproduce\r\n(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n1.\r\n2.\r\n\r\n## What have you tried to solve it?\r\n\r\n1.\r\n2.\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1069", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1069/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1069/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1069/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1069", "id": 540132164, "node_id": "MDU6SXNzdWU1NDAxMzIxNjQ=", "number": 1069, "title": "Github default branch", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 963101581, "node_id": "MDU6TGFiZWw5NjMxMDE1ODE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/discussion", "name": "discussion", "color": "c5def5", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-12-19T07:30:14Z", "updated_at": "2019-12-19T07:31:13Z", "closed_at": "2019-12-19T07:31:13Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Should gluonnlp display the latest stable release branch as the default branch on Github? I came across a few cases where users clones the script/notebook on github master branch, but the pip installed version is actually gluonnlp nightly. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1068", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1068/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1068/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1068/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1068", "id": 540130755, "node_id": "MDU6SXNzdWU1NDAxMzA3NTU=", "number": 1068, "title": "Github default branch", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 963101581, "node_id": "MDU6TGFiZWw5NjMxMDE1ODE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/discussion", "name": "discussion", "color": "c5def5", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-19T07:26:49Z", "updated_at": "2019-12-23T05:14:03Z", "closed_at": "2019-12-23T05:14:03Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Should gluonnlp display the latest stable release branch as the default branch on Github? I came across a few cases where users clones the script/notebook on github master branch, but the pip installed version is actually gluonnlp nightly. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1062", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1062/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1062/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1062/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1062", "id": 539960175, "node_id": "MDU6SXNzdWU1Mzk5NjAxNzU=", "number": 1062, "title": "nlp.model.list_models(), nlp.data.list_datasets()", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-18T22:29:28Z", "updated_at": "2020-03-18T19:26:13Z", "closed_at": "2020-03-18T19:26:13Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Description\r\nWe have a lot of pre-trained models and hosted datasets in gluonnlp. Currently the only way to discover them is via the API documentation. It would be great to have APIs to query the list of models and datasets available. The list is already maintained in the code anyways. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1061", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1061/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1061/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1061/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1061", "id": 539772355, "node_id": "MDU6SXNzdWU1Mzk3NzIzNTU=", "number": 1061, "title": "Problem with gluon.utils.split_data", "user": {"login": "zburning", "id": 26197318, "node_id": "MDQ6VXNlcjI2MTk3MzE4", "avatar_url": "https://avatars1.githubusercontent.com/u/26197318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zburning", "html_url": "https://github.com/zburning", "followers_url": "https://api.github.com/users/zburning/followers", "following_url": "https://api.github.com/users/zburning/following{/other_user}", "gists_url": "https://api.github.com/users/zburning/gists{/gist_id}", "starred_url": "https://api.github.com/users/zburning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zburning/subscriptions", "organizations_url": "https://api.github.com/users/zburning/orgs", "repos_url": "https://api.github.com/users/zburning/repos", "events_url": "https://api.github.com/users/zburning/events{/privacy}", "received_events_url": "https://api.github.com/users/zburning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-18T16:02:26Z", "updated_at": "2019-12-19T02:36:06Z", "closed_at": "2019-12-19T02:36:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nThe current gluon.utils.split_data() has:\r\n```\r\nstep = size // num_slice\r\n\r\n# If size < num_slice, make fewer slices\r\nif not even_split and size < num_slice:\r\n        step = 1\r\n        num_slice = size\r\n\r\nif batch_axis == 0:\r\n        slices = [data[i*step:(i+1)*step] if i < num_slice - 1 else data[i*step:size]\r\n                  for i in range(num_slice)]\r\n```\r\n\r\nConsidering an example:\r\nwe have a tensor of shape (31, *), and we want to split it into 8 slices. According to the function, step will be (31 // 8 = 3), so that the tensor will be split into 8 tensors of size [3, 3 ,3 ,3 ,3 ,3, 3, 10], in which the last tensor is extremely large. A better result could be [4, 4, 4, 4, 4, 4, 4, 3]\r\n\r\nIn many cases, we will have a batch size for model, for example, 32, and we wish each gpu to have a tensor of size 4. But within bucket sampler or in the last batch, it could be smaller, as exampled above, 31, then a tensor of size 10 can be to large in this case.\r\n\r\nSo I suggest to have step_size = ceil(size / num_slice), then the last slice will always be smaller. \r\n\r\n\r\n### Error Message\r\n(Paste the complete error message, including stack trace.)\r\n\r\n## To Reproduce\r\n(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\r\n\r\n### Steps to reproduce\r\n(Paste the commands you ran that produced the error.)\r\n\r\n1.\r\n2.\r\n\r\n## What have you tried to solve it?\r\n\r\n1.\r\n2.\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1060", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1060/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1060/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1060/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1060", "id": 539488772, "node_id": "MDU6SXNzdWU1Mzk0ODg3NzI=", "number": 1060, "title": "Cannot apply parameter sharing on WeightDropParameter", "user": {"login": "liuzh91", "id": 12567586, "node_id": "MDQ6VXNlcjEyNTY3NTg2", "avatar_url": "https://avatars3.githubusercontent.com/u/12567586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liuzh91", "html_url": "https://github.com/liuzh91", "followers_url": "https://api.github.com/users/liuzh91/followers", "following_url": "https://api.github.com/users/liuzh91/following{/other_user}", "gists_url": "https://api.github.com/users/liuzh91/gists{/gist_id}", "starred_url": "https://api.github.com/users/liuzh91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liuzh91/subscriptions", "organizations_url": "https://api.github.com/users/liuzh91/orgs", "repos_url": "https://api.github.com/users/liuzh91/repos", "events_url": "https://api.github.com/users/liuzh91/events{/privacy}", "received_events_url": "https://api.github.com/users/liuzh91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2019-12-18T06:53:18Z", "updated_at": "2020-01-03T08:19:03Z", "closed_at": "2020-01-03T08:19:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nParameter sharing of `WeightDropParameter` is broken. I apply weight sharing between `AWDRNN` and `train.AWDRNN` as followed:\r\n\r\n```python\r\nmodel = nlp.model.train.AWDRNN(args.model, len(vocab), args.emsize, args.nhid, args.nlayers,\r\n                               args.tied, args.dropout, args.weight_dropout,\r\n                               args.dropout_h, args.dropout_i, args.dropout_e)\r\nmodel_eval = nlp.model.AWDRNN(args.model, len(vocab), args.emsize, args.nhid, args.nlayers,\r\n                              args.tied, args.dropout, args.weight_dropout,\r\n                              args.dropout_h, args.dropout_i, args.dropout_e,\r\n                              params=model.collect_params())\r\n\r\nmodel.initialize(mx.init.Xavier(), ctx=context)\r\n\r\nmodel.hybridize(static_alloc=True)\r\n\r\nprint(model)\r\n\r\ndef check_initialized(net):\r\n    params = net.collect_params()\r\n    for param in params:\r\n        try:\r\n            params[param].list_ctx()\r\n        except RuntimeError:\r\n            return False\r\n    return True\r\n\r\nprint(check_initialized(model))\r\nprint(check_initialized(model_eval))\r\n```\r\n\r\n### Log Message\r\nAfter I ran the above code, I got the following message:\r\n```python\r\nTrue\r\nFalse\r\n```\r\nIt appeared that `model_eval` is not properly initialized. After an inspection, we found it is the `WeightDropParameter` that not initialized.\r\n```\r\n(Pdb) model_eval.collect_params()[\"awdrnn0_hybridsequential0_embedding0_weight\"].data()\r\n*** RuntimeError: Parameter 'awdrnn0_hybridsequential0_embedding0_weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks\r\n(Pdb) model_eval.collect_params()[\"awdrnn0_hybridsequential0_embedding0_weight\"]\r\nWeightDropParameter awdrnn0_hybridsequential0_embedding0_weight (shape=(33278, 400), dtype=float32, rate=0.1, mode=training)\r\n```\r\n\r\n## Environment\r\nMy environment specs:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n---------Python Info----------\r\nVersion      : 3.6.6\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Jun 28 2018 17:14:51')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.2.3\r\nDirectory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.6.0\r\nDirectory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet\r\nNum GPUs     : 1\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\nPlatform     : Linux-4.15.0-1056-aws-x86_64-with-debian-buster-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-23-26\r\nrelease      : 4.15.0-1056-aws\r\nversion      : #58-Ubuntu SMP Tue Nov 26 15:14:34 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              8\r\nOn-line CPU(s) list: 0-7\r\nThread(s) per core:  2\r\nCore(s) per socket:  4\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               79\r\nModel name:          Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:            1\r\nCPU MHz:             2704.026\r\nCPU max MHz:         3000.0000\r\nCPU min MHz:         1200.0000\r\nBogoMIPS:            4600.12\r\nHypervisor vendor:   Xen\r\nVirtualization type: full\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            46080K\r\nNUMA node0 CPU(s):   0-7\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1055", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1055/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1055/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1055/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1055", "id": 538320157, "node_id": "MDU6SXNzdWU1MzgzMjAxNTc=", "number": 1055, "title": "Unicode comma error", "user": {"login": "liuzh91", "id": 12567586, "node_id": "MDQ6VXNlcjEyNTY3NTg2", "avatar_url": "https://avatars3.githubusercontent.com/u/12567586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liuzh91", "html_url": "https://github.com/liuzh91", "followers_url": "https://api.github.com/users/liuzh91/followers", "following_url": "https://api.github.com/users/liuzh91/following{/other_user}", "gists_url": "https://api.github.com/users/liuzh91/gists{/gist_id}", "starred_url": "https://api.github.com/users/liuzh91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liuzh91/subscriptions", "organizations_url": "https://api.github.com/users/liuzh91/orgs", "repos_url": "https://api.github.com/users/liuzh91/repos", "events_url": "https://api.github.com/users/liuzh91/events{/privacy}", "received_events_url": "https://api.github.com/users/liuzh91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-12-16T10:26:48Z", "updated_at": "2019-12-17T12:10:50Z", "closed_at": "2019-12-17T12:10:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nWhen running the `word_language_model.py` script, sometimes I ran into the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"word_language_model.py\", line 468, in <module>\r\n    train()\r\n  File \"word_language_model.py\", line 426, in train\r\n    trainer.learning_rate))\r\nUnicodeEncodeError: 'ascii' codec can't encode character '\\uff0c' in position 62: ordinal not in range(128)\r\n```\r\nThe error is caused by the following print statement:\r\n\r\n```\r\nprint('[Epoch %d] time cost %.2fs, valid loss %.2f, valid ppl %.2f\uff0clr %.2f' % (\r\n            epoch, time.time() - start_epoch_time, val_L, math.exp(val_L),\r\n            trainer.learning_rate))\r\n```\r\n\r\nAfter a careful inspection, we found the third comma is a chinese comma `\uff0c` in  `valid ppl %.2f\uff0c`.  To avoid potential running error, this comma needed to be replaced with an ASCII comma `,`.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1040", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1040/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1040/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1040/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1040", "id": 536153608, "node_id": "MDU6SXNzdWU1MzYxNTM2MDg=", "number": 1040, "title": "example code for learning a vocabulary ", "user": {"login": "lilongyue", "id": 3581832, "node_id": "MDQ6VXNlcjM1ODE4MzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3581832?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lilongyue", "html_url": "https://github.com/lilongyue", "followers_url": "https://api.github.com/users/lilongyue/followers", "following_url": "https://api.github.com/users/lilongyue/following{/other_user}", "gists_url": "https://api.github.com/users/lilongyue/gists{/gist_id}", "starred_url": "https://api.github.com/users/lilongyue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lilongyue/subscriptions", "organizations_url": "https://api.github.com/users/lilongyue/orgs", "repos_url": "https://api.github.com/users/lilongyue/repos", "events_url": "https://api.github.com/users/lilongyue/events{/privacy}", "received_events_url": "https://api.github.com/users/lilongyue/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-11T05:36:14Z", "updated_at": "2019-12-14T12:27:35Z", "closed_at": "2019-12-14T12:27:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nbert vocabulary tokens are directly downloaded but the code to generate a new vocabulary from plain text is not give.\r\n\r\nThree ways are now available according to google team. [1]\r\n1.Google's SentencePiece library\r\n2.tensor2tensor's WordPiece generation script\r\n3.Rico Sennrich's Byte Pair Encoding library\r\n\r\nThere is a tutorial on how to generate a bert-style vocabulary from SentencePiece lib. [2]\r\n\r\n\r\n\r\n## References\r\n[1]https://github.com/google-research/bert \r\n[2https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379]\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1038", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1038/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1038/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1038/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1038", "id": 534582575, "node_id": "MDU6SXNzdWU1MzQ1ODI1NzU=", "number": 1038, "title": "Transformer en-de pretrained models are outdated", "user": {"login": "JulianSlzr", "id": 4734836, "node_id": "MDQ6VXNlcjQ3MzQ4MzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/4734836?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JulianSlzr", "html_url": "https://github.com/JulianSlzr", "followers_url": "https://api.github.com/users/JulianSlzr/followers", "following_url": "https://api.github.com/users/JulianSlzr/following{/other_user}", "gists_url": "https://api.github.com/users/JulianSlzr/gists{/gist_id}", "starred_url": "https://api.github.com/users/JulianSlzr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JulianSlzr/subscriptions", "organizations_url": "https://api.github.com/users/JulianSlzr/orgs", "repos_url": "https://api.github.com/users/JulianSlzr/repos", "events_url": "https://api.github.com/users/JulianSlzr/events{/privacy}", "received_events_url": "https://api.github.com/users/JulianSlzr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 18, "created_at": "2019-12-08T18:43:14Z", "updated_at": "2020-01-15T17:59:25Z", "closed_at": "2020-01-15T17:59:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n[Recent changes to the API](https://github.com/dmlc/gluon-nlp/commit/57a45aaf7e82a826e1bffb133c328f913844bd4c) (@leezu) have made the Transformer en-de pretrained models out of date. The models I tried were:\r\n- The one listed in `inference_transformer.py`: https://github.com/dmlc/gluon-nlp/blame/3ce9995329fb0d18787019df541d4f229d7c9ded/scripts/machine_translation/inference_transformer.py#L169\r\n- The one listed in the Model Zoo: `https://gluon-nlp.mxnet.io/master/model_zoo/machine_translation/index.html`\r\n\r\n(also these models are not the same!)\r\n\r\n## To Reproduce\r\nDownload and load either .params file, and load via `--model_parameter` in `inference_transformer.py`\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1036", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1036/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1036/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1036/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1036", "id": 532611096, "node_id": "MDU6SXNzdWU1MzI2MTEwOTY=", "number": 1036, "title": "ERROR: Cannot determine archive format of /tmp/pip-req-build-layq6u4w", "user": {"login": "m0dulo", "id": 17985352, "node_id": "MDQ6VXNlcjE3OTg1MzUy", "avatar_url": "https://avatars0.githubusercontent.com/u/17985352?v=4", "gravatar_id": "", "url": "https://api.github.com/users/m0dulo", "html_url": "https://github.com/m0dulo", "followers_url": "https://api.github.com/users/m0dulo/followers", "following_url": "https://api.github.com/users/m0dulo/following{/other_user}", "gists_url": "https://api.github.com/users/m0dulo/gists{/gist_id}", "starred_url": "https://api.github.com/users/m0dulo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/m0dulo/subscriptions", "organizations_url": "https://api.github.com/users/m0dulo/orgs", "repos_url": "https://api.github.com/users/m0dulo/repos", "events_url": "https://api.github.com/users/m0dulo/events{/privacy}", "received_events_url": "https://api.github.com/users/m0dulo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-04T11:02:56Z", "updated_at": "2019-12-06T08:04:15Z", "closed_at": "2019-12-04T12:05:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "~/anaconda3/bin$ ./pip install gluonnlp https://pypi.tuna.tsinghua.edu.cn/simple\r\nCollecting https://pypi.tuna.tsinghua.edu.cn/simple\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/simple\r\n  **ERROR: Cannot unpack file /tmp/pip-unpack-izb3uygg/simple (downloaded from /tmp/pip-req-build-layq6u4w, content-type: text/html; charset=utf-8); cannot detect archive format\r\nERROR: Cannot determine archive format of /tmp/pip-req-build-layq6u4w**\r\nMxNet Version:1.5.0\r\nPython Version:3.7.4", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1034", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1034/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1034/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1034/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1034", "id": 531640450, "node_id": "MDU6SXNzdWU1MzE2NDA0NTA=", "number": 1034, "title": "Error when using fp16 trainer", "user": {"login": "rich-junwang", "id": 17483734, "node_id": "MDQ6VXNlcjE3NDgzNzM0", "avatar_url": "https://avatars1.githubusercontent.com/u/17483734?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rich-junwang", "html_url": "https://github.com/rich-junwang", "followers_url": "https://api.github.com/users/rich-junwang/followers", "following_url": "https://api.github.com/users/rich-junwang/following{/other_user}", "gists_url": "https://api.github.com/users/rich-junwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/rich-junwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rich-junwang/subscriptions", "organizations_url": "https://api.github.com/users/rich-junwang/orgs", "repos_url": "https://api.github.com/users/rich-junwang/repos", "events_url": "https://api.github.com/users/rich-junwang/events{/privacy}", "received_events_url": "https://api.github.com/users/rich-junwang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-12-03T01:04:51Z", "updated_at": "2019-12-05T02:48:29Z", "closed_at": "2019-12-05T02:48:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI use fp16 trainer in fp16_utils.py to train model. I got the following error. \r\n@eric-haibin-lin \r\n\r\n\r\n### Error Message\r\n  File \"/home/ec2-user/project/src/deep/utils/fp16_utils.py\", line 179, in step\r\n    overflow = self._scaler.has_overflow(self.fp32_trainer._params)\r\n  File \"/home/ec2-user/project/src/deep/utils/fp16_utils.py\", line 195, in has_overflow\r\n    is_not_finite += mx.nd.contrib.isnan(grad).sum()\r\n  File \"/apollo/env/project/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\", line 217, in __iadd__\r\n    return op.broadcast_add(self, other, out=self)\r\n  File \"<string>\", line 56, in broadcast_add\r\n  File \"/apollo/env/project/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\", line 92, in _imperative_invoke\r\n    ctypes.byref(out_stypes)))\r\n  File \"/apollo/env/project/lib/python3.6/site-packages/mxnet/base.py\", line 253, in check_call\r\nraise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [22:57:10] /opt/brazil-pkg-cache/packages/DeepMXNet/DeepMXNet-1.5.x.1353.0/AL2012/generic-flavor/src/src/io/../operator/elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)): Incompatible attr in node  at 1-th input: expected float16, got float32\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1019", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1019/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1019/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1019/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1019", "id": 527818455, "node_id": "MDU6SXNzdWU1Mjc4MTg0NTU=", "number": 1019, "title": "New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-11-25T03:19:51Z", "updated_at": "2020-01-16T22:51:05Z", "closed_at": "2020-01-16T22:51:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`[2019-11-25T02:55:07.913Z] /var/lib/jenkins/workspace/gluon-nlp-cpu-py3/conda/cpu/py3-master/lib/python3.5/site-packages/mxnet/optimizer/optimizer.py:166: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1015", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1015/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1015/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1015/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1015", "id": 525383063, "node_id": "MDU6SXNzdWU1MjUzODMwNjM=", "number": 1015, "title": "prev_len in gpt.py", "user": {"login": "carter54", "id": 26741594, "node_id": "MDQ6VXNlcjI2NzQxNTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/26741594?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carter54", "html_url": "https://github.com/carter54", "followers_url": "https://api.github.com/users/carter54/followers", "following_url": "https://api.github.com/users/carter54/following{/other_user}", "gists_url": "https://api.github.com/users/carter54/gists{/gist_id}", "starred_url": "https://api.github.com/users/carter54/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carter54/subscriptions", "organizations_url": "https://api.github.com/users/carter54/orgs", "repos_url": "https://api.github.com/users/carter54/repos", "events_url": "https://api.github.com/users/carter54/events{/privacy}", "received_events_url": "https://api.github.com/users/carter54/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-11-20T02:31:59Z", "updated_at": "2019-11-20T08:20:28Z", "closed_at": "2019-11-20T08:20:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nthe gpt code in \r\nhttps://github.com/dmlc/gluon-nlp/blob/5e11334f5c00fd2875ab75c670b2595c560c30fc/scripts/text_generation/model/gpt.py#L258\r\nseems to have a mistake.\r\n\r\nI might be wrong, but I think the code `prev_len = states[0].shape[1]` means to return the length of previous key/value matrix (or the previous input tokens) . However it returns the number of multi-head (12 for the 124M gpt2 model).\r\n\r\n### Error Message\r\nNA\r\n\r\n## To Reproduce\r\nrun scripts/text_generation/sequence_sampling.py script and print the output of `prev_len = states[0].shape[1]` at line 258 in scripts/text_generation/model/gpt.py.\r\n\r\n## What have you tried to solve it?\r\n1. change to `prev_len = states[0].shape[2]` \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1002", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1002/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1002/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/1002/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/1002", "id": 521941994, "node_id": "MDU6SXNzdWU1MjE5NDE5OTQ=", "number": 1002, "title": "ImportError: cannot import name 'Seq2SeqOneStepDecoder'", "user": {"login": "yljylj", "id": 18459082, "node_id": "MDQ6VXNlcjE4NDU5MDgy", "avatar_url": "https://avatars1.githubusercontent.com/u/18459082?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yljylj", "html_url": "https://github.com/yljylj", "followers_url": "https://api.github.com/users/yljylj/followers", "following_url": "https://api.github.com/users/yljylj/following{/other_user}", "gists_url": "https://api.github.com/users/yljylj/gists{/gist_id}", "starred_url": "https://api.github.com/users/yljylj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yljylj/subscriptions", "organizations_url": "https://api.github.com/users/yljylj/orgs", "repos_url": "https://api.github.com/users/yljylj/repos", "events_url": "https://api.github.com/users/yljylj/events{/privacy}", "received_events_url": "https://api.github.com/users/yljylj/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-13T03:49:41Z", "updated_at": "2019-11-13T08:03:52Z", "closed_at": "2019-11-13T06:21:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nWhen I tried to run the train_gnmt.py, it got an error. I tried different version of gluonnlp including 0.6.0, 0.7.0, 0.7.1, 0.8.0 but it always got the same error.\r\n\r\n### Error Message\r\nTraceback (most recent call last):\r\n  File \"train_gnmt.py\", line 48, in <module>\r\n    from gnmt import get_gnmt_encoder_decoder\r\n  File \"/home/lujiayin/gluon-nlp/scripts/machine_translation/gnmt.py\", line 24, in <module>\r\n    from gluonnlp.model.seq2seq_encoder_decoder import Seq2SeqEncoder, Seq2SeqDecoder, \\\r\nImportError: cannot import name 'Seq2SeqOneStepDecoder'\r\n\r\n\r\n## To Reproduce\r\npython gluon-nlp/scripts/machine_translation/train_gnmt.py\r\n\r\n\r\n## What have you tried to solve it?\r\n\r\n1. I tried to use different version of gluonnlp.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/996", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/996/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/996/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/996/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/996", "id": 516041754, "node_id": "MDU6SXNzdWU1MTYwNDE3NTQ=", "number": 996, "title": "How does weight tying work between src_embed and tgt_embed in NMTModel?", "user": {"login": "zeeshansayyed", "id": 543495, "node_id": "MDQ6VXNlcjU0MzQ5NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/543495?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zeeshansayyed", "html_url": "https://github.com/zeeshansayyed", "followers_url": "https://api.github.com/users/zeeshansayyed/followers", "following_url": "https://api.github.com/users/zeeshansayyed/following{/other_user}", "gists_url": "https://api.github.com/users/zeeshansayyed/gists{/gist_id}", "starred_url": "https://api.github.com/users/zeeshansayyed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zeeshansayyed/subscriptions", "organizations_url": "https://api.github.com/users/zeeshansayyed/orgs", "repos_url": "https://api.github.com/users/zeeshansayyed/repos", "events_url": "https://api.github.com/users/zeeshansayyed/events{/privacy}", "received_events_url": "https://api.github.com/users/zeeshansayyed/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-01T10:48:20Z", "updated_at": "2019-11-08T15:44:47Z", "closed_at": "2019-11-02T00:37:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I have a question regarding weight tying in the encoder and decoder embedding matrix of the NMTModel. Consider [these lines](https://github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/model/translation.py#L84-L130) of the NMTModel class.\r\n\r\nAs has been described in Issue [#7785](https://github.com/apache/incubator-mxnet/issues/7785) of mxnet repo and [this section](https://d2l.ai/chapter_deep-learning-computation/parameters.html#tied-parameters) in d2l.ai, we usually do it by calling the `params` argument of the layer new layer and pass the params of the layer from which we want to tie.\r\n\r\nBut in the NMTModel class referenced above, we are simply assigning the references in line 98 and 101 as `self.src_embed = src_embed` and `self.tgt_embed = self.src_embed`.\r\n\r\n_Is this also a valid way of tying weights?_\r\n\r\nNote: I have also opened an [issue](https://github.com/apache/incubator-mxnet/issues/16684) in the mxnet repo since I didn't know which was the right place to ask. I will close the one which is not needed.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/994", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/994/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/994/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/994/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/994", "id": 514127287, "node_id": "MDU6SXNzdWU1MTQxMjcyODc=", "number": 994, "title": "Support Python 3.5", "user": {"login": "sxjscience", "id": 5178350, "node_id": "MDQ6VXNlcjUxNzgzNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5178350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sxjscience", "html_url": "https://github.com/sxjscience", "followers_url": "https://api.github.com/users/sxjscience/followers", "following_url": "https://api.github.com/users/sxjscience/following{/other_user}", "gists_url": "https://api.github.com/users/sxjscience/gists{/gist_id}", "starred_url": "https://api.github.com/users/sxjscience/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sxjscience/subscriptions", "organizations_url": "https://api.github.com/users/sxjscience/orgs", "repos_url": "https://api.github.com/users/sxjscience/repos", "events_url": "https://api.github.com/users/sxjscience/events{/privacy}", "received_events_url": "https://api.github.com/users/sxjscience/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 22, "created_at": "2019-10-29T18:20:52Z", "updated_at": "2019-11-15T23:39:56Z", "closed_at": "2019-11-15T23:39:56Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We no longer support python 3.5\r\n\r\nhttps://github.com/dmlc/gluon-nlp/blob/bfa5503e81ae53d26b9f202bce4fedcf09e47db4/setup.py#L35-L40 .\r\n\r\nHowever, the default python3 in Ubuntu 16.04 still uses 3.5 and we should not drop the support.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/993", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/993/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/993/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/993/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/993", "id": 513928478, "node_id": "MDU6SXNzdWU1MTM5Mjg0Nzg=", "number": 993, "title": "Export for GPT-2", "user": {"login": "gigasquid", "id": 340299, "node_id": "MDQ6VXNlcjM0MDI5OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/340299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gigasquid", "html_url": "https://github.com/gigasquid", "followers_url": "https://api.github.com/users/gigasquid/followers", "following_url": "https://api.github.com/users/gigasquid/following{/other_user}", "gists_url": "https://api.github.com/users/gigasquid/gists{/gist_id}", "starred_url": "https://api.github.com/users/gigasquid/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gigasquid/subscriptions", "organizations_url": "https://api.github.com/users/gigasquid/orgs", "repos_url": "https://api.github.com/users/gigasquid/repos", "events_url": "https://api.github.com/users/gigasquid/events{/privacy}", "received_events_url": "https://api.github.com/users/gigasquid/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-10-29T13:45:46Z", "updated_at": "2019-11-20T08:20:28Z", "closed_at": "2019-11-20T08:20:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nI would like to be able to to export the GPT-2 model for text generation into MXNet Clojure. Would the same approach with the BERT export script work? https://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/export.py\r\n\r\nLooking for the best way to approach it - happy to help with this issue if I'm able.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/992", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/992/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/992/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/992/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/992", "id": 513616463, "node_id": "MDU6SXNzdWU1MTM2MTY0NjM=", "number": 992, "title": "[Inconsistency] Non-deterministic behavior of pre-trained BERT within mx.autograd.record() after calling uuid.uuid1()", "user": {"login": "AaronYALai", "id": 14147661, "node_id": "MDQ6VXNlcjE0MTQ3NjYx", "avatar_url": "https://avatars1.githubusercontent.com/u/14147661?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AaronYALai", "html_url": "https://github.com/AaronYALai", "followers_url": "https://api.github.com/users/AaronYALai/followers", "following_url": "https://api.github.com/users/AaronYALai/following{/other_user}", "gists_url": "https://api.github.com/users/AaronYALai/gists{/gist_id}", "starred_url": "https://api.github.com/users/AaronYALai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AaronYALai/subscriptions", "organizations_url": "https://api.github.com/users/AaronYALai/orgs", "repos_url": "https://api.github.com/users/AaronYALai/repos", "events_url": "https://api.github.com/users/AaronYALai/events{/privacy}", "received_events_url": "https://api.github.com/users/AaronYALai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-10-28T23:46:58Z", "updated_at": "2019-11-13T02:23:40Z", "closed_at": "2019-11-13T02:23:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "Sample snippets to reproduce the inconsistency issue:\r\n\r\n```\r\nimport random\r\nimport mxnet as mx\r\nimport numpy as np\r\n\r\nimport gluonnlp as nlp\r\nimport uuid\r\n\r\n# mx.__version__ '1.5.0' (mxnet-cu100mkl)\r\n# np.__version__ '1.17.3'\r\n# nlp.__version__ '0.8.1'\r\n# environment: source activate mxnet_p36 (Amazon Deep Learning AMI)\r\n# machine: EC2 p3.8xl\r\n\r\n\r\ndef run_bert(context=[mx.gpu()]):\r\n    seed = 0\r\n    mx.random.seed(seed)\r\n    random.seed(seed)\r\n    np.random.seed(seed)\r\n\r\n    # Execute this line makes BERT non-deterministic inside mx.autograd.record()\r\n    # uid = uuid.uuid1()\r\n\r\n    bert_model, bert_vocab = nlp.model.get_model(\r\n        name='bert_12_768_12',\r\n        dataset_name='book_corpus_wiki_en_uncased',\r\n        pretrained=True,\r\n        ctx=context,\r\n        use_pooler=True,\r\n        use_decoder=False,\r\n        use_classifier=False,\r\n        dropout=0.1,\r\n        embed_dropout=0.1)\r\n\r\n    # sample inputs\r\n    ti = mx.nd.array([[2, 22100, 2080, 2629, 2072, 2475, 2912, 7685, 4160, 2078,\r\n                       2629, 4430, 2581, 6895,  3501, 2546, 2629, 2480, 17299, 3],\r\n                      [2, 2064, 1045, 2689, 2000, 2151, 12485, 1029, 2835, 1999,\r\n                       6421, 2575, 2683, 12521, 18139, 2575, 2581, 16068, 2475, 3]],\r\n                     dtype=int, ctx=context[0])\r\n    tt = mx.nd.zeros((2, 20), dtype=int, ctx=context[0])\r\n    vl = mx.nd.array([20, 20], ctx=context[0])\r\n\r\n    # BERT forward, outside and inside autograd.record()\r\n    out1 = [a.sum().asscalar() for a in bert_model(ti, tt, vl)]\r\n\r\n    with mx.autograd.record():\r\n        # Inconsistent if call \"uuid.uuid1()\"\r\n        out2 = [a.sum().asscalar() for a in bert_model(ti, tt, vl)]\r\n\r\n    print('Outside autograd:', out1)\r\n    print('Inside autograd:', out2)\r\n\r\n\r\nif __name__ == '__main__':\r\n    run_bert()\r\n```\r\n\r\nOnly when un-commenting and executing \"uuid.uuid1()\", the \"out2\" will have different values when you run the script again and again.\r\n\r\nSuspect the it messed up with internal states used by gluonnlp BERT implementation.\r\n\r\nThanks in advance for taking care of this issue!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/990", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/990/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/990/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/990/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/990", "id": 513073018, "node_id": "MDU6SXNzdWU1MTMwNzMwMTg=", "number": 990, "title": "Consider providing a BERT weight download link?", "user": {"login": "fierceX", "id": 13912058, "node_id": "MDQ6VXNlcjEzOTEyMDU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13912058?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fierceX", "html_url": "https://github.com/fierceX", "followers_url": "https://api.github.com/users/fierceX/followers", "following_url": "https://api.github.com/users/fierceX/following{/other_user}", "gists_url": "https://api.github.com/users/fierceX/gists{/gist_id}", "starred_url": "https://api.github.com/users/fierceX/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fierceX/subscriptions", "organizations_url": "https://api.github.com/users/fierceX/orgs", "repos_url": "https://api.github.com/users/fierceX/repos", "events_url": "https://api.github.com/users/fierceX/events{/privacy}", "received_events_url": "https://api.github.com/users/fierceX/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 890393504, "node_id": "MDU6TGFiZWw4OTAzOTM1MDQ=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/help%20wanted", "name": "help wanted", "color": "b0f22e", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-10-28T03:07:45Z", "updated_at": "2019-12-18T23:30:14Z", "closed_at": "2019-12-18T23:30:14Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Now the BERT weight is downloaded via gluonnlp, but in some cases the network may not be too good or the server does not have an external network. This requires running gluonnlp to download the BERT weight, which is a bit inconvenient, can provide a BERT weight download link, or more Multiple models and dataset download pages, you can download the required weights and datasets without running gluonnlp\r\n@dmlc/gluon-nlp-team \r\n\r\n## References\r\n- list reference and related literature\r\n- list known implementations\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/984", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/984/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/984/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/984/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/984", "id": 511133115, "node_id": "MDU6SXNzdWU1MTExMzMxMTU=", "number": 984, "title": "BERT tutorial failed", "user": {"login": "zburning", "id": 26197318, "node_id": "MDQ6VXNlcjI2MTk3MzE4", "avatar_url": "https://avatars1.githubusercontent.com/u/26197318?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zburning", "html_url": "https://github.com/zburning", "followers_url": "https://api.github.com/users/zburning/followers", "following_url": "https://api.github.com/users/zburning/following{/other_user}", "gists_url": "https://api.github.com/users/zburning/gists{/gist_id}", "starred_url": "https://api.github.com/users/zburning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zburning/subscriptions", "organizations_url": "https://api.github.com/users/zburning/orgs", "repos_url": "https://api.github.com/users/zburning/repos", "events_url": "https://api.github.com/users/zburning/events{/privacy}", "received_events_url": "https://api.github.com/users/zburning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-23T07:32:36Z", "updated_at": "2019-11-30T16:17:42Z", "closed_at": "2019-11-30T16:17:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nI was trying to go through the BERT tutorial on [http://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html](http://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html)and got error in the following code.\r\nfor epoch_id in range(num_epochs):\r\n    metric.reset()\r\n    step_loss = 0\r\n    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(bert_dataloader):\r\n        with mx.autograd.record():\r\n            # Load the data to the GPU\r\n            token_ids = token_ids.as_in_context(ctx)\r\n            valid_length = valid_length.as_in_context(ctx)\r\n            segment_ids = segment_ids.as_in_context(ctx)\r\n            label = label.as_in_context(ctx)\r\n            # Forward computation\r\n            out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\r\n            ls = loss_function(out, label).mean()\r\n        # And backwards computation\r\n        ls.backward()\r\n\r\n\r\n\r\n### Error Message\r\nTraceback (most recent call last):\r\n  File \"/Users/zechenw/PycharmProjects/bert_playground/playground.py\", line 104, in <module>\r\n    out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/gluonnlp/model/bert.py\", line 635, in __call__\r\n    return super(BERTClassifier, self).__call__(inputs, token_types, valid_length)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 548, in __call__\r\n    out = self.forward(*args)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 915, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 805, in _call_cached_op\r\n    self._build_cache(*args)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 757, in _build_cache\r\n    data, out = self._get_graph(*args)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 749, in _get_graph\r\n    out = self.hybrid_forward(symbol, *grouped_inputs, **params)  # pylint: disable=no-value-for-parameter\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/gluonnlp/model/bert.py\", line 656, in hybrid_forward\r\n    _, pooler_out = self.bert(inputs, token_types, valid_length)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/gluonnlp/model/bert.py\", line 425, in __call__\r\n    valid_length, masked_positions)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 548, in __call__\r\n    out = self.forward(*args)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 932, in forward\r\n    return self.hybrid_forward(symbol, x, *args, **params)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/gluonnlp/model/bert.py\", line 434, in hybrid_forward\r\n    seq_out, attention_out = self._encode_sequence(inputs, token_types, valid_length)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/gluonnlp/model/bert.py\", line 470, in _encode_sequence\r\n    outputs, additional_outputs = self.encoder(embedding, valid_length=valid_length)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/gluonnlp/model/transformer.py\", line 440, in __call__\r\n    return super(BaseTransformerEncoder, self).__call__(inputs, states, valid_length)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/gluonnlp/model/seq2seq_encoder_decoder.py\", line 149, in __call__\r\n    return super(Seq2SeqEncoder, self).__call__(inputs, valid_length, states)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 548, in __call__\r\n    out = self.forward(*args)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 932, in forward\r\n    return self.hybrid_forward(symbol, x, *args, **params)\r\n  File \"/opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/gluonnlp/model/transformer.py\", line 479, in hybrid_forward\r\n    steps = F.contrib.arange_like(inputs, axis=1)\r\nAttributeError: module 'mxnet.symbol.contrib' has no attribute 'arange_like'\r\n\r\n\r\n\r\n## To Reproduce\r\n[http://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html](http://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html)\r\n\r\n## What have you tried to solve it?\r\nI'm using gluonnlp installed from github.\r\nI checked mxnet.symbol.contrib and mxnet.symbol.gen_contrib, but did not find arrage_like(). \r\n\r\n## Environment\r\n\r\n----------Python Info----------\r\nVersion      : 3.7.4\r\nCompiler     : Clang 4.0.1 (tags/RELEASE_401/final)\r\nBuild        : ('default', 'Aug 13 2019 15:17:50')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.3.1\r\nDirectory    : /opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.1\r\nDirectory    : /opt/anaconda3/envs/mxnet_15/lib/python3.7/site-packages/mxnet\r\nNum GPUs     : 0\r\nCommit Hash   : c9818480680f84daa6e281a974ab263691302ba8\r\n----------System Info----------\r\nPlatform     : Darwin-18.6.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : a483e7462a21.ant.amazon.com\r\nrelease      : 18.6.0\r\nversion      : Darwin Kernel Version 18.6.0: Sun Apr 28 18:06:45 PDT 2019; root:xnu-4903.261.4~6/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb'machdep.cpu.brand_string: Intel(R) Core(TM) i7-8557U CPU @ 1.70GHz'\r\nb'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'\r\nb'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 AVX2 BMI2 INVPCID SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT TSXFA IBRS STIBP L1DF SSBD'\r\nb'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0009 sec, LOAD: 1.1944 sec.\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0006 sec, LOAD: 1.1631 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0008 sec, LOAD: 0.3726 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.0008 sec, LOAD: 0.3690 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0012 sec, LOAD: 0.3752 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0017 sec, LOAD: 0.7922 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.1924 sec, LOAD: 3.0321 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0005 sec, LOAD: 0.7737 sec.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/981", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/981/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/981/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/981/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/981", "id": 510213605, "node_id": "MDU6SXNzdWU1MTAyMTM2MDU=", "number": 981, "title": "FastText embeddings not working on MxNET 1.5.1/GluonNLP 0.8.1", "user": {"login": "mohammedkhalilia", "id": 6099774, "node_id": "MDQ6VXNlcjYwOTk3NzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/6099774?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mohammedkhalilia", "html_url": "https://github.com/mohammedkhalilia", "followers_url": "https://api.github.com/users/mohammedkhalilia/followers", "following_url": "https://api.github.com/users/mohammedkhalilia/following{/other_user}", "gists_url": "https://api.github.com/users/mohammedkhalilia/gists{/gist_id}", "starred_url": "https://api.github.com/users/mohammedkhalilia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mohammedkhalilia/subscriptions", "organizations_url": "https://api.github.com/users/mohammedkhalilia/orgs", "repos_url": "https://api.github.com/users/mohammedkhalilia/repos", "events_url": "https://api.github.com/users/mohammedkhalilia/events{/privacy}", "received_events_url": "https://api.github.com/users/mohammedkhalilia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-10-21T19:02:38Z", "updated_at": "2019-10-21T21:21:00Z", "closed_at": "2019-10-21T21:21:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nCalling `gluonnlp.model.train.FasttextEmbeddingModel.load_fasttext_format()` generates an error when using MxNET 1.5.1 and GluonNLP 0.8.1. But the call works when using MxNET 1.4.1 and GluonNLP 0.7.1.\r\n\r\n### Error Message\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/khallia/workspace/CompMedNER/bin/train.py\", line 66, in <module>\r\n    main()\r\n  File \"/home/khallia/workspace/CompMedNER/bin/train.py\", line 38, in main\r\n    Vocab(sentences, wordvectors=config.word_vecs, bert_vocab=config.bert_vocab)\r\n  File \"/home/khallia/workspace/CompMedNER/src/vocab.py\", line 29, in __init__\r\n    Vocab.word = self.create_word_vocab()\r\n  File \"/home/khallia/workspace/CompMedNER/src/vocab.py\", line 120, in create_word_vocab\r\n    model = nlp.model.train.FasttextEmbeddingModel.load_fasttext_format(self.wordvectors)\r\n  File \"/env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/gluonnlp/model/train/embedding.py\", line 278, in load_fasttext_format\r\n    self.weight.set_data(nd.array(matrix))\r\n  File \"/env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/ndarray/utils.py\", line 146, in array\r\n    return _array(source_array, ctx=ctx, dtype=dtype)\r\n  File \"/env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\", line 2505, in array\r\n    arr[:] = source_array\r\n  File \"/env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\", line 449, in __setitem__\r\n    self._set_nd_basic_indexing(key, value)\r\n  File \"/env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\", line 715, in _set_nd_basic_indexing\r\n    self._sync_copyfrom(value)\r\n  File \"/env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\", line 881, in _sync_copyfrom\r\n    ctypes.c_size_t(source_array.size)))\r\n  File \"/env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/base.py\", line 253, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [11:32:50] src/ndarray/ndarray_function.cc:51: Check failed: size == to->Size() (-585876896 vs. 3709090400) : copying size mismatch, from: 18446744071366044032 bytes, to: 14836361600 bytes.\r\nStack trace:\r\n  [bt] (0) /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x4b04cb) [0x7f350d5a34cb]\r\n  [bt] (1) /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x281c85b) [0x7f350f90f85b]\r\n  [bt] (2) /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/libmxnet.so(mxnet::NDArray::SyncCopyFromCPU(void const*, unsigned long) const+0x27c) [0x7f350f89b59c]\r\n  [bt] (3) /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet/libmxnet.so(MXNDArraySyncCopyFromCPU+0x2b) [0x7f350f61790b]\r\n  [bt] (4) /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call_unix64+0x4c) [0x7f354255ee20]\r\n  [bt] (5) /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call+0x2eb) [0x7f354255e88b]\r\n  [bt] (6) /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(_ctypes_callproc+0x49a) [0x7f354255901a]\r\n  [bt] (7) /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(+0x9fcb) [0x7f354254cfcb]\r\n  [bt] (8) /env/mx_1.5.1_gnlp_0.8.1/bin/python3(PyObject_Call+0x47) [0x5c20e7]\r\n\r\n```\r\n## To Reproduce\r\n    import mxnet as mx\r\n    import gluonnlp as nlp\r\n    wordvectors = 'BioWordVec_PubMed_MIMICIII_d200.bin'\r\n    model = nlp.model.train.FasttextEmbeddingModel.load_fasttext_format(wordvectors)\r\n\r\n### Steps to reproduce\r\n1. Download the embeddings from here:\r\n    https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/BioSentVec/BioWordVec_PubMed_MIMICIII_d200.bin\r\n2. Run the code snippet above.\r\n\r\n## Environment\r\n```\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                64\r\nOn-line CPU(s) list:   0-63\r\nThread(s) per core:    2\r\nCore(s) per socket:    16\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2699.984\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.15\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-15,32-47\r\nNUMA node1 CPU(s):     16-31,48-63\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida\r\n----------Python Info----------\r\nVersion      : 3.5.2\r\nCompiler     : GCC 5.4.0 20160609\r\nBuild        : ('default', 'Nov 12 2018 13:43:14')\r\nArch         : ('64bit', 'ELF')\r\n------------Pip Info-----------\r\nVersion      : 19.3\r\nDirectory    : /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.1\r\nDirectory    : /env/mx_1.5.1_gnlp_0.8.1/lib/python3.5/site-packages/mxnet\r\nNum GPUs     : 8\r\nCommit Hash   : c9818480680f84daa6e281a974ab263691302ba8\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1090-aws-x86_64-with-Ubuntu-16.04-xenial\r\nsystem       : Linux\r\nnode         : ip-172-31-30-122\r\nrelease      : 4.4.0-1090-aws\r\nversion      : #101-Ubuntu SMP Fri Aug 2 15:21:01 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0023 sec, LOAD: 0.4338 sec.\r\nTiming for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0919 sec, LOAD: 0.0523 sec.\r\nTiming for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0060 sec, LOAD: 0.0718 sec.\r\nTiming for D2L: http://d2l.ai, DNS: 0.0155 sec, LOAD: 0.0264 sec.\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0003 sec, LOAD: 0.4836 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0024 sec, LOAD: 0.3733 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0127 sec, LOAD: 0.0653 sec.\r\nTiming for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.1836 sec, LOAD: 0.2207 sec.\r\n\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/968", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/968/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/968/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/968/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/968", "id": 505504439, "node_id": "MDU6SXNzdWU1MDU1MDQ0Mzk=", "number": 968, "title": "Print statement in train.language_model", "user": {"login": "sxjscience", "id": 5178350, "node_id": "MDQ6VXNlcjUxNzgzNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5178350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sxjscience", "html_url": "https://github.com/sxjscience", "followers_url": "https://api.github.com/users/sxjscience/followers", "following_url": "https://api.github.com/users/sxjscience/following{/other_user}", "gists_url": "https://api.github.com/users/sxjscience/gists{/gist_id}", "starred_url": "https://api.github.com/users/sxjscience/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sxjscience/subscriptions", "organizations_url": "https://api.github.com/users/sxjscience/orgs", "repos_url": "https://api.github.com/users/sxjscience/repos", "events_url": "https://api.github.com/users/sxjscience/events{/privacy}", "received_events_url": "https://api.github.com/users/sxjscience/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-10T20:52:02Z", "updated_at": "2019-10-11T04:46:05Z", "closed_at": "2019-10-10T23:19:01Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://github.com/dmlc/gluon-nlp/blob/c3cac54083ca0da2faef764a37bb222806133a8b/src/gluonnlp/model/train/language_model.py#L305\r\n\r\nhttps://github.com/dmlc/gluon-nlp/blob/c3cac54083ca0da2faef764a37bb222806133a8b/src/gluonnlp/model/train/language_model.py#L338", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/965", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/965/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/965/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/965/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/965", "id": 504418034, "node_id": "MDU6SXNzdWU1MDQ0MTgwMzQ=", "number": 965, "title": "Chinese Roberta conversion", "user": {"login": "kenjewu", "id": 27672489, "node_id": "MDQ6VXNlcjI3NjcyNDg5", "avatar_url": "https://avatars0.githubusercontent.com/u/27672489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kenjewu", "html_url": "https://github.com/kenjewu", "followers_url": "https://api.github.com/users/kenjewu/followers", "following_url": "https://api.github.com/users/kenjewu/following{/other_user}", "gists_url": "https://api.github.com/users/kenjewu/gists{/gist_id}", "starred_url": "https://api.github.com/users/kenjewu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kenjewu/subscriptions", "organizations_url": "https://api.github.com/users/kenjewu/orgs", "repos_url": "https://api.github.com/users/kenjewu/repos", "events_url": "https://api.github.com/users/kenjewu/events{/privacy}", "received_events_url": "https://api.github.com/users/kenjewu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-10-09T05:07:05Z", "updated_at": "2020-07-14T15:17:22Z", "closed_at": "2020-07-14T15:17:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nProvides Roberta parameters pre-trained by large-scale Chinese corpus.\r\nI plan to convert it from https://github.com/brightmart/roberta_zh\r\n## References\r\n- https://github.com/brightmart/roberta_zh\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/939", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/939/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/939/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/939/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/939", "id": 497403764, "node_id": "MDU6SXNzdWU0OTc0MDM3NjQ=", "number": 939, "title": "Korean BERT pre-trained", "user": {"login": "haven-jeon", "id": 957840, "node_id": "MDQ6VXNlcjk1Nzg0MA==", "avatar_url": "https://avatars2.githubusercontent.com/u/957840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haven-jeon", "html_url": "https://github.com/haven-jeon", "followers_url": "https://api.github.com/users/haven-jeon/followers", "following_url": "https://api.github.com/users/haven-jeon/following{/other_user}", "gists_url": "https://api.github.com/users/haven-jeon/gists{/gist_id}", "starred_url": "https://api.github.com/users/haven-jeon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haven-jeon/subscriptions", "organizations_url": "https://api.github.com/users/haven-jeon/orgs", "repos_url": "https://api.github.com/users/haven-jeon/repos", "events_url": "https://api.github.com/users/haven-jeon/events{/privacy}", "received_events_url": "https://api.github.com/users/haven-jeon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": {"login": "szha", "id": 2626883, "node_id": "MDQ6VXNlcjI2MjY4ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2626883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szha", "html_url": "https://github.com/szha", "followers_url": "https://api.github.com/users/szha/followers", "following_url": "https://api.github.com/users/szha/following{/other_user}", "gists_url": "https://api.github.com/users/szha/gists{/gist_id}", "starred_url": "https://api.github.com/users/szha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szha/subscriptions", "organizations_url": "https://api.github.com/users/szha/orgs", "repos_url": "https://api.github.com/users/szha/repos", "events_url": "https://api.github.com/users/szha/events{/privacy}", "received_events_url": "https://api.github.com/users/szha/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "szha", "id": 2626883, "node_id": "MDQ6VXNlcjI2MjY4ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2626883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szha", "html_url": "https://github.com/szha", "followers_url": "https://api.github.com/users/szha/followers", "following_url": "https://api.github.com/users/szha/following{/other_user}", "gists_url": "https://api.github.com/users/szha/gists{/gist_id}", "starred_url": "https://api.github.com/users/szha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szha/subscriptions", "organizations_url": "https://api.github.com/users/szha/orgs", "repos_url": "https://api.github.com/users/szha/repos", "events_url": "https://api.github.com/users/szha/events{/privacy}", "received_events_url": "https://api.github.com/users/szha/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2019-09-24T01:22:20Z", "updated_at": "2020-01-31T04:08:08Z", "closed_at": "2020-01-31T04:08:08Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Description\r\n- Korean BERT pre-trained cased (KoBERT)\r\n\r\n## References\r\n- https://github.com/SKTBrain/KoBERT\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/924", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/924/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/924/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/924/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/924", "id": 493082161, "node_id": "MDU6SXNzdWU0OTMwODIxNjE=", "number": 924, "title": "AssertionError: masked_positions tensor is required for decoding masked language model", "user": {"login": "xf05888", "id": 33285394, "node_id": "MDQ6VXNlcjMzMjg1Mzk0", "avatar_url": "https://avatars1.githubusercontent.com/u/33285394?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xf05888", "html_url": "https://github.com/xf05888", "followers_url": "https://api.github.com/users/xf05888/followers", "following_url": "https://api.github.com/users/xf05888/following{/other_user}", "gists_url": "https://api.github.com/users/xf05888/gists{/gist_id}", "starred_url": "https://api.github.com/users/xf05888/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xf05888/subscriptions", "organizations_url": "https://api.github.com/users/xf05888/orgs", "repos_url": "https://api.github.com/users/xf05888/repos", "events_url": "https://api.github.com/users/xf05888/events{/privacy}", "received_events_url": "https://api.github.com/users/xf05888/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-09-13T00:07:55Z", "updated_at": "2019-09-13T06:12:38Z", "closed_at": "2019-09-13T06:12:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "### Description\r\nI want to import RoBERTa in GluonNLP\r\n\r\n### Error message for the last command\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/dist-packages/gluonnlp/model/bert.py\", line 604, in __call__\r\n    masked_positions=masked_positions)\r\n  File \"/usr/local/lib/python3.7/dist-packages/gluonnlp/model/bert.py\", line 429, in __call__\r\n    valid_length, masked_positions)\r\n  File \"/usr/local/lib/python3.7/dist-packages/mxnet/gluon/block.py\", line 573, in __call__\r\n    out = self.forward(*args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/mxnet/gluon/block.py\", line 957, in forward\r\n    return self.hybrid_forward(ndarray, x, *args, **params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/gluonnlp/model/bert.py\", line 462, in hybrid_forward\r\n    'masked_positions tensor is required for decoding masked language model'\r\nAssertionError: masked_positions tensor is required for decoding masked language model\r\n```\r\n\r\n### Command I ran from [http://gluon-nlp.mxnet.io/model_zoo/bert/index.html](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html)\r\n```\r\nimport gluonnlp as nlp; import mxnet as mx;\r\nmodel, vocab = nlp.model.get_model('roberta_12_768_12', dataset_name='openwebtext_ccnews_stories_books_cased');\r\ntokenizer = nlp.data.GPT2BPETokenizer();\r\ntext = [vocab.bos_token] + tokenizer('Hello world!') + [vocab.eos_token];\r\nseq_encoding = model(mx.nd.array([vocab[text]]))\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/905", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/905/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/905/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/905/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/905", "id": 486190439, "node_id": "MDU6SXNzdWU0ODYxOTA0Mzk=", "number": 905, "title": "KeyError: '<pad>' if run /scripts/word_embeddings/evaluate_pretrained.py with flag `analog-max-vocab-size`", "user": {"login": "liusy182", "id": 3293332, "node_id": "MDQ6VXNlcjMyOTMzMzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/3293332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liusy182", "html_url": "https://github.com/liusy182", "followers_url": "https://api.github.com/users/liusy182/followers", "following_url": "https://api.github.com/users/liusy182/following{/other_user}", "gists_url": "https://api.github.com/users/liusy182/gists{/gist_id}", "starred_url": "https://api.github.com/users/liusy182/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liusy182/subscriptions", "organizations_url": "https://api.github.com/users/liusy182/orgs", "repos_url": "https://api.github.com/users/liusy182/repos", "events_url": "https://api.github.com/users/liusy182/events{/privacy}", "received_events_url": "https://api.github.com/users/liusy182/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-08-28T06:47:59Z", "updated_at": "2019-09-11T20:52:51Z", "closed_at": "2019-09-11T20:52:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n\r\nrun `/scripts/word_embeddings/evaluate_pretrained.py` with flag `analog-max-vocab-size` throws exception.\r\n\r\n### Error Message\r\n```\r\nTraceback (most recent call last):\r\n  File \"evaluate_pretrained.py\", line 216, in <module>\r\n    vocab.set_embedding(token_embedding_)\r\n  File \"/Users/siyuanl/private/gluon-nlp/src/gluonnlp/vocab/vocab.py\", line 412, in set_embedding\r\n    new_idx_to_vec[1:, col_start:col_end] = embs[self._idx_to_token[1:]]\r\n  File \"/Users/siyuanl/private/gluon-nlp/src/gluonnlp/embedding/token_embedding.py\", line 637, in __getitem__\r\n    indices = [self._token_to_idx[token] for token in tokens]\r\n  File \"/Users/siyuanl/private/gluon-nlp/src/gluonnlp/embedding/token_embedding.py\", line 637, in <listcomp>\r\n    indices = [self._token_to_idx[token] for token in tokens]\r\nKeyError: '<pad>'\r\n```\r\n\r\n## To Reproduce\r\n\r\n```\r\ncd scripts/word_embeddings\r\n\r\npython evaluate_pretrained.py --gpu 0  --embedding-name glove --embedding-source glove.42B.300d --logdir results --analogy-max-vocab-size 300000 --analogy-datasets GoogleAnalogyTestSet BiggerAnalogyTestSet\r\n```\r\n\r\n## What have you tried to solve it?\r\n\r\nIt looks like the reason is because [enforce_max_size](https://github.com/dmlc/gluon-nlp/blob/master/scripts/word_embeddings/evaluate_pretrained.py#L208) trims off certain tokens such as `<pad>` which results to the error above.\r\n\r\nWhat should be the correct way to run this script?\r\n\r\n## Environment\r\n\r\nWe recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\r\n```\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/902", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/902/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/902/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/902/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/902", "id": 486028018, "node_id": "MDU6SXNzdWU0ODYwMjgwMTg=", "number": 902, "title": "Loading BERT external vocab file error", "user": {"login": "mohammedkhalilia", "id": 6099774, "node_id": "MDQ6VXNlcjYwOTk3NzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/6099774?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mohammedkhalilia", "html_url": "https://github.com/mohammedkhalilia", "followers_url": "https://api.github.com/users/mohammedkhalilia/followers", "following_url": "https://api.github.com/users/mohammedkhalilia/following{/other_user}", "gists_url": "https://api.github.com/users/mohammedkhalilia/gists{/gist_id}", "starred_url": "https://api.github.com/users/mohammedkhalilia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mohammedkhalilia/subscriptions", "organizations_url": "https://api.github.com/users/mohammedkhalilia/orgs", "repos_url": "https://api.github.com/users/mohammedkhalilia/repos", "events_url": "https://api.github.com/users/mohammedkhalilia/events{/privacy}", "received_events_url": "https://api.github.com/users/mohammedkhalilia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-08-27T20:51:44Z", "updated_at": "2019-08-28T19:17:04Z", "closed_at": "2019-08-28T11:44:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nWhen calling  [get_model(name, **kwargs)](https://github.com/dmlc/gluon-nlp/blob/ea1ae703afd9c9e59d55718ae32e91e74ce25ef4/src/gluonnlp/model/__init__.py#L99), we can specify either the `--dataset_name`, which will load the vocab for that dataset, or we can pass the `--vocab` for custom BERT vocabulary. An error occurs when calling a BERT model such as `bert_12_768_12` with `--vocab` and without passing `--dataset_name`.\r\n\r\n### Error Message\r\n    Traceback (most recent call last):\r\n      File \"finetune_ner.py\", line 260, in <module>\r\n        main(parse_args())\r\n      File \"finetune_ner.py\", line 121, in main\r\n        bert_model.load_parameters(config.parameters, ctx=ctx, ignore_extra=True)\r\n      File \"/env/mx_1.5_gnlp_0.8/lib/python3.5/site-packages/mxnet/gluon/block.py\", line 410, in load_parameters\r\n        params[name]._load_init(loaded[name], ctx, cast_dtype=cast_dtype, dtype_source=dtype_source)\r\n      File \"/env/mx_1.5_gnlp_0.8/lib/python3.5/site-packages/mxnet/gluon/parameter.py\", line 279, in _load_init\r\n        self.name, str(self.shape), str(data.shape))\r\n    AssertionError: Failed loading Parameter 'bertmodel0_word_embed_embedding0_weight' from saved params: shape incompatible expected (98, 768) vs saved (28996, 768)\r\n\r\nNote that I did make minor modification to finetune_ner.py script, but that is irrelevant. The correct vocabulary size in this example is 28996 and the 98 is the length of the filename passed in the vocab argument in the function [_load_vocab(dataset_name, vocab, root, cls=None)](https://github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/model/utils.py#L265)\r\n\r\n## To Reproduce\r\nTo reproduce, you need to convert a BERT to Gluon. In my case I convereted [Clinical BERT \r\n](https://github.com/EmilyAlsentzer/clinicalBERT) TensorFlow model to Gluon using [convert_tf_model.py](https://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/conversion_tools/convert_tf_model.py). Then try loading a model using [get_model(name, **kwargs)](https://github.com/dmlc/gluon-nlp/blob/ea1ae703afd9c9e59d55718ae32e91e74ce25ef4/src/gluonnlp/model/__init__.py#L99). See instructions below.\r\n\r\n### Steps to reproduce\r\n\r\n1. Download Clinical BERT. [See instructions here](https://github.com/EmilyAlsentzer/clinicalBERT)\r\n2. Convert any of the Clinical BERT models to Gluon using [convert_tf_model.py](https://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/conversion_tools/convert_tf_model.py)\r\n3. Call [get_model(name, **kwargs)](https://github.com/dmlc/gluon-nlp/blob/ea1ae703afd9c9e59d55718ae32e91e74ce25ef4/src/gluonnlp/model/__init__.py#L99) without specifying `--dataset_name` and pass the converted vocabulary using `--vocab` argument.  \r\n\r\n```\r\n    params = {\r\n        'dataset_name': None,\r\n        'vocab': 'path/to/filename.vocab',\r\n        'pretrained': False,\r\n        'ctx': ctx,\r\n        'use_pooler': False,\r\n        'use_decoder': False,\r\n        'use_classifier': False,\r\n        'dropout': 0.1,\r\n        'embed_dropout': 0.1\r\n    }\r\n\r\n    bert_model, text_vocab = gluonnlp.model.get_model('bert_12_768_12', **params)\r\n```\r\n\r\n## What have you tried to solve it?\r\n[_load_vocab(dataset_name, vocab, root, cls=None)](https://github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/model/utils.py#L265) returns the vocab variable (str) if `--dataset_name` is not set, hence the vocab length 98 you see in the error message above. To resolve the issue, I modified the function [_load_vocab(dataset_name, vocab, root, cls=None)](https://github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/model/utils.py#L265) and added the following lines after line [273](https://github.com/dmlc/gluon-nlp/blob/b7332817c77ab40451043fad81f3e91a9bb677a2/src/gluonnlp/model/utils.py#L273)\r\n\r\n    with open(vocab, 'r') as fh:\r\n        vocab = gluonnlp.Vocab().from_json(fh.read())\r\n        return vocab\r\n\r\n\r\n## Environment\r\n```\r\n    Architecture:          x86_64\r\n    CPU op-mode(s):        32-bit, 64-bit\r\n    Byte Order:            Little Endian\r\n    CPU(s):                64\r\n    On-line CPU(s) list:   0-63\r\n    Thread(s) per core:    2\r\n    Core(s) per socket:    16\r\n    Socket(s):             2\r\n    NUMA node(s):          2\r\n    Vendor ID:             GenuineIntel\r\n    CPU family:            6\r\n    Model:                 79\r\n    Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\n    Stepping:              1\r\n    CPU MHz:               2089.316\r\n    CPU max MHz:           3000.0000\r\n    CPU min MHz:           1200.0000\r\n    BogoMIPS:              4600.15\r\n    Hypervisor vendor:     Xen\r\n    Virtualization type:   full\r\n    L1d cache:             32K\r\n    L1i cache:             32K\r\n    L2 cache:              256K\r\n    L3 cache:              46080K\r\n    NUMA node0 CPU(s):     0-15,32-47\r\n    NUMA node1 CPU(s):     16-31,48-63\r\n    Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida\r\n    ----------Python Info----------\r\n    Version      : 3.5.2\r\n    Compiler     : GCC 5.4.0 20160609\r\n    Build        : ('default', 'Nov 12 2018 13:43:14')\r\n    Arch         : ('64bit', 'ELF')\r\n    ------------Pip Info-----------\r\n    Version      : 19.2.2\r\n    Directory    : /env/mx_1.5_gnlp_0.8/lib/python3.5/site-packages/pip\r\n    ----------MXNet Info-----------\r\n    Version      : 1.5.0\r\n    Directory    : /env/mx_1.5_gnlp_0.8/lib/python3.5/site-packages/mxnet\r\n    Num GPUs     : 8\r\n    Commit Hash   : 75a9e187d00a8b7ebc71412a02ed0e3ae489d91f\r\n    ----------System Info----------\r\n    Platform     : Linux-4.4.0-1090-aws-x86_64-with-Ubuntu-16.04-xenial\r\n    system       : Linux\r\n    node         : ip-172-31-30-122\r\n    release      : 4.4.0-1090-aws\r\n    version      : #101-Ubuntu SMP Fri Aug 2 15:21:01 UTC 2019\r\n    ----------Hardware Info----------\r\n    machine      : x86_64\r\n    processor    : x86_64\r\n    ----------Network Test----------\r\n    Setting timeout: 10\r\n    Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0011 sec, LOAD: 0.5163 sec.\r\n    Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0004 sec, LOAD: 0.0498 sec.\r\n    Timing for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0004 sec, LOAD: 0.0210 sec.\r\n    Timing for D2L: http://d2l.ai, DNS: 0.0004 sec, LOAD: 0.0183 sec.\r\n    Timing for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0003 sec, LOAD: 0.0373 sec.\r\n    Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0003 sec, LOAD: 0.1360 sec.\r\n    Timing for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0003 sec, LOAD: 0.0211 sec.\r\n    Timing for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0003 sec, LOAD: 0.3963 sec.\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/901", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/901/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/901/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/901/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/901", "id": 485504529, "node_id": "MDU6SXNzdWU0ODU1MDQ1Mjk=", "number": 901, "title": "script version checking ", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-26T23:36:20Z", "updated_at": "2019-09-22T21:49:20Z", "closed_at": "2019-09-22T21:49:20Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently users download scripts from the gluonnlp website, which is up-to-date with the latest gluonnlp release. \r\n\r\nHowever, some user still have old version of gluonnlp installed, and didn't realize that the downloaded script only works for latest gluonnlp (0.8). \r\n\r\nI suggest we add version checking in the beginning of the script and print a warning if the installed gluonnlp version is lower than the expected gluonnlp version.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/899", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/899/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/899/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/899/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/899", "id": 485300952, "node_id": "MDU6SXNzdWU0ODUzMDA5NTI=", "number": 899, "title": "Add RAdam", "user": {"login": "seujung", "id": 20786778, "node_id": "MDQ6VXNlcjIwNzg2Nzc4", "avatar_url": "https://avatars2.githubusercontent.com/u/20786778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seujung", "html_url": "https://github.com/seujung", "followers_url": "https://api.github.com/users/seujung/followers", "following_url": "https://api.github.com/users/seujung/following{/other_user}", "gists_url": "https://api.github.com/users/seujung/gists{/gist_id}", "starred_url": "https://api.github.com/users/seujung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seujung/subscriptions", "organizations_url": "https://api.github.com/users/seujung/orgs", "repos_url": "https://api.github.com/users/seujung/repos", "events_url": "https://api.github.com/users/seujung/events{/privacy}", "received_events_url": "https://api.github.com/users/seujung/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-26T15:36:31Z", "updated_at": "2019-10-08T23:53:57Z", "closed_at": "2019-10-08T23:53:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nRAdam \r\n- RAdam is a new variant of Adam, by introducing a term to rectify the varianceof the adaptive learning rate\r\n- Experimental results on language modeling and neural machine translation demonstrate the effectiveness and robustness results\r\n\r\n## References\r\n- https://arxiv.org/pdf/1908.03265v1.pdf\r\n- https://github.com/LiyuanLucasLiu/RAdam\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/896", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/896/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/896/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/896/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/896", "id": 484755709, "node_id": "MDU6SXNzdWU0ODQ3NTU3MDk=", "number": 896, "title": "Citation for converted BERT model", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2019-08-24T00:18:41Z", "updated_at": "2019-09-02T21:37:36Z", "closed_at": "2019-09-02T21:37:36Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We shall explicitly cite the converted BERT models on the website to avoid confusions. For example, there are multiple ClinicalBERT model repositories and papers: \r\nhttps://github.com/EmilyAlsentzer/clinicalBERT\r\nhttps://github.com/kexinhuang12345/clinicalBERT\r\n@leezu ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/892", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/892/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/892/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/892/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/892", "id": 484364330, "node_id": "MDU6SXNzdWU0ODQzNjQzMzA=", "number": 892, "title": "Loading Dataset Error (wikitext)", "user": {"login": "GeorgiosHajivassiliou", "id": 54028137, "node_id": "MDQ6VXNlcjU0MDI4MTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/54028137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GeorgiosHajivassiliou", "html_url": "https://github.com/GeorgiosHajivassiliou", "followers_url": "https://api.github.com/users/GeorgiosHajivassiliou/followers", "following_url": "https://api.github.com/users/GeorgiosHajivassiliou/following{/other_user}", "gists_url": "https://api.github.com/users/GeorgiosHajivassiliou/gists{/gist_id}", "starred_url": "https://api.github.com/users/GeorgiosHajivassiliou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GeorgiosHajivassiliou/subscriptions", "organizations_url": "https://api.github.com/users/GeorgiosHajivassiliou/orgs", "repos_url": "https://api.github.com/users/GeorgiosHajivassiliou/repos", "events_url": "https://api.github.com/users/GeorgiosHajivassiliou/events{/privacy}", "received_events_url": "https://api.github.com/users/GeorgiosHajivassiliou/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-23T07:04:40Z", "updated_at": "2019-08-23T08:36:03Z", "closed_at": "2019-08-23T08:36:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, \r\n\r\nI'm trying to experiment with a pre-trained LSTM model.\r\n\r\nI am loading some text I need to build my vocabulary\r\n\r\n`wikitext103 = nlp.data.WikiText103('val', root='./datasets/wikitext2')`\r\n\r\nbut all I get is this:\r\n\r\n> ~/.local/lib/python3.5/site-packages/mxnet/gluon/utils.py in download(url, path, overwrite, sha1_hash, retries, verify_ssl)\r\n    310             try:\r\n    311                 print('Downloading {} from {}...'.format(fname, url))\r\n--> 312                 r = requests.get(url, stream=True, verify=verify_ssl)\r\n    313                 if r.status_code != 200:\r\n    314                     raise RuntimeError('Failed downloading url {}'.format(url))\r\n\r\nAttributeError: type object 'requests_failed_to_import' has no attribute 'get'\r\n\r\nI have looked online and there is a similar error solved by importing the requests package but this does not help here.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/881", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/881/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/881/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/881/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/881", "id": 481373604, "node_id": "MDU6SXNzdWU0ODEzNzM2MDQ=", "number": 881, "title": "Missing error log from CI", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-08-15T23:02:54Z", "updated_at": "2019-08-16T19:50:40Z", "closed_at": "2019-08-16T19:50:40Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The notebook tests in some cases don't report the error log:\r\nhttp://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-877/9/pipeline\r\nNot sure if it's transient or consistent across runs", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/879", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/879/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/879/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/879/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/879", "id": 481294269, "node_id": "MDU6SXNzdWU0ODEyOTQyNjk=", "number": 879, "title": "Using FastText subword embeddings with Gluon", "user": {"login": "charlieyou", "id": 17055727, "node_id": "MDQ6VXNlcjE3MDU1NzI3", "avatar_url": "https://avatars2.githubusercontent.com/u/17055727?v=4", "gravatar_id": "", "url": "https://api.github.com/users/charlieyou", "html_url": "https://github.com/charlieyou", "followers_url": "https://api.github.com/users/charlieyou/followers", "following_url": "https://api.github.com/users/charlieyou/following{/other_user}", "gists_url": "https://api.github.com/users/charlieyou/gists{/gist_id}", "starred_url": "https://api.github.com/users/charlieyou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/charlieyou/subscriptions", "organizations_url": "https://api.github.com/users/charlieyou/orgs", "repos_url": "https://api.github.com/users/charlieyou/repos", "events_url": "https://api.github.com/users/charlieyou/events{/privacy}", "received_events_url": "https://api.github.com/users/charlieyou/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2019-08-15T19:09:12Z", "updated_at": "2019-08-29T17:11:08Z", "closed_at": "2019-08-29T17:11:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to understand how to use FastText embeddings in a Gluon model. I've been looking at [this section of the documentation](https://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html#Using-Pre-trained-Word-Embeddings-in-Gluon), but it does not address how to use the `gluon.nn.Embedding` layer when you have out-of-vocab words and want to take advantage of FTs subword functionality.\r\n\r\nI do realize that I could grab the embeddings first and then feed that as input data to the model, but I would like to be able to fine-tune the embeddings during the training process as well.\r\n\r\nThank you for your help!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/872", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/872/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/872/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/872/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/872", "id": 479360427, "node_id": "MDU6SXNzdWU0NzkzNjA0Mjc=", "number": 872, "title": "WordEmbedding Why train.step with batchsize 1", "user": {"login": "gemire", "id": 3426489, "node_id": "MDQ6VXNlcjM0MjY0ODk=", "avatar_url": "https://avatars2.githubusercontent.com/u/3426489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gemire", "html_url": "https://github.com/gemire", "followers_url": "https://api.github.com/users/gemire/followers", "following_url": "https://api.github.com/users/gemire/following{/other_user}", "gists_url": "https://api.github.com/users/gemire/gists{/gist_id}", "starred_url": "https://api.github.com/users/gemire/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gemire/subscriptions", "organizations_url": "https://api.github.com/users/gemire/orgs", "repos_url": "https://api.github.com/users/gemire/repos", "events_url": "https://api.github.com/users/gemire/events{/privacy}", "received_events_url": "https://api.github.com/users/gemire/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-08-11T11:38:38Z", "updated_at": "2019-08-14T11:09:09Z", "closed_at": "2019-08-14T11:09:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nIn scripts/word_embeddings/train_glove.py:319:             trainer.step(batch_size=1)\r\nand scripts/word_embeddings/train_sg_cbow.py:240 trainer.step(batch_size=1)\r\n\r\nwhy the batch_size set to 1?  why not average the loss first? or batch_size set to the real batchsize?\r\nwhen the batch size is large, it would cause the loss large too.\r\n\r\nThank you for help!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/861", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/861/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/861/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/861/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/861", "id": 476452392, "node_id": "MDU6SXNzdWU0NzY0NTIzOTI=", "number": 861, "title": "Bert backward propagation order isn't correct ??", "user": {"login": "YouhuiBai", "id": 27176645, "node_id": "MDQ6VXNlcjI3MTc2NjQ1", "avatar_url": "https://avatars0.githubusercontent.com/u/27176645?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YouhuiBai", "html_url": "https://github.com/YouhuiBai", "followers_url": "https://api.github.com/users/YouhuiBai/followers", "following_url": "https://api.github.com/users/YouhuiBai/following{/other_user}", "gists_url": "https://api.github.com/users/YouhuiBai/gists{/gist_id}", "starred_url": "https://api.github.com/users/YouhuiBai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YouhuiBai/subscriptions", "organizations_url": "https://api.github.com/users/YouhuiBai/orgs", "repos_url": "https://api.github.com/users/YouhuiBai/repos", "events_url": "https://api.github.com/users/YouhuiBai/events{/privacy}", "received_events_url": "https://api.github.com/users/YouhuiBai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2019-08-03T13:36:05Z", "updated_at": "2019-12-13T05:37:00Z", "closed_at": "2019-12-13T05:37:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nHi, I downloaded Bert source code from [Bert](https://gluon-nlp.mxnet.io/model_zoo/bert/index.html), and ran successfully at a single machine with one GPU. Then I expanded the code and made it be with the support of Horovod, modified source code [here](https://gitee.com/YouhuiBai/Bert), only changed the `finetune_classifier.py`, then I ran it with 2 servers with one GPU per machine, and profiled the process with [Horovod timeline](https://github.com/horovod/horovod/blob/master/docs/timeline.rst), found that there was no overlap between backward computation and communication, namely, it begins to transfer after the completion of backward, cause the order of transfer is exactly the same with forward computation order.\r\n\r\nThe earliest operators completed from mxnet engine will be transferred first by Horovod, but the transfer order is the same with forward's order, so I think the backward completion order from mxnet engine is not correct. Can anyone give some suggestions? \r\n\r\nThanks.\r\n\r\n## To Reproduce\r\nI used the latest code from [Bert](https://gluon-nlp.mxnet.io/model_zoo/bert/index.html) and made it be with the support of horovod too, the same result I can get.\r\n\r\n## What have you tried to solve it?\r\n\r\n1. I changed the Bert computation graph from static to dynamic, but it didn't matter.\r\n2. I tracked to mxnet imperative computation graph, the node ids indicate that the backward order is the reverse of forward, then the operators are sent to mxnet engine to execute with dependency.\r\n\r\n\r\nBut the Bert from google-research with tensorflow and horovod does have overlap between backward and communication. And the image-classification models from [here](https://github.com/horovod/horovod/blob/master/examples/mxnet_imagenet_resnet50.py) also have overlap with mxnet and horovod.\r\n\r\n## Environment\r\n\r\ngluonnlp 0.7.1, mxnet 1.5.0, horovod 0.16.1, openmpi 3.1.2\r\n\r\n# paste outputs here\r\nFor example, you can see that the transformer1 is transferred after transformer0, but the transformer1 is computed and completed first in backward propagation in theory.\r\n![image](https://user-images.githubusercontent.com/27176645/62412480-886ede80-b635-11e9-8583-6ab603bb55d3.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/849", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/849/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/849/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/849/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/849", "id": 473540756, "node_id": "MDU6SXNzdWU0NzM1NDA3NTY=", "number": 849, "title": "Fix all Pad() calls", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-26T21:21:31Z", "updated_at": "2019-10-08T23:46:38Z", "closed_at": "2019-10-08T23:46:38Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Now that for all `Pad()` calls without pad_val set, users see a warning that `pad_val` is set to default value 0. This may confuse ppl who uses existing script and wonder if there's any problem in their setup for the warning message printed. We should fix all these usages. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/843", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/843/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/843/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/843/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/843", "id": 470862203, "node_id": "MDU6SXNzdWU0NzA4NjIyMDM=", "number": 843, "title": "How can i load pretained biobert  with  BertEmbedding,", "user": {"login": "cpmss521", "id": 47856948, "node_id": "MDQ6VXNlcjQ3ODU2OTQ4", "avatar_url": "https://avatars0.githubusercontent.com/u/47856948?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cpmss521", "html_url": "https://github.com/cpmss521", "followers_url": "https://api.github.com/users/cpmss521/followers", "following_url": "https://api.github.com/users/cpmss521/following{/other_user}", "gists_url": "https://api.github.com/users/cpmss521/gists{/gist_id}", "starred_url": "https://api.github.com/users/cpmss521/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cpmss521/subscriptions", "organizations_url": "https://api.github.com/users/cpmss521/orgs", "repos_url": "https://api.github.com/users/cpmss521/repos", "events_url": "https://api.github.com/users/cpmss521/events{/privacy}", "received_events_url": "https://api.github.com/users/cpmss521/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-07-22T02:24:06Z", "updated_at": "2019-10-08T23:59:07Z", "closed_at": "2019-10-08T23:59:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "i get  a  `ValueError` when  use `BertEmbedding` ,\r\n `bert_embedding = BertEmbedding(model='bert_24_1024_16', dataset_name=\"biobert_v1.1_pmc_cased\")`,\r\n`ValueError: Vocabulary for biobert_v1.1_pmc_cased is not available.` this  `BertEmbedding` is not support pretained  biobert??", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/839", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/839/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/839/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/839/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/839", "id": 469812499, "node_id": "MDU6SXNzdWU0Njk4MTI0OTk=", "number": 839, "title": "MXNet nightly numpy dependency bump breaks stuff", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-18T14:45:44Z", "updated_at": "2019-07-19T20:07:55Z", "closed_at": "2019-07-19T20:07:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nSomewhere between today and 11th July, MXNet pre-release on Pypi declared to rely on `numpy<2.0.0,>1.16.0` instead of `numpy<1.15.0,>=1.8.2`, thus bringing with it some breaking changes:\r\n\r\nIn particular, we're hit by:\r\n\r\n> Unpickling while loading requires explicit opt-in\r\n> \r\n> The functions load, and lib.format.read_array take an\r\n> allow_pickle keyword which now defaults to False in response to\r\n> CVE-2019-6446 <https://nvd.nist.gov/vuln/detail/CVE-2019-6446>_.\r\n> \r\n> .. currentmodule:: numpy.random.mtrand\r\n\r\nas it breaks `./scripts/bert/run_pretraining.py`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/831", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/831/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/831/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/831/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/831", "id": 468725698, "node_id": "MDU6SXNzdWU0Njg3MjU2OTg=", "number": 831, "title": "ATIS/SNIPS datasets and GLUE datasets don't appear in the website API doc ", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1440115736, "node_id": "MDU6TGFiZWwxNDQwMTE1NzM2", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/documentation", "name": "documentation", "color": "bfdadc", "default": true, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-07-16T15:35:14Z", "updated_at": "2019-07-26T16:59:50Z", "closed_at": "2019-07-26T16:59:49Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "http://gluon-nlp.mxnet.io/api/modules/data.html\r\n\r\ndoes not show the details of ATISDataset/SNIPSDataset and GlueCoLA, GlueSST2, GlueSTSB, GlueQQP, GlueRTE, GlueMNLI, GlueQNLI, GlueWNLI\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/822", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/822/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/822/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/822/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/822", "id": 466108781, "node_id": "MDU6SXNzdWU0NjYxMDg3ODE=", "number": 822, "title": "Missing Models", "user": {"login": "bhavanaganesh", "id": 6783009, "node_id": "MDQ6VXNlcjY3ODMwMDk=", "avatar_url": "https://avatars3.githubusercontent.com/u/6783009?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bhavanaganesh", "html_url": "https://github.com/bhavanaganesh", "followers_url": "https://api.github.com/users/bhavanaganesh/followers", "following_url": "https://api.github.com/users/bhavanaganesh/following{/other_user}", "gists_url": "https://api.github.com/users/bhavanaganesh/gists{/gist_id}", "starred_url": "https://api.github.com/users/bhavanaganesh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bhavanaganesh/subscriptions", "organizations_url": "https://api.github.com/users/bhavanaganesh/orgs", "repos_url": "https://api.github.com/users/bhavanaganesh/repos", "events_url": "https://api.github.com/users/bhavanaganesh/events{/privacy}", "received_events_url": "https://api.github.com/users/bhavanaganesh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-10T05:35:34Z", "updated_at": "2019-08-02T06:12:32Z", "closed_at": "2019-08-02T06:12:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n- Topic models like LDA\r\n- Lemmatization and Stemming for preprocessing\r\n- Expose sparse n gram representation or BOW representation for sentences/documents to user.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/820", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/820/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/820/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/820/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/820", "id": 465566245, "node_id": "MDU6SXNzdWU0NjU1NjYyNDU=", "number": 820, "title": "FixedBucketSampler causes excessive memory consumption", "user": {"login": "rjk-git", "id": 44219470, "node_id": "MDQ6VXNlcjQ0MjE5NDcw", "avatar_url": "https://avatars3.githubusercontent.com/u/44219470?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjk-git", "html_url": "https://github.com/rjk-git", "followers_url": "https://api.github.com/users/rjk-git/followers", "following_url": "https://api.github.com/users/rjk-git/following{/other_user}", "gists_url": "https://api.github.com/users/rjk-git/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjk-git/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjk-git/subscriptions", "organizations_url": "https://api.github.com/users/rjk-git/orgs", "repos_url": "https://api.github.com/users/rjk-git/repos", "events_url": "https://api.github.com/users/rjk-git/events{/privacy}", "received_events_url": "https://api.github.com/users/rjk-git/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-09T04:43:53Z", "updated_at": "2019-08-28T19:20:04Z", "closed_at": "2019-08-28T19:20:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI am having a problem with FixedBucketSampler. My language model uses a simple lstm, hidden_dim:300, num_layer:3. Batch_size: 32, max_seq_len: 100. However, the memory consumption will reach 15G after training 1000batch. In this process, the memory consumption has been increasing.\r\n\r\n### Error Message\r\nThere is an obvious rule: if the current batch has a length of 46 and the next batch is still 46, the memory will hardly increase. However, if the sentence length of the next batch is different, the memory consumption of less than or greater than 46 will continue to increase.\r\nThen I fixed the length of each batch of sentences into same length, and the memory consumption will be fixed at around 3G.\r\nI think that using batch data with different sentence lengths, the memory consumption is too large, is there a BUG.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/818", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/818/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/818/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/818/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/818", "id": 464901719, "node_id": "MDU6SXNzdWU0NjQ5MDE3MTk=", "number": 818, "title": "Follow-up items for ESIM", "user": {"login": "szha", "id": 2626883, "node_id": "MDQ6VXNlcjI2MjY4ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2626883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szha", "html_url": "https://github.com/szha", "followers_url": "https://api.github.com/users/szha/followers", "following_url": "https://api.github.com/users/szha/following{/other_user}", "gists_url": "https://api.github.com/users/szha/gists{/gist_id}", "starred_url": "https://api.github.com/users/szha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szha/subscriptions", "organizations_url": "https://api.github.com/users/szha/orgs", "repos_url": "https://api.github.com/users/szha/repos", "events_url": "https://api.github.com/users/szha/events{/privacy}", "received_events_url": "https://api.github.com/users/szha/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-07T00:26:41Z", "updated_at": "2020-07-23T20:11:09Z", "closed_at": "2020-07-23T20:11:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Some items left from #689:\r\n- [ ] report performance and upload log to dmlc/web-data\r\n- [ ] update model zoo page to include the description of the model, the command, and link to the log", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/809", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/809/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/809/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/809/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/809", "id": 463121880, "node_id": "MDU6SXNzdWU0NjMxMjE4ODA=", "number": 809, "title": "Sphinx-autorun output broken on website", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-02T09:29:38Z", "updated_at": "2019-07-04T20:39:19Z", "closed_at": "2019-07-04T20:39:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\nThe autorun output on our master-branch version of the website is broken. All current PRs are also affected. The last stable release was still working.\r\n\r\nStable: http://gluon-nlp.mxnet.io/api/modules/embedding.html#gluonnlp.embedding.GloVe\r\nMaster: http://gluon-nlp.mxnet.io/master/api/modules/embedding.html#gluonnlp.embedding.GloVe\r\n\r\n```\r\n\r\n  File \"<input>\", line 1\r\n    -\r\n    ^\r\nSyntaxError: invalid syntax\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/797", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/797/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/797/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/797/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/797", "id": 461191197, "node_id": "MDU6SXNzdWU0NjExOTExOTc=", "number": 797, "title": "TransformerXL for GluonNLP", "user": {"login": "sxjscience", "id": 5178350, "node_id": "MDQ6VXNlcjUxNzgzNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5178350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sxjscience", "html_url": "https://github.com/sxjscience", "followers_url": "https://api.github.com/users/sxjscience/followers", "following_url": "https://api.github.com/users/sxjscience/following{/other_user}", "gists_url": "https://api.github.com/users/sxjscience/gists{/gist_id}", "starred_url": "https://api.github.com/users/sxjscience/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sxjscience/subscriptions", "organizations_url": "https://api.github.com/users/sxjscience/orgs", "repos_url": "https://api.github.com/users/sxjscience/repos", "events_url": "https://api.github.com/users/sxjscience/events{/privacy}", "received_events_url": "https://api.github.com/users/sxjscience/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-26T21:31:38Z", "updated_at": "2019-08-19T02:59:25Z", "closed_at": "2019-08-19T02:59:25Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "TransformerXL: https://arxiv.org/pdf/1901.02860.pdf (ACL2019)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/792", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/792/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/792/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/792/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/792", "id": 460018072, "node_id": "MDU6SXNzdWU0NjAwMTgwNzI=", "number": 792, "title": "SplitSampler to have configurable sampling ability", "user": {"login": "chandana1332", "id": 8731489, "node_id": "MDQ6VXNlcjg3MzE0ODk=", "avatar_url": "https://avatars3.githubusercontent.com/u/8731489?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chandana1332", "html_url": "https://github.com/chandana1332", "followers_url": "https://api.github.com/users/chandana1332/followers", "following_url": "https://api.github.com/users/chandana1332/following{/other_user}", "gists_url": "https://api.github.com/users/chandana1332/gists{/gist_id}", "starred_url": "https://api.github.com/users/chandana1332/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chandana1332/subscriptions", "organizations_url": "https://api.github.com/users/chandana1332/orgs", "repos_url": "https://api.github.com/users/chandana1332/repos", "events_url": "https://api.github.com/users/chandana1332/events{/privacy}", "received_events_url": "https://api.github.com/users/chandana1332/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-06-24T17:50:56Z", "updated_at": "2019-10-13T04:35:54Z", "closed_at": "2019-10-13T04:35:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\nI'm currently trying to integrate Horovod with Gluon. I came across SplitSampler that virtually partitions the data and randomly samples from a particular partition. I would like to use this partitioning mechanism with other samplers such as bucket sampler, etc. Would it be possible to configure the choice of sampling mechanism in SplitSampler rather than forcing it to be randomly sampled?\r\n\r\n## References\r\n- https://gluon-nlp.mxnet.io/_modules/gluonnlp/data/sampler.html\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/790", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/790/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/790/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/790/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/790", "id": 459620874, "node_id": "MDU6SXNzdWU0NTk2MjA4NzQ=", "number": 790, "title": "[DISCUSS] Semantic Versioning and Deprecation", "user": {"login": "szha", "id": 2626883, "node_id": "MDQ6VXNlcjI2MjY4ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2626883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szha", "html_url": "https://github.com/szha", "followers_url": "https://api.github.com/users/szha/followers", "following_url": "https://api.github.com/users/szha/following{/other_user}", "gists_url": "https://api.github.com/users/szha/gists{/gist_id}", "starred_url": "https://api.github.com/users/szha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szha/subscriptions", "organizations_url": "https://api.github.com/users/szha/orgs", "repos_url": "https://api.github.com/users/szha/repos", "events_url": "https://api.github.com/users/szha/events{/privacy}", "received_events_url": "https://api.github.com/users/szha/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 963101581, "node_id": "MDU6TGFiZWw5NjMxMDE1ODE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/discussion", "name": "discussion", "color": "c5def5", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-23T21:39:58Z", "updated_at": "2020-06-18T06:55:53Z", "closed_at": "2020-06-18T06:55:53Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It has been taken for granted that GluonNLP project adheres to [semantic versioning](https://semver.org). I'd like to use this thread to make explicit decision about this, and about how we change APIs in the 0.x version. I propose the following:\r\n- GluonNLP project API adheres to [semantic versioning](https://semver.org).\r\n- Model Zoo scripts are not shipped as part of the API and thus does not adhere to semantic versioning.\r\n- In the 0.x versions, we add deprecation warning to any API or argument in API \r\n\r\nFor pre-trained models the semantic versioning is more nuanced. I propose the following:\r\n- Pre-trained models should support explicit versioning so that the `get_model` API always returns the same model with the same behavior when version is explicitly specified.\r\n- We can continue to use the file hash as the pre-trained model version. Each model version should have descrption about:\r\n  - the commit hash of GluonNLP based on which the model is trained.\r\n  - the script, dataset and hyperparameter settings.\r\n  - if converted from elsewhere, the source where the model comes from along with the license.\r\n- When getting pre-trained models by simply specifying pre-trained flag to be True, the model does not follow semantic versioning so that models could be updated.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/789", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/789/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/789/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/789/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/789", "id": 459397747, "node_id": "MDU6SXNzdWU0NTkzOTc3NDc=", "number": 789, "title": "Making transformer encoder fully hybridized for export", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-06-21T22:48:58Z", "updated_at": "2019-09-19T22:26:48Z", "closed_at": "2019-09-19T22:26:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently BERT can be [exported](https://github.com/dmlc/gluon-nlp/blob/master/scripts/bert/export/export.py) with static length support. BERTEncoder inherits Transformer encoder, which contains a few `.shape` API calls, making the transformer encoder not fully hybridizable and create issues during export. As the result, the exported model only supports static length. These calls are located here:\r\nhttps://github.com/dmlc/gluon-nlp/blob/master/src/gluonnlp/model/transformer.py#L450-L463\r\n\r\nWe need to remove these calls to export a model that supports variable length. \r\n\r\n## handling arange\r\nIn particular, we have \r\n```\r\nlength = inputs.shape[1]\r\narange = mx.nd.arange(length, ctx=valid_length.context, dtype=valid_length.dtype)\r\n```\r\n\r\nTo remove these .shape calls, we have 2 options:\r\n### contrib.arange_like op with ndarray input\r\nInstead of `contrib.arange(arr.shape[1], ...)`, we can introduce an arange_like op:\r\n- input: `arr` with shape (x,) and abitrary data\r\n- output: an output with shape `arr.shape`, and value of `[0, 1, 2, ... size(arr) - 1]`. \r\n\r\nWith this op, we just need to slice the inputs on axis 1 and pass it to arange_like op: \r\n```\r\narr = inputs.slice(begin=(0,0,0), end=(0,None,0)\r\narange = F.contrib.arange(arr)\r\n```\r\n\r\n### control flow op\r\n\r\nAlternatively, we can use control flow op (either foreach, or while loop) to loop N times, where N = inputs.shape[1]. Loop i fills in the value i in the output \"arange\" array.\r\n\r\nHowever, this may have high overhead when N is large (512). \r\n\r\n## handling other `.shape` calls\r\n\r\n- `mask = mx.nd.broadcast_axes(mx.nd.expand_dims(mask, axis=1), axis=1, size=length)` can be replaced with `broadcast_mul` op with `ones_like(arr)`\r\n- `inputs * math.sqrt(inputs.shape[-1])` can be replace with `shape_nd` op\r\n\r\n@TaoLv ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/788", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/788/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/788/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/788/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/788", "id": 458997271, "node_id": "MDU6SXNzdWU0NTg5OTcyNzE=", "number": 788, "title": "simverb3500 link broken", "user": {"login": "szha", "id": 2626883, "node_id": "MDQ6VXNlcjI2MjY4ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2626883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szha", "html_url": "https://github.com/szha", "followers_url": "https://api.github.com/users/szha/followers", "following_url": "https://api.github.com/users/szha/following{/other_user}", "gists_url": "https://api.github.com/users/szha/gists{/gist_id}", "starred_url": "https://api.github.com/users/szha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szha/subscriptions", "organizations_url": "https://api.github.com/users/szha/orgs", "repos_url": "https://api.github.com/users/szha/repos", "events_url": "https://api.github.com/users/szha/events{/privacy}", "received_events_url": "https://api.github.com/users/szha/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-21T04:03:47Z", "updated_at": "2019-07-04T20:39:19Z", "closed_at": "2019-07-04T20:39:19Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Description\r\nhttp://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-783/3/pipeline#step-64-log-1246\r\n\r\n## What have you tried to solve it?\r\n\r\nWe will skip its test for now which needs to be added back.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/787", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/787/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/787/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/787/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/787", "id": 458876181, "node_id": "MDU6SXNzdWU0NTg4NzYxODE=", "number": 787, "title": "Port XLNet to gluonnlp ", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-20T20:52:54Z", "updated_at": "2019-10-16T22:48:53Z", "closed_at": "2019-10-16T22:48:53Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://github.com/zihangdai/xlnet\r\nhttps://arxiv.org/abs/1906.08237 \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/784", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/784/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/784/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/784/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/784", "id": 458278364, "node_id": "MDU6SXNzdWU0NTgyNzgzNjQ=", "number": 784, "title": "Jenkins CI badge broken", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-20T00:15:29Z", "updated_at": "2019-06-30T02:41:57Z", "closed_at": "2019-06-30T02:41:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "In our README, the Jenkins CI badge is broken after Jenkins update.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/779", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/779/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/779/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/779/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/779", "id": 457637856, "node_id": "MDU6SXNzdWU0NTc2Mzc4NTY=", "number": 779, "title": "BiLMEncoder fails to initialize if num_layers > 1", "user": {"login": "Ishitori", "id": 3286787, "node_id": "MDQ6VXNlcjMyODY3ODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/3286787?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ishitori", "html_url": "https://github.com/Ishitori", "followers_url": "https://api.github.com/users/Ishitori/followers", "following_url": "https://api.github.com/users/Ishitori/following{/other_user}", "gists_url": "https://api.github.com/users/Ishitori/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ishitori/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ishitori/subscriptions", "organizations_url": "https://api.github.com/users/Ishitori/orgs", "repos_url": "https://api.github.com/users/Ishitori/repos", "events_url": "https://api.github.com/users/Ishitori/events{/privacy}", "received_events_url": "https://api.github.com/users/Ishitori/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-18T18:44:23Z", "updated_at": "2019-06-24T20:13:39Z", "closed_at": "2019-06-24T20:13:39Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n`BiLMEncoder` fails during initialization if `num_layers > 1`. Works fine when num_layers = 1, but if it is at least 2, then initialization fails with a weird message. See simplest reproducible example below.\r\n\r\n### Error Message\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 505, in initialize\r\n    self.collect_params().initialize(init, ctx, verbose, force_reinit)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/gluon/parameter.py\", line 830, in initialize\r\n    v.initialize(None, ctx, init, force_reinit=force_reinit)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/gluon/parameter.py\", line 400, in initialize\r\n    if not shape_is_known(self.shape):\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/gluon/utils.py\", line 430, in shape_is_known\r\n    assert dim_size > unknown_dim_size, \"shape dimension size cannot be less than {}, while \" \\\r\nTypeError: '>' not supported between instances of 'NoneType' and 'int'\r\n```\r\n\r\n## To Reproduce\r\n```python\r\nfrom gluonnlp.model import BiLMEncoder\r\nencoder = BiLMEncoder(mode='lstm', num_layers=2, input_size=200, hidden_size=100, dropout=0.1, skip_connection=False)\r\nencoder.initialize()\r\n```\r\n\r\n## Environment\r\n`pip install gluonnlp --pre`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/776", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/776/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/776/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/776/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/776", "id": 457211640, "node_id": "MDU6SXNzdWU0NTcyMTE2NDA=", "number": 776, "title": "BERT documentation improvement", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393503, "node_id": "MDU6TGFiZWw4OTAzOTM1MDM=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/enhancement", "name": "enhancement", "color": "135caf", "default": true, "description": "New feature or request"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2019-06-18T01:03:27Z", "updated_at": "2019-07-23T01:17:12Z", "closed_at": "2019-07-23T01:17:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The model zoo page for BERT is lengthy and is not easy to follow. We need to \r\n- replace shell command with links to dmlc/web-data\r\n- simplify bert pre-training instructions ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/765", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/765/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/765/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/765/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/765", "id": 455064233, "node_id": "MDU6SXNzdWU0NTUwNjQyMzM=", "number": 765, "title": "there is a error, when I import the model exported by bert/export.py  ", "user": {"login": "rongruosong", "id": 25951813, "node_id": "MDQ6VXNlcjI1OTUxODEz", "avatar_url": "https://avatars0.githubusercontent.com/u/25951813?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rongruosong", "html_url": "https://github.com/rongruosong", "followers_url": "https://api.github.com/users/rongruosong/followers", "following_url": "https://api.github.com/users/rongruosong/following{/other_user}", "gists_url": "https://api.github.com/users/rongruosong/gists{/gist_id}", "starred_url": "https://api.github.com/users/rongruosong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rongruosong/subscriptions", "organizations_url": "https://api.github.com/users/rongruosong/orgs", "repos_url": "https://api.github.com/users/rongruosong/repos", "events_url": "https://api.github.com/users/rongruosong/events{/privacy}", "received_events_url": "https://api.github.com/users/rongruosong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-12T07:55:15Z", "updated_at": "2019-06-12T08:33:14Z", "closed_at": "2019-06-12T08:33:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Description\r\n(A clear and concise description of what the bug is.)\r\n\r\n### Error Message\r\nUserWarning: Cannot decide type for the following arguments. Consider providing them as input:\r\n\tdata: None\r\n  input_sym_arg_type = in_param.infer_type()[0]\r\nTraceback (most recent call last):\r\n  File \"/Users/rongruosong/PycharmProjects/mxnet_bert/tvm_compile.py\", line 14, in <module>\r\n    'output_dir/classification-0000.params')\r\n  File \"/Users/rongruosong/PycharmProjects/mxnet_bert/venv/lib/python3.7/site-packages/mxnet/gluon/block.py\", line 1027, in imports\r\n    ret.collect_params().load(param_file, ctx=ctx)\r\n  File \"/Users/rongruosong/PycharmProjects/mxnet_bert/venv/lib/python3.7/site-packages/mxnet/gluon/parameter.py\", line 932, in load\r\n    name[lprefix:], filename, _brief_print_list(arg_dict.keys()))\r\nAssertionError: Parameter 'data2' is missing in file 'output_dir/classification-0000.params', which contains parameters: 'hybridbertencoder0_position_weight', 'hybridbertencoder0_bertlayernorm0_gamma', 'hybridbertencoder0_bertlayernorm0_beta', ..., 'hybridbertmodel0_pooler_weight', 'hybridbertmodel0_pooler_bias', 'hybridbertclassifier0_dense0_weight', 'hybridbertclassifier0_dense0_bias'. Please make sure source and target networks have the same prefix.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/760", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/760/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/760/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/760/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/760", "id": 453939118, "node_id": "MDU6SXNzdWU0NTM5MzkxMTg=", "number": 760, "title": "Incorrect TOC in the website sidebar for tutorials", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-09T21:02:58Z", "updated_at": "2019-06-11T17:29:33Z", "closed_at": "2019-06-11T17:29:32Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "\"process data\", \"loading pretrained elmo data\", \"putting everything together\" should not appear in the sidebar.\r\n\r\n<img width=\"886\" alt=\"Screen Shot 2019-06-09 at 2 01 12 PM\" src=\"https://user-images.githubusercontent.com/5545640/59164236-30957a80-8abf-11e9-90b3-01151821f0d8.png\">\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/753", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/753/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/753/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/753/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/753", "id": 453417329, "node_id": "MDU6SXNzdWU0NTM0MTczMjk=", "number": 753, "title": "Missing wiki_cn Bert vocab artifacts on S3", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-06-07T09:20:16Z", "updated_at": "2019-06-11T22:50:42Z", "closed_at": "2019-06-11T22:50:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "@szha, following https://github.com/dmlc/gluon-nlp/pull/655 please copy \r\n\r\n`aws s3 cp s3://apache-mxnet/gluon/dataset/vocab/wiki_cn_cased-ddebd8f3.zip s3://apache-mxnet/gluon/dataset/vocab/wiki_cn-ddebd8f3.zip`\r\n\r\nBoth are required, as `wiki_cn` is an alias of `wiki_cn_cased`.\r\n\r\nThis bug must not be closed before tests are added that would have caught this error.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/751", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/751/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/751/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/751/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/751", "id": 453371557, "node_id": "MDU6SXNzdWU0NTMzNzE1NTc=", "number": 751, "title": "CI reports linkcheck as passing for pull-requests even though it fails", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 997120945, "node_id": "MDU6TGFiZWw5OTcxMjA5NDU=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/release%20focus", "name": "release focus", "color": "fbca04", "default": false, "description": "Progress focus for release"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-07T07:15:24Z", "updated_at": "2019-06-08T09:27:04Z", "closed_at": "2019-06-08T09:27:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "@szha There is some bug in the CI setup for pull-requests. Even though the\r\nlinkcheck consistently failed for all pull-requests after #566, the CI did not\r\nrecognize the failure and reported the test as passing. Only on the master\r\nbranch, the CI correctly reports the test as failing.\r\n\r\nSee for example the log for #732:\r\n- The pipeline checking the links is reported as passing\r\n  http://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-732/32/pipeline/85\r\n- However, looking at the detailed log files,\r\n  http://ci.mxnet.io/blue/rest/organizations/jenkins/pipelines/GluonNLP-py3-master-gpu-doc/branches/PR-732/runs/32/nodes/85/steps/106/log/?start=0\r\n  we see that the recipe for target linkcheck failed and reported Error 1 (last few lines)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/727", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/727/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/727/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/727/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/727", "id": 448209752, "node_id": "MDU6SXNzdWU0NDgyMDk3NTI=", "number": 727, "title": "pytest 4 support", "user": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 890393501, "node_id": "MDU6TGFiZWw4OTAzOTM1MDE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": {"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "leezu", "id": 946903, "node_id": "MDQ6VXNlcjk0NjkwMw==", "avatar_url": "https://avatars1.githubusercontent.com/u/946903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leezu", "html_url": "https://github.com/leezu", "followers_url": "https://api.github.com/users/leezu/followers", "following_url": "https://api.github.com/users/leezu/following{/other_user}", "gists_url": "https://api.github.com/users/leezu/gists{/gist_id}", "starred_url": "https://api.github.com/users/leezu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leezu/subscriptions", "organizations_url": "https://api.github.com/users/leezu/orgs", "repos_url": "https://api.github.com/users/leezu/repos", "events_url": "https://api.github.com/users/leezu/events{/privacy}", "received_events_url": "https://api.github.com/users/leezu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-05-24T14:46:15Z", "updated_at": "2019-05-24T18:20:11Z", "closed_at": "2019-05-24T18:20:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Tests are failing with current pytest 4.5\r\n\r\nThis does not affect CI as pytest < 4 is specified in the environment, but affects contributors running tests outside of CI.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/722", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/722/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/722/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/722/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/722", "id": 447392494, "node_id": "MDU6SXNzdWU0NDczOTI0OTQ=", "number": 722, "title": "gluonnlp._constant not using unicode for python2", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-23T00:02:21Z", "updated_at": "2019-07-04T23:27:13Z", "closed_at": "2019-07-04T23:27:13Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The pre-defined constants with py2 are encoded in ascii instead of unicode. This causes inconsistency in nlp.vocab.Vocab, where some tokens may be in unicode, and some reserved tokens are in ascii. \r\n\r\nThis may cause issue if users pre-process data with hard-coded string literals that is inconsistent with what's stored in Vocab. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/721", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/721/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/721/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/721/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/721", "id": 447391881, "node_id": "MDU6SXNzdWU0NDczOTE4ODE=", "number": 721, "title": "python2 end of life (will announce deprecation in 0.7)", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 963101581, "node_id": "MDU6TGFiZWw5NjMxMDE1ODE=", "url": "https://api.github.com/repos/dmlc/gluon-nlp/labels/discussion", "name": "discussion", "color": "c5def5", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-05-22T23:59:49Z", "updated_at": "2019-07-19T20:27:06Z", "closed_at": "2019-07-19T20:27:06Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "@dmlc/gluon-nlp-team \r\nPython2 will stop its support on January 1, 2020. We need to discuss a timeline to drop python2 support for gluon-nlp, too. \r\n\r\nhttps://www.python.org/dev/peps/pep-0373/\r\n\r\nThere's also a discussion thread to drop py2 for mxnet https://lists.apache.org/thread.html/f8440615095c5472d1b16c554fca0fe5bad3fb8b20feaceba39ca694@%3Cdev.mxnet.apache.org%3E \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/718", "repository_url": "https://api.github.com/repos/dmlc/gluon-nlp", "labels_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/718/labels{/name}", "comments_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/718/comments", "events_url": "https://api.github.com/repos/dmlc/gluon-nlp/issues/718/events", "html_url": "https://github.com/dmlc/gluon-nlp/issues/718", "id": 447245380, "node_id": "MDU6SXNzdWU0NDcyNDUzODA=", "number": 718, "title": "Flaky Test:  test_datasets.py::test_conll2004", "user": {"login": "eric-haibin-lin", "id": 5545640, "node_id": "MDQ6VXNlcjU1NDU2NDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5545640?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-haibin-lin", "html_url": "https://github.com/eric-haibin-lin", "followers_url": "https://api.github.com/users/eric-haibin-lin/followers", "following_url": "https://api.github.com/users/eric-haibin-lin/following{/other_user}", "gists_url": "https://api.github.com/users/eric-haibin-lin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-haibin-lin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-haibin-lin/subscriptions", "organizations_url": "https://api.github.com/users/eric-haibin-lin/orgs", "repos_url": "https://api.github.com/users/eric-haibin-lin/repos", "events_url": "https://api.github.com/users/eric-haibin-lin/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-haibin-lin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-05-22T16:57:27Z", "updated_at": "2019-05-23T05:50:35Z", "closed_at": "2019-05-23T05:50:35Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "http://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-cpu-unittest/detail/PR-669/11/pipeline\r\n\r\n```\r\n        if overwrite or not os.path.exists(fname) or (sha1_hash and not check_sha1(fname, sha1_hash)):\r\n\r\n            dirname = os.path.dirname(os.path.abspath(os.path.expanduser(fname)))\r\n\r\n            if not os.path.exists(dirname):\r\n\r\n                os.makedirs(dirname)\r\n\r\n            while retries + 1 > 0:\r\n\r\n                # Disable pyling too broad Exception\r\n\r\n                # pylint: disable=W0703\r\n\r\n                try:\r\n\r\n                    print('Downloading {} from {}...'.format(fname, url))\r\n\r\n                    r = requests.get(url, stream=True, verify=verify_ssl)\r\n\r\n                    if r.status_code != 200:\r\n\r\n>                       raise RuntimeError('Failed downloading url {}'.format(url))\r\n\r\nE                       RuntimeError: Failed downloading url http://www.cs.upc.edu/~srlconll/st04/conll04st-release.tar.gz\r\n\r\n\r\n```\r\n\r\nCan we host it ourselves? I did not find license information for this file at http://www.lsi.upc.es/~srlconll/st04/st04.html ", "performed_via_github_app": null, "score": 1.0}]}