{"total_count": 7, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/31", "repository_url": "https://api.github.com/repos/pytest-dev/pytest-subtests", "labels_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/31/labels{/name}", "comments_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/31/comments", "events_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/31/events", "html_url": "https://github.com/pytest-dev/pytest-subtests/issues/31", "id": 667612506, "node_id": "MDU6SXNzdWU2Njc2MTI1MDY=", "number": 31, "title": "pytest==6.0.0 breaks pytest-subtests", "user": {"login": "pmeier", "id": 6849766, "node_id": "MDQ6VXNlcjY4NDk3NjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6849766?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pmeier", "html_url": "https://github.com/pmeier", "followers_url": "https://api.github.com/users/pmeier/followers", "following_url": "https://api.github.com/users/pmeier/following{/other_user}", "gists_url": "https://api.github.com/users/pmeier/gists{/gist_id}", "starred_url": "https://api.github.com/users/pmeier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pmeier/subscriptions", "organizations_url": "https://api.github.com/users/pmeier/orgs", "repos_url": "https://api.github.com/users/pmeier/repos", "events_url": "https://api.github.com/users/pmeier/events{/privacy}", "received_events_url": "https://api.github.com/users/pmeier/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-29T07:19:12Z", "updated_at": "2020-08-01T15:02:26Z", "closed_at": "2020-08-01T15:02:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "Content of `test_subtests.py`\r\n\r\n```python\r\ndef test_subtests(subtests):\r\n    with subtests.test(\"foo\"):\r\n        assert True\r\n```\r\n\r\nRun with `pytest==5.4.3`\r\n\r\n```\r\n================================ test session starts =================================\r\nplatform linux -- Python 3.6.9, pytest-5.4.3, py-1.9.0, pluggy-0.13.1\r\nrootdir: /home/user\r\nplugins: subtests-0.3.1\r\ncollected 1 item                                                                     \r\n\r\ntest_subtests.py ..                                                            [100%]\r\n\r\n================================= 1 passed in 0.01s ==================================\r\n```\r\n\r\nRun with `pytest==6.0.0`\r\n\r\n```\r\nplatform linux -- Python 3.6.9, pytest-6.0.0, py-1.9.0, pluggy-0.13.1\r\nrootdir: /home/user\r\nplugins: subtests-0.3.1\r\ncollected 1 item                                                                     \r\n\r\ntest_subtests.py F                                                             [100%]\r\n\r\n====================================== FAILURES ======================================\r\n___________________________________ test_subtests ____________________________________\r\n\r\nsubtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f6abd329cf8>, suspend_capture_ctx=<bound method CaptureManager.gl...'suspended' _in_suspended=False> _capture_fixture=None>>, request=<SubRequest 'subtests' for <Function test_subtests>>)\r\n\r\n    def test_subtests(subtests):\r\n        with subtests.test(\"foo\"):\r\n>           assert True\r\n\r\ntest_subtests.py:3: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/usr/lib/python3.6/contextlib.py:88: in __exit__\r\n    next(self.gen)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f6abd329cf8>, suspend_capture_ctx=<bound method CaptureManager.gl...'suspended' _in_suspended=False> _capture_fixture=None>>, request=<SubRequest 'subtests' for <Function test_subtests>>)\r\nmsg = 'foo', kwargs = {}, start = 6178.172653449, exc_info = None\r\ncaptured = Captured(out='', err=''), stop = 6178.172874861\r\n\r\n    @contextmanager\r\n    def test(self, msg=None, **kwargs):\r\n        start = monotonic()\r\n        exc_info = None\r\n    \r\n        with self._capturing_output() as captured:\r\n            try:\r\n                yield\r\n            except (Exception, OutcomeException):\r\n                exc_info = ExceptionInfo.from_current()\r\n    \r\n        stop = monotonic()\r\n    \r\n>       call_info = CallInfo(None, exc_info, start, stop, when=\"call\")\r\nE       TypeError: __init__() missing 1 required positional argument: 'duration'\r\n\r\n.venv/lib/python3.6/site-packages/pytest_subtests.py:161: TypeError\r\n============================== short test summary info ===============================\r\nFAILED test_subtests.py::test_subtests - TypeError: __init__() missing 1 required p...\r\n================================= 1 failed in 0.03s ==================================\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/21", "repository_url": "https://api.github.com/repos/pytest-dev/pytest-subtests", "labels_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/21/labels{/name}", "comments_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/21/comments", "events_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/21/events", "html_url": "https://github.com/pytest-dev/pytest-subtests/issues/21", "id": 586010192, "node_id": "MDU6SXNzdWU1ODYwMTAxOTI=", "number": 21, "title": "Some tests are failing", "user": {"login": "fabaff", "id": 116184, "node_id": "MDQ6VXNlcjExNjE4NA==", "avatar_url": "https://avatars0.githubusercontent.com/u/116184?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fabaff", "html_url": "https://github.com/fabaff", "followers_url": "https://api.github.com/users/fabaff/followers", "following_url": "https://api.github.com/users/fabaff/following{/other_user}", "gists_url": "https://api.github.com/users/fabaff/gists{/gist_id}", "starred_url": "https://api.github.com/users/fabaff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fabaff/subscriptions", "organizations_url": "https://api.github.com/users/fabaff/orgs", "repos_url": "https://api.github.com/users/fabaff/repos", "events_url": "https://api.github.com/users/fabaff/events{/privacy}", "received_events_url": "https://api.github.com/users/fabaff/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-03-23T08:06:59Z", "updated_at": "2020-04-28T14:19:27Z", "closed_at": "2020-04-28T14:19:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "```bash\r\n[fab@1234 repos]$ git clone git@github.com:fabaff/pytest-subtests.git\r\nCloning into 'pytest-subtests'...\r\nremote: Enumerating objects: 25, done.\r\nremote: Counting objects: 100% (25/25), done.\r\nremote: Compressing objects: 100% (18/18), done.\r\nremote: Total 166 (delta 5), reused 12 (delta 3), pack-reused 141\r\nReceiving objects: 100% (166/166), 39.34 KiB | 592.00 KiB/s, done.\r\nResolving deltas: 100% (74/74), done.\r\n[fab@1234 repos]$ cd pytest-subtests/\r\n[fab@1234 pytest-subtests]$ python3 -m venv .\r\n[fab@1234 pytest-subtests]$ source bin/activate\r\n(pytest-subtests) [fab@1234 pytest-subtests]$ python3 setup.py develop\r\nrunning develop\r\nrunning egg_info\r\ncreating pytest_subtests.egg-info\r\nwriting pytest_subtests.egg-info/PKG-INFO\r\nwriting dependency_links to pytest_subtests.egg-info/dependency_links.txt\r\nwriting entry points to pytest_subtests.egg-info/entry_points.txt\r\nwriting requirements to pytest_subtests.egg-info/requires.txt\r\nwriting top-level names to pytest_subtests.egg-info/top_level.txt\r\nwriting manifest file 'pytest_subtests.egg-info/SOURCES.txt'\r\nwriting manifest file 'pytest_subtests.egg-info/SOURCES.txt'\r\nrunning build_ext\r\nCreating /home/fab/Documents/repos/pytest-subtests/lib/python3.7/site-packages/pytest-subtests.egg-link (link to .)\r\nAdding pytest-subtests 0.3.1.dev1+gc5442e3 to easy-install.pth file\r\n\r\nInstalled /home/fab/Documents/repos/pytest-subtests\r\nProcessing dependencies for pytest-subtests==0.3.1.dev1+gc5442e3\r\n[...]\r\nFinished processing dependencies for pytest-subtests==0.3.1.dev1+gc5442e3\r\n\r\n```\r\n\r\n```bash\r\n(pytest-subtests) [fab@1234 pytest-subtests]$ pytest-3 -v tests\r\n```\r\n\r\n<details>\r\n\r\n```bash\r\n/usr/lib/python3.7/site-packages/trio/_core/_multierror.py:450: RuntimeWarning: You seem to already have a custom sys.excepthook handler installed. I'll skip installing trio's custom handler, but this means MultiErrors will not show full tracebacks.\r\n  category=RuntimeWarning\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\ncachedir: .pytest_cache\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /home/fab/Documents/repos/pytest-subtests\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\ncollecting ... \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestFixture.test_simple_terminal_normal[normal] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestFixture object at 0x7f12c26c0fd0>, simple_script = None, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal0')>\r\nmode = 'normal'\r\n\r\n    def test_simple_terminal_normal(self, simple_script, testdir, mode):\r\n        if mode == \"normal\":\r\n            result = testdir.runpytest()\r\n            expected_lines = [\"collected 1 item\"]\r\n        else:\r\n            pytest.importorskip(\"xdist\")\r\n            result = testdir.runpytest(\"-n1\")\r\n            expected_lines = [\"gw0 [1]\"]\r\n    \r\n        expected_lines += [\r\n            \"* test_foo [[]custom[]] (i=1) *\",\r\n            \"* test_foo [[]custom[]] (i=3) *\",\r\n            \"* 2 failed, 1 passed in *\",\r\n        ]\r\n>       result.stdout.fnmatch_lines(expected_lines)\r\nE       Failed: nomatch: 'collected 1 item'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal0'\r\nE           and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: 'file /tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal0/test_simple_terminal_normal.py, line 1'\r\nE           and: '  def test_foo(subtests):'\r\nE           and: \"E       fixture 'subtests' not found\"\r\nE           and: '>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave'\r\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\r\nE           and: ''\r\nE           and: '/tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal0/test_simple_terminal_normal.py:1'\r\nE           and: '\\r                                                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.08s):'\r\nE           and: '\\x1b[31m       1 error\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: 'collected 1 item'\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:37: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal0\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\nfile /tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal0/test_simple_terminal_normal.py, line 1\r\n  def test_foo(subtests):\r\nE       fixture 'subtests' not found\r\n>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave\r\n>       use 'pytest --fixtures [testpath]' for help on them.\r\n\r\n/tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal0/test_simple_terminal_normal.py:1\r\n                                                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.08s):\r\n       1 error\r\n\r\n tests/test_subtests.py::TestFixture.test_simple_terminal_normal[normal] \u2a2f                                                                                           5% \u258c         \r\n tests/test_subtests.py::TestFixture.test_simple_terminal_normal[xdist] s                                                                                           11% \u2588\u258f        \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestFixture.test_simple_terminal_verbose[normal] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestFixture object at 0x7f12c1a71090>, simple_script = None, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose0')>\r\nmode = 'normal'\r\n\r\n    def test_simple_terminal_verbose(self, simple_script, testdir, mode):\r\n        if mode == \"normal\":\r\n            result = testdir.runpytest(\"-v\")\r\n            expected_lines = [\r\n                \"*collected 1 item\",\r\n                \"test_simple_terminal_verbose.py::test_foo PASSED *100%*\",\r\n                \"test_simple_terminal_verbose.py::test_foo FAILED *100%*\",\r\n                \"test_simple_terminal_verbose.py::test_foo PASSED *100%*\",\r\n                \"test_simple_terminal_verbose.py::test_foo FAILED *100%*\",\r\n                \"test_simple_terminal_verbose.py::test_foo PASSED *100%*\",\r\n                \"test_simple_terminal_verbose.py::test_foo PASSED *100%*\",\r\n            ]\r\n        else:\r\n            pytest.importorskip(\"xdist\")\r\n            result = testdir.runpytest(\"-n1\", \"-v\")\r\n            expected_lines = [\r\n                \"gw0 [1]\",\r\n                \"*gw0*100%* test_simple_terminal_verbose.py::test_foo*\",\r\n                \"*gw0*100%* test_simple_terminal_verbose.py::test_foo*\",\r\n                \"*gw0*100%* test_simple_terminal_verbose.py::test_foo*\",\r\n                \"*gw0*100%* test_simple_terminal_verbose.py::test_foo*\",\r\n                \"*gw0*100%* test_simple_terminal_verbose.py::test_foo*\",\r\n                \"*gw0*100%* test_simple_terminal_verbose.py::test_foo*\",\r\n            ]\r\n    \r\n        expected_lines += [\r\n            \"* test_foo [[]custom[]] (i=1) *\",\r\n            \"* test_foo [[]custom[]] (i=3) *\",\r\n            \"* 2 failed, 1 passed in *\",\r\n        ]\r\n>       result.stdout.fnmatch_lines(expected_lines)\r\nE       Failed: nomatch: '*collected 1 item'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: 'cachedir: .pytest_cache'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose0'\r\nE           and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: 'collecting ... '\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: 'file /tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose0/test_simple_terminal_verbose.py, line 1'\r\nE           and: '  def test_foo(subtests):'\r\nE           and: \"E       fixture 'subtests' not found\"\r\nE           and: '>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave'\r\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\r\nE           and: ''\r\nE           and: '/tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose0/test_simple_terminal_verbose.py:1'\r\nE           and: '\\r                                                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.06s):'\r\nE           and: '\\x1b[31m       1 error\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: '*collected 1 item'\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:69: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\ncachedir: .pytest_cache\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose0\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\ncollecting ... \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\nfile /tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose0/test_simple_terminal_verbose.py, line 1\r\n  def test_foo(subtests):\r\nE       fixture 'subtests' not found\r\n>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave\r\n>       use 'pytest --fixtures [testpath]' for help on them.\r\n\r\n/tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose0/test_simple_terminal_verbose.py:1\r\n                                                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.06s):\r\n       1 error\r\n\r\n tests/test_subtests.py::TestFixture.test_simple_terminal_verbose[normal] \u2a2f                                                                                         16% \u2588\u258b        \r\n tests/test_subtests.py::TestFixture.test_simple_terminal_verbose[xdist] s                                                                                          21% \u2588\u2588\u258f       \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestFixture.test_skip[normal] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestFixture object at 0x7f12cdfb7990>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_skip0')>, mode = 'normal'\r\n\r\n    def test_skip(self, testdir, mode):\r\n        testdir.makepyfile(\r\n            \"\"\"\r\n            import pytest\r\n            def test_foo(subtests):\r\n                for i in range(5):\r\n                    with subtests.test(msg=\"custom\", i=i):\r\n                        if i % 2 == 0:\r\n                            pytest.skip('even number')\r\n        \"\"\"\r\n        )\r\n        if mode == \"normal\":\r\n            result = testdir.runpytest()\r\n            expected_lines = [\"collected 1 item\"]\r\n        else:\r\n            pytest.importorskip(\"xdist\")\r\n            result = testdir.runpytest(\"-n1\")\r\n            expected_lines = [\"gw0 [1]\"]\r\n        expected_lines += [\"* 1 passed, 3 skipped in *\"]\r\n>       result.stdout.fnmatch_lines(expected_lines)\r\nE       Failed: nomatch: 'collected 1 item'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_skip0'\r\nE           and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: 'file /tmp/pytest-of-fab/pytest-4/test_skip0/test_skip.py, line 2'\r\nE           and: '  def test_foo(subtests):'\r\nE           and: \"E       fixture 'subtests' not found\"\r\nE           and: '>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave'\r\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\r\nE           and: ''\r\nE           and: '/tmp/pytest-of-fab/pytest-4/test_skip0/test_skip.py:2'\r\nE           and: '\\r                                                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.06s):'\r\nE           and: '\\x1b[31m       1 error\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: 'collected 1 item'\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:90: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_skip0\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\nfile /tmp/pytest-of-fab/pytest-4/test_skip0/test_skip.py, line 2\r\n  def test_foo(subtests):\r\nE       fixture 'subtests' not found\r\n>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave\r\n>       use 'pytest --fixtures [testpath]' for help on them.\r\n\r\n/tmp/pytest-of-fab/pytest-4/test_skip0/test_skip.py:2\r\n                                                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.06s):\r\n       1 error\r\n\r\n tests/test_subtests.py::TestFixture.test_skip[normal] \u2a2f                                                                                                            26% \u2588\u2588\u258b       \r\n tests/test_subtests.py::TestFixture.test_skip[xdist] s                                                                                                             32% \u2588\u2588\u2588\u258e      \r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_normal[unittest] \u2713                                                                                        37% \u2588\u2588\u2588\u258a      \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestSubTest.test_simple_terminal_normal[pytest-normal] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestSubTest object at 0x7f12cdf6a750>, simple_script = local('/tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal3/test_simple_terminal_normal.py')\r\ntestdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal3')>, runner = 'pytest-normal'\r\n\r\n    @pytest.mark.parametrize(\"runner\", [\"unittest\", \"pytest-normal\", \"pytest-xdist\"])\r\n    def test_simple_terminal_normal(self, simple_script, testdir, runner):\r\n    \r\n        if runner == \"unittest\":\r\n            result = testdir.run(sys.executable, simple_script)\r\n            result.stderr.fnmatch_lines(\r\n                [\r\n                    \"FAIL: test_foo (__main__.T) [custom] (i=1)\",\r\n                    \"AssertionError: 1 != 0\",\r\n                    \"FAIL: test_foo (__main__.T) [custom] (i=3)\",\r\n                    \"AssertionError: 1 != 0\",\r\n                    \"Ran 1 test in *\",\r\n                    \"FAILED (failures=2)\",\r\n                ]\r\n            )\r\n        else:\r\n            if runner == \"pytest-normal\":\r\n                result = testdir.runpytest(simple_script)\r\n                expected_lines = [\"collected 1 item\"]\r\n            else:\r\n                pytest.importorskip(\"xdist\")\r\n                result = testdir.runpytest(simple_script, \"-n1\")\r\n                expected_lines = [\"gw0 [1]\"]\r\n            result.stdout.fnmatch_lines(\r\n                expected_lines\r\n                + [\r\n                    \"* T.test_foo [[]custom[]] (i=1) *\",\r\n                    \"E  * AssertionError: 1 != 0\",\r\n                    \"* T.test_foo [[]custom[]] (i=3) *\",\r\n                    \"E  * AssertionError: 1 != 0\",\r\n>                   \"* 2 failed, 1 passed in *\",\r\n                ]\r\n            )\r\nE           Failed: nomatch: 'collected 1 item'\r\nE               and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE               and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE               and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal3'\r\nE               and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE               and: ''\r\nE               and: ''\r\nE               and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE               and: ''\r\nE               and: 'self = <test_simple_terminal_normal.T testMethod=test_foo>'\r\nE               and: ''\r\nE               and: '    def test_foo(self):'\r\nE               and: '        for i in range(5):'\r\nE               and: '            with self.subTest(msg=\"custom\", i=i):'\r\nE               and: '>               self.assertEqual(i % 2, 0)'\r\nE               and: 'E               AssertionError: 1 != 0'\r\nE               and: ''\r\nE               and: 'test_simple_terminal_normal.py:8: AssertionError'\r\nE               and: '\\r'\r\nE               and: '\\r \\x1b[36m\\x1b[0mtest_simple_terminal_normal.py\\x1b[0m \\x1b[31m\u2a2f\\x1b[0m                                \\x1b[31m100% \\x1b[0m\\x1b[40m\\x1b[31m\u2588\\x1b[0m\\x1b[40m\\x1b[31m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE               and: '===Flaky Test Report==='\r\nE               and: ''\r\nE               and: ''\r\nE               and: '===End Flaky Test Report==='\r\nE               and: ''\r\nE               and: 'Results (0.08s):'\r\nE               and: '\\x1b[31m       1 failed\\x1b[0m'\r\nE               and: '         - \\x1b[36m\\x1b[0mtest_simple_terminal_normal.py\\x1b[0m:5 \\x1b[31mT.test_foo\\x1b[0m'\r\nE               and: ''\r\nE           remains unmatched: 'collected 1 item'\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:146: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_simple_terminal_normal3\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_simple_terminal_normal.T testMethod=test_foo>\r\n\r\n    def test_foo(self):\r\n        for i in range(5):\r\n            with self.subTest(msg=\"custom\", i=i):\r\n>               self.assertEqual(i % 2, 0)\r\nE               AssertionError: 1 != 0\r\n\r\ntest_simple_terminal_normal.py:8: AssertionError\r\n\r\n test_simple_terminal_normal.py \u2a2f                                100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.08s):\r\n       1 failed\r\n         - test_simple_terminal_normal.py:5 T.test_foo\r\n\r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_normal[pytest-normal] \u2a2f                                                                                   42% \u2588\u2588\u2588\u2588\u258e     \r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_normal[pytest-xdist] s                                                                                    47% \u2588\u2588\u2588\u2588\u258a     \r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_verbose[unittest] \u2713                                                                                       53% \u2588\u2588\u2588\u2588\u2588\u258d    \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestSubTest.test_simple_terminal_verbose[pytest-normal] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestSubTest object at 0x7f12cdefdad0>, simple_script = local('/tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose3/test_simple_terminal_verbose.py')\r\ntestdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose3')>, runner = 'pytest-normal'\r\n\r\n    @pytest.mark.parametrize(\"runner\", [\"unittest\", \"pytest-normal\", \"pytest-xdist\"])\r\n    def test_simple_terminal_verbose(self, simple_script, testdir, runner):\r\n    \r\n        if runner == \"unittest\":\r\n            result = testdir.run(sys.executable, simple_script, \"-v\")\r\n            result.stderr.fnmatch_lines(\r\n                [\r\n                    \"test_foo (__main__.T) ... \",\r\n                    \"FAIL: test_foo (__main__.T) [custom] (i=1)\",\r\n                    \"AssertionError: 1 != 0\",\r\n                    \"FAIL: test_foo (__main__.T) [custom] (i=3)\",\r\n                    \"AssertionError: 1 != 0\",\r\n                    \"Ran 1 test in *\",\r\n                    \"FAILED (failures=2)\",\r\n                ]\r\n            )\r\n        else:\r\n            if runner == \"pytest-normal\":\r\n                result = testdir.runpytest(simple_script, \"-v\")\r\n                expected_lines = [\r\n                    \"*collected 1 item\",\r\n                    \"test_simple_terminal_verbose.py::T::test_foo FAILED *100%*\",\r\n                    \"test_simple_terminal_verbose.py::T::test_foo FAILED *100%*\",\r\n                    \"test_simple_terminal_verbose.py::T::test_foo PASSED *100%*\",\r\n                ]\r\n            else:\r\n                pytest.importorskip(\"xdist\")\r\n                result = testdir.runpytest(simple_script, \"-n1\", \"-v\")\r\n                expected_lines = [\r\n                    \"gw0 [1]\",\r\n                    \"*gw0*100%* FAILED test_simple_terminal_verbose.py::T::test_foo*\",\r\n                    \"*gw0*100%* FAILED test_simple_terminal_verbose.py::T::test_foo*\",\r\n                    \"*gw0*100%* PASSED test_simple_terminal_verbose.py::T::test_foo*\",\r\n                ]\r\n            result.stdout.fnmatch_lines(\r\n                expected_lines\r\n                + [\r\n                    \"* T.test_foo [[]custom[]] (i=1) *\",\r\n                    \"E  * AssertionError: 1 != 0\",\r\n                    \"* T.test_foo [[]custom[]] (i=3) *\",\r\n                    \"E  * AssertionError: 1 != 0\",\r\n>                   \"* 2 failed, 1 passed in *\",\r\n                ]\r\n            )\r\nE           Failed: nomatch: '*collected 1 item'\r\nE               and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE               and: 'cachedir: .pytest_cache'\r\nE               and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE               and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose3'\r\nE               and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE               and: 'collecting ... '\r\nE               and: ''\r\nE               and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE               and: ''\r\nE               and: 'self = <test_simple_terminal_verbose.T testMethod=test_foo>'\r\nE               and: ''\r\nE               and: '    def test_foo(self):'\r\nE               and: '        for i in range(5):'\r\nE               and: '            with self.subTest(msg=\"custom\", i=i):'\r\nE               and: '>               self.assertEqual(i % 2, 0)'\r\nE               and: 'E               AssertionError: 1 != 0'\r\nE               and: ''\r\nE               and: 'test_simple_terminal_verbose.py:8: AssertionError'\r\nE               and: '\\r'\r\nE               and: '\\r \\x1b[36mtest_simple_terminal_verbose.py\\x1b[0m::T.test_foo\\x1b[0m \\x1b[31m\u2a2f\\x1b[0m                   \\x1b[31m100% \\x1b[0m\\x1b[40m\\x1b[31m\u2588\\x1b[0m\\x1b[40m\\x1b[31m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE               and: '===Flaky Test Report==='\r\nE               and: ''\r\nE               and: ''\r\nE               and: '===End Flaky Test Report==='\r\nE               and: ''\r\nE               and: 'Results (0.08s):'\r\nE               and: '\\x1b[31m       1 failed\\x1b[0m'\r\nE               and: '         - \\x1b[36m\\x1b[0mtest_simple_terminal_verbose.py\\x1b[0m:5 \\x1b[31mT.test_foo\\x1b[0m'\r\nE               and: ''\r\nE           remains unmatched: '*collected 1 item'\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:191: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\ncachedir: .pytest_cache\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_simple_terminal_verbose3\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\ncollecting ... \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_simple_terminal_verbose.T testMethod=test_foo>\r\n\r\n    def test_foo(self):\r\n        for i in range(5):\r\n            with self.subTest(msg=\"custom\", i=i):\r\n>               self.assertEqual(i % 2, 0)\r\nE               AssertionError: 1 != 0\r\n\r\ntest_simple_terminal_verbose.py:8: AssertionError\r\n\r\n test_simple_terminal_verbose.py::T.test_foo \u2a2f                   100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.08s):\r\n       1 failed\r\n         - test_simple_terminal_verbose.py:5 T.test_foo\r\n\r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_verbose[pytest-normal] \u2a2f                                                                                  58% \u2588\u2588\u2588\u2588\u2588\u258a    \r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_verbose[pytest-xdist] s                                                                                   63% \u2588\u2588\u2588\u2588\u2588\u2588\u258d   \r\n tests/test_subtests.py::TestSubTest.test_skip[unittest] \u2713                                                                                                          68% \u2588\u2588\u2588\u2588\u2588\u2588\u2589   \r\n tests/test_subtests.py::TestSubTest.test_skip[pytest-normal] x                                                                                                     74% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  \r\n tests/test_subtests.py::TestSubTest.test_skip[pytest-xdist] x                                                                                                      79% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestCapture.test_capturing \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestCapture object at 0x7f12c14c03d0>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_capturing0')>\r\n\r\n    def test_capturing(self, testdir):\r\n        self.create_file(testdir)\r\n        result = testdir.runpytest()\r\n        result.stdout.fnmatch_lines(\r\n            [\r\n                \"*__ test (i='A') __*\",\r\n                \"*Captured stdout call*\",\r\n                \"hello stdout A\",\r\n                \"*Captured stderr call*\",\r\n                \"hello stderr A\",\r\n                \"*__ test (i='B') __*\",\r\n                \"*Captured stdout call*\",\r\n                \"hello stdout B\",\r\n                \"*Captured stderr call*\",\r\n                \"hello stderr B\",\r\n                \"*__ test __*\",\r\n                \"*Captured stdout call*\",\r\n                \"start test\",\r\n>               \"end test\",\r\n            ]\r\n        )\r\nE       Failed: nomatch: \"*__ test (i='A') __*\"\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_capturing0'\r\nE           and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: 'file /tmp/pytest-of-fab/pytest-4/test_capturing0/test_capturing.py, line 2'\r\nE           and: '  def test(subtests):'\r\nE           and: \"E       fixture 'subtests' not found\"\r\nE           and: '>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave'\r\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\r\nE           and: ''\r\nE           and: '/tmp/pytest-of-fab/pytest-4/test_capturing0/test_capturing.py:2'\r\nE           and: '\\r                                                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.06s):'\r\nE           and: '\\x1b[31m       1 error\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: \"*__ test (i='A') __*\"\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:266: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_capturing0\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\nfile /tmp/pytest-of-fab/pytest-4/test_capturing0/test_capturing.py, line 2\r\n  def test(subtests):\r\nE       fixture 'subtests' not found\r\n>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave\r\n>       use 'pytest --fixtures [testpath]' for help on them.\r\n\r\n/tmp/pytest-of-fab/pytest-4/test_capturing0/test_capturing.py:2\r\n                                                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.06s):\r\n       1 error\r\n\r\n tests/test_subtests.py::TestCapture.test_capturing \u2a2f                                                                                                               84% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestCapture.test_no_capture \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestCapture object at 0x7f12c14d5810>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_no_capture0')>\r\n\r\n    def test_no_capture(self, testdir):\r\n        self.create_file(testdir)\r\n        result = testdir.runpytest(\"-s\")\r\n        result.stdout.fnmatch_lines(\r\n            [\r\n                \"start test\",\r\n                \"hello stdout A\",\r\n                \"Fhello stdout B\",\r\n                \"Fend test\",\r\n                \"*__ test (i='A') __*\",\r\n                \"*__ test (i='B') __*\",\r\n>               \"*__ test __*\",\r\n            ]\r\n        )\r\nE       Failed: nomatch: 'start test'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_no_capture0'\r\nE           and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: 'file /tmp/pytest-of-fab/pytest-4/test_no_capture0/test_no_capture.py, line 2'\r\nE           and: '  def test(subtests):'\r\nE           and: \"E       fixture 'subtests' not found\"\r\nE           and: '>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave'\r\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\r\nE           and: ''\r\nE           and: '/tmp/pytest-of-fab/pytest-4/test_no_capture0/test_no_capture.py:2'\r\nE           and: '\\r                                                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.06s):'\r\nE           and: '\\x1b[31m       1 error\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: 'start test'\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:281: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_no_capture0\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\nfile /tmp/pytest-of-fab/pytest-4/test_no_capture0/test_no_capture.py, line 2\r\n  def test(subtests):\r\nE       fixture 'subtests' not found\r\n>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave\r\n>       use 'pytest --fixtures [testpath]' for help on them.\r\n\r\n/tmp/pytest-of-fab/pytest-4/test_no_capture0/test_no_capture.py:2\r\n                                                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.06s):\r\n       1 error\r\n\r\n tests/test_subtests.py::TestCapture.test_no_capture \u2a2f                                                                                                              89% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestCapture.test_capture_with_fixture[capsys] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestCapture object at 0x7f12c1372ad0>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_capture_with_fixture0')>, fixture = 'capsys'\r\n\r\n    @pytest.mark.parametrize(\"fixture\", [\"capsys\", \"capfd\"])\r\n    def test_capture_with_fixture(self, testdir, fixture):\r\n        testdir.makepyfile(\r\n            r\"\"\"\r\n            import sys\r\n    \r\n            def test(subtests, {fixture}):\r\n                print('start test')\r\n    \r\n                with subtests.test(i='A'):\r\n                    print(\"hello stdout A\")\r\n                    print(\"hello stderr A\", file=sys.stderr)\r\n    \r\n                out, err = {fixture}.readouterr()\r\n                assert out == 'start test\\nhello stdout A\\n'\r\n                assert err == 'hello stderr A\\n'\r\n        \"\"\".format(\r\n                fixture=fixture\r\n            )\r\n        )\r\n        result = testdir.runpytest()\r\n        result.stdout.fnmatch_lines(\r\n>           [\"*1 passed*\",]\r\n        )\r\nE       Failed: nomatch: '*1 passed*'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_capture_with_fixture0'\r\nE           and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: 'file /tmp/pytest-of-fab/pytest-4/test_capture_with_fixture0/test_capture_with_fixture.py, line 3'\r\nE           and: '  def test(subtests, capsys):'\r\nE           and: \"E       fixture 'subtests' not found\"\r\nE           and: '>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave'\r\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\r\nE           and: ''\r\nE           and: '/tmp/pytest-of-fab/pytest-4/test_capture_with_fixture0/test_capture_with_fixture.py:3'\r\nE           and: '\\r                                                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.06s):'\r\nE           and: '\\x1b[31m       1 error\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: '*1 passed*'\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:308: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_capture_with_fixture0\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\nfile /tmp/pytest-of-fab/pytest-4/test_capture_with_fixture0/test_capture_with_fixture.py, line 3\r\n  def test(subtests, capsys):\r\nE       fixture 'subtests' not found\r\n>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave\r\n>       use 'pytest --fixtures [testpath]' for help on them.\r\n\r\n/tmp/pytest-of-fab/pytest-4/test_capture_with_fixture0/test_capture_with_fixture.py:3\r\n                                                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.06s):\r\n       1 error\r\n\r\n tests/test_subtests.py::TestCapture.test_capture_with_fixture[capsys] \u2a2f                                                                                            95% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestCapture.test_capture_with_fixture[capfd] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestCapture object at 0x7f12c1372210>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-4/test_capture_with_fixture1')>, fixture = 'capfd'\r\n\r\n    @pytest.mark.parametrize(\"fixture\", [\"capsys\", \"capfd\"])\r\n    def test_capture_with_fixture(self, testdir, fixture):\r\n        testdir.makepyfile(\r\n            r\"\"\"\r\n            import sys\r\n    \r\n            def test(subtests, {fixture}):\r\n                print('start test')\r\n    \r\n                with subtests.test(i='A'):\r\n                    print(\"hello stdout A\")\r\n                    print(\"hello stderr A\", file=sys.stderr)\r\n    \r\n                out, err = {fixture}.readouterr()\r\n                assert out == 'start test\\nhello stdout A\\n'\r\n                assert err == 'hello stderr A\\n'\r\n        \"\"\".format(\r\n                fixture=fixture\r\n            )\r\n        )\r\n        result = testdir.runpytest()\r\n        result.stdout.fnmatch_lines(\r\n>           [\"*1 passed*\",]\r\n        )\r\nE       Failed: nomatch: '*1 passed*'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-4/test_capture_with_fixture1'\r\nE           and: 'plugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: 'file /tmp/pytest-of-fab/pytest-4/test_capture_with_fixture1/test_capture_with_fixture.py, line 3'\r\nE           and: '  def test(subtests, capfd):'\r\nE           and: \"E       fixture 'subtests' not found\"\r\nE           and: '>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave'\r\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\r\nE           and: ''\r\nE           and: '/tmp/pytest-of-fab/pytest-4/test_capture_with_fixture1/test_capture_with_fixture.py:3'\r\nE           and: '\\r                                                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.04s):'\r\nE           and: '\\x1b[31m       1 error\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: '*1 passed*'\r\n\r\n/home/fab/Documents/repos/pytest-subtests/tests/test_subtests.py:308: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/pytest-subtests/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-4/test_capture_with_fixture1\r\nplugins: hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR at setup of test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\nfile /tmp/pytest-of-fab/pytest-4/test_capture_with_fixture1/test_capture_with_fixture.py, line 3\r\n  def test(subtests, capfd):\r\nE       fixture 'subtests' not found\r\n>       available fixtures: _dj_autoclear_mailbox, _django_clear_site_cache, _django_db_marker, _django_set_urlconf, _django_setup_unittest, _fail_for_invalid_template_variable, _live_server_helper, _template_string_if_invalid_marker, _vcr_marker, admin_client, admin_user, autojump_clock, betamax_parametrized_recorder, betamax_parametrized_session, betamax_recorder, betamax_session, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, cov, datafiles, db, django_assert_max_num_queries, django_assert_num_queries, django_db_blocker, django_db_createdb, django_db_keepdb, django_db_modify_db_settings, django_db_modify_db_settings_parallel_suffix, django_db_modify_db_settings_tox_suffix, django_db_modify_db_settings_xdist_suffix, django_db_reset_sequences, django_db_setup, django_db_use_migrations, django_mail_dnsname, django_mail_patch_dns, django_test_environment, django_user_model, django_username_field, doctest_namespace, event_loop, live_server, loop, mailoutbox, mock, mock_clock, mocker, monkeypatch, no_cover, nursery, patching, print_logs, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, requests_mock, rf, settings, smart_caplog, stdouts, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tmpworkdir, transactional_db, unused_tcp_port, unused_tcp_port_factory, vcr, vcr_cassette, vcr_cassette_dir, vcr_cassette_name, vcr_config, weave\r\n>       use 'pytest --fixtures [testpath]' for help on them.\r\n\r\n/tmp/pytest-of-fab/pytest-4/test_capture_with_fixture1/test_capture_with_fixture.py:3\r\n                                                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.04s):\r\n       1 error\r\n\r\n tests/test_subtests.py::TestCapture.test_capture_with_fixture[capfd] \u2a2f                                                                                            100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (6.78s):\r\n       3 passed\r\n       9 failed\r\n         - tests/test_subtests.py:23 TestFixture.test_simple_terminal_normal[normal]\r\n         - tests/test_subtests.py:39 TestFixture.test_simple_terminal_verbose[normal]\r\n         - tests/test_subtests.py:71 TestFixture.test_skip[normal]\r\n         - tests/test_subtests.py:116 TestSubTest.test_simple_terminal_normal[pytest-normal]\r\n         - tests/test_subtests.py:150 TestSubTest.test_simple_terminal_verbose[pytest-normal]\r\n         - tests/test_subtests.py:248 TestCapture.test_capturing\r\n         - tests/test_subtests.py:270 TestCapture.test_no_capture\r\n         - tests/test_subtests.py:286 TestCapture.test_capture_with_fixture[capsys]\r\n         - tests/test_subtests.py:286 TestCapture.test_capture_with_fixture[capfd]\r\n       2 xfailed\r\n       5 skipped\r\n```\r\n\r\n</details>\r\n\r\nAt least it seems that a fixture is not found.\r\n\r\n\r\nTests for 0.3.0 are failing as well during the RPM build process for Fedora.\r\n\r\n\r\n<details>\r\n\r\n```bash\r\n+ pytest-3.7 -v tests\r\n/usr/lib/python3.7/site-packages/trio/_core/_multierror.py:450: RuntimeWarning: You seem to already have a custom sys.excepthook handler installed. I'll skip installing trio's custom handler, but this means MultiErrors will not show full tracebacks.\r\n  category=RuntimeWarning\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\ncachedir: .pytest_cache\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\r\nrootdir: /home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0\r\nplugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\ncollecting ... \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestFixture.test_simple_terminal_normal[normal] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestFixture object at 0x7f9f46c9c290>, simple_script = None, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-1/test_simple_terminal_normal0')>\r\nmode = 'normal'\r\n\r\n    def test_simple_terminal_normal(self, simple_script, testdir, mode):\r\n        if mode == \"normal\":\r\n            result = testdir.runpytest()\r\n            expected_lines = [\"collected 1 item\"]\r\n        else:\r\n            pytest.importorskip(\"xdist\")\r\n            result = testdir.runpytest(\"-n1\")\r\n            expected_lines = [\"gw0 [1]\"]\r\n    \r\n        expected_lines += [\r\n            \"* test_foo [[]custom[]] (i=1) *\",\r\n            \"* test_foo [[]custom[]] (i=3) *\",\r\n            \"* 2 failed, 1 passed in *\",\r\n        ]\r\n>       result.stdout.fnmatch_lines(expected_lines)\r\nE       Failed: nomatch: 'collected 1 item'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-1/test_simple_terminal_normal0'\r\nE           and: 'plugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: '\\r'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test_foo [custom] (i=1) \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: ''\r\nE           and: \"subtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f46ea42d0>, suspend_capture_ctx=<bound method CaptureManager.gl... _in_suspended='<UNSET>'> _current_item=<Function test_foo>>>, request=<SubRequest 'subtests' for <Function test_foo>>)\"\r\nE           and: ''\r\nE           and: '    def test_foo(subtests):'\r\nE           and: '        for i in range(5):'\r\nE           and: '            with subtests.test(msg=\"custom\", i=i):'\r\nE           and: '>               assert i % 2 == 0'\r\nE           and: 'E               assert (1 % 2) == 0'\r\nE           and: ''\r\nE           and: 'test_simple_terminal_normal.py:4: AssertionError'\r\nE           and: '\\r'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test_foo [custom] (i=3) \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: ''\r\nE           and: \"subtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f46ea42d0>, suspend_capture_ctx=<bound method CaptureManager.gl... _in_suspended='<UNSET>'> _current_item=<Function test_foo>>>, request=<SubRequest 'subtests' for <Function test_foo>>)\"\r\nE           and: ''\r\nE           and: '    def test_foo(subtests):'\r\nE           and: '        for i in range(5):'\r\nE           and: '            with subtests.test(msg=\"custom\", i=i):'\r\nE           and: '>               assert i % 2 == 0'\r\nE           and: 'E               assert (3 % 2) == 0'\r\nE           and: ''\r\nE           and: 'test_simple_terminal_normal.py:4: AssertionError'\r\nE           and: '\\r'\r\nE           and: '\\r \\x1b[36m\\x1b[0mtest_simple_terminal_normal.py\\x1b[0m \\x1b[31m\u2a2f\\x1b[0m\\x1b[32m\u2713\\x1b[0m\\x1b[32m\u2713\\x1b[0m                              \\x1b[31m100% \\x1b[0m\\x1b[40m\\x1b[31m\u2588\\x1b[0m\\x1b[40m\\x1b[31m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.13s):'\r\nE           and: '\\x1b[32m       4 passed\\x1b[0m'\r\nE           and: '\\x1b[31m       2 failed\\x1b[0m'\r\nE           and: '         - \\x1b[36m\\x1b[0mtest_simple_terminal_normal.py\\x1b[0m:1 \\x1b[31mtest_foo\\x1b[0m'\r\nE           and: '         - \\x1b[36m\\x1b[0mtest_simple_terminal_normal.py\\x1b[0m:1 \\x1b[31mtest_foo\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: 'collected 1 item'\r\n\r\n/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/tests/test_subtests.py:37: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-1/test_simple_terminal_normal0\r\nplugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\r\n[...]\r\nrootdir: /tmp/pytest-of-fab/pytest-1/test_simple_terminal_normal3\r\nplugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo [custom] (i=1) \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_simple_terminal_normal.T testMethod=test_foo>\r\n\r\n    def test_foo(self):\r\n        for i in range(5):\r\n            with self.subTest(msg=\"custom\", i=i):\r\n>               self.assertEqual(i % 2, 0)\r\nE               AssertionError: 1 != 0\r\n\r\ntest_simple_terminal_normal.py:8: AssertionError\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo [custom] (i=3) \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_simple_terminal_normal.T testMethod=test_foo>\r\n\r\n    def test_foo(self):\r\n        for i in range(5):\r\n            with self.subTest(msg=\"custom\", i=i):\r\n>               self.assertEqual(i % 2, 0)\r\nE               AssertionError: 1 != 0\r\n\r\ntest_simple_terminal_normal.py:8: AssertionError\r\n\r\n test_simple_terminal_normal.py \u2a2f\u2713                               100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.07s):\r\n       1 passed\r\n       2 failed\r\n         - test_simple_terminal_normal.py:5 T.test_foo\r\n         - test_simple_terminal_normal.py:5 T.test_foo\r\n\r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_normal[pytest-normal] \u2a2f                                                                                   42% \u2588\u2588\u2588\u2588\u258e     \r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_normal[pytest-xdist] s                                                                                    47% \u2588\u2588\u2588\u2588\u258a     \r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_verbose[unittest] \u2713                                                                                       53% \u2588\u2588\u2588\u2588\u2588\u258d    \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestSubTest.test_simple_terminal_verbose[pytest-normal] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestSubTest object at 0x7f9f532ab3d0>, simple_script = local('/tmp/pytest-of-fab/pytest-1/test_simple_terminal_verbose3/test_simple_terminal_verbose.py')\r\ntestdir = <Testdir local('/tmp/pytest-of-fab/pytest-1/test_simple_terminal_verbose3')>, runner = 'pytest-normal'\r\n\r\n    @pytest.mark.parametrize(\"runner\", [\"unittest\", \"pytest-normal\", \"pytest-xdist\"])\r\n    def test_simple_terminal_verbose(self, simple_script, testdir, runner):\r\n    \r\n        if runner == \"unittest\":\r\n            result = testdir.run(sys.executable, simple_script, \"-v\")\r\n            result.stderr.fnmatch_lines(\r\n                [\r\n                    \"test_foo (__main__.T) ... \",\r\n                    \"FAIL: test_foo (__main__.T) [custom] (i=1)\",\r\n                    \"AssertionError: 1 != 0\",\r\n                    \"FAIL: test_foo (__main__.T) [custom] (i=3)\",\r\n                    \"AssertionError: 1 != 0\",\r\n                    \"Ran 1 test in *\",\r\n                    \"FAILED (failures=2)\",\r\n                ]\r\n            )\r\n        else:\r\n            if runner == \"pytest-normal\":\r\n                result = testdir.runpytest(simple_script, \"-v\")\r\n                expected_lines = [\r\n                    \"*collected 1 item\",\r\n                    \"test_simple_terminal_verbose.py::T::test_foo FAILED *100%*\",\r\n                    \"test_simple_terminal_verbose.py::T::test_foo FAILED *100%*\",\r\n                    \"test_simple_terminal_verbose.py::T::test_foo PASSED *100%*\",\r\n                ]\r\n            else:\r\n                pytest.importorskip(\"xdist\")\r\n                result = testdir.runpytest(simple_script, \"-n1\", \"-v\")\r\n                expected_lines = [\r\n                    \"gw0 [1]\",\r\n                    \"*gw0*100%* FAILED test_simple_terminal_verbose.py::T::test_foo*\",\r\n                    \"*gw0*100%* FAILED test_simple_terminal_verbose.py::T::test_foo*\",\r\n                    \"*gw0*100%* PASSED test_simple_terminal_verbose.py::T::test_foo*\",\r\n                ]\r\n            result.stdout.fnmatch_lines(\r\n                expected_lines\r\n                + [\r\n                    \"* T.test_foo [[]custom[]] (i=1) *\",\r\n                    \"E  * AssertionError: 1 != 0\",\r\n                    \"* T.test_foo [[]custom[]] (i=3) *\",\r\n                    \"E  * AssertionError: 1 != 0\",\r\n>                   \"* 2 failed, 1 passed in *\",\r\n                ]\r\n            )\r\nE           Failed: nomatch: '*collected 1 item'\r\nE               and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE               and: 'cachedir: .pytest_cache'\r\nE               and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\"\r\nE               and: 'rootdir: /tmp/pytest-of-fab/pytest-1/test_simple_terminal_verbose3'\r\nE               and: 'plugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE               and: 'collecting ... '\r\nE               and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo [custom] (i=1) \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE               and: ''\r\nE               and: 'self = <test_simple_terminal_verbose.T testMethod=test_foo>'\r\nE               and: ''\r\nE               and: '    def test_foo(self):'\r\nE               and: '        for i in range(5):'\r\nE               and: '            with self.subTest(msg=\"custom\", i=i):'\r\nE               and: '>               self.assertEqual(i % 2, 0)'\r\nE               and: 'E               AssertionError: 1 != 0'\r\nE               and: ''\r\nE               and: 'test_simple_terminal_verbose.py:8: AssertionError'\r\nE               and: '\\r'\r\nE               and: ''\r\nE               and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo [custom] (i=3) \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE               and: ''\r\nE               and: 'self = <test_simple_terminal_verbose.T testMethod=test_foo>'\r\nE               and: ''\r\nE               and: '    def test_foo(self):'\r\nE               and: '        for i in range(5):'\r\nE               and: '            with self.subTest(msg=\"custom\", i=i):'\r\nE               and: '>               self.assertEqual(i % 2, 0)'\r\nE               and: 'E               AssertionError: 1 != 0'\r\nE               and: ''\r\nE               and: 'test_simple_terminal_verbose.py:8: AssertionError'\r\nE               and: '\\r'\r\nE               and: '\\r \\x1b[36mtest_simple_terminal_verbose.py\\x1b[0m::T.test_foo\\x1b[0m \\x1b[31m\u2a2f\\x1b[0m\\x1b[32m\u2713\\x1b[0m                  \\x1b[31m100% \\x1b[0m\\x1b[40m\\x1b[31m\u2588\\x1b[0m\\x1b[40m\\x1b[31m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE               and: '===Flaky Test Report==='\r\nE               and: ''\r\nE               and: ''\r\nE               and: '===End Flaky Test Report==='\r\nE               and: ''\r\nE               and: 'Results (0.06s):'\r\nE               and: '\\x1b[32m       1 passed\\x1b[0m'\r\nE               and: '\\x1b[31m       2 failed\\x1b[0m'\r\nE               and: '         - \\x1b[36m\\x1b[0mtest_simple_terminal_verbose.py\\x1b[0m:5 \\x1b[31mT.test_foo\\x1b[0m'\r\nE               and: '         - \\x1b[36m\\x1b[0mtest_simple_terminal_verbose.py\\x1b[0m:5 \\x1b[31mT.test_foo\\x1b[0m'\r\nE               and: ''\r\nE           remains unmatched: '*collected 1 item'\r\n\r\n/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/tests/test_subtests.py:191: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\ncachedir: .pytest_cache\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-1/test_simple_terminal_verbose3\r\nplugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\ncollecting ... \r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo [custom] (i=1) \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_simple_terminal_verbose.T testMethod=test_foo>\r\n\r\n    def test_foo(self):\r\n        for i in range(5):\r\n            with self.subTest(msg=\"custom\", i=i):\r\n>               self.assertEqual(i % 2, 0)\r\nE               AssertionError: 1 != 0\r\n\r\ntest_simple_terminal_verbose.py:8: AssertionError\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 T.test_foo [custom] (i=3) \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_simple_terminal_verbose.T testMethod=test_foo>\r\n\r\n    def test_foo(self):\r\n        for i in range(5):\r\n            with self.subTest(msg=\"custom\", i=i):\r\n>               self.assertEqual(i % 2, 0)\r\nE               AssertionError: 1 != 0\r\n\r\ntest_simple_terminal_verbose.py:8: AssertionError\r\n\r\n test_simple_terminal_verbose.py::T.test_foo \u2a2f\u2713                  100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.06s):\r\n       1 passed\r\n       2 failed\r\n         - test_simple_terminal_verbose.py:5 T.test_foo\r\n         - test_simple_terminal_verbose.py:5 T.test_foo\r\n\r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_verbose[pytest-normal] \u2a2f                                                                                  58% \u2588\u2588\u2588\u2588\u2588\u258a    \r\n tests/test_subtests.py::TestSubTest.test_simple_terminal_verbose[pytest-xdist] s                                                                                   63% \u2588\u2588\u2588\u2588\u2588\u2588\u258d   \r\n tests/test_subtests.py::TestSubTest.test_skip[unittest] \u2713                                                                                                          68% \u2588\u2588\u2588\u2588\u2588\u2588\u2589   \r\n tests/test_subtests.py::TestSubTest.test_skip[pytest-normal] x                                                                                                     74% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  \r\n tests/test_subtests.py::TestSubTest.test_skip[pytest-xdist] x                                                                                                      79% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestCapture.test_capturing \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestCapture object at 0x7f9f468f91d0>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-1/test_capturing0')>\r\n\r\n    def test_capturing(self, testdir):\r\n        self.create_file(testdir)\r\n        result = testdir.runpytest()\r\n        result.stdout.fnmatch_lines(\r\n            [\r\n                \"*__ test (i='A') __*\",\r\n                \"*Captured stdout call*\",\r\n                \"hello stdout A\",\r\n                \"*Captured stderr call*\",\r\n                \"hello stderr A\",\r\n                \"*__ test (i='B') __*\",\r\n                \"*Captured stdout call*\",\r\n                \"hello stdout B\",\r\n                \"*Captured stderr call*\",\r\n                \"hello stderr B\",\r\n                \"*__ test __*\",\r\n                \"*Captured stdout call*\",\r\n                \"start test\",\r\n>               \"end test\",\r\n            ]\r\n        )\r\nE       Failed: nomatch: \"*__ test (i='A') __*\"\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-1/test_capturing0'\r\nE           and: 'plugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: ''\r\nE           and: ''\r\nE           and: \"\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test (i='A') \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\"\r\nE           and: ''\r\nE           and: \"subtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f4694c550>, suspend_capture_ctx=<bound method CaptureManager.gl...resumed' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\"\r\nE           and: ''\r\nE           and: '    def test(subtests):'\r\nE           and: '        print()'\r\nE           and: \"        print('start test')\"\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='A'):\"\r\nE           and: '            print(\"hello stdout A\")'\r\nE           and: '            print(\"hello stderr A\", file=sys.stderr)'\r\nE           and: '>           assert 0'\r\nE           and: 'E           assert 0'\r\nE           and: ''\r\nE           and: 'test_capturing.py:9: AssertionError'\r\nE           and: '----------------------------- Captured stdout call -----------------------------'\r\nE           and: 'hello stdout A'\r\nE           and: '----------------------------- Captured stderr call -----------------------------'\r\nE           and: 'hello stderr A'\r\nE           and: '\\r'\r\nE           and: ''\r\nE           and: ''\r\nE           and: \"\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test (i='B') \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\"\r\nE           and: ''\r\nE           and: \"subtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f4694c550>, suspend_capture_ctx=<bound method CaptureManager.gl...resumed' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\"\r\nE           and: ''\r\nE           and: '    def test(subtests):'\r\nE           and: '        print()'\r\nE           and: \"        print('start test')\"\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='A'):\"\r\nE           and: '            print(\"hello stdout A\")'\r\nE           and: '            print(\"hello stderr A\", file=sys.stderr)'\r\nE           and: '            assert 0'\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='B'):\"\r\nE           and: '            print(\"hello stdout B\")'\r\nE           and: '            print(\"hello stderr B\", file=sys.stderr)'\r\nE           and: '>           assert 0'\r\nE           and: 'E           assert 0'\r\nE           and: ''\r\nE           and: 'test_capturing.py:14: AssertionError'\r\nE           and: '----------------------------- Captured stdout call -----------------------------'\r\nE           and: 'hello stdout B'\r\nE           and: '----------------------------- Captured stderr call -----------------------------'\r\nE           and: 'hello stderr B'\r\nE           and: '\\r'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: ''\r\nE           and: \"subtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f4694c550>, suspend_capture_ctx=<bound method CaptureManager.gl...spended' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\"\r\nE           and: ''\r\nE           and: '    def test(subtests):'\r\nE           and: '        print()'\r\nE           and: \"        print('start test')\"\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='A'):\"\r\nE           and: '            print(\"hello stdout A\")'\r\nE           and: '            print(\"hello stderr A\", file=sys.stderr)'\r\nE           and: '            assert 0'\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='B'):\"\r\nE           and: '            print(\"hello stdout B\")'\r\nE           and: '            print(\"hello stderr B\", file=sys.stderr)'\r\nE           and: '            assert 0'\r\nE           and: '    '\r\nE           and: \"        print('end test')\"\r\nE           and: '>       assert 0'\r\nE           and: 'E       assert 0'\r\nE           and: ''\r\nE           and: 'test_capturing.py:17: AssertionError'\r\nE           and: '----------------------------- Captured stdout call -----------------------------'\r\nE           and: ''\r\nE           and: 'start test'\r\nE           and: 'end test'\r\nE           and: '\\r'\r\nE           and: '\\r \\x1b[36m\\x1b[0mtest_capturing.py\\x1b[0m \\x1b[31m\u2a2f\\x1b[0m                                             \\x1b[31m100% \\x1b[0m\\x1b[40m\\x1b[31m\u2588\\x1b[0m\\x1b[40m\\x1b[31m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.10s):'\r\nE           and: '\\x1b[31m       3 failed\\x1b[0m'\r\nE           and: '         - \\x1b[36m\\x1b[0mtest_capturing.py\\x1b[0m:2 \\x1b[31mtest\\x1b[0m'\r\nE           and: '         - \\x1b[36m\\x1b[0mtest_capturing.py\\x1b[0m:2 \\x1b[31mtest\\x1b[0m'\r\nE           and: '         - \\x1b[36m\\x1b[0mtest_capturing.py\\x1b[0m:2 \\x1b[31mtest\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: \"*__ test (i='A') __*\"\r\n\r\n/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/tests/test_subtests.py:266: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-1/test_capturing0\r\nplugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test (i='A') \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nsubtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f4694c550>, suspend_capture_ctx=<bound method CaptureManager.gl...resumed' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\r\n\r\n    def test(subtests):\r\n        print()\r\n        print('start test')\r\n    \r\n        with subtests.test(i='A'):\r\n            print(\"hello stdout A\")\r\n            print(\"hello stderr A\", file=sys.stderr)\r\n>           assert 0\r\nE           assert 0\r\n\r\ntest_capturing.py:9: AssertionError\r\n----------------------------- Captured stdout call -----------------------------\r\nhello stdout A\r\n----------------------------- Captured stderr call -----------------------------\r\nhello stderr A\r\n\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test (i='B') \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nsubtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f4694c550>, suspend_capture_ctx=<bound method CaptureManager.gl...resumed' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\r\n\r\n    def test(subtests):\r\n        print()\r\n        print('start test')\r\n    \r\n        with subtests.test(i='A'):\r\n            print(\"hello stdout A\")\r\n            print(\"hello stderr A\", file=sys.stderr)\r\n            assert 0\r\n    \r\n        with subtests.test(i='B'):\r\n            print(\"hello stdout B\")\r\n            print(\"hello stderr B\", file=sys.stderr)\r\n>           assert 0\r\nE           assert 0\r\n\r\ntest_capturing.py:14: AssertionError\r\n----------------------------- Captured stdout call -----------------------------\r\nhello stdout B\r\n----------------------------- Captured stderr call -----------------------------\r\nhello stderr B\r\n\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nsubtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f4694c550>, suspend_capture_ctx=<bound method CaptureManager.gl...spended' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\r\n\r\n    def test(subtests):\r\n        print()\r\n        print('start test')\r\n    \r\n        with subtests.test(i='A'):\r\n            print(\"hello stdout A\")\r\n            print(\"hello stderr A\", file=sys.stderr)\r\n            assert 0\r\n    \r\n        with subtests.test(i='B'):\r\n            print(\"hello stdout B\")\r\n            print(\"hello stderr B\", file=sys.stderr)\r\n            assert 0\r\n    \r\n        print('end test')\r\n>       assert 0\r\nE       assert 0\r\n\r\ntest_capturing.py:17: AssertionError\r\n----------------------------- Captured stdout call -----------------------------\r\n\r\nstart test\r\nend test\r\n\r\n test_capturing.py \u2a2f                                             100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.10s):\r\n       3 failed\r\n         - test_capturing.py:2 test\r\n         - test_capturing.py:2 test\r\n         - test_capturing.py:2 test\r\n\r\n tests/test_subtests.py::TestCapture.test_capturing \u2a2f                                                                                                               84% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestCapture.test_no_capture \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestCapture object at 0x7f9f4691e690>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-1/test_no_capture0')>\r\n\r\n    def test_no_capture(self, testdir):\r\n        self.create_file(testdir)\r\n        result = testdir.runpytest(\"-s\")\r\n        result.stdout.fnmatch_lines(\r\n            [\r\n                \"start test\",\r\n                \"hello stdout A\",\r\n                \"Fhello stdout B\",\r\n                \"Fend test\",\r\n                \"*__ test (i='A') __*\",\r\n                \"*__ test (i='B') __*\",\r\n>               \"*__ test __*\",\r\n            ]\r\n        )\r\nE       Failed: nomatch: 'start test'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-1/test_no_capture0'\r\nE           and: 'plugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: ''\r\nE       exact match: 'start test'\r\nE       exact match: 'hello stdout A'\r\nE       nomatch: 'Fhello stdout B'\r\nE           and: ''\r\nE           and: ''\r\nE           and: \"\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test (i='A') \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\"\r\nE           and: ''\r\nE           and: \"subtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f46838b90>, suspend_capture_ctx=<bound method CaptureManager.gl...resumed' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\"\r\nE           and: ''\r\nE           and: '    def test(subtests):'\r\nE           and: '        print()'\r\nE           and: \"        print('start test')\"\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='A'):\"\r\nE           and: '            print(\"hello stdout A\")'\r\nE           and: '            print(\"hello stderr A\", file=sys.stderr)'\r\nE           and: '>           assert 0'\r\nE           and: 'E           assert 0'\r\nE           and: ''\r\nE           and: 'test_no_capture.py:9: AssertionError'\r\nE           and: '\\r'\r\nE           and: 'hello stdout B'\r\nE           and: ''\r\nE           and: ''\r\nE           and: \"\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test (i='B') \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\"\r\nE           and: ''\r\nE           and: \"subtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f46838b90>, suspend_capture_ctx=<bound method CaptureManager.gl...resumed' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\"\r\nE           and: ''\r\nE           and: '    def test(subtests):'\r\nE           and: '        print()'\r\nE           and: \"        print('start test')\"\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='A'):\"\r\nE           and: '            print(\"hello stdout A\")'\r\nE           and: '            print(\"hello stderr A\", file=sys.stderr)'\r\nE           and: '            assert 0'\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='B'):\"\r\nE           and: '            print(\"hello stdout B\")'\r\nE           and: '            print(\"hello stderr B\", file=sys.stderr)'\r\nE           and: '>           assert 0'\r\nE           and: 'E           assert 0'\r\nE           and: ''\r\nE           and: 'test_no_capture.py:14: AssertionError'\r\nE           and: '\\r'\r\nE           and: 'end test'\r\nE           and: ''\r\nE           and: ''\r\nE           and: '\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015'\r\nE           and: ''\r\nE           and: \"subtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f46838b90>, suspend_capture_ctx=<bound method CaptureManager.gl...spended' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\"\r\nE           and: ''\r\nE           and: '    def test(subtests):'\r\nE           and: '        print()'\r\nE           and: \"        print('start test')\"\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='A'):\"\r\nE           and: '            print(\"hello stdout A\")'\r\nE           and: '            print(\"hello stderr A\", file=sys.stderr)'\r\nE           and: '            assert 0'\r\nE           and: '    '\r\nE           and: \"        with subtests.test(i='B'):\"\r\nE           and: '            print(\"hello stdout B\")'\r\nE           and: '            print(\"hello stderr B\", file=sys.stderr)'\r\nE           and: '            assert 0'\r\nE           and: '    '\r\nE           and: \"        print('end test')\"\r\nE           and: '>       assert 0'\r\nE           and: 'E       assert 0'\r\nE           and: ''\r\nE           and: 'test_no_capture.py:17: AssertionError'\r\nE           and: '\\r'\r\nE           and: '\\r \\x1b[36m\\x1b[0mtest_no_capture.py\\x1b[0m \\x1b[31m\u2a2f\\x1b[0m                                            \\x1b[31m100% \\x1b[0m\\x1b[40m\\x1b[31m\u2588\\x1b[0m\\x1b[40m\\x1b[31m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.06s):'\r\nE           and: '\\x1b[31m       3 failed\\x1b[0m'\r\nE           and: '         - \\x1b[36m\\x1b[0mtest_no_capture.py\\x1b[0m:2 \\x1b[31mtest\\x1b[0m'\r\nE           and: '         - \\x1b[36m\\x1b[0mtest_no_capture.py\\x1b[0m:2 \\x1b[31mtest\\x1b[0m'\r\nE           and: '         - \\x1b[36m\\x1b[0mtest_no_capture.py\\x1b[0m:2 \\x1b[31mtest\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: 'Fhello stdout B'\r\n\r\n/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/tests/test_subtests.py:281: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-1/test_no_capture0\r\nplugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\nstart test\r\nhello stdout A\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test (i='A') \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nsubtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f46838b90>, suspend_capture_ctx=<bound method CaptureManager.gl...resumed' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\r\n\r\n    def test(subtests):\r\n        print()\r\n        print('start test')\r\n    \r\n        with subtests.test(i='A'):\r\n            print(\"hello stdout A\")\r\n            print(\"hello stderr A\", file=sys.stderr)\r\n>           assert 0\r\nE           assert 0\r\n\r\ntest_no_capture.py:9: AssertionError\r\n\r\nhello stdout B\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test (i='B') \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nsubtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f46838b90>, suspend_capture_ctx=<bound method CaptureManager.gl...resumed' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\r\n\r\n    def test(subtests):\r\n        print()\r\n        print('start test')\r\n    \r\n        with subtests.test(i='A'):\r\n            print(\"hello stdout A\")\r\n            print(\"hello stderr A\", file=sys.stderr)\r\n            assert 0\r\n    \r\n        with subtests.test(i='B'):\r\n            print(\"hello stdout B\")\r\n            print(\"hello stderr B\", file=sys.stderr)\r\n>           assert 0\r\nE           assert 0\r\n\r\ntest_no_capture.py:14: AssertionError\r\n\r\nend test\r\n\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 test \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nsubtests = SubTests(ihook=<pluggy.hooks._HookRelay object at 0x7f9f46838b90>, suspend_capture_ctx=<bound method CaptureManager.gl...spended' _in_suspended='<UNSET>'> _current_item=<Function test>>>, request=<SubRequest 'subtests' for <Function test>>)\r\n\r\n    def test(subtests):\r\n        print()\r\n        print('start test')\r\n    \r\n        with subtests.test(i='A'):\r\n            print(\"hello stdout A\")\r\n            print(\"hello stderr A\", file=sys.stderr)\r\n            assert 0\r\n    \r\n        with subtests.test(i='B'):\r\n            print(\"hello stdout B\")\r\n            print(\"hello stderr B\", file=sys.stderr)\r\n            assert 0\r\n    \r\n        print('end test')\r\n>       assert 0\r\nE       assert 0\r\n\r\ntest_no_capture.py:17: AssertionError\r\n\r\n test_no_capture.py \u2a2f                                            100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.06s):\r\n       3 failed\r\n         - test_no_capture.py:2 test\r\n         - test_no_capture.py:2 test\r\n         - test_no_capture.py:2 test\r\n------------------------------------------------------------------------------ Captured stderr call ------------------------------------------------------------------------------\r\nhello stderr A\r\nhello stderr B\r\n\r\n tests/test_subtests.py::TestCapture.test_no_capture \u2a2f                                                                                                              89% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 \r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestCapture.test_capture_with_fixture[capsys] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestCapture object at 0x7f9f4677c3d0>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-1/test_capture_with_fixture0')>, fixture = 'capsys'\r\n\r\n    @pytest.mark.parametrize(\"fixture\", [\"capsys\", \"capfd\"])\r\n    def test_capture_with_fixture(self, testdir, fixture):\r\n        testdir.makepyfile(\r\n            r\"\"\"\r\n            import sys\r\n    \r\n            def test(subtests, {fixture}):\r\n                print('start test')\r\n    \r\n                with subtests.test(i='A'):\r\n                    print(\"hello stdout A\")\r\n                    print(\"hello stderr A\", file=sys.stderr)\r\n    \r\n                out, err = {fixture}.readouterr()\r\n                assert out == 'start test\\nhello stdout A\\n'\r\n                assert err == 'hello stderr A\\n'\r\n        \"\"\".format(\r\n                fixture=fixture\r\n            )\r\n        )\r\n        result = testdir.runpytest()\r\n        result.stdout.fnmatch_lines(\r\n>           [\"*1 passed*\",]\r\n        )\r\nE       Failed: nomatch: '*1 passed*'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-1/test_capture_with_fixture0'\r\nE           and: 'plugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: '\\r'\r\nE           and: '\\r \\x1b[36m\\x1b[0mtest_capture_with_fixture.py\\x1b[0m \\x1b[32m\u2713\\x1b[0m\\x1b[32m\u2713\\x1b[0m                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\\x1b[32m\u2588\\x1b[0m\\x1b[40m\\x1b[32m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.05s):'\r\nE           and: '\\x1b[32m       2 passed\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: '*1 passed*'\r\n\r\n/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/tests/test_subtests.py:308: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-1/test_capture_with_fixture0\r\nplugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n test_capture_with_fixture.py \u2713\u2713                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.05s):\r\n       2 passed\r\n\r\n tests/test_subtests.py::TestCapture.test_capture_with_fixture[capsys] \u2a2f                                                                                            95% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c\r\n\r\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 TestCapture.test_capture_with_fixture[capfd] \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\r\n\r\nself = <test_subtests.TestCapture object at 0x7f9f46788610>, testdir = <Testdir local('/tmp/pytest-of-fab/pytest-1/test_capture_with_fixture1')>, fixture = 'capfd'\r\n\r\n    @pytest.mark.parametrize(\"fixture\", [\"capsys\", \"capfd\"])\r\n    def test_capture_with_fixture(self, testdir, fixture):\r\n        testdir.makepyfile(\r\n            r\"\"\"\r\n            import sys\r\n    \r\n            def test(subtests, {fixture}):\r\n                print('start test')\r\n    \r\n                with subtests.test(i='A'):\r\n                    print(\"hello stdout A\")\r\n                    print(\"hello stderr A\", file=sys.stderr)\r\n    \r\n                out, err = {fixture}.readouterr()\r\n                assert out == 'start test\\nhello stdout A\\n'\r\n                assert err == 'hello stderr A\\n'\r\n        \"\"\".format(\r\n                fixture=fixture\r\n            )\r\n        )\r\n        result = testdir.runpytest()\r\n        result.stdout.fnmatch_lines(\r\n>           [\"*1 passed*\",]\r\n        )\r\nE       Failed: nomatch: '*1 passed*'\r\nE           and: 'Test session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)'\r\nE           and: \"hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\"\r\nE           and: 'rootdir: /tmp/pytest-of-fab/pytest-1/test_capture_with_fixture1'\r\nE           and: 'plugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0'\r\nE           and: '\\r'\r\nE           and: '\\r \\x1b[36m\\x1b[0mtest_capture_with_fixture.py\\x1b[0m \\x1b[32m\u2713\\x1b[0m\\x1b[32m\u2713\\x1b[0m                                 \\x1b[32m100% \\x1b[0m\\x1b[40m\\x1b[32m\u2588\\x1b[0m\\x1b[40m\\x1b[32m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\\x1b[0m'\r\nE           and: '===Flaky Test Report==='\r\nE           and: ''\r\nE           and: ''\r\nE           and: '===End Flaky Test Report==='\r\nE           and: ''\r\nE           and: 'Results (0.05s):'\r\nE           and: '\\x1b[32m       2 passed\\x1b[0m'\r\nE           and: ''\r\nE       remains unmatched: '*1 passed*'\r\n\r\n/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/tests/test_subtests.py:308: Failed\r\n------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------\r\nTest session starts (platform: linux, Python 3.7.6, pytest 4.6.9, pytest-sugar 0.9.2)\r\nhypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/fab/Documents/repos/rpmbuild/BUILD/pytest-subtests-0.3.0/.hypothesis/examples')\r\nrootdir: /tmp/pytest-of-fab/pytest-1/test_capture_with_fixture1\r\nplugins: subtests-0.3.0, hypothesis-4.23.8, requests-mock-1.7.0, case-1.5.3, sugar-0.9.2, betamax-0.8.1, asyncio-0.10.0, toolbox-0.4, timeout-1.3.3, cov-2.8.1, isort-0.3.1, forked-1.0.2, datafiles-2.0, vcr-1.0.2, aspectlib-1.4.2, mock-1.10.4, trio-0.5.2, flaky-3.5.3, django-3.7.0\r\n\r\n test_capture_with_fixture.py \u2713\u2713                                 100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (0.05s):\r\n       2 passed\r\n\r\n tests/test_subtests.py::TestCapture.test_capture_with_fixture[capfd] \u2a2f                                                                                            100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\n===Flaky Test Report===\r\n\r\n\r\n===End Flaky Test Report===\r\n\r\nResults (5.99s):\r\n       3 passed\r\n       9 failed\r\n         - tests/test_subtests.py:23 TestFixture.test_simple_terminal_normal[normal]\r\n         - tests/test_subtests.py:39 TestFixture.test_simple_terminal_verbose[normal]\r\n         - tests/test_subtests.py:71 TestFixture.test_skip[normal]\r\n         - tests/test_subtests.py:116 TestSubTest.test_simple_terminal_normal[pytest-normal]\r\n         - tests/test_subtests.py:150 TestSubTest.test_simple_terminal_verbose[pytest-normal]\r\n         - tests/test_subtests.py:248 TestCapture.test_capturing\r\n         - tests/test_subtests.py:270 TestCapture.test_no_capture\r\n         - tests/test_subtests.py:286 TestCapture.test_capture_with_fixture[capsys]\r\n         - tests/test_subtests.py:286 TestCapture.test_capture_with_fixture[capfd]\r\n       2 xfailed\r\n       5 skipped\r\nerror: Bad exit status from /var/tmp/rpm-tmp.U5gasx (%check)\r\n\r\n```\r\n\r\n</details>", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/18", "repository_url": "https://api.github.com/repos/pytest-dev/pytest-subtests", "labels_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/18/labels{/name}", "comments_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/18/comments", "events_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/18/events", "html_url": "https://github.com/pytest-dev/pytest-subtests/issues/18", "id": 474247443, "node_id": "MDU6SXNzdWU0NzQyNDc0NDM=", "number": 18, "title": "No logs?", "user": {"login": "tzachshabtay", "id": 1819001, "node_id": "MDQ6VXNlcjE4MTkwMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1819001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tzachshabtay", "html_url": "https://github.com/tzachshabtay", "followers_url": "https://api.github.com/users/tzachshabtay/followers", "following_url": "https://api.github.com/users/tzachshabtay/following{/other_user}", "gists_url": "https://api.github.com/users/tzachshabtay/gists{/gist_id}", "starred_url": "https://api.github.com/users/tzachshabtay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tzachshabtay/subscriptions", "organizations_url": "https://api.github.com/users/tzachshabtay/orgs", "repos_url": "https://api.github.com/users/tzachshabtay/repos", "events_url": "https://api.github.com/users/tzachshabtay/events{/privacy}", "received_events_url": "https://api.github.com/users/tzachshabtay/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1280747412, "node_id": "MDU6TGFiZWwxMjgwNzQ3NDEy", "url": "https://api.github.com/repos/pytest-dev/pytest-subtests/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-07-29T20:43:45Z", "updated_at": "2020-06-10T23:45:30Z", "closed_at": "2020-01-23T00:02:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thanks for the plugin, subtests are properly named now. However...\r\n\r\nAfter installing the plugin the whole section in the output showing the logs is gone (i.e the `\"Captured stdout call\"` and `\"Captured log call\"` that appear in the bottom without this plugin).\r\n\r\nIt's very hard to debug failing tests without logs, making this plugin currently unusable for me.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/16", "repository_url": "https://api.github.com/repos/pytest-dev/pytest-subtests", "labels_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/16/labels{/name}", "comments_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/16/comments", "events_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/16/events", "html_url": "https://github.com/pytest-dev/pytest-subtests/issues/16", "id": 443074860, "node_id": "MDU6SXNzdWU0NDMwNzQ4NjA=", "number": 16, "title": "Question: subtests and pytest-xdist", "user": {"login": "liiight", "id": 4374581, "node_id": "MDQ6VXNlcjQzNzQ1ODE=", "avatar_url": "https://avatars3.githubusercontent.com/u/4374581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liiight", "html_url": "https://github.com/liiight", "followers_url": "https://api.github.com/users/liiight/followers", "following_url": "https://api.github.com/users/liiight/following{/other_user}", "gists_url": "https://api.github.com/users/liiight/gists{/gist_id}", "starred_url": "https://api.github.com/users/liiight/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liiight/subscriptions", "organizations_url": "https://api.github.com/users/liiight/orgs", "repos_url": "https://api.github.com/users/liiight/repos", "events_url": "https://api.github.com/users/liiight/events{/privacy}", "received_events_url": "https://api.github.com/users/liiight/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-05-12T07:33:08Z", "updated_at": "2019-05-12T09:02:40Z", "closed_at": "2019-05-12T09:02:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have started using subtests and I'm loving it. Would it be possible (and feasible) to make subtest work with xdist in order to parallelize the test executions?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/13", "repository_url": "https://api.github.com/repos/pytest-dev/pytest-subtests", "labels_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/13/labels{/name}", "comments_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/13/comments", "events_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/13/events", "html_url": "https://github.com/pytest-dev/pytest-subtests/issues/13", "id": 431649569, "node_id": "MDU6SXNzdWU0MzE2NDk1Njk=", "number": 13, "title": "Fixture to make all assertions into their own subtest", "user": {"login": "apnewberry", "id": 31109952, "node_id": "MDQ6VXNlcjMxMTA5OTUy", "avatar_url": "https://avatars1.githubusercontent.com/u/31109952?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apnewberry", "html_url": "https://github.com/apnewberry", "followers_url": "https://api.github.com/users/apnewberry/followers", "following_url": "https://api.github.com/users/apnewberry/following{/other_user}", "gists_url": "https://api.github.com/users/apnewberry/gists{/gist_id}", "starred_url": "https://api.github.com/users/apnewberry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apnewberry/subscriptions", "organizations_url": "https://api.github.com/users/apnewberry/orgs", "repos_url": "https://api.github.com/users/apnewberry/repos", "events_url": "https://api.github.com/users/apnewberry/events{/privacy}", "received_events_url": "https://api.github.com/users/apnewberry/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-10T18:30:38Z", "updated_at": "2019-04-11T13:07:45Z", "closed_at": "2019-04-11T13:07:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Currently the usage requires a context manager, like this:\r\n\r\n```python\r\ndef test(subtests):\r\n    for i in range(5):\r\n        with subtests.test(msg=\"custom message\", i=i):\r\n            assert i % 2 == 0\r\n```\r\n\r\nOften I want to have a subtest for each assert statement so that I can see all of the failures individually. So for example\r\n\r\n\r\n```python\r\ndef test(assert_subtests):\r\n    for i in range(5):        \r\n        assert i % 2 == 0\r\n```\r\n\r\n\r\nI'm not sure what possible implementations would look like. Would this require a major reimplementation of the assertion rewriting?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/12", "repository_url": "https://api.github.com/repos/pytest-dev/pytest-subtests", "labels_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/12/labels{/name}", "comments_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/12/comments", "events_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/12/events", "html_url": "https://github.com/pytest-dev/pytest-subtests/issues/12", "id": 430092372, "node_id": "MDU6SXNzdWU0MzAwOTIzNzI=", "number": 12, "title": "htmlrunner report does not display passed subtests using unittest (selenium+python).", "user": {"login": "ankurgupta02", "id": 49353604, "node_id": "MDQ6VXNlcjQ5MzUzNjA0", "avatar_url": "https://avatars3.githubusercontent.com/u/49353604?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ankurgupta02", "html_url": "https://github.com/ankurgupta02", "followers_url": "https://api.github.com/users/ankurgupta02/followers", "following_url": "https://api.github.com/users/ankurgupta02/following{/other_user}", "gists_url": "https://api.github.com/users/ankurgupta02/gists{/gist_id}", "starred_url": "https://api.github.com/users/ankurgupta02/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ankurgupta02/subscriptions", "organizations_url": "https://api.github.com/users/ankurgupta02/orgs", "repos_url": "https://api.github.com/users/ankurgupta02/repos", "events_url": "https://api.github.com/users/ankurgupta02/events{/privacy}", "received_events_url": "https://api.github.com/users/ankurgupta02/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-04-07T01:02:57Z", "updated_at": "2019-04-11T11:28:06Z", "closed_at": "2019-04-11T11:28:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "htmlrunner report does not display passed subtests using unittest (selenium+python).\r\nCan anyone help me?\r\n\r\nI have created a method which iterates multiple times for all links available on webpage. Also, validating the links url (current and expected) via assertion. htmlrunner generating the report for all those link whose urls are not equal but I want that htmlrunner report should also generate for passed links as well.\r\n\r\nThanks in advance.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/7", "repository_url": "https://api.github.com/repos/pytest-dev/pytest-subtests", "labels_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/7/labels{/name}", "comments_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/7/comments", "events_url": "https://api.github.com/repos/pytest-dev/pytest-subtests/issues/7/events", "html_url": "https://github.com/pytest-dev/pytest-subtests/issues/7", "id": 428566829, "node_id": "MDU6SXNzdWU0Mjg1NjY4Mjk=", "number": 7, "title": "verbose output confusing, as it shows test passed", "user": {"login": "okken", "id": 1568356, "node_id": "MDQ6VXNlcjE1NjgzNTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1568356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/okken", "html_url": "https://github.com/okken", "followers_url": "https://api.github.com/users/okken/followers", "following_url": "https://api.github.com/users/okken/following{/other_user}", "gists_url": "https://api.github.com/users/okken/gists{/gist_id}", "starred_url": "https://api.github.com/users/okken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/okken/subscriptions", "organizations_url": "https://api.github.com/users/okken/orgs", "repos_url": "https://api.github.com/users/okken/repos", "events_url": "https://api.github.com/users/okken/events{/privacy}", "received_events_url": "https://api.github.com/users/okken/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2019-04-03T04:58:11Z", "updated_at": "2019-04-04T22:08:49Z", "closed_at": "2019-04-04T22:08:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "The example given in the readme is kinda weird when passed the `-v` flag.\r\n\r\n```\r\n(subtest) $ pytest -v test_sub_pytest.py  --tb=no\r\n================= test session starts =================\r\nplatform darwin -- Python 3.8.0a1, pytest-4.4.0, py-1.8.0, pluggy-0.9.0 -- \r\nplugins: subtests-0.1.0\r\ncollected 1 item                                      \r\n\r\ntest_sub_pytest.py::test \r\ntest_sub_pytest.py::test PASSED                 [100%]\r\n\r\n========= 2 failed, 1 passed in 0.05 seconds ==========\r\n```\r\n\r\nThe double `::test` is a bit odd.\r\nAs is the `PASSED`.\r\nAnd, well, with 1 test that has 5 subtests, where does the `2 failed 1 passed` come from?\r\nSpecifically, the `1 passed`?\r\n", "performed_via_github_app": null, "score": 1.0}]}