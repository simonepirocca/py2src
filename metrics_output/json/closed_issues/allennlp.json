{"total_count": 1968, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/allenai/allennlp/issues/4571", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4571/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4571/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4571/events", "html_url": "https://github.com/allenai/allennlp/issues/4571", "id": 680847708, "node_id": "MDU6SXNzdWU2ODA4NDc3MDg=", "number": 4571, "title": "https://raw.githubusercontent.com/allenai/allennlp/master/tutorials/tagger/training.txt with status code 404", "user": {"login": "heheda-sys", "id": 59784945, "node_id": "MDQ6VXNlcjU5Nzg0OTQ1", "avatar_url": "https://avatars3.githubusercontent.com/u/59784945?v=4", "gravatar_id": "", "url": "https://api.github.com/users/heheda-sys", "html_url": "https://github.com/heheda-sys", "followers_url": "https://api.github.com/users/heheda-sys/followers", "following_url": "https://api.github.com/users/heheda-sys/following{/other_user}", "gists_url": "https://api.github.com/users/heheda-sys/gists{/gist_id}", "starred_url": "https://api.github.com/users/heheda-sys/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/heheda-sys/subscriptions", "organizations_url": "https://api.github.com/users/heheda-sys/orgs", "repos_url": "https://api.github.com/users/heheda-sys/repos", "events_url": "https://api.github.com/users/heheda-sys/events{/privacy}", "received_events_url": "https://api.github.com/users/heheda-sys/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-08-18T09:33:16Z", "updated_at": "2020-08-18T21:28:17Z", "closed_at": "2020-08-18T21:28:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi.\r\n\r\nIn the code that runs  **LSTM for Part-of-Speech Tagging**, I have an error here.\r\n**OSError: HEAD request failed for url https://raw.githubusercontent.com/allenai/allennlp/master/tutorials/tagger/training.txt with status code 404**.\r\nWhere can I find the training files.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4565", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4565/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4565/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4565/events", "html_url": "https://github.com/allenai/allennlp/issues/4565", "id": 680161626, "node_id": "MDU6SXNzdWU2ODAxNjE2MjY=", "number": 4565, "title": "Corpus NER whitout Pos-Tag and Chunk-Tag", "user": {"login": "calusbr", "id": 25322394, "node_id": "MDQ6VXNlcjI1MzIyMzk0", "avatar_url": "https://avatars0.githubusercontent.com/u/25322394?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calusbr", "html_url": "https://github.com/calusbr", "followers_url": "https://api.github.com/users/calusbr/followers", "following_url": "https://api.github.com/users/calusbr/following{/other_user}", "gists_url": "https://api.github.com/users/calusbr/gists{/gist_id}", "starred_url": "https://api.github.com/users/calusbr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calusbr/subscriptions", "organizations_url": "https://api.github.com/users/calusbr/orgs", "repos_url": "https://api.github.com/users/calusbr/repos", "events_url": "https://api.github.com/users/calusbr/events{/privacy}", "received_events_url": "https://api.github.com/users/calusbr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-17T11:27:15Z", "updated_at": "2020-08-21T16:04:01Z", "closed_at": "2020-08-21T16:04:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, I have a problem with my NER execution. I have a Corpus NER with only NER tag and no pos-tag and chunk-tag options, how can I run my experiment? Are there any parameters I can change in my .jsonnet?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4564", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4564/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4564/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4564/events", "html_url": "https://github.com/allenai/allennlp/issues/4564", "id": 679663965, "node_id": "MDU6SXNzdWU2Nzk2NjM5NjU=", "number": 4564, "title": "Wrong metrics calculations when running in distributed mode ", "user": {"login": "eladsegal", "id": 13485709, "node_id": "MDQ6VXNlcjEzNDg1NzA5", "avatar_url": "https://avatars3.githubusercontent.com/u/13485709?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eladsegal", "html_url": "https://github.com/eladsegal", "followers_url": "https://api.github.com/users/eladsegal/followers", "following_url": "https://api.github.com/users/eladsegal/following{/other_user}", "gists_url": "https://api.github.com/users/eladsegal/gists{/gist_id}", "starred_url": "https://api.github.com/users/eladsegal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eladsegal/subscriptions", "organizations_url": "https://api.github.com/users/eladsegal/orgs", "repos_url": "https://api.github.com/users/eladsegal/repos", "events_url": "https://api.github.com/users/eladsegal/events{/privacy}", "received_events_url": "https://api.github.com/users/eladsegal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-08-16T00:23:56Z", "updated_at": "2020-08-19T21:52:54Z", "closed_at": "2020-08-19T21:52:54Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## Version\r\nv1.1.0rc3\r\n\r\n## Description\r\n`BooleanAccuracy` and `CategoricalAccuracy` (and possibly other metrics) are not calculated correctly when running in distributed mode, causing them to return `nan`.\r\n\r\nIt is caused by repeated addition of an accumulated variable with itself with each call to update the metric, resulting in an exponential growth until it gets to a value of `inf` (and when `inf` is divided by `inf` the result is `nan`).\r\nhttps://github.com/allenai/allennlp/blob/v1.1.0rc3/allennlp/training/metrics/categorical_accuracy.py#L102-L108\r\n\r\n## Steps to reproduce\r\nI've encountered the issue when I used `BooleanAccuracy` and `CategoricalAccuracy`, but from quickly looking at the code of other metrics it is possible it can occur for some of them as well.\r\n\r\nClone [allennlp-models](https://github.com/allenai/allennlp-models), switch to tag `v1.1.0rc3` and run the following from it:\r\n```allennlp train training_config/rc/transformer_qa_distributed.jsonnet -s training_dir -o '{\"dataset_reader\": {\"max_instances\": 2000}, \"validation_dataset_reader\": {\"max_instances\": 10}}'```\r\n\r\nAfter less than 200 training steps the metrics `start_acc`, `end_acc` (CategoricalAccuracy) and `span_acc` (BooleanAccuracy) will be `nan`.\r\n\r\n## Fix\r\nA fix for `BooleanAccuracy` and `CategoricalAccuracy` is [here](https://github.com/eladsegal/allennlp/commit/564fbb727b8a7d7b9959fa2ebe9d3f64dbc3e808).\r\nI currently don't have time to verify and fix other metrics, so let me know if you'd like me to create a pull request just for these two.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4563", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4563/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4563/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4563/events", "html_url": "https://github.com/allenai/allennlp/issues/4563", "id": 679614635, "node_id": "MDU6SXNzdWU2Nzk2MTQ2MzU=", "number": 4563, "title": "ImportError: cannot import name 'PretrainedBertIndexer'", "user": {"login": "Mayar2009", "id": 38237790, "node_id": "MDQ6VXNlcjM4MjM3Nzkw", "avatar_url": "https://avatars2.githubusercontent.com/u/38237790?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mayar2009", "html_url": "https://github.com/Mayar2009", "followers_url": "https://api.github.com/users/Mayar2009/followers", "following_url": "https://api.github.com/users/Mayar2009/following{/other_user}", "gists_url": "https://api.github.com/users/Mayar2009/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mayar2009/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mayar2009/subscriptions", "organizations_url": "https://api.github.com/users/Mayar2009/orgs", "repos_url": "https://api.github.com/users/Mayar2009/repos", "events_url": "https://api.github.com/users/Mayar2009/events{/privacy}", "received_events_url": "https://api.github.com/users/Mayar2009/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-15T17:38:52Z", "updated_at": "2020-08-21T15:47:16Z", "closed_at": "2020-08-21T15:47:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi!\r\nI have this code \r\n\r\n```\r\nfrom allennlp.data.token_indexers import PretrainedBertIndexer\r\n\r\ntoken_indexer = PretrainedBertIndexer(\r\n    pretrained_model=\"bert-base-uncased\",\r\n    max_pieces=config.max_seq_len,\r\n    do_lowercase=True,\r\n )\r\n\r\ndef tokenizer(s: str):\r\n    return token_indexer.wordpiece_tokenizer(s)[:config.max_seq_len - 2]\r\n```\r\n\r\ngives this error \r\n\r\nImportError: cannot import name 'PretrainedBertIndexer'\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4559", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4559/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4559/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4559/events", "html_url": "https://github.com/allenai/allennlp/issues/4559", "id": 679397747, "node_id": "MDU6SXNzdWU2NzkzOTc3NDc=", "number": 4559, "title": "Ignore this issue, I'm testing a bot to autoclose stale issues", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2276693919, "node_id": "MDU6TGFiZWwyMjc2NjkzOTE5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "aaaaaa", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-14T20:57:10Z", "updated_at": "2020-08-14T21:54:11Z", "closed_at": "2020-08-14T21:54:11Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4553", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4553/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4553/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4553/events", "html_url": "https://github.com/allenai/allennlp/issues/4553", "id": 677730380, "node_id": "MDU6SXNzdWU2Nzc3MzAzODA=", "number": 4553, "title": "Text to sql atis training set", "user": {"login": "nagumamta", "id": 50141588, "node_id": "MDQ6VXNlcjUwMTQxNTg4", "avatar_url": "https://avatars3.githubusercontent.com/u/50141588?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nagumamta", "html_url": "https://github.com/nagumamta", "followers_url": "https://api.github.com/users/nagumamta/followers", "following_url": "https://api.github.com/users/nagumamta/following{/other_user}", "gists_url": "https://api.github.com/users/nagumamta/gists{/gist_id}", "starred_url": "https://api.github.com/users/nagumamta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nagumamta/subscriptions", "organizations_url": "https://api.github.com/users/nagumamta/orgs", "repos_url": "https://api.github.com/users/nagumamta/repos", "events_url": "https://api.github.com/users/nagumamta/events{/privacy}", "received_events_url": "https://api.github.com/users/nagumamta/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-12T14:18:04Z", "updated_at": "2020-08-14T14:28:17Z", "closed_at": "2020-08-14T14:28:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am working  on text to sql(atis),  i created model using experiment.json and sample.json,  present  in the tests\\fixtures, used the same  model to predict,  but predicted values are 0 even for the  utterance present in sample.json\r\n\r\ncan u plz point out what  is wrong and can u plz provide entire training set (as i noticed that  sample.json has only 14 utterance)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4552", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4552/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4552/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4552/events", "html_url": "https://github.com/allenai/allennlp/issues/4552", "id": 677526703, "node_id": "MDU6SXNzdWU2Nzc1MjY3MDM=", "number": 4552, "title": "Question regarding model interpretations", "user": {"login": "heytitle", "id": 1214890, "node_id": "MDQ6VXNlcjEyMTQ4OTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1214890?v=4", "gravatar_id": "", "url": "https://api.github.com/users/heytitle", "html_url": "https://github.com/heytitle", "followers_url": "https://api.github.com/users/heytitle/followers", "following_url": "https://api.github.com/users/heytitle/following{/other_user}", "gists_url": "https://api.github.com/users/heytitle/gists{/gist_id}", "starred_url": "https://api.github.com/users/heytitle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/heytitle/subscriptions", "organizations_url": "https://api.github.com/users/heytitle/orgs", "repos_url": "https://api.github.com/users/heytitle/repos", "events_url": "https://api.github.com/users/heytitle/events{/privacy}", "received_events_url": "https://api.github.com/users/heytitle/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-12T09:04:13Z", "updated_at": "2020-08-14T04:44:56Z", "closed_at": "2020-08-14T04:44:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nMay I ask a couple of questions regarding model interpretations?\r\n1. Is it common to use SmoothGrad in NLP? It's a bit counterintuitive to me because embeddings are static.\r\n2. When visualizing contribution scores, is it common to select top K tokens for the visualization?\r\n<img width=\"825\" alt=\"image\" src=\"https://user-images.githubusercontent.com/1214890/89996495-26ef4000-dc8b-11ea-8fc8-1b9e6aec286a.png\">\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4551", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4551/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4551/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4551/events", "html_url": "https://github.com/allenai/allennlp/issues/4551", "id": 677524829, "node_id": "MDU6SXNzdWU2Nzc1MjQ4Mjk=", "number": 4551, "title": "Can we support multi-dataset when training \uff1f", "user": {"login": "wlhgtc", "id": 16603773, "node_id": "MDQ6VXNlcjE2NjAzNzcz", "avatar_url": "https://avatars2.githubusercontent.com/u/16603773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wlhgtc", "html_url": "https://github.com/wlhgtc", "followers_url": "https://api.github.com/users/wlhgtc/followers", "following_url": "https://api.github.com/users/wlhgtc/following{/other_user}", "gists_url": "https://api.github.com/users/wlhgtc/gists{/gist_id}", "starred_url": "https://api.github.com/users/wlhgtc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wlhgtc/subscriptions", "organizations_url": "https://api.github.com/users/wlhgtc/orgs", "repos_url": "https://api.github.com/users/wlhgtc/repos", "events_url": "https://api.github.com/users/wlhgtc/events{/privacy}", "received_events_url": "https://api.github.com/users/wlhgtc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-12T09:01:31Z", "updated_at": "2020-08-14T09:40:05Z", "closed_at": "2020-08-14T09:33:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I am reproduce an seq2seq model in Open-NMT, \r\nI wonder if we could  support param like `data weight`  in NMT, specifically:\r\n  1.  support more than one datasets (share same vocabulary)\r\n  2. could set weight to each dataset (e.g. 2:1 means 2 batch in the first one and 1 in another)\r\nI find your discussion in  #4422. Multi-task seems need same feature like this.  Actually, multi-task needs two part: multi-dataset feature and model(multi-task head) feature.\r\n\r\nCan you could give me some advice about how to do it ?  I'd like to try it. @dirkgr  @matt-gardner  @jiasenlu \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4550", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4550/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4550/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4550/events", "html_url": "https://github.com/allenai/allennlp/issues/4550", "id": 677373571, "node_id": "MDU6SXNzdWU2NzczNzM1NzE=", "number": 4550, "title": "[Models] BART model output is incorrect shape", "user": {"login": "nitishgupta", "id": 6223213, "node_id": "MDQ6VXNlcjYyMjMyMTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6223213?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nitishgupta", "html_url": "https://github.com/nitishgupta", "followers_url": "https://api.github.com/users/nitishgupta/followers", "following_url": "https://api.github.com/users/nitishgupta/following{/other_user}", "gists_url": "https://api.github.com/users/nitishgupta/gists{/gist_id}", "starred_url": "https://api.github.com/users/nitishgupta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nitishgupta/subscriptions", "organizations_url": "https://api.github.com/users/nitishgupta/orgs", "repos_url": "https://api.github.com/users/nitishgupta/repos", "events_url": "https://api.github.com/users/nitishgupta/events{/privacy}", "received_events_url": "https://api.github.com/users/nitishgupta/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2020-08-12T04:29:28Z", "updated_at": "2020-08-18T11:57:02Z", "closed_at": "2020-08-18T11:57:01Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nThe output of the BART model is incorrect here -- https://github.com/allenai/allennlp-models/blob/master/allennlp_models/generation/models/bart.py#L206\r\n\r\nIt should be `(batch_size, seq_len, vocab_size)` but is `(batch_size, 1, vocab_size)`\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n-e git+git@github.com:allenai/allennlp.git@e53d18580807dabff707f618f7e148c98d25da18#egg=allennlp\r\n-e git+git@github.com:allenai/allennlp-models.git@45f85ce67b869e6f33fb0a38bd9ae17bd99f287c#egg=allennlp_models\r\napex @ git+https://github.com/NVIDIA/apex.git@459de22d59c64e30fd4b368c368c5b74e269f3dd\r\nappdirs==1.4.4\r\nattrs==19.3.0\r\nbert-score==0.3.5\r\nblack==19.10b0\r\nbleach==3.1.5\r\nblis==0.4.1\r\nboto3==1.14.29\r\nbotocore==1.17.29\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.1\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncodecov==2.1.8\r\ncolorama==0.4.3\r\nconllu==3.1.1\r\ncoverage==5.2.1\r\ncryptography==3.0\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndateparser==0.7.6\r\ndocutils==0.15.2\r\neditdistance==0.5.3\r\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\r\nfilelock==3.0.12\r\nflake8==3.8.3\r\nflaky==3.7.0\r\nftfy==5.8\r\nfuture==0.18.2\r\ngoogledrivedownloader==0.4\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata==1.7.0\r\njeepney==0.4.3\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsons==1.2.0\r\nkeyring==21.2.1\r\nkiwisolver==1.2.0\r\nlivereload==2.6.2\r\nlunr==0.5.8\r\nlxml==4.5.2\r\nMarkdown==3.2.2\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.3.0\r\nmccabe==0.6.1\r\nmkdocs==1.1.2\r\nmkdocs-material==5.5.5\r\nmkdocs-material-extensions==1.0\r\nmkl-fft==1.1.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy==0.782\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnr.collections==0.0.1\r\nnr.databind.core==0.0.16\r\nnr.databind.json==0.0.13\r\nnr.interface==0.0.3\r\nnr.metaclass==0.0.5\r\nnr.parsing.date==0.2.0\r\nnr.pylang.utils==0.0.3\r\nnr.stream==0.0.4\r\nnr.utils.re==0.1.0\r\nnumpy==1.18.5\r\nolefile==0.46\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==1.1.0\r\npathspec==0.8.0\r\npathtools==0.1.2\r\nPillow @ file:///tmp/build/80754af9/pillow_1594307325547/work\r\npkginfo==1.5.0.1\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.12.2\r\npy==1.9.0\r\npy-cpuinfo==7.0.0\r\npy-rouge==1.1\r\npycodestyle==2.6.0\r\npycparser==2.20\r\npydoc-markdown @ git+https://github.com/NiklasRosenstein/pydoc-markdown.git@f0bf8af1db4f11581c19d206d4ed1ab34b4854c1\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\npymdown-extensions==7.1\r\npyparsing==2.4.7\r\npytest==5.4.3\r\npytest-benchmark==3.2.3\r\npytest-cov==2.10.0\r\npython-dateutil==2.8.1\r\npytz==2020.1\r\nPyYAML==5.3.1\r\nreadme-renderer==26.0\r\nregex==2020.7.14\r\nrequests==2.24.0\r\nrequests-toolbelt==0.9.1\r\nresponses==0.10.15\r\nrfc3986==1.4.0\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nsacrerouge==0.0.4\r\nscikit-learn==0.23.1\r\nscipy==1.5.2\r\nseaborn==0.10.1\r\nSecretStorage==3.1.2\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.3.2\r\nsrsly==1.0.2\r\ntensorboardX==2.1\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.8.1rc1\r\ntoml==0.10.1\r\ntorch==1.5.1\r\ntorchvision==0.6.0a0+82fd1c8\r\ntornado==6.0.4\r\ntqdm==4.48.0\r\ntransformers==3.0.2\r\ntwine==3.2.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\ntypish==1.7.0\r\ntzlocal==2.1\r\nUnidecode==1.1.1\r\nurllib3==1.25.10\r\nwasabi==0.7.1\r\nwatchdog==0.10.3\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nword2number==1.1\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nx = torch.LongTensor([[0, 133, 766, 9]])\r\nm = torch.BoolTensor([[True, True, True, True]])\r\nbart = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\", output_past=True)\r\ny = bart(input_ids=x, attention_mask=m, decoder_input_ids=x, decoder_attention_mask=m)[0]\r\ny.size()   # output == torch.Size([1, 1, 50265])\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4546", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4546/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4546/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4546/events", "html_url": "https://github.com/allenai/allennlp/issues/4546", "id": 675514302, "node_id": "MDU6SXNzdWU2NzU1MTQzMDI=", "number": 4546, "title": "This line may cause mask tensor change to type LongTensor", "user": {"login": "lixinsu", "id": 15691697, "node_id": "MDQ6VXNlcjE1NjkxNjk3", "avatar_url": "https://avatars1.githubusercontent.com/u/15691697?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lixinsu", "html_url": "https://github.com/lixinsu", "followers_url": "https://api.github.com/users/lixinsu/followers", "following_url": "https://api.github.com/users/lixinsu/following{/other_user}", "gists_url": "https://api.github.com/users/lixinsu/gists{/gist_id}", "starred_url": "https://api.github.com/users/lixinsu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lixinsu/subscriptions", "organizations_url": "https://api.github.com/users/lixinsu/orgs", "repos_url": "https://api.github.com/users/lixinsu/repos", "events_url": "https://api.github.com/users/lixinsu/events{/privacy}", "received_events_url": "https://api.github.com/users/lixinsu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-08T11:57:43Z", "updated_at": "2020-08-08T12:06:20Z", "closed_at": "2020-08-08T12:06:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/allenai/allennlp/blob/f639336a2c721a2efc575397c009c958f02d9d91/allennlp/modules/token_embedders/pretrained_transformer_embedder.py#L220\r\n\r\nThis line causes the null mask tensor change to type long, and error raises when calling torch.stack(tensor_list) during batching.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4541", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4541/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4541/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4541/events", "html_url": "https://github.com/allenai/allennlp/issues/4541", "id": 674021573, "node_id": "MDU6SXNzdWU2NzQwMjE1NzM=", "number": 4541, "title": "Convert AllenNLP model to transformers model", "user": {"login": "PrettyPrettyMeng", "id": 46803821, "node_id": "MDQ6VXNlcjQ2ODAzODIx", "avatar_url": "https://avatars3.githubusercontent.com/u/46803821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PrettyPrettyMeng", "html_url": "https://github.com/PrettyPrettyMeng", "followers_url": "https://api.github.com/users/PrettyPrettyMeng/followers", "following_url": "https://api.github.com/users/PrettyPrettyMeng/following{/other_user}", "gists_url": "https://api.github.com/users/PrettyPrettyMeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/PrettyPrettyMeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PrettyPrettyMeng/subscriptions", "organizations_url": "https://api.github.com/users/PrettyPrettyMeng/orgs", "repos_url": "https://api.github.com/users/PrettyPrettyMeng/repos", "events_url": "https://api.github.com/users/PrettyPrettyMeng/events{/privacy}", "received_events_url": "https://api.github.com/users/PrettyPrettyMeng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-06T05:10:59Z", "updated_at": "2020-08-07T16:13:28Z", "closed_at": "2020-08-07T16:13:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "It seems that in current AllenNLP, the model we save and create cannot interact with apis in transformers. (because we have different keys in model.state_dict()) I think it will be highly helpful if we can convert a trained AllenNLP model to a transformers model. This will provide more flexibility in applications and researchs.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4539", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4539/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4539/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4539/events", "html_url": "https://github.com/allenai/allennlp/issues/4539", "id": 673688179, "node_id": "MDU6SXNzdWU2NzM2ODgxNzk=", "number": 4539, "title": "Release allennlp-semparse to pypi", "user": {"login": "iamsaurabhc", "id": 19235748, "node_id": "MDQ6VXNlcjE5MjM1NzQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/19235748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iamsaurabhc", "html_url": "https://github.com/iamsaurabhc", "followers_url": "https://api.github.com/users/iamsaurabhc/followers", "following_url": "https://api.github.com/users/iamsaurabhc/following{/other_user}", "gists_url": "https://api.github.com/users/iamsaurabhc/gists{/gist_id}", "starred_url": "https://api.github.com/users/iamsaurabhc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iamsaurabhc/subscriptions", "organizations_url": "https://api.github.com/users/iamsaurabhc/orgs", "repos_url": "https://api.github.com/users/iamsaurabhc/repos", "events_url": "https://api.github.com/users/iamsaurabhc/events{/privacy}", "received_events_url": "https://api.github.com/users/iamsaurabhc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 9, "closed_issues": 5, "state": "open", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-08-20T22:36:37Z", "due_on": null, "closed_at": null}, "comments": 9, "created_at": "2020-08-05T16:32:35Z", "updated_at": "2020-08-20T22:36:37Z", "closed_at": "2020-08-20T22:36:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\nTried all three URLs from the [AllenNLP Public Models](https://storage.googleapis.com/allennlp-public-models/) for the upgrade but none of them passes: \r\n- wikitables-model-2018.09.14.tar.gz\r\n- wikitables-model-2019.07.29.tar.gz\r\n- wikitables-model-2020.02.10.tar.gz\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nbotml/service/serve.py:48: in make_app\r\n    return make_app_helper(features, app, available_features)\r\nbotml/service/serve.py:56: in make_app_helper\r\n    avail_features[feat](app)\r\nbotml/service/score_serve_mc.py:23: in add_api_mc\r\n    predictor_qa = qa_tables.load_archive_from_model(model_path)\r\nbotml/nlp/qa_tables.py:12: in load_archive_from_model\r\n    archive = load_archive(model_path)\r\nallennlp/lib/python3.7/site-packages/allennlp/models/archival.py:197: in load_archive\r\n    opt_level=opt_level,\r\nallennlp/lib/python3.7/site-packages/allennlp/models/model.py:391: in load\r\n    model_class: Type[Model] = cls.by_name(model_type)  # type: ignore\r\nallennlp/lib/python3.7/site-packages/allennlp/common/registrable.py:137: in by_name\r\n    subclass, constructor = cls.resolve_class_name(name)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\ncls = <class 'allennlp.models.model.Model'>, name = 'wikitables_erm_parser'\r\n\r\n    @classmethod\r\n    def resolve_class_name(cls: Type[T], name: str) -> Tuple[Type[T], Optional[str]]:\r\n        \"\"\"\r\n        Returns the subclass that corresponds to the given `name`, along with the name of the\r\n        method that was registered as a constructor for that `name`, if any.\r\n    \r\n        This method also allows `name` to be a fully-specified module name, instead of a name that\r\n        was already added to the `Registry`.  In that case, you cannot use a separate function as\r\n        a constructor (as you need to call `cls.register()` in order to tell us what separate\r\n        function to use).\r\n        \"\"\"\r\n        if name in Registrable._registry[cls]:\r\n            subclass, constructor = Registrable._registry[cls].get(name)\r\n            return subclass, constructor\r\n        elif \".\" in name:\r\n            # This might be a fully qualified class name, so we'll try importing its \"module\"\r\n            # and finding it there.\r\n            parts = name.split(\".\")\r\n            submodule = \".\".join(parts[:-1])\r\n            class_name = parts[-1]\r\n    \r\n            try:\r\n                module = importlib.import_module(submodule)\r\n            except ModuleNotFoundError:\r\n                raise ConfigurationError(\r\n                    f\"tried to interpret {name} as a path to a class \"\r\n                    f\"but unable to import module {submodule}\"\r\n                )\r\n    \r\n            try:\r\n                subclass = getattr(module, class_name)\r\n                constructor = None\r\n                return subclass, constructor\r\n            except AttributeError:\r\n                raise ConfigurationError(\r\n                    f\"tried to interpret {name} as a path to a class \"\r\n                    f\"but unable to find class {class_name} in {submodule}\"\r\n                )\r\n    \r\n        else:\r\n            # is not a qualified class name\r\n            raise ConfigurationError(\r\n>               f\"{name} is not a registered name for {cls.__name__}. \"\r\n                \"You probably need to use the --include-package flag \"\r\n                \"to load your custom code. Alternatively, you can specify your choices \"\r\n                \"\"\"using fully-qualified paths, e.g. {\"model\": \"my_module.models.MyModel\"} \"\"\"\r\n                \"in which case they will be automatically imported correctly.\"\r\n            )\r\nE           allennlp.common.checks.ConfigurationError: wikitables_erm_parser is not a registered name for Model. You probably need to use the --include-package flag to load your custom code. Alternatively, you can specify your choices using fully-qualified paths, e.g. {\"model\": \"my_module.models.MyModel\"} in which case they will be automatically imported correctly.\r\n\r\nallennlp/lib/python3.7/site-packages/allennlp/common/registrable.py:185: ConfigurationError\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4535", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4535/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4535/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4535/events", "html_url": "https://github.com/allenai/allennlp/issues/4535", "id": 673260755, "node_id": "MDU6SXNzdWU2NzMyNjA3NTU=", "number": 4535, "title": "A \"py.typed\" marker", "user": {"login": "davidatbu", "id": 52462475, "node_id": "MDQ6VXNlcjUyNDYyNDc1", "avatar_url": "https://avatars3.githubusercontent.com/u/52462475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidatbu", "html_url": "https://github.com/davidatbu", "followers_url": "https://api.github.com/users/davidatbu/followers", "following_url": "https://api.github.com/users/davidatbu/following{/other_user}", "gists_url": "https://api.github.com/users/davidatbu/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidatbu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidatbu/subscriptions", "organizations_url": "https://api.github.com/users/davidatbu/orgs", "repos_url": "https://api.github.com/users/davidatbu/repos", "events_url": "https://api.github.com/users/davidatbu/events{/privacy}", "received_events_url": "https://api.github.com/users/davidatbu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-05T05:18:28Z", "updated_at": "2020-08-17T17:22:13Z", "closed_at": "2020-08-17T17:22:13Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi all,\r\n\r\nI was wondering if there's a specific reason that neither `allennlp`, nor `allennlp-models` include an empty marker file named `py.typed` in their respective python package root directories, as that file is required to mark a package as \"PEP-561 compliant\", which gives static code analysis tools like mypy the go-ahead to do type inference.\r\n\r\nOtherwise, I am currently forced to clone the repo locally, add the marker file, and `pip install -e` to stop mypy from complaining that stubs are missing for `allennlp`. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4530", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4530/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4530/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4530/events", "html_url": "https://github.com/allenai/allennlp/issues/4530", "id": 672466759, "node_id": "MDU6SXNzdWU2NzI0NjY3NTk=", "number": 4530, "title": "Is this a bug of using BERT in version 0.9.0?", "user": {"login": "entslscheia", "id": 15921425, "node_id": "MDQ6VXNlcjE1OTIxNDI1", "avatar_url": "https://avatars3.githubusercontent.com/u/15921425?v=4", "gravatar_id": "", "url": "https://api.github.com/users/entslscheia", "html_url": "https://github.com/entslscheia", "followers_url": "https://api.github.com/users/entslscheia/followers", "following_url": "https://api.github.com/users/entslscheia/following{/other_user}", "gists_url": "https://api.github.com/users/entslscheia/gists{/gist_id}", "starred_url": "https://api.github.com/users/entslscheia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/entslscheia/subscriptions", "organizations_url": "https://api.github.com/users/entslscheia/orgs", "repos_url": "https://api.github.com/users/entslscheia/repos", "events_url": "https://api.github.com/users/entslscheia/events{/privacy}", "received_events_url": "https://api.github.com/users/entslscheia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-04T02:55:11Z", "updated_at": "2020-08-04T18:01:51Z", "closed_at": "2020-08-04T18:01:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "First of all, I know the usage of BERT has been changed drastically since 0.9.0. But since I am still working on my old project, I am still sticking to 0.9.0 (updating to 1.0 will make many of my codes totally unusable...).\r\n\r\nIn version 0.9.0, it seems like padding is not handled at all when using `PretrainedTransformerEmbedder`:\r\n```python\r\nclass PretrainedTransformerEmbedder(TokenEmbedder):\r\n    \"\"\"\r\n    Uses a pretrained model from ``pytorch-transformers`` as a ``TokenEmbedder``.\r\n    \"\"\"\r\n    def __init__(self, model_name: str) -> None:\r\n        super().__init__()\r\n        self.transformer_model = AutoModel.from_pretrained(model_name)\r\n        # I'm not sure if this works for all models; open an issue on github if you find a case\r\n        # where it doesn't work.\r\n        self.output_dim = self.transformer_model.config.hidden_size\r\n\r\n    @overrides\r\n    def get_output_dim(self):\r\n        return self.output_dim\r\n\r\n    def forward(self, token_ids: torch.LongTensor) -> torch.Tensor:  # type: ignore\r\n        # pylint: disable=arguments-differ\r\n        return self.transformer_model(token_ids)[0]\r\n```\r\nYou can see in `forward` method, there is only one argument `token_ids`.\r\nAlso, in `forward` of `self.transformer_model`, which I use BERT here, padding is not handled either:\r\n```python\r\n    def forward(self, input_ids, token_type_ids=None, attention_mask=None, position_ids=None, head_mask=None):\r\n        if attention_mask is None:\r\n            attention_mask = torch.ones_like(input_ids)\r\n        if token_type_ids is None:\r\n            token_type_ids = torch.zeros_like(input_ids)\r\n        ...\r\n``` \r\nYou can see that `attention_mask` is required as an explicit input instead of generating from `input_ids`, and since `PretrainedTransformerEmbedder` does not accept an input of `attention_mask` at all, it indicates that paddings input to BERT are not ignored. I didn't notice this issue till this afternoon, which is kinda surprising to me. I expected this kind of stuff to be handled by AllenNLP and made transparent to users, but now it seems I probably need to implement my own `PretrainedTransformerEmbedder` to take care of this.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4528", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4528/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4528/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4528/events", "html_url": "https://github.com/allenai/allennlp/issues/4528", "id": 671947150, "node_id": "MDU6SXNzdWU2NzE5NDcxNTA=", "number": 4528, "title": "To train the model without specifying a GPU.", "user": {"login": "PrettyPrettyMeng", "id": 46803821, "node_id": "MDQ6VXNlcjQ2ODAzODIx", "avatar_url": "https://avatars3.githubusercontent.com/u/46803821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PrettyPrettyMeng", "html_url": "https://github.com/PrettyPrettyMeng", "followers_url": "https://api.github.com/users/PrettyPrettyMeng/followers", "following_url": "https://api.github.com/users/PrettyPrettyMeng/following{/other_user}", "gists_url": "https://api.github.com/users/PrettyPrettyMeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/PrettyPrettyMeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PrettyPrettyMeng/subscriptions", "organizations_url": "https://api.github.com/users/PrettyPrettyMeng/orgs", "repos_url": "https://api.github.com/users/PrettyPrettyMeng/repos", "events_url": "https://api.github.com/users/PrettyPrettyMeng/events{/privacy}", "received_events_url": "https://api.github.com/users/PrettyPrettyMeng/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-03T09:45:04Z", "updated_at": "2020-08-04T00:54:11Z", "closed_at": "2020-08-04T00:54:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "For the cluster that I'm using, it does not allow specifying cuda device in my code. I think it's pretty common in many different clusters. I have not found how to do it for current allennlp library. Does there exist one that I have not noticed or can you add a feature like this? For example, by setting some config parameters, we can use model.cuda() instead of model.to(device). Thanks in advance!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4523", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4523/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4523/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4523/events", "html_url": "https://github.com/allenai/allennlp/issues/4523", "id": 668383372, "node_id": "MDU6SXNzdWU2NjgzODMzNzI=", "number": 4523, "title": "ConfigurationError: Cannot register evaluate as Subcommand; name already in use for Evaluate", "user": {"login": "ScottishFold007", "id": 36957508, "node_id": "MDQ6VXNlcjM2OTU3NTA4", "avatar_url": "https://avatars1.githubusercontent.com/u/36957508?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ScottishFold007", "html_url": "https://github.com/ScottishFold007", "followers_url": "https://api.github.com/users/ScottishFold007/followers", "following_url": "https://api.github.com/users/ScottishFold007/following{/other_user}", "gists_url": "https://api.github.com/users/ScottishFold007/gists{/gist_id}", "starred_url": "https://api.github.com/users/ScottishFold007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ScottishFold007/subscriptions", "organizations_url": "https://api.github.com/users/ScottishFold007/orgs", "repos_url": "https://api.github.com/users/ScottishFold007/repos", "events_url": "https://api.github.com/users/ScottishFold007/events{/privacy}", "received_events_url": "https://api.github.com/users/ScottishFold007/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-30T05:25:36Z", "updated_at": "2020-07-31T16:12:54Z", "closed_at": "2020-07-31T16:12:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n![image](https://user-images.githubusercontent.com/36957508/88883941-1640d200-d268-11ea-8803-6e15f5b2c985.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4520", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4520/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4520/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4520/events", "html_url": "https://github.com/allenai/allennlp/issues/4520", "id": 667973598, "node_id": "MDU6SXNzdWU2Njc5NzM1OTg=", "number": 4520, "title": "Iterators \u2794 DataLoaders v1.0 upgrade: key \"sampler\" is required at location data_loader.batch_sampler", "user": {"login": "iamsaurabhc", "id": 19235748, "node_id": "MDQ6VXNlcjE5MjM1NzQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/19235748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iamsaurabhc", "html_url": "https://github.com/iamsaurabhc", "followers_url": "https://api.github.com/users/iamsaurabhc/followers", "following_url": "https://api.github.com/users/iamsaurabhc/following{/other_user}", "gists_url": "https://api.github.com/users/iamsaurabhc/gists{/gist_id}", "starred_url": "https://api.github.com/users/iamsaurabhc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iamsaurabhc/subscriptions", "organizations_url": "https://api.github.com/users/iamsaurabhc/orgs", "repos_url": "https://api.github.com/users/iamsaurabhc/repos", "events_url": "https://api.github.com/users/iamsaurabhc/events{/privacy}", "received_events_url": "https://api.github.com/users/iamsaurabhc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-29T16:24:34Z", "updated_at": "2020-08-05T16:25:08Z", "closed_at": "2020-07-31T16:10:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [ x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [ x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x ] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [ x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [ ] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n'!! Traceback (most recent call last):\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/params.py\", line 237, in pop\\n    value = self.params.pop(key)\\n!! KeyError: \\'sampler\\'\\n!! \\nDuring handling of the above exception, another exception occurred:\\n\\n!! Traceback (most recent call last):\\n!!   File \"/home/saurabh/botml/botml/common/sherlock.py\", line 43, in wrap\\n    status.result = func(*args, **kwargs)\\n!!   File \"/home/saurabh/botml/botml/botai/api.py\", line 104, in train\\n    model = allentrain.train_model(params, ser_file)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/commands/train.py\", line 230, in train_model\\n    dry_run=dry_run,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/commands/train.py\", line 418, in _train_worker\\n    params=params, serialization_dir=serialization_dir, local_rank=process_rank,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\\n    **extras,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\\n    return constructor_to_call(**kwargs)  # type: ignore\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/commands/train.py\", line 646, in from_partial_objects\\n    data_loader_ = data_loader.construct(dataset=datasets[\"train\"])\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 46, in construct\\n    return self._constructor(**kwargs)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 446, in constructor\\n    return value_cls.from_params(params=deepcopy(popped_params), **constructor_extras)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\\n    **extras,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\\n    return constructor_to_call(**kwargs)  # type: ignore\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/data/dataloader.py\", line 127, in from_partial_objects\\n    batch_sampler_ = batch_sampler.construct(data_source=dataset)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/lazy.py\", line 46, in construct\\n    return self._constructor(**kwargs)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 446, in constructor\\n    return value_cls.from_params(params=deepcopy(popped_params), **constructor_extras)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\\n    **extras,\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 609, in from_params\\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 181, in create_kwargs\\n    cls.__name__, param_name, annotation, param.default, params, **extras\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 280, in pop_and_construct_arg\\n    popped_params = params.pop(name, default) if default != _NO_DEFAULT else params.pop(name)\\n!!   File \"/home/saurabh/botml/allennlp/lib/python3.7/site-packages/allennlp/common/params.py\", line 242, in pop\\n    raise ConfigurationError(msg)\\n!! allennlp.common.checks.ConfigurationError: key \"sampler\" is required at location \"data_loader.batch_sampler.\"\\n'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.4.4\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\nAPScheduler==3.6.3\r\nastroid==2.1.0\r\nasync-timeout==3.0.1\r\nattrs==19.3.0\r\nazure-common==1.1.25\r\nazure-cosmosdb-nspkg==2.0.2\r\nazure-cosmosdb-table==1.0.3\r\nazure-nspkg==3.0.2\r\nazure-storage==0.34.3\r\nazure-storage-common==1.1.0\r\nazure-storage-nspkg==3.1.0\r\nbeautifulsoup4==4.9.0\r\nblis==0.4.1\r\n-e git+finons@vs-ssh.visualstudio.com:v3/finons/BMML/botml@cdfaae98ee6019ee90171079d8f3694796cc1bd4#egg=botml\r\nboto==2.49.0\r\nboto3==1.14.28\r\nbotocore==1.17.28\r\nbreadability==0.1.20\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nclick==7.1.2\r\nconllu==3.0\r\ncoverage==4.5.1\r\ncryptography==3.0\r\ncssselect==1.1.0\r\ncymem==2.0.3\r\nCython==0.29.16\r\ndill==0.2.7.1\r\ndocopt==0.6.2\r\ndocutils==0.15.2\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nfeedfinder2==0.0.4\r\nfeedparser==5.2.1\r\nfilelock==3.0.12\r\nFlask==1.0.2\r\nFlask-Cors==3.0.8\r\nfuture==0.18.2\r\nfutures==3.1.1\r\ngensim==3.8.2\r\ngevent==1.5.0\r\ngreenlet==0.4.16\r\nh5py==2.10.0\r\nhtml5lib==1.0.1\r\nidna==2.6\r\nimportlib-metadata==1.7.0\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njieba3k==0.35.1\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.11\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nlazy-object-proxy==1.5.1\r\nlightgbm==2.0.4\r\nlxml==4.5.0\r\nMarkupSafe==1.1.1\r\nmccabe==0.6.1\r\nmore-itertools==8.4.0\r\nmultidict==4.7.6\r\nmurmurhash==1.0.2\r\nnewspaper3k==0.2.8\r\nnltk==3.5\r\nnose==1.3.7\r\nnumpy==1.18.3\r\noverrides==3.0.0\r\npackaging==20.4\r\npandas==1.0.3\r\nPillow==7.2.0\r\npkg-resources==0.0.0\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npycparser==2.20\r\npylint==2.4.4\r\npymongo==3.10.1\r\npyparsing==2.4.7\r\npytest==5.4.1\r\npytest-cov==2.8.1\r\npython-dateutil==2.8.1\r\npytz==2017.3\r\nPyYAML==5.3.1\r\nregex==2020.7.14\r\nrequests==2.18.4\r\nrequests-file==1.5.1\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.20.3\r\nscipy==1.4.1\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nslackclient==1.2.1\r\nsmart-open==2.1.0\r\nsoupsieve==2.0.1\r\nspacy==2.2.4\r\nsrsly==1.0.2\r\nsumy==0.7.0\r\ntensorboardX==2.1\r\nthinc==7.4.0\r\ntinysegmenter==0.3\r\ntldextract==2.2.2\r\ntokenizers==0.7.0\r\ntorch==1.5.0\r\ntqdm==4.45.0\r\ntransformers==2.11.0\r\ntzlocal==2.1\r\nurllib3==1.22\r\nwasabi==0.7.1\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nWerkzeug==1.0.1\r\nword2number==1.1\r\nwordninja==0.1.5\r\nwrapt==1.12.1\r\nyarl==1.4.2\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n# Updating from older version to v1.0\r\nUpdated config : \r\n\"data_loader\": {\r\n        \"batch_sampler\": {\r\n        \"type\": \"basic\",\r\n        \"batch_size\": 32\r\n        }\r\n    }\r\nPrevious config: \r\n\"iterator\": {\r\n        \"type\": \"basic\",\r\n        \"batch_size\": 32\r\n    }\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4518", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4518/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4518/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4518/events", "html_url": "https://github.com/allenai/allennlp/issues/4518", "id": 667504462, "node_id": "MDU6SXNzdWU2Njc1MDQ0NjI=", "number": 4518, "title": "lazy mode is helpful for us?", "user": {"login": "Nagin-Kim", "id": 24890015, "node_id": "MDQ6VXNlcjI0ODkwMDE1", "avatar_url": "https://avatars3.githubusercontent.com/u/24890015?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nagin-Kim", "html_url": "https://github.com/Nagin-Kim", "followers_url": "https://api.github.com/users/Nagin-Kim/followers", "following_url": "https://api.github.com/users/Nagin-Kim/following{/other_user}", "gists_url": "https://api.github.com/users/Nagin-Kim/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nagin-Kim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nagin-Kim/subscriptions", "organizations_url": "https://api.github.com/users/Nagin-Kim/orgs", "repos_url": "https://api.github.com/users/Nagin-Kim/repos", "events_url": "https://api.github.com/users/Nagin-Kim/events{/privacy}", "received_events_url": "https://api.github.com/users/Nagin-Kim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-29T02:42:29Z", "updated_at": "2020-07-31T16:09:20Z", "closed_at": "2020-07-31T16:09:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I try to pretrain the model , I found that the gpu memory are unsteady due to the reason of that i set the laze mode as True, however when i try to train it again with parameter --laze_mode=False, my cpu cache are only 50gb, which can't run this mode on my 30gb datasets with its code.\r\n**Describe the solution you'd like**\r\nCan we train the model with laze_mode =True, and the datareader can synthetically read the data from the cache at the same time?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4517", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4517/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4517/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4517/events", "html_url": "https://github.com/allenai/allennlp/issues/4517", "id": 667034405, "node_id": "MDU6SXNzdWU2NjcwMzQ0MDU=", "number": 4517, "title": "Textual Entailment - ROBERTa model trained on SNLI - Different results using the demo and the library", "user": {"login": "silvia596", "id": 68905372, "node_id": "MDQ6VXNlcjY4OTA1Mzcy", "avatar_url": "https://avatars2.githubusercontent.com/u/68905372?v=4", "gravatar_id": "", "url": "https://api.github.com/users/silvia596", "html_url": "https://github.com/silvia596", "followers_url": "https://api.github.com/users/silvia596/followers", "following_url": "https://api.github.com/users/silvia596/following{/other_user}", "gists_url": "https://api.github.com/users/silvia596/gists{/gist_id}", "starred_url": "https://api.github.com/users/silvia596/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/silvia596/subscriptions", "organizations_url": "https://api.github.com/users/silvia596/orgs", "repos_url": "https://api.github.com/users/silvia596/repos", "events_url": "https://api.github.com/users/silvia596/events{/privacy}", "received_events_url": "https://api.github.com/users/silvia596/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-07-28T12:30:15Z", "updated_at": "2020-07-31T16:08:39Z", "closed_at": "2020-07-31T16:08:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've just copied the usage snippet from your demo, and I obtained different results using the demo and the code (not only the probabilities are different, the results are completely different). Is the model different? How can I use the demo model in local?\r\nI attach you a pair of images with a simple example.\r\n<img width=\"439\" alt=\"CaptureDemo\" src=\"https://user-images.githubusercontent.com/68905372/88663344-c33a1400-d0db-11ea-8daa-1bb55be59656.PNG\">\r\n<img width=\"516\" alt=\"CaptureCode\" src=\"https://user-images.githubusercontent.com/68905372/88663488-fbd9ed80-d0db-11ea-8fd2-3999a91a2bb4.PNG\">\r\nVersions:\r\nallennlp==1.0.0\r\nallennlp-models==1.0.0\r\n\r\nThanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4516", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4516/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4516/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4516/events", "html_url": "https://github.com/allenai/allennlp/issues/4516", "id": 666930128, "node_id": "MDU6SXNzdWU2NjY5MzAxMjg=", "number": 4516, "title": "How the 'hotflip' is applied to the BERT?", "user": {"login": "JJumSSu", "id": 39372342, "node_id": "MDQ6VXNlcjM5MzcyMzQy", "avatar_url": "https://avatars1.githubusercontent.com/u/39372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JJumSSu", "html_url": "https://github.com/JJumSSu", "followers_url": "https://api.github.com/users/JJumSSu/followers", "following_url": "https://api.github.com/users/JJumSSu/following{/other_user}", "gists_url": "https://api.github.com/users/JJumSSu/gists{/gist_id}", "starred_url": "https://api.github.com/users/JJumSSu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JJumSSu/subscriptions", "organizations_url": "https://api.github.com/users/JJumSSu/orgs", "repos_url": "https://api.github.com/users/JJumSSu/repos", "events_url": "https://api.github.com/users/JJumSSu/events{/privacy}", "received_events_url": "https://api.github.com/users/JJumSSu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-28T09:39:15Z", "updated_at": "2020-07-29T01:34:20Z", "closed_at": "2020-07-28T16:45:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, this [hotflip](https://demo.allennlp.org/masked-lm?text=The%20doctor%20ran%20to%20the%20emergency%20room%20to%20see%20%5BMASK%5D%20patient.) demo is neat, thank you for providing such a nice library&demo.\r\n\r\nHowever, I have a question. BERT uses wordpiece vocabulary and is subword-unit based language model. But in the demo, it seems that the token is flipped at the \"word\" level. Also, the hotflip attack implementation in the allennlp [library](https://github.com/allenai/allennlp/blob/master/allennlp/interpret/attackers/hotflip.py) is based on word-level. \r\n\r\nDid you guys give special treatment for this discrepancy? Or do you guys just flip the token at the subword-level?\r\nI couldn't find out the source code processing this part.\r\n\r\nThank you.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4515", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4515/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4515/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4515/events", "html_url": "https://github.com/allenai/allennlp/issues/4515", "id": 666100236, "node_id": "MDU6SXNzdWU2NjYxMDAyMzY=", "number": 4515, "title": "PretrainedTransformerMismatchedIndexer _add_encoding_to_vocabulary_if_needed is broken", "user": {"login": "OhadRubin", "id": 4252994, "node_id": "MDQ6VXNlcjQyNTI5OTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/4252994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OhadRubin", "html_url": "https://github.com/OhadRubin", "followers_url": "https://api.github.com/users/OhadRubin/followers", "following_url": "https://api.github.com/users/OhadRubin/following{/other_user}", "gists_url": "https://api.github.com/users/OhadRubin/gists{/gist_id}", "starred_url": "https://api.github.com/users/OhadRubin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OhadRubin/subscriptions", "organizations_url": "https://api.github.com/users/OhadRubin/orgs", "repos_url": "https://api.github.com/users/OhadRubin/repos", "events_url": "https://api.github.com/users/OhadRubin/events{/privacy}", "received_events_url": "https://api.github.com/users/OhadRubin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-27T08:39:06Z", "updated_at": "2020-07-28T17:57:41Z", "closed_at": "2020-07-27T10:04:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "the tokenizers library doesn't take into account that self._tokenizer might be a dictionary \r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-7f51839e03f5> in <module>\r\n      2 for inst in train_dataset:\r\n      3     a = inst\r\n----> 4     res_list = model.forward_on_instances([inst])\r\n      5     print(res_list)\r\n      6 #     break\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/models/model.py in forward_on_instances(self, instances)\r\n    168             cuda_device = self._get_prediction_device()\r\n    169             dataset = Batch(instances)\r\n--> 170             dataset.index_instances(self.vocab)\r\n    171             model_input = util.move_to_device(dataset.as_tensor_dict(), cuda_device)\r\n    172             outputs = self.make_output_human_readable(self(**model_input))\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/batch.py in index_instances(self, vocab)\r\n    157     def index_instances(self, vocab: Vocabulary) -> None:\r\n    158         for instance in self.instances:\r\n--> 159             instance.index_fields(vocab)\r\n    160 \r\n    161     def print_statistics(self) -> None:\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/instance.py in index_fields(self, vocab)\r\n     73             self.indexed = True\r\n     74             for field in self.fields.values():\r\n---> 75                 field.index(vocab)\r\n     76 \r\n     77     def get_padding_lengths(self) -> Dict[str, Dict[str, int]]:\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/fields/text_field.py in index(self, vocab)\r\n     66         self._indexed_tokens = {}\r\n     67         for indexer_name, indexer in self._token_indexers.items():\r\n---> 68             self._indexed_tokens[indexer_name] = indexer.tokens_to_indices(self.tokens, vocab)\r\n     69 \r\n     70     @overrides\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/token_indexers/pretrained_transformer_mismatched_indexer.py in tokens_to_indices(self, tokens, vocabulary)\r\n     61     @overrides\r\n     62     def tokens_to_indices(self, tokens: List[Token], vocabulary: Vocabulary) -> IndexedTokenList:\r\n---> 63         self._matched_indexer._add_encoding_to_vocabulary_if_needed(vocabulary)\r\n     64 \r\n     65         wordpieces, offsets = self._allennlp_tokenizer.intra_word_tokenize([t.text for t in tokens])\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/allennlp/data/token_indexers/pretrained_transformer_indexer.py in _add_encoding_to_vocabulary_if_needed(self, vocab)\r\n     72 \r\n     73         try:\r\n---> 74             vocab_items = self._tokenizer.get_vocab().items()\r\n     75         except NotImplementedError:\r\n     76             vocab_items = (\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/transformers/tokenization_utils.py in get_vocab(self)\r\n   2368 \r\n   2369     def get_vocab(self):\r\n-> 2370         return self._tokenizer.get_vocab(True)\r\n   2371 \r\n   2372     def convert_tokens_to_string(self, tokens: List[int], skip_special_tokens: bool = False) -> str:\r\n\r\n/home/ohad/.conda/cap/lib/python3.7/site-packages/tokenizers/implementations/base_tokenizer.py in get_vocab(self, with_added_tokens)\r\n     36             The vocabulary\r\n     37         \"\"\"\r\n---> 38         return self._tokenizer.get_vocab(with_added_tokens=with_added_tokens)\r\n     39 \r\n     40     def get_vocab_size(self, with_added_tokens: bool = True) -> int:\r\n\r\nAttributeError: 'dict' object has no attribute 'get_vocab'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4514", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4514/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4514/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4514/events", "html_url": "https://github.com/allenai/allennlp/issues/4514", "id": 665988431, "node_id": "MDU6SXNzdWU2NjU5ODg0MzE=", "number": 4514, "title": "sign of the hotflip implementation?", "user": {"login": "seongeun1", "id": 50171725, "node_id": "MDQ6VXNlcjUwMTcxNzI1", "avatar_url": "https://avatars0.githubusercontent.com/u/50171725?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seongeun1", "html_url": "https://github.com/seongeun1", "followers_url": "https://api.github.com/users/seongeun1/followers", "following_url": "https://api.github.com/users/seongeun1/following{/other_user}", "gists_url": "https://api.github.com/users/seongeun1/gists{/gist_id}", "starred_url": "https://api.github.com/users/seongeun1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seongeun1/subscriptions", "organizations_url": "https://api.github.com/users/seongeun1/orgs", "repos_url": "https://api.github.com/users/seongeun1/repos", "events_url": "https://api.github.com/users/seongeun1/events{/privacy}", "received_events_url": "https://api.github.com/users/seongeun1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-27T05:32:19Z", "updated_at": "2020-07-27T15:45:38Z", "closed_at": "2020-07-27T15:45:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi. Thanks for the great library.\r\n\r\nI have a question about the implementation of the [hotflip](https://github.com/allenai/allennlp/blob/master/allennlp/interpret/attackers/hotflip.py)\r\n\r\nAccording to the equation(3) from the [paper](https://arxiv.org/abs/1903.06620), Isn't it supposed to be \"argmin\" instead of \"argmax\" in the implemented function  [\"_first_order_taylor\"](https://github.com/allenai/allennlp/blob/master/allennlp/interpret/attackers/hotflip.py) because you guys are subtracting the embedded vocabulary from the embedded src_tokens.  I'm a bit confused here. \r\n\r\nThank you!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4513", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4513/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4513/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4513/events", "html_url": "https://github.com/allenai/allennlp/issues/4513", "id": 665776187, "node_id": "MDU6SXNzdWU2NjU3NzYxODc=", "number": 4513, "title": "Sticky top navbar", "user": {"login": "Rajwrita", "id": 47374547, "node_id": "MDQ6VXNlcjQ3Mzc0NTQ3", "avatar_url": "https://avatars1.githubusercontent.com/u/47374547?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rajwrita", "html_url": "https://github.com/Rajwrita", "followers_url": "https://api.github.com/users/Rajwrita/followers", "following_url": "https://api.github.com/users/Rajwrita/following{/other_user}", "gists_url": "https://api.github.com/users/Rajwrita/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rajwrita/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rajwrita/subscriptions", "organizations_url": "https://api.github.com/users/Rajwrita/orgs", "repos_url": "https://api.github.com/users/Rajwrita/repos", "events_url": "https://api.github.com/users/Rajwrita/events{/privacy}", "received_events_url": "https://api.github.com/users/Rajwrita/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-26T13:02:13Z", "updated_at": "2020-07-27T17:05:30Z", "closed_at": "2020-07-27T17:05:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "A sticky navbar would probably be helpful to access the various pages on the website with ease.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4506", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4506/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4506/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4506/events", "html_url": "https://github.com/allenai/allennlp/issues/4506", "id": 665063480, "node_id": "MDU6SXNzdWU2NjUwNjM0ODA=", "number": 4506, "title": "Coreference resolution out of memory error", "user": {"login": "erncnerky", "id": 13177658, "node_id": "MDQ6VXNlcjEzMTc3NjU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13177658?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erncnerky", "html_url": "https://github.com/erncnerky", "followers_url": "https://api.github.com/users/erncnerky/followers", "following_url": "https://api.github.com/users/erncnerky/following{/other_user}", "gists_url": "https://api.github.com/users/erncnerky/gists{/gist_id}", "starred_url": "https://api.github.com/users/erncnerky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erncnerky/subscriptions", "organizations_url": "https://api.github.com/users/erncnerky/orgs", "repos_url": "https://api.github.com/users/erncnerky/repos", "events_url": "https://api.github.com/users/erncnerky/events{/privacy}", "received_events_url": "https://api.github.com/users/erncnerky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-24T10:06:21Z", "updated_at": "2020-07-31T16:06:55Z", "closed_at": "2020-07-31T16:06:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am using coreference resolution model (https://demo.allennlp.org/coreference-resolution)\r\n\r\n```Python\r\nclass CoreferenceResolution():\r\n\r\n    def __init__(self):\r\n        self.predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\", cuda_device=0)\r\n\r\n    def predict(self, text):\r\n        prediction = self.predictor.predict(document=text)\r\n        return prediction\r\n```\r\n\r\nAfter a certain period of time, I get CUDA out of memory error.\r\n\r\n```\r\nERROR:api:Exception on /api/v1/coreference-resolution [POST]\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2446, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1951, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1820, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1949, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1935, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"/app/api.py\", line 43, in coreference_resolution_f\r\n    coreference_prediction = coreference_resolution.predict(text)\r\n  File \"/app/src/coreference.py\", line 12, in predict\r\n    prediction = self.predictor.predict(document=text)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp_models/coref/predictors/coref.py\", line 65, in predict\r\n    return self.predict_json({\"document\": document})\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py\", line 48, in predict_json\r\n    return self.predict_instance(instance)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py\", line 171, in predict_instance\r\n    outputs = self._model.forward_on_instance(instance)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py\", line 146, in forward_on_instance\r\n    return self.forward_on_instances([instance])[0]\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py\", line 172, in forward_on_instances\r\n    outputs = self.make_output_human_readable(self(**model_input))\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp_models/coref/models/coref.py\", line 206, in forward\r\n    attended_span_embeddings = self._attentive_span_extractor(text_embeddings, spans)\r\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/modules/span_extractors/self_attentive_span_extractor.py\", line 73, in forward\r\n    attended_text_embeddings = util.weighted_sum(span_embeddings, span_attention_weights)\r\n  File \"/usr/local/lib/python3.6/dist-packages/allennlp/nn/util.py\", line 692, in weighted_sum\r\n    intermediate = attention.unsqueeze(-1).expand_as(matrix) * matrix\r\nRuntimeError: CUDA out of memory. Tried to allocate 1.69 GiB (GPU 0; 11.17 GiB total capacity; 3.18 GiB already allocated; 1.14 GiB free; 3.19 GiB reserved in total by PyTorch)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4504", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4504/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4504/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4504/events", "html_url": "https://github.com/allenai/allennlp/issues/4504", "id": 664894725, "node_id": "MDU6SXNzdWU2NjQ4OTQ3MjU=", "number": 4504, "title": "After #4470 the output is duplicated and Tqdm effect is lost", "user": {"login": "bratao", "id": 1090152, "node_id": "MDQ6VXNlcjEwOTAxNTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/1090152?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bratao", "html_url": "https://github.com/bratao", "followers_url": "https://api.github.com/users/bratao/followers", "following_url": "https://api.github.com/users/bratao/following{/other_user}", "gists_url": "https://api.github.com/users/bratao/gists{/gist_id}", "starred_url": "https://api.github.com/users/bratao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bratao/subscriptions", "organizations_url": "https://api.github.com/users/bratao/orgs", "repos_url": "https://api.github.com/users/bratao/repos", "events_url": "https://api.github.com/users/bratao/events{/privacy}", "received_events_url": "https://api.github.com/users/bratao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-24T03:39:47Z", "updated_at": "2020-07-31T16:16:43Z", "closed_at": "2020-07-31T16:16:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nIn PyCharm console in Windows and in the CI ( Ubuntu 18.04) the output is duplicated. The nice Tqdm bars is lost. The output is repeated like that:\r\n\r\n```\r\naccuracy: 0.9193, accuracy3: 0.9219, precision-overall: 0.3077, recall-overall: 0.2727, f1-measure-overall: 0.2892, loss: 95.4325, reg_loss: 6.7843 ||:  33%|###3      | 1/3 [00:02<00:04,  2.14s/it]\r\naccuracy: 0.9211, accuracy3: 0.9237, precision-overall: 0.3571, recall-overall: 0.3191, f1-measure-overall: 0.3371, loss: 37.8299, reg_loss: 7.8506 ||: 100%|##########| 3/3 [00:02<00:00,  1.52s/it]\r\naccuracy: 0.9211, accuracy3: 0.9237, precision-overall: 0.3571, recall-overall: 0.3191, f1-measure-overall: 0.3371, loss: 37.8299, reg_loss: 7.8506 ||: 100%|##########| 3/3 [00:02<00:00,  1.30it/s]\r\n\r\n```\r\nThe #4470 Pull by @epwalsh  checks for sys.stderr.isatty() and in my Pycharm console and in my Gitlab C.I the output is duplicated. Probably because the console is redirected internal. A option to keep the previous behavior would be great\r\n\r\n<details>\r\n\r\n\r\n\r\n\r\n\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nHappened after the #4470 Pull\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Windows 10 or Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.8\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\nN/A - Any training code reproduces this error.\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4503", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4503/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4503/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4503/events", "html_url": "https://github.com/allenai/allennlp/issues/4503", "id": 664726260, "node_id": "MDU6SXNzdWU2NjQ3MjYyNjA=", "number": 4503, "title": "Coreference resolution help: from clusters to transformed text", "user": {"login": "griff4692", "id": 12277915, "node_id": "MDQ6VXNlcjEyMjc3OTE1", "avatar_url": "https://avatars1.githubusercontent.com/u/12277915?v=4", "gravatar_id": "", "url": "https://api.github.com/users/griff4692", "html_url": "https://github.com/griff4692", "followers_url": "https://api.github.com/users/griff4692/followers", "following_url": "https://api.github.com/users/griff4692/following{/other_user}", "gists_url": "https://api.github.com/users/griff4692/gists{/gist_id}", "starred_url": "https://api.github.com/users/griff4692/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/griff4692/subscriptions", "organizations_url": "https://api.github.com/users/griff4692/orgs", "repos_url": "https://api.github.com/users/griff4692/repos", "events_url": "https://api.github.com/users/griff4692/events{/privacy}", "received_events_url": "https://api.github.com/users/griff4692/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2020-07-23T19:51:53Z", "updated_at": "2020-08-07T09:12:33Z", "closed_at": "2020-07-27T15:33:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Are there any tips / scripts available for taking coreference output and transforming original text (replacing coreferent mentions with antecedent or longest span).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4496", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4496/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4496/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4496/events", "html_url": "https://github.com/allenai/allennlp/issues/4496", "id": 662265555, "node_id": "MDU6SXNzdWU2NjIyNjU1NTU=", "number": 4496, "title": "Padding error for two ListFields in Instance object", "user": {"login": "mateuszpieniak", "id": 31375424, "node_id": "MDQ6VXNlcjMxMzc1NDI0", "avatar_url": "https://avatars2.githubusercontent.com/u/31375424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mateuszpieniak", "html_url": "https://github.com/mateuszpieniak", "followers_url": "https://api.github.com/users/mateuszpieniak/followers", "following_url": "https://api.github.com/users/mateuszpieniak/following{/other_user}", "gists_url": "https://api.github.com/users/mateuszpieniak/gists{/gist_id}", "starred_url": "https://api.github.com/users/mateuszpieniak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mateuszpieniak/subscriptions", "organizations_url": "https://api.github.com/users/mateuszpieniak/orgs", "repos_url": "https://api.github.com/users/mateuszpieniak/repos", "events_url": "https://api.github.com/users/mateuszpieniak/events{/privacy}", "received_events_url": "https://api.github.com/users/mateuszpieniak/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-20T21:08:13Z", "updated_at": "2020-08-04T10:24:38Z", "closed_at": "2020-08-04T10:24:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nIn my custom `DatasetReader` I read pairs of text, where each text is processed with `ListField`. It results in the exception for `batch_size` > 1. It works for `batch_size` == 1. It suggests that the issue is with the padding logic.\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n  0%|          | 0/100 [00:00<?, ?it/s]\r\n2020-07-20 22:48:57,813 - CRITICAL - root - Uncaught exception\r\nTraceback (most recent call last):\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/__main__.py\", line 38, in <module>\r\n    run()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/__main__.py\", line 34, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 105, in train_model_from_args\r\n    dry_run=args.dry_run,\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 159, in train_model_from_file\r\n    dry_run=dry_run,\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 213, in train_model\r\n    dry_run=dry_run,\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 407, in _train_worker\r\n    metrics = train_loop.run()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/commands/train.py\", line 469, in run\r\n    return self.trainer.train()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/training/trainer.py\", line 848, in train\r\n    train_metrics = self._train_epoch(epoch)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/training/trainer.py\", line 554, in _train_epoch\r\n    for batch_group in batch_group_generator_tqdm:\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/tqdm/std.py\", line 1129, in __iter__\r\n    for obj in iterable:\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/common/util.py\", line 135, in lazy_groups_of\r\n    s = list(islice(iterator, group_size))\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/dataloader.py\", line 119, in __iter__\r\n    yield next(self._data_generator)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\r\n    data = self._next_data()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 385, in _next_data\r\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 35, in fetch\r\n    return self.collate_fn(data)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/dataloader.py\", line 18, in allennlp_collate\r\n    return batch.as_tensor_dict(batch.get_padding_lengths())\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/batch.py\", line 141, in as_tensor_dict\r\n    for field, tensors in instance.as_tensor_dict(lengths_to_use).items():\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/instance.py\", line 101, in as_tensor_dict\r\n    tensors[field_name] = field.as_tensor(padding_lengths[field_name])\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/fields/list_field.py\", line 99, in as_tensor\r\n    return self.field_list[0].batch_tensors(padded_fields)\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/fields/text_field.py\", line 132, in batch_tensors\r\n    for indexer_name, indexer_outputs in indexer_lists.items()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/data/fields/text_field.py\", line 132, in <dictcomp>\r\n    for indexer_name, indexer_outputs in indexer_lists.items()\r\n  File \"/home/pi3ni0/.venv/dev/lib/python3.6/site-packages/allennlp/nn/util.py\", line 99, in batch_tensor_dicts\r\n    batched_tensor = torch.stack(tensor_list)\r\nRuntimeError: Expected object of scalar type bool but got scalar type long int for sequence element 16.\r\nreading instances: 3it [00:00,  8.25it/s]\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nNot a duplicate, but a bit related (address only a single ListField in the returned `Instance` object)\r\n- https://github.com/allenai/allennlp/issues/2839\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04.4 LTS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.9\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nalabaster==0.7.12\r\nalembic==1.4.2\r\nallennlp @ git+https://github.com/allenai/allennlp.git@478bf46cb676524ee9b74fb271ec0a592d1c4a48\r\nallennlp-models==1.0.0\r\n-e git+https://github.com/allenai/allennlp-server@4901cd9c93b77949d1877e18c6b019615004a6b5#egg=allennlp_server\r\naltgraph==0.17\r\nappdirs==1.4.3\r\nattrs==19.3.0\r\nawscli==1.18.34\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nbeautifulsoup4==4.8.2\r\nblack==19.10b0\r\nbleach==3.1.4\r\nblis==0.4.1\r\nboto3==1.14.17\r\nbotocore==1.17.19\r\nbravado==10.6.0\r\nbravado-core==5.17.0\r\nbs4==0.0.1\r\ncachetools==4.0.0\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncliff==3.3.0\r\ncloudpickle==1.3.0\r\ncmaes==0.5.1\r\ncmd2==1.1.0\r\ncolorama==0.4.3\r\ncolorlog==4.1.0\r\nConfigArgParse==1.2.3\r\nconfigparser==5.0.0\r\nconllu==3.0\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndask==2.14.0\r\ndatabricks-cli==0.10.0\r\ndataclasses==0.7\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndill==0.3.1.1\r\ndocker==4.2.0\r\ndocutils==0.15.2\r\neditdistance==0.5.3\r\nen-core-sci-sm @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz\r\nentrypoints==0.3\r\nface-alignment==1.0.0\r\nfasttext==0.9.1\r\nfilelock==3.0.12\r\nflaky==3.6.1\r\nFlask==1.1.1\r\nFlask-Cors==3.0.8\r\nftfy==5.7\r\nfuture==0.18.2\r\ngensim==3.8.1\r\ngevent==1.4.0\r\ngitdb==4.0.4\r\nGitPython==3.1.1\r\ngoogle-api-core==1.16.0\r\ngoogle-auth==1.12.0\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-cloud-core==1.3.0\r\ngoogle-cloud-storage==1.26.0\r\ngoogle-resumable-media==0.5.0\r\ngoogleapis-common-protos==1.51.0\r\ngorilla==0.3.0\r\ngreenlet==0.4.15\r\ngrpcio==1.28.1\r\ngunicorn==20.0.4\r\nh5py==2.10.0\r\nhydra-core==0.11.3\r\nicalendar==4.0.4\r\nidna==2.10\r\nimageio==2.8.0\r\nimagesize==1.2.0\r\nimportlib-metadata==1.7.0\r\nipykernel==5.2.0\r\nipython==7.13.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nitsdangerous==1.1.0\r\njedi==0.16.0\r\nJinja2==2.11.1\r\njmespath==0.10.0\r\njoblib==0.16.0\r\njson-lines==0.5.0\r\njsonlines==1.2.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonpointer==2.0\r\njsonref==0.2\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.2\r\njupyter-console==6.1.0\r\njupyter-core==4.6.3\r\nkiwisolver==1.1.0\r\nMako==1.1.2\r\nMarkdown==3.2.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.1\r\nmistune==0.8.4\r\nmlflow==1.8.0\r\nmonotonic==1.5\r\nmore-itertools==8.4.0\r\nmsgpack==1.0.0\r\nmsgpack-python==0.5.6\r\nmurmurhash==1.0.2\r\nnbconvert==5.6.1\r\nnbformat==5.0.4\r\nneptune-client==0.4.113\r\nnetworkx==2.4\r\nnltk==3.5\r\nnmslib==2.0.5\r\nnotebook==6.0.3\r\nnumpy==1.19.0\r\nnumpydoc==0.9.2\r\noauthlib==3.1.0\r\nomegaconf==1.4.1\r\nopencv-python==4.2.0.34\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==1.0.1\r\npandocfilters==1.4.2\r\nparsimonious==0.8.1\r\nparso==0.6.2\r\npathspec==0.8.0\r\npbr==5.4.5\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.0.0\r\npkg-resources==0.0.0\r\nplac==1.1.3\r\nplotly==4.5.4\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprettytable==0.7.2\r\nprometheus-client==0.7.1\r\nprometheus-flask-exporter==0.13.0\r\nprompt-toolkit==3.0.5\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npy==1.9.0\r\npy-rouge==1.1\r\npy3nvml==0.2.6\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npybind11==2.5.0\r\npycparser==2.20\r\npyfakewebcam==0.1.0\r\npygit==0.1\r\nPygments==2.6.1\r\nPyInstaller==3.6\r\nPyJWT==1.7.1\r\npyparsing==2.4.7\r\npyperclip==1.8.0\r\npyrsistent==0.16.0\r\npysbd==0.2.3\r\npyspellchecker==0.5.4\r\npytest==5.4.3\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython-Levenshtein==0.12.0\r\npytorch-lightning==0.7.5\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.1.0\r\npytz==2019.3\r\nPyWavelets==1.1.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.0\r\nqtconsole==4.7.2\r\nQtPy==1.9.0\r\nquerystring-parser==1.2.4\r\nregex==2020.6.8\r\nrequests==2.24.0\r\nrequests-oauthlib==1.3.0\r\nresponses==0.10.12\r\nretrying==1.3.3\r\nrfc3987==1.3.8\r\nrsa==3.4.2\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nSciencePlots==1.0.3\r\nscikit-image==0.16.2\r\nscikit-learn==0.23.1\r\nscipy==1.5.1\r\nseaborn==0.10.0\r\nsemantic-version==2.8.5\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsimplejson==3.17.0\r\nsix==1.15.0\r\nsklearn==0.0\r\nsmart-open==1.10.0\r\nsmmap==3.0.2\r\nsnowballstemmer==2.0.0\r\nsoupsieve==2.0\r\nspacy==2.2.4\r\nSphinx==2.4.4\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nSQLAlchemy==1.3.13\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\nstevedore==2.0.1\r\nstrict-rfc3339==0.7\r\nswagger-spec-validator==2.5.0\r\ntabulate==0.8.7\r\ntensorboard==2.2.1\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorboardX==2.1\r\nterminado==0.8.3\r\ntest-tube==0.7.5\r\ntestpath==0.4.4\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.8.1rc1\r\ntoml==0.10.0\r\ntoolz==0.10.0\r\ntorch==1.5.1\r\ntorchtext==0.6.0\r\ntorchvision==0.6.0\r\ntornado==6.0.4\r\ntqdm==4.47.0\r\ntraitlets==4.3.3\r\ntransformers==3.0.2\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\nUnidecode==1.1.1\r\nurllib3==1.25.9\r\nwasabi==0.7.0\r\nwcwidth==0.2.5\r\nwebcolors==1.11.1\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nWerkzeug==1.0.0\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nwordsegment==1.3.1\r\nxmltodict==0.12.0\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n\r\n### Reader\r\n```\r\nimport json\r\nfrom typing import Dict, Iterable, Optional, List\r\n\r\nfrom allennlp.data.dataset_readers.dataset_reader import DatasetReader\r\nfrom allennlp.data.fields import Field, TextField, LabelField, ListField\r\nfrom allennlp.data.instance import Instance\r\nfrom allennlp.data.token_indexers import TokenIndexer\r\nfrom allennlp.data.tokenizers import Tokenizer\r\nfrom allennlp.data.tokenizers.sentence_splitter import SpacySentenceSplitter\r\nfrom overrides import overrides\r\n\r\n\r\n@DatasetReader.register(\"custom_reader\")\r\nclass CustomReader(DatasetReader):\r\n    def __init__(\r\n        self,\r\n        tokenizer: Tokenizer,\r\n        token_indexers: Dict[str, TokenIndexer],\r\n        segment_sentences: bool,\r\n        **kwargs,\r\n    ) -> None:\r\n        super().__init__(**kwargs)\r\n        self._tokenizer = tokenizer\r\n        self._token_indexers = token_indexers\r\n        self._segment_sentences = segment_sentences\r\n        if self._segment_sentences:\r\n            self._sentence_segmenter = SpacySentenceSplitter(language=\"en_core_sci_sm\")\r\n\r\n    @overrides\r\n    def _read(self, file_path: str) -> Iterable[Instance]:\r\n        with open(file_path, \"r\") as file:\r\n            for line in file:\r\n                example = json.loads(line)\r\n\r\n                yield self.text_to_instance(\r\n                    text1=example[\"text1\"],\r\n                    text2=example[\"text2\"],\r\n                    label=example.get(\"label\"),\r\n                )\r\n\r\n    def __get_text_fields(self, text: str, prefix_name: str) -> Dict[str, Field]:\r\n        fields: Dict[str, Field] = {}\r\n\r\n        if not self._segment_sentences:\r\n            tokens = self._tokenizer.tokenize(text)\r\n            fields[f\"{prefix_name}_tokens\"] = TextField(tokens, self._token_indexers)\r\n            return fields\r\n\r\n        sentences: List[Field] = []\r\n        sentence_splits = self._sentence_segmenter.split_sentences(text)\r\n        for sentence in sentence_splits:\r\n            tokens = self._tokenizer.tokenize(sentence)\r\n            sentences.append(TextField(tokens, self._token_indexers))\r\n\r\n        fields[f\"{prefix_name}_tokens\"] = ListField(sentences)\r\n        return fields\r\n\r\n    @overrides\r\n    def text_to_instance(\r\n        self, text1: str, text2: str, label: Optional[int] = None\r\n    ) -> Instance:\r\n        text1_fields = self.__get_text_fields(text1 prefix_name=\"text1\")\r\n        text2_fields = self.__get_text_fields(text2, prefix_name=\"text2\")\r\n        fields = {**text1_fields, **text2_fields}\r\n\r\n        if label is not None:\r\n            fields[\"labels\"] = LabelField(label, skip_indexing=True)\r\n\r\n        return Instance(fields)\r\n```\r\n\r\n### Related Config\r\n```\r\n  dataset_reader: {\r\n    type: 'custom_reader',\r\n    segment_sentences: true,\r\n    tokenizer: {\r\n      type: 'pretrained_transformer',\r\n      model_name: 'allenai/scibert_scivocab_cased',\r\n    },\r\n    token_indexers: {\r\n      tokens: {\r\n        type: 'pretrained_transformer',\r\n        model_name: 'allenai/scibert_scivocab_cased',\r\n        max_length: 512,\r\n      },\r\n    },\r\n\r\n    // DatasetReader's fields\r\n    max_instances: 10,\r\n    lazy: true,\r\n  },\r\n  data_loader: {\r\n    batch_size: 2\r\n  },\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4494", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4494/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4494/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4494/events", "html_url": "https://github.com/allenai/allennlp/issues/4494", "id": 660828528, "node_id": "MDU6SXNzdWU2NjA4Mjg1Mjg=", "number": 4494, "title": "[Suggestion] One line change in the comments", "user": {"login": "WweiL", "id": 10248890, "node_id": "MDQ6VXNlcjEwMjQ4ODkw", "avatar_url": "https://avatars0.githubusercontent.com/u/10248890?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WweiL", "html_url": "https://github.com/WweiL", "followers_url": "https://api.github.com/users/WweiL/followers", "following_url": "https://api.github.com/users/WweiL/following{/other_user}", "gists_url": "https://api.github.com/users/WweiL/gists{/gist_id}", "starred_url": "https://api.github.com/users/WweiL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WweiL/subscriptions", "organizations_url": "https://api.github.com/users/WweiL/orgs", "repos_url": "https://api.github.com/users/WweiL/repos", "events_url": "https://api.github.com/users/WweiL/events{/privacy}", "received_events_url": "https://api.github.com/users/WweiL/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-19T13:10:20Z", "updated_at": "2020-07-31T16:16:15Z", "closed_at": "2020-07-31T16:16:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nhttps://github.com/allenai/allennlp/blob/master/allennlp/data/dataloader.py#L54\r\nThis line should be deleted as allennlp_collate is moved to the dataloader.py file itself.\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nhttps://github.com/allenai/allennlp/blob/master/allennlp/data/dataloader.py#L54\r\nThis line should be deleted as allennlp_collate is moved to the dataloader.py file itself.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\nN/A\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\nN/A\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n\r\n\r\n## Steps to reproduce\r\n\r\nSee the page: https://github.com/allenai/allennlp/blob/master/allennlp/data/dataloader.py#L54", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4492", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4492/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4492/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4492/events", "html_url": "https://github.com/allenai/allennlp/issues/4492", "id": 659969907, "node_id": "MDU6SXNzdWU2NTk5Njk5MDc=", "number": 4492, "title": "Getting error while building Allennlp", "user": {"login": "faysalhossain2007", "id": 1239654, "node_id": "MDQ6VXNlcjEyMzk2NTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1239654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/faysalhossain2007", "html_url": "https://github.com/faysalhossain2007", "followers_url": "https://api.github.com/users/faysalhossain2007/followers", "following_url": "https://api.github.com/users/faysalhossain2007/following{/other_user}", "gists_url": "https://api.github.com/users/faysalhossain2007/gists{/gist_id}", "starred_url": "https://api.github.com/users/faysalhossain2007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/faysalhossain2007/subscriptions", "organizations_url": "https://api.github.com/users/faysalhossain2007/orgs", "repos_url": "https://api.github.com/users/faysalhossain2007/repos", "events_url": "https://api.github.com/users/faysalhossain2007/events{/privacy}", "received_events_url": "https://api.github.com/users/faysalhossain2007/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-18T07:15:17Z", "updated_at": "2020-07-24T15:45:40Z", "closed_at": "2020-07-24T15:45:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n I am using python 3.7 in conda environment. I have installed allenlp using the pip command. Now I want to run the basic function using allennlp:\r\n```    \r\nal = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")\r\n    al.predict(\"my age is 14.\")\r\n```\r\nand it is throwing the following exception:\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```Traceback (most recent call last):\r\n  File \"/home/faysal/code/uiuc/dataprivacy/analyzer/src/detector.py\", line 102, in <module>\r\n    run()\r\n  File \"/home/faysal/code/uiuc/dataprivacy/analyzer/src/detector.py\", line 95, in run\r\n    detect_using_allennlp()\r\n  File \"/home/faysal/code/uiuc/dataprivacy/analyzer/src/detector.py\", line 11, in detect_using_allennlp\r\n    al = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 275, in from_path\r\n    load_archive(archive_path, cuda_device=cuda_device),\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/models/archival.py\", line 199, in load_archive\r\n    opt_level=opt_level,\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/models/model.py\", line 406, in load\r\n    return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/models/model.py\", line 303, in _load\r\n    model = Model.from_params(vocab=vocab, params=model_params)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 609, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 181, in create_kwargs\r\n    cls.__name__, param_name, annotation, param.default, params, **extras\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 287, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 321, in construct_arg\r\n    return annotation.from_params(params=popped_params, **subextras)\r\n  File \"/home/faysal/anaconda3/envs/python3_7/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 533, in from_params\r\n    \"from_params was passed a `params` object that was not a `Params`. This probably \"\r\nallennlp.common.checks.ConfigurationError: from_params was passed a `params` object that was not a `Params`. This probably indicates malformed parameters in a configuration file, where something that should have been a dictionary was actually a list, or something else. This happened when constructing an object of type <class 'allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator'>.\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04 LTS\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.7.7 \r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nallennlp==1.1.0rc2.dev20200717\r\nallennlp-models==1.1.0rc2.dev20200717\r\nasgiref==3.2.7\r\nastor==0.7.1\r\nastunparse==1.6.3\r\nattrs==19.3.0\r\nbeautifulsoup4==4.9.0\r\nblinker==1.4\r\nblis==0.4.1\r\nboto3==1.14.23\r\nbotocore==1.17.23\r\nbrotlipy==0.7.0\r\nbs4==0.0.1\r\ncachetools==4.1.0\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncolorama==0.4.3\r\nconllu==3.0\r\ncryptography==2.9.2\r\ncssselect==1.1.0\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nDjango==3.0.6\r\ndocutils==0.15.2\r\nesprima==4.0.1\r\nfilelock==3.0.12\r\nfire==0.3.1\r\nfuture==0.18.2\r\ngast==0.3.3\r\ngoogle-api-core==1.17.0\r\ngoogle-auth==1.17.2\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-cloud-bigquery==1.24.0\r\ngoogle-cloud-core==1.3.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==0.5.0\r\ngoogleapis-common-protos==1.51.0\r\ngraphviz==0.14\r\ngrpcio==1.27.2\r\nh5py==2.10.0\r\nhtml5lib==1.1\r\nidna==2.9\r\nimage==1.5.32\r\nimportlib-metadata==1.6.1\r\njmespath==0.10.0\r\njoblib==0.13.2\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nKeras==2.3.1\r\nKeras-Applications==1.0.8\r\nkeras-metrics==1.1.0\r\nKeras-Preprocessing==1.1.0\r\nkiwisolver==1.2.0\r\n-e git+https://github.com/lgsvl/PythonAPI.git@183ccdcb1d66fb827c074aaadacc012ec33da306#egg=lgsvl\r\nlxml==4.5.1\r\nMako==1.1.0\r\nMarkdown==3.2.2\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.1\r\nmkl-fft==1.0.15\r\nmkl-random==1.1.0\r\nmkl-service==2.3.0\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nneobolt==1.7.17\r\nneotime==1.7.4\r\nnltk==3.5\r\nnumpy==1.18.1\r\noauthlib==3.0.1\r\nopencv-python==4.2.0.34\r\nopt-einsum==0+untagged.56.g2664021.dirty\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas==1.0.3\r\nparse==1.15.0\r\nPillow==7.1.2\r\nplac==1.1.3\r\npluggy==0.13.1\r\nply==3.11\r\npreshed==3.0.2\r\nprompt-toolkit==3.0.5\r\nprotobuf==3.12.3\r\npy==1.9.0\r\npy-rouge==1.1\r\npy2neo==4.2.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\nPygments==2.6.1\r\npygpu==0.7.6\r\nPyJWT==1.7.1\r\npyOpenSSL==19.1.0\r\npyparsing==2.4.7\r\npyquery==1.4.1\r\nPySocks==1.7.1\r\npytest==5.4.3\r\npython-dateutil==2.8.1\r\npytz==2020.1\r\npywebcopy==6.3.0\r\nPyYAML==5.3.1\r\nregex==2020.7.14\r\nrequests==2.24.0\r\nrequests-oauthlib==1.2.0\r\nrsa==4.6\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.22.1\r\nscipy==1.4.1\r\nselenium==3.141.0\r\nsentencepiece==0.1.91\r\nsix==1.14.0\r\nslimit==0.8.1\r\nsoupsieve==2.0.1\r\nspacy==2.2.4\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\ntensorboard==2.2.2\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorboardX==2.1\r\ntensorflow==2.2.0\r\ntensorflow-estimator==2.2.0\r\ntermcolor==1.1.0\r\nTheano==1.0.4\r\nthinc==7.4.0\r\ntokenizers==0.8.1rc1\r\ntorch==1.5.0\r\ntorchvision==0.6.0\r\ntqdm==4.47.0\r\ntransformers==3.0.2\r\nurllib3==1.25.9\r\nw3lib==1.22.0\r\nwasabi==0.7.1\r\nwcwidth==0.1.9\r\nwebencodings==0.5.1\r\nwebsockets==7.0\r\nWerkzeug==1.0.1\r\nword2number==1.1\r\nwrapt==1.12.1\r\nzipp==3.1.0\r\n\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4491", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4491/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4491/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4491/events", "html_url": "https://github.com/allenai/allennlp/issues/4491", "id": 659648206, "node_id": "MDU6SXNzdWU2NTk2NDgyMDY=", "number": 4491, "title": "Copyright notice?", "user": {"login": "ajorg-aws", "id": 19536151, "node_id": "MDQ6VXNlcjE5NTM2MTUx", "avatar_url": "https://avatars3.githubusercontent.com/u/19536151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajorg-aws", "html_url": "https://github.com/ajorg-aws", "followers_url": "https://api.github.com/users/ajorg-aws/followers", "following_url": "https://api.github.com/users/ajorg-aws/following{/other_user}", "gists_url": "https://api.github.com/users/ajorg-aws/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajorg-aws/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajorg-aws/subscriptions", "organizations_url": "https://api.github.com/users/ajorg-aws/orgs", "repos_url": "https://api.github.com/users/ajorg-aws/repos", "events_url": "https://api.github.com/users/ajorg-aws/events{/privacy}", "received_events_url": "https://api.github.com/users/ajorg-aws/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2020-07-17T21:15:48Z", "updated_at": "2020-08-20T16:39:24Z", "closed_at": "2020-08-20T16:07:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "What is the correct copyright notice for this project? To use the project in some other project or product, we would normally add a copyright notice to an attribution document or third-party notices file, but I don't find any copyright notice in this project at all.\r\n\r\nIt looks like the Apache-2.0 license only requires that we attribute this project *if* the project includes a NOTICES file (condition 4(d)), so possibly this is intentional in order to not trigger that requirement.\r\n\r\nWe do find a copyright notice on https://allennlp.org/ but those often don't apply to the software because the software usually has contributors outside the parent organization.\r\n\r\n> \u00a9 The Allen Institute for Artificial Intelligence - All Rights Reserved.\r\n\r\nThere's some guidance at the bottom of the license as to [how to apply the license to your work](https://www.apache.org/licenses/LICENSE-2.0#apply) and there's also an [example NOTICE file](https://www.apache.org/licenses/example-NOTICE.txt) provided by the foundation.\r\n\r\nI don't want to suggest any particular action, rather I'm just seeking clarity so we can be sure we're complying with your license correctly.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4490", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4490/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4490/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4490/events", "html_url": "https://github.com/allenai/allennlp/issues/4490", "id": 658750294, "node_id": "MDU6SXNzdWU2NTg3NTAyOTQ=", "number": 4490, "title": "Using Word and Character level embeddings", "user": {"login": "lianna1016", "id": 31545387, "node_id": "MDQ6VXNlcjMxNTQ1Mzg3", "avatar_url": "https://avatars0.githubusercontent.com/u/31545387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lianna1016", "html_url": "https://github.com/lianna1016", "followers_url": "https://api.github.com/users/lianna1016/followers", "following_url": "https://api.github.com/users/lianna1016/following{/other_user}", "gists_url": "https://api.github.com/users/lianna1016/gists{/gist_id}", "starred_url": "https://api.github.com/users/lianna1016/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lianna1016/subscriptions", "organizations_url": "https://api.github.com/users/lianna1016/orgs", "repos_url": "https://api.github.com/users/lianna1016/repos", "events_url": "https://api.github.com/users/lianna1016/events{/privacy}", "received_events_url": "https://api.github.com/users/lianna1016/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-17T01:59:48Z", "updated_at": "2020-07-17T02:24:46Z", "closed_at": "2020-07-17T02:24:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello! \r\n\r\nI am very new to AllenNLP and am trying to create an NER LSTM model. I have gotten it to use the word2vec embeddings, but I am also trying to add character level embeddings as well for out of vocab words. I have been looking for examples on how to do this but cannot find a clear one. Are there any resources you could point me towards? \r\n\r\nBelow is a screenshot of an attempt with a config file\r\n\r\n![image](https://user-images.githubusercontent.com/31545387/87740115-666f5d00-c7af-11ea-9ae9-ec1daaa3fac4.png)\r\n\r\nAn error that I get is \r\n```allennlp.common.checks.ConfigurationError: Mismatched token keys: dict_keys(['token_characters', 'tokens']) and dict_keys(['tokens'])```\r\n\r\nThanks so much! \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4489", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4489/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4489/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4489/events", "html_url": "https://github.com/allenai/allennlp/issues/4489", "id": 658705586, "node_id": "MDU6SXNzdWU2NTg3MDU1ODY=", "number": 4489, "title": "Set Detectron2 version as v0.2", "user": {"login": "j-min", "id": 18069263, "node_id": "MDQ6VXNlcjE4MDY5MjYz", "avatar_url": "https://avatars3.githubusercontent.com/u/18069263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-min", "html_url": "https://github.com/j-min", "followers_url": "https://api.github.com/users/j-min/followers", "following_url": "https://api.github.com/users/j-min/following{/other_user}", "gists_url": "https://api.github.com/users/j-min/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-min/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-min/subscriptions", "organizations_url": "https://api.github.com/users/j-min/orgs", "repos_url": "https://api.github.com/users/j-min/repos", "events_url": "https://api.github.com/users/j-min/events{/privacy}", "received_events_url": "https://api.github.com/users/j-min/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/14", "html_url": "https://github.com/allenai/allennlp/milestone/14", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/14/labels", "id": 5601713, "node_id": "MDk6TWlsZXN0b25lNTYwMTcxMw==", "number": 14, "title": "2.0", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 9, "closed_issues": 6, "state": "open", "created_at": "2020-06-30T17:05:12Z", "updated_at": "2020-08-18T11:41:12Z", "due_on": null, "closed_at": null}, "comments": 2, "created_at": "2020-07-17T00:44:44Z", "updated_at": "2020-07-17T12:12:12Z", "closed_at": "2020-07-17T12:12:12Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Let's fix Detectron2 version as v0.2, the latest release version.\r\nIn [setup.py](https://github.com/allenai/allennlp/blob/DetectronNLVR/setup.py#L71), we could change\r\n`\"detectron2 @ git+https://github.com/facebookresearch/detectron2\"`\r\nto `\"detectron2 @ git+https://github.com/facebookresearch/detectron2@v0.2\"`\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4482", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4482/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4482/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4482/events", "html_url": "https://github.com/allenai/allennlp/issues/4482", "id": 657674053, "node_id": "MDU6SXNzdWU2NTc2NzQwNTM=", "number": 4482, "title": "Allow training of specific layers of pretrained transformers", "user": {"login": "successar", "id": 1499824, "node_id": "MDQ6VXNlcjE0OTk4MjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1499824?v=4", "gravatar_id": "", "url": "https://api.github.com/users/successar", "html_url": "https://github.com/successar", "followers_url": "https://api.github.com/users/successar/followers", "following_url": "https://api.github.com/users/successar/following{/other_user}", "gists_url": "https://api.github.com/users/successar/gists{/gist_id}", "starred_url": "https://api.github.com/users/successar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/successar/subscriptions", "organizations_url": "https://api.github.com/users/successar/orgs", "repos_url": "https://api.github.com/users/successar/repos", "events_url": "https://api.github.com/users/successar/events{/privacy}", "received_events_url": "https://api.github.com/users/successar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-07-15T21:33:58Z", "updated_at": "2020-07-24T20:35:49Z", "closed_at": "2020-07-24T20:35:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently pretrained transformer embedders allow training of either or none of the parameters in a model. I would like to be able to training only specific layers -- say top 2 while keeping everything else fixed.\r\n\r\n**Describe the solution you'd like**\r\nCurrent the model takes in a boolean train_parameters option here https://github.com/allenai/allennlp/blob/53eeec105fa0da91a7793e45c66b9cec14c45dff/allennlp/modules/token_embedders/pretrained_transformer_embedder.py#L82\r\nWe can put it as a Union of bool or list of regexes type. Bool input will work same as current version (for backward compatibility); while with regex list, we will match each parameter name with the each regex and set required=True for those that match any of the regexes. Currently I don't forsee any big issues with this setup and looking for teams opinion before implementing it as pull request.\r\n\r\n**Describe alternatives you've considered**\r\nCurrently I specify regexes as part of my outer model but that is not clean when I am using TextFieldEmbedder API and breaks the dependency structure.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4480", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4480/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4480/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4480/events", "html_url": "https://github.com/allenai/allennlp/issues/4480", "id": 657412500, "node_id": "MDU6SXNzdWU2NTc0MTI1MDA=", "number": 4480, "title": "Inconsistency in answers generated by ELMo-Bidaf( trained on SQuAD) Demo and downloaded ", "user": {"login": "sukeshlaghate", "id": 25061957, "node_id": "MDQ6VXNlcjI1MDYxOTU3", "avatar_url": "https://avatars1.githubusercontent.com/u/25061957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sukeshlaghate", "html_url": "https://github.com/sukeshlaghate", "followers_url": "https://api.github.com/users/sukeshlaghate/followers", "following_url": "https://api.github.com/users/sukeshlaghate/following{/other_user}", "gists_url": "https://api.github.com/users/sukeshlaghate/gists{/gist_id}", "starred_url": "https://api.github.com/users/sukeshlaghate/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sukeshlaghate/subscriptions", "organizations_url": "https://api.github.com/users/sukeshlaghate/orgs", "repos_url": "https://api.github.com/users/sukeshlaghate/repos", "events_url": "https://api.github.com/users/sukeshlaghate/events{/privacy}", "received_events_url": "https://api.github.com/users/sukeshlaghate/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-15T14:48:37Z", "updated_at": "2020-07-20T10:43:59Z", "closed_at": "2020-07-20T10:43:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe the bug**\r\nInconsistent answers generated by `bidaf-elmo-model-2020.03.19.tar.gz` model when run in Allennlp demo website and when run on local machine after downloading the model.\r\n\r\n**Steps to reproduce the behavior**\r\nI followed instructions given in the usage section of online demo for reading comprehension \r\n\r\n1. conda create --name allennlp python=3.7\r\n2. conda activate allennlp\r\n3. conda install -c conda-forge jsonnet\r\n4. pip install allennlp==1.0.0 allennlp-models==1.0.0\r\n5. download bidaf-elmo model and store in folder\r\n     5a. download from `https://storage.googleapis.com/allennlp-public-models/bidaf-elmo-model-2020.03.19.tar.gz` \r\n     5b. move it to python notebook location `~/sandbox/python/`\r\n\r\nUsed following python code as given in Usage section of allennlp demo website\r\n~~~~\r\n \r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.rc\r\n\r\nmodel_path = r\"~/sandbox/python/rc_model\"\r\npredictor = Predictor.from_path(model_path)\r\n\r\ntext =\"Becuase Pepsodent is a trusted brand. it has 130% germ attack power.\"\r\n\r\nwhat_benefit = 'What is the benefit?'\r\nwhy_use = 'Why use?'\r\n\r\n\r\nwhy_answer = predictor.predict_json({\r\n    \"passage\": text,\r\n    \"question\": why_use\r\n})\r\n\r\nprint(f\"Answer for why should I use :{why_answer['best_span_str']}\")\r\n# Expected answer is Pepsodent is trusted brand.\r\n\r\nwhat_answer = predictor.predict(\r\n  passage=text,\r\n  question=what_benefit\r\n)\r\n\r\nprint(f\"Answer for what is the benefit: {what_answer['best_span_str']}\")\r\n# Expected answer is 130% germ attack power\r\n\r\n~~~~\r\n\r\n**Expected behavior**\r\nFor why question expected answer is  \"Pepsodent is trusted brand.\"\r\nFor what question expected answer is \"130% germ attack power\"\r\n\r\nActual answer for both cases is \"130% germ attack power\" refer  screen shot below\r\n\r\n![Downloaded_Model_answers](https://user-images.githubusercontent.com/25061957/87558881-3b193f00-c6d7-11ea-8786-7be8b8dd0d55.jpg)\r\n\r\nHowever when same passage and questions are fed into online demo, the model generates expected responses  please refer to the screen shots\r\n\r\nResponse for what is the benefit question\r\n![Allennlp_Demo_What_is_benifit_Answer](https://user-images.githubusercontent.com/25061957/87558621-f1c8ef80-c6d6-11ea-92f9-d65317da9532.jpg)\r\n\r\nResponse for why use question\r\n![Allennlp_Demo_Why_Use_Answer](https://user-images.githubusercontent.com/25061957/87558920-47050100-c6d7-11ea-9f56-7ff5b8654b1c.jpg)\r\n\r\n**System**\r\n\r\n    OS: [ubuntu 20.0.4]\r\n    Python version: [3.7.6]\r\n    AllenNLP version: [ v1.0.0]\r\n\r\nRequest you to help in resolving this inconsistency. \r\nAny pointers/ insights/ solutions are much appreciated.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4478", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4478/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4478/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4478/events", "html_url": "https://github.com/allenai/allennlp/issues/4478", "id": 657288336, "node_id": "MDU6SXNzdWU2NTcyODgzMzY=", "number": 4478, "title": "loss computed by ConditionalRandomField.forward() exceeds 10^29", "user": {"login": "flyangovoyang", "id": 45290558, "node_id": "MDQ6VXNlcjQ1MjkwNTU4", "avatar_url": "https://avatars2.githubusercontent.com/u/45290558?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flyangovoyang", "html_url": "https://github.com/flyangovoyang", "followers_url": "https://api.github.com/users/flyangovoyang/followers", "following_url": "https://api.github.com/users/flyangovoyang/following{/other_user}", "gists_url": "https://api.github.com/users/flyangovoyang/gists{/gist_id}", "starred_url": "https://api.github.com/users/flyangovoyang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flyangovoyang/subscriptions", "organizations_url": "https://api.github.com/users/flyangovoyang/orgs", "repos_url": "https://api.github.com/users/flyangovoyang/repos", "events_url": "https://api.github.com/users/flyangovoyang/events{/privacy}", "received_events_url": "https://api.github.com/users/flyangovoyang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-07-15T11:48:38Z", "updated_at": "2020-07-27T02:12:39Z", "closed_at": "2020-07-23T07:05:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, I am doing a NER task with single entity class.\r\nwhen training, the loss returned by `forward()` exceeds 10^29, and the result on evaluation dataset is terrible, F1 is nearly 0.\r\n```python\r\n# from allennlp.modules.conditional_random_field import ConditionalRandomField as crf_layer\r\n# ...\r\n\r\ndef train(...):\r\n    #...\r\n            if use_crf:\r\n                loss = -self.crf_layer.forward(inputs=token_logits, tags=tags, mask=input_masks)/token_logits.size(0)\r\n                return loss\r\n```\r\nrelated hyper-parameters are: batch_size=128, and num_tags=3, max_seq_len=100, learing_rate=1e-5\r\n\r\nI also tried CrossEntropy as my loss function, the loss of the first step is a normal value, about 1.3, which decreases during the training procedure.\r\n\r\nAnyone can help me out? My sincerely thanks~", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4474", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4474/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4474/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4474/events", "html_url": "https://github.com/allenai/allennlp/issues/4474", "id": 656705502, "node_id": "MDU6SXNzdWU2NTY3MDU1MDI=", "number": 4474, "title": "[Models] Wrong usage of *cls_pooler* in the SST Roberta model", "user": {"login": "dcfidalgo", "id": 15979778, "node_id": "MDQ6VXNlcjE1OTc5Nzc4", "avatar_url": "https://avatars2.githubusercontent.com/u/15979778?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcfidalgo", "html_url": "https://github.com/dcfidalgo", "followers_url": "https://api.github.com/users/dcfidalgo/followers", "following_url": "https://api.github.com/users/dcfidalgo/following{/other_user}", "gists_url": "https://api.github.com/users/dcfidalgo/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcfidalgo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcfidalgo/subscriptions", "organizations_url": "https://api.github.com/users/dcfidalgo/orgs", "repos_url": "https://api.github.com/users/dcfidalgo/repos", "events_url": "https://api.github.com/users/dcfidalgo/events{/privacy}", "received_events_url": "https://api.github.com/users/dcfidalgo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-07-14T15:33:59Z", "updated_at": "2020-07-24T20:43:58Z", "closed_at": "2020-07-24T20:43:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [ ] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [ ] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nI think the usage of the *cls_pooler* as `seq2vec_encoder` is not appropriate [in this model](https://github.com/allenai/allennlp-models/blob/888596c8d41fcde755e91ca00474b88009175700/training_config/classification/stanford_sentiment_treebank_roberta.jsonnet#L44). If i am not mistaken the `PretrainedTransformerMismatchedIndexer/Embedder` get rid of the special tokens via the `offsets`, so the *cls_pooler* just takes the embedding of the first \"real text\" token.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 20.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\naiohttp==3.6.2\r\nalembic==1.4.2\r\nallennlp==1.0.0\r\nappdirs==1.4.4\r\nastroid==2.4.2\r\nasync-timeout==3.0.1\r\nattrs==19.3.0\r\nazure-core==1.7.0\r\nazure-storage-blob==12.3.2\r\nbackcall==0.2.0\r\nbeautifulsoup4==4.9.1\r\n-e git+git@github.com:recognai/biome-text.git@7a22136a713f634587702e096f778ea44aa94123#egg=biome_text\r\nblack==19.10b0\r\nbleach==3.1.5\r\nblis==0.4.1\r\nbokeh==2.0.2\r\nboto3==1.14.7\r\nbotocore==1.17.7\r\ncachetools==4.1.1\r\ncachey==0.2.1\r\ncaptum==0.2.0\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncloudpickle==1.4.1\r\ncolorama==0.4.3\r\ncoverage==5.1\r\ncryptography==2.9.2\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndask==2.17.2\r\ndask-elk==0.4.0\r\ndatabricks-cli==0.11.0\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndistributed==2.19.0\r\ndocker==4.2.2\r\ndocutils==0.15.2\r\nelasticsearch==7.8.0\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nfastapi==0.55.1\r\nfilelock==3.0.12\r\nFlask==1.1.2\r\nFlask-Cors==3.0.8\r\nflatdict==4.0.1\r\nfsspec==0.7.4\r\nfuture==0.18.2\r\ngevent==1.4.0\r\ngitdb==4.0.5\r\nGitPython==3.1.3\r\ngoogle==2.0.3\r\ngoogle-auth==1.18.0\r\ngoogle-auth-oauthlib==0.4.1\r\ngorilla==0.3.0\r\ngreenlet==0.4.16\r\ngrpcio==1.30.0\r\ngunicorn==20.0.4\r\nh11==0.9.0\r\nh5py==2.10.0\r\nHeapDict==1.0.1\r\nhttptools==0.1.1\r\nidna==2.9\r\nimportlib-metadata==1.6.1\r\nimportlib-resources==2.0.1\r\nipykernel==5.3.0\r\nipython==7.15.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nisodate==0.6.0\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njedi==0.17.1\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njson5==0.9.5\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter-client==6.1.3\r\njupyter-core==4.6.3\r\njupyterlab==2.1.5\r\njupyterlab-server==1.1.5\r\nkiwisolver==1.2.0\r\nlazy-object-proxy==1.4.3\r\nlocket==0.2.0\r\nlxml==4.5.1\r\nMako==1.1.3\r\nMarkdown==3.2.2\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.2\r\nmccabe==0.6.1\r\nmemory-profiler==0.57.0\r\nmistune==0.8.4\r\nmkl-fft==1.1.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmlflow==1.9.1\r\nmore-itertools==8.4.0\r\nmsgpack==0.6.2\r\nmsrest==0.6.17\r\nmultidict==4.7.6\r\nmurmurhash==1.0.2\r\nnbconvert==5.6.1\r\nnbdime==2.0.0\r\nnbformat==5.0.7\r\nnltk==3.5\r\nnotebook==6.0.3\r\nnumpy==1.18.1\r\noauthlib==3.1.0\r\nolefile==0.46\r\noverrides==3.0.0\r\npackaging==20.4\r\npandas==1.0.5\r\npandocfilters==1.4.2\r\nparso==0.7.0\r\npartd==1.1.0\r\npathspec==0.8.0\r\npdoc3==0.8.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.1.2\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprometheus-client==0.8.0\r\nprometheus-flask-exporter==0.14.1\r\nprompt-toolkit==3.0.5\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npy==1.8.2\r\npy-spy==0.3.3\r\npyarrow==0.17.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\npydantic==1.5.1\r\nPygments==2.6.1\r\npygraphviz==1.3\r\npylint==2.5.3\r\npyparsing==2.4.7\r\npyrsistent==0.16.0\r\npytest==5.4.3\r\npytest-cov==2.10.0\r\npytest-notebook==0.6.0\r\npytest-pylint==0.14.1\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npytz==2020.1\r\nPyYAML==5.3.1\r\npyzmq==19.0.1\r\nquerystring-parser==1.2.4\r\nray==0.8.6\r\nredis==3.4.1\r\nregex==2020.6.8\r\nrequests==2.24.0\r\nrequests-oauthlib==1.3.0\r\nrsa==4.6\r\ns3fs==0.4.2\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.5.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nsmmap==3.0.4\r\nsortedcontainers==2.2.2\r\nsoupsieve==2.0.1\r\nspacy==2.2.4\r\nSQLAlchemy==1.3.13\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\nstarlette==0.13.2\r\ntabulate==0.8.7\r\ntblib==1.6.0\r\ntensorboard==2.2.2\r\ntensorboard-plugin-wit==1.7.0\r\ntensorboardX==2.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.1\r\ntoolz==0.10.0\r\ntorch==1.5.1\r\ntorchvision==0.6.0a0+35d732a\r\ntornado==6.0.4\r\ntqdm==4.46.1\r\ntraitlets==4.3.3\r\ntransformers==2.11.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\nujson==2.0.3\r\nurllib3==1.25.9\r\nuvicorn==0.11.5\r\nuvloop==0.14.0\r\nwasabi==0.7.0\r\nwcwidth==0.2.4\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nwebsockets==8.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nwrapt==1.12.1\r\nxlrd==1.2.0\r\nyarl==1.4.2\r\nzict==2.0.0\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.data.tokenizers import SpacyTokenizer\r\nfrom allennlp.data.token_indexers import PretrainedTransformerMismatchedIndexer\r\nfrom allennlp.data.fields import TextField\r\nfrom allennlp.data.vocabulary import Vocabulary\r\nfrom allennlp.data.instance import Instance\r\nfrom allennlp.data import Batch\r\n\r\nfrom allennlp.modules.token_embedders import PretrainedTransformerMismatchedEmbedder\r\nfrom allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\r\n\r\n\r\ninput_str = \"Check this annoying string!\"\r\n\r\ntokenizer = SpacyTokenizer()\r\ntoken_indexer = {\r\n    \"tokens\": PretrainedTransformerMismatchedIndexer(\r\n        model_name=\"distilroberta-base\"\r\n    )\r\n}\r\n\r\ntf = TextField(tokenizer.tokenize(input_str), token_indexer)\r\ninstance = Instance({\"text\": tf})\r\nvocab = Vocabulary.from_instances([instance])\r\nbatch = Batch([instance])\r\nbatch.index_instances(vocab)\r\npadding_length = batch.get_padding_lengths()\r\n\r\nembedder = PretrainedTransformerMismatchedEmbedder(\r\n    model_name=\"distilroberta-base\"\r\n)\r\ntf_embedder = BasicTextFieldEmbedder({\"tokens\": embedder})\r\n\r\ntensor_dict = batch.as_tensor_dict(padding_length)\r\nembeddings = tf_embedder(tensor_dict[\"text\"])\r\n\r\nprint(tf)\r\nprint(tensor_dict)\r\nprint(embeddings)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4471", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4471/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4471/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4471/events", "html_url": "https://github.com/allenai/allennlp/issues/4471", "id": 656037144, "node_id": "MDU6SXNzdWU2NTYwMzcxNDQ=", "number": 4471, "title": "How to get results up to 4 decimal points in SpanBasedF1Measure, CategoricalAccuracy and other metrics", "user": {"login": "abubakar-ucr", "id": 39277339, "node_id": "MDQ6VXNlcjM5Mjc3MzM5", "avatar_url": "https://avatars2.githubusercontent.com/u/39277339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abubakar-ucr", "html_url": "https://github.com/abubakar-ucr", "followers_url": "https://api.github.com/users/abubakar-ucr/followers", "following_url": "https://api.github.com/users/abubakar-ucr/following{/other_user}", "gists_url": "https://api.github.com/users/abubakar-ucr/gists{/gist_id}", "starred_url": "https://api.github.com/users/abubakar-ucr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abubakar-ucr/subscriptions", "organizations_url": "https://api.github.com/users/abubakar-ucr/orgs", "repos_url": "https://api.github.com/users/abubakar-ucr/repos", "events_url": "https://api.github.com/users/abubakar-ucr/events{/privacy}", "received_events_url": "https://api.github.com/users/abubakar-ucr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-13T18:00:59Z", "updated_at": "2020-07-29T06:07:05Z", "closed_at": "2020-07-29T06:07:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, how can I get results up to 4 decimal points in SpanBasedF1Measure, CategoricalAccuracy and other metrics in evaluate(...) method? By default, it only shows up to 2 points, and I see other libs (e.g., scikit-learn) takes in an argument to specify the precision value? Does AllenNLP have something like this that I am not aware of?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4467", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4467/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4467/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4467/events", "html_url": "https://github.com/allenai/allennlp/issues/4467", "id": 655810461, "node_id": "MDU6SXNzdWU2NTU4MTA0NjE=", "number": 4467, "title": "Question on output of SRL model", "user": {"login": "panwarnaveen9", "id": 5768823, "node_id": "MDQ6VXNlcjU3Njg4MjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5768823?v=4", "gravatar_id": "", "url": "https://api.github.com/users/panwarnaveen9", "html_url": "https://github.com/panwarnaveen9", "followers_url": "https://api.github.com/users/panwarnaveen9/followers", "following_url": "https://api.github.com/users/panwarnaveen9/following{/other_user}", "gists_url": "https://api.github.com/users/panwarnaveen9/gists{/gist_id}", "starred_url": "https://api.github.com/users/panwarnaveen9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/panwarnaveen9/subscriptions", "organizations_url": "https://api.github.com/users/panwarnaveen9/orgs", "repos_url": "https://api.github.com/users/panwarnaveen9/repos", "events_url": "https://api.github.com/users/panwarnaveen9/events{/privacy}", "received_events_url": "https://api.github.com/users/panwarnaveen9/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2276693919, "node_id": "MDU6TGFiZWwyMjc2NjkzOTE5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "aaaaaa", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-13T12:26:49Z", "updated_at": "2020-08-18T16:18:26Z", "closed_at": "2020-08-18T16:18:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "```python\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport spacy\r\n\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz\")\r\n\r\nsentence = \"Apple corporation sold 1 million computers this month\"\r\n\r\nnlp = spacy.load(\"en_core_web_sm\")\r\ndoc = nlp(sentence)\r\n\r\nwords = sentence.split()\r\nverb_labels = [0 for _ in words]\r\nverb_labels[2] = 1\r\n\r\ninstance = predictor._dataset_reader.text_to_instance(doc, verb_labels)\r\noutput = predictor._model.forward_on_instance(instance)\r\n\r\nprint(\"logits\", output[\"logits\"].shape)\r\nprint(\"probabilities\", output[\"class_probabilities\"].shape)\r\n```\r\n\r\nit returned me a shape of numpy array as follow\r\n\r\n```\r\n(12, 130)\r\n(12, 130)\r\n```\r\n\r\nHow can I use understand this ? \r\nSequence length is 8 and what is 130 ? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4466", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4466/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4466/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4466/events", "html_url": "https://github.com/allenai/allennlp/issues/4466", "id": 655677228, "node_id": "MDU6SXNzdWU2NTU2NzcyMjg=", "number": 4466, "title": "Encode candidates seperately when fine-tuning BERT to avoid CUDA out of memory error", "user": {"login": "731935354", "id": 19267474, "node_id": "MDQ6VXNlcjE5MjY3NDc0", "avatar_url": "https://avatars3.githubusercontent.com/u/19267474?v=4", "gravatar_id": "", "url": "https://api.github.com/users/731935354", "html_url": "https://github.com/731935354", "followers_url": "https://api.github.com/users/731935354/followers", "following_url": "https://api.github.com/users/731935354/following{/other_user}", "gists_url": "https://api.github.com/users/731935354/gists{/gist_id}", "starred_url": "https://api.github.com/users/731935354/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/731935354/subscriptions", "organizations_url": "https://api.github.com/users/731935354/orgs", "repos_url": "https://api.github.com/users/731935354/repos", "events_url": "https://api.github.com/users/731935354/events{/privacy}", "received_events_url": "https://api.github.com/users/731935354/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-13T09:03:10Z", "updated_at": "2020-07-17T16:12:33Z", "closed_at": "2020-07-17T16:12:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Question\r\nHi, I want to build a 100-way classification model by fine-tuning BERT but get CUDA out of memory error. I tried to encode candidates separately but it seems not working as I expected.\r\n\r\n## Environment\r\nOS: Redhat\r\nAllenNLP: 1.0.0\r\nGPU: single Nvidia P100 16GB\r\n\r\n## Task description\r\nEach instance in my dataset contains\r\n* a context sentence\r\n* 100 candidate sentences\r\n* an integer label that indicates the index of the correct answer\r\n\r\nAll sentences are truncated to have a maiximum of 72 wordpieces.\r\n\r\nGenerally given a batch of examples, my model works in the following manner:\r\n1. Encode context sentences of shape `[batch_size, num_word_pieces, embedding_size]` using pretrained BERT, get a tensor of shape `[batch_size, embedding_size]`\r\n2. Encode candidates of shape `[batch_size, num_candidates, num_word_pieces, embedding_size]` using the same BERT model as in step 1, get a tensor of shape `[batch_size, num_candidates, embedding_size]`.\r\n3. repeat encoded context sentences `num_candidates` times, and concatenated with encoded candidates along the last dimension. At this stage we get a tensor of shape `[batch_size, num_candidates, embedding_size * 2]`\r\n4. use fully connected layers to get unnormalized class distributions of shape `[batch_size, num_candidates]`.\r\n\r\nI implemented step 2 as follows to avoid encoding 100 candidates together (also, BERT expects inputs of shape `[batch_size, num_word_pieces]`) :\r\n```python\r\n# candidates_token_ids, candidates_type_ids, candidates_mask all \r\n# with shape [batch_size, num_candidates, num_word_pieces]\r\n\r\nencoded_cands = []  # conceptually of shape: [num_candidates, batch_size, embedding_size]\r\nfor i in range(num_candidates):\r\n    # encode the i-th candidate in this batch\r\n    slice_token_ids = candidates_token_ids[:, i, :]  \r\n    slice_type_ids = candidates_type_ids[:, i, :]\r\n    slice_mask = candidates_mask[:, i, :]\r\n    # [batch_size, num_word_pieces, embedding_size]\r\n    slice_encoded_last_layer = self.bert_model(slice_token_ids, slice_type_ids, slice_mask)\r\n                                                                                      \r\n    # [batch_size, embedding_size]\r\n    encoded_slice = get_first_token_emb(slice_encoded_last_layer)\r\n    encoded_cands.append(slice_encoded_la)\r\n    \r\n# rearrange as [batch_size, num_cands, emb_size * 2]\r\ncands_encoded = rearrange(encoded_cands)\r\n```\r\n\r\nI tried batch_size=2, but got CUDA out of memory error right at the first batch. Also note that the sentences are encoded deliberately in this way (because I want to compare it with another model with the same encoding scheme).\r\n\r\nAny suggestions will be appreciated!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4464", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4464/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4464/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4464/events", "html_url": "https://github.com/allenai/allennlp/issues/4464", "id": 655658753, "node_id": "MDU6SXNzdWU2NTU2NTg3NTM=", "number": 4464, "title": "not support python3.8", "user": {"login": "linpan", "id": 6077601, "node_id": "MDQ6VXNlcjYwNzc2MDE=", "avatar_url": "https://avatars2.githubusercontent.com/u/6077601?v=4", "gravatar_id": "", "url": "https://api.github.com/users/linpan", "html_url": "https://github.com/linpan", "followers_url": "https://api.github.com/users/linpan/followers", "following_url": "https://api.github.com/users/linpan/following{/other_user}", "gists_url": "https://api.github.com/users/linpan/gists{/gist_id}", "starred_url": "https://api.github.com/users/linpan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/linpan/subscriptions", "organizations_url": "https://api.github.com/users/linpan/orgs", "repos_url": "https://api.github.com/users/linpan/repos", "events_url": "https://api.github.com/users/linpan/events{/privacy}", "received_events_url": "https://api.github.com/users/linpan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-13T08:39:27Z", "updated_at": "2020-07-17T12:46:53Z", "closed_at": "2020-07-17T12:46:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "bug: \r\n Downloading http://mirrors.aliyun.com/pypi/packages/c6/27/07b57d22496ed6c98b247e578712122402487f5c265ec70a747900f97060/gluonnlp-0.9.1.tar.gz (252 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 252 kB 317 kB/s \r\n    ERROR: Command errored out with exit status 1:\r\n     command: /Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-install-lev8or49/gluonnlp/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-install-lev8or49/gluonnlp/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-pip-egg-info-z2950nce\r\n         cwd: /private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-install-lev8or49/gluonnlp/\r\n    Complete output (34 lines):\r\n    WARNING: The wheel package is not available.\r\n    WARNING: The repository located at mirrors.aliyun.com is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host mirrors.aliyun.com'.\r\n    ERROR: Could not find a version that satisfies the requirement cython (from versions: none)\r\n    ERROR: No matching distribution found for cython\r\n    Traceback (most recent call last):\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/installer.py\", line 128, in fetch_build_egg\r\n        subprocess.check_call(cmd)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/lib/python3.8/subprocess.py\", line 364, in check_call\r\n        raise CalledProcessError(retcode, cmd)\r\n    subprocess.CalledProcessError: Command '['/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/bin/python3', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/tmptdb_jxqw', '--quiet', 'cython']' returned non-zero exit status 1.\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/private/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/pip-install-lev8or49/gluonnlp/setup.py\", line 37, in <module>\r\n        setup(\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/__init__.py\", line 143, in setup\r\n        _install_setup_requires(attrs)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/__init__.py\", line 138, in _install_setup_requires\r\n        dist.fetch_build_eggs(dist.setup_requires)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/dist.py\", line 695, in fetch_build_eggs\r\n        resolved_dists = pkg_resources.working_set.resolve(\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 781, in resolve\r\n        dist = best[req.key] = env.best_match(\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 1066, in best_match\r\n        return self.obtain(req, installer)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 1078, in obtain\r\n        return installer(requirement)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/dist.py\", line 754, in fetch_build_egg\r\n        return fetch_build_egg(self, req)\r\n      File \"/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/lib/python3.8/site-packages/setuptools/installer.py\", line 130, in fetch_build_egg\r\n        raise DistutilsError(str(e))\r\n    distutils.errors.DistutilsError: Command '['/Users/rct/.pyenv/versions/3.8-dev/envs/env-3.8/bin/python3', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/9_/vtg8g16x3ln1lw6yw96rqst80000gn/T/tmptdb_jxqw', '--quiet', 'cython']' returned non-zero exit status 1.\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4463", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4463/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4463/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4463/events", "html_url": "https://github.com/allenai/allennlp/issues/4463", "id": 655439641, "node_id": "MDU6SXNzdWU2NTU0Mzk2NDE=", "number": 4463, "title": "Missing srl-eval.pl in allennlp-models", "user": {"login": "Riccorl", "id": 10062216, "node_id": "MDQ6VXNlcjEwMDYyMjE2", "avatar_url": "https://avatars0.githubusercontent.com/u/10062216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Riccorl", "html_url": "https://github.com/Riccorl", "followers_url": "https://api.github.com/users/Riccorl/followers", "following_url": "https://api.github.com/users/Riccorl/following{/other_user}", "gists_url": "https://api.github.com/users/Riccorl/gists{/gist_id}", "starred_url": "https://api.github.com/users/Riccorl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Riccorl/subscriptions", "organizations_url": "https://api.github.com/users/Riccorl/orgs", "repos_url": "https://api.github.com/users/Riccorl/repos", "events_url": "https://api.github.com/users/Riccorl/events{/privacy}", "received_events_url": "https://api.github.com/users/Riccorl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-07-12T17:13:44Z", "updated_at": "2020-08-19T12:48:51Z", "closed_at": "2020-08-19T12:48:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "When installing allennlp-models 1.0.0 through pip with\r\n\r\n```\r\npip install allennlp-models\r\n```\r\n\r\n[srl-eval.pl](https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/tools/srl-eval.pl) file is missing.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4459", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4459/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4459/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4459/events", "html_url": "https://github.com/allenai/allennlp/issues/4459", "id": 654419454, "node_id": "MDU6SXNzdWU2NTQ0MTk0NTQ=", "number": 4459, "title": "Add vision and language dataset readers. ", "user": {"login": "jiasenlu", "id": 4209491, "node_id": "MDQ6VXNlcjQyMDk0OTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/4209491?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jiasenlu", "html_url": "https://github.com/jiasenlu", "followers_url": "https://api.github.com/users/jiasenlu/followers", "following_url": "https://api.github.com/users/jiasenlu/following{/other_user}", "gists_url": "https://api.github.com/users/jiasenlu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jiasenlu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jiasenlu/subscriptions", "organizations_url": "https://api.github.com/users/jiasenlu/orgs", "repos_url": "https://api.github.com/users/jiasenlu/repos", "events_url": "https://api.github.com/users/jiasenlu/events{/privacy}", "received_events_url": "https://api.github.com/users/jiasenlu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/14", "html_url": "https://github.com/allenai/allennlp/milestone/14", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/14/labels", "id": 5601713, "node_id": "MDk6TWlsZXN0b25lNTYwMTcxMw==", "number": 14, "title": "2.0", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 9, "closed_issues": 6, "state": "open", "created_at": "2020-06-30T17:05:12Z", "updated_at": "2020-08-18T11:41:12Z", "due_on": null, "closed_at": null}, "comments": 0, "created_at": "2020-07-10T00:02:57Z", "updated_at": "2020-07-10T18:22:07Z", "closed_at": "2020-07-10T18:22:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "commits and discussions that add vision and language dataset reader", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4458", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4458/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4458/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4458/events", "html_url": "https://github.com/allenai/allennlp/issues/4458", "id": 654328208, "node_id": "MDU6SXNzdWU2NTQzMjgyMDg=", "number": 4458, "title": "ConfigurationError: from_params was passed a `params` object that was not a `Params` when loading SRL model", "user": {"login": "suuuuuperrrr", "id": 48231194, "node_id": "MDQ6VXNlcjQ4MjMxMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/48231194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suuuuuperrrr", "html_url": "https://github.com/suuuuuperrrr", "followers_url": "https://api.github.com/users/suuuuuperrrr/followers", "following_url": "https://api.github.com/users/suuuuuperrrr/following{/other_user}", "gists_url": "https://api.github.com/users/suuuuuperrrr/gists{/gist_id}", "starred_url": "https://api.github.com/users/suuuuuperrrr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suuuuuperrrr/subscriptions", "organizations_url": "https://api.github.com/users/suuuuuperrrr/orgs", "repos_url": "https://api.github.com/users/suuuuuperrrr/repos", "events_url": "https://api.github.com/users/suuuuuperrrr/events{/privacy}", "received_events_url": "https://api.github.com/users/suuuuuperrrr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-09T20:28:49Z", "updated_at": "2020-07-17T13:25:35Z", "closed_at": "2020-07-17T13:25:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi. I tried to load the pre-trained model of SRL model but Predictor.from_path is not working. My code is below:\r\n\r\n```\r\nimport allennlp_models\r\nfrom allennlp.models.archival import load_archive\r\nfrom allennlp.predictors import Predictor\r\nimport allennlp_models.syntax.srl\r\nimport allennlp_models.coref\r\n\r\nload_archive('https://s3-us-west-2.amazonaws.com/allennlp/models/srl-model-2018.05.25.tar.gz')\r\n```\r\n\r\nThe traceback is:\r\n\r\n```\r\n> ---------------------------------------------------------------------------\r\nConfigurationError                        Traceback (most recent call last)\r\n<ipython-input-20-65d2982a782f> in <module>()\r\n      1 from allennlp.predictors import Predictor\r\n----> 2 load_archive('https://s3-us-west-2.amazonaws.com/allennlp/models/srl-model-2018.05.25.tar.gz')\r\n\r\n8 frames\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/archival.py in load_archive(archive_file, cuda_device, opt_level, overrides, weights_file)\r\n    195         serialization_dir=serialization_dir,\r\n    196         cuda_device=cuda_device,\r\n--> 197         opt_level=opt_level,\r\n    198     )\r\n    199 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py in load(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    385 \r\n    386         model_class: Type[Model] = cls.by_name(model_type)  # type: ignore\r\n--> 387         return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    388 \r\n    389     def extend_embedder_vocab(self, embedding_sources_mapping: Dict[str, str] = None) -> None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py in _load(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    288         # want the code to look for it, so we remove it from the parameters here.\r\n    289         remove_pretrained_embedding_params(model_params)\r\n--> 290         model = Model.from_params(vocab=vocab, params=model_params)\r\n    291 \r\n    292         # Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    550                     constructor_to_call=constructor_to_call,\r\n    551                     constructor_to_inspect=constructor_to_inspect,\r\n--> 552                     **extras,\r\n    553                 )\r\n    554             else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    578             else:\r\n    579                 # This class has a constructor, so create kwargs for it.\r\n--> 580                 kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n    581 \r\n    582             return constructor_to_call(**kwargs)  # type: ignore\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in create_kwargs(constructor, cls, params, **extras)\r\n    162 \r\n    163         constructed_arg = pop_and_construct_arg(\r\n--> 164             cls.__name__, param_name, annotation, param.default, params, **extras\r\n    165         )\r\n    166 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in pop_and_construct_arg(class_name, argument_name, annotation, default, params, **extras)\r\n    268         return None\r\n    269 \r\n--> 270     return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n    271 \r\n    272 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in construct_arg(class_name, argument_name, popped_params, annotation, default, **extras)\r\n    302             elif isinstance(popped_params, dict):\r\n    303                 popped_params = Params(popped_params)\r\n--> 304             return annotation.from_params(params=popped_params, **subextras)\r\n    305         elif not optional:\r\n    306             # Not optional and not supplied, that's an error!\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    514         if not isinstance(params, Params):\r\n    515             raise ConfigurationError(\r\n--> 516                 \"from_params was passed a `params` object that was not a `Params`. This probably \"\r\n    517                 \"indicates malformed parameters in a configuration file, where something that \"\r\n    518                 \"should have been a dictionary was actually a list, or something else. \"\r\n\r\nConfigurationError: from_params was passed a `params` object that was not a `Params`. This probably indicates malformed parameters in a configuration file, where something that should have been a dictionary was actually a list, or something else. This happened when constructing an object of type <class 'allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator'>.\r\n```\r\n\r\nEnvironment:\r\nGoogle colab;\r\nallennlp==1.0.0rc3\r\nallennlp-models==1.0.0rc3\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4455", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4455/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4455/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4455/events", "html_url": "https://github.com/allenai/allennlp/issues/4455", "id": 654188474, "node_id": "MDU6SXNzdWU2NTQxODg0NzQ=", "number": 4455, "title": "Add option to use scalar mix of pretrained transformer layers as embedding, not just last layer", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/11", "html_url": "https://github.com/allenai/allennlp/milestone/11", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/11/labels", "id": 5183675, "node_id": "MDk6TWlsZXN0b25lNTE4MzY3NQ==", "number": 11, "title": "1.1", "description": "A placeholder for work we'd like to do after the 1.0 release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 21, "state": "open", "created_at": "2020-03-09T17:46:04Z", "updated_at": "2020-08-12T17:28:23Z", "due_on": null, "closed_at": null}, "comments": 0, "created_at": "2020-07-09T16:19:18Z", "updated_at": "2020-07-10T19:34:26Z", "closed_at": "2020-07-10T19:34:26Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "See the discussion here: https://github.com/allenai/allennlp/issues/4216", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4452", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4452/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4452/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4452/events", "html_url": "https://github.com/allenai/allennlp/issues/4452", "id": 653237665, "node_id": "MDU6SXNzdWU2NTMyMzc2NjU=", "number": 4452, "title": "Missing 'allennlp.data.fields.production_rule_field' in allennlp-1.0.0", "user": {"login": "madcpt", "id": 33171760, "node_id": "MDQ6VXNlcjMzMTcxNzYw", "avatar_url": "https://avatars3.githubusercontent.com/u/33171760?v=4", "gravatar_id": "", "url": "https://api.github.com/users/madcpt", "html_url": "https://github.com/madcpt", "followers_url": "https://api.github.com/users/madcpt/followers", "following_url": "https://api.github.com/users/madcpt/following{/other_user}", "gists_url": "https://api.github.com/users/madcpt/gists{/gist_id}", "starred_url": "https://api.github.com/users/madcpt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/madcpt/subscriptions", "organizations_url": "https://api.github.com/users/madcpt/orgs", "repos_url": "https://api.github.com/users/madcpt/repos", "events_url": "https://api.github.com/users/madcpt/events{/privacy}", "received_events_url": "https://api.github.com/users/madcpt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-08T11:57:22Z", "updated_at": "2020-07-19T00:28:20Z", "closed_at": "2020-07-08T12:14:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/zihan/.local/bin/allennlp\", line 11, in <module>\r\n    sys.exit(run())\r\n  File \"/home/zihan/.local/lib/python3.6/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/zihan/.local/lib/python3.6/site-packages/allennlp/commands/__init__.py\", line 91, in main\r\n    import_module_and_submodules(package_name)\r\n  File \"/home/zihan/.local/lib/python3.6/site-packages/allennlp/common/util.py\", line 340, in import_module_and_submodules\r\n    module = importlib.import_module(package_name)\r\n  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/mnt/d/projects/spider-schema-gnn-global/dataset_readers/spider.py\", line 10, in <module>\r\n    from allennlp.data.fields.production_rule_field import ProductionRuleField\r\nModuleNotFoundError: No module named 'allennlp.data.fields.production_rule_field'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.1\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp (1.0.0)\r\nasn1crypto (0.24.0)\r\nattrs (17.4.0)\r\nAutomat (0.6.0)\r\nbeautifulsoup4 (4.9.1)\r\nblinker (1.4)\r\nblis (0.4.1)\r\nboto3 (1.14.18)\r\nbotocore (1.17.18)\r\ncatalogue (1.0.0)\r\ncertifi (2020.6.20)\r\nchardet (3.0.4)\r\ncheroot (8.3.0)\r\nCherryPy (18.6.0)\r\nclick (7.1.2)\r\ncloud-init (19.4)\r\ncolorama (0.3.7)\r\ncommand-not-found (0.3)\r\nconfigobj (5.0.6)\r\nconstantly (15.1.0)\r\ncontextvars (2.4)\r\ncryptography (2.1.4)\r\ncymem (2.0.3)\r\ndataclasses (0.7)\r\ndecorator (4.4.2)\r\ndill (0.3.2)\r\ndistro-info (0.18ubuntu0.18.04.1)\r\ndocutils (0.15.2)\r\ndocx (0.2.4)\r\nen-core-web-sm (2.0.0)\r\nfeedparser (5.2.1)\r\nfilelock (3.0.12)\r\nflake8 (3.8.3)\r\nfuture (0.18.2)\r\nh5py (2.10.0)\r\nhttplib2 (0.9.2)\r\nhyperlink (17.3.1)\r\nidna (2.10)\r\nimmutables (0.14)\r\nimportlib-metadata (1.7.0)\r\nimportlib-resources (3.0.0)\r\nincremental (16.10.1)\r\nisodate (0.6.0)\r\njaraco.classes (3.1.0)\r\njaraco.collections (3.0.0)\r\njaraco.functools (3.0.1)\r\njaraco.text (3.2.0)\r\nJinja2 (2.10)\r\njmespath (0.10.0)\r\njoblib (0.16.0)\r\njsonpatch (1.16)\r\njsonpickle (1.4.1)\r\njsonpointer (1.10)\r\njsonschema (2.6.0)\r\nkeyring (10.6.0)\r\nkeyrings.alt (3.0)\r\nlanguage-selector (0.1)\r\nlxml (4.5.1)\r\nMarkupSafe (1.0)\r\nmccabe (0.6.1)\r\nmore-itertools (8.4.0)\r\nmurmurhash (1.0.2)\r\nnetifaces (0.10.4)\r\nnetworkx (2.4)\r\nnltk (3.5)\r\nnumpy (1.19.0)\r\noauthlib (2.0.6)\r\nordered-set (4.0.2)\r\noverrides (3.1.0)\r\npackaging (20.4)\r\nPAM (0.4.2)\r\npandas (1.0.5)\r\npattern3 (3.0.0)\r\npdfminer.six (20200517)\r\npdfminer3k (1.3.4)\r\nPillow (7.2.0)\r\npip (9.0.1)\r\nplac (1.1.3)\r\nply (3.11)\r\nplyfile (0.7.2)\r\nportend (2.6)\r\npreshed (3.0.2)\r\nprotobuf (3.12.2)\r\npyasn1 (0.4.2)\r\npyasn1-modules (0.2.1)\r\npycodestyle (2.6.0)\r\npycrypto (2.6.1)\r\npycryptodome (3.9.8)\r\npydantic (1.5.1)\r\npyflakes (2.2.0)\r\npygobject (3.26.1)\r\nPyJWT (1.5.3)\r\npyOpenSSL (17.5.0)\r\npyparsing (2.4.7)\r\npyserial (3.4)\r\npython-apt (1.6.5+ubuntu0.2)\r\npython-dateutil (2.8.1)\r\npython-debian (0.1.32)\r\npytz (2020.1)\r\npyxdg (0.25)\r\nPyYAML (3.12)\r\nrdflib (5.0.0)\r\nregex (2020.6.8)\r\nrequests (2.24.0)\r\nrequests-unixsocket (0.1.5)\r\ns3transfer (0.3.3)\r\nsacremoses (0.0.43)\r\nscikit-learn (0.23.1)\r\nscipy (1.5.1)\r\nSecretStorage (2.3.1)\r\nsentencepiece (0.1.91)\r\nservice-identity (16.0.0)\r\nsetuptools (49.1.0)\r\nsimplejson (3.17.0)\r\nsix (1.15.0)\r\nsortedcontainers (2.2.2)\r\nsoupsieve (2.0.1)\r\nspacy (3.0.0a0)\r\nsrsly (2.2.0)\r\nssh-import-id (5.7)\r\nsystemd-python (234)\r\ntempora (3.0.0)\r\ntensorboardX (2.1)\r\nthinc (8.0.0a11)\r\nthreadpoolctl (2.1.0)\r\ntokenizers (0.8.1rc1)\r\ntorch (1.5.0+cpu)\r\ntorch-cluster (1.3.0)\r\ntorch-geometric (1.2.1)\r\ntorch-scatter (1.2.0)\r\ntorch-sparse (0.4.3)\r\ntqdm (4.47.0)\r\ntransformers (3.0.2)\r\nTwisted (17.9.0)\r\ntyper (0.3.0)\r\ntyping-extensions (3.7.4.2)\r\nufw (0.36)\r\nunattended-upgrades (0.1)\r\nurllib3 (1.25.9)\r\nwasabi (0.7.0)\r\nwheel (0.30.0)\r\nzc.lockfile (2.0)\r\nzipp (3.1.0)\r\nzope.interface (4.3.2)\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4450", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4450/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4450/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4450/events", "html_url": "https://github.com/allenai/allennlp/issues/4450", "id": 652932661, "node_id": "MDU6SXNzdWU2NTI5MzI2NjE=", "number": 4450, "title": "Restrict the version of `boto3` for package manager", "user": {"login": "tamuhey", "id": 24998666, "node_id": "MDQ6VXNlcjI0OTk4NjY2", "avatar_url": "https://avatars2.githubusercontent.com/u/24998666?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tamuhey", "html_url": "https://github.com/tamuhey", "followers_url": "https://api.github.com/users/tamuhey/followers", "following_url": "https://api.github.com/users/tamuhey/following{/other_user}", "gists_url": "https://api.github.com/users/tamuhey/gists{/gist_id}", "starred_url": "https://api.github.com/users/tamuhey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tamuhey/subscriptions", "organizations_url": "https://api.github.com/users/tamuhey/orgs", "repos_url": "https://api.github.com/users/tamuhey/repos", "events_url": "https://api.github.com/users/tamuhey/events{/privacy}", "received_events_url": "https://api.github.com/users/tamuhey/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-08T04:21:15Z", "updated_at": "2020-07-09T16:15:33Z", "closed_at": "2020-07-09T16:15:33Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Now allennlp depends on `boto3==*`, which sometimes causes a package manager `poetry` to get stuck in dependency resolution (see https://github.com/python-poetry/poetry/issues/771#issuecomment-630677036).\r\nUsers can avoid this by specifying `boto3` dependency, but it is not trivial.\r\n\r\nI think it's good to rewrite the below line to, for example, `boto3>=1.14`\r\n\r\nhttps://github.com/allenai/allennlp/blob/5b988d637d9d2fde405eb0d0bc22b3bdb4012ad2/setup.py#L60", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4442", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4442/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4442/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4442/events", "html_url": "https://github.com/allenai/allennlp/issues/4442", "id": 651206583, "node_id": "MDU6SXNzdWU2NTEyMDY1ODM=", "number": 4442, "title": "allennlp.common.checks.ConfigurationError: key \"token_embedders\" is required at location \"model.text_field_embedder.\"", "user": {"login": "563017732", "id": 44391305, "node_id": "MDQ6VXNlcjQ0MzkxMzA1", "avatar_url": "https://avatars2.githubusercontent.com/u/44391305?v=4", "gravatar_id": "", "url": "https://api.github.com/users/563017732", "html_url": "https://github.com/563017732", "followers_url": "https://api.github.com/users/563017732/followers", "following_url": "https://api.github.com/users/563017732/following{/other_user}", "gists_url": "https://api.github.com/users/563017732/gists{/gist_id}", "starred_url": "https://api.github.com/users/563017732/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/563017732/subscriptions", "organizations_url": "https://api.github.com/users/563017732/orgs", "repos_url": "https://api.github.com/users/563017732/repos", "events_url": "https://api.github.com/users/563017732/events{/privacy}", "received_events_url": "https://api.github.com/users/563017732/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-06T02:36:59Z", "updated_at": "2020-07-07T02:08:46Z", "closed_at": "2020-07-06T14:12:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Describe the bug**\r\n\r\nI0706 10:33:02.516595 140677189486400 archival.py:171] extracting archive file /home/jiawen/.allennlp/cache/60c14844468543e4329ce7e8d3444fa1f9f7057b4b0de5b3f4a597eb57113d32.73aa20bab6336a582588814d8458d040b59536ca1f60b6a769a2da61c7aa3c9a to temp dir /tmp/tmp15lrx2nb\r\nI0706 10:33:06.706750 140677189486400 params.py:247] type = from_instances\r\nI0706 10:33:06.706835 140677189486400 vocabulary.py:323] Loading token dictionary from /tmp/tmp15lrx2nb/vocabulary.\r\nI0706 10:33:06.706987 140677189486400 filelock.py:274] Lock 140674091466936 acquired on /tmp/tmp15lrx2nb/vocabulary/.lock\r\nI0706 10:33:06.707335 140677189486400 filelock.py:318] Lock 140674091466936 released on /tmp/tmp15lrx2nb/vocabulary/.lock\r\nI0706 10:33:06.707670 140677189486400 params.py:247] model.type = constituency_parser\r\nI0706 10:33:06.707974 140677189486400 params.py:247] model.regularizer = None\r\nI0706 10:33:06.708117 140677189486400 params.py:247] model.text_field_embedder.type = basic\r\nTraceback (most recent call last):\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/params.py\", line 237, in pop\r\n    value = self.params.pop(key)\r\nKeyError: 'token_embedders'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"src/scripts/athene/pipeline.py\", line 193, in <module>\r\n    document_retrieval(logger, args.mode)\r\n  File \"src/scripts/athene/pipeline.py\", line 163, in document_retrieval\r\n    Config.document_add_claim, Config.document_parallel)\r\n  File \"/home/jiawen/Documents/Code/Code/fact_checking/ESIM/src/athene/retrieval/document/docment_retrieval.py\", line 194, in main\r\n    method = Doc_Retrieval(database_path=db_file, add_claim=add_claim, k_wiki_results=k_wiki)\r\n  File \"/home/jiawen/Documents/Code/Code/fact_checking/ESIM/src/athene/retrieval/document/docment_retrieval.py\", line 47, in __init__\r\n    self.predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo-constituency-parser-2018.03.14.tar.gz\")\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/predictors/predictor.py\", line 275, in from_path\r\n    load_archive(archive_path, cuda_device=cuda_device),\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/models/archival.py\", line 197, in load_archive\r\n    opt_level=opt_level,\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/models/model.py\", line 398, in load\r\n    return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/models/model.py\", line 295, in _load\r\n    model = Model.from_params(vocab=vocab, params=model_params)\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 609, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 181, in create_kwargs\r\n    cls.__name__, param_name, annotation, param.default, params, **extras\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 287, in pop_and_construct_arg\r\n    return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 321, in construct_arg\r\n    return annotation.from_params(params=popped_params, **subextras)\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 609, in from_params\r\n    kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 181, in create_kwargs\r\n    cls.__name__, param_name, annotation, param.default, params, **extras\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/from_params.py\", line 280, in pop_and_construct_arg\r\n    popped_params = params.pop(name, default) if default != _NO_DEFAULT else params.pop(name)\r\n  File \"/home/jiawen/anaconda3/envs/esim/lib/python3.6/site-packages/allennlp/common/params.py\", line 242, in pop\r\n    raise ConfigurationError(msg)\r\nallennlp.common.checks.ConfigurationError: key \"token_embedders\" is required at location \"model.text_field_embedder.\"\r\nI0706 10:33:06.710113 140677189486400 archival.py:205] removing temporary unarchived model dir at /tmp/tmp15lrx2nb", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4441", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4441/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4441/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4441/events", "html_url": "https://github.com/allenai/allennlp/issues/4441", "id": 651002569, "node_id": "MDU6SXNzdWU2NTEwMDI1Njk=", "number": 4441, "title": "where is part of speech and proper name category label collection?", "user": {"login": "hugess", "id": 43957, "node_id": "MDQ6VXNlcjQzOTU3", "avatar_url": "https://avatars1.githubusercontent.com/u/43957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hugess", "html_url": "https://github.com/hugess", "followers_url": "https://api.github.com/users/hugess/followers", "following_url": "https://api.github.com/users/hugess/following{/other_user}", "gists_url": "https://api.github.com/users/hugess/gists{/gist_id}", "starred_url": "https://api.github.com/users/hugess/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hugess/subscriptions", "organizations_url": "https://api.github.com/users/hugess/orgs", "repos_url": "https://api.github.com/users/hugess/repos", "events_url": "https://api.github.com/users/hugess/events{/privacy}", "received_events_url": "https://api.github.com/users/hugess/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-05T05:05:52Z", "updated_at": "2020-07-06T15:11:30Z", "closed_at": "2020-07-06T15:11:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "A list like this:\r\nhttps://github.com/baidu/lac\r\n\r\n\u6807\u7b7e | \u542b\u4e49 | \u6807\u7b7e | \u542b\u4e49 | \u6807\u7b7e | \u542b\u4e49 | \u6807\u7b7e | \u542b\u4e49\r\n-- | -- | -- | -- | -- | -- | -- | --\r\nn | \u666e\u901a\u540d\u8bcd | f | \u65b9\u4f4d\u540d\u8bcd | s | \u5904\u6240\u540d\u8bcd | nw | \u4f5c\u54c1\u540d\r\nnz | \u5176\u4ed6\u4e13\u540d | v | \u666e\u901a\u52a8\u8bcd | vd | \u52a8\u526f\u8bcd | vn | \u540d\u52a8\u8bcd\r\na | \u5f62\u5bb9\u8bcd | ad | \u526f\u5f62\u8bcd | an | \u540d\u5f62\u8bcd | d | \u526f\u8bcd\r\nm | \u6570\u91cf\u8bcd | q | \u91cf\u8bcd | r | \u4ee3\u8bcd | p | \u4ecb\u8bcd\r\nc | \u8fde\u8bcd | u | \u52a9\u8bcd | xc | \u5176\u4ed6\u865a\u8bcd | w | \u6807\u70b9\u7b26\u53f7\r\nPER | \u4eba\u540d\r\n\r\nI didn't find such instructions in the AllenNlP's doc\r\nIs it consistent with baidu/lac?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4440", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4440/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4440/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4440/events", "html_url": "https://github.com/allenai/allennlp/issues/4440", "id": 650938326, "node_id": "MDU6SXNzdWU2NTA5MzgzMjY=", "number": 4440, "title": "just can stay the original and nomore same like dog place", "user": {"login": "marskong88", "id": 67506725, "node_id": "MDQ6VXNlcjY3NTA2NzI1", "avatar_url": "https://avatars1.githubusercontent.com/u/67506725?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marskong88", "html_url": "https://github.com/marskong88", "followers_url": "https://api.github.com/users/marskong88/followers", "following_url": "https://api.github.com/users/marskong88/following{/other_user}", "gists_url": "https://api.github.com/users/marskong88/gists{/gist_id}", "starred_url": "https://api.github.com/users/marskong88/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marskong88/subscriptions", "organizations_url": "https://api.github.com/users/marskong88/orgs", "repos_url": "https://api.github.com/users/marskong88/repos", "events_url": "https://api.github.com/users/marskong88/events{/privacy}", "received_events_url": "https://api.github.com/users/marskong88/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-04T18:46:16Z", "updated_at": "2020-07-04T21:03:34Z", "closed_at": "2020-07-04T21:03:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4438", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4438/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4438/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4438/events", "html_url": "https://github.com/allenai/allennlp/issues/4438", "id": 650573780, "node_id": "MDU6SXNzdWU2NTA1NzM3ODA=", "number": 4438, "title": "A parameter problem", "user": {"login": "Zessay", "id": 39905704, "node_id": "MDQ6VXNlcjM5OTA1NzA0", "avatar_url": "https://avatars1.githubusercontent.com/u/39905704?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zessay", "html_url": "https://github.com/Zessay", "followers_url": "https://api.github.com/users/Zessay/followers", "following_url": "https://api.github.com/users/Zessay/following{/other_user}", "gists_url": "https://api.github.com/users/Zessay/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zessay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zessay/subscriptions", "organizations_url": "https://api.github.com/users/Zessay/orgs", "repos_url": "https://api.github.com/users/Zessay/repos", "events_url": "https://api.github.com/users/Zessay/events{/privacy}", "received_events_url": "https://api.github.com/users/Zessay/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-03T12:43:42Z", "updated_at": "2020-07-06T14:21:45Z", "closed_at": "2020-07-06T14:21:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the file `pretrained_transformer_mismatched_embedder.py`, there is a `*` in the `__init__` (line 43). I haven't seen this parameter before (only know `*args` and `**kwargs`), and can't understand the use of this here.  Could you please explain the usage of this parameter? Thank you!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4437", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4437/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4437/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4437/events", "html_url": "https://github.com/allenai/allennlp/issues/4437", "id": 650391347, "node_id": "MDU6SXNzdWU2NTAzOTEzNDc=", "number": 4437, "title": "Add new attribute in Token class", "user": {"login": "Zessay", "id": 39905704, "node_id": "MDQ6VXNlcjM5OTA1NzA0", "avatar_url": "https://avatars1.githubusercontent.com/u/39905704?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zessay", "html_url": "https://github.com/Zessay", "followers_url": "https://api.github.com/users/Zessay/followers", "following_url": "https://api.github.com/users/Zessay/following{/other_user}", "gists_url": "https://api.github.com/users/Zessay/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zessay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zessay/subscriptions", "organizations_url": "https://api.github.com/users/Zessay/orgs", "repos_url": "https://api.github.com/users/Zessay/repos", "events_url": "https://api.github.com/users/Zessay/events{/privacy}", "received_events_url": "https://api.github.com/users/Zessay/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-03T07:06:37Z", "updated_at": "2020-07-07T11:01:12Z", "closed_at": "2020-07-07T11:01:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the dialogue task of NLP, we often need to know turn id  or role id so that we can get the turn embedding or role embedding of a token. In current `Token` class, the attributes are fixed. And we need to rewrite a subclass of `Token` to add our own attributes,  which is inconvenient. We \r\nmight need to fix all of the `Tokenizer`, `TokenIndexer` and `TokenEmbedder`, just because of one extra attribute.\r\n\r\nI think it is necessary to add a new attribute to the `Token` whose type is `Dict[str, Any]`, or use `**kwargs` and `setattr`, so that we can add our own attribute to token according to specific task. Of course, there may be other solution to this problem which doesn't need to fix `Token`,  while I still think extra info of a token is necessary. \r\n\r\nHope you can think about this problem.\r\n\r\n**- Solution 1: use `**kwargs` and `setattr`**\r\n\r\n \r\n![image](https://user-images.githubusercontent.com/39905704/86440889-dc9aab00-bd3d-11ea-8872-1802ae5bafae.png)\r\n\r\nIf we use this solution, we can't use `__slots__`, because we are not sure what attributes will be added. Because we remove `__slots__`, we can add attributes dynamically.\r\n\r\n**- Solution 2: add a new attribute whose type is `Dict[str, Any]`**\r\n\r\n![image](https://user-images.githubusercontent.com/39905704/86441178-6185c480-bd3e-11ea-8438-f2f870165329.png)\r\n\r\nWith this solution, we can still use `__slots__`,  just need to add `'extra_info'` in it.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4436", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4436/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4436/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4436/events", "html_url": "https://github.com/allenai/allennlp/issues/4436", "id": 650066885, "node_id": "MDU6SXNzdWU2NTAwNjY4ODU=", "number": 4436, "title": "Stop logging regularization loss of 0", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 723800354, "node_id": "MDU6TGFiZWw3MjM4MDAzNTQ=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Good%20First%20Issue", "name": "Good First Issue", "color": "e99695", "default": false, "description": null}, {"id": 1771936803, "node_id": "MDU6TGFiZWwxNzcxOTM2ODAz", "url": "https://api.github.com/repos/allenai/allennlp/labels/Hour", "name": "Hour", "color": "0052cc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/11", "html_url": "https://github.com/allenai/allennlp/milestone/11", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/11/labels", "id": 5183675, "node_id": "MDk6TWlsZXN0b25lNTE4MzY3NQ==", "number": 11, "title": "1.1", "description": "A placeholder for work we'd like to do after the 1.0 release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 21, "state": "open", "created_at": "2020-03-09T17:46:04Z", "updated_at": "2020-08-12T17:28:23Z", "due_on": null, "closed_at": null}, "comments": 2, "created_at": "2020-07-02T16:36:18Z", "updated_at": "2020-07-10T17:28:26Z", "closed_at": "2020-07-10T17:28:26Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We now log (and show during training) the regularization loss. But in many configs, that loss is always 0. We should not show it in that case, at least not on the console.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4433", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4433/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4433/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4433/events", "html_url": "https://github.com/allenai/allennlp/issues/4433", "id": 649859008, "node_id": "MDU6SXNzdWU2NDk4NTkwMDg=", "number": 4433, "title": "Type hint error", "user": {"login": "Zessay", "id": 39905704, "node_id": "MDQ6VXNlcjM5OTA1NzA0", "avatar_url": "https://avatars1.githubusercontent.com/u/39905704?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zessay", "html_url": "https://github.com/Zessay", "followers_url": "https://api.github.com/users/Zessay/followers", "following_url": "https://api.github.com/users/Zessay/following{/other_user}", "gists_url": "https://api.github.com/users/Zessay/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zessay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zessay/subscriptions", "organizations_url": "https://api.github.com/users/Zessay/orgs", "repos_url": "https://api.github.com/users/Zessay/repos", "events_url": "https://api.github.com/users/Zessay/events{/privacy}", "received_events_url": "https://api.github.com/users/Zessay/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-02T11:31:58Z", "updated_at": "2020-07-02T11:48:22Z", "closed_at": "2020-07-02T11:48:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the 94 line of the file `allennlp/allennlp/data/fields/text_field.py`, the output type should be `TextFieldTensors` rather than `Dict[str, torch.Tensor]`. Python doesn't inspect whether the type of the parameter is right, while I think it is important for us to understand the code. \r\n\r\n![image](https://user-images.githubusercontent.com/39905704/86354090-fd5df480-bc9a-11ea-9dcf-66bc9fc4f02c.png)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4432", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4432/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4432/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4432/events", "html_url": "https://github.com/allenai/allennlp/issues/4432", "id": 649852339, "node_id": "MDU6SXNzdWU2NDk4NTIzMzk=", "number": 4432, "title": "How to add hand-craft feature in seq2seq model ?", "user": {"login": "wlhgtc", "id": 16603773, "node_id": "MDQ6VXNlcjE2NjAzNzcz", "avatar_url": "https://avatars2.githubusercontent.com/u/16603773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wlhgtc", "html_url": "https://github.com/wlhgtc", "followers_url": "https://api.github.com/users/wlhgtc/followers", "following_url": "https://api.github.com/users/wlhgtc/following{/other_user}", "gists_url": "https://api.github.com/users/wlhgtc/gists{/gist_id}", "starred_url": "https://api.github.com/users/wlhgtc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wlhgtc/subscriptions", "organizations_url": "https://api.github.com/users/wlhgtc/orgs", "repos_url": "https://api.github.com/users/wlhgtc/repos", "events_url": "https://api.github.com/users/wlhgtc/events{/privacy}", "received_events_url": "https://api.github.com/users/wlhgtc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-02T11:20:56Z", "updated_at": "2020-07-02T17:57:00Z", "closed_at": "2020-07-02T17:57:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi there,\r\n I'm using allennlp for seq2seq task. And I use the `copynet_seq2seq`  .\r\nHere are  part of my configs:\r\n\r\n\r\n    \"type\":\"copynet-seq2seq\", \r\n    \"source_token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"single_id\",\r\n        \"namespace\": \"source_tokens\",\r\n        \"lowercase_tokens\": true\r\n      }\r\n    },\r\n     ....\r\n\r\nI wonder if I want use pos(of a word) as another feature. How could I do it ?\r\n Should I add another `indexers` like:\r\n\r\n    \"type\":\"copynet-seq2seq\", \r\n    \"source_pos_indexers\": {\r\n      \"pos\": {\r\n        \"type\": \"single_id\",\r\n        \"namespace\": \"source_tokens\",\r\n        \"lowercase_tokens\": true\r\n      }\r\n    },\r\n     ....\r\n\r\n\r\nOr I could add it together?\r\n\r\n    \"type\":\"copynet-seq2seq\", \r\n    \"source_token_indexers\": {\r\n      \"pos\": {\r\n        \"type\": \"single_id\",\r\n        \"namespace\": \"source_tokens\",\r\n        \"lowercase_tokens\": true\r\n      }\r\n      \"tokens\": {\r\n        \"type\": \"single_id\",\r\n        \"namespace\": \"source_tokens\",\r\n        \"lowercase_tokens\": true\r\n      }\r\n    },\r\n     ....\r\n\r\n\r\nAnd do I have to use same `namespace` between them ?\r\n\r\n\r\n@matt-gardner  I saw your reply in #3091 , but the link is out of date. Could you help me ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4431", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4431/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4431/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4431/events", "html_url": "https://github.com/allenai/allennlp/issues/4431", "id": 649813160, "node_id": "MDU6SXNzdWU2NDk4MTMxNjA=", "number": 4431, "title": "Error loading model using load_archive from local path", "user": {"login": "itsmemala", "id": 8657349, "node_id": "MDQ6VXNlcjg2NTczNDk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8657349?v=4", "gravatar_id": "", "url": "https://api.github.com/users/itsmemala", "html_url": "https://github.com/itsmemala", "followers_url": "https://api.github.com/users/itsmemala/followers", "following_url": "https://api.github.com/users/itsmemala/following{/other_user}", "gists_url": "https://api.github.com/users/itsmemala/gists{/gist_id}", "starred_url": "https://api.github.com/users/itsmemala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/itsmemala/subscriptions", "organizations_url": "https://api.github.com/users/itsmemala/orgs", "repos_url": "https://api.github.com/users/itsmemala/repos", "events_url": "https://api.github.com/users/itsmemala/events{/privacy}", "received_events_url": "https://api.github.com/users/itsmemala/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-02T10:16:47Z", "updated_at": "2020-07-04T05:31:23Z", "closed_at": "2020-07-04T05:31:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\nI'm trying to load a model saved to a local path in the Kaggle environment, using the allennlp.models.load_archive() method but I get the below error:\r\n\"ConfigurationError: discourse_classifier is not a registered name for Model. You probably need to use the --include-package flag to load your custom code. Alternatively, you can specify your choices using fully-qualified paths, e.g. {\"model\": \"my_module.models.MyModel\"} in which case they will be automatically imported correctly.\"\r\n\r\nModel location: https://s3-us-west-2.amazonaws.com/pubmed-rct/model.tar.gz\r\n\r\nTraceback:\r\n```\r\n<ipython-input-21-1d9004d63a1a> in <module>\r\n----> 1 archive = load_archive(\"/kaggle/input/modelbase\") ## available at github\r\n      2 predictor = Predictor.from_archive(archive, 'discourse_crf_predictor')\r\n      3 gc.collect()\r\n\r\n/opt/conda/lib/python3.7/site-packages/allennlp/models/archival.py in load_archive(archive_file, cuda_device, opt_level, overrides, weights_file)\r\n    195         serialization_dir=serialization_dir,\r\n    196         cuda_device=cuda_device,\r\n--> 197         opt_level=opt_level,\r\n    198     )\r\n    199 \r\n\r\n/opt/conda/lib/python3.7/site-packages/allennlp/models/model.py in load(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    389         # This allows subclasses of Model to override _load.\r\n    390 \r\n--> 391         model_class: Type[Model] = cls.by_name(model_type)  # type: ignore\r\n    392         if not isinstance(model_class, type):\r\n    393             # If you're using from_archive to specify your model (e.g., for fine tuning), then you\r\n\r\n/opt/conda/lib/python3.7/site-packages/allennlp/common/registrable.py in by_name(cls, name)\r\n    135         \"\"\"\r\n    136         logger.debug(f\"instantiating registered subclass {name} of {cls}\")\r\n--> 137         subclass, constructor = cls.resolve_class_name(name)\r\n    138         if not constructor:\r\n    139             return subclass\r\n\r\n/opt/conda/lib/python3.7/site-packages/allennlp/common/registrable.py in resolve_class_name(cls, name)\r\n    183             # is not a qualified class name\r\n    184             raise ConfigurationError(\r\n--> 185                 f\"{name} is not a registered name for {cls.__name__}. \"\r\n    186                 \"You probably need to use the --include-package flag \"\r\n    187                 \"to load your custom code. Alternatively, you can specify your choices \"\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Kaggle kernel\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nadal==1.2.2\r\naffine==2.3.0\r\naiohttp==3.6.2\r\nalabaster==0.7.12\r\nalbumentations==0.4.5\r\nalembic==1.4.2\r\nallennlp==1.0.0\r\naltair==4.1.0\r\nanaconda-client==1.7.2\r\nanaconda-project==0.8.3\r\nannoy==1.16.3\r\nansiwrap==0.8.4\r\nappdirs==1.4.3\r\nargh==0.26.2\r\narrow==0.15.5\r\narviz==0.8.3\r\nasn1crypto==1.3.0\r\nastroid==2.3.3\r\nastropy==4.0.1.post1\r\nastunparse==1.6.3\r\nasync-generator==1.10\r\nasync-timeout==3.0.1\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\naudioread==2.1.8\r\nautopep8==1.5.1\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nbackports.shutil-get-terminal-size==1.0.0\r\nBaker==1.3\r\nbasemap==1.2.1\r\nbayesian-optimization @ git+https://github.com/fmfn/BayesianOptimization.git@cb28df83f757c5c7406b2730eac3a67a2d0270a5\r\nbayespy==0.5.19\r\nbcolz==1.2.1\r\nbeautifulsoup4==4.9.0\r\nbinaryornot==0.4.4\r\nbiopython==1.77\r\nbitarray==1.2.1\r\nbkcharts==0.2\r\nblack==19.10b0\r\nbleach==3.1.4\r\nblinker==1.4\r\nblis==0.4.1\r\nbokeh==2.0.1\r\nBoruta==0.3\r\nboto==2.49.0\r\nboto3==1.14.6\r\nbotocore==1.17.6\r\nBottleneck==1.3.2\r\n-e git+https://github.com/SohierDane/BigQuery_Helper@8615a7f6c1663e7f2d48aa2b32c2dbcb600a440f#egg=bq_helper\r\nbqplot==0.12.12\r\nbranca==0.4.1\r\nbrewer2mpl==1.4.1\r\nbrotlipy==0.7.0\r\ncachetools==3.1.1\r\ncairocffi==1.1.0\r\nCairoSVG==2.4.2\r\nCartopy @ file:///home/conda/feedstock_root/build_artifacts/cartopy_1588596947365/work\r\ncatalogue==1.0.0\r\ncatalyst==20.6\r\ncatboost==0.23.2\r\ncategory-encoders @ git+https://github.com/scikit-learn-contrib/categorical-encoding.git@ea9428a896bef77baf8b26159f7030cee924e916\r\ncertifi==2020.4.5.2\r\ncesium==0.9.12\r\ncffi==1.14.0\r\ncftime==1.1.3\r\nchainer==7.4.0\r\nchainer-chemistry==0.7.0\r\nchainercv==0.13.1\r\nchardet==3.0.4\r\ncleverhans==3.0.1\r\nclick==7.1.1\r\nclick-plugins==1.1.1\r\ncliff==3.3.0\r\ncligj==0.5.0\r\ncloud-tpu-client==0.10\r\ncloudpickle==1.3.0\r\nclyent==1.2.2\r\ncmaes==0.5.0\r\ncmd2==1.1.0\r\ncmdstanpy==0.4.0\r\ncmudict==0.4.4\r\ncolorama==0.4.3\r\ncolorcet==2.0.2\r\ncolorlog==4.1.0\r\ncolorlover==0.3.0\r\nconda==4.8.3\r\nconda-package-handling==1.6.0\r\nConfigArgParse==1.2.3\r\nconfigparser==5.0.0\r\nconfuse==1.1.0\r\ncontextily==1.0.0\r\ncontextlib2==0.6.0.post1\r\nconvertdate==2.2.1\r\nconx==3.7.10\r\ncookiecutter==1.7.0\r\ncoverage==5.1\r\ncrc32c==2.0\r\ncryptography==2.8\r\ncssselect2==0.3.0\r\ncufflinks==0.17.3\r\nCVXcanon==0.1.1\r\ncvxpy==1.1.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ncysignals==1.10.2\r\nCython==0.29.20\r\ncytoolz==0.10.1\r\ndask==2.18.1\r\ndask-glm==0.2.0\r\ndask-ml==1.5.0\r\ndask-xgboost==0.1.10\r\ndatashader==0.11.0\r\ndatashape==0.5.2\r\ndeap==1.3.1\r\ndecorator==4.4.2\r\ndeepdish==0.3.6\r\ndefusedxml==0.6.0\r\nDelorean==1.0.0\r\nDeprecated @ file:///home/conda/feedstock_root/build_artifacts/deprecated_1589409885623/work\r\ndeprecation==2.1.0\r\ndescartes==1.1.0\r\ndiff-match-patch==20181111\r\ndill==0.3.2\r\ndipy==1.1.1\r\ndistributed==2.14.0\r\ndlib==19.20.0\r\ndocker==4.2.0\r\ndocker-pycreds==0.4.0\r\ndocopt==0.6.2\r\ndocutils==0.15.2\r\nearthengine-api==0.1.226\r\necos==2.0.7.post1\r\neli5==0.10.1\r\nemoji==0.5.4\r\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nephem==3.7.7.1\r\nessentia==2.1b6.dev234\r\net-xmlfile==1.0.1\r\nfancyimpute==0.5.4\r\nfastai==1.0.61\r\nfastcache==1.1.0\r\nfastprogress==0.2.3\r\nfasttext==0.9.2\r\nfbpca==1.0\r\nfbprophet==0.6\r\nfeather-format==0.4.1\r\nfeaturetools==0.16.0\r\nfilelock==3.0.10\r\nFiona==1.8.13\r\nfitter==1.2.1\r\nflake8==3.7.9\r\nflashtext==2.7\r\nFlask==1.1.2\r\nfolium==0.11.0\r\nfsspec==0.7.2\r\nfuncy==1.14\r\nfury==0.5.1\r\nfuture==0.18.2\r\nfuzzywuzzy==0.18.0\r\ngast==0.3.3\r\ngatspy==0.3\r\ngcsfs==0.6.1\r\nGDAL==3.0.4\r\ngensim==3.8.3\r\ngeographiclib==1.50\r\nGeohash==1.0\r\ngeojson==2.5.0\r\ngeopandas==0.6.3\r\ngeoplot==0.4.1\r\ngeopy==1.22.0\r\ngeoviews==1.8.1\r\ngevent==1.5.0\r\nggplot @ https://github.com/hbasria/ggpy/archive/0.11.5.zip\r\ngitdb==4.0.4\r\nGitPython==3.1.1\r\nglob2==0.7\r\ngluoncv==0.7.0\r\ngluonnlp==0.9.1\r\ngmpy2==2.1.0b1\r\ngoogle==2.0.3\r\ngoogle-api-core==1.17.0\r\ngoogle-api-python-client==1.8.0\r\ngoogle-auth==1.14.0\r\ngoogle-auth-httplib2==0.0.3\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-cloud-automl==0.10.0\r\ngoogle-cloud-bigquery==1.12.1\r\ngoogle-cloud-bigtable==1.2.1\r\ngoogle-cloud-core==1.3.0\r\ngoogle-cloud-dataproc==0.7.0\r\ngoogle-cloud-datastore==1.12.0\r\ngoogle-cloud-firestore==1.6.2\r\ngoogle-cloud-kms==1.4.0\r\ngoogle-cloud-language==1.3.0\r\ngoogle-cloud-logging==1.15.0\r\ngoogle-cloud-pubsub==1.4.3\r\ngoogle-cloud-scheduler==1.2.1\r\ngoogle-cloud-spanner==1.15.1\r\ngoogle-cloud-speech==1.3.2\r\ngoogle-cloud-storage==1.27.0\r\ngoogle-cloud-tasks==1.5.0\r\ngoogle-cloud-translate==2.0.1\r\ngoogle-cloud-videointelligence==1.14.0\r\ngoogle-cloud-vision==1.0.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==0.5.0\r\ngoogleapis-common-protos==1.51.0\r\ngplearn==0.4.1\r\ngpxpy==1.4.1\r\ngql==0.2.0\r\ngraphql-core==1.1\r\ngraphviz==0.8.4\r\ngreenlet==0.4.15\r\ngrpc-google-iam-v1==0.12.3\r\ngrpcio==1.29.0\r\ngrpcio-gcp==0.2.2\r\ngym==0.17.2\r\nh2o==3.30.0.5\r\nh5py==2.10.0\r\nhaversine==2.2.0\r\nheamy==0.0.7\r\nHeapDict==1.0.1\r\nhep-ml==0.6.1\r\nhmmlearn==0.2.3\r\nholidays==0.10.2\r\nholoviews==1.13.2\r\nhpsklearn==0.1.0\r\nhtml5lib==1.0.1\r\nhtmlmin==0.1.12\r\nhttplib2==0.17.2\r\nhttplib2shim==0.0.3\r\nhumanize==2.4.0\r\nhunspell==0.5.5\r\nhusl==4.0.3\r\nhyperopt==0.2.4\r\nhypertools==0.6.2\r\nhypothesis==5.10.0\r\nibis-framework==1.3.0\r\nidna==2.9\r\nimagecodecs==2020.5.30\r\nImageHash==4.1.0\r\nimageio==2.8.0\r\nimagesize==1.2.0\r\nimbalanced-learn==0.7.0\r\nimgaug==0.2.6\r\nimplicit==0.4.2\r\nimportlib-metadata==1.6.0\r\nintervaltree==3.0.2\r\nipykernel==5.1.1\r\nipython==7.13.0\r\nipython-genutils==0.2.0\r\nipython-sql==0.3.9\r\nipywidgets==7.5.1\r\niso3166==1.0.1\r\nisort==4.3.21\r\nisoweek==1.3.3\r\nitsdangerous==1.1.0\r\nJanome==0.3.10\r\njdcal==1.4.1\r\njedi==0.15.2\r\njeepney==0.4.3\r\njieba==0.42.1\r\nJinja2==2.11.2\r\njinja2-time==0.2.0\r\njmespath==0.10.0\r\njoblib==0.14.1\r\njson5==0.9.0\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-aihub-deploy-extension==0.1\r\njupyter-client==6.1.3\r\njupyter-console==6.1.0\r\njupyter-core==4.6.3\r\njupyter-http-over-ws==0.0.8\r\njupyterlab==1.2.10\r\njupyterlab-git==0.10.0\r\njupyterlab-server==1.1.1\r\nkaggle==1.5.6\r\nkaggle-environments==1.0.8\r\nKeras==2.4.0\r\nKeras-Preprocessing==1.1.2\r\nkeras-tuner==1.0.1\r\nkeyring==21.1.1\r\nkiwisolver==1.2.0\r\nkmapper==1.2.0\r\nkmeans-smote==0.1.2\r\nkmodes==0.10.2\r\nknnimpute==0.1.0\r\nkorean-lunar-calendar==0.2.1\r\nkornia==0.3.1\r\nkubernetes==10.1.0\r\nlangid==1.1.6\r\nLasagne @ git+git://github.com/Lasagne/Lasagne.git@5d3c63cb315c50b1cbd27a6bc8664b406f34dd99\r\nlazy-object-proxy==1.4.3\r\nlearntools @ git+https://github.com/Kaggle/learntools@886f5c215de079287f21e2d3a92bd852fb95d105\r\nleven==1.0.4\r\nlibarchive-c==2.9\r\nlibrosa==0.7.2\r\nlief==0.9.0\r\nlightfm==1.15\r\nlightgbm==2.3.1\r\nlime==0.2.0.0\r\nline-profiler==3.0.2\r\nllvmlite==0.31.0\r\nlml==0.0.9\r\nlocket==0.2.0\r\nLunarCalendar==0.0.9\r\nlxml==4.5.0\r\nMako==1.1.3\r\nmapclassify==2.3.0\r\nmarisa-trie==0.7.5\r\nMarkdown==3.2.1\r\nmarkovify==0.8.2\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.1\r\nmatplotlib-venn==0.11.5\r\nmccabe==0.6.1\r\nmemory-profiler==0.57.0\r\nmercantile==1.1.5\r\nmissingno==0.4.2\r\nmistune==0.8.4\r\nmizani==0.7.1\r\nmkl-fft==1.1.0\r\nmkl-random==1.1.0\r\nmkl-service==2.3.0\r\nml-metrics==0.1.4\r\nmlcrate==0.2.0\r\nmlens==0.2.3\r\nmlxtend==0.17.2\r\nmmh3==2.5.1\r\nmne==0.20.7\r\nmnist==0.2.2\r\nmock==3.0.5\r\nmore-itertools==8.2.0\r\nmpld3==0.5.1\r\nmplleaflet==0.0.5\r\nmpmath==1.1.0\r\nmsgpack==0.6.2\r\nmsgpack-numpy==0.4.6.post0\r\nmultidict==4.7.6\r\nmultipledispatch==0.6.0\r\nmultiprocess==0.70.10\r\nmunch==2.5.0\r\nmurmurhash==1.0.2\r\nmxnet==1.6.0\r\nmypy-extensions==0.4.3\r\nnb-conda==2.2.1\r\nnb-conda-kernels==2.2.3\r\nnbclient==0.2.0\r\nnbconvert==5.6.1\r\nnbdime==2.0.0\r\nnbformat==5.0.6\r\nnbpresent==3.0.2\r\nnervananeon @ file:///usr/local/src/neon\r\nnest-asyncio==1.3.2\r\nnetCDF4==1.5.3\r\nnetworkx==2.4\r\nnibabel==3.1.0\r\nnilearn==0.6.2\r\nnltk==3.2.4\r\nnnabla==1.8.0\r\nnolearn==0.6.1\r\nnose==1.3.7\r\nnotebook==5.5.0\r\nnotebook-executor==0.2\r\nnumba==0.48.0\r\nnumexpr==2.7.1\r\nnumpy==1.18.1\r\nnumpydoc==0.9.2\r\nnvidia-ml-py3==7.352.0\r\noauth2client==4.1.3\r\noauthlib==3.0.1\r\nodfpy==1.4.1\r\nolefile==0.46\r\nonnx==1.7.0\r\nopencv-python==4.2.0.34\r\nopenpyxl==3.0.3\r\nopenslide-python @ git+git://github.com/rosbo/openslide-python.git@6bb6e3dbae448fe9ccf21a5a2078e9d7e890153c\r\nopt-einsum==3.2.1\r\noptuna==1.5.0\r\norderedmultidict==1.0.1\r\nortools==7.7.7810\r\nosmnx==0.14.1\r\nosqp==0.6.1\r\noverrides==3.0.0\r\nOWSLib @ file:///home/conda/feedstock_root/build_artifacts/owslib_1591376955812/work\r\npackaging==20.1\r\npalettable==3.3.0\r\npandas==1.0.3\r\npandas-datareader==0.8.1\r\npandas-profiling==2.6.0\r\npandas-summary==0.0.7\r\npandasql==0.7.3\r\npandoc==1.0.2\r\npandocfilters==1.4.2\r\npanel==0.9.5\r\npapermill==2.1.0\r\nparam==1.9.3\r\nparso==0.5.2\r\npartd==1.1.0\r\npath==13.1.0\r\npath.py==12.4.0\r\npathlib2==2.3.5\r\npathos==0.2.6\r\npathspec==0.8.0\r\npathtools==0.1.2\r\npatsy==0.5.1\r\npbr==5.4.5\r\npdf2image==1.13.1\r\nPDPbox @ git+https://github.com/SauceCat/PDPbox@73c69665f1663b53984e187c7bc8996e25fea18e\r\npep8==1.7.1\r\npexpect==4.8.0\r\nphik==0.9.11\r\npickleshare==0.7.5\r\nPillow==5.4.1\r\npkginfo==1.5.0.1\r\nplac==1.1.3\r\nplotly==4.8.1\r\nplotly-express==0.4.1\r\nplotnine==0.7.0\r\npluggy==0.13.0\r\nply==3.11\r\npolyglot==16.7.4\r\nportalocker==1.7.0\r\nposix-ipc==1.0.4\r\npox==0.2.8\r\npoyo==0.5.0\r\nppca==0.0.4\r\nppft==1.6.6.2\r\npreprocessing==0.1.13\r\npreshed==3.0.2\r\nprettytable==0.7.2\r\nprometheus-client==0.7.1\r\npromise==2.3\r\nprompt-toolkit==3.0.5\r\npronouncing==0.2.0\r\nprotobuf==3.12.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npudb==2019.2\r\npy==1.8.1\r\npy-cpuinfo==6.0.0\r\npy-lz4framed==0.14.0\r\npy-spy==0.3.3\r\npy-stringmatching==0.4.1\r\npy-stringsimjoin==0.3.1\r\npyahocorasick==1.4.0\r\npyaml==20.4.0\r\nPyArabic==0.6.7\r\npyarrow==0.16.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.7\r\nPyAstronomy==0.15.0\r\npybind11==2.5.0\r\nPyBrain==0.3\r\npycairo==1.19.1\r\npycodestyle==2.5.0\r\npycosat==0.6.3\r\npycountry==19.8.18\r\npycparser==2.20\r\npycrypto==2.6.1\r\npyct==0.4.6\r\npycurl==7.43.0.5\r\npydash==4.8.0\r\npydicom==2.0.0\r\npydocstyle==5.0.2\r\npydot==1.4.1\r\npydub==0.24.1\r\npyemd==0.5.1\r\npyepsg==0.4.0\r\npyexcel-io==0.5.20\r\npyexcel-ods==0.5.6\r\npyfasttext==0.4.6\r\npyflakes==2.1.1\r\npyglet==1.5.0\r\nPygments==2.6.1\r\nPyJWT==1.7.1\r\npykalman==0.9.5\r\npyLDAvis==2.1.2\r\npylint==2.4.4\r\npymc3==3.9.1\r\nPyMeeus==0.3.7\r\npymongo==3.10.1\r\nPympler==0.8\r\npyocr==0.7.2\r\npyodbc==4.0.30\r\npyOpenSSL==19.1.0\r\npypandoc==1.5\r\npyparsing==2.4.7\r\npyPdf==1.13\r\npyperclip==1.8.0\r\nPyPrind==2.11.2\r\npyproj @ file:///home/conda/feedstock_root/build_artifacts/pyproj_1588596070165/work\r\nPyQt5==5.12.3\r\nPyQt5-sip==4.19.18\r\nPyQtWebEngine==5.12.1\r\npyrsistent==0.16.0\r\npysal==2.1.0\r\npyshp==2.1.0\r\nPySocks==1.7.1\r\npystan==2.19.1.1\r\npytagcloud==0.3.5\r\npytesseract==0.3.4\r\npytest==5.4.1\r\npytest-arraydiff==0.3\r\npytest-astropy==0.7.0\r\npytest-astropy-header==0.1.2\r\npytest-cov==2.10.0\r\npytest-doctestplus==0.4.0\r\npytest-mock==3.1.1\r\npytest-openfiles==0.4.0\r\npytest-remotedata==0.3.1\r\npytext-nlp==0.1.2\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython-igraph @ file:///home/conda/feedstock_root/build_artifacts/python-igraph_1588168236405/work\r\npython-jsonrpc-server==0.3.4\r\npython-language-server==0.31.10\r\npython-Levenshtein==0.12.0\r\npython-louvain==0.14\r\npython-slugify==4.0.0\r\npytorch-ignite==0.3.0\r\npytz==2019.3\r\nPyUpSet==0.1.1.post7\r\npyviz-comms==0.7.5\r\nPyWavelets==1.1.1\r\npyxdg==0.26\r\nPyYAML==5.3.1\r\npyzmq==19.0.0\r\nQDarkStyle==2.8.1\r\nqgrid==1.3.1\r\nQtAwesome==0.7.1\r\nqtconsole==4.7.3\r\nQtPy==1.9.0\r\nrandomgen==1.16.6\r\nrasterio==1.1.5\r\nray==0.8.5\r\nredis==3.4.1\r\nregex==2020.4.4\r\nrequests==2.23.0\r\nrequests-oauthlib==1.2.0\r\nresampy==0.2.2\r\nretrying==1.3.3\r\nrgf-python==3.8.0\r\nrope==0.16.0\r\nrsa==4.0\r\nRtree==0.9.4\r\nruamel-yaml==0.15.80\r\ns2sphere==0.2.5\r\ns3fs==0.4.2\r\ns3transfer==0.3.3\r\nsacred==0.8.1\r\nsacremoses==0.0.43\r\nscattertext==0.0.2.65\r\nscikit-image==0.16.2\r\nscikit-learn==0.23.1\r\nscikit-multilearn==0.2.0\r\nscikit-optimize==0.7.4\r\nscikit-plot==0.3.7\r\nscikit-surprise==1.1.0\r\nscipy==1.4.1\r\nscs==2.1.2\r\nseaborn==0.10.0\r\nSecretStorage==3.1.2\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsentry-sdk==0.15.1\r\nsetuptools-git==1.2\r\nshap==0.35.0\r\nShapely==1.7.0\r\nshortuuid==1.0.1\r\nsimplegeneric==0.8.1\r\nSimpleITK==1.2.4\r\nsimplejson==3.17.0\r\nsingledispatch==3.4.0.3\r\nsip==4.19.20\r\nsix==1.14.0\r\nsklearn==0.0\r\nsklearn-contrib-py-earth @ git+git://github.com/scikit-learn-contrib/py-earth.git@dde5f899255411a7b9cbbabf93a817eff4b02e5e\r\nsklearn-pandas==1.8.0\r\nsmart-open==2.0.0\r\nsmhasher==0.150.1\r\nsmmap==3.0.2\r\nsnowballstemmer==2.0.0\r\nsnuggs==1.4.7\r\nsortedcollections==1.1.2\r\nsortedcontainers==2.1.0\r\nSoundFile==0.10.3.post1\r\nsoupsieve==1.9.4\r\nspacy==2.2.4\r\nspectral==0.21\r\nSphinx==3.0.2\r\nsphinx-rtd-theme==0.2.4\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nsphinxcontrib-websupport==1.2.1\r\nspyder==4.1.2\r\nspyder-kernels==1.9.0\r\nSQLAlchemy==1.3.16\r\nsqlparse==0.3.1\r\nsquarify==0.4.3\r\nsrsly==1.0.2\r\nstatsmodels==0.11.1\r\nstemming==1.0.1\r\nstevedore==2.0.0\r\nstop-words==2018.7.23\r\nstopit==1.1.2\r\nsubprocess32==3.5.4\r\nsvgwrite==1.4\r\nsympy==1.5.1\r\ntables==3.6.1\r\ntabulate==0.8.7\r\ntangled-up-in-unicode==0.0.4\r\ntblib==1.6.0\r\ntenacity==6.1.0\r\ntensorboard==2.2.2\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorboardX==2.0\r\ntensorflow @ file:///tmp/tensorflow_cpu/tensorflow-2.2.0-cp37-cp37m-linux_x86_64.whl\r\ntensorflow-addons @ file:///tmp/tfa_cpu/tensorflow_addons-0.10.0-cp37-cp37m-linux_x86_64.whl\r\ntensorflow-datasets==3.1.0\r\ntensorflow-estimator==2.2.0\r\ntensorflow-gcs-config @ file:///tmp/tensorflow_gcs_config/tensorflow_gcs_config-2.1.7-py3-none-any.whl\r\ntensorflow-hub==0.8.0\r\ntensorflow-metadata==0.22.2\r\ntensorflow-probability==0.10.0\r\nTensorforce==0.5.5\r\ntensorpack==0.10.1\r\ntermcolor==1.1.0\r\nterminado==0.8.3\r\nterminalplot==0.3.0\r\nterminaltables==3.1.0\r\ntestpath==0.4.4\r\ntext-unidecode==1.3\r\ntextblob==0.15.3\r\ntexttable==1.6.2\r\ntextwrap3==0.9.2\r\nTheano==1.0.4\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntifffile==2020.6.3\r\ntinycss2==1.0.2\r\ntokenizers==0.7.0\r\ntoml==0.10.0\r\ntoolz==0.10.0\r\ntorch==1.5.0\r\ntorchaudio==0.5.0a0+738ccba\r\ntorchtext==0.6.0\r\ntorchvision==0.6.0a0+35d732a\r\ntornado==5.0.2\r\nTPOT==0.11.5\r\ntqdm==4.45.0\r\ntraitlets==4.3.3\r\ntraittypes==0.2.1\r\ntransformers==2.11.0\r\ntrueskill==0.4.5\r\ntsfresh==0.16.0\r\ntyped-ast==1.4.1\r\ntypeguard==2.9.1\r\ntyping==3.7.4.1\r\ntyping-extensions==3.7.4.1\r\ntzlocal==2.1\r\nujson==1.35\r\numap-learn @ https://api.github.com/repos/lmcinnes/umap/tarball/5f9488a9540d1e0ac149e2dd42ebf03c39706110\r\nunicodecsv==0.14.1\r\nUnidecode==1.1.1\r\nupdate-checker==0.17\r\nuritemplate==3.0.1\r\nurllib3==1.24.3\r\nurwid==2.1.0\r\nvecstack==0.4.0\r\nvisions==0.4.1\r\nvowpalwabbit==8.8.1\r\nvtk==8.1.2\r\nWand==0.5.3\r\nwandb==0.9.1\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwavio==0.0.4\r\nwcwidth==0.1.9\r\nwebencodings==0.5.1\r\nwebsocket-client==0.57.0\r\nWerkzeug==1.0.1\r\nwfdb==3.0.1\r\nwhichcraft==0.6.1\r\nwidgetsnbextension==3.5.1\r\nWordbatch==1.4.6\r\nwordcloud==1.7.0\r\nwordsegment==1.3.1\r\nwrapt==1.11.2\r\nwurlitzer==2.0.0\r\nxarray==0.15.1\r\nxgboost==1.1.1\r\nxlrd==1.2.0\r\nXlsxWriter==1.2.8\r\nxlwt==1.3.0\r\nxvfbwrapper==0.2.9\r\nyapf==0.29.0\r\nyarl==1.4.2\r\nyellowbrick==1.1\r\nzict==2.0.0\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nfrom allennlp.models.archival import load_archive\r\narchive = load_archive(<insert-model-path>)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4430", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4430/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4430/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4430/events", "html_url": "https://github.com/allenai/allennlp/issues/4430", "id": 649147059, "node_id": "MDU6SXNzdWU2NDkxNDcwNTk=", "number": 4430, "title": "BERT sliding window embedding size smaller than number of tokens", "user": {"login": "j6mes", "id": 7656957, "node_id": "MDQ6VXNlcjc2NTY5NTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/7656957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j6mes", "html_url": "https://github.com/j6mes", "followers_url": "https://api.github.com/users/j6mes/followers", "following_url": "https://api.github.com/users/j6mes/following{/other_user}", "gists_url": "https://api.github.com/users/j6mes/gists{/gist_id}", "starred_url": "https://api.github.com/users/j6mes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j6mes/subscriptions", "organizations_url": "https://api.github.com/users/j6mes/orgs", "repos_url": "https://api.github.com/users/j6mes/repos", "events_url": "https://api.github.com/users/j6mes/events{/privacy}", "received_events_url": "https://api.github.com/users/j6mes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-01T17:22:51Z", "updated_at": "2020-07-02T23:08:29Z", "closed_at": "2020-07-02T23:08:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a question about the behaviour o embeddings generated by BERT for long token sequences.\r\n\r\nI'm aware there is some functionality for generating embeddings using a sliding window approach (#2537) -- and in v1.0.0 of allennlp, I no longer get warnings about long sequences being truncated (so I assume that embeddings are now generated with a sliding window for long token sequences.  \r\n\r\nWith a batch-size of 1, I would expect the length of the textfields and length of the embeddings generated by BERT to be equivalent. However, in a simple SQuAD style evaluation with an input sequence of 1088 tokens I am finding that my embedding size is only 1080 after using the BERT embedder. I have added this assertion which fails:\r\n\r\n```\r\n    def forward(  # type: ignore\r\n        self,\r\n        question_with_context: Dict[str, Dict[str, torch.LongTensor]],\r\n        context_span: torch.IntTensor,\r\n        answer_span: Optional[torch.IntTensor] = None,\r\n        metadata: List[Dict[str, Any]] = None\r\n    ) -> Dict[str, torch.Tensor]:\r\n        embedded_text = self._text_field_embedder(question_with_context)\r\n        assert embedded_text.shape[1] == question_with_context[\"tokens\"][\"token_ids\"].shape[1], \"Expected embedding size and sequence length to be equal, but instead got an embedding size of {} for {} tokens\".format(embedded_text.shape[1], question_with_context[\"tokens\"][\"token_ids\"].shape[1])\r\n```\r\n\r\n```\r\nAssertionError: Expected embedding size and sequence length to be equal, but instead got an embedding size of 1080 for 1088 tokens\r\n```\r\n\r\nIf this is expected, how would the original tokens map to the embedded tokens? If it is not expected, what could the source of the issue be? Could it be something silly I'm doing?\r\n\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4429", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4429/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4429/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4429/events", "html_url": "https://github.com/allenai/allennlp/issues/4429", "id": 648797463, "node_id": "MDU6SXNzdWU2NDg3OTc0NjM=", "number": 4429, "title": "allowed_start_transitions and allowed_end_transitions don't actually enforce their constraints", "user": {"login": "zhuango", "id": 5491519, "node_id": "MDQ6VXNlcjU0OTE1MTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5491519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhuango", "html_url": "https://github.com/zhuango", "followers_url": "https://api.github.com/users/zhuango/followers", "following_url": "https://api.github.com/users/zhuango/following{/other_user}", "gists_url": "https://api.github.com/users/zhuango/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhuango/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhuango/subscriptions", "organizations_url": "https://api.github.com/users/zhuango/orgs", "repos_url": "https://api.github.com/users/zhuango/repos", "events_url": "https://api.github.com/users/zhuango/events{/privacy}", "received_events_url": "https://api.github.com/users/zhuango/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-07-01T08:52:50Z", "updated_at": "2020-07-02T11:30:57Z", "closed_at": "2020-07-02T11:05:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "I working on a project that uses [viterbi_decode ](https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py#L403) function in allennlp.nn.util. viterbi_decode function has _allowed_start_transitions_/_allowed_end_transitions_ parameters, which aim to enable viterbi decoding process to take the start/end timestep restriction into account. But how it works confuses me.\r\n\r\nFollows are what I learned from viterbi_decode code. _path_score_ is initialized with tag_sequence[0] which is a zero vector when _has_start_end_restrictions_ is true. When calculating the _score_ for the first time step through a topk op on _path_score_ + _transition_matrix_, the state of previous timestep (_paths_) is depend on _transition_matrix_ and not restricted on \"start\". \r\n\r\nFor an extreme case, the first timestep cannot be any state and _allowed_start_transitions_ are all -inf. Normally, the _score_ of the first timestep is -inf vector because no state is allowed at first timestep. But topk op on _path_score_ + _transition_matrix_  could still get non-inf _score_ and non-start _paths_of previous time step. Because there are potentials bigger than -inf and those corresponding previous states will be append to _paths_ which is not \"start\" state. The _allowed_start_transitions_ is not working ?\r\nSo it confuses me. Please help me to understand how does the _allowed_start_transitions_/_allowed_end_transitions_  actually work.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4428", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4428/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4428/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4428/events", "html_url": "https://github.com/allenai/allennlp/issues/4428", "id": 648766247, "node_id": "MDU6SXNzdWU2NDg3NjYyNDc=", "number": 4428, "title": "ModuleNotFoundError when num_workers>0 & DistributeDataParallel & lazy read", "user": {"login": "AutoTemp", "id": 17263752, "node_id": "MDQ6VXNlcjE3MjYzNzUy", "avatar_url": "https://avatars1.githubusercontent.com/u/17263752?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AutoTemp", "html_url": "https://github.com/AutoTemp", "followers_url": "https://api.github.com/users/AutoTemp/followers", "following_url": "https://api.github.com/users/AutoTemp/following{/other_user}", "gists_url": "https://api.github.com/users/AutoTemp/gists{/gist_id}", "starred_url": "https://api.github.com/users/AutoTemp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AutoTemp/subscriptions", "organizations_url": "https://api.github.com/users/AutoTemp/orgs", "repos_url": "https://api.github.com/users/AutoTemp/repos", "events_url": "https://api.github.com/users/AutoTemp/events{/privacy}", "received_events_url": "https://api.github.com/users/AutoTemp/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-01T08:06:24Z", "updated_at": "2020-07-17T16:02:19Z", "closed_at": "2020-07-17T16:02:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nWhen num_workers>0, DistributeDataParallel and lazy read, allennlp report ModuleNotFoundError.\r\n('my_text_classifier' is include-package)\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/xxx/anaconda3/envs/allennlp1.0/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"/home/xxx/anaconda3/envs/allennlp1.0/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\r\n    self = reduction.pickle.load(from_parent)\r\nModuleNotFoundError: No module named 'my_text_classifier'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/xxx/anaconda3/envs/allennlp1.0/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"/home/xxx/anaconda3/envs/allennlp1.0/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\r\n    self = reduction.pickle.load(from_parent)\r\nModuleNotFoundError: No module named 'my_text_classifier'\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- #3924\r\n(ModuleNotFoundError also mentioned in the issue but the solution does not work)\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.0\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nrsa==3.4.2\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.20.0\r\nscipy==1.5.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.1.9\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.0.8\r\ntokenizers==0.7.0\r\ntorch==1.5.1\r\ntqdm==4.47.0\r\ntransformers==2.11.0\r\nUnidecode==1.1.1\r\nurllib3==1.25.9\r\nwasabi==0.6.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nwidgetsnbextension==3.5.1\r\nword2number==1.1\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n1. use the example in [allennlp-guide-examples/quick_start](https://github.com/allenai/allennlp-guide-examples/tree/master/quick_start)\r\n2. In 'my_text_classifier.jsonnet', set lazy=true in reader, add distributed info, and set num_workers=2 in data_loader\r\n(details are as follow)\r\n3. run \"allennlp train my_text_classifier.jsonnet -s demo --include-package my_text_classifier\"\r\n\r\nwhen remove --include-package and turn into .allennlp_plugins (with one line: my_text_classifier)\r\nalso same error\r\n\r\nremove any of num_workers>0 & DistributeDataParallel & lazy read, the project is ok.\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nallennlp train my_text_classifier.jsonnet -s demo --include-package my_text_classifier\r\n(also error when use .allennlp_plugins)\r\n\r\nmy_text_classifier.jsonnet:\r\n\r\n{\r\n    \"dataset_reader\" : {\r\n        \"type\": \"classification-tsv\",\r\n        \"token_indexers\": {\r\n            \"tokens\": {\r\n                \"type\": \"single_id\"\r\n            }\r\n        },\r\n        \"lazy\": true\r\n    },\r\n    \"train_data_path\": \"data/movie_review/train.tsv\",\r\n    \"validation_data_path\": \"data/movie_review/dev.tsv\",\r\n    \"model\": {\r\n        \"type\": \"simple_classifier\",\r\n        \"embedder\": {\r\n            \"token_embedders\": {\r\n                \"tokens\": {\r\n                    \"type\": \"embedding\",\r\n                    \"embedding_dim\": 10\r\n                }\r\n            }\r\n        },\r\n        \"encoder\": {\r\n            \"type\": \"bag_of_embeddings\",\r\n            \"embedding_dim\": 10\r\n        }\r\n    },\r\n    \"data_loader\": {\r\n        \"batch_size\": 8,\r\n        \"num_workers\": 2\r\n\r\n    },\r\n    \"trainer\": {\r\n        \"optimizer\": \"adam\",\r\n        \"num_epochs\": 5\r\n    },\r\n    \"distributed\":{\r\n        \"cuda_devices\": [0,2],\r\n        \"num_nodes\": 1\r\n    }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4427", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4427/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4427/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4427/events", "html_url": "https://github.com/allenai/allennlp/issues/4427", "id": 648712712, "node_id": "MDU6SXNzdWU2NDg3MTI3MTI=", "number": 4427, "title": "PretrainedModelInitializer fails to initialize a model with a 0-dim tensor", "user": {"login": "reiyw", "id": 12150295, "node_id": "MDQ6VXNlcjEyMTUwMjk1", "avatar_url": "https://avatars2.githubusercontent.com/u/12150295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reiyw", "html_url": "https://github.com/reiyw", "followers_url": "https://api.github.com/users/reiyw/followers", "following_url": "https://api.github.com/users/reiyw/following{/other_user}", "gists_url": "https://api.github.com/users/reiyw/gists{/gist_id}", "starred_url": "https://api.github.com/users/reiyw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reiyw/subscriptions", "organizations_url": "https://api.github.com/users/reiyw/orgs", "repos_url": "https://api.github.com/users/reiyw/repos", "events_url": "https://api.github.com/users/reiyw/events{/privacy}", "received_events_url": "https://api.github.com/users/reiyw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-01T06:31:01Z", "updated_at": "2020-07-06T14:15:50Z", "closed_at": "2020-07-06T14:15:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 27, in <module>\r\n    applicator(net)\r\n  File \"/Users/reiyw/.ghq/ghq/github.com/allenai/allennlp/allennlp/nn/initializers.py\", line 482, in __call__\r\n    initializer(parameter, parameter_name=name)\r\n  File \"/Users/reiyw/.ghq/ghq/github.com/allenai/allennlp/allennlp/nn/initializers.py\", line 406, in __call__\r\n    tensor.data[:] = source_weights[:]\r\nIndexError: slice() cannot be applied to a 0-dim tensor.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n`PretrainedModelInitializer` fails to initialize a model with 0-dim tensors. The error occurs at:\r\nhttps://github.com/allenai/allennlp/blob/637dbb159082999c546ac2fc64746b88e5c9d1b5/allennlp/nn/initializers.py#L405-L406\r\nThe cause is that slicing cannot be applied to a 0-dim tensor. Instead of slicing a tensor here, we can avoid the error by using `copy_` method:\r\n```\r\ntensor.data.copy_(source_weights.data)\r\n```\r\nI have confirmed that this change will not break the pretrained model initializer test.\r\n\r\nAnother workaround is to use a 1-dim tensor instead of a 0-dim tensor to represent a scalar, but I think it's better to fix it so that others don't face the same problem.\r\n\r\nIf that change is appropriate, I would be happy to submit a PR.\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: OS X\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n-e git+ssh://git@github.com/allenai/allennlp.git@9c4dfa544e85e00d636beb0026a08e40dcdb6404#egg=allennlp\r\napex @ git+https://github.com/NVIDIA/apex.git@44532b30a4fad442f00635a0f4c8f241b06c2315\r\nappdirs==1.4.4\r\nattrs==19.3.0\r\nblack==19.10b0\r\nbleach==3.1.5\r\nblis==0.4.1\r\nboto3==1.14.12\r\nbotocore==1.17.12\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncodecov==2.1.7\r\ncolorama==0.4.3\r\ncoverage==5.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndocutils==0.15.2\r\nfilelock==3.0.12\r\nflake8==3.8.3\r\nflaky==3.6.1\r\nfuture==0.18.2\r\nh5py==2.10.0\r\nidna==2.10\r\nimportlib-metadata==1.7.0\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nkeyring==21.2.1\r\nkiwisolver==1.2.0\r\nlivereload==2.6.2\r\nlunr==0.5.8\r\nMarkdown==3.2.2\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.2\r\nmccabe==0.6.1\r\nmkdocs==1.1.2\r\nmkdocs-material==5.3.3\r\nmkdocs-material-extensions==1.0\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy==0.782\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnr.collections==0.0.1\r\nnr.databind.core==0.0.16\r\nnr.databind.json==0.0.11\r\nnr.interface==0.0.3\r\nnr.metaclass==0.0.5\r\nnr.parsing.date==0.1.0\r\nnr.pylang.utils==0.0.3\r\nnr.stream==0.0.4\r\nnumpy==1.19.0\r\noverrides==3.1.0\r\npackaging==20.4\r\npathspec==0.8.0\r\npathtools==0.1.2\r\npkginfo==1.5.0.1\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.12.2\r\npy==1.9.0\r\npy-cpuinfo==6.0.0\r\npycodestyle==2.6.0\r\npyflakes==2.2.0\r\nPygments==2.6.1\r\npymdown-extensions==7.1\r\npyparsing==2.4.7\r\npytest==5.4.3\r\npytest-benchmark==3.2.3\r\npytest-cov==2.10.0\r\npython-dateutil==2.8.1\r\nPyYAML==5.3.1\r\nreadme-renderer==26.0\r\nregex==2020.6.8\r\nrequests==2.24.0\r\nrequests-toolbelt==0.9.1\r\nresponses==0.10.15\r\nrfc3986==1.4.0\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.5.0\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.3.0\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nthinc==7.4.1\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.1\r\ntorch==1.5.1\r\ntornado==6.0.4\r\ntqdm==4.47.0\r\ntransformers==2.11.0\r\ntwine==3.2.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.2\r\nurllib3==1.25.9\r\nwasabi==0.7.0\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nimport tempfile\r\nimport pathlib\r\n\r\nimport torch\r\n\r\nfrom allennlp.nn import InitializerApplicator\r\nfrom allennlp.nn.initializers import PretrainedModelInitializer\r\n\r\n\r\nclass Net(torch.nn.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        # 0-dim tensor\r\n        self.scalar = torch.nn.Parameter(torch.tensor(1.0))\r\n\r\n\r\nnet = Net()\r\ntemp_dir = pathlib.Path(tempfile.mkdtemp())\r\nweights_file = temp_dir / \"weights.th\"\r\ntorch.save(net.state_dict(), weights_file)\r\n\r\ninitializer = PretrainedModelInitializer(weights_file)\r\napplicator = InitializerApplicator([(\"scalar\", initializer)])\r\napplicator(net)\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4426", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4426/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4426/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4426/events", "html_url": "https://github.com/allenai/allennlp/issues/4426", "id": 648383141, "node_id": "MDU6SXNzdWU2NDgzODMxNDE=", "number": 4426, "title": "Add an ImageEncoder abstraction, and a DetectronImageEncoder implementation of it", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/14", "html_url": "https://github.com/allenai/allennlp/milestone/14", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/14/labels", "id": 5601713, "node_id": "MDk6TWlsZXN0b25lNTYwMTcxMw==", "number": 14, "title": "2.0", "description": "", "creator": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "open_issues": 9, "closed_issues": 6, "state": "open", "created_at": "2020-06-30T17:05:12Z", "updated_at": "2020-08-18T11:41:12Z", "due_on": null, "closed_at": null}, "comments": 3, "created_at": "2020-06-30T17:56:00Z", "updated_at": "2020-07-16T17:44:07Z", "closed_at": "2020-07-16T17:31:31Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "#4420 loads up a detectron model and runs it, but it hard-codes which model it loads and how it's configured. This issue is about making this flexible and configurable. I want to be able to say in the configuration file something like this:\r\n\r\n```\r\n...\r\nmodel: {\r\n    \"type\": \"my-vqa-model\",\r\n    \"image_encoder\": {\r\n        \"type\": \"detectron\",\r\n        \"config\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\r\n    }\r\n}\r\n...\r\n```\r\n\r\nIn order to set parameters individually (and not just load a yaml file), it would look like this:\r\n```\r\n...\r\nmodel: {\r\n    \"type\": \"my-vqa-model\",\r\n    \"image_encoder\": {\r\n        \"type\": \"detectron\",\r\n        \"config\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\",    // load defaults from built-in files\r\n        \"model\": {\"resnets\": {\"depth\": 100}},    // override some values, mapping 1:1 to detectron configs\r\n    }\r\n}\r\n...\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4419", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4419/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4419/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4419/events", "html_url": "https://github.com/allenai/allennlp/issues/4419", "id": 648012359, "node_id": "MDU6SXNzdWU2NDgwMTIzNTk=", "number": 4419, "title": "QANet in allennlp-models still used the old version of regularizer", "user": {"login": "pengshuang", "id": 11802795, "node_id": "MDQ6VXNlcjExODAyNzk1", "avatar_url": "https://avatars0.githubusercontent.com/u/11802795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pengshuang", "html_url": "https://github.com/pengshuang", "followers_url": "https://api.github.com/users/pengshuang/followers", "following_url": "https://api.github.com/users/pengshuang/following{/other_user}", "gists_url": "https://api.github.com/users/pengshuang/gists{/gist_id}", "starred_url": "https://api.github.com/users/pengshuang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pengshuang/subscriptions", "organizations_url": "https://api.github.com/users/pengshuang/orgs", "repos_url": "https://api.github.com/users/pengshuang/repos", "events_url": "https://api.github.com/users/pengshuang/events{/privacy}", "received_events_url": "https://api.github.com/users/pengshuang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "e827b7", "default": false, "description": ""}, {"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-30T09:17:59Z", "updated_at": "2020-07-01T03:36:11Z", "closed_at": "2020-07-01T03:36:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "As the ``Upgrade guide from v0.9.0`` said:\r\n\r\nRegularization now needs another key in a config file. Instead of specifying regularization as ``\"regularizer\": [[regex1, regularizer_params], [regex2, regularizer_params]]``, it now must be specified as \"regularizer\": ``{\"regexes\": [[regex1, regularizer_params], [regex2, regularizer_params]]}``(https://github.com/allenai/allennlp/releases/tag/v1.0.0).\r\n\r\nBut I find that the training_config of qanet still used the old version of ``regularizer``\r\n\r\nsee:\r\nhttps://github.com/allenai/allennlp-models/blob/37136f8ecbc42d26d9b135d06e4042f22d0d1bee/training_config/rc/qanet.jsonnet#L114.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4409", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4409/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4409/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4409/events", "html_url": "https://github.com/allenai/allennlp/issues/4409", "id": 647349644, "node_id": "MDU6SXNzdWU2NDczNDk2NDQ=", "number": 4409, "title": "ElmoEmbedder seem missing from new version", "user": {"login": "pinedbean", "id": 9152586, "node_id": "MDQ6VXNlcjkxNTI1ODY=", "avatar_url": "https://avatars0.githubusercontent.com/u/9152586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pinedbean", "html_url": "https://github.com/pinedbean", "followers_url": "https://api.github.com/users/pinedbean/followers", "following_url": "https://api.github.com/users/pinedbean/following{/other_user}", "gists_url": "https://api.github.com/users/pinedbean/gists{/gist_id}", "starred_url": "https://api.github.com/users/pinedbean/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pinedbean/subscriptions", "organizations_url": "https://api.github.com/users/pinedbean/orgs", "repos_url": "https://api.github.com/users/pinedbean/repos", "events_url": "https://api.github.com/users/pinedbean/events{/privacy}", "received_events_url": "https://api.github.com/users/pinedbean/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-29T12:51:58Z", "updated_at": "2020-06-29T17:25:54Z", "closed_at": "2020-06-29T17:25:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "ElmoEmbedder seem missing from new version, how can I get embedding from ELMo (already have hdf5 weight)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4408", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4408/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4408/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4408/events", "html_url": "https://github.com/allenai/allennlp/issues/4408", "id": 647014714, "node_id": "MDU6SXNzdWU2NDcwMTQ3MTQ=", "number": 4408, "title": "Allennlp Predictor code giving an error.", "user": {"login": "mmb1793", "id": 67561966, "node_id": "MDQ6VXNlcjY3NTYxOTY2", "avatar_url": "https://avatars1.githubusercontent.com/u/67561966?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mmb1793", "html_url": "https://github.com/mmb1793", "followers_url": "https://api.github.com/users/mmb1793/followers", "following_url": "https://api.github.com/users/mmb1793/following{/other_user}", "gists_url": "https://api.github.com/users/mmb1793/gists{/gist_id}", "starred_url": "https://api.github.com/users/mmb1793/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mmb1793/subscriptions", "organizations_url": "https://api.github.com/users/mmb1793/orgs", "repos_url": "https://api.github.com/users/mmb1793/repos", "events_url": "https://api.github.com/users/mmb1793/events{/privacy}", "received_events_url": "https://api.github.com/users/mmb1793/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2276693919, "node_id": "MDU6TGFiZWwyMjc2NjkzOTE5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "aaaaaa", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-28T22:02:03Z", "updated_at": "2020-08-18T16:18:29Z", "closed_at": "2020-08-18T16:18:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI am trying to run the following code -\r\nfrom allennlp.predictors.predictor import Predictor\r\npredictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz\")\r\n\r\nbut it is giving me an error -\r\n![image](https://user-images.githubusercontent.com/67561966/85959288-145dc780-b9b9-11ea-82fc-3f3c57f1fe6c.png)\r\n\r\nI have tried installing the packages multiple times - both pytorch and allennlp, but i am unable to resolve this issue.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4407", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4407/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4407/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4407/events", "html_url": "https://github.com/allenai/allennlp/issues/4407", "id": 646822736, "node_id": "MDU6SXNzdWU2NDY4MjI3MzY=", "number": 4407, "title": "How to use models in different epochs for test ?", "user": {"login": "wlhgtc", "id": 16603773, "node_id": "MDQ6VXNlcjE2NjAzNzcz", "avatar_url": "https://avatars2.githubusercontent.com/u/16603773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wlhgtc", "html_url": "https://github.com/wlhgtc", "followers_url": "https://api.github.com/users/wlhgtc/followers", "following_url": "https://api.github.com/users/wlhgtc/following{/other_user}", "gists_url": "https://api.github.com/users/wlhgtc/gists{/gist_id}", "starred_url": "https://api.github.com/users/wlhgtc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wlhgtc/subscriptions", "organizations_url": "https://api.github.com/users/wlhgtc/orgs", "repos_url": "https://api.github.com/users/wlhgtc/repos", "events_url": "https://api.github.com/users/wlhgtc/events{/privacy}", "received_events_url": "https://api.github.com/users/wlhgtc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-28T03:00:03Z", "updated_at": "2020-06-28T03:27:50Z", "closed_at": "2020-06-28T03:27:50Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I set the `\"num_serialized_models_to_keep\": -1` . \r\nSo I got many serialized model in different epochs(files like `model_state_epoch_1.th`).\r\nI tried to evaluate these models on test set, but I failed.\r\nCould anyone guide me how to do it ? Seem I have to convert them to file like (model.tar.gz)?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4406", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4406/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4406/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4406/events", "html_url": "https://github.com/allenai/allennlp/issues/4406", "id": 646754615, "node_id": "MDU6SXNzdWU2NDY3NTQ2MTU=", "number": 4406, "title": "Home page of docs not rendering properly", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2020-06-27T20:17:56Z", "updated_at": "2020-06-30T14:52:37Z", "closed_at": "2020-06-30T14:52:37Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://docs.allennlp.org/master/", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4405", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4405/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4405/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4405/events", "html_url": "https://github.com/allenai/allennlp/issues/4405", "id": 646368802, "node_id": "MDU6SXNzdWU2NDYzNjg4MDI=", "number": 4405, "title": "Is there any guide that writes a script to use trained model to predict?", "user": {"login": "nine09", "id": 27999909, "node_id": "MDQ6VXNlcjI3OTk5OTA5", "avatar_url": "https://avatars0.githubusercontent.com/u/27999909?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nine09", "html_url": "https://github.com/nine09", "followers_url": "https://api.github.com/users/nine09/followers", "following_url": "https://api.github.com/users/nine09/following{/other_user}", "gists_url": "https://api.github.com/users/nine09/gists{/gist_id}", "starred_url": "https://api.github.com/users/nine09/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nine09/subscriptions", "organizations_url": "https://api.github.com/users/nine09/orgs", "repos_url": "https://api.github.com/users/nine09/repos", "events_url": "https://api.github.com/users/nine09/events{/privacy}", "received_events_url": "https://api.github.com/users/nine09/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-06-26T16:16:08Z", "updated_at": "2020-08-18T18:49:42Z", "closed_at": "2020-08-18T18:49:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>\r\nI am looking forward to write a script to use my trained model do prediction. But I cannot find any tutorial about how to predict by a trained model with a scripts rather than command line.\r\n</b>\r\n\r\nIn fact I saw examples to define a predictor and use it to predict. However, it takes the model and the data_reader as argument, and I define both of them by a json config file.\r\n\r\nAfter use `allennlp.commands.train.train_model_from_file` and a config file, I get the best model. Now I want write a script to use it do prediction. So, does I have to new a data_reader instance by hand rather than by a config file to feed to the predicator?\r\n\r\nIs any tutorial that explain how to solve the mentioned problem?\r\n\r\nThe config json of the training procedure is as follow:\r\n```\r\n{\r\n  \"dataset_reader\": {\r\n    \"type\": \"qamr_pred\",\r\n    \"source_tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": \"bert-base-cased\",\r\n      \"add_special_tokens\": true\r\n    },\r\n    \"source_token_indexer\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer_mismatched\",\r\n        \"model_name\": \"bert-base-cased\"\r\n      }\r\n    }\r\n  },\r\n  \"validation_dataset_reader\": {\r\n    \"type\": \"qamr_pred\",\r\n    \"source_tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": \"bert-base-cased\",\r\n      \"add_special_tokens\": true\r\n    },\r\n    \"source_token_indexer\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer_mismatched\",\r\n        \"model_name\": \"bert-base-cased\"\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"data/pred_data/train.txt\",\r\n  \"validation_data_path\": \"data/pred_data/dev.txt\",\r\n  \"model\": {\r\n    \"type\": \"o\",\r\n    \"embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer_mismatched\",\r\n          \"model_name\": \"bert-base-cased\",\r\n          \"train_parameters\": true\r\n        }\r\n      }\r\n    },\r\n    \"metric_in_training\": {\r\n      \"accuracy\": {\r\n        \"type\": \"categorical_accuracy\"\r\n      },\r\n      \"f1\": {\r\n        \"type\": \"fbeta\",\r\n        \"average\": \"micro\"\r\n      }\r\n    }\r\n  },\r\n  \"data_loader\" : {\r\n    \"sampler\": {\r\n      \"type\": \"random\"\r\n    },\r\n    \"batch_size\": 32,\r\n    \"drop_last\": true\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 6,\r\n    \"cuda_device\": 0,\r\n    \"validation_metric\": \"+f1\",\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"parameter_groups\": [\r\n        [[\"embedder\"], {\"lr\": 2e-5, \"t_total\": 50000, \"warmup\": 0.1}],\r\n        [[\"^((?!embedder).)*$\"], {\"lr\": 1e-3}]\r\n      ],\r\n      \"lr\": 1e-3\r\n    },\r\n    \"checkpointer\": {\r\n      \"num_serialized_models_to_keep\": 2\r\n    }\r\n  }\r\n}\r\n```\r\n</summary>", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4404", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4404/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4404/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4404/events", "html_url": "https://github.com/allenai/allennlp/issues/4404", "id": 646131247, "node_id": "MDU6SXNzdWU2NDYxMzEyNDc=", "number": 4404, "title": "Logging Learning Rate ", "user": {"login": "pasinit", "id": 7542554, "node_id": "MDQ6VXNlcjc1NDI1NTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/7542554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pasinit", "html_url": "https://github.com/pasinit", "followers_url": "https://api.github.com/users/pasinit/followers", "following_url": "https://api.github.com/users/pasinit/following{/other_user}", "gists_url": "https://api.github.com/users/pasinit/gists{/gist_id}", "starred_url": "https://api.github.com/users/pasinit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pasinit/subscriptions", "organizations_url": "https://api.github.com/users/pasinit/orgs", "repos_url": "https://api.github.com/users/pasinit/repos", "events_url": "https://api.github.com/users/pasinit/events{/privacy}", "received_events_url": "https://api.github.com/users/pasinit/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}, {"id": 2276693919, "node_id": "MDU6TGFiZWwyMjc2NjkzOTE5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "aaaaaa", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-06-26T09:22:10Z", "updated_at": "2020-08-18T16:18:31Z", "closed_at": "2020-08-18T16:18:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there an easy way to log the learning rate (especially when using a scheduler) within the training progress bar?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4399", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4399/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4399/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4399/events", "html_url": "https://github.com/allenai/allennlp/issues/4399", "id": 645065685, "node_id": "MDU6SXNzdWU2NDUwNjU2ODU=", "number": 4399, "title": "TypeError: can't pickle Tokenizer objects when num_workers > 0 and lazy = true", "user": {"login": "JohnGiorgi", "id": 8917831, "node_id": "MDQ6VXNlcjg5MTc4MzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/8917831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JohnGiorgi", "html_url": "https://github.com/JohnGiorgi", "followers_url": "https://api.github.com/users/JohnGiorgi/followers", "following_url": "https://api.github.com/users/JohnGiorgi/following{/other_user}", "gists_url": "https://api.github.com/users/JohnGiorgi/gists{/gist_id}", "starred_url": "https://api.github.com/users/JohnGiorgi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JohnGiorgi/subscriptions", "organizations_url": "https://api.github.com/users/JohnGiorgi/orgs", "repos_url": "https://api.github.com/users/JohnGiorgi/repos", "events_url": "https://api.github.com/users/JohnGiorgi/events{/privacy}", "received_events_url": "https://api.github.com/users/JohnGiorgi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-06-25T00:47:30Z", "updated_at": "2020-06-25T19:54:21Z", "closed_at": "2020-06-25T19:54:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discourse forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [X] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [X] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [X] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [X] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [X] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [X] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [X] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [X] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [X] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [X] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nI get a `TypeError: can't pickle Tokenizer objects` when trying to train a model that uses a `PretrainedTransformerTokenizer` tokenizer when `\"dataset_reader.lazy\": true` and `\"data_loader.num_workers\" > 0`. This appears to happen for every version of AllenNLP _after_ 1.0.0rc3 (specifically [this commit](https://github.com/allenai/allennlp/commit/9766eb407e7d83a0bf2150ad054a7c8e2da4ae2b)) including the current master branch. The 1.0.0rc3 release and earlier releases do not have this issue.\r\n\r\nThe notes in #4344 seem to suggest it has been solved, but I can still trigger it with a minimal example (see below).\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/johnmg/t2t/bin/allennlp\", line 33, in <module>\r\n    sys.exit(load_entry_point('allennlp', 'console_scripts', 'allennlp')())\r\n  File \"/scratch/johnmg/allennlp/allennlp/__main__.py\", line 24, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 112, in train_model_from_args\r\n    dry_run=args.dry_run,\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 171, in train_model_from_file\r\n    dry_run=dry_run,\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 295, in train_model\r\n    nprocs=num_procs,\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 200, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 158, in start_processes\r\n    while not context.join():\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 418, in _train_worker\r\n    params=params, serialization_dir=serialization_dir, local_rank=process_rank,\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/scratch/johnmg/allennlp/allennlp/commands/train.py\", line 647, in from_partial_objects\r\n    data_loader_ = data_loader.construct(dataset=datasets[\"train\"])\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/lazy.py\", line 46, in construct\r\n    return self._constructor(**kwargs)\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 446, in constructor\r\n    return value_cls.from_params(params=deepcopy(popped_params), **constructor_extras)\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/scratch/johnmg/allennlp/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/scratch/johnmg/allennlp/allennlp/data/dataloader.py\", line 151, in from_partial_objects\r\n    batches_per_epoch=batches_per_epoch,\r\n  File \"/scratch/johnmg/allennlp/allennlp/data/dataloader.py\", line 90, in __init__\r\n    self._data_generator = super().__iter__()\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 279, in __iter__\r\n    return _MultiProcessingDataLoaderIter(self)\r\n  File \"/home/johnmg/t2t/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 719, in __init__\r\n    w.start()\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/process.py\", line 112, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\r\n    self._launch(process_obj)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/multiprocessing/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nTypeError: can't pickle Tokenizer objects\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- #4344\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: \r\n\r\n```\r\nNAME=\"CentOS Linux\"\r\nVERSION=\"7 (Core)\"\r\nID=\"centos\"\r\nID_LIKE=\"rhel fedora\"\r\nVERSION_ID=\"7\"\r\nPRETTY_NAME=\"CentOS Linux 7 (Core)\"\r\nANSI_COLOR=\"0;31\"\r\nCPE_NAME=\"cpe:/o:centos:centos:7\"\r\nHOME_URL=\"https://www.centos.org/\"\r\nBUG_REPORT_URL=\"https://bugs.centos.org/\"\r\n\r\nCENTOS_MANTISBT_PROJECT=\"CentOS-7\"\r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\r\nREDHAT_SUPPORT_PRODUCT=\"centos\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\r\n```\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.4\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.7.1\r\naiohttp==3.6.2\r\nalabaster==0.7.12\r\n-e git+https://github.com/allenai/allennlp.git@b6fd6978b507ce6118023e23f3e4dbfa334d39b5#egg=allennlp\r\napex==0.1\r\nappdirs==1.4.3\r\naspy.yaml==1.3.0\r\nastor==0.8.1\r\nasync-timeout==3.0.1\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\nBabel==2.7.0\r\nbackcall==0.1.0\r\nbeautifulsoup4==4.8.2\r\nblack==19.10b0\r\nbleach==3.1.0\r\nblis==0.2.4\r\nboto==2.49.0\r\nboto3==1.10.9\r\nbotocore==1.13.9\r\ncachetools==3.1.1\r\ncc-net==0.1.0\r\ncertifi==2019.9.11\r\ncffi==1.13.2\r\ncfgv==2.0.1\r\nchardet==3.0.4\r\nclick==7.1.1\r\ncodecov==2.0.15\r\nconllu==2.3.2\r\ncoverage==4.5.4\r\ncryptography==2.8\r\ncycler==0.10.0\r\ncymem==2.0.2\r\n-e git+https://github.com/JohnGiorgi/t2t.git@5cc03ed58253e12bd1060f1fea2b89bae3acdb84#egg=declutr\r\ndecorator==4.4.1\r\ndill==0.3.1.1\r\ndocutils==0.15.2\r\neditdistance==0.5.2\r\nen-core-web-sm==2.1.0\r\nentrypoints==0.3\r\nfastapi==0.58.0\r\nfasttext==0.9.1\r\nfilelock==3.0.12\r\nfire==0.2.1\r\nflake8==3.7.9\r\nflaky==3.6.1\r\nFlask==1.1.1\r\nFlask-Cors==3.0.8\r\nftfy==5.5.1\r\nfunc-argparse==1.1.1\r\nfuture==0.17.1\r\ngast==0.2.2\r\ngensim==3.8.1\r\ngetpy==0.9.9\r\ngevent==1.4.0\r\ngoogle-auth==1.11.0\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-pasta==0.1.8\r\ngreenlet==0.4.15\r\ngrpcio==1.25.0\r\nh11==0.9.0\r\nh5py==2.9.0\r\nhtmlmin==0.1.12\r\nhttptools==0.1.1\r\nhypothesis==5.16.0\r\nidentify==1.4.10\r\nidna==2.8\r\nimagesize==1.1.0\r\nimportlib-metadata==0.23\r\nipython==7.10.1\r\nipython-genutils==0.2.0\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njedi==0.15.1\r\njeepney==0.4.2\r\nJinja2==2.10.3\r\njmespath==0.9.4\r\njoblib==0.14.0\r\njsmin==2.2.2\r\njsonnet==0.10.0\r\njsonpickle==1.2\r\njsonschema==3.0.2\r\nkenlm==0.0.0\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nkeyring==21.1.0\r\nkiwisolver==1.1.0\r\nlivereload==2.6.1\r\nlxml==4.4.1\r\nMarkdown==3.1.1\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.1.1\r\nmathy-pydoc==0.6.7\r\nmatplotlib==3.0.3\r\nmaturin==0.8.1\r\nmccabe==0.6.1\r\nmkdocs==1.0.4\r\nmkdocs-material==4.6.3\r\nmkdocs-minify-plugin==0.2.1\r\nmore-itertools==7.2.0\r\nmultidict==4.5.2\r\nmurmurhash==0.28.0\r\nmypy==0.770\r\nmypy-extensions==0.4.3\r\nnltk==3.4\r\nnodeenv==1.3.4\r\nnumpy==1.16.3\r\nnumpydoc==0.8.0\r\noauthlib==3.1.0\r\nopt-einsum==2.3.2\r\noverrides==3.1.0\r\npackaging==19.2\r\npandas==0.25.3\r\nparsimonious==0.8.0\r\nparso==0.5.1\r\npathspec==0.7.0\r\npep562==1.0\r\npexpect==4.7.0\r\npickleshare==0.7.5\r\nPillow==6.2.1\r\nPillow-SIMD==7.0.0.post3\r\npkginfo==1.5.0.1\r\nplac==0.9.6\r\npluggy==0.13.0\r\npre-commit==2.2.0\r\npreshed==2.0.1\r\nprompt-toolkit==3.0.2\r\nprotobuf==3.10.0\r\nptyprocess==0.6.0\r\npy==1.8.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npybind11==2.4.3\r\npycodestyle==2.5.0\r\npycparser==2.19\r\npydantic==1.5.1\r\npydoc-markdown==2.0.5\r\npyflakes==2.1.1\r\nPygments==2.4.2\r\npymdown-extensions==6.3\r\npyparsing==2.4.3\r\npyrsistent==0.15.3\r\npytest==5.2.2\r\npytest-cov==2.8.1\r\npython-dateutil==2.8.0\r\n-e git+https://github.com/KevinMusgrave/pytorch-metric-learning.git@48de2dd9c4d78873d675f19187c5205075a6a9de#egg=pytorch_metric_learning\r\npytz==2019.3\r\nPyYAML==5.1.2\r\n-e git+https://github.com/JohnGiorgi/QuickThought.git@397b8b18f3cc50a3471fe26f9725401fb2297816#egg=quickthought\r\nreadme-renderer==24.0\r\nregex==2018.1.10\r\nrequests==2.22.0\r\nrequests-oauthlib==1.3.0\r\nrequests-toolbelt==0.9.1\r\nresponses==0.10.6\r\nrsa==4.0\r\nruamel.yaml==0.16.5\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.2.1\r\nsacremoses==0.0.35\r\nscikit-learn==0.21.2\r\nscipy==1.4.1\r\nSecretStorage==3.1.2\r\nsemantic-version==2.8.4\r\nsentence-splitter==1.4\r\nsentence-transformers==0.2.6.1\r\nsentencepiece==0.1.82\r\nsetuptools-rust==0.10.6\r\nsingledispatch==3.4.0.3\r\nsix==1.12.0\r\nsmart-open==1.8.4\r\nsnowballstemmer==2.0.0\r\nsortedcontainers==2.2.2\r\nsoupsieve==2.0\r\nspacy==2.1.4\r\nSphinx==2.2.1\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsqlparse==0.3.0\r\nsrsly==0.0.5\r\nstarlette==0.13.4\r\ntensorboard==1.15.0\r\ntensorboardX==1.9\r\ntensorflow-estimator==1.15.1\r\ntensorflow-gpu==1.15.0\r\ntensorflow-hub==0.8.0\r\ntermcolor==1.1.0\r\nTheano==1.0.1\r\nthinc==7.0.4\r\ntokenizers==0.7.0\r\ntoml==0.10.0\r\ntorch==1.5.0\r\ntorchvision==0.6.0+cu101\r\ntornado==6.0.3\r\ntqdm==4.37.0\r\ntraitlets==4.3.3\r\ntransformers==2.11.0\r\ntwine==3.1.1\r\ntyped-ast==1.4.1\r\ntyper==0.2.1\r\ntyping-extensions==3.7.4.1\r\nUnidecode==1.1.1\r\nurllib3==1.25.6\r\nuvicorn==0.11.5\r\nuvloop==0.14.0\r\nvirtualenv==16.7.9\r\nwasabi==0.4.0\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nwebsockets==8.1\r\nWerkzeug==0.16.0\r\nword2number==1.1\r\nwrapt==1.11.2\r\nyarl==1.4.2\r\nzipp==0.6.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Install a version of AllenNLP and AllenNLP-Models _newer_ than 1.0.0rc3.\r\n2. Train a model which uses a `PretrainedTransformerTokenizer` with `\"dataset_reader.lazy\": true` and `\"data_loader.num_workers\" > 0`. E.g. I used [this config](https://github.com/allenai/allennlp-models/blob/master/training_config/pair_classification/mnli_roberta.jsonnet) with some overrides (see below).\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n \r\n```bash\r\nallennlp train mnli_roberta.jsonnet \\\r\n\t--serialization-dir ./debug \\\r\n        --overrides \"{'dataset_reader.lazy': true, 'data_loader.batch_sampler': null, 'data_loader.num_workers': 1}\" \\\r\n\t-f\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4393", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4393/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4393/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4393/events", "html_url": "https://github.com/allenai/allennlp/issues/4393", "id": 643187853, "node_id": "MDU6SXNzdWU2NDMxODc4NTM=", "number": 4393, "title": "Unexpected behavior with DataLoader.batches_per_epoch", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-06-22T15:56:43Z", "updated_at": "2020-07-06T15:26:20Z", "closed_at": "2020-06-25T11:54:54Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "From the discussion in https://github.com/allenai/allennlp/issues/4362.\r\n\r\nIf `batches_per_epochs` is less than the total number of batches in the dataset, there is no guarantee that all unique instances will be seen during training.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4388", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4388/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4388/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4388/events", "html_url": "https://github.com/allenai/allennlp/issues/4388", "id": 643059760, "node_id": "MDU6SXNzdWU2NDMwNTk3NjA=", "number": 4388, "title": "SRL predictor misses Auxiliary verb", "user": {"login": "deanyan7", "id": 30431964, "node_id": "MDQ6VXNlcjMwNDMxOTY0", "avatar_url": "https://avatars3.githubusercontent.com/u/30431964?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deanyan7", "html_url": "https://github.com/deanyan7", "followers_url": "https://api.github.com/users/deanyan7/followers", "following_url": "https://api.github.com/users/deanyan7/following{/other_user}", "gists_url": "https://api.github.com/users/deanyan7/gists{/gist_id}", "starred_url": "https://api.github.com/users/deanyan7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deanyan7/subscriptions", "organizations_url": "https://api.github.com/users/deanyan7/orgs", "repos_url": "https://api.github.com/users/deanyan7/repos", "events_url": "https://api.github.com/users/deanyan7/events{/privacy}", "received_events_url": "https://api.github.com/users/deanyan7/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-22T13:11:27Z", "updated_at": "2020-06-29T17:15:57Z", "closed_at": "2020-06-26T16:13:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "System (please complete the following information):\r\n\r\nOS: Linux\r\nPython version: 3.6.9\r\nAllenNLP version: 1.0.0\r\nPyTorch version: 1.5.0\r\n\r\nWhen I used the SRL model to predict sentences, \r\nThe inputs is \u201cThe new rights are nice enough.\u201d\r\n\r\nThe result is:\r\n[{'verbs': [], 'words': ['The', 'new', 'rights', 'are', 'nice', 'enough']}]\r\n\r\nThe Correct  result is\uff1a\r\n[{\"verbs\": [{\"verb\": \"are\", \"description\": \"[ARG1: The new rights] [V: are] [ARG2: nice enough]\", \"tags\": [\"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"B-V\", \"B-ARG2\", \"I-ARG2\"]}]\r\n\r\n\r\nHow can I fix it?  Thank you!\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4384", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4384/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4384/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4384/events", "html_url": "https://github.com/allenai/allennlp/issues/4384", "id": 642079473, "node_id": "MDU6SXNzdWU2NDIwNzk0NzM=", "number": 4384, "title": "allennlp.commands.elmo doesn't exists anymore", "user": {"login": "Dastgheyb", "id": 5506911, "node_id": "MDQ6VXNlcjU1MDY5MTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5506911?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dastgheyb", "html_url": "https://github.com/Dastgheyb", "followers_url": "https://api.github.com/users/Dastgheyb/followers", "following_url": "https://api.github.com/users/Dastgheyb/following{/other_user}", "gists_url": "https://api.github.com/users/Dastgheyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dastgheyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dastgheyb/subscriptions", "organizations_url": "https://api.github.com/users/Dastgheyb/orgs", "repos_url": "https://api.github.com/users/Dastgheyb/repos", "events_url": "https://api.github.com/users/Dastgheyb/events{/privacy}", "received_events_url": "https://api.github.com/users/Dastgheyb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-19T16:08:10Z", "updated_at": "2020-06-22T20:33:04Z", "closed_at": "2020-06-19T16:35:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi :)\r\nlast weak my code works on the colab. but now after I install allennlp I get an error on the following line.\r\n`from allennlp.commands.elmo import ElmoEmbedder`\r\nand the error is : ModuleNotFoundError: No module named 'allennlp.commands.elmo'\r\nI searched this repository for ElmoEmbedder but none found.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4382", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4382/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4382/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4382/events", "html_url": "https://github.com/allenai/allennlp/issues/4382", "id": 641741407, "node_id": "MDU6SXNzdWU2NDE3NDE0MDc=", "number": 4382, "title": "Add tutorial on using Optuna with AllenNLP", "user": {"login": "Crissman", "id": 4338467, "node_id": "MDQ6VXNlcjQzMzg0Njc=", "avatar_url": "https://avatars0.githubusercontent.com/u/4338467?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Crissman", "html_url": "https://github.com/Crissman", "followers_url": "https://api.github.com/users/Crissman/followers", "following_url": "https://api.github.com/users/Crissman/following{/other_user}", "gists_url": "https://api.github.com/users/Crissman/gists{/gist_id}", "starred_url": "https://api.github.com/users/Crissman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Crissman/subscriptions", "organizations_url": "https://api.github.com/users/Crissman/orgs", "repos_url": "https://api.github.com/users/Crissman/repos", "events_url": "https://api.github.com/users/Crissman/events{/privacy}", "received_events_url": "https://api.github.com/users/Crissman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "e827b7", "default": false, "description": ""}, {"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, {"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2020-06-19T06:35:16Z", "updated_at": "2020-08-18T20:40:25Z", "closed_at": "2020-08-18T20:40:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\nOptuna is a new hyperparameter optimization library, and we\u2019ve written an integration module for AllenNLP to make it easy to use Optuna to search for good hyperparameter settings and prune unpromising trials. We\u2019re looking for ways to let AllenNLP users know this is available and thought a badge to show Optuna integration is available would be helpful.\r\n\r\n**Describe the solution you'd like**\r\nWould an PR for a Guide on the AllenNLP repo on how to use Optuna with AllenNLP be helpful?\r\n\r\n**Describe alternatives you've considered**\r\nWe've already published a [blog post on using Optuna with AllenNLP](https://medium.com/optuna/hyperparameter-optimization-for-allennlp-using-optuna-54b4bfecd78b).\r\n\r\n**Additional context**\r\nIf there are other ways you would recommend reaching out to AllenNLP users to let them know about Optuna, please let us know.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4378", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4378/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4378/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4378/events", "html_url": "https://github.com/allenai/allennlp/issues/4378", "id": 641522424, "node_id": "MDU6SXNzdWU2NDE1MjI0MjQ=", "number": 4378, "title": "PDB++ arrow/tab keys don't work with allennlp", "user": {"login": "successar", "id": 1499824, "node_id": "MDQ6VXNlcjE0OTk4MjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1499824?v=4", "gravatar_id": "", "url": "https://api.github.com/users/successar", "html_url": "https://github.com/successar", "followers_url": "https://api.github.com/users/successar/followers", "following_url": "https://api.github.com/users/successar/following{/other_user}", "gists_url": "https://api.github.com/users/successar/gists{/gist_id}", "starred_url": "https://api.github.com/users/successar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/successar/subscriptions", "organizations_url": "https://api.github.com/users/successar/orgs", "repos_url": "https://api.github.com/users/successar/repos", "events_url": "https://api.github.com/users/successar/events{/privacy}", "received_events_url": "https://api.github.com/users/successar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-06-18T20:16:13Z", "updated_at": "2020-07-01T15:15:24Z", "closed_at": "2020-07-01T15:15:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [ ] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nI can't use pdb/pdb++ arrow keys or tab key for autocompletion when running `allennlp train` . Possibly related to this issue https://stackoverflow.com/a/56418204\r\n\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- Reopening this issue - https://github.com/allenai/allennlp/issues/2176\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.7\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nallennlp==1.0.0\r\nappdirs==1.4.3\r\nastroid==2.4.1\r\nattrs==19.3.0\r\nblack==19.10b0\r\nblis==0.4.1\r\nboto3==1.14.4\r\nbotocore==1.17.4\r\ncatalogue==1.0.0\r\ncertifi==2020.4.5.2\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncymem==2.0.3\r\ndocutils==0.15.2\r\nfancycompleter==0.9.1\r\nfilelock==3.0.12\r\nfuture==0.18.2\r\ngnureadline==8.0.0\r\nh5py==2.10.0\r\nidna==2.9\r\nimportlib-metadata==1.6.1\r\nisort==4.3.21\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nlazy-object-proxy==1.4.3\r\nmccabe==0.6.1\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nmypy-extensions==0.4.3\r\nnltk==3.5\r\nnumpy==1.18.5\r\noverrides==3.0.0\r\npackaging==20.4\r\npathspec==0.7.0\r\npdbpp==0.10.2\r\nplac==1.1.3\r\npluggy==0.13.1\r\npreshed==3.0.2\r\nprotobuf==3.12.2\r\npy==1.8.2\r\nPygments==2.6.1\r\npylint==2.5.2\r\npyparsing==2.4.7\r\npyrepl==0.9.0\r\npytest==5.4.3\r\npython-dateutil==2.8.1\r\nregex==2020.6.8\r\nrequests==2.23.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.4.1\r\nsentencepiece==0.1.91\r\nsix==1.15.0\r\nspacy==2.2.4\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nthinc==7.4.0\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.7.0\r\ntoml==0.10.0\r\ntorch==1.5.0\r\ntqdm==4.46.1\r\ntransformers==2.11.0\r\ntyped-ast==1.4.1\r\ntyping-extensions==3.7.4.1\r\nurllib3==1.25.9\r\nwasabi==0.6.0\r\nwcwidth==0.2.4\r\nwmctrl==0.3\r\nwrapt==1.11.2\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n1. Install allennlp in clean environment\r\n2. Run a short script and try arrow keys\r\n\r\n```python\r\nv = 10\r\nbreakpoint()\r\n```\r\n\r\nArrow keys should work\r\n\r\n3. Next run a `allennlp train` script and again put breakpoint somewhere. Check arrow keys.\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4376", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4376/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4376/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4376/events", "html_url": "https://github.com/allenai/allennlp/issues/4376", "id": 641482527, "node_id": "MDU6SXNzdWU2NDE0ODI1Mjc=", "number": 4376, "title": "AllenNLP install failing on jsonnet", "user": {"login": "butoialexandra", "id": 24324620, "node_id": "MDQ6VXNlcjI0MzI0NjIw", "avatar_url": "https://avatars3.githubusercontent.com/u/24324620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/butoialexandra", "html_url": "https://github.com/butoialexandra", "followers_url": "https://api.github.com/users/butoialexandra/followers", "following_url": "https://api.github.com/users/butoialexandra/following{/other_user}", "gists_url": "https://api.github.com/users/butoialexandra/gists{/gist_id}", "starred_url": "https://api.github.com/users/butoialexandra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/butoialexandra/subscriptions", "organizations_url": "https://api.github.com/users/butoialexandra/orgs", "repos_url": "https://api.github.com/users/butoialexandra/repos", "events_url": "https://api.github.com/users/butoialexandra/events{/privacy}", "received_events_url": "https://api.github.com/users/butoialexandra/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-06-18T19:04:27Z", "updated_at": "2020-06-26T16:03:06Z", "closed_at": "2020-06-26T16:03:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [ ] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [ ] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nRunning setup.py install for jsonnet ... error\r\n    ERROR: Command errored out with exit status 1:\r\n     command: /Library/Frameworks/Python.framework/Versions/3.6/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-record-k7ysxmf7/install-record.txt --single-version-externally-managed --compile --install-headers /Library/Frameworks/Python.framework/Versions/3.6/include/python3.6m/jsonnet\r\n         cwd: /private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/\r\n    Complete output (102 lines):\r\n    running install\r\n    running build\r\n    running build_ext\r\n    make: `core/desugarer.o' is up to date.\r\n    make: `core/formatter.o' is up to date.\r\n    make: `core/libjsonnet.o' is up to date.\r\n    make: `core/lexer.o' is up to date.\r\n    c++ -c -g -O3 -Wall -Wextra -Woverloaded-virtual -pedantic -std=c++0x -fPIC -Iinclude -Ithird_party/md5 -Ithird_party/json core/parser.cpp -o core/parser.o\r\n    In file included from core/parser.cpp:18:\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:317:9: error: no member named 'signbit' in the global namespace\r\n    using ::signbit;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:318:9: error: no member named 'fpclassify' in the global namespace\r\n    using ::fpclassify;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:319:9: error: no member named 'isfinite' in the global namespace; did you mean 'finite'?\r\n    using ::isfinite;\r\n          ~~^\r\n    /usr/local/include/math.h:749:12: note: 'finite' declared here\r\n    extern int finite(double)\r\n               ^\r\n    In file included from core/parser.cpp:18:\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:320:9: error: no member named 'isinf' in the global namespace\r\n    using ::isinf;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:321:9: error: no member named 'isnan' in the global namespace\r\n    using ::isnan;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:322:9: error: no member named 'isnormal' in the global namespace\r\n    using ::isnormal;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:323:9: error: no member named 'isgreater' in the global namespace\r\n    using ::isgreater;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:324:9: error: no member named 'isgreaterequal' in the global namespace\r\n    using ::isgreaterequal;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:325:9: error: no member named 'isless' in the global namespace\r\n    using ::isless;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:326:9: error: no member named 'islessequal' in the global namespace\r\n    using ::islessequal;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:327:9: error: no member named 'islessgreater' in the global namespace\r\n    using ::islessgreater;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:328:9: error: no member named 'isunordered' in the global namespace\r\n    using ::isunordered;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:329:9: error: no member named 'isunordered' in the global namespace\r\n    using ::isunordered;\r\n          ~~^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:640:26: error: no template named 'numeric_limits'\r\n        bool _FloatBigger = (numeric_limits<_FloatT>::digits > numeric_limits<_IntT>::digits),\r\n                             ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:640:60: error: no template named 'numeric_limits'\r\n        bool _FloatBigger = (numeric_limits<_FloatT>::digits > numeric_limits<_IntT>::digits),\r\n                                                               ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:641:18: error: no template named 'numeric_limits'\r\n        int _Bits = (numeric_limits<_IntT>::digits - numeric_limits<_FloatT>::digits)>\r\n                     ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:641:50: error: no template named 'numeric_limits'\r\n        int _Bits = (numeric_limits<_IntT>::digits - numeric_limits<_FloatT>::digits)>\r\n                                                     ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:646:17: error: no template named 'numeric_limits'\r\n      static_assert(numeric_limits<_FloatT>::radix == 2, \"FloatT has incorrect radix\");\r\n                    ^\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/cmath:649:25: error: no template named 'numeric_limits'\r\n      return _FloatBigger ? numeric_limits<_IntT>::max() :  (numeric_limits<_IntT>::max() >> _Bits << _Bits);\r\n                            ^\r\n    fatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n    20 errors generated.\r\n    make: *** [core/parser.o] Error 1\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py\", line 75, in <module>\r\n        test_suite=\"python._jsonnet_test\",\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/setuptools/__init__.py\", line 161, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py\", line 955, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/setuptools/command/install.py\", line 61, in run\r\n        return orig.install.run(self)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/command/install.py\", line 545, in run\r\n        self.run_command('build')\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/command/build.py\", line 135, in run\r\n        self.run_command(cmd_name)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py\", line 974, in run_command\r\n        cmd_obj.run()\r\n      File \"/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py\", line 54, in run\r\n        raise Exception('Could not build %s' % (', '.join(LIB_OBJECTS)))\r\n    Exception: Could not build core/desugarer.o, core/formatter.o, core/libjsonnet.o, core/lexer.o, core/parser.o, core/pass.o, core/static_analysis.o, core/string_utils.o, core/vm.o, third_party/md5/md5.o\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.6/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-install-anu0d9_5/jsonnet/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/dj/27jw3fzj6kgfm7v2h7y9vq7w0000gn/T/pip-record-k7ysxmf7/install-record.txt --single-version-externally-managed --compile --install-headers /Library/Frameworks/Python.framework/Versions/3.6/include/python3.6m/jsonnet Check the logs for full command output.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nI tried the proposed solutions in [#1938](https://github.com/allenai/allennlp/issues/1938), [#1969](https://github.com/allenai/allennlp/issues/1969), [#2779](https://github.com/allenai/allennlp/issues/2779) as well as [this](https://stackoverflow.com/questions/52509602/cant-compile-c-program-on-a-mac-after-upgrade-to-mojave) and [this](https://stackoverflow.com/questions/58278260/cant-compile-a-c-program-on-a-mac-after-upgrading-to-catalina-10-15/58278392#58278392). Also I tried installing with pip, conda and from source and they all fail on jsonnet. I could install jsonnet successfully using Homebrew but allennlp still fails to install. \r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: macOS Catalina 10.15.5\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: Python 3.6.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4374", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4374/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4374/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4374/events", "html_url": "https://github.com/allenai/allennlp/issues/4374", "id": 641112440, "node_id": "MDU6SXNzdWU2NDExMTI0NDA=", "number": 4374, "title": "how to set vocabulary (from another model) from a config file allennlp", "user": {"login": "semerekiros", "id": 26526408, "node_id": "MDQ6VXNlcjI2NTI2NDA4", "avatar_url": "https://avatars3.githubusercontent.com/u/26526408?v=4", "gravatar_id": "", "url": "https://api.github.com/users/semerekiros", "html_url": "https://github.com/semerekiros", "followers_url": "https://api.github.com/users/semerekiros/followers", "following_url": "https://api.github.com/users/semerekiros/following{/other_user}", "gists_url": "https://api.github.com/users/semerekiros/gists{/gist_id}", "starred_url": "https://api.github.com/users/semerekiros/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/semerekiros/subscriptions", "organizations_url": "https://api.github.com/users/semerekiros/orgs", "repos_url": "https://api.github.com/users/semerekiros/repos", "events_url": "https://api.github.com/users/semerekiros/events{/privacy}", "received_events_url": "https://api.github.com/users/semerekiros/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-18T10:57:33Z", "updated_at": "2020-06-18T22:04:48Z", "closed_at": "2020-06-18T22:04:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi I am new to allennlp. Instead of building my Vocabulary from instances which is the default implementation, I would like to build it from an external file that contains a list of words. What do I need to change in the config file?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4373", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4373/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4373/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4373/events", "html_url": "https://github.com/allenai/allennlp/issues/4373", "id": 640899713, "node_id": "MDU6SXNzdWU2NDA4OTk3MTM=", "number": 4373, "title": "Predict is not working for pre-trained fine grained NER model", "user": {"login": "MISabic", "id": 20471525, "node_id": "MDQ6VXNlcjIwNDcxNTI1", "avatar_url": "https://avatars2.githubusercontent.com/u/20471525?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MISabic", "html_url": "https://github.com/MISabic", "followers_url": "https://api.github.com/users/MISabic/followers", "following_url": "https://api.github.com/users/MISabic/following{/other_user}", "gists_url": "https://api.github.com/users/MISabic/gists{/gist_id}", "starred_url": "https://api.github.com/users/MISabic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MISabic/subscriptions", "organizations_url": "https://api.github.com/users/MISabic/orgs", "repos_url": "https://api.github.com/users/MISabic/repos", "events_url": "https://api.github.com/users/MISabic/events{/privacy}", "received_events_url": "https://api.github.com/users/MISabic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-06-18T04:36:36Z", "updated_at": "2020-07-02T08:51:04Z", "closed_at": "2020-07-02T08:51:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nHi. I tried to load the pre-trained model of fine-grained NER model but Predictor.from_path is not working.\r\n\r\nHere's my code \r\n\r\n`!pip3 install allennlp`\r\n`!pip3 install allennlp-models`\r\n`from allennlp.predictors import Predictor`\r\n`al = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")`\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nConfigurationError                        Traceback (most recent call last)\r\n<ipython-input-16-7116a695b09f> in <module>()\r\n      2 get_ipython().system('pip install --pre allennlp-models')\r\n      3 from allennlp.predictors import Predictor\r\n----> 4 al = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")\r\n      5 al.predict(sentence=document)\r\n\r\n9 frames\r\n/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py in from_path(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen, import_plugins)\r\n    273             plugins.import_plugins()\r\n    274         return Predictor.from_archive(\r\n--> 275             load_archive(archive_path, cuda_device=cuda_device),\r\n    276             predictor_name,\r\n    277             dataset_reader_to_load=dataset_reader_to_load,\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/archival.py in load_archive(archive_file, cuda_device, opt_level, overrides, weights_file)\r\n    195         serialization_dir=serialization_dir,\r\n    196         cuda_device=cuda_device,\r\n--> 197         opt_level=opt_level,\r\n    198     )\r\n    199 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py in load(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    396             # get_model_class method, that recurses whenever it finds a from_archive model type.\r\n    397             model_class = Model\r\n--> 398         return model_class._load(config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    399 \r\n    400     def extend_embedder_vocab(self, embedding_sources_mapping: Dict[str, str] = None) -> None:\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/models/model.py in _load(cls, config, serialization_dir, weights_file, cuda_device, opt_level)\r\n    293         # want the code to look for it, so we remove it from the parameters here.\r\n    294         remove_pretrained_embedding_params(model_params)\r\n--> 295         model = Model.from_params(vocab=vocab, params=model_params)\r\n    296 \r\n    297         # Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    578                     constructor_to_call=constructor_to_call,\r\n    579                     constructor_to_inspect=constructor_to_inspect,\r\n--> 580                     **extras,\r\n    581                 )\r\n    582             else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    607             else:\r\n    608                 # This class has a constructor, so create kwargs for it.\r\n--> 609                 kwargs = create_kwargs(constructor_to_inspect, cls, params, **extras)\r\n    610 \r\n    611             return constructor_to_call(**kwargs)  # type: ignore\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in create_kwargs(constructor, cls, params, **extras)\r\n    179 \r\n    180         constructed_arg = pop_and_construct_arg(\r\n--> 181             cls.__name__, param_name, annotation, param.default, params, **extras\r\n    182         )\r\n    183 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in pop_and_construct_arg(class_name, argument_name, annotation, default, params, **extras)\r\n    285         return None\r\n    286 \r\n--> 287     return construct_arg(class_name, name, popped_params, annotation, default, **extras)\r\n    288 \r\n    289 \r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in construct_arg(class_name, argument_name, popped_params, annotation, default, **extras)\r\n    319             elif isinstance(popped_params, dict):\r\n    320                 popped_params = Params(popped_params)\r\n--> 321             return annotation.from_params(params=popped_params, **subextras)\r\n    322         elif not optional:\r\n    323             # Not optional and not supplied, that's an error!\r\n\r\n/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\r\n    531         if not isinstance(params, Params):\r\n    532             raise ConfigurationError(\r\n--> 533                 \"from_params was passed a `params` object that was not a `Params`. This probably \"\r\n    534                 \"indicates malformed parameters in a configuration file, where something that \"\r\n    535                 \"should have been a dictionary was actually a list, or something else. \"\r\n\r\nConfigurationError: from_params was passed a `params` object that was not a `Params`. This probably indicates malformed parameters in a configuration file, where something that should have been a dictionary was actually a list, or something else. This happened when constructing an object of type <class 'allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator'>.\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.7.6\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nalabaster==0.7.12\r\nanaconda-client==1.7.2\r\nanaconda-navigator==1.9.12\r\nanaconda-project==0.8.3\r\nargh==0.26.2\r\nasn1crypto==1.3.0\r\nastroid==2.3.3\r\nastropy==4.0\r\natomicwrites==1.3.0\r\nattrs==19.3.0\r\nautopep8==1.4.4\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nbackports.functools-lru-cache==1.6.1\r\nbackports.shutil-get-terminal-size==1.0.0\r\nbackports.tempfile==1.0\r\nbackports.weakref==1.0.post1\r\nbcrypt==3.1.7\r\nbeautifulsoup4==4.8.2\r\nbitarray==1.2.1\r\nbkcharts==0.2\r\nbleach==3.1.0\r\nblis==0.4.1\r\nbokeh==1.4.0\r\nboto==2.49.0\r\nBottleneck==1.3.2\r\ncatalogue==1.0.0\r\ncertifi==2019.11.28\r\ncffi==1.14.0\r\nchardet==3.0.4\r\nClick==7.0\r\ncloudpickle==1.3.0\r\nclyent==1.2.2\r\ncolorama==0.4.3\r\ncomtypes==1.1.7\r\nconda==4.8.3\r\nconda-build==3.18.11\r\nconda-package-handling==1.6.0\r\nconda-verify==3.4.2\r\ncontextlib2==0.6.0.post1\r\ncryptography==2.8\r\ncycler==0.10.0\r\ncymem==2.0.3\r\nCython==0.29.15\r\ncytoolz==0.10.1\r\ndask==2.11.0\r\ndecorator==4.4.1\r\ndefusedxml==0.6.0\r\ndiff-match-patch==20181111\r\ndistributed==2.11.0\r\ndocutils==0.16\r\nen-core-web-lg==2.3.0\r\nen-core-web-md==2.3.0\r\nen-core-web-sm==2.3.0\r\nentrypoints==0.3\r\net-xmlfile==1.0.1\r\nfastcache==1.1.0\r\nfilelock==3.0.12\r\nflake8==3.7.9\r\nFlask==1.1.1\r\nfsspec==0.6.2\r\nfuture==0.18.2\r\ngevent==1.4.0\r\nglob2==0.7\r\ngreenlet==0.4.15\r\nh5py==2.10.0\r\nHeapDict==1.0.1\r\nhtml5lib==1.0.1\r\nhypothesis==5.5.4\r\nidna==2.8\r\nimageio==2.6.1\r\nimagesize==1.2.0\r\nimportlib-metadata==1.6.1\r\nintervaltree==3.0.2\r\nipykernel==5.1.4\r\nipython==7.12.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.5.1\r\nisort==4.3.21\r\nitsdangerous==1.1.0\r\njdcal==1.4.1\r\njedi==0.14.1\r\nJinja2==2.11.1\r\njoblib==0.14.1\r\njson5==0.9.1\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==5.3.4\r\njupyter-console==6.1.0\r\njupyter-core==4.6.1\r\njupyterlab==1.2.6\r\njupyterlab-server==1.0.6\r\nkeyring==21.1.0\r\nkiwisolver==1.1.0\r\nlazy-object-proxy==1.4.3\r\nlibarchive-c==2.8\r\nllvmlite==0.31.0\r\nlocket==0.2.0\r\nlxml==4.5.0\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.1.3\r\nmccabe==0.6.1\r\nmenuinst==1.4.16\r\nmistune==0.8.4\r\nmkl-fft==1.0.15\r\nmkl-random==1.1.0\r\nmkl-service==2.3.0\r\nmock==4.0.1\r\nmore-itertools==8.2.0\r\nmpmath==1.1.0\r\nmsgpack==0.6.1\r\nmultipledispatch==0.6.0\r\nmurmurhash==1.0.0\r\nnavigator-updater==0.2.1\r\nnbconvert==5.6.1\r\nnbformat==5.0.4\r\nnetworkx==2.4\r\nnltk==3.4.5\r\nnose==1.3.7\r\nnotebook==6.0.3\r\nnumba==0.48.0\r\nnumexpr==2.7.1\r\nnumpy==1.18.1\r\nnumpydoc==0.9.2\r\nolefile==0.46\r\nopenpyxl==3.0.3\r\npackaging==20.1\r\npandas==1.0.1\r\npandocfilters==1.4.2\r\nparamiko==2.7.1\r\nparso==0.5.2\r\npartd==1.1.0\r\npath==13.1.0\r\npathlib2==2.3.5\r\npathtools==0.1.2\r\npatsy==0.5.1\r\npep8==1.7.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==7.0.0\r\npkginfo==1.5.0.1\r\nplac==0.9.6\r\npluggy==0.13.1\r\nply==3.11\r\npreshed==3.0.2\r\nprometheus-client==0.7.1\r\nprompt-toolkit==3.0.3\r\npsutil==5.6.7\r\npy==1.8.1\r\npycodestyle==2.5.0\r\npycosat==0.6.3\r\npycparser==2.19\r\npycrypto==2.6.1\r\npycurl==7.43.0.5\r\npydocstyle==4.0.1\r\npyflakes==2.1.1\r\nPygments==2.5.2\r\npylint==2.4.4\r\nPyNaCl==1.3.0\r\npyodbc===4.0.0-unsupported\r\npyOpenSSL==19.1.0\r\npyparsing==2.4.6\r\npyreadline==2.1\r\npyrsistent==0.15.7\r\nPySocks==1.7.1\r\npytest==5.3.5\r\npytest-arraydiff==0.3\r\npytest-astropy==0.8.0\r\npytest-astropy-header==0.1.2\r\npytest-doctestplus==0.5.0\r\npytest-openfiles==0.4.0\r\npytest-remotedata==0.3.2\r\npython-dateutil==2.8.1\r\npython-jsonrpc-server==0.3.4\r\npython-language-server==0.31.7\r\npytz==2019.3\r\nPyWavelets==1.1.1\r\npywin32==227\r\npywin32-ctypes==0.2.0\r\npywinpty==0.5.7\r\nPyYAML==5.3\r\npyzmq==18.1.1\r\nQDarkStyle==2.8\r\nQtAwesome==0.6.1\r\nqtconsole==4.6.0\r\nQtPy==1.9.0\r\nrequests==2.22.0\r\nrope==0.16.0\r\nRtree==0.9.3\r\nruamel-yaml==0.15.87\r\nscikit-image==0.16.2\r\nscikit-learn==0.22.1\r\nscipy==1.4.1\r\nseaborn==0.10.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nsimplegeneric==0.8.1\r\nsingledispatch==3.4.0.3\r\nsix==1.14.0\r\nsnowballstemmer==2.0.0\r\nsortedcollections==1.1.2\r\nsortedcontainers==2.1.0\r\nsoupsieve==1.9.5\r\nspacy==2.3.0\r\nSphinx==2.4.0\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsphinxcontrib-websupport==1.2.0\r\nspyder==4.0.1\r\nspyder-kernels==1.8.1\r\nSQLAlchemy==1.3.13\r\nsrsly==1.0.2\r\nstatsmodels==0.11.0\r\nsympy==1.5.1\r\ntables==3.6.1\r\ntblib==1.6.0\r\nterminado==0.8.3\r\ntestpath==0.4.4\r\nthinc==7.4.1\r\ntoolz==0.10.0\r\ntorch==1.5.0\r\ntorchtext==0.6.0\r\ntorchvision==0.6.0\r\ntornado==6.0.3\r\ntqdm==4.42.1\r\ntraitlets==4.3.3\r\nujson==1.35\r\nunicodecsv==0.14.1\r\nurllib3==1.25.8\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwcwidth==0.1.8\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.0\r\nwidgetsnbextension==3.5.1\r\nwin-inet-pton==1.1.0\r\nwin-unicode-console==0.5\r\nwincertstore==0.2\r\nwrapt==1.11.2\r\nxlrd==1.2.0\r\nXlsxWriter==1.2.7\r\nxlwings==0.17.1\r\nxlwt==1.3.0\r\nxmltodict==0.12.0\r\nyapf==0.28.0\r\nzict==1.0.0\r\nzipp==2.2.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4369", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4369/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4369/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4369/events", "html_url": "https://github.com/allenai/allennlp/issues/4369", "id": 640411021, "node_id": "MDU6SXNzdWU2NDA0MTEwMjE=", "number": 4369, "title": "change pretrained model in coref model", "user": {"login": "Sneriko", "id": 36701982, "node_id": "MDQ6VXNlcjM2NzAxOTgy", "avatar_url": "https://avatars2.githubusercontent.com/u/36701982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sneriko", "html_url": "https://github.com/Sneriko", "followers_url": "https://api.github.com/users/Sneriko/followers", "following_url": "https://api.github.com/users/Sneriko/following{/other_user}", "gists_url": "https://api.github.com/users/Sneriko/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sneriko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sneriko/subscriptions", "organizations_url": "https://api.github.com/users/Sneriko/orgs", "repos_url": "https://api.github.com/users/Sneriko/repos", "events_url": "https://api.github.com/users/Sneriko/events{/privacy}", "received_events_url": "https://api.github.com/users/Sneriko/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, {"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-06-17T12:41:49Z", "updated_at": "2020-08-18T18:50:44Z", "closed_at": "2020-08-18T18:50:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi!\r\nI'm trying to build a Swedish coref model using distantly supervised machine learning. The idea is to run AllenNLP:s English coref model on a bilingual dataset (Europarl) and then use a word aligner to transfer the English coreference annotations to swedish annotations and then train the AllenNLP coref model on the Swedish Dataset, using a tiny Swedish coref dataset (17000 tokens, unfortunately the biggest available) as an evaluation set. The transfer is working ok, but just to test the idea I trained the coref model on a very small part of the created Swedish dataset (about 11000 tokens), using a Swedish BERT model as embedding (rather than spanBERT which is used by the allennlp model). I used the same set for evaluation and training (I know this is horrible, but I just wanted to see what happened), and therefore I expected the f1 score to be pretty high, even though the dataset was so small. But I got some strange results. The loss went down, but the f1-score went down as well, all the way to zero, even though the training and evaluation set were the same. Of course, this was just a silly test, and the aim is to create a dataset of about a million tokens, and use the 17000 tokens hand-annotated dataset as an evaluation set, but I was just wondering if there is any logical explanation to these initial results. Is there something I don't understand about the relationship between loss and f1-score?\r\nMy second question is whether you actually can just switch the pretrained layer from spanbert to swedish-bert-base and expect the model to be working anyways, although not as accurately?  ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4367", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4367/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4367/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4367/events", "html_url": "https://github.com/allenai/allennlp/issues/4367", "id": 640384155, "node_id": "MDU6SXNzdWU2NDAzODQxNTU=", "number": 4367, "title": "Make allennlp work with allentune once again", "user": {"login": "apohllo", "id": 40543, "node_id": "MDQ6VXNlcjQwNTQz", "avatar_url": "https://avatars3.githubusercontent.com/u/40543?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apohllo", "html_url": "https://github.com/apohllo", "followers_url": "https://api.github.com/users/apohllo/followers", "following_url": "https://api.github.com/users/apohllo/following{/other_user}", "gists_url": "https://api.github.com/users/apohllo/gists{/gist_id}", "starred_url": "https://api.github.com/users/apohllo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apohllo/subscriptions", "organizations_url": "https://api.github.com/users/apohllo/orgs", "repos_url": "https://api.github.com/users/apohllo/repos", "events_url": "https://api.github.com/users/apohllo/events{/privacy}", "received_events_url": "https://api.github.com/users/apohllo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "kernelmachine", "id": 1164135, "node_id": "MDQ6VXNlcjExNjQxMzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/1164135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kernelmachine", "html_url": "https://github.com/kernelmachine", "followers_url": "https://api.github.com/users/kernelmachine/followers", "following_url": "https://api.github.com/users/kernelmachine/following{/other_user}", "gists_url": "https://api.github.com/users/kernelmachine/gists{/gist_id}", "starred_url": "https://api.github.com/users/kernelmachine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kernelmachine/subscriptions", "organizations_url": "https://api.github.com/users/kernelmachine/orgs", "repos_url": "https://api.github.com/users/kernelmachine/repos", "events_url": "https://api.github.com/users/kernelmachine/events{/privacy}", "received_events_url": "https://api.github.com/users/kernelmachine/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "kernelmachine", "id": 1164135, "node_id": "MDQ6VXNlcjExNjQxMzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/1164135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kernelmachine", "html_url": "https://github.com/kernelmachine", "followers_url": "https://api.github.com/users/kernelmachine/followers", "following_url": "https://api.github.com/users/kernelmachine/following{/other_user}", "gists_url": "https://api.github.com/users/kernelmachine/gists{/gist_id}", "starred_url": "https://api.github.com/users/kernelmachine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kernelmachine/subscriptions", "organizations_url": "https://api.github.com/users/kernelmachine/orgs", "repos_url": "https://api.github.com/users/kernelmachine/repos", "events_url": "https://api.github.com/users/kernelmachine/events{/privacy}", "received_events_url": "https://api.github.com/users/kernelmachine/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2020-06-17T11:58:00Z", "updated_at": "2020-07-29T10:49:34Z", "closed_at": "2020-07-27T23:46:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section below all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\nRunning allentune with the latest allennlp master causes the following error:\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\nTraceback (most recent call last):\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 918, in save_global\r\n    obj2, parent = _getattribute(module, name)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 266, in _getattribute\r\n    .format(name, obj))\r\nAttributeError: Can't get local attribute 'wrap_function.<locals>.WrappedFunc' on <function wrap_function at 0x2b6ace9a7d90>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 639, in save_global\r\n    return Pickler.save_global(self, obj, name=name)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 922, in save_global\r\n    (obj, module_name, name))\r\n_pickle.PicklingError: Can't pickle <class 'ray.tune.trainable.wrap_function.<locals>.WrappedFunc'>: it's not found as ray.tune.trainable.wrap_function.<locals>.WrappedFunc\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/net/people/plgapohl/python-albert-pytorch/bin/allentune\", line 11, in <module>\r\n    load_entry_point('allentune', 'console_scripts', 'allentune')()\r\n  File \"/net/people/plgapohl/allentune/allentune/commands/__init__.py\", line 67, in main\r\n    args.func(args)\r\n  File \"/net/people/plgapohl/allentune/allentune/commands/search.py\", line 126, in search_from_args\r\n    executor.run(args)\r\n  File \"/net/people/plgapohl/allentune/allentune/modules/ray_executor.py\", line 94, in run\r\n    self.run_distributed(run_func, args)\r\n  File \"/net/people/plgapohl/allentune/allentune/modules/ray_executor.py\", line 58, in run_distributed\r\n    register_trainable(\"run\", run_func)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/tune/registry.py\", line 49, in register_trainable\r\n    _global_registry.register(TRAINABLE_CLASS, name, trainable)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/tune/registry.py\", line 88, in register\r\n    self._to_flush[(category, key)] = pickle.dumps(value)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 881, in dumps\r\n    cp.dump(obj)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 268, in dump\r\n    return Pickler.dump(self, obj)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 409, in dump\r\n    self.save(obj)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 648, in save_global\r\n    return self.save_dynamic_class(obj)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 495, in save_dynamic_class\r\n    save(clsdict)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n   save(v)                                                                                                                                                                                        [26/1833]\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 410, in save_function\r\n    self.save_function_tuple(obj)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 553, in save_function_tuple\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 781, in save_list\r\n    self._batch_appends(obj)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 808, in _batch_appends\r\n    save(tmp[0])\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 410, in save_function\r\n    self.save_function_tuple(obj)\r\n  File \"/net/people/plgapohl/python-albert-pytorch/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 553, in save_function_tuple\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n  f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 781, in save_list\r\n    self._batch_appends(obj)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 808, in _batch_appends\r\n    save(tmp[0])\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 521, in save\r\n    self.save_reduce(obj=obj, *rv)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 634, in save_reduce\r\n    save(state)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 476, in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 821, in save_dict\r\n    self._batch_setitems(obj.items())\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 847, in _batch_setitems\r\n    save(v)\r\n  File \"/net/software/local/python/3.6.5/lib/python3.6/pickle.py\", line 496, in save\r\n    rv = reduce(self.proto)\r\nTypeError: can't pickle _thread.RLock objects\r\n```\r\n\r\nThis error in not present if we switch to:\r\nhttps://github.com/allenai/allennlp/commit/26e313b7d11eacf3a78c09c34608ad1bfd7db120\r\nbut appers when we move to the next commit, i.e.:\r\nhttps://github.com/allenai/allennlp/commit/4a6023b3ee692da50ff27126f331546e7c2f284a\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\nI have reported the issue in allentune, but it's a problem in allennlp:\r\n\r\n- https://github.com/allenai/allentune/issues/11\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS:\r\nLinux p2311 3.10.0-1062.9.1.el7.x86_64 #1 SMP Fri Dec 6 15:49:49 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version:\r\n3.6.5\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\nabsl-py==0.9.0\r\nalabaster==0.7.12\r\nallennlp==1.0.0rc4\r\n-e git+https://github.com/allenai/allentune.git@6ef9a2e38a9bcf944f83f2034dd181f94ff00d9c#egg=allentune\r\napex==0.1\r\nastor==0.8.1\r\nastunparse==1.6.3\r\nattrs==19.3.0\r\nBabel==2.8.0\r\nbackcall==0.1.0\r\nblis==0.2.4\r\nboto3==1.11.12\r\nbotocore==1.14.12\r\ncachetools==4.0.0\r\ncatalogue==1.0.0\r\ncertifi==2019.11.28\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncolorama==0.4.3\r\nconfigparser==5.0.0\r\nconllu==2.3.2\r\ncoverage==5.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ndataclasses==0.7\r\ndecorator==4.4.1\r\ndocker-pycreds==0.4.0\r\ndocutils==0.15.2\r\neditdistance==0.5.3\r\nfilelock==3.0.12\r\nfire==0.2.1\r\nflaky==3.6.1\r\nFlask==1.1.2\r\nFlask-Cors==3.0.8\r\nflatbuffers==1.12\r\nftfy==5.7\r\nfuncsigs==1.0.2\r\nfuture==0.18.2\r\ngast==0.2.2\r\ngevent==20.6.2\r\ngitdb==4.0.5\r\nGitPython==3.1.3\r\ngoogle-auth==1.11.0\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-pasta==0.2.0\r\ngql==0.2.0\r\ngraphql-core==1.1\r\ngreenlet==0.4.16\r\ngrpcio==1.26.0\r\nh5py==2.10.0\r\nhtml2text==2020.1.16\r\nidna==2.8\r\nimagesize==1.2.0\r\nimportlib-metadata==1.6.1\r\nipdb==0.12.3\r\nipython==7.12.0\r\nipython-genutils==0.2.0\r\nitsdangerous==1.1.0\r\njedi==0.16.0\r\nJinja2==2.11.2\r\njmespath==0.9.4\r\njoblib==0.15.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\nKeras==2.3.1\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.2\r\nkiwisolver==1.2.0\r\nMarkdown==3.1.1\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.2.1\r\nmore-itertools==8.4.0\r\nmurmurhash==1.0.2\r\nnltk==3.4.5\r\nnumpy==1.18.1\r\nnumpydoc==1.0.0\r\nnvidia-ml-py3==7.352.0\r\noauthlib==3.1.0\r\nopt-einsum==3.2.1\r\noverrides==2.8.0\r\npackaging==20.4\r\npandas==1.0.4\r\nparsimonious==0.8.1\r\nparso==0.6.1\r\npathtools==0.1.2\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nplac==0.9.6\r\npluggy==0.13.1\r\npreshed==2.0.1\r\nprogressbar==2.5\r\npromise==2.3\r\nprompt-toolkit==3.0.3\r\nprotobuf==3.11.2\r\npsutil==5.7.0\r\nptyprocess==0.6.0\r\npy==1.8.2\r\npy-rouge==1.1\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\nPygments==2.5.2\r\npyparsing==2.4.7\r\npytest==5.4.3\r\npytest-cov==2.10.0\r\npython-dateutil==2.8.1\r\npytorch-pretrained-bert==0.6.2\r\npytorch-transformers==1.1.0\r\npytz==2020.1\r\nPyYAML==5.3.1\r\nray==0.6.2\r\nredis==3.5.3\r\nregex==2020.5.14\r\nrequests==2.22.0\r\nrequests-oauthlib==1.3.0\r\nresponses==0.10.15\r\nrsa==4.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.4.1\r\nseaborn==0.10.1\r\nsemantic-version==2.8.5\r\nsentencepiece==0.1.91\r\nsentry-sdk==0.14.4\r\nseqeval==0.0.12\r\nshortuuid==1.0.1\r\nsimpletransformers==0.34.0\r\nsix==1.14.0\r\nsmmap==3.0.4\r\nsnowballstemmer==2.0.0\r\nspacy==2.1.9\r\nSphinx==3.1.1\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nsqlparse==0.3.1\r\nsrsly==1.0.2\r\nsubprocess32==3.5.4\r\ntensorboard==1.15.0\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorboardX==2.0\r\ntensorflow==1.15.0\r\ntensorflow-estimator==1.15.1\r\ntermcolor==1.1.0\r\nthinc==7.0.8\r\nthreadpoolctl==2.1.0\r\ntokenizers==0.5.2\r\ntorch==1.5.0\r\ntqdm==4.42.0\r\ntraitlets==4.3.3\r\ntransformers==2.8.0\r\nUnidecode==1.1.1\r\nurllib3==1.25.8\r\nwandb==0.8.36\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwcwidth==0.1.8\r\nWerkzeug==0.16.1\r\nword2number==1.1\r\nwrapt==1.12.1\r\nzipp==3.1.0\r\nzope.event==4.4\r\nzope.interface==5.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nJust run the example search in allentune:\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```\r\nallentune search \\\r\n    --experiment-name classifier_search \\\r\n    --num-cpus 56 \\\r\n    --num-gpus 4 \\\r\n    --cpus-per-trial 1 \\\r\n    --gpus-per-trial 1 \\\r\n    --search-space examples/search_space.json \\\r\n    --num-samples 30 \\\r\n    --base-config examples/classifier.jsonnet\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4362", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4362/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4362/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4362/events", "html_url": "https://github.com/allenai/allennlp/issues/4362", "id": 639573262, "node_id": "MDU6SXNzdWU2Mzk1NzMyNjI=", "number": 4362, "title": "Calculate validation loss more frequently", "user": {"login": "mateuszpieniak", "id": 31375424, "node_id": "MDQ6VXNlcjMxMzc1NDI0", "avatar_url": "https://avatars2.githubusercontent.com/u/31375424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mateuszpieniak", "html_url": "https://github.com/mateuszpieniak", "followers_url": "https://api.github.com/users/mateuszpieniak/followers", "following_url": "https://api.github.com/users/mateuszpieniak/following{/other_user}", "gists_url": "https://api.github.com/users/mateuszpieniak/gists{/gist_id}", "starred_url": "https://api.github.com/users/mateuszpieniak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mateuszpieniak/subscriptions", "organizations_url": "https://api.github.com/users/mateuszpieniak/orgs", "repos_url": "https://api.github.com/users/mateuszpieniak/repos", "events_url": "https://api.github.com/users/mateuszpieniak/events{/privacy}", "received_events_url": "https://api.github.com/users/mateuszpieniak/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-16T11:01:08Z", "updated_at": "2020-06-22T15:58:12Z", "closed_at": "2020-06-22T15:58:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\nI noticed that BERT-like architecture is usually fully fine-tuned, but very shortly (1-2 epochs) with some warm-up (to avoid catastrophic forgetting) - for example in https://arxiv.org/pdf/2004.07180.pdf. I believe that such a resolution is not enough for good validation score estimation i.e. you don't really know the curve's shape. I could lower down learning rate and increase the number of epochs, but it will take a lot of time to train. \r\n\r\nA slightly different example of calculating the validation score more frequently is https://arxiv.org/pdf/1803.09820.pdf, which was implemented in Caffe (no epoch concept). In the paper, the LR test was performed on the whole validation set after N batches.\r\n\r\n**Describe the solution you'd like**\r\nProvide an additional argument to `Trainer` that denotes the frequency of validation evaluation.\r\n\r\n**Describe alternatives you've considered**\r\nDecrease the learning rate and increase the number of epochs.\r\n\r\n**Additional context**\r\n1) It would require some changes for EarlyStopping\r\n2) When I reproduce some papers my validation loss looks like the following\r\n![image](https://user-images.githubusercontent.com/31375424/84766557-50645600-afd1-11ea-847e-a095fd57531c.png)\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4358", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4358/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4358/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4358/events", "html_url": "https://github.com/allenai/allennlp/issues/4358", "id": 638786199, "node_id": "MDU6SXNzdWU2Mzg3ODYxOTk=", "number": 4358, "title": "Textual Entailment using roBERTa only predicting one category", "user": {"login": "ud2195", "id": 42403625, "node_id": "MDQ6VXNlcjQyNDAzNjI1", "avatar_url": "https://avatars2.githubusercontent.com/u/42403625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ud2195", "html_url": "https://github.com/ud2195", "followers_url": "https://api.github.com/users/ud2195/followers", "following_url": "https://api.github.com/users/ud2195/following{/other_user}", "gists_url": "https://api.github.com/users/ud2195/gists{/gist_id}", "starred_url": "https://api.github.com/users/ud2195/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ud2195/subscriptions", "organizations_url": "https://api.github.com/users/ud2195/orgs", "repos_url": "https://api.github.com/users/ud2195/repos", "events_url": "https://api.github.com/users/ud2195/events{/privacy}", "received_events_url": "https://api.github.com/users/ud2195/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}, {"id": 2276693919, "node_id": "MDU6TGFiZWwyMjc2NjkzOTE5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "aaaaaa", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-15T11:46:24Z", "updated_at": "2020-08-18T16:18:33Z", "closed_at": "2020-08-18T16:18:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I followed the exact config file given here \r\nhttps://github.com/allenai/allennlp-models/blob/master/training_config/pair_classification/snli_roberta.jsonnet\r\njust changed `max_len` in my config file and now it looks like this:-\r\n\r\n```\r\nlocal transformer_model = \"roberta-large\";\r\nlocal transformer_dim = 1024;\r\nlocal cls_is_last_token = false;\r\n\r\n{\r\n  \"dataset_reader\":{\r\n    \"type\": \"snli\",\r\n    \"lazy\": true,\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": transformer_model,\r\n      \"add_special_tokens\": false\r\n    },\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": transformer_model,\r\n        \"max_length\": 40\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"/opt/ml/input/data/training/cnli_sampletrain_5L.jsonl\",\r\n  \"validation_data_path\": \"/opt/ml/input/data/validation/cnli_sampleval_5L.jsonl\",\r\n  \r\n  \"model\": {\r\n    \"type\": \"basic_classifier\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": transformer_model,\r\n          \"max_length\": 40\r\n        }\r\n      }\r\n    },\r\n    \"seq2vec_encoder\": {\r\n       \"type\": \"cls_pooler\",\r\n       \"embedding_dim\": transformer_dim,\r\n       \"cls_is_last_token\": cls_is_last_token\r\n    },\r\n    \"feedforward\": {\r\n      \"input_dim\": transformer_dim,\r\n      \"num_layers\": 1,\r\n      \"hidden_dims\": transformer_dim,\r\n      \"activations\": \"tanh\"\r\n    },\r\n    \"dropout\": 0.3,\r\n    \"namespace\": \"tags\"\r\n  },\r\n  \"data_loader\": {\r\n        \"batch_size\": 4,\r\n        \r\n        \"drop_last\": true,\r\n    },\r\n  \"trainer\": {\r\n    \"num_epochs\": 3,\r\n    \"cuda_device\" : 0,\r\n    \"validation_metric\": \"+accuracy\",\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"slanted_triangular\",\r\n      \"cut_frac\": 0.06\r\n    },\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 2e-5,\r\n      \"weight_decay\": 0.1,\r\n    }\r\n  }\r\n}\r\n```\r\nThe objective is to do Textual entailment using roBERTa , but after training my model for 2 epochs the accuracy(roughly 79%)  hardly changed and then upon trying my model to predict it strangely predicted the same label for all the instances present in the test data. \r\n\r\ni have a few doubts , The `model_type:basic_classifier` mentioned in default config is it right ? doesnt `basic_classifier` implement a normal text classifier ?\r\n\r\n\r\nCode i am using for prediction-\r\n```\r\nimport pandas as pd\r\nfrom allennlp_models import pair_classification\r\nfrom allennlp.predictors.predictor import Predictor \r\nimport numpy as np\r\n\r\ndata=pd.read_csv(r'/home/episourcein.episource.com/espm1854/Downloads/context_3_classes.csv')\r\npredictor=Predictor.from_path(\"/home/episourcein.episource.com/espm1854/Documents/robertaTE/model.tar.gz\",predictor_name=\"textual_entailment\")\r\n\r\nlabels_dict = predictor._model.vocab.get_index_to_token_vocabulary('labels')\r\n\r\ndef get_labels(hypothesis, premise):\r\n    pred = predictor.predict(\r\n      hypothesis=hypothesis,\r\n      premise=premise\r\n    )\r\n    \r\n    label = labels_dict[np.argmax(pred['probs'])]\r\n    return label\r\n\r\ndata['predictions']= data.apply(lambda x: get_labels(x['hypothesis'],x['sentence']),  axis=1)\r\n```\r\nif the `model_type` here is wrong then what `model_type` should i specify inplace of `basic_classifier` to do textual entailment with roBERTa? A sample config file for doing entailment with roBERTa would really be helpful \r\nAny help will be appreciated ! @epwalsh @matt-gardner \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4357", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4357/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4357/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4357/events", "html_url": "https://github.com/allenai/allennlp/issues/4357", "id": 638463439, "node_id": "MDU6SXNzdWU2Mzg0NjM0Mzk=", "number": 4357, "title": "Bug on calculating \"argmax_predictions\". It increases the false positive count for last label.", "user": {"login": "12seetharaman", "id": 53142037, "node_id": "MDQ6VXNlcjUzMTQyMDM3", "avatar_url": "https://avatars0.githubusercontent.com/u/53142037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/12seetharaman", "html_url": "https://github.com/12seetharaman", "followers_url": "https://api.github.com/users/12seetharaman/followers", "following_url": "https://api.github.com/users/12seetharaman/following{/other_user}", "gists_url": "https://api.github.com/users/12seetharaman/gists{/gist_id}", "starred_url": "https://api.github.com/users/12seetharaman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/12seetharaman/subscriptions", "organizations_url": "https://api.github.com/users/12seetharaman/orgs", "repos_url": "https://api.github.com/users/12seetharaman/repos", "events_url": "https://api.github.com/users/12seetharaman/events{/privacy}", "received_events_url": "https://api.github.com/users/12seetharaman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 887719346, "node_id": "MDU6TGFiZWw4ODc3MTkzNDY=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Contributions%20welcome", "name": "Contributions welcome", "color": "e827b7", "default": false, "description": ""}, {"id": 1771935780, "node_id": "MDU6TGFiZWwxNzcxOTM1Nzgw", "url": "https://api.github.com/repos/allenai/allennlp/labels/Day", "name": "Day", "color": "0052cc", "default": false, "description": ""}, {"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/11", "html_url": "https://github.com/allenai/allennlp/milestone/11", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/11/labels", "id": 5183675, "node_id": "MDk6TWlsZXN0b25lNTE4MzY3NQ==", "number": 11, "title": "1.1", "description": "A placeholder for work we'd like to do after the 1.0 release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 21, "state": "open", "created_at": "2020-03-09T17:46:04Z", "updated_at": "2020-08-12T17:28:23Z", "due_on": null, "closed_at": null}, "comments": 1, "created_at": "2020-06-15T00:26:20Z", "updated_at": "2020-07-13T20:54:55Z", "closed_at": "2020-07-13T20:54:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "File: https://github.com/allenai/allennlp/blob/master/allennlp/training/metrics/fbeta_measure.py\r\nLine no: 132\r\n\r\nPrediction tensor is all zero \"[0, 0, 0, 0, 0, 0]\", when a record is not classified to any of the labels. \r\n\r\n`argmax_predictions = predictions.max(dim=-1)[1].float()`\r\n\r\nHere, we are calculating argmax predictions by a max value index. \r\nIn the case of all zeros tensor, we will get the index of the last label. It increases the false positive count of the last label and affects the F1 score.\r\n\r\n```\r\n>>> prediction =  torch.zeros(6)\r\n>>> prediction\r\ntensor([0., 0., 0., 0., 0., 0.])\r\n>>> prediction.max(dim=-1)\r\n(tensor(0.), tensor(5))\r\n>>> prediction.max(dim=-1)[1]\r\ntensor(5)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4354", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4354/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4354/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4354/events", "html_url": "https://github.com/allenai/allennlp/issues/4354", "id": 637191936, "node_id": "MDU6SXNzdWU2MzcxOTE5MzY=", "number": 4354, "title": "Reported loss is confusing", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1771935780, "node_id": "MDU6TGFiZWwxNzcxOTM1Nzgw", "url": "https://api.github.com/repos/allenai/allennlp/labels/Day", "name": "Day", "color": "0052cc", "default": false, "description": ""}, {"id": 723800354, "node_id": "MDU6TGFiZWw3MjM4MDAzNTQ=", "url": "https://api.github.com/repos/allenai/allennlp/labels/Good%20First%20Issue", "name": "Good First Issue", "color": "e99695", "default": false, "description": null}, {"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "AkshitaB", "id": 6500683, "node_id": "MDQ6VXNlcjY1MDA2ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6500683?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AkshitaB", "html_url": "https://github.com/AkshitaB", "followers_url": "https://api.github.com/users/AkshitaB/followers", "following_url": "https://api.github.com/users/AkshitaB/following{/other_user}", "gists_url": "https://api.github.com/users/AkshitaB/gists{/gist_id}", "starred_url": "https://api.github.com/users/AkshitaB/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AkshitaB/subscriptions", "organizations_url": "https://api.github.com/users/AkshitaB/orgs", "repos_url": "https://api.github.com/users/AkshitaB/repos", "events_url": "https://api.github.com/users/AkshitaB/events{/privacy}", "received_events_url": "https://api.github.com/users/AkshitaB/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/11", "html_url": "https://github.com/allenai/allennlp/milestone/11", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/11/labels", "id": 5183675, "node_id": "MDk6TWlsZXN0b25lNTE4MzY3NQ==", "number": 11, "title": "1.1", "description": "A placeholder for work we'd like to do after the 1.0 release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 21, "state": "open", "created_at": "2020-03-09T17:46:04Z", "updated_at": "2020-08-12T17:28:23Z", "due_on": null, "closed_at": null}, "comments": 2, "created_at": "2020-06-11T17:19:28Z", "updated_at": "2020-07-17T08:44:54Z", "closed_at": "2020-07-17T08:44:54Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The loss we write into tensorboard is the average loss over the epoch. So the first number we get is not averaged at all, while the last number in the epoch is averaged over the entire epoch. Then we start the second epoch, and the next value reported is just the loss of the first batch of the second epoch. As a result, we always see a big drop in loss when the epoch changes. This makes no sense.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4353", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4353/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4353/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4353/events", "html_url": "https://github.com/allenai/allennlp/issues/4353", "id": 636804308, "node_id": "MDU6SXNzdWU2MzY4MDQzMDg=", "number": 4353, "title": "Questions about discriminative_fine_tuning", "user": {"login": "wlhgtc", "id": 16603773, "node_id": "MDQ6VXNlcjE2NjAzNzcz", "avatar_url": "https://avatars2.githubusercontent.com/u/16603773?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wlhgtc", "html_url": "https://github.com/wlhgtc", "followers_url": "https://api.github.com/users/wlhgtc/followers", "following_url": "https://api.github.com/users/wlhgtc/following{/other_user}", "gists_url": "https://api.github.com/users/wlhgtc/gists{/gist_id}", "starred_url": "https://api.github.com/users/wlhgtc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wlhgtc/subscriptions", "organizations_url": "https://api.github.com/users/wlhgtc/orgs", "repos_url": "https://api.github.com/users/wlhgtc/repos", "events_url": "https://api.github.com/users/wlhgtc/events{/privacy}", "received_events_url": "https://api.github.com/users/wlhgtc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-06-11T07:57:26Z", "updated_at": "2020-06-28T07:33:18Z", "closed_at": "2020-06-16T11:47:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi there,\r\nThanks for your great work, it's easy for me to do experiments.\r\nBut still few questions about the `discriminative_fine_tuning`\uff1a\r\nI use the model in [https://github.com/allenai/allennlp/blob/v0.9.0/allennlp/models/bert_for_classification.py#L16](url)\r\nAnd  I want to use the parameter  `discriminative_fine_tuning` to set  different learning rate.\r\nSpecifically, I want three groups like `[[layer0,layer1,layer2,layer3][layer4,layer5.layer6,layer7],[layer8,layer9,layer10,layer11]]`.\r\nIn #2159 , It seems that I could print all their name and list them in my config file.\r\nCause of some many parameters, can I finish it in an elegant way ?\r\n@matt-peters  Hope you could help, thx!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4352", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4352/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4352/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4352/events", "html_url": "https://github.com/allenai/allennlp/issues/4352", "id": 636718451, "node_id": "MDU6SXNzdWU2MzY3MTg0NTE=", "number": 4352, "title": "Wanted to use the allen nlp api", "user": {"login": "HarshMultani", "id": 24610919, "node_id": "MDQ6VXNlcjI0NjEwOTE5", "avatar_url": "https://avatars2.githubusercontent.com/u/24610919?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HarshMultani", "html_url": "https://github.com/HarshMultani", "followers_url": "https://api.github.com/users/HarshMultani/followers", "following_url": "https://api.github.com/users/HarshMultani/following{/other_user}", "gists_url": "https://api.github.com/users/HarshMultani/gists{/gist_id}", "starred_url": "https://api.github.com/users/HarshMultani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HarshMultani/subscriptions", "organizations_url": "https://api.github.com/users/HarshMultani/orgs", "repos_url": "https://api.github.com/users/HarshMultani/repos", "events_url": "https://api.github.com/users/HarshMultani/events{/privacy}", "received_events_url": "https://api.github.com/users/HarshMultani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-11T05:02:02Z", "updated_at": "2020-06-19T16:33:45Z", "closed_at": "2020-06-19T16:33:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "I went through the text to sql (ATIS parser) demo : https://demo.allennlp.org/atis-parser\r\nI was not able to find a place where I can get a documentation about how to use this api for my project. Can you provide any link that can give some starting procedure on how to do this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4351", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4351/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4351/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4351/events", "html_url": "https://github.com/allenai/allennlp/issues/4351", "id": 636657259, "node_id": "MDU6SXNzdWU2MzY2NTcyNTk=", "number": 4351, "title": "Provide documentation for uploading pretrained transformer weights to HuggingFace", "user": {"login": "JohnGiorgi", "id": 8917831, "node_id": "MDQ6VXNlcjg5MTc4MzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/8917831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JohnGiorgi", "html_url": "https://github.com/JohnGiorgi", "followers_url": "https://api.github.com/users/JohnGiorgi/followers", "following_url": "https://api.github.com/users/JohnGiorgi/following{/other_user}", "gists_url": "https://api.github.com/users/JohnGiorgi/gists{/gist_id}", "starred_url": "https://api.github.com/users/JohnGiorgi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JohnGiorgi/subscriptions", "organizations_url": "https://api.github.com/users/JohnGiorgi/orgs", "repos_url": "https://api.github.com/users/JohnGiorgi/repos", "events_url": "https://api.github.com/users/JohnGiorgi/events{/privacy}", "received_events_url": "https://api.github.com/users/JohnGiorgi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1875662321, "node_id": "MDU6TGFiZWwxODc1NjYyMzIx", "url": "https://api.github.com/repos/allenai/allennlp/labels/Feature%20request", "name": "Feature request", "color": "5558ba", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/13", "html_url": "https://github.com/allenai/allennlp/milestone/13", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/13/labels", "id": 5535962, "node_id": "MDk6TWlsZXN0b25lNTUzNTk2Mg==", "number": 13, "title": "1.2", "description": "", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 9, "closed_issues": 5, "state": "open", "created_at": "2020-06-12T16:16:52Z", "updated_at": "2020-08-20T22:36:37Z", "due_on": null, "closed_at": null}, "comments": 14, "created_at": "2020-06-11T01:50:16Z", "updated_at": "2020-08-18T21:06:26Z", "closed_at": "2020-08-18T21:06:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nAs per [my post on the forums](https://discourse.allennlp.org/t/upload-a-pretrained-transformer-to-huggingfaces-transformers/325), I think it would be very useful if there were instructions for uploading the weights of a transformer-based language model trained with AllenNLP to [HuggingFace's Models](https://huggingface.co/models).\r\n\r\n**Describe the solution you'd like**\r\n\r\nA mechanism (if it doesn't already exist) and instructions for uploading the weights of a pretrained language model trained with AllenNLP to [HuggingFace's Models](https://huggingface.co/models).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nN/A.\r\n\r\n**Additional context**\r\n\r\nI first asked if this was possible [in the forums](https://discourse.allennlp.org/t/upload-a-pretrained-transformer-to-huggingfaces-transformers/325) and @matt-gardner asked me to open a feature request here.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4347", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4347/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4347/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4347/events", "html_url": "https://github.com/allenai/allennlp/issues/4347", "id": 635888913, "node_id": "MDU6SXNzdWU2MzU4ODg5MTM=", "number": 4347, "title": "Metrics under distributed training", "user": {"login": "ZhaofengWu", "id": 11954789, "node_id": "MDQ6VXNlcjExOTU0Nzg5", "avatar_url": "https://avatars2.githubusercontent.com/u/11954789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZhaofengWu", "html_url": "https://github.com/ZhaofengWu", "followers_url": "https://api.github.com/users/ZhaofengWu/followers", "following_url": "https://api.github.com/users/ZhaofengWu/following{/other_user}", "gists_url": "https://api.github.com/users/ZhaofengWu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZhaofengWu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZhaofengWu/subscriptions", "organizations_url": "https://api.github.com/users/ZhaofengWu/orgs", "repos_url": "https://api.github.com/users/ZhaofengWu/repos", "events_url": "https://api.github.com/users/ZhaofengWu/events{/privacy}", "received_events_url": "https://api.github.com/users/ZhaofengWu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-10T02:58:53Z", "updated_at": "2020-06-10T18:38:22Z", "closed_at": "2020-06-10T18:38:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently metrics are simply being averages across GPUs -- this is probably not exact for most metrics. Should we do something smarter here? This will probably require a decent amount of work though, as each metric has to implement its own reduction function.\r\nhttps://github.com/allenai/allennlp/blob/2012fea98bfbb1b60980cdd2760fdf56ae352006/allennlp/training/util.py#L299-L307", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4345", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4345/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4345/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4345/events", "html_url": "https://github.com/allenai/allennlp/issues/4345", "id": 635123107, "node_id": "MDU6SXNzdWU2MzUxMjMxMDc=", "number": 4345, "title": "Can't run allennlp-server in 1.0.0 rc6", "user": {"login": "YKX-A", "id": 38134733, "node_id": "MDQ6VXNlcjM4MTM0NzMz", "avatar_url": "https://avatars0.githubusercontent.com/u/38134733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YKX-A", "html_url": "https://github.com/YKX-A", "followers_url": "https://api.github.com/users/YKX-A/followers", "following_url": "https://api.github.com/users/YKX-A/following{/other_user}", "gists_url": "https://api.github.com/users/YKX-A/gists{/gist_id}", "starred_url": "https://api.github.com/users/YKX-A/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YKX-A/subscriptions", "organizations_url": "https://api.github.com/users/YKX-A/orgs", "repos_url": "https://api.github.com/users/YKX-A/repos", "events_url": "https://api.github.com/users/YKX-A/events{/privacy}", "received_events_url": "https://api.github.com/users/YKX-A/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-09T05:29:27Z", "updated_at": "2020-06-11T16:44:43Z", "closed_at": "2020-06-11T16:44:38Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "environment\r\n```\r\nallennlp                       1.0.0rc6\r\nallennlp-models                1.0.0rc6\r\nallennlp-reading-comprehension 0.0.1-unreleased\r\nallennlp-server                1.0.0-unreleased    \r\n```\r\n\r\nMy target is to run a **simple server (web demo)**, like [this](https://github.com/YKX-A/allennlp_0.9.1_bk/blob/master/docs/tutorials/getting_started/predicting_paper_venues/predicting_paper_venues_pt2.md#running-a-web-demo). Following the installing guide on https://github.com/allenai/allennlp-server, **I can't see `configure ` and `serve` in `allennlp` command.**\r\n```\r\n\u279c allennlp\r\n2020-06-09 13:20:34,347 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\nusage: allennlp [-h] [--version]  ...\r\n\r\nRun AllenNLP\r\n\r\noptional arguments:\r\n  -h, --help     show this help message and exit\r\n  --version      show program's version number and exit\r\n\r\nCommands:\r\n\r\n    evaluate     Evaluate the specified model + dataset.\r\n    find-lr      Find a learning rate range.\r\n    predict      Use a trained model to make predictions.\r\n    print-results\r\n                 Print results from allennlp serialization directories to the\r\n                 console.\r\n    test-install\r\n                 Test AllenNLP installation.\r\n    train        Train a model.\r\n```\r\n\r\nI try another approach:\r\n```\r\n\u279c python allennlp_server/commands/server_simple.py\r\nTraceback (most recent call last):\r\n  File \"allennlp_server/commands/server_simple.py\", line 168, in <module>\r\n    class SimpleServer(Subcommand):\r\n  File \"/Users/ykx/anaconda3/envs/allennlp_server2/lib/python3.7/site-packages/allennlp/commands/subcommand.py\", line 40, in add_name_to_reverse_registry\r\n    subclass = super_register_fn(subclass)\r\n  File \"/Users/ykx/anaconda3/envs/allennlp_server2/lib/python3.7/site-packages/allennlp/common/registrable.py\", line 123, in add_subclass_to_registry\r\n    raise ConfigurationError(message)\r\nallennlp.common.checks.ConfigurationError: Cannot register serve as Subcommand; name already in use for SimpleServer\r\n```\r\nSo, is there any matched `allennlp` and`annennlp-serve` version that I can run, or any other approach I can finish the demo?\r\nThanks for your suggestions.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4339", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4339/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4339/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4339/events", "html_url": "https://github.com/allenai/allennlp/issues/4339", "id": 634239980, "node_id": "MDU6SXNzdWU2MzQyMzk5ODA=", "number": 4339, "title": "Make an AllenNLP Project Template", "user": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "matt-gardner", "id": 3291951, "node_id": "MDQ6VXNlcjMyOTE5NTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3291951?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-gardner", "html_url": "https://github.com/matt-gardner", "followers_url": "https://api.github.com/users/matt-gardner/followers", "following_url": "https://api.github.com/users/matt-gardner/following{/other_user}", "gists_url": "https://api.github.com/users/matt-gardner/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-gardner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-gardner/subscriptions", "organizations_url": "https://api.github.com/users/matt-gardner/orgs", "repos_url": "https://api.github.com/users/matt-gardner/repos", "events_url": "https://api.github.com/users/matt-gardner/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-gardner/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/11", "html_url": "https://github.com/allenai/allennlp/milestone/11", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/11/labels", "id": 5183675, "node_id": "MDk6TWlsZXN0b25lNTE4MzY3NQ==", "number": 11, "title": "1.1", "description": "A placeholder for work we'd like to do after the 1.0 release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 21, "state": "open", "created_at": "2020-03-09T17:46:04Z", "updated_at": "2020-08-12T17:28:23Z", "due_on": null, "closed_at": null}, "comments": 5, "created_at": "2020-06-08T06:41:01Z", "updated_at": "2020-07-13T17:41:25Z", "closed_at": "2020-07-13T17:40:55Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We should have a template GitHub repo for people to get started with.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4337", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4337/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4337/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4337/events", "html_url": "https://github.com/allenai/allennlp/issues/4337", "id": 633764491, "node_id": "MDU6SXNzdWU2MzM3NjQ0OTE=", "number": 4337, "title": "SRL predictor misses \"get\" verb.", "user": {"login": "ducalpha", "id": 3000864, "node_id": "MDQ6VXNlcjMwMDA4NjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/3000864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ducalpha", "html_url": "https://github.com/ducalpha", "followers_url": "https://api.github.com/users/ducalpha/followers", "following_url": "https://api.github.com/users/ducalpha/following{/other_user}", "gists_url": "https://api.github.com/users/ducalpha/gists{/gist_id}", "starred_url": "https://api.github.com/users/ducalpha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ducalpha/subscriptions", "organizations_url": "https://api.github.com/users/ducalpha/orgs", "repos_url": "https://api.github.com/users/ducalpha/repos", "events_url": "https://api.github.com/users/ducalpha/events{/privacy}", "received_events_url": "https://api.github.com/users/ducalpha/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-07T21:07:40Z", "updated_at": "2020-06-08T15:51:31Z", "closed_at": "2020-06-08T15:51:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "SRL Predictor only considers verbs with VERB Universal POS (https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/predictors/srl.py#L108), but \"get\" commonly is tagged as AUX by Spacy. Therefore, the verb \"get\" in sentences is frequently ignored.\r\n\r\nHow to reproduce:\r\nTrying the following sentence on SRL demo (https://demo.allennlp.org/semantic-role-labeling) with Allennlp 1.0 RC5 and BERT SRL yields a dictionary with only \"go\" verb.\r\n\r\n\"we go to the party to get free food.\"\r\n\r\n```\r\nfrom allennlp.predictors.predictor import Predictor\r\nimport allennlp_models.structured_prediction.models.srl\r\npredictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz\")\r\npredictor.predict(\r\n  sentence=\"we go to the party to get free food.\"\r\n)\r\n```\r\n\r\n(P.S. The usage on the demo web page is not updated to AllenNLP 1.0 RC5 but it should be filed on another bug.)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4335", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4335/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4335/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4335/events", "html_url": "https://github.com/allenai/allennlp/issues/4335", "id": 632918958, "node_id": "MDU6SXNzdWU2MzI5MTg5NTg=", "number": 4335, "title": "pretrained file from word2vec model", "user": {"login": "wj-Mcat", "id": 10242208, "node_id": "MDQ6VXNlcjEwMjQyMjA4", "avatar_url": "https://avatars3.githubusercontent.com/u/10242208?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wj-Mcat", "html_url": "https://github.com/wj-Mcat", "followers_url": "https://api.github.com/users/wj-Mcat/followers", "following_url": "https://api.github.com/users/wj-Mcat/following{/other_user}", "gists_url": "https://api.github.com/users/wj-Mcat/gists{/gist_id}", "starred_url": "https://api.github.com/users/wj-Mcat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wj-Mcat/subscriptions", "organizations_url": "https://api.github.com/users/wj-Mcat/orgs", "repos_url": "https://api.github.com/users/wj-Mcat/repos", "events_url": "https://api.github.com/users/wj-Mcat/events{/privacy}", "received_events_url": "https://api.github.com/users/wj-Mcat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2276693919, "node_id": "MDU6TGFiZWwyMjc2NjkzOTE5", "url": "https://api.github.com/repos/allenai/allennlp/labels/stale", "name": "stale", "color": "aaaaaa", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-07T01:59:37Z", "updated_at": "2020-08-18T16:18:35Z", "closed_at": "2020-08-18T16:18:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "I get pretrained embedding from word2vec model, which doesn't contains oov padding.  Allennlp must require oov padding in token.txt files. So, embedding file `word_idx `[0] is not `oov` index. \r\n\r\nhow to resolve this matching problems?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4332", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4332/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4332/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4332/events", "html_url": "https://github.com/allenai/allennlp/issues/4332", "id": 632036763, "node_id": "MDU6SXNzdWU2MzIwMzY3NjM=", "number": 4332, "title": "Predict doesn't work for SNLI on 1.0.0rc5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 4, "created_at": "2020-06-05T22:57:21Z", "updated_at": "2020-06-11T16:52:09Z", "closed_at": "2020-06-11T16:52:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n$ echo '{\"hypothesis\": \"Two women are sitting on a blanket near some rocks talking about politics.\", \"premise\": \"Two women are wandering along the shore drinking iced tea.\"}' | allennlp predict --predictor textual-entailment https://storage.googleapis.com/allennlp-public-models/snli-roberta-large-2020.04.30.tar.gz -\r\n2020-06-05 15:56:14,840 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-05 15:56:15,495 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/snli-roberta-large-2020.04.30.tar.gz from cache at /home/michaels/.allennlp/cache/589d6edb6a58b240ecd4c9fdbe356edf24cc1200ff1fb0c65835bfdc8b05ba1c.90841b7d888cf623f8ffdafbdd06a233a1fa2eb2f2ed42376f3cd690ecd49462\r\n2020-06-05 15:56:15,514 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/589d6edb6a58b240ecd4c9fdbe356edf24cc1200ff1fb0c65835bfdc8b05ba1c.90841b7d888cf623f8ffdafbdd06a233a1fa2eb2f2ed42376f3cd690ecd49462 to temp dir /tmp/tmps6xeghmu\r\n2020-06-05 15:56:24,813 - INFO - allennlp.common.params - type = from_instances\r\n2020-06-05 15:56:24,814 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmps6xeghmu/vocabulary.\r\n2020-06-05 15:56:24,814 - INFO - allennlp.common.params - model.type = basic_classifier\r\n2020-06-05 15:56:24,814 - INFO - allennlp.common.params - model.regularizer = None\r\n2020-06-05 15:56:24,814 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\r\n2020-06-05 15:56:24,815 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer\r\n2020-06-05 15:56:24,815 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-large\r\n2020-06-05 15:56:24,815 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\r\n2020-06-05 15:56:25,129 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:25,129 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:25,177 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /home/michaels/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\r\n2020-06-05 15:56:34,879 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:34,880 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:35,521 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:35,521 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:35,909 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:35,910 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:36,542 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:36,542 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:36,629 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\r\n2020-06-05 15:56:36,629 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 1024\r\n2020-06-05 15:56:36,629 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False\r\n2020-06-05 15:56:36,629 - INFO - allennlp.common.params - model.seq2seq_encoder = None\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.input_dim = 1024\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.num_layers = 1\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.hidden_dims = 1024\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.activations = tanh\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - type = tanh\r\n2020-06-05 15:56:36,630 - INFO - allennlp.common.params - model.feedforward.dropout = 0.0\r\n2020-06-05 15:56:36,636 - INFO - allennlp.common.params - model.dropout = 0.1\r\n2020-06-05 15:56:36,636 - INFO - allennlp.common.params - model.num_labels = None\r\n2020-06-05 15:56:36,637 - INFO - allennlp.common.params - model.label_namespace = labels\r\n2020-06-05 15:56:36,637 - INFO - allennlp.common.params - model.namespace = tags\r\n2020-06-05 15:56:36,637 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f8c862de050>\r\n2020-06-05 15:56:36,637 - INFO - allennlp.nn.initializers - Initializing parameters\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _classification_layer.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _classification_layer.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _feedforward._linear_layers.0.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _feedforward._linear_layers.0.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\r\n2020-06-05 15:56:36,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight\r\n2020-06-05 15:56:36,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.weight\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.bias\r\n2020-06-05 15:56:36,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.bias\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.weight\r\n2020-06-05 15:56:36,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias\r\n2020-06-05 15:56:36,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.weight\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.bias\r\n2020-06-05 15:56:36,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight\r\n2020-06-05 15:56:36,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\r\n2020-06-05 15:56:36,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.type = snli\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.lazy = False\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.max_instances = None\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-large\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = None\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.truncation_strategy = longest_first\r\n2020-06-05 15:56:37,743 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None\r\n2020-06-05 15:56:38,053 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:38,054 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:38,680 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:38,680 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:39,086 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:39,087 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:39,717 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:39,718 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:39,797 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer\r\n2020-06-05 15:56:39,797 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\r\n2020-06-05 15:56:39,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-large\r\n2020-06-05 15:56:39,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\r\n2020-06-05 15:56:39,798 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\r\n2020-06-05 15:56:40,092 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:40,093 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:40,779 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:40,780 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:41,177 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:56:41,178 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:56:41,931 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:56:41,932 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:56:42,014 - INFO - allennlp.common.params - dataset_reader.combine_input_fields = None\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 197, in _predict\r\n    predictor = _get_predictor(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 102, in _get_predictor\r\n    archive, args.predictor, dataset_reader_to_load=args.dataset_reader_choice\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 294, in from_archive\r\n    dataset_reader = DatasetReader.from_params(dataset_reader_params)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp_models/pair_classification/dataset_readers/snli.py\", line 51, in __init__\r\n    assert not self._tokenizer._add_special_tokens\r\nAssertionError\r\n2020-06-05 15:56:42,015 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmps6xeghmu\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4331", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4331/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4331/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4331/events", "html_url": "https://github.com/allenai/allennlp/issues/4331", "id": 632035151, "node_id": "MDU6SXNzdWU2MzIwMzUxNTE=", "number": 4331, "title": "Predict doesn't work for Roberta MNLI on 1.0.0rc5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 7, "created_at": "2020-06-05T22:54:31Z", "updated_at": "2020-06-11T19:03:03Z", "closed_at": "2020-06-11T16:52:18Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n$ echo '{\"hypothesis\": \"Two women are sitting on a blanket near some rocks talking about politics.\", \"premise\": \"Two women are wandering along the shore drinking iced tea.\"}' | allennlp predict --predictor textual-entailment https://storage.googleapis.com/allennlp-public-models/mnli-roberta-large-2020.05.13.tar.gz -\r\n2020-06-05 15:53:08,894 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-05 15:53:09,595 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/mnli-roberta-large-2020.05.13.tar.gz from cache at /home/michaels/.allennlp/cache/6464891350f0d2a96fed729f770a3c95cfdcdfac243c7a016377c0ded406e599.128e3323e8512d3bdda5113ef51fa10fa25624d0213c5c73445832a2f73916f3\r\n2020-06-05 15:53:09,596 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/6464891350f0d2a96fed729f770a3c95cfdcdfac243c7a016377c0ded406e599.128e3323e8512d3bdda5113ef51fa10fa25624d0213c5c73445832a2f73916f3 to temp dir /tmp/tmp20uyprv6\r\n2020-06-05 15:53:18,719 - INFO - allennlp.common.params - type = from_instances\r\n2020-06-05 15:53:18,719 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp20uyprv6/vocabulary.\r\n2020-06-05 15:53:18,720 - INFO - allennlp.common.params - model.type = basic_classifier\r\n2020-06-05 15:53:18,720 - INFO - allennlp.common.params - model.regularizer = None\r\n2020-06-05 15:53:18,720 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\r\n2020-06-05 15:53:18,720 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer\r\n2020-06-05 15:53:18,721 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-large\r\n2020-06-05 15:53:18,721 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\r\n2020-06-05 15:53:19,042 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:19,043 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:19,625 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /home/michaels/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\r\n2020-06-05 15:53:29,290 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:29,291 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:29,904 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:29,905 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:30,290 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:30,291 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:30,915 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:30,916 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.seq2vec_encoder.type = cls_pooler\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.seq2vec_encoder.embedding_dim = 1024\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.seq2vec_encoder.cls_is_last_token = False\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.seq2seq_encoder = None\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.feedforward.input_dim = 1024\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.feedforward.num_layers = 1\r\n2020-06-05 15:53:31,005 - INFO - allennlp.common.params - model.feedforward.hidden_dims = 1024\r\n2020-06-05 15:53:31,006 - INFO - allennlp.common.params - model.feedforward.activations = tanh\r\n2020-06-05 15:53:31,006 - INFO - allennlp.common.params - type = tanh\r\n2020-06-05 15:53:31,006 - INFO - allennlp.common.params - model.feedforward.dropout = 0.0\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.dropout = 0.1\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.num_labels = None\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.label_namespace = labels\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.namespace = tags\r\n2020-06-05 15:53:31,012 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fa4abe41f50>\r\n2020-06-05 15:53:31,012 - INFO - allennlp.nn.initializers - Initializing parameters\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _classification_layer.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _classification_layer.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _feedforward._linear_layers.0.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _feedforward._linear_layers.0.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\r\n2020-06-05 15:53:31,014 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.weight\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.bias\r\n2020-06-05 15:53:31,015 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.weight\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.bias\r\n2020-06-05 15:53:31,016 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.bias\r\n2020-06-05 15:53:31,017 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.bias\r\n2020-06-05 15:53:31,018 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.bias\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.weight\r\n2020-06-05 15:53:31,019 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight\r\n2020-06-05 15:53:31,020 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias\r\n2020-06-05 15:53:31,021 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight\r\n2020-06-05 15:53:31,022 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias\r\n2020-06-05 15:53:31,023 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight\r\n2020-06-05 15:53:31,023 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\r\n2020-06-05 15:53:31,023 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\r\n2020-06-05 15:53:32,133 - INFO - allennlp.common.params - dataset_reader.type = snli\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.lazy = False\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.max_instances = None\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-large\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = None\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.truncation_strategy = longest_first\r\n2020-06-05 15:53:32,134 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None\r\n2020-06-05 15:53:32,437 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:32,438 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:33,058 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:33,058 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:33,440 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:33,441 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:34,073 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:34,074 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:34,153 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer\r\n2020-06-05 15:53:34,154 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\r\n2020-06-05 15:53:34,154 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-large\r\n2020-06-05 15:53:34,154 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\r\n2020-06-05 15:53:34,154 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\r\n2020-06-05 15:53:35,462 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:35,463 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:36,086 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:36,087 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:36,505 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/michaels/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\r\n2020-06-05 15:53:36,506 - INFO - transformers.configuration_utils - Model config RobertaConfig {\r\n  \"architectures\": [\r\n    \"RobertaForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"bos_token_id\": 0,\r\n  \"eos_token_id\": 2,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 1024,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 4096,\r\n  \"layer_norm_eps\": 1e-05,\r\n  \"max_position_embeddings\": 514,\r\n  \"model_type\": \"roberta\",\r\n  \"num_attention_heads\": 16,\r\n  \"num_hidden_layers\": 24,\r\n  \"pad_token_id\": 1,\r\n  \"type_vocab_size\": 1,\r\n  \"vocab_size\": 50265\r\n}\r\n\r\n2020-06-05 15:53:37,181 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at /home/michaels/.cache/torch/transformers/1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\r\n2020-06-05 15:53:37,181 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at /home/michaels/.cache/torch/transformers/f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\r\n2020-06-05 15:53:37,310 - INFO - allennlp.common.params - dataset_reader.combine_input_fields = None\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 197, in _predict\r\n    predictor = _get_predictor(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 102, in _get_predictor\r\n    archive, args.predictor, dataset_reader_to_load=args.dataset_reader_choice\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 294, in from_archive\r\n    dataset_reader = DatasetReader.from_params(dataset_reader_params)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 580, in from_params\r\n    **extras,\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/from_params.py\", line 611, in from_params\r\n    return constructor_to_call(**kwargs)  # type: ignore\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp_models/pair_classification/dataset_readers/snli.py\", line 51, in __init__\r\n    assert not self._tokenizer._add_special_tokens\r\nAssertionError\r\n2020-06-05 15:53:37,312 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp20uyprv6\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4330", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4330/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4330/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4330/events", "html_url": "https://github.com/allenai/allennlp/issues/4330", "id": 632013863, "node_id": "MDU6SXNzdWU2MzIwMTM4NjM=", "number": 4330, "title": "Transformer tokenizers cause deadlocks when dataset reader is lazy and dataloader num_workers > 0", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/12", "html_url": "https://github.com/allenai/allennlp/milestone/12", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/12/labels", "id": 5445272, "node_id": "MDk6TWlsZXN0b25lNTQ0NTI3Mg==", "number": 12, "title": "Performance", "description": "We have a strong commitment to improve the training time of at least 3 of or models by 50%.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 8, "state": "open", "created_at": "2020-05-20T21:04:27Z", "updated_at": "2020-07-29T23:07:29Z", "due_on": "2020-08-01T07:00:00Z", "closed_at": null}, "comments": 8, "created_at": "2020-06-05T22:18:19Z", "updated_at": "2020-07-09T18:50:13Z", "closed_at": "2020-07-09T18:50:13Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "<!--\r\nPlease fill this template entirely and do not erase any of it.\r\nWe reserve the right to close without a response bug reports which are incomplete.\r\n\r\nIf you can't fill in the checklist then it's likely that this is a question, not a bug,\r\nin which case it probably belongs on our discource forum instead:\r\n\r\nhttps://discourse.allennlp.org/\r\n-->\r\n\r\n## Checklist\r\n\r\n<!-- To check an item on the list replace [ ] with [x]. -->\r\n\r\n- [x] I have verified that the issue exists against the `master` branch of AllenNLP.\r\n- [x] I have read the relevant section in the [contribution guide](https://github.com/allenai/allennlp/blob/master/CONTRIBUTING.md#bug-fixes-and-new-features) on reporting bugs.\r\n- [x] I have checked the [issues list](https://github.com/allenai/allennlp/issues) for similar or identical bug reports.\r\n- [x] I have checked the [pull requests list](https://github.com/allenai/allennlp/pulls) for existing proposed fixes.\r\n- [x] I have checked the [CHANGELOG](https://github.com/allenai/allennlp/blob/master/CHANGELOG.md) and the [commit log](https://github.com/allenai/allennlp/commits/master) to find out if the bug was already fixed in the master branch.\r\n- [x] I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\r\n- [x] I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\r\n- [x] I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\r\n- [x] I have included in the \"Environment\" section below the output of `pip freeze`.\r\n- [x] I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\r\n\r\n\r\n## Description\r\n\r\n<!-- Please provide a clear and concise description of what the bug is here. -->\r\n\r\nDataset readers that use a `PretrainedTransformerTokenizer` can cause a deadlock when used lazily and with `num_workers > 0` in the `Dataloader`.\r\n\r\n<details>\r\n<summary><b>Python traceback:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the traceback from any exception (if there was one) in between the next two lines below -->\r\n```\r\n...\r\n2020-06-05 15:04:14,980 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\r\n2020-06-05 15:04:14,980 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\r\n2020-06-05 15:04:14,980 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\r\n2020-06-05 15:04:14,980 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\r\n2020-06-05 15:04:14,982 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\r\n2020-06-05 15:04:14,982 - INFO - allennlp.training.trainer - Beginning training.\r\n2020-06-05 15:04:14,982 - INFO - allennlp.training.trainer - Epoch 0/9\r\n2020-06-05 15:04:14,982 - INFO - allennlp.training.trainer - Worker 0 memory usage MB: 3119.212\r\n2020-06-05 15:04:14,989 - INFO - allennlp.common.file_utils - checking cache for https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_dev.jsonl at /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687\r\n2020-06-05 15:04:14,989 - INFO - allennlp.common.file_utils - waiting to acquire lock on /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687\r\n2020-06-05 15:04:14,989 - INFO - filelock - Lock 140643240348696 acquired on /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687.lock\r\n2020-06-05 15:04:14,989 - INFO - allennlp.common.file_utils - cache of https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_dev.jsonl is up-to-date\r\n2020-06-05 15:04:14,989 - INFO - filelock - Lock 140643240348696 released on /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687.lock\r\n2020-06-05 15:04:14,990 - INFO - allennlp_models.pair_classification.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: /home/epwalsh/.allennlp/cache/144d0e8739288dbcde80c238baf94dde44c4ed58da59c92cf48ccce5b649574a.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687\r\n2020-06-05 15:04:15,010 - INFO - allennlp.common.file_utils - checking cache for https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl at /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92\r\n2020-06-05 15:04:15,011 - INFO - allennlp.common.file_utils - waiting to acquire lock on /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92\r\n2020-06-05 15:04:15,011 - INFO - filelock - Lock 140642731300176 acquired on /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92.lock\r\n2020-06-05 15:04:15,011 - INFO - allennlp.common.file_utils - cache of https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl is up-to-date\r\n2020-06-05 15:04:15,011 - INFO - filelock - Lock 140642731300176 released on /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92.lock\r\n2020-06-05 15:04:15,011 - INFO - allennlp_models.pair_classification.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: /home/epwalsh/.allennlp/cache/321a276d553780889b3d4276a1ce372c54c405f8e57917cdfa993feb5a0783a2.02752124e6570073d50876f7f66a32191d9787dcb992c56e79f558cebf5faf92\r\n2020-06-05 15:04:15,026 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 29\r\n2020-06-05 15:04:15,031 - INFO - allennlp.training.trainer - Training\r\n2020-06-05 15:04:15,133 - INFO - allennlp.common.file_utils - checking cache for https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl at /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484\r\n2020-06-05 15:04:15,133 - INFO - allennlp.common.file_utils - waiting to acquire lock on /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484\r\n2020-06-05 15:04:15,134 - INFO - filelock - Lock 140642730869648 acquired on /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484.lock\r\n2020-06-05 15:04:15,134 - INFO - allennlp.common.file_utils - cache of https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl is up-to-date\r\n2020-06-05 15:04:15,134 - INFO - filelock - Lock 140642730869648 released on /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484.lock\r\n2020-06-05 15:04:15,134 - INFO - allennlp_models.pair_classification.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: /home/epwalsh/.allennlp/cache/e00019e4314663e308d583b0fce3b28548b1935143669947b5642779f366dce0.a6d9333199c8569c358962009242171183a893a532b6a5267c91fd3ea0ca6484\r\n# hangs forever here\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Related issues or possible duplicates\r\n\r\n- I'm pretty sure this has to do with https://github.com/huggingface/tokenizers/issues/187\r\n\r\n\r\n## Environment\r\n\r\n<!-- Provide the name of operating system below (e.g. OS X, Linux) -->\r\nOS: Ubuntu 18.04\r\n\r\n<!-- Provide the Python version you were using (e.g. 3.7.1) -->\r\nPython version: 3.6.5\r\n\r\n<details>\r\n<summary><b>Output of <code>pip freeze</code>:</b></summary>\r\n<p>\r\n\r\n<!-- Paste the output of `pip freeze` in between the next two lines below -->\r\n```\r\naiohttp==3.6.2\r\nalabaster==0.7.11\r\n-e git+git@github.com:epwalsh/allennlp.git@902d36a520dd75fd82ebaa014799ed8fa6d02e2e#egg=allennlp\r\n-e git+git@github.com:allenai/allennlp-beaker.git@d3afc6e23ae22ea434aff6b9296f9d6e17fc2b45#egg=allennlp_beaker\r\n-e git+git@github.com:allenai/allennlp-models.git@efe66bc086c95a78c7779933b82e1382b63a3ee1#egg=allennlp_models\r\napex==0.1\r\nappdirs==1.4.3\r\nargh==0.26.2\r\nasn1crypto==0.24.0\r\naspy.yaml==1.3.0\r\nastroid==2.3.0\r\nasync-timeout==3.0.0\r\natomicwrites==1.1.5\r\nattrs==19.3.0\r\naws-xray-sdk==0.95\r\nawscli==1.18.40\r\nBabel==2.6.0\r\nbackcall==0.1.0\r\nblack==19.10b0\r\nbleach==2.1.3\r\nblis==0.4.1\r\nboto==2.49.0\r\nboto3==1.13.16\r\nbotocore==1.16.16\r\ncatalogue==1.0.0\r\ncattrs==0.9.0\r\ncertifi==2020.4.5.1\r\ncffi==1.11.5\r\ncfgv==2.0.1\r\nchardet==3.0.4\r\nclick==7.1.2\r\nclick-completion==0.5.0\r\nclick-spinner==0.1.10\r\ncodecov==2.1.3\r\ncolorama==0.3.9\r\nconllu==3.0\r\ncookies==2.2.1\r\ncoverage==5.1\r\ncoveralls==1.5.1\r\ncrayons==0.1.2\r\ncryptography==2.3.1\r\ncycler==0.10.0\r\ncymem==2.0.3\r\ncytoolz==0.9.0.1\r\ndash==1.5.1\r\ndash-auth==1.3.2\r\ndash-bootstrap-components==0.7.2\r\ndash-core-components==1.4.0\r\ndash-daq==0.1.4\r\ndash-html-components==1.0.1\r\ndash-renderer==1.2.0\r\ndash-table==4.5.0\r\ndataclasses==0.7\r\ndecorator==4.3.0\r\ndill==0.2.8.2\r\ndocker==3.5.0\r\ndocker-pycreds==0.3.0\r\ndocopt==0.6.2\r\ndocutils==0.15.2\r\necdsa==0.13\r\neditdistance==0.4\r\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\r\nentrypoints==0.3\r\nfilelock==3.0.12\r\nflake8==3.8.1\r\nflaky==3.6.1\r\nFlask==1.0.2\r\nFlask-Caching==1.7.2\r\nFlask-Compress==1.4.0\r\nFlask-Cors==3.0.7\r\nFlask-Login==0.4.1\r\nFlask-SeaSurf==0.2.2\r\nftfy==5.5.0\r\nfuture==0.18.2\r\ngevent==1.3.6\r\ngreenlet==0.4.14\r\ngunicorn==19.9.0\r\nh5py==2.10.0\r\nhide-code==0.5.2\r\nhtml5lib==1.0.1\r\nidentify==1.4.7\r\nidna==2.9\r\nidna-ssl==1.1.0\r\nimagesize==1.0.0\r\nimportlib-metadata==1.6.0\r\nimportlib-resources==1.0.2\r\ninotify==0.2.10\r\nipykernel==4.8.2\r\nipython==6.5.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.4.0\r\nisort==4.3.4\r\nitsdangerous==0.24\r\njedi==0.16.0\r\njeepney==0.4.3\r\nJinja2==2.11.1\r\njmespath==0.10.0\r\njoblib==0.15.1\r\njsondiff==1.1.1\r\njsonnet==0.16.0\r\njsonpickle==1.4.1\r\njsonschema==2.6.0\r\njupyter==1.0.0\r\njupyter-client==5.2.3\r\njupyter-console==5.2.0\r\njupyter-contrib-core==0.3.3\r\njupyter-core==4.4.0\r\njupyter-nbextensions-configurator==0.4.0\r\nkeyring==21.2.1\r\nkiwisolver==1.0.1\r\nlazy-object-proxy==1.3.1                                                                                                                                                                                  \r\nlivereload==2.5.2\r\nlunr==0.5.6\r\nMarkdown==3.2.1\r\nmarkdown-include==0.5.1\r\nMarkupSafe==1.0\r\nmathy-pydoc==0.6.7\r\nmatplotlib==3.2.1\r\nmccabe==0.6.1\r\nmistune==0.8.3\r\nmkdocs==1.1\r\nmkdocs-material==5.2.0\r\nmkdocs-material-extensions==1.0\r\nmock==2.0.0\r\nmore-itertools==8.3.0\r\nmoto==1.3.4\r\nmsgpack==0.5.6\r\nmsgpack-numpy==0.4.3.1\r\nmultidict==4.7.6\r\nmurmurhash==1.0.2\r\nmypy==0.770\r\nmypy-extensions==0.4.3\r\nnbconvert==5.3.1\r\nnbformat==4.4.0\r\nneovim==0.2.6\r\n-e git+git@github.com:epwalsh/nlp-models.git@23232ea470503e5a6453aca2bb9a22b84de6848d#egg=nlpete\r\nnltk==3.5\r\nnodeenv==1.3.3\r\nnose==1.3.7\r\nnotebook==5.6.0\r\nnr.collections==0.0.1\r\nnr.databind==0.0.4\r\nnr.databind.core==0.0.14\r\nnr.databind.json==0.0.9\r\nnr.interface==0.0.2\r\nnr.metaclass==0.0.5\r\nnr.parsing.date==0.1.0\r\nnr.pylang.utils==0.0.2\r\nnr.stream==0.0.3\r\nnumpy==1.18.4\r\nnumpydoc==0.8.0\r\nnvidia-ml-py3==7.352.0\r\noverrides==3.0.0\r\npackaging==20.4\r\npandocfilters==1.4.2\r\nparsimonious==0.8.0\r\nparso==0.6.2\r\npathspec==0.7.0\r\npathtools==0.1.2\r\npbr==4.2.0\r\npdfkit==0.6.1\r\npexpect==4.6.0\r\npickleshare==0.7.4\r\npkg-resources==0.0.0\r\npkginfo==1.4.2\r\nplac==1.1.3\r\nplotly==4.2.1                                                                                                                                                                                               [50/1861]\r\npluggy==0.13.1\r\nport-for==0.3.1\r\npre-commit==2.3.0\r\npreshed==3.0.2\r\nprometheus-client==0.3.1\r\nprompt-toolkit==1.0.15\r\nprotobuf==3.12.1\r\nptyprocess==0.6.0\r\npy==1.8.1\r\npy-rouge==1.1\r\npy3nvml==0.2.5\r\npyaml==17.12.1\r\npyasn1==0.4.4\r\npycodestyle==2.6.0\r\npycparser==2.18\r\npycryptodome==3.6.5\r\npycycle==0.0.8\r\npydoc-markdown @ git+https://github.com/NiklasRosenstein/pydoc-markdown.git@f0bf8af1db4f11581c19d206d4ed1ab34b4854c1\r\npydocstyle==5.0.2\r\npyflakes==2.2.0\r\nPygments==2.5.2\r\npylint==2.4.1\r\npymdown-extensions==7.0\r\npypandoc==1.4\r\npyparsing==2.4.7\r\npytest==5.4.2\r\npytest-cov==2.8.1\r\npython-dateutil==2.8.1\r\npython-jose==2.0.2\r\npytorch-pretrained-bert==0.6.1\r\npytz==2017.3\r\nPyYAML==5.3\r\npyzmq==17.1.2\r\nqtconsole==4.3.1\r\nreadme-renderer==26.0\r\nregex==2020.5.14\r\nregistrable==0.0.1\r\nrequests==2.23.0\r\nrequests-toolbelt==0.8.0\r\nresponses==0.10.14\r\nretrying==1.3.3\r\nrsa==3.4.2\r\nruamel.yaml==0.16.10\r\nruamel.yaml.clib==0.2.0\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-learn==0.23.1\r\nscipy==1.4.1\r\nSecretStorage==3.1.2\r\nsemantic-version==2.8.5\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.91\r\nshellingham==1.2.8\r\nsimplegeneric==0.8.1\r\nsix==1.15.0\r\nsnowballstemmer==1.2.1\r\nspacy==2.2.4\r\nSphinx==2.2.0\r\nsphinx-autobuild==0.7.1\r\nsphinx-rtd-theme==0.4.1\r\nsphinxcontrib-applehelp==1.0.1\r\nsphinxcontrib-devhelp==1.0.1\r\nsphinxcontrib-htmlhelp==1.0.2\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.2\r\nsphinxcontrib-serializinghtml==1.1.3\r\nsqlparse==0.2.4\r\nsrsly==1.0.2\r\ntensorboardX==2.0\r\nterminado==0.8.1\r\ntestpath==0.3.1\r\nthinc==7.4.0\r\nthreadpoolctl==2.0.0\r\ntokenizers==0.7.0\r\ntoml==0.10.0\r\ntoolz==0.9.0\r\ntorch==1.5.0\r\ntornado==5.1\r\ntqdm==4.46.1\r\ntraitlets==4.3.2\r\ntransformers==2.9.1\r\ntwine==3.1.1\r\ntyped-ast==1.4.0\r\ntyping==3.7.4.1\r\ntyping-extensions==3.7.4\r\nua-parser==0.8.0\r\nujson==1.35\r\nUnidecode==1.0.22\r\nurllib3==1.25.9\r\nvirtualenv==16.7.5\r\nwasabi==0.6.0\r\nwatchdog==0.10.2\r\nwcwidth==0.1.9\r\nwebencodings==0.5.1\r\nwebsocket-client==0.49.0\r\nWerkzeug==0.14.1\r\nwidgetsnbextension==3.4.0\r\nword2number==1.1\r\nwrapt==1.10.11\r\nxmltodict==0.11.0\r\nyarl==1.2.6\r\nzipp==3.1.0\r\n```\r\n\r\n</p>\r\n</details>\r\n\r\n\r\n## Steps to reproduce\r\n\r\nRun `allennlp train` on this config:\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\n<!-- Add a fully runnable example in between the next two lines below that will reproduce the bug -->\r\n```jsonnet\r\nlocal transformer_model = \"roberta-large\";\r\nlocal transformer_dim = 1024;\r\nlocal cls_is_last_token = false;\r\n\r\n{\r\n  \"dataset_reader\":{\r\n    \"type\": \"snli\",\r\n    \"lazy\": true,\r\n    \"tokenizer\": {\r\n      \"type\": \"pretrained_transformer\",\r\n      \"model_name\": transformer_model,\r\n      \"add_special_tokens\": false\r\n    },\r\n    \"token_indexers\": {\r\n      \"tokens\": {\r\n        \"type\": \"pretrained_transformer\",\r\n        \"model_name\": transformer_model,\r\n        \"max_length\": 40\r\n      }\r\n    }\r\n  },\r\n  \"train_data_path\": \"https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\",\r\n  \"validation_data_path\": \"https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_dev.jsonl\",\r\n  \"test_data_path\": \"https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\",\r\n  \"model\": {\r\n    \"type\": \"basic_classifier\",\r\n    \"text_field_embedder\": {\r\n      \"token_embedders\": {\r\n        \"tokens\": {\r\n          \"type\": \"pretrained_transformer\",\r\n          \"model_name\": transformer_model,\r\n          \"max_length\": 512\r\n        }\r\n      }\r\n    },\r\n    \"seq2vec_encoder\": {\r\n       \"type\": \"cls_pooler\",\r\n       \"embedding_dim\": transformer_dim,\r\n       \"cls_is_last_token\": cls_is_last_token\r\n    },\r\n    \"feedforward\": {\r\n      \"input_dim\": transformer_dim,\r\n      \"num_layers\": 1,\r\n      \"hidden_dims\": transformer_dim,\r\n      \"activations\": \"tanh\"\r\n    },\r\n    \"dropout\": 0.1,\r\n    \"namespace\": \"tags\"\r\n  },\r\n  \"data_loader\": {\r\n    \"batch_size\" : 8,\r\n    \"num_workers\": true,\r\n  },\r\n  \"trainer\": {\r\n    \"num_epochs\": 10,\r\n    \"cuda_device\" : -1,\r\n    \"validation_metric\": \"+accuracy\",\r\n    \"learning_rate_scheduler\": {\r\n      \"type\": \"slanted_triangular\",\r\n      \"cut_frac\": 0.06\r\n    },\r\n    \"optimizer\": {\r\n      \"type\": \"huggingface_adamw\",\r\n      \"lr\": 2e-5,\r\n      \"weight_decay\": 0.1,\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4329", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4329/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4329/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4329/events", "html_url": "https://github.com/allenai/allennlp/issues/4329", "id": 631957068, "node_id": "MDU6SXNzdWU2MzE5NTcwNjg=", "number": 4329, "title": "TransformerQA has much lower performance with mixed precision training", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/12", "html_url": "https://github.com/allenai/allennlp/milestone/12", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/12/labels", "id": 5445272, "node_id": "MDk6TWlsZXN0b25lNTQ0NTI3Mg==", "number": 12, "title": "Performance", "description": "We have a strong commitment to improve the training time of at least 3 of or models by 50%.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 2, "closed_issues": 8, "state": "open", "created_at": "2020-05-20T21:04:27Z", "updated_at": "2020-07-29T23:07:29Z", "due_on": "2020-08-01T07:00:00Z", "closed_at": null}, "comments": 2, "created_at": "2020-06-05T21:02:36Z", "updated_at": "2020-07-29T23:26:31Z", "closed_at": "2020-07-29T23:07:29Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I've run a lot of benchmarks now on the TransformerQA model both with and without mixed precision training using Apex. While using Apex does result in a significant speed up, the loss and f1 metrics are significantly worse:\r\n\r\n<img width=\"1555\" alt=\"image\" src=\"https://user-images.githubusercontent.com/8812459/83922326-fc39b600-a734-11ea-90d0-1a2dc7626376.png\">\r\n\r\nPer @matt-peters suggestion we should try training the same models with HuggingFace directly to see if we see the same results.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4326", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4326/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4326/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4326/events", "html_url": "https://github.com/allenai/allennlp/issues/4326", "id": 631756062, "node_id": "MDU6SXNzdWU2MzE3NTYwNjI=", "number": 4326, "title": "Metric logging should be sorted for readability", "user": {"login": "epwalsh", "id": 8812459, "node_id": "MDQ6VXNlcjg4MTI0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8812459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epwalsh", "html_url": "https://github.com/epwalsh", "followers_url": "https://api.github.com/users/epwalsh/followers", "following_url": "https://api.github.com/users/epwalsh/following{/other_user}", "gists_url": "https://api.github.com/users/epwalsh/gists{/gist_id}", "starred_url": "https://api.github.com/users/epwalsh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epwalsh/subscriptions", "organizations_url": "https://api.github.com/users/epwalsh/orgs", "repos_url": "https://api.github.com/users/epwalsh/repos", "events_url": "https://api.github.com/users/epwalsh/events{/privacy}", "received_events_url": "https://api.github.com/users/epwalsh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-05T16:57:38Z", "updated_at": "2020-06-05T21:06:13Z", "closed_at": "2020-06-05T21:06:13Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It would be nice if the metrics were logged in alphabetically order. It's not much of an issue on a single GPU experiment, but when training on multiple GPUs and I want to quickly look at the memory metrics, it's a little annoying trying to find what I'm looking for.\r\n\r\n<img width=\"1025\" alt=\"image\" src=\"https://user-images.githubusercontent.com/8812459/83903287-b4a23280-a712-11ea-97a8-1949d0f5c8e2.png\">", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4325", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4325/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4325/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4325/events", "html_url": "https://github.com/allenai/allennlp/issues/4325", "id": 631556515, "node_id": "MDU6SXNzdWU2MzE1NTY1MTU=", "number": 4325, "title": "OpenIE demo not working with 1.0.0rc5", "user": {"login": "FelixLabelle", "id": 23347756, "node_id": "MDQ6VXNlcjIzMzQ3NzU2", "avatar_url": "https://avatars1.githubusercontent.com/u/23347756?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FelixLabelle", "html_url": "https://github.com/FelixLabelle", "followers_url": "https://api.github.com/users/FelixLabelle/followers", "following_url": "https://api.github.com/users/FelixLabelle/following{/other_user}", "gists_url": "https://api.github.com/users/FelixLabelle/gists{/gist_id}", "starred_url": "https://api.github.com/users/FelixLabelle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FelixLabelle/subscriptions", "organizations_url": "https://api.github.com/users/FelixLabelle/orgs", "repos_url": "https://api.github.com/users/FelixLabelle/repos", "events_url": "https://api.github.com/users/FelixLabelle/events{/privacy}", "received_events_url": "https://api.github.com/users/FelixLabelle/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-05T12:34:26Z", "updated_at": "2020-06-05T16:01:37Z", "closed_at": "2020-06-05T16:01:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "## Description\r\n\r\nI'm trying to run the [OpenIE demo](https://demo.allennlp.org/open-information-extraction) with a more recent release (1.0.0rc5 instead of 1.0.0rc3). There appears to have been a change in the layout of the AllenNLP modules (syntax no longer exists).\r\n\r\nOriginally I got an error to that effect and checked the layout of the files. I replaced \"import allennlp_models.syntax.srl\" with \"allennlp_models.structured_prediction.predictors.srl\", but now get the second error listed below. I'm not familiar with the design of this API, so I figured I would ask what the correct import before going further.\r\n\r\n<details>\r\n<summary><b>Original traceback:</b></summary>\r\n<p>\r\nTraceback (most recent call last):\r\n  File \"qa_models.py\", line 4, in <module>\r\n    import allennlp_models.syntax.srl\r\nModuleNotFoundError: No module named 'allennlp_models.syntax'\r\n\r\n</p>\r\n</details>\r\n\r\n<details>\r\n<summary><b>Latest traceback:</b></summary>\r\n<p>\r\nTraceback (most recent call last):\r\n  File \"qa_models.py\", line 41, in <module>\r\n    main(args)\r\n  File \"qa_models.py\", line 31, in main\r\n    prediction = predictor.prediction(register[-5])\r\nAttributeError: 'SemanticRoleLabelerPredictor' object has no attribute 'prediction'\r\n</p>\r\n</details>\r\n\r\n## Related issues or possible duplicates\r\n\r\n- None\r\n\r\n\r\n## Environment\r\n\r\nOS: Ubuntu 18.04\r\n\r\nPython version: Python 3.7.3\r\n\r\n\r\n## Steps to reproduce\r\n\r\n\r\n<details>\r\n<summary><b>Example source:</b></summary>\r\n<p>\r\n\r\nUsing allennlp 1.0.0rc5 run the demo code.\r\n\r\n</p>\r\n</details>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4324", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4324/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4324/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4324/events", "html_url": "https://github.com/allenai/allennlp/issues/4324", "id": 631415013, "node_id": "MDU6SXNzdWU2MzE0MTUwMTM=", "number": 4324, "title": "Upper limit on dependencies versions", "user": {"login": "jankrepl", "id": 18519371, "node_id": "MDQ6VXNlcjE4NTE5Mzcx", "avatar_url": "https://avatars3.githubusercontent.com/u/18519371?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jankrepl", "html_url": "https://github.com/jankrepl", "followers_url": "https://api.github.com/users/jankrepl/followers", "following_url": "https://api.github.com/users/jankrepl/following{/other_user}", "gists_url": "https://api.github.com/users/jankrepl/gists{/gist_id}", "starred_url": "https://api.github.com/users/jankrepl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jankrepl/subscriptions", "organizations_url": "https://api.github.com/users/jankrepl/orgs", "repos_url": "https://api.github.com/users/jankrepl/repos", "events_url": "https://api.github.com/users/jankrepl/events{/privacy}", "received_events_url": "https://api.github.com/users/jankrepl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-05T08:33:10Z", "updated_at": "2020-06-05T15:49:10Z", "closed_at": "2020-06-05T15:49:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Similar issues:\r\n\r\n- #2650\r\n\r\nI was wondering why do you quite often limit the upper version of your dependencies. See below a list of all examples from the current `setup.py`\r\n\r\n- `\"torch>=1.5.0,<1.6.0\"`\r\n- `\"spacy>=2.1.0,<2.3\"`\r\n- `\"transformers>=2.9,<2.12\"`\r\n- `\"filelock>=3.0,<3.1\"`\r\n\r\nAre you just afraid that the future versions of these packages are going to break `allennlp`? Or you already somehow know they will be incompatible?\r\n\r\nIn my case, I am encountering a lot of issues because of this strategy. I want to use an older version `allennlp==0.9.0` however there you assert `'spacy>=2.1.0,<2.2'`. My other dependencies, however, require more recent `spacy>2.2`.\r\n\r\nThanks for your response!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4322", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4322/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4322/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4322/events", "html_url": "https://github.com/allenai/allennlp/issues/4322", "id": 631154490, "node_id": "MDU6SXNzdWU2MzExNTQ0OTA=", "number": 4322, "title": "Cannot predict with NAQANET on 1.0.0rc5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 3, "created_at": "2020-06-04T21:18:37Z", "updated_at": "2020-06-12T16:54:01Z", "closed_at": "2020-06-12T16:54:01Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\necho '{\"passage\": \"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\", \"question\": \"Who stars in The Matrix?\"}' | allennlp predict https://storage.googleapis.com/allennlp-public-models/naqanet-2020.02.19.tar.gz -\r\n\r\n...\r\n\r\n2020-06-04 14:17:42,669 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-04 14:17:43,325 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/naqanet-2020.02.19.tar.gz from cache at /home/michaels/.allennlp/cache/7a9f9036e6aece092be73634db952aed5f466b304b316ad42498404e9553071d.a70ea31258e5d77abb9aca4f2b160e004991c57f41ea30a877774c9e97798e42\r\n2020-06-04 14:17:43,326 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/7a9f9036e6aece092be73634db952aed5f466b304b316ad42498404e9553071d.a70ea31258e5d77abb9aca4f2b160e004991c57f41ea30a877774c9e97798e42 to temp dir /tmp/tmpbzru1koa\r\n2020-06-04 14:17:43,720 - INFO - allennlp.common.params - vocabulary.type = from_instances\r\n2020-06-04 14:17:43,720 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpbzru1koa/vocabulary.\r\n2020-06-04 14:17:43,741 - INFO - allennlp.common.params - model.type = naqanet\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.type = character_encoding\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 64\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.weight = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters\r\n2020-06-04 14:17:43,742 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 64\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 200\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [5]\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = None\r\n2020-06-04 14:17:43,743 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None\r\n2020-06-04 14:17:43,744 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0\r\n2020-06-04 14:17:43,744 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = embedding\r\n2020-06-04 14:17:43,744 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.embedding_dim = 300\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.num_embeddings = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.projection_dim = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.weight = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.padding_index = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.trainable = False\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_norm = None\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.norm_type = 2.0\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sparse = False\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens\r\n2020-06-04 14:17:43,745 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_file = None\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.num_highway_layers = 2\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.type = qanet_encoder\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.input_dim = 128\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.hidden_dim = 128\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.attention_projection_dim = 128\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.feedforward_hidden_dim = 128\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.num_blocks = 1\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.num_convs_per_block = 4\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.conv_kernel_size = 7\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.num_attention_heads = 8\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.use_positional_encoding = True\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.dropout_prob = 0.1\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.layer_dropout_undecayed_prob = 0.1\r\n2020-06-04 14:17:43,820 - INFO - allennlp.common.params - model.phrase_layer.attention_dropout_prob = 0\r\n2020-06-04 14:17:43,823 - INFO - allennlp.common.params - model.matrix_attention_layer.type = linear\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.matrix_attention_layer.tensor_1_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.matrix_attention_layer.tensor_2_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.matrix_attention_layer.combination = x,y,x*y\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.matrix_attention_layer.activation = None\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.type = qanet_encoder\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.input_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.hidden_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.attention_projection_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.feedforward_hidden_dim = 128\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.num_blocks = 6\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.num_convs_per_block = 2\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.conv_kernel_size = 5\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.num_attention_heads = 8\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.use_positional_encoding = True\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.dropout_prob = 0.1\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.layer_dropout_undecayed_prob = 0.1\r\n2020-06-04 14:17:43,824 - INFO - allennlp.common.params - model.modeling_layer.attention_dropout_prob = 0\r\n2020-06-04 14:17:43,835 - INFO - allennlp.common.params - model.dropout_prob = 0.1\r\n2020-06-04 14:17:43,836 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f3603701ad0>\r\n2020-06-04 14:17:43,836 - INFO - allennlp.common.params - model.regularizer.regexes.0.1.type = l2\r\n2020-06-04 14:17:43,836 - INFO - allennlp.common.params - model.regularizer.regexes.0.1.alpha = 1e-07\r\n2020-06-04 14:17:43,836 - INFO - allennlp.common.params - model.answering_abilities = ['passage_span_extraction', 'question_span_extraction', 'addition_subtraction', 'counting']\r\n2020-06-04 14:17:43,841 - INFO - allennlp.nn.initializers - Initializing parameters\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _answer_ability_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _count_number_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _embedding_proj_layer.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _embedding_proj_layer.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _encoding_proj_layer.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _encoding_proj_layer.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _highway_layer._layers.0.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _highway_layer._layers.0.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _highway_layer._layers.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _highway_layer._layers.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _matrix_attention._bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _matrix_attention._weight_vector\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_norm_layer.bias\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.attention_norm_layer.weight\r\n2020-06-04 14:17:43,842 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.0.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_norm_layer.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.attention_norm_layer.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.1.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_norm_layer.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.attention_norm_layer.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,843 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.2.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.attention_norm_layer.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.3.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.attention_norm_layer.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,844 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.4.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_norm_layer.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.attention_norm_layer.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_layer._encoder_blocks.5.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_proj_layer.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _modeling_proj_layer.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _number_sign_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_end_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_span_start_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _passage_weights_predictor.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.0.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.0.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.0.2.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.0.2.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.1.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.1.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.1.2.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.1.2.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.2.1.bias\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.2.1.weight\r\n2020-06-04 14:17:43,845 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.2.2.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.2.2.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.3.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.3.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.3.2.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_layers.3.2.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.2.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.2.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.3.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0._conv_norm_layers.3.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_layer._combined_projection.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_layer._combined_projection.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_layer._output_projection.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_layer._output_projection.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_norm_layer.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.attention_norm_layer.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward._linear_layers.0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward._linear_layers.0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward._linear_layers.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward._linear_layers.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward_norm_layer.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _phrase_layer._encoder_blocks.0.feedforward_norm_layer.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_end_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.1.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_span_start_predictor._linear_layers.1.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_weights_predictor.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _question_weights_predictor.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._embedding._module.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight\r\n2020-06-04 14:17:43,846 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.weight\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.type = drop\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.lazy = False\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.cache_directory = None\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer = None\r\n2020-06-04 14:17:43,908 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.type = characters\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.namespace = token_characters\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.character_tokenizer = <allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer object at 0x7f360b8897d0>\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.start_tokens = None\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.end_tokens = None\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.min_padding_length = 5\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.token_characters.token_min_padding_length = 0\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = single_id\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tokens\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.lowercase_tokens = True\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.start_tokens = None\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.end_tokens = None\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.feature_name = text\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.passage_length_limit = 1000\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.question_length_limit = 100\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.skip_when_all_empty = []\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.instance_format = drop\r\n2020-06-04 14:17:43,909 - INFO - allennlp.common.params - validation_dataset_reader.relaxed_span_match_for_finding_labels = True\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 212, in _predict\r\n    manager.run()\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 186, in run\r\n    for model_input_json, result in zip(batch_json, self._predict_json(batch_json)):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 132, in _predict_json\r\n    results = [self._predictor.predict_json(batch_data[0])]\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 47, in predict_json\r\n    instance = self._json_to_instance(inputs)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 195, in _json_to_instance\r\n    raise NotImplementedError\r\nNotImplementedError\r\n2020-06-04 14:17:44,276 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpbzru1koa\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4321", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4321/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4321/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4321/events", "html_url": "https://github.com/allenai/allennlp/issues/4321", "id": 631153622, "node_id": "MDU6SXNzdWU2MzExNTM2MjI=", "number": 4321, "title": "Cannot predict with TransformerQA on 1.0.0rc5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 7, "created_at": "2020-06-04T21:17:02Z", "updated_at": "2020-06-12T16:54:04Z", "closed_at": "2020-06-12T16:54:04Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\r\n$ echo '{\"passage\": \"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\", \"question\": \"Who stars in The Matrix?\"}' | allennlp predict https://storage.googleapis.com/allennlp-public-models/transformer-qa-2020-05-26.tar.gz -\r\n\r\n2020-06-04 14:15:44,818 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-04 14:15:45,477 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/transformer-qa-2020-05-26.tar.gz from cache at /home/michaels/.allennlp/cache/4c6eacd3c5ba190ae88644f866eb35b9e6ca10b01c15848f166fdb1b020d8a35.6bb2b04ba1dc0eb8d7e4172e5d8c72551fe73b45f947d390ba43ed25d9cce60f\r\n2020-06-04 14:15:45,478 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/4c6eacd3c5ba190ae88644f866eb35b9e6ca10b01c15848f166fdb1b020d8a35.6bb2b04ba1dc0eb8d7e4172e5d8c72551fe73b45f947d390ba43ed25d9cce60f to temp dir /tmp/tmpkl0n2lie\r\n2020-06-04 14:15:48,296 - INFO - allennlp.common.params - type = from_instances\r\n2020-06-04 14:15:48,296 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpkl0n2lie/vocabulary.\r\n2020-06-04 14:15:48,296 - INFO - allennlp.common.params - model.type = transformer_qa\r\n2020-06-04 14:15:48,296 - INFO - allennlp.common.params - model.regularizer = None\r\n2020-06-04 14:15:48,296 - INFO - allennlp.common.params - model.transformer_model_name = bert-base-cased\r\n2020-06-04 14:15:48,613 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/michaels/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\r\n2020-06-04 14:15:48,614 - INFO - transformers.configuration_utils - Model config BertConfig {\r\n  \"architectures\": [\r\n    \"BertForMaskedLM\"\r\n  ],\r\n  \"attention_probs_dropout_prob\": 0.1,\r\n  \"hidden_act\": \"gelu\",\r\n  \"hidden_dropout_prob\": 0.1,\r\n  \"hidden_size\": 768,\r\n  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 3072,\r\n  \"layer_norm_eps\": 1e-12,\r\n  \"max_position_embeddings\": 512,\r\n  \"model_type\": \"bert\",\r\n  \"num_attention_heads\": 12,\r\n  \"num_hidden_layers\": 12,\r\n  \"pad_token_id\": 0,\r\n  \"type_vocab_size\": 2,\r\n  \"vocab_size\": 28996\r\n}\r\n\r\n...\r\n\r\n2020-06-04 14:15:55,391 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/michaels/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 212, in _predict\r\n    manager.run()\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 186, in run\r\n    for model_input_json, result in zip(batch_json, self._predict_json(batch_json)):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 132, in _predict_json\r\n    results = [self._predictor.predict_json(batch_data[0])]\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 47, in predict_json\r\n    instance = self._json_to_instance(inputs)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/predictors/predictor.py\", line 195, in _json_to_instance\r\n    raise NotImplementedError\r\nNotImplementedError\r\n2020-06-04 14:15:55,419 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpkl0n2lie\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/allenai/allennlp/issues/4320", "repository_url": "https://api.github.com/repos/allenai/allennlp", "labels_url": "https://api.github.com/repos/allenai/allennlp/issues/4320/labels{/name}", "comments_url": "https://api.github.com/repos/allenai/allennlp/issues/4320/comments", "events_url": "https://api.github.com/repos/allenai/allennlp/issues/4320/events", "html_url": "https://github.com/allenai/allennlp/issues/4320", "id": 631064745, "node_id": "MDU6SXNzdWU2MzEwNjQ3NDU=", "number": 4320, "title": "Sentiment evaluate command fails on AllenNLP RC5", "user": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 605609792, "node_id": "MDU6TGFiZWw2MDU2MDk3OTI=", "url": "https://api.github.com/repos/allenai/allennlp/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "dirkgr", "id": 920638, "node_id": "MDQ6VXNlcjkyMDYzOA==", "avatar_url": "https://avatars2.githubusercontent.com/u/920638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dirkgr", "html_url": "https://github.com/dirkgr", "followers_url": "https://api.github.com/users/dirkgr/followers", "following_url": "https://api.github.com/users/dirkgr/following{/other_user}", "gists_url": "https://api.github.com/users/dirkgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/dirkgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dirkgr/subscriptions", "organizations_url": "https://api.github.com/users/dirkgr/orgs", "repos_url": "https://api.github.com/users/dirkgr/repos", "events_url": "https://api.github.com/users/dirkgr/events{/privacy}", "received_events_url": "https://api.github.com/users/dirkgr/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/allenai/allennlp/milestones/10", "html_url": "https://github.com/allenai/allennlp/milestone/10", "labels_url": "https://api.github.com/repos/allenai/allennlp/milestones/10/labels", "id": 4707383, "node_id": "MDk6TWlsZXN0b25lNDcwNzM4Mw==", "number": 10, "title": "1.0.0", "description": "We're starting to think about what a 1.0 release would look like and wanted a place to organize the work we think should be done before such a release.", "creator": {"login": "schmmd", "id": 954798, "node_id": "MDQ6VXNlcjk1NDc5OA==", "avatar_url": "https://avatars3.githubusercontent.com/u/954798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/schmmd", "html_url": "https://github.com/schmmd", "followers_url": "https://api.github.com/users/schmmd/followers", "following_url": "https://api.github.com/users/schmmd/following{/other_user}", "gists_url": "https://api.github.com/users/schmmd/gists{/gist_id}", "starred_url": "https://api.github.com/users/schmmd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/schmmd/subscriptions", "organizations_url": "https://api.github.com/users/schmmd/orgs", "repos_url": "https://api.github.com/users/schmmd/repos", "events_url": "https://api.github.com/users/schmmd/events{/privacy}", "received_events_url": "https://api.github.com/users/schmmd/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 91, "state": "closed", "created_at": "2019-09-30T20:54:42Z", "updated_at": "2020-07-09T16:33:07Z", "due_on": null, "closed_at": "2020-07-09T16:33:07Z"}, "comments": 3, "created_at": "2020-06-04T18:43:12Z", "updated_at": "2020-06-10T17:11:15Z", "closed_at": "2020-06-10T17:11:14Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "This code snippet is available on our demo.\r\n\r\n```\r\nallennlp evaluate \\\r\n>     https://storage.googleapis.com/allennlp-public-models/sst-2-basic-classifier-glove-2019.06.27.tar.gz \\\r\n>     https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt\r\n2020-06-04 11:40:50,162 - INFO - transformers.file_utils - PyTorch version 1.5.0 available.\r\n2020-06-04 11:40:50,817 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/sst-2-basic-classifier-glove-2019.06.27.tar.gz from cache at /home/michaels/.allennlp/cache/020023ed51a1aa767d7d2c0fac738b3ac0784eb6db2702ec0e35b3611284a767.bb12d8472ca5c5337beb9ee41ef6ee16ac89136ba0e49091654fb76a9ea7f44f\r\n2020-06-04 11:40:50,818 - INFO - allennlp.models.archival - extracting archive file /home/michaels/.allennlp/cache/020023ed51a1aa767d7d2c0fac738b3ac0784eb6db2702ec0e35b3611284a767.bb12d8472ca5c5337beb9ee41ef6ee16ac89136ba0e49091654fb76a9ea7f44f to temp dir /tmp/tmpzc_b8ch9\r\n2020-06-04 11:40:51,089 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpzc_b8ch9/vocabulary.\r\n2020-06-04 11:40:51,279 - INFO - allennlp.common.checks - Pytorch version: 1.5.0\r\n2020-06-04 11:40:51,280 - INFO - allennlp.commands.evaluate - Reading evaluation data from https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt\r\n0it [00:00, ?it/s]2020-06-04 11:40:51,350 - INFO - allennlp.common.file_utils - https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt not found in cache, downloading to /tmp/tmpmb5jiyiq\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 280825/280825 [00:00<00:00, 5887943.44B/s]\r\n2020-06-04 11:40:51,490 - INFO - allennlp.common.file_utils - copying /tmp/tmpmb5jiyiq to cache at /home/michaels/.allennlp/cache/a7f3236709afd54d8a52df413be2892c0fd15416570a33228b65ee62d354ef82.45cca2e5ec407e60a4e09e08a8be4e1d8457b9a63fa3e2a9c236e7475e92b5cf\r\n2020-06-04 11:40:51,491 - INFO - allennlp.common.file_utils - creating metadata file for /home/michaels/.allennlp/cache/a7f3236709afd54d8a52df413be2892c0fd15416570a33228b65ee62d354ef82.45cca2e5ec407e60a4e09e08a8be4e1d8457b9a63fa3e2a9c236e7475e92b5cf\r\n2020-06-04 11:40:51,491 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpmb5jiyiq\r\n2020-06-04 11:40:51,491 - INFO - allennlp_models.classification.dataset_readers.stanford_sentiment_tree_bank - Reading instances from lines in file at: https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt\r\n872it [00:00, 2535.57it/s]\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/params.py\", line 237, in pop\r\n    value = self.params.pop(key)\r\nKeyError: 'data_loader'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/bin/allennlp\", line 8, in <module>\r\n    sys.exit(run())\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/__main__.py\", line 19, in run\r\n    main(prog=\"allennlp\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\r\n    args.func(args)\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/commands/evaluate.py\", line 136, in evaluate_from_args\r\n    data_loader_params = config.pop(\"data_loader\")\r\n  File \"/home/michaels/miniconda2/envs/allennlp-rc5/lib/python3.7/site-packages/allennlp/common/params.py\", line 242, in pop\r\n    raise ConfigurationError(msg)\r\nallennlp.common.checks.ConfigurationError: key \"data_loader\" is required\r\n2020-06-04 11:40:51,624 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpzc_b8ch9\r\n```", "performed_via_github_app": null, "score": 1.0}]}