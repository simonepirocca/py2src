{"total_count": 62, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/tensorflow/text/issues/363", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/363/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/363/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/363/events", "html_url": "https://github.com/tensorflow/text/issues/363", "id": 679816987, "node_id": "MDU6SXNzdWU2Nzk4MTY5ODc=", "number": 363, "title": "No matching distribution found for trax & tensorflow-text and I'm on windows 10", "user": {"login": "alexsomoza", "id": 8261170, "node_id": "MDQ6VXNlcjgyNjExNzA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8261170?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexsomoza", "html_url": "https://github.com/alexsomoza", "followers_url": "https://api.github.com/users/alexsomoza/followers", "following_url": "https://api.github.com/users/alexsomoza/following{/other_user}", "gists_url": "https://api.github.com/users/alexsomoza/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexsomoza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexsomoza/subscriptions", "organizations_url": "https://api.github.com/users/alexsomoza/orgs", "repos_url": "https://api.github.com/users/alexsomoza/repos", "events_url": "https://api.github.com/users/alexsomoza/events{/privacy}", "received_events_url": "https://api.github.com/users/alexsomoza/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694859, "node_id": "MDU6TGFiZWwxMzgyNjk0ODU5", "url": "https://api.github.com/repos/tensorflow/text/labels/duplicate", "name": "duplicate", "color": "cfd3d7", "default": true, "description": "This issue or pull request already exists"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-16T20:04:10Z", "updated_at": "2020-08-21T18:34:02Z", "closed_at": "2020-08-21T18:34:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "Please, need support on Windows 10 with python 3.7 !!!!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/342", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/342/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/342/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/342/events", "html_url": "https://github.com/tensorflow/text/issues/342", "id": 665145693, "node_id": "MDU6SXNzdWU2NjUxNDU2OTM=", "number": 342, "title": "Protobuf error when building from source ", "user": {"login": "bedapisl", "id": 10141878, "node_id": "MDQ6VXNlcjEwMTQxODc4", "avatar_url": "https://avatars1.githubusercontent.com/u/10141878?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bedapisl", "html_url": "https://github.com/bedapisl", "followers_url": "https://api.github.com/users/bedapisl/followers", "following_url": "https://api.github.com/users/bedapisl/following{/other_user}", "gists_url": "https://api.github.com/users/bedapisl/gists{/gist_id}", "starred_url": "https://api.github.com/users/bedapisl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bedapisl/subscriptions", "organizations_url": "https://api.github.com/users/bedapisl/orgs", "repos_url": "https://api.github.com/users/bedapisl/repos", "events_url": "https://api.github.com/users/bedapisl/events{/privacy}", "received_events_url": "https://api.github.com/users/bedapisl/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-24T12:48:09Z", "updated_at": "2020-08-06T06:02:11Z", "closed_at": "2020-08-06T06:02:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nwhen building from sources I am getting following error:\r\n```dl-innovations1:tensorflow_text$ bazel build oss_scripts/pip_package:build_pip_package --verbose_failures\r\nWARNING: /home/pislb/.cache/bazel/_bazel_pislb/d2fe6109348acff805203e8c70522889/external/local_config_tf/BUILD:10:1: in linkstatic attribute of cc_library rule @local_config_tf//:libtensorflow_framework: setting 'linkstatic=1' is recommended if there are no object files\r\nINFO: Analyzed target //oss_scripts/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /home/pislb/packages/tensorflow_text/tensorflow_text/core/kernels/BUILD:207:1: C++ compilation of rule '//tensorflow_text/core/kernels:normalize_kernels' failed (Exit 1)\r\nIn file included from tensorflow_text/core/kernels/normalize_kernels.cc:33:0:\r\nbazel-out/k8-opt/bin/tensorflow_text/core/kernels/edit_changes.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is\r\n #error This file was generated by a newer version of protoc which is\r\n  ^~~~~\r\nbazel-out/k8-opt/bin/tensorflow_text/core/kernels/edit_changes.pb.h:13:2: error: #error incompatible with your Protocol Buffer headers. Please update\r\n #error incompatible with your Protocol Buffer headers. Please update\r\n  ^~~~~\r\nbazel-out/k8-opt/bin/tensorflow_text/core/kernels/edit_changes.pb.h:14:2: error: #error your headers.\r\n #error your headers.\r\n  ^~~~~\r\nTarget //oss_scripts/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 6.840s, Critical Path: 6.65s\r\nINFO: 25 processes: 25 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\nI installed the latest protobufs, but the problem persist.\r\n```\r\ndl-innovations1:tensorflow_text$ protoc --version\r\nlibprotoc 3.12.3\r\ndl-innovations1:tensorflow_text$ grep GOOGLE_PROTOBUF_VERSION /usr/local/include/google/protobuf/stubs/common.h\r\n#define GOOGLE_PROTOBUF_VERSION 3012003\r\n```\r\n\r\nWould someone help me with this please? Thanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/326", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/326/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/326/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/326/events", "html_url": "https://github.com/tensorflow/text/issues/326", "id": 646088932, "node_id": "MDU6SXNzdWU2NDYwODg5MzI=", "number": 326, "title": "build error", "user": {"login": "alanpurple", "id": 4515120, "node_id": "MDQ6VXNlcjQ1MTUxMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/4515120?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alanpurple", "html_url": "https://github.com/alanpurple", "followers_url": "https://api.github.com/users/alanpurple/followers", "following_url": "https://api.github.com/users/alanpurple/following{/other_user}", "gists_url": "https://api.github.com/users/alanpurple/gists{/gist_id}", "starred_url": "https://api.github.com/users/alanpurple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alanpurple/subscriptions", "organizations_url": "https://api.github.com/users/alanpurple/orgs", "repos_url": "https://api.github.com/users/alanpurple/repos", "events_url": "https://api.github.com/users/alanpurple/events{/privacy}", "received_events_url": "https://api.github.com/users/alanpurple/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-26T08:07:50Z", "updated_at": "2020-07-15T23:27:50Z", "closed_at": "2020-07-15T23:27:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "build error for tensorflow 2.2.0,2.3.0-rc.0\r\nmaster branch, with cuda 10.2\r\n\r\nusing anaconda with python 3.8.2\r\nprotobuf & libprotobuf 3.12.3\r\n\r\n```\r\nERROR: /home/wmind/repo/tftext/tensorflow_text/core/kernels/BUILD:310:18: C++ compilation of rule '//tensorflow_text/core/kernels:sentencepiece_kernels' failed (Exit 1)\r\nIn file included from tensorflow_text/core/kernels/sentencepiece_kernels.cc:23:0:\r\nbazel-out/k8-opt/bin/external/com_google_sentencepiece/src/sentencepiece.pb.h:17:2: error: #error This file was generated by an older version of protoc which is\r\n #error This file was generated by an older version of protoc which is\r\n  ^~~~~\r\nbazel-out/k8-opt/bin/external/com_google_sentencepiece/src/sentencepiece.pb.h:18:2: error: #error incompatible with your Protocol Buffer headers. Please\r\n #error incompatible with your Protocol Buffer headers. Please\r\n  ^~~~~\r\nbazel-out/k8-opt/bin/external/com_google_sentencepiece/src/sentencepiece.pb.h:19:2: error: #error regenerate this file with a newer version of protoc.\r\n #error regenerate this file with a newer version of protoc.\r\n  ^~~~~\r\nTarget //oss_scripts/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 68.145s, Critical Path: 25.44s\r\nINFO: 640 processes: 640 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/325", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/325/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/325/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/325/events", "html_url": "https://github.com/tensorflow/text/issues/325", "id": 646082324, "node_id": "MDU6SXNzdWU2NDYwODIzMjQ=", "number": 325, "title": "import error, can't use at all", "user": {"login": "alanpurple", "id": 4515120, "node_id": "MDQ6VXNlcjQ1MTUxMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/4515120?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alanpurple", "html_url": "https://github.com/alanpurple", "followers_url": "https://api.github.com/users/alanpurple/followers", "following_url": "https://api.github.com/users/alanpurple/following{/other_user}", "gists_url": "https://api.github.com/users/alanpurple/gists{/gist_id}", "starred_url": "https://api.github.com/users/alanpurple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alanpurple/subscriptions", "organizations_url": "https://api.github.com/users/alanpurple/orgs", "repos_url": "https://api.github.com/users/alanpurple/repos", "events_url": "https://api.github.com/users/alanpurple/events{/privacy}", "received_events_url": "https://api.github.com/users/alanpurple/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-26T07:55:56Z", "updated_at": "2020-07-15T23:30:26Z", "closed_at": "2020-07-15T23:30:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "installed by pip\r\n\r\nerror for tensorflow 2.2.0, 2.3.0-rc.0, and 2.4.0\r\nwith CUDA 10.2 and 11.0 both\r\n\r\n```\r\n>>> import tensorflow_text as text\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/wmind/anaconda3/lib/python3.8/site-packages/tensorflow_text/__init__.py\", line 21, in <module>\r\n    from tensorflow_text.python import metrics\r\n  File \"/home/wmind/anaconda3/lib/python3.8/site-packages/tensorflow_text/python/metrics/__init__.py\", line 20, in <module>\r\n    from tensorflow_text.python.metrics.text_similarity_metric_ops import *\r\n  File \"/home/wmind/anaconda3/lib/python3.8/site-packages/tensorflow_text/python/metrics/text_similarity_metric_ops.py\", line 28, in <module>\r\n    gen_text_similarity_metric_ops = load_library.load_op_library(resource_loader.get_path_to_datafile('_text_similarity_metric_ops.so'))\r\n  File \"/home/wmind/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 58, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/wmind/anaconda3/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/318", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/318/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/318/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/318/events", "html_url": "https://github.com/tensorflow/text/issues/318", "id": 642495723, "node_id": "MDU6SXNzdWU2NDI0OTU3MjM=", "number": 318, "title": "Implement tfds.features.text tokenizers", "user": {"login": "yashjakhotiya", "id": 26331636, "node_id": "MDQ6VXNlcjI2MzMxNjM2", "avatar_url": "https://avatars0.githubusercontent.com/u/26331636?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yashjakhotiya", "html_url": "https://github.com/yashjakhotiya", "followers_url": "https://api.github.com/users/yashjakhotiya/followers", "following_url": "https://api.github.com/users/yashjakhotiya/following{/other_user}", "gists_url": "https://api.github.com/users/yashjakhotiya/gists{/gist_id}", "starred_url": "https://api.github.com/users/yashjakhotiya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yashjakhotiya/subscriptions", "organizations_url": "https://api.github.com/users/yashjakhotiya/orgs", "repos_url": "https://api.github.com/users/yashjakhotiya/repos", "events_url": "https://api.github.com/users/yashjakhotiya/events{/privacy}", "received_events_url": "https://api.github.com/users/yashjakhotiya/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-21T05:02:13Z", "updated_at": "2020-07-15T23:31:03Z", "closed_at": "2020-07-15T23:31:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "When using tfds.load where info includes a encoder there is a deprecation warning suggesting to switch to text. But text does not have SubwordTextEncoder and other tokenizers supported by tfds.features.text. It'd be good to have them implemented here.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/317", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/317/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/317/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/317/events", "html_url": "https://github.com/tensorflow/text/issues/317", "id": 642270094, "node_id": "MDU6SXNzdWU2NDIyNzAwOTQ=", "number": 317, "title": "_text_similarity_metric_ops.so: undefined symbol", "user": {"login": "summa-code", "id": 67173950, "node_id": "MDQ6VXNlcjY3MTczOTUw", "avatar_url": "https://avatars3.githubusercontent.com/u/67173950?v=4", "gravatar_id": "", "url": "https://api.github.com/users/summa-code", "html_url": "https://github.com/summa-code", "followers_url": "https://api.github.com/users/summa-code/followers", "following_url": "https://api.github.com/users/summa-code/following{/other_user}", "gists_url": "https://api.github.com/users/summa-code/gists{/gist_id}", "starred_url": "https://api.github.com/users/summa-code/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/summa-code/subscriptions", "organizations_url": "https://api.github.com/users/summa-code/orgs", "repos_url": "https://api.github.com/users/summa-code/repos", "events_url": "https://api.github.com/users/summa-code/events{/privacy}", "received_events_url": "https://api.github.com/users/summa-code/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-06-20T00:11:33Z", "updated_at": "2020-07-15T23:30:45Z", "closed_at": "2020-07-15T23:30:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Linux Ubuntu 20.04\r\nTensorFlow installed from source latest nightly build for Cuda 11\r\nTensorFlow-text version: Latest from source\r\nPython version: 3.8.2\r\nInstalled using virtualenv? NO\r\nBazel version (if compiling from source): 3.1.0\r\nGCC/Compiler version (if compiling from source): 9.3.0\r\nCUDA/cuDNN version: 11.0\r\nGPU model and memory: GeForce RTX 2070 8G\r\n\r\nimport tensorflow-text as tx\r\n  File \"<stdin>\", line 1\r\n    import tensorflow-text as tx\r\n                     ^\r\nSyntaxError: invalid syntax\r\n>>> import tensorflow_text as tx\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/xxxxx/.virtualenvs/tf-nightly/lib/python3.8/site-packages/tensorflow_text/__init__.py\", line 21, in <module>\r\n    from tensorflow_text.python import metrics\r\n  File \"/home/xxxxx/.virtualenvs/tf-nightly/lib/python3.8/site-packages/tensorflow_text/python/metrics/__init__.py\", line 20, in <module>\r\n    from tensorflow_text.python.metrics.text_similarity_metric_ops import *\r\n  File \"/home/xxxxx/.virtualenvs/tf-nightly/lib/python3.8/site-packages/tensorflow_text/python/metrics/text_similarity_metric_ops.py\", line 28, in <module>\r\n    gen_text_similarity_metric_ops = load_library.load_op_library(resource_loader.get_path_to_datafile('_text_similarity_metric_ops.so'))\r\n  File \"/home/xxxxx/.virtualenvs/tf-nightly/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 58, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/xxxxx/.virtualenvs/tf-nightly/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl11string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS8_EE\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/315", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/315/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/315/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/315/events", "html_url": "https://github.com/tensorflow/text/issues/315", "id": 640654700, "node_id": "MDU6SXNzdWU2NDA2NTQ3MDA=", "number": 315, "title": "Demonstrating compatibility issue with TFX/ potential issue with multiple workers", "user": {"login": "tommywei110", "id": 12221646, "node_id": "MDQ6VXNlcjEyMjIxNjQ2", "avatar_url": "https://avatars3.githubusercontent.com/u/12221646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tommywei110", "html_url": "https://github.com/tommywei110", "followers_url": "https://api.github.com/users/tommywei110/followers", "following_url": "https://api.github.com/users/tommywei110/following{/other_user}", "gists_url": "https://api.github.com/users/tommywei110/gists{/gist_id}", "starred_url": "https://api.github.com/users/tommywei110/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tommywei110/subscriptions", "organizations_url": "https://api.github.com/users/tommywei110/orgs", "repos_url": "https://api.github.com/users/tommywei110/repos", "events_url": "https://api.github.com/users/tommywei110/events{/privacy}", "received_events_url": "https://api.github.com/users/tommywei110/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694859, "node_id": "MDU6TGFiZWwxMzgyNjk0ODU5", "url": "https://api.github.com/repos/tensorflow/text/labels/duplicate", "name": "duplicate", "color": "cfd3d7", "default": true, "description": "This issue or pull request already exists"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-17T18:30:52Z", "updated_at": "2020-07-15T08:16:17Z", "closed_at": "2020-06-22T19:58:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "It was found Tensorflow_text would have error:\r\n`RuntimeError: tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'RegexSplitWithOffsets' in binary running on penguin. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) tf.contrib.resampler should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed. [while running 'Analyze/ComputeDeferredMetadata'] [while running 'Run[Transform]']`\r\n\r\nAnd this error is _potentially_ caused by tf_text ops not being properly imported on multiple workers when trying to run the pipeline in parallel.\r\n\r\nIn the example code, change the parameter `direct_num_workers` to 0, would cause the error to occur as the runner would try to use multiple workers\r\n\r\nMore detail is in the repo.\r\n\r\nhttps://github.com/tommywei110/demonstrateTFX-TFText", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/313", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/313/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/313/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/313/events", "html_url": "https://github.com/tensorflow/text/issues/313", "id": 640164364, "node_id": "MDU6SXNzdWU2NDAxNjQzNjQ=", "number": 313, "title": "Protoc version error with sentencepiece", "user": {"login": "summacod", "id": 66105087, "node_id": "MDQ6VXNlcjY2MTA1MDg3", "avatar_url": "https://avatars0.githubusercontent.com/u/66105087?v=4", "gravatar_id": "", "url": "https://api.github.com/users/summacod", "html_url": "https://github.com/summacod", "followers_url": "https://api.github.com/users/summacod/followers", "following_url": "https://api.github.com/users/summacod/following{/other_user}", "gists_url": "https://api.github.com/users/summacod/gists{/gist_id}", "starred_url": "https://api.github.com/users/summacod/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/summacod/subscriptions", "organizations_url": "https://api.github.com/users/summacod/orgs", "repos_url": "https://api.github.com/users/summacod/repos", "events_url": "https://api.github.com/users/summacod/events{/privacy}", "received_events_url": "https://api.github.com/users/summacod/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-06-17T05:58:09Z", "updated_at": "2020-07-15T23:31:20Z", "closed_at": "2020-07-15T23:31:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "ERROR: /home/XXXX/Downloads/text/tensorflow_text/core/kernels/BUILD:310:18: C++ compilation of rule '//tensorflow_text/core/kernels:sentencepiece_kernels' failed (Exit 1)\r\nIn file included from tensorflow_text/core/kernels/sentencepiece_kernels.cc:23:\r\nbazel-out/k8-opt/bin/external/com_google_sentencepiece/src/sentencepiece.pb.h:17:2: error: #error This file was generated by an older version of protoc which is\r\n   17 | #error This file was generated by an older version of protoc which is\r\n      |  ^~~~~\r\nbazel-out/k8-opt/bin/external/com_google_sentencepiece/src/sentencepiece.pb.h:18:2: error: #error incompatible with your Protocol Buffer headers. Please\r\n   18 | #error incompatible with your Protocol Buffer headers. Please\r\n      |  ^~~~~\r\nbazel-out/k8-opt/bin/external/com_google_sentencepiece/src/sentencepiece.pb.h:19:2: error: #error regenerate this file with a newer version of protoc.\r\n   19 | #error regenerate this file with a newer version of protoc.\r\n      |  ^~~~~\r\nTarget //oss_scripts/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 4.338s, Critical Path: 4.10s\r\nINFO: 5 processes: 5 local.\r\nFAILED: Build did NOT complete successfully", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/311", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/311/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/311/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/311/events", "html_url": "https://github.com/tensorflow/text/issues/311", "id": 637850555, "node_id": "MDU6SXNzdWU2Mzc4NTA1NTU=", "number": 311, "title": "TFX compatibility issue Op type not registered 'RegexSplitWithOffsets' in binary", "user": {"login": "tommywei110", "id": 12221646, "node_id": "MDQ6VXNlcjEyMjIxNjQ2", "avatar_url": "https://avatars3.githubusercontent.com/u/12221646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tommywei110", "html_url": "https://github.com/tommywei110", "followers_url": "https://api.github.com/users/tommywei110/followers", "following_url": "https://api.github.com/users/tommywei110/following{/other_user}", "gists_url": "https://api.github.com/users/tommywei110/gists{/gist_id}", "starred_url": "https://api.github.com/users/tommywei110/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tommywei110/subscriptions", "organizations_url": "https://api.github.com/users/tommywei110/orgs", "repos_url": "https://api.github.com/users/tommywei110/repos", "events_url": "https://api.github.com/users/tommywei110/events{/privacy}", "received_events_url": "https://api.github.com/users/tommywei110/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-12T15:56:35Z", "updated_at": "2020-07-31T17:47:56Z", "closed_at": "2020-07-31T17:47:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/303", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/303/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/303/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/303/events", "html_url": "https://github.com/tensorflow/text/issues/303", "id": 630866932, "node_id": "MDU6SXNzdWU2MzA4NjY5MzI=", "number": 303, "title": "Dependency lib ICU checksum is incorrect", "user": {"login": "hyperloglogy", "id": 37256626, "node_id": "MDQ6VXNlcjM3MjU2NjI2", "avatar_url": "https://avatars3.githubusercontent.com/u/37256626?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hyperloglogy", "html_url": "https://github.com/hyperloglogy", "followers_url": "https://api.github.com/users/hyperloglogy/followers", "following_url": "https://api.github.com/users/hyperloglogy/following{/other_user}", "gists_url": "https://api.github.com/users/hyperloglogy/gists{/gist_id}", "starred_url": "https://api.github.com/users/hyperloglogy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hyperloglogy/subscriptions", "organizations_url": "https://api.github.com/users/hyperloglogy/orgs", "repos_url": "https://api.github.com/users/hyperloglogy/repos", "events_url": "https://api.github.com/users/hyperloglogy/events{/privacy}", "received_events_url": "https://api.github.com/users/hyperloglogy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-04T14:18:43Z", "updated_at": "2020-06-05T17:56:18Z", "closed_at": "2020-06-05T17:56:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "in the current WORKSPACE, ICU sha256 = `dfc62618aa4bd3ca14a3df548cd65fe393155edd213e49c39f3a30ccd618fc27`\r\n\r\n```\r\nhttp_archive(\r\n    name = \"icu\",\r\n    strip_prefix = \"icu-release-64-2\",\r\n    sha256 = \"dfc62618aa4bd3ca14a3df548cd65fe393155edd213e49c39f3a30ccd618fc27\",\r\n    urls = [\r\n        \"https://github.com/unicode-org/icu/archive/release-64-2.zip\",\r\n    ],\r\n    build_file = \"//third_party/icu:BUILD.bzl\",\r\n    patches = [\"//third_party/icu:udata.patch\"],\r\n    patch_args = [\"-p1\", \"-s\"],\r\n)\r\n```\r\nhowever, the real checksum is `10cd92f1585c537d937ecbb587f6c3b36a5275c87feabe05d777a828677ec32f`\r\n\r\nto verify: \r\n```\r\nwget https://github.com/unicode-org/icu/archive/release-64-2.zip\r\nshasum -a 256 ./release-64-2.zip\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/291", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/291/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/291/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/291/events", "html_url": "https://github.com/tensorflow/text/issues/291", "id": 625967771, "node_id": "MDU6SXNzdWU2MjU5Njc3NzE=", "number": 291, "title": "pip install tensorflow-text fails on windows", "user": {"login": "evyasonov", "id": 8870922, "node_id": "MDQ6VXNlcjg4NzA5MjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/8870922?v=4", "gravatar_id": "", "url": "https://api.github.com/users/evyasonov", "html_url": "https://github.com/evyasonov", "followers_url": "https://api.github.com/users/evyasonov/followers", "following_url": "https://api.github.com/users/evyasonov/following{/other_user}", "gists_url": "https://api.github.com/users/evyasonov/gists{/gist_id}", "starred_url": "https://api.github.com/users/evyasonov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/evyasonov/subscriptions", "organizations_url": "https://api.github.com/users/evyasonov/orgs", "repos_url": "https://api.github.com/users/evyasonov/repos", "events_url": "https://api.github.com/users/evyasonov/events{/privacy}", "received_events_url": "https://api.github.com/users/evyasonov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-05-27T19:23:00Z", "updated_at": "2020-07-15T23:35:39Z", "closed_at": "2020-07-15T23:35:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey\r\n\r\nSeem this issue is actual again: https://github.com/tensorflow/text/issues/89 -- it had a lot of new comments, but it was closed. So I opened this issue.\r\n\r\nI've got this error:\r\n```\r\npip install tensorflow-text\r\nERROR: Could not find a version that satisfies the requirement tensorflow-text (from versions: none)\r\nERROR: No matching distribution found for tensorflow-text\r\n```\r\n\r\n```\r\nPython:  3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)]\r\nTF Version:  2.2.0\r\nEager mode:  True\r\nHub version:  0.8.0\r\nGPU is NOT AVAILABLE\r\nWindows 10\r\n```\r\n\r\nCan you help please\r\n\r\nThanks in advance", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/284", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/284/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/284/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/284/events", "html_url": "https://github.com/tensorflow/text/issues/284", "id": 615452366, "node_id": "MDU6SXNzdWU2MTU0NTIzNjY=", "number": 284, "title": "No Python 3.8 distribution", "user": {"login": "tomweingarten", "id": 3465707, "node_id": "MDQ6VXNlcjM0NjU3MDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/3465707?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tomweingarten", "html_url": "https://github.com/tomweingarten", "followers_url": "https://api.github.com/users/tomweingarten/followers", "following_url": "https://api.github.com/users/tomweingarten/following{/other_user}", "gists_url": "https://api.github.com/users/tomweingarten/gists{/gist_id}", "starred_url": "https://api.github.com/users/tomweingarten/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tomweingarten/subscriptions", "organizations_url": "https://api.github.com/users/tomweingarten/orgs", "repos_url": "https://api.github.com/users/tomweingarten/repos", "events_url": "https://api.github.com/users/tomweingarten/events{/privacy}", "received_events_url": "https://api.github.com/users/tomweingarten/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694858, "node_id": "MDU6TGFiZWwxMzgyNjk0ODU4", "url": "https://api.github.com/repos/tensorflow/text/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2020-05-10T18:49:32Z", "updated_at": "2020-06-05T06:11:35Z", "closed_at": "2020-06-04T21:19:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Ubuntu 20.04 defaults to Python 3.8, and there are no pre-built pip packages for tensorflow-text targeting that Python version. When I try to follow the instructions to build the package, I receive the following error:\r\n\r\n```\r\n++ uname -s\r\n+ osname=Linux\r\n+ [[ Linux == \\D\\a\\r\\w\\i\\n ]]\r\n+ ./oss_scripts/configure.sh\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nWARNING: Package(s) not found: tensorflow\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nWARNING: Package(s) not found: tf-nightly\r\nInstalling tensorflow.\r\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\r\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\r\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\r\nERROR: Could not find a version that satisfies the requirement tensorflow==2.1.0 (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0)\r\nERROR: No matching distribution found for tensorflow==2.1.0\r\n+ bazel build oss_scripts/pip_package:build_pip_package\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=81\r\nINFO: Reading rc options for 'build' from /home/tom/Downloads/text/.bazelrc:\r\n  'build' options: --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --define=framework_shared_object=true --experimental_repo_remote_exec --action_env TF_HEADER_DIR=/home/tom/.local/lib/python3.8/site-packages/tensorflow/include --action_env TF_SHARED_LIBRARY_DIR=/home/tom/.local/lib/python3.8/site-packages/tensorflow --action_env TF_SHARED_LIBRARY_NAME=libtensorflow_framework.so.2\r\nERROR: Unrecognized option: --experimental_repo_remote_exec\r\n```\r\nFor reference:\r\n```\r\n$ pip freeze|grep -i tensorflow\r\nmesh-tensorflow==0.1.13\r\ntensorflow-datasets==3.1.0\r\ntensorflow-estimator==2.2.0\r\ntensorflow-gan==2.0.0\r\ntensorflow-gpu==2.2.0rc4\r\ntensorflow-hub==0.8.0\r\ntensorflow-metadata==0.21.2\r\ntensorflow-probability==0.7.0\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/281", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/281/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/281/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/281/events", "html_url": "https://github.com/tensorflow/text/issues/281", "id": 607568779, "node_id": "MDU6SXNzdWU2MDc1Njg3Nzk=", "number": 281, "title": "Cannot serve model with v2.1.1 and TF Serving 2.2.0-rc1", "user": {"login": "elmadj", "id": 30871472, "node_id": "MDQ6VXNlcjMwODcxNDcy", "avatar_url": "https://avatars0.githubusercontent.com/u/30871472?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elmadj", "html_url": "https://github.com/elmadj", "followers_url": "https://api.github.com/users/elmadj/followers", "following_url": "https://api.github.com/users/elmadj/following{/other_user}", "gists_url": "https://api.github.com/users/elmadj/gists{/gist_id}", "starred_url": "https://api.github.com/users/elmadj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elmadj/subscriptions", "organizations_url": "https://api.github.com/users/elmadj/orgs", "repos_url": "https://api.github.com/users/elmadj/repos", "events_url": "https://api.github.com/users/elmadj/events{/privacy}", "received_events_url": "https://api.github.com/users/elmadj/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2020-04-27T13:52:03Z", "updated_at": "2020-06-08T12:29:46Z", "closed_at": "2020-06-02T22:38:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there !\r\n\r\nWe're using TF Serving 2.2.0-rc1 to serve a model  which uses the BERT tokenizer (tensorflow/text version v2.1.1). TF Serving starts and shows no error about missing ops. But then, when we try to call the API, it returns: \r\n`{'error': 'U_FILE_ACCESS_ERROR: Could not retrieve ICU NFKC_CaseFold normalizer\\n\\t [[{{node CaseFoldUTF8/CaseFoldUTF8}}]]'}` .\r\n\r\nAnything we are missing when building our docker image ?\r\n\r\nHere are the logs :\r\n\r\n`2020-04-27 13:41:46.870282: I tensorflow_serving/model_servers/server_core.cc:464] Adding/updating models.\r\n2020-04-27 13:41:46.870316: I tensorflow_serving/model_servers/server_core.cc:575]  (Re-)adding model: mymodel\r\n2020-04-27 13:41:46.971922: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: mymodel version: 1}\r\n2020-04-27 13:41:46.972053: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: mymodel version: 1}\r\n2020-04-27 13:41:46.972109: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: mymodel version: 1}\r\n2020-04-27 13:41:46.972258: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /models/mymodel/1\r\n2020-04-27 13:41:47.026067: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\r\n2020-04-27 13:41:47.026114: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /models/mymodel/1\r\n2020-04-27 13:41:47.026236: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-04-27 13:41:47.108802: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\r\n2020-04-27 13:41:47.251983: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 89075712 exceeds 10% of free system memory.\r\n2020-04-27 13:41:47.558168: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /models/mymodel/1\r\n2020-04-27 13:41:47.629049: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 656807 microseconds.\r\n2020-04-27 13:41:47.638016: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /models/mymodel/1/assets.extra/tf_serving_warmup_requests\r\n2020-04-27 13:41:47.638652: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: mymodel version: 1}\r\n2020-04-27 13:41:47.640812: I tensorflow_serving/model_servers/server.cc:355] Running gRPC ModelServer at 0.0.0.0:8500 ...\r\n[warn] getaddrinfo: address family for nodename not supported\r\n2020-04-27 13:41:47.642975: I tensorflow_serving/model_servers/server.cc:375] Exporting HTTP/REST API at:localhost:8501 ...\r\n[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/278", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/278/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/278/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/278/events", "html_url": "https://github.com/tensorflow/text/issues/278", "id": 604516057, "node_id": "MDU6SXNzdWU2MDQ1MTYwNTc=", "number": 278, "title": "Use pre-trained sentencepiece model with SentencepieceTokenizer", "user": {"login": "ramji-c", "id": 12154068, "node_id": "MDQ6VXNlcjEyMTU0MDY4", "avatar_url": "https://avatars1.githubusercontent.com/u/12154068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ramji-c", "html_url": "https://github.com/ramji-c", "followers_url": "https://api.github.com/users/ramji-c/followers", "following_url": "https://api.github.com/users/ramji-c/following{/other_user}", "gists_url": "https://api.github.com/users/ramji-c/gists{/gist_id}", "starred_url": "https://api.github.com/users/ramji-c/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ramji-c/subscriptions", "organizations_url": "https://api.github.com/users/ramji-c/orgs", "repos_url": "https://api.github.com/users/ramji-c/repos", "events_url": "https://api.github.com/users/ramji-c/events{/privacy}", "received_events_url": "https://api.github.com/users/ramji-c/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-22T07:16:49Z", "updated_at": "2020-04-22T17:46:21Z", "closed_at": "2020-04-22T17:46:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to load a pre-trained sentencepiece model using the SentencepieceTokenizer, but got internal error as mentioned in issue #215 . I then made the suggested changes to read model file, but now get a unicode error show below. Any suggestions?\r\n\r\nTensorflow version: 2.1.0\r\nTensorflow text version: 2.1.1\r\nOS: MacOs 10.15.3\r\n\r\n`Traceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"/Users/rchandrasekara/anaconda3/envs/lx-sort/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 128, in read\r\n    pywrap_tensorflow.ReadFromStream(self._read_buf, length))\r\n  File \"/Users/rchandrasekara/anaconda3/envs/lx-sort/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 98, in _prepare_value\r\n    return compat.as_str_any(val)\r\n  File \"/Users/rchandrasekara/anaconda3/envs/lx-sort/lib/python3.7/site-packages/tensorflow_core/python/util/compat.py\", line 139, in as_str_any\r\n    return as_str(value)\r\n  File \"/Users/rchandrasekara/anaconda3/envs/lx-sort/lib/python3.7/site-packages/tensorflow_core/python/util/compat.py\", line 109, in as_text\r\n    return bytes_or_text.decode(encoding)\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xae in position 53: invalid start byte`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/272", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/272/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/272/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/272/events", "html_url": "https://github.com/tensorflow/text/issues/272", "id": 601267559, "node_id": "MDU6SXNzdWU2MDEyNjc1NTk=", "number": 272, "title": "mac os wheel broken for 2.2.0rc2", "user": {"login": "sylviawhoa", "id": 10911155, "node_id": "MDQ6VXNlcjEwOTExMTU1", "avatar_url": "https://avatars3.githubusercontent.com/u/10911155?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sylviawhoa", "html_url": "https://github.com/sylviawhoa", "followers_url": "https://api.github.com/users/sylviawhoa/followers", "following_url": "https://api.github.com/users/sylviawhoa/following{/other_user}", "gists_url": "https://api.github.com/users/sylviawhoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/sylviawhoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sylviawhoa/subscriptions", "organizations_url": "https://api.github.com/users/sylviawhoa/orgs", "repos_url": "https://api.github.com/users/sylviawhoa/repos", "events_url": "https://api.github.com/users/sylviawhoa/events{/privacy}", "received_events_url": "https://api.github.com/users/sylviawhoa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, {"login": "thuang513", "id": 556234, "node_id": "MDQ6VXNlcjU1NjIzNA==", "avatar_url": "https://avatars0.githubusercontent.com/u/556234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thuang513", "html_url": "https://github.com/thuang513", "followers_url": "https://api.github.com/users/thuang513/followers", "following_url": "https://api.github.com/users/thuang513/following{/other_user}", "gists_url": "https://api.github.com/users/thuang513/gists{/gist_id}", "starred_url": "https://api.github.com/users/thuang513/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thuang513/subscriptions", "organizations_url": "https://api.github.com/users/thuang513/orgs", "repos_url": "https://api.github.com/users/thuang513/repos", "events_url": "https://api.github.com/users/thuang513/events{/privacy}", "received_events_url": "https://api.github.com/users/thuang513/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2020-04-16T17:30:47Z", "updated_at": "2020-07-15T23:38:52Z", "closed_at": "2020-07-15T23:38:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm getting an error running tokenize with tensorflow-text==2.2.0rc2 that I can only reproduce on macs.\r\n(same error on rc1, and possibly earlier versions)\r\n\r\nSteps to reproduce:\r\n\r\n1. Setup:\r\n```\r\npython3 -m venv .test_venv \r\nsource .test_venv/bin/activate\r\npip install --upgrade pip\r\npip install tensorflow==2.2.0rc3\r\npip install tensorflow-text==2.2.0rc2\r\n```\r\n\r\n2. Download vocab.txt into the dir you plan to run the test:\r\n```aws s3 cp s3://models.huggingface.co/bert/bert-base-uncased-vocab.txt ./vocab.txt```\r\n\r\n3. And then run these 5 lines in python\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow_text import BertTokenizer\r\ntokenizer = BertTokenizer('./vocab.txt')\r\ntest2 = tf.convert_to_tensor(\r\n    'Hello', dtype=tf.string\r\n)\r\ntokenizer.tokenize(test2)\r\n```\r\n\r\nWorks on linux, (returns <tf.RaggedTensor [[[100]]]>) \r\nOn Mac, it throws an error. I've run on two separate macs (one with all totally fresh installs)\r\n```\r\n2020-04-16 13:18:07.892934: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at wordpiece_kernel.cc:204 : Invalid argument: Trying to access resource using the wrong type. Expected N10tensorflow6lookup15LookupInterfaceE got N10tensorflow6lookup15LookupInterfaceE\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/sylvia/Desktop/workspace/.tfvenv/lib/python3.7/site-packages/tensorflow_text/python/ops/bert_tokenizer.py\", line 222, in tokenize\r\n    return self._wordpiece_tokenizer.tokenize(tokens)\r\n  File \"/Users/sylvia/Desktop/workspace/.tfvenv/lib/python3.7/site-packages/tensorflow_text/python/ops/wordpiece_tokenizer.py\", line 100, in tokenize\r\n    subword, _, _ = self.tokenize_with_offsets(input)\r\n  File \"/Users/sylvia/Desktop/workspace/.tfvenv/lib/python3.7/site-packages/tensorflow_text/python/ops/wordpiece_tokenizer.py\", line 156, in tokenize_with_offsets\r\n    tokens.flat_values)\r\n  File \"/Users/sylvia/Desktop/workspace/.tfvenv/lib/python3.7/site-packages/tensorflow_text/python/ops/wordpiece_tokenizer.py\", line 182, in tokenize_with_offsets\r\n    **kwargs))\r\n  File \"<string>\", line 141, in wordpiece_tokenize_with_offsets\r\n  File \"/Users/sylvia/Desktop/workspace/.tfvenv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 6653, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Trying to access resource using the wrong type. Expected N10tensorflow6lookup15LookupInterfaceE got N10tensorflow6lookup15LookupInterfaceE [Op:WordpieceTokenizeWithOffsets]\r\n```\r\nrunning on python 3.7.6", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/271", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/271/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/271/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/271/events", "html_url": "https://github.com/tensorflow/text/issues/271", "id": 601153678, "node_id": "MDU6SXNzdWU2MDExNTM2Nzg=", "number": 271, "title": "Can't save and reload model that contains a text.keras.layers.ToDense layer", "user": {"login": "jasonbrancazio", "id": 22603787, "node_id": "MDQ6VXNlcjIyNjAzNzg3", "avatar_url": "https://avatars1.githubusercontent.com/u/22603787?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasonbrancazio", "html_url": "https://github.com/jasonbrancazio", "followers_url": "https://api.github.com/users/jasonbrancazio/followers", "following_url": "https://api.github.com/users/jasonbrancazio/following{/other_user}", "gists_url": "https://api.github.com/users/jasonbrancazio/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasonbrancazio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasonbrancazio/subscriptions", "organizations_url": "https://api.github.com/users/jasonbrancazio/orgs", "repos_url": "https://api.github.com/users/jasonbrancazio/repos", "events_url": "https://api.github.com/users/jasonbrancazio/events{/privacy}", "received_events_url": "https://api.github.com/users/jasonbrancazio/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "markomernick", "id": 26491096, "node_id": "MDQ6VXNlcjI2NDkxMDk2", "avatar_url": "https://avatars3.githubusercontent.com/u/26491096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markomernick", "html_url": "https://github.com/markomernick", "followers_url": "https://api.github.com/users/markomernick/followers", "following_url": "https://api.github.com/users/markomernick/following{/other_user}", "gists_url": "https://api.github.com/users/markomernick/gists{/gist_id}", "starred_url": "https://api.github.com/users/markomernick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markomernick/subscriptions", "organizations_url": "https://api.github.com/users/markomernick/orgs", "repos_url": "https://api.github.com/users/markomernick/repos", "events_url": "https://api.github.com/users/markomernick/events{/privacy}", "received_events_url": "https://api.github.com/users/markomernick/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "markomernick", "id": 26491096, "node_id": "MDQ6VXNlcjI2NDkxMDk2", "avatar_url": "https://avatars3.githubusercontent.com/u/26491096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markomernick", "html_url": "https://github.com/markomernick", "followers_url": "https://api.github.com/users/markomernick/followers", "following_url": "https://api.github.com/users/markomernick/following{/other_user}", "gists_url": "https://api.github.com/users/markomernick/gists{/gist_id}", "starred_url": "https://api.github.com/users/markomernick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markomernick/subscriptions", "organizations_url": "https://api.github.com/users/markomernick/orgs", "repos_url": "https://api.github.com/users/markomernick/repos", "events_url": "https://api.github.com/users/markomernick/events{/privacy}", "received_events_url": "https://api.github.com/users/markomernick/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2020-04-16T15:16:58Z", "updated_at": "2020-08-07T10:24:27Z", "closed_at": "2020-04-30T22:53:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "An LSTM model I created inspired by https://github.com/tensorflow/text/blob/master/examples/keras_example_174.ipynb can be successfully trained. However, I get an error when trying to save and reload it.\r\n\r\nIt turns out that even the toy model in the docstring for text.keras.layers.ToDense can't be saved and reloaded.\r\n\r\nUsing either 2.1.1 or 2.2.0-rc2:\r\n```\r\nx = tf.keras.layers.Input(shape=(None, None), ragged=True)\r\ny = text.keras.layers.ToDense(mask=True)(x)\r\ntest_model = tf.keras.Model(x, y)\r\ntest_model.save('/tmp/test_model')\r\nreloaded_test_model = tf.keras.models.load_model('/tmp/test_model')\r\n```\r\n\r\nError:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-7-990dc0115c64> in <module>()\r\n      3 test_model = tf.keras.Model(x, y)\r\n      4 test_model.save('/tmp/test_model')\r\n----> 5 reloaded_test_model = tf.keras.models.load_model('/tmp/test_model')\r\n\r\n11 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)\r\n    188     if isinstance(filepath, six.string_types):\r\n    189       loader_impl.parse_saved_model(filepath)\r\n--> 190       return saved_model_load.load(filepath, compile)\r\n    191 \r\n    192   raise IOError(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile)\r\n    114   # TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.\r\n    115   # TODO(kathywu): Add code to load from objects that contain all endpoints\r\n--> 116   model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)\r\n    117 \r\n    118   # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, loader_cls)\r\n    602       loader = loader_cls(object_graph_proto,\r\n    603                           saved_model_proto,\r\n--> 604                           export_dir)\r\n    605       root = loader.get(0)\r\n    606       if isinstance(loader, Loader):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py in __init__(self, *args, **kwargs)\r\n    186     self._models_to_reconstruct = []\r\n    187 \r\n--> 188     super(KerasObjectLoader, self).__init__(*args, **kwargs)\r\n    189 \r\n    190     # Now that the node object has been fully loaded, and the checkpoint has\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir)\r\n    121       self._concrete_functions[name] = _WrapperFunction(concrete_function)\r\n    122 \r\n--> 123     self._load_all()\r\n    124     self._restore_checkpoint()\r\n    125 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_all(self)\r\n    213 \r\n    214     # Finish setting up layers and models. See function docstring for more info.\r\n--> 215     self._finalize_objects()\r\n    216 \r\n    217   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py in _finalize_objects(self)\r\n    508 \r\n    509     # Initialize graph networks, now that layer dependencies have been resolved.\r\n--> 510     self._reconstruct_all_models()\r\n    511 \r\n    512   def _unblock_model_reconstruction(self, layer_id, layer):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py in _reconstruct_all_models(self)\r\n    526       all_initialized_models.add(model_id)\r\n    527       model, layers = self.model_layer_dependencies[model_id]\r\n--> 528       self._reconstruct_model(model_id, model, layers)\r\n    529       self._add_object_graph_edges(self._proto.nodes[model_id], model_id)\r\n    530       _finalize_config_layers([model])\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py in _reconstruct_model(self, model_id, model, layers)\r\n    562     else:\r\n    563       (inputs, outputs, created_layers) = network_lib.reconstruct_from_config(\r\n--> 564           config, created_layers={layer.name: layer for layer in layers})\r\n    565       model.__init__(inputs, outputs, name=config['name'])\r\n    566       network_lib.connect_ancillary_layers(model, created_layers)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in reconstruct_from_config(config, custom_objects, created_layers)\r\n   2022       if layer in unprocessed_nodes:\r\n   2023         for node_data in unprocessed_nodes.pop(layer):\r\n-> 2024           process_node(layer, node_data)\r\n   2025 \r\n   2026   input_tensors = []\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in process_node(layer, node_data)\r\n   1970     if input_tensors is not None:\r\n   1971       input_tensors = base_layer_utils.unnest_if_single_tensor(input_tensors)\r\n-> 1972       output_tensors = layer(input_tensors, **kwargs)\r\n   1973 \r\n   1974       # Update node index map.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    889           raise ValueError('Layer %s does not support RaggedTensors as input. '\r\n    890                            'Inputs received: %s. You can try converting your '\r\n--> 891                            'input to an uniform tensor.' % (self.name, inputs))\r\n    892 \r\n    893         graph = backend.get_graph()\r\n\r\nValueError: Layer to_dense does not support RaggedTensors as input. Inputs received: tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_3:0\", shape=(None,), dtype=float32), row_splits=Tensor(\"Placeholder_5:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_4:0\", shape=(None,), dtype=int64)). You can try converting your input to an uniform tensor.\r\n```\r\n\r\nIt's strange that the error upon reloading reports that the ToDense layer does not support RaggedTensors as input. The __init__ for the layer sets _supports_ragged_inputs to True.\r\nhttps://github.com/tensorflow/text/blob/master/tensorflow_text/python/keras/layers/todense.py#L75\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/268", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/268/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/268/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/268/events", "html_url": "https://github.com/tensorflow/text/issues/268", "id": 599358925, "node_id": "MDU6SXNzdWU1OTkzNTg5MjU=", "number": 268, "title": "install through pip with tensorflow gpu", "user": {"login": "anirudhraju", "id": 1093615, "node_id": "MDQ6VXNlcjEwOTM2MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1093615?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anirudhraju", "html_url": "https://github.com/anirudhraju", "followers_url": "https://api.github.com/users/anirudhraju/followers", "following_url": "https://api.github.com/users/anirudhraju/following{/other_user}", "gists_url": "https://api.github.com/users/anirudhraju/gists{/gist_id}", "starred_url": "https://api.github.com/users/anirudhraju/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anirudhraju/subscriptions", "organizations_url": "https://api.github.com/users/anirudhraju/orgs", "repos_url": "https://api.github.com/users/anirudhraju/repos", "events_url": "https://api.github.com/users/anirudhraju/events{/privacy}", "received_events_url": "https://api.github.com/users/anirudhraju/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694859, "node_id": "MDU6TGFiZWwxMzgyNjk0ODU5", "url": "https://api.github.com/repos/tensorflow/text/labels/duplicate", "name": "duplicate", "color": "cfd3d7", "default": true, "description": "This issue or pull request already exists"}], "state": "closed", "locked": false, "assignee": {"login": "thuang513", "id": 556234, "node_id": "MDQ6VXNlcjU1NjIzNA==", "avatar_url": "https://avatars0.githubusercontent.com/u/556234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thuang513", "html_url": "https://github.com/thuang513", "followers_url": "https://api.github.com/users/thuang513/followers", "following_url": "https://api.github.com/users/thuang513/following{/other_user}", "gists_url": "https://api.github.com/users/thuang513/gists{/gist_id}", "starred_url": "https://api.github.com/users/thuang513/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thuang513/subscriptions", "organizations_url": "https://api.github.com/users/thuang513/orgs", "repos_url": "https://api.github.com/users/thuang513/repos", "events_url": "https://api.github.com/users/thuang513/events{/privacy}", "received_events_url": "https://api.github.com/users/thuang513/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "thuang513", "id": 556234, "node_id": "MDQ6VXNlcjU1NjIzNA==", "avatar_url": "https://avatars0.githubusercontent.com/u/556234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thuang513", "html_url": "https://github.com/thuang513", "followers_url": "https://api.github.com/users/thuang513/followers", "following_url": "https://api.github.com/users/thuang513/following{/other_user}", "gists_url": "https://api.github.com/users/thuang513/gists{/gist_id}", "starred_url": "https://api.github.com/users/thuang513/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thuang513/subscriptions", "organizations_url": "https://api.github.com/users/thuang513/orgs", "repos_url": "https://api.github.com/users/thuang513/repos", "events_url": "https://api.github.com/users/thuang513/events{/privacy}", "received_events_url": "https://api.github.com/users/thuang513/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-04-14T07:32:23Z", "updated_at": "2020-06-06T00:57:13Z", "closed_at": "2020-06-06T00:57:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "What's the best way to pip install tensorflow_text with an existing tensorflow gpu wheel already installed?\r\n\r\nI'm running the below command, but it seems to be looking for tensorflow CPU installation only.  \r\n`pip install tensorflow_text-2.0.0-cp36-cp36m-manylinux1_x86_64.whl  -f wheels/ --no-index -v `\r\nThe wheels/ dir above has all of the tensorflow-gpu related wheels and obtained through pip download tensorflow-gpu\r\n\r\nNote that directly installing tensorflow_text seems to install the CPU version of tensorflow\r\n\r\nError message:\r\n```\r\n  Skipping link file://wheels/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/decorator-4.4.2-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/opt_einsum-3.1.0.tar.gz; Missing project version for tensorflow\r\n  Skipping link file://wheels/setuptools-41.4.0-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/astor-0.8.0-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/Markdown-3.1.1-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/absl-py-0.8.0.tar.gz; Missing project version for tensorflow\r\n  Skipping link file://wheels/cloudpickle-1.1.1-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/gast-0.2.2.tar.gz; Missing project version for tensorflow\r\n  Skipping link file://wheels/six-1.12.0-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/wrapt-1.11.2.tar.gz; Missing project version for tensorflow\r\n  Skipping link file://wheels/tensorflow_probability-0.8.0-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/tensorflow_addons-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/protobuf-3.10.0-cp36-cp36m-manylinux1_x86_64.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/Werkzeug-0.16.0-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/tensorboard-2.0.0-py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/wheel-0.33.6-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/pip-19.0.1-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/Keras_Applications-1.0.8-py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/google_pasta-0.1.7-py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/tensorflow_text-2.0.0-cp36-cp36m-manylinux1_x86_64.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/termcolor-1.1.0.tar.gz; Missing project version for tensorflow\r\n  Skipping link file://wheels/tensorflow_estimator-2.0.0-py2.py3-none-any.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/grpcio-1.24.1-cp36-cp36m-manylinux1_x86_64.whl; wrong project name (not tensorflow)\r\n  Skipping link file://wheels/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl; wrong project name (not tensorflow)\r\n  Could not find a version that satisfies the requirement tensorflow<2.1,>=2.0.0 (from tensorflow-text==2.0.0) (from versions: )\r\nCleaning up...\r\nRemoved build tracker '/storage/tmp/pip-req-tracker-4zv0mcxe'\r\nNo matching distribution found for tensorflow<2.1,>=2.0.0 (from tensorflow-text==2.0.0)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/261", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/261/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/261/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/261/events", "html_url": "https://github.com/tensorflow/text/issues/261", "id": 592796922, "node_id": "MDU6SXNzdWU1OTI3OTY5MjI=", "number": 261, "title": "`Op type not registered RegexSplitWithOffsets` when running TF Text v1.15.1 in TF Transform component via Kubeflow", "user": {"login": "jshph", "id": 6334450, "node_id": "MDQ6VXNlcjYzMzQ0NTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/6334450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jshph", "html_url": "https://github.com/jshph", "followers_url": "https://api.github.com/users/jshph/followers", "following_url": "https://api.github.com/users/jshph/following{/other_user}", "gists_url": "https://api.github.com/users/jshph/gists{/gist_id}", "starred_url": "https://api.github.com/users/jshph/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jshph/subscriptions", "organizations_url": "https://api.github.com/users/jshph/orgs", "repos_url": "https://api.github.com/users/jshph/repos", "events_url": "https://api.github.com/users/jshph/events{/privacy}", "received_events_url": "https://api.github.com/users/jshph/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694859, "node_id": "MDU6TGFiZWwxMzgyNjk0ODU5", "url": "https://api.github.com/repos/tensorflow/text/labels/duplicate", "name": "duplicate", "color": "cfd3d7", "default": true, "description": "This issue or pull request already exists"}, {"id": 1382694861, "node_id": "MDU6TGFiZWwxMzgyNjk0ODYx", "url": "https://api.github.com/repos/tensorflow/text/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "thuang513", "id": 556234, "node_id": "MDQ6VXNlcjU1NjIzNA==", "avatar_url": "https://avatars0.githubusercontent.com/u/556234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thuang513", "html_url": "https://github.com/thuang513", "followers_url": "https://api.github.com/users/thuang513/followers", "following_url": "https://api.github.com/users/thuang513/following{/other_user}", "gists_url": "https://api.github.com/users/thuang513/gists{/gist_id}", "starred_url": "https://api.github.com/users/thuang513/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thuang513/subscriptions", "organizations_url": "https://api.github.com/users/thuang513/orgs", "repos_url": "https://api.github.com/users/thuang513/repos", "events_url": "https://api.github.com/users/thuang513/events{/privacy}", "received_events_url": "https://api.github.com/users/thuang513/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "thuang513", "id": 556234, "node_id": "MDQ6VXNlcjU1NjIzNA==", "avatar_url": "https://avatars0.githubusercontent.com/u/556234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thuang513", "html_url": "https://github.com/thuang513", "followers_url": "https://api.github.com/users/thuang513/followers", "following_url": "https://api.github.com/users/thuang513/following{/other_user}", "gists_url": "https://api.github.com/users/thuang513/gists{/gist_id}", "starred_url": "https://api.github.com/users/thuang513/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thuang513/subscriptions", "organizations_url": "https://api.github.com/users/thuang513/orgs", "repos_url": "https://api.github.com/users/thuang513/repos", "events_url": "https://api.github.com/users/thuang513/events{/privacy}", "received_events_url": "https://api.github.com/users/thuang513/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-04-02T17:20:20Z", "updated_at": "2020-07-15T23:41:01Z", "closed_at": "2020-07-15T23:41:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have installed TF Text v1.15.1 on Kubeflow (and Dataflow workers) and am running `BertTokenizer.tokenize` in a TF Transform component. I get the error `Op type not registered 'RegexSplitWithOffsets'`; here is a partial stack trace from Kubeflow logs:\r\n```\r\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 462, in process\r\n    lambda: self._make_graph_state(saved_model_dir))\r\n  File \"/usr/local/lib/python3.6/site-packages/tfx_bsl/beam/shared.py\", line 221, in acquire\r\n    return _shared_map.acquire(self._key, constructor_fn)\r\n  File \"/usr/local/lib/python3.6/site-packages/tfx_bsl/beam/shared.py\", line 184, in acquire\r\n    result = control_block.acquire(constructor_fn)\r\n  File \"/usr/local/lib/python3.6/site-packages/tfx_bsl/beam/shared.py\", line 87, in acquire\r\n    result = constructor_fn()\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 462, in <lambda>\r\n    lambda: self._make_graph_state(saved_model_dir))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 438, in _make_graph_state\r\n    self._exclude_outputs, self._tf_config)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 341, in __init__\r\n    saved_model_dir, {}))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_transform/saved/saved_transform_io.py\", line 397, in partially_apply_saved_transform_internal\r\n    saved_model_dir, logical_input_map, tensor_replacement_map)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_transform/saved/saved_transform_io.py\", line 240, in _partially_apply_saved_transform_impl\r\n    input_map=input_map)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1453, in import_meta_graph\r\n    **kwargs)[0]\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\r\n    **kwargs))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\r\n    return_elements=return_elements)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\r\n    producer_op_list=producer_op_list)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 501, in _import_graph_def_internal\r\n    graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\nRuntimeError: tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'RegexSplitWithOffsets' in binary\r\n```\r\nI am running this on Tensorflow 1.15.2 and TF Transform 0.15.0.\r\n\r\nWhen I run the transform using a local Beam graph, it runs without issue and writes out TF records to disk. I install tensorflow-text on the Dataflow workers by supplying an `--extra_package` arg. I'm getting no error issues in worker startup logs that the package failed to install. But I am curious if all was done that's necessary to setup tensorflow-text on these workers.\r\n\r\nReverting to v1.15.0rc0 also reverts the `regex_split_ops` in question, but even after fixing the issue with `merge_dims` I get an issue with `UnicodeScriptTokenizeWithOffsets` op type not registered.\r\n\r\nI'm eager to get TF Text running in our production Kubeflow pipeline, but I'm a little out of ideas and would appreciate insights!!\r\n\r\nI have filed an issue in TF Transform here: https://github.com/tensorflow/transform/issues/170\r\nTagging @andrewsmartin who has helped me debug internally.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/258", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/258/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/258/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/258/events", "html_url": "https://github.com/tensorflow/text/issues/258", "id": 591344363, "node_id": "MDU6SXNzdWU1OTEzNDQzNjM=", "number": 258, "title": "Could not find a version that satisfies the requirement tensorflow-text==1.15.0", "user": {"login": "danyaljj", "id": 2441454, "node_id": "MDQ6VXNlcjI0NDE0NTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/2441454?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danyaljj", "html_url": "https://github.com/danyaljj", "followers_url": "https://api.github.com/users/danyaljj/followers", "following_url": "https://api.github.com/users/danyaljj/following{/other_user}", "gists_url": "https://api.github.com/users/danyaljj/gists{/gist_id}", "starred_url": "https://api.github.com/users/danyaljj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danyaljj/subscriptions", "organizations_url": "https://api.github.com/users/danyaljj/orgs", "repos_url": "https://api.github.com/users/danyaljj/repos", "events_url": "https://api.github.com/users/danyaljj/events{/privacy}", "received_events_url": "https://api.github.com/users/danyaljj/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "kevinbrooks-g", "id": 44984821, "node_id": "MDQ6VXNlcjQ0OTg0ODIx", "avatar_url": "https://avatars1.githubusercontent.com/u/44984821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevinbrooks-g", "html_url": "https://github.com/kevinbrooks-g", "followers_url": "https://api.github.com/users/kevinbrooks-g/followers", "following_url": "https://api.github.com/users/kevinbrooks-g/following{/other_user}", "gists_url": "https://api.github.com/users/kevinbrooks-g/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevinbrooks-g/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevinbrooks-g/subscriptions", "organizations_url": "https://api.github.com/users/kevinbrooks-g/orgs", "repos_url": "https://api.github.com/users/kevinbrooks-g/repos", "events_url": "https://api.github.com/users/kevinbrooks-g/events{/privacy}", "received_events_url": "https://api.github.com/users/kevinbrooks-g/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "kevinbrooks-g", "id": 44984821, "node_id": "MDQ6VXNlcjQ0OTg0ODIx", "avatar_url": "https://avatars1.githubusercontent.com/u/44984821?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevinbrooks-g", "html_url": "https://github.com/kevinbrooks-g", "followers_url": "https://api.github.com/users/kevinbrooks-g/followers", "following_url": "https://api.github.com/users/kevinbrooks-g/following{/other_user}", "gists_url": "https://api.github.com/users/kevinbrooks-g/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevinbrooks-g/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevinbrooks-g/subscriptions", "organizations_url": "https://api.github.com/users/kevinbrooks-g/orgs", "repos_url": "https://api.github.com/users/kevinbrooks-g/repos", "events_url": "https://api.github.com/users/kevinbrooks-g/events{/privacy}", "received_events_url": "https://api.github.com/users/kevinbrooks-g/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-03-31T18:57:09Z", "updated_at": "2020-07-28T14:53:33Z", "closed_at": "2020-06-06T01:27:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Am getting the following error while trying to use your package along with TF 1.15: \r\n```\r\n$ pip install tensorflow-text==1.15.0\r\nERROR: Could not find a version that satisfies the requirement tensorflow-text==1.15.0 (from versions: 0.1.0rc2, 0.1.0, 1.0.0b0, 1.0.0b2, 1.15.0rc0, 1.15.1, 2.0.0rc0, 2.0.1, 2.1.0rc0, 2.1.1, 2.2.0rc1)\r\nERROR: No matching distribution found for tensorflow-text==1.15.0\r\n```\r\nDespite knowing that this version does really exist:  https://pypi.org/project/tensorflow-text/1.15.0/\r\nAny thoughts what's going on here? \r\n\r\nHere my environment information: \r\n```\r\n $ pip --version\r\npip 20.0.2 from /Users/danielk/opt/anaconda3/envs/py367/lib/python3.6/site-packages/pip (python 3.6)\r\n\r\n$ python --version\r\nPython 3.6.7 :: Anaconda, Inc.\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/251", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/251/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/251/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/251/events", "html_url": "https://github.com/tensorflow/text/issues/251", "id": 585210575, "node_id": "MDU6SXNzdWU1ODUyMTA1NzU=", "number": 251, "title": "Unable to install latest version (2.2.0rc1)?", "user": {"login": "sakinaljana", "id": 2888190, "node_id": "MDQ6VXNlcjI4ODgxOTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/2888190?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sakinaljana", "html_url": "https://github.com/sakinaljana", "followers_url": "https://api.github.com/users/sakinaljana/followers", "following_url": "https://api.github.com/users/sakinaljana/following{/other_user}", "gists_url": "https://api.github.com/users/sakinaljana/gists{/gist_id}", "starred_url": "https://api.github.com/users/sakinaljana/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sakinaljana/subscriptions", "organizations_url": "https://api.github.com/users/sakinaljana/orgs", "repos_url": "https://api.github.com/users/sakinaljana/repos", "events_url": "https://api.github.com/users/sakinaljana/events{/privacy}", "received_events_url": "https://api.github.com/users/sakinaljana/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-03-20T17:09:02Z", "updated_at": "2020-04-24T18:12:42Z", "closed_at": "2020-04-24T18:12:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi TF-text team,\r\n\r\nI'm trying to install the library using pip for the latest version (`2.2.0rc1`), but couldn't find any matching distribution. I'm using Python 3.7 and pip 20.0.2. The full errors is below\r\n\r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow-text==2.2.0rc1 (from versions: 0.1.0, 1.0.0b0, 1.0.0b1, 1.0.0b2, 1.15.0rc0, 1.15.1, 2.0.0rc0, 2.0.1, 2.1.0rc0)\r\nERROR: No matching distribution found for tensorflow-text==2.2.0rc1\r\n```\r\n\r\nFrom the [pypi](https://pypi.org/project/tensorflow-text/2.2.0rc1/) should be available, but why pip unable to find it. Any idea?\r\n\r\nThanks before", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/243", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/243/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/243/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/243/events", "html_url": "https://github.com/tensorflow/text/issues/243", "id": 581495611, "node_id": "MDU6SXNzdWU1ODE0OTU2MTE=", "number": 243, "title": "2.2.0-rc0 Release", "user": {"login": "terrykong", "id": 7576060, "node_id": "MDQ6VXNlcjc1NzYwNjA=", "avatar_url": "https://avatars3.githubusercontent.com/u/7576060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/terrykong", "html_url": "https://github.com/terrykong", "followers_url": "https://api.github.com/users/terrykong/followers", "following_url": "https://api.github.com/users/terrykong/following{/other_user}", "gists_url": "https://api.github.com/users/terrykong/gists{/gist_id}", "starred_url": "https://api.github.com/users/terrykong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/terrykong/subscriptions", "organizations_url": "https://api.github.com/users/terrykong/orgs", "repos_url": "https://api.github.com/users/terrykong/repos", "events_url": "https://api.github.com/users/terrykong/events{/privacy}", "received_events_url": "https://api.github.com/users/terrykong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-15T03:48:56Z", "updated_at": "2020-03-17T20:53:01Z", "closed_at": "2020-03-17T20:53:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Howdy,\r\n\r\nCan we expect a 2.2.0-rc0 release anytime soon?\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/232", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/232/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/232/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/232/events", "html_url": "https://github.com/tensorflow/text/issues/232", "id": 575964391, "node_id": "MDU6SXNzdWU1NzU5NjQzOTE=", "number": 232, "title": "KeyError: 'WhitespaceTokenizeWithOffsets'  when trying to run SavedModel ", "user": {"login": "17patelumang", "id": 6100731, "node_id": "MDQ6VXNlcjYxMDA3MzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/6100731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/17patelumang", "html_url": "https://github.com/17patelumang", "followers_url": "https://api.github.com/users/17patelumang/followers", "following_url": "https://api.github.com/users/17patelumang/following{/other_user}", "gists_url": "https://api.github.com/users/17patelumang/gists{/gist_id}", "starred_url": "https://api.github.com/users/17patelumang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/17patelumang/subscriptions", "organizations_url": "https://api.github.com/users/17patelumang/orgs", "repos_url": "https://api.github.com/users/17patelumang/repos", "events_url": "https://api.github.com/users/17patelumang/events{/privacy}", "received_events_url": "https://api.github.com/users/17patelumang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-05T03:18:04Z", "updated_at": "2020-04-24T18:15:38Z", "closed_at": "2020-04-24T18:15:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm using this for simple tokenization in text classifier model. When I try to run my model from SavedModel export file, I get this error: KeyError: 'WhitespaceTokenizeWithOffsets'\r\n\r\n    TF: 1.14.0\r\n    TF-text: 0.1.0\r\n\r\nError:\r\n   KeyError: 'WhitespaceTokenizeWithOffsets'\r\n\r\nWhen I do \"import tensorflow_text\" it works . \r\n\r\n\r\nHaving read different blogs and issues on tensorflow/text and tensorflow/serving git repo , I found that issue was TF Text ops is not included in core graph . \r\n\r\nFrom https://github.com/tensorflow/serving/issues/1490  including .so explicitly in Java at run time using throws segmentation fault . \r\n\r\nReading the reply from issue here - https://github.com/tensorflow/text/issues/130 , there was no code of Java provided where adding .so file explicitly we are able to solve this issue. Is there any java code available ?  \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/227", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/227/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/227/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/227/events", "html_url": "https://github.com/tensorflow/text/issues/227", "id": 571567102, "node_id": "MDU6SXNzdWU1NzE1NjcxMDI=", "number": 227, "title": "Raspberry Pi Support", "user": {"login": "michaelnhw", "id": 6496769, "node_id": "MDQ6VXNlcjY0OTY3Njk=", "avatar_url": "https://avatars0.githubusercontent.com/u/6496769?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelnhw", "html_url": "https://github.com/michaelnhw", "followers_url": "https://api.github.com/users/michaelnhw/followers", "following_url": "https://api.github.com/users/michaelnhw/following{/other_user}", "gists_url": "https://api.github.com/users/michaelnhw/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelnhw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelnhw/subscriptions", "organizations_url": "https://api.github.com/users/michaelnhw/orgs", "repos_url": "https://api.github.com/users/michaelnhw/repos", "events_url": "https://api.github.com/users/michaelnhw/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelnhw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-02-26T18:15:05Z", "updated_at": "2020-03-17T20:56:41Z", "closed_at": "2020-03-17T20:56:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Build from source is currently broken on Raspberry pi. When I tried to build using bazel, the following error occurs:\r\n\r\n/root/.cache/bazel/_bazel_root/7ca663d4ab74a0b23905915c5a09aeae/external/com_goo\r\ngle_absl/absl/strings/BUILD.bazel:83:1: C++ compilation of rule '@com_google_absl//absl\r\n/strings:internal' failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"external/org_tensorflow/third_party/toolchains/preconfig/ubuntu16.04/gcc7_manyl\r\ninux2010-nvcc-cuda10.0/clang/bin/crosstool_wrapper_driver_is_not_gcc\", line 272, in <mo\r\ndule>\r\n    sys.exit(main())\r\n  File \"external/org_tensorflow/third_party/toolchains/preconfig/ubuntu16.04/gcc7_manylinux2010-nvcc-cuda10.0/clang/bin/crosstool_wrapper_driver_is_not_gcc\", line 269, in main\r\n    return subprocess.call([CPU_COMPILER] + cpu_compiler_flags)\r\n  File \"/usr/lib/python3.7/subprocess.py\", line 323, in call\r\n    with Popen(*popenargs, **kwargs) as p:\r\n  File \"/usr/lib/python3.7/subprocess.py\", line 775, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"/usr/lib/python3.7/subprocess.py\", line 1522, in _execute_child\r\n    raise child_exception_type(errno_num, err_msg, err_filename)\r\nFileNotFoundError: [Errno 2] No such file or directory: '/dt7/usr/bin/gcc': '/dt7/usr/bin/gcc'\r\nTarget //oss_scripts/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 0.979s, Critical Path: 0.47s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n\r\nThe compilation process seems to rely on some cuda gcc. The procedure I used for building is as following:\r\n\r\n1. bash oss_scripts/configure.sh\r\n2. remove these 2 lines from WORKSPACE as they are causing patch error: patches = [\"//third_party/icu:udata.patch\"], patch_args = [\"-p1\"]\r\n3. bazel build oss_scripts/pip_package:build_pip_package\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/225", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/225/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/225/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/225/events", "html_url": "https://github.com/tensorflow/text/issues/225", "id": 566864734, "node_id": "MDU6SXNzdWU1NjY4NjQ3MzQ=", "number": 225, "title": "No matching distribution found for tensorflow-text on Windows 10", "user": {"login": "antoinecomp", "id": 9776965, "node_id": "MDQ6VXNlcjk3NzY5NjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/9776965?v=4", "gravatar_id": "", "url": "https://api.github.com/users/antoinecomp", "html_url": "https://github.com/antoinecomp", "followers_url": "https://api.github.com/users/antoinecomp/followers", "following_url": "https://api.github.com/users/antoinecomp/following{/other_user}", "gists_url": "https://api.github.com/users/antoinecomp/gists{/gist_id}", "starred_url": "https://api.github.com/users/antoinecomp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/antoinecomp/subscriptions", "organizations_url": "https://api.github.com/users/antoinecomp/orgs", "repos_url": "https://api.github.com/users/antoinecomp/repos", "events_url": "https://api.github.com/users/antoinecomp/events{/privacy}", "received_events_url": "https://api.github.com/users/antoinecomp/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694859, "node_id": "MDU6TGFiZWwxMzgyNjk0ODU5", "url": "https://api.github.com/repos/tensorflow/text/labels/duplicate", "name": "duplicate", "color": "cfd3d7", "default": true, "description": "This issue or pull request already exists"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-18T12:37:50Z", "updated_at": "2020-02-25T18:58:30Z", "closed_at": "2020-02-25T18:58:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I try to download `tensorflow-text` I have the error message `No matching distribution found for tensorflow-text` and I'm on windows 10. I can't use tensorflow-text yeton Windows, right?\r\n\r\n```\r\n(seg_env) C:\\Users\\antoi\\Documents\\Programming\\Covent Garden\\Segmentation>python -m pip install tensorflow-text\r\nERROR: Could not find a version that satisfies the requirement tensorflow-text (from versions: none)\r\nERROR: No matching distribution found for tensorflow-text\r\n```\r\n\r\ntensorflow 2.1.0\r\nPython 3.6.7", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/224", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/224/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/224/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/224/events", "html_url": "https://github.com/tensorflow/text/issues/224", "id": 563921530, "node_id": "MDU6SXNzdWU1NjM5MjE1MzA=", "number": 224, "title": "Error on saving keras custom layer with tensorflow_text.BertTokenizer", "user": {"login": "galfridman", "id": 15233194, "node_id": "MDQ6VXNlcjE1MjMzMTk0", "avatar_url": "https://avatars2.githubusercontent.com/u/15233194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/galfridman", "html_url": "https://github.com/galfridman", "followers_url": "https://api.github.com/users/galfridman/followers", "following_url": "https://api.github.com/users/galfridman/following{/other_user}", "gists_url": "https://api.github.com/users/galfridman/gists{/gist_id}", "starred_url": "https://api.github.com/users/galfridman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/galfridman/subscriptions", "organizations_url": "https://api.github.com/users/galfridman/orgs", "repos_url": "https://api.github.com/users/galfridman/repos", "events_url": "https://api.github.com/users/galfridman/events{/privacy}", "received_events_url": "https://api.github.com/users/galfridman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "markomernick", "id": 26491096, "node_id": "MDQ6VXNlcjI2NDkxMDk2", "avatar_url": "https://avatars3.githubusercontent.com/u/26491096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markomernick", "html_url": "https://github.com/markomernick", "followers_url": "https://api.github.com/users/markomernick/followers", "following_url": "https://api.github.com/users/markomernick/following{/other_user}", "gists_url": "https://api.github.com/users/markomernick/gists{/gist_id}", "starred_url": "https://api.github.com/users/markomernick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markomernick/subscriptions", "organizations_url": "https://api.github.com/users/markomernick/orgs", "repos_url": "https://api.github.com/users/markomernick/repos", "events_url": "https://api.github.com/users/markomernick/events{/privacy}", "received_events_url": "https://api.github.com/users/markomernick/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "markomernick", "id": 26491096, "node_id": "MDQ6VXNlcjI2NDkxMDk2", "avatar_url": "https://avatars3.githubusercontent.com/u/26491096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markomernick", "html_url": "https://github.com/markomernick", "followers_url": "https://api.github.com/users/markomernick/followers", "following_url": "https://api.github.com/users/markomernick/following{/other_user}", "gists_url": "https://api.github.com/users/markomernick/gists{/gist_id}", "starred_url": "https://api.github.com/users/markomernick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markomernick/subscriptions", "organizations_url": "https://api.github.com/users/markomernick/orgs", "repos_url": "https://api.github.com/users/markomernick/repos", "events_url": "https://api.github.com/users/markomernick/events{/privacy}", "received_events_url": "https://api.github.com/users/markomernick/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 19, "created_at": "2020-02-12T11:02:06Z", "updated_at": "2020-07-29T07:06:52Z", "closed_at": "2020-07-28T22:35:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "Trying so save a keras custom layers with tokenizer in it fails\r\nversions info: \r\n\r\n> tensorflow==2.1.0\r\n> tensorflow-text==2.1.1\r\n\r\nCode to reproduce:\r\n```\r\n\r\nimport tensorflow_text\r\nimport tensorflow as tf\r\n\r\n\r\nclass TokenizationLayer(tf.keras.layers.Layer):\r\n    def __init__(self, vocab_path, **kwargs):\r\n        self.vocab_path =vocab_path\r\n        self.tokenizer = tensorflow_text.BertTokenizer(vocab_path, token_out_type=tf.int64)\r\n        super(TokenizationLayer, self).__init__(**kwargs)\r\n        \r\n    def get_config(self):\r\n        config = super(TokenizationLayer, self).get_config()\r\n        config.update({\r\n            'vocab_path': self.vocab_path,\r\n        })\r\n        return config\r\n\r\n    def call(self,inputs):\r\n        return self.tokenizer.tokenize(inputs).to_tensor()\r\n\r\n\r\nvocab_path = r\"/home/resources/bert_en_uncased_L-12_H-768_A-12/1/assets/vocab.txt\"\r\n# tensorflow_text.BertTokenizer(vocab_lookup_table = vocab_path, token_out_type=tf.int64)\r\ninputs = tf.keras.layers.Input(shape=(), dtype=tf.string)\r\ntokenization_layer = TokenizationLayer(vocab_path)\r\noutputs = tokenization_layer(inputs)\r\nmodel = tf.keras.models.Model(inputs=inputs, outputs=outputs)\r\n\r\nmodel.save(\"./test\")\r\n```\r\n\r\nIt also gives error on\r\n```\r\n def call(self,inputs):\r\n        return self.tokenizer.tokenize(inputs)\r\n```\r\n\r\nError:\r\n\r\n```\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-55-e49dd5ac9a41> in <module>\r\n----> 1 model.save(\"./test\")\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\r\n   1006     \"\"\"\r\n   1007     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\r\n-> 1008                     signatures, options)\r\n   1009 \r\n   1010   def save_weights(self, filepath, overwrite=True, save_format=None):\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\r\n    113   else:\r\n    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,\r\n--> 115                           signatures, options)\r\n    116 \r\n    117 \r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)\r\n     76     # we use the default replica context here.\r\n     77     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access\r\n---> 78       save_lib.save(model, filepath, signatures, options)\r\n     79 \r\n     80   if not include_optimizer:\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)\r\n    907   object_saver = util.TrackableSaver(checkpoint_graph_view)\r\n    908   asset_info, exported_graph = _fill_meta_graph_def(\r\n--> 909       meta_graph_def, saveable_view, signatures, options.namespace_whitelist)\r\n    910   saved_model.saved_model_schema_version = (\r\n    911       constants.SAVED_MODEL_SCHEMA_VERSION)\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py in _fill_meta_graph_def(meta_graph_def, saveable_view, signature_functions, namespace_whitelist)\r\n    585 \r\n    586   with exported_graph.as_default():\r\n--> 587     signatures = _generate_signatures(signature_functions, resource_map)\r\n    588     for concrete_function in saveable_view.concrete_functions:\r\n    589       concrete_function.add_to_graph()\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py in _generate_signatures(signature_functions, resource_map)\r\n    456             argument_inputs, signature_key, function.name))\r\n    457     outputs = _call_function_with_mapped_captures(\r\n--> 458         function, mapped_inputs, resource_map)\r\n    459     signatures[signature_key] = signature_def_utils.build_signature_def(\r\n    460         _tensor_dict_to_tensorinfo(exterior_argument_placeholders),\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py in _call_function_with_mapped_captures(function, args, resource_map)\r\n    408   \"\"\"Calls `function` in the exported graph, using mapped resource captures.\"\"\"\r\n    409   export_captures = _map_captures_to_created_tensors(\r\n--> 410       function.graph.captures, resource_map)\r\n    411   # Calls the function quite directly, since we have new captured resource\r\n    412   # tensors we need to feed in which weren't part of the original function\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py in _map_captures_to_created_tensors(original_captures, resource_map)\r\n    330            \"be tracked by assigning them to an attribute of a tracked object \"\r\n    331            \"or assigned to an attribute of the main object directly.\")\r\n--> 332           .format(interior))\r\n    333     export_captures.append(mapped_resource)\r\n    334   return export_captures\r\n\r\nAssertionError: Tried to export a function which references untracked object Tensor(\"StatefulPartitionedCall/args_1:0\", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/215", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/215/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/215/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/215/events", "html_url": "https://github.com/tensorflow/text/issues/215", "id": 558071738, "node_id": "MDU6SXNzdWU1NTgwNzE3Mzg=", "number": 215, "title": "Can not load SentencePiece model", "user": {"login": "dcferreira", "id": 7372804, "node_id": "MDQ6VXNlcjczNzI4MDQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/7372804?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dcferreira", "html_url": "https://github.com/dcferreira", "followers_url": "https://api.github.com/users/dcferreira/followers", "following_url": "https://api.github.com/users/dcferreira/following{/other_user}", "gists_url": "https://api.github.com/users/dcferreira/gists{/gist_id}", "starred_url": "https://api.github.com/users/dcferreira/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dcferreira/subscriptions", "organizations_url": "https://api.github.com/users/dcferreira/orgs", "repos_url": "https://api.github.com/users/dcferreira/repos", "events_url": "https://api.github.com/users/dcferreira/events{/privacy}", "received_events_url": "https://api.github.com/users/dcferreira/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-31T11:18:46Z", "updated_at": "2020-02-01T19:42:17Z", "closed_at": "2020-02-01T19:42:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm struggling with loading a sentencepiece model, and the error message is a bit cryptic so I'm not sure where to go next.\r\n\r\nThe error I get is the following:\r\n```\r\n2020-01-31 12:07:45.420864: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at sentencepiece_kernels.cc:211 : Internal: external/com_google_sentencepiece/src/sentencepiece_processor.cc(73) [model_proto->ParseFromArray(serialized.data(), serialized.size())] \r\nTraceback (most recent call last):\r\n  File \"load.py\", line 4, in <module>\r\n    tokenizer = tensorflow_text.SentencepieceTokenizer('model.model')\r\n  File \"/home/dferreira/projects/porn_classifier_tf2/venv/lib/python3.7/site-packages/tensorflow_text/python/ops/sentencepiece_tokenizer.py\", line 79, in __init__\r\n    model=model)\r\n  File \"<string>\", line 51, in sentencepiece_op\r\n  File \"<string>\", line 125, in sentencepiece_op_eager_fallback\r\n  File \"/home/dferreira/projects/porn_classifier_tf2/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: external/com_google_sentencepiece/src/sentencepiece_processor.cc(73) [model_proto->ParseFromArray(serialized.data(), serialized.size())]  [Op:SentencepieceOp]\r\n```\r\nI'm using Python 3.7.6 with:\r\n```\r\ntensorflow==2.1.0\r\ntensorflow-text==2.1.0rc0\r\nsentencepiece==0.1.85\r\n```\r\n\r\nThe following is a minimal reproducible example:\r\n- Create a file `raw_text` with the content:\r\n```\r\nThis is a raw text file.\r\nWith 2 lines.\r\n```\r\n- Create `train.py` with the content:\r\n```\r\nimport sentencepiece\r\n\r\nsentencepiece.SentencePieceTrainer.Train('--input=raw_text --vocab_size=20 --model_prefix=model')\r\n```\r\n- Run `python train.py`. You will get a `model.model` and `model.vocab`.\r\n- Create `load.py` with the content:\r\n```\r\nimport tensorflow_text\r\n\r\ntokenizer = tensorflow_text.SentencepieceTokenizer('model.model')\r\n```\r\n- Run `python load.py` and you will get the error above.\r\n\r\nIt should be noted that loading the same model via `sentencepiece.SentencePieceProcessor.Load` works.\r\n\r\nLike I said, I wasn't really able to interpret the error message.\r\nHow can I make this work?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/210", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/210/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/210/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/210/events", "html_url": "https://github.com/tensorflow/text/issues/210", "id": 553847944, "node_id": "MDU6SXNzdWU1NTM4NDc5NDQ=", "number": 210, "title": "NotImplementedError: Saving is not yet supported for TextVectorization layers.", "user": {"login": "dzlab", "id": 1645304, "node_id": "MDQ6VXNlcjE2NDUzMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1645304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzlab", "html_url": "https://github.com/dzlab", "followers_url": "https://api.github.com/users/dzlab/followers", "following_url": "https://api.github.com/users/dzlab/following{/other_user}", "gists_url": "https://api.github.com/users/dzlab/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzlab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzlab/subscriptions", "organizations_url": "https://api.github.com/users/dzlab/orgs", "repos_url": "https://api.github.com/users/dzlab/repos", "events_url": "https://api.github.com/users/dzlab/events{/privacy}", "received_events_url": "https://api.github.com/users/dzlab/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "markomernick", "id": 26491096, "node_id": "MDQ6VXNlcjI2NDkxMDk2", "avatar_url": "https://avatars3.githubusercontent.com/u/26491096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markomernick", "html_url": "https://github.com/markomernick", "followers_url": "https://api.github.com/users/markomernick/followers", "following_url": "https://api.github.com/users/markomernick/following{/other_user}", "gists_url": "https://api.github.com/users/markomernick/gists{/gist_id}", "starred_url": "https://api.github.com/users/markomernick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markomernick/subscriptions", "organizations_url": "https://api.github.com/users/markomernick/orgs", "repos_url": "https://api.github.com/users/markomernick/repos", "events_url": "https://api.github.com/users/markomernick/events{/privacy}", "received_events_url": "https://api.github.com/users/markomernick/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "markomernick", "id": 26491096, "node_id": "MDQ6VXNlcjI2NDkxMDk2", "avatar_url": "https://avatars3.githubusercontent.com/u/26491096?v=4", "gravatar_id": "", "url": "https://api.github.com/users/markomernick", "html_url": "https://github.com/markomernick", "followers_url": "https://api.github.com/users/markomernick/followers", "following_url": "https://api.github.com/users/markomernick/following{/other_user}", "gists_url": "https://api.github.com/users/markomernick/gists{/gist_id}", "starred_url": "https://api.github.com/users/markomernick/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/markomernick/subscriptions", "organizations_url": "https://api.github.com/users/markomernick/orgs", "repos_url": "https://api.github.com/users/markomernick/repos", "events_url": "https://api.github.com/users/markomernick/events{/privacy}", "received_events_url": "https://api.github.com/users/markomernick/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-01-22T23:10:15Z", "updated_at": "2020-04-05T21:14:21Z", "closed_at": "2020-02-28T19:53:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm defining a TextVectorization layer like this\r\n```python\r\ndecoder_vectorize = TextVectorization(\r\n  name='de_vectorize',\r\n  standardize = 'lower_and_strip_punctuation',\r\n  split       = 'whitespace',\r\n  max_tokens  = config.tar_vocab,\r\n  output_mode ='int', \r\n  output_sequence_length=config.tar_timesteps\r\n)\r\n```\r\nThen after training, I try to save the model but i'm hitting errors\r\n```python\r\n>>> model.save('model.h5')\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in <listcomp>(.0)\r\n   3312   if context.executing_eagerly():\r\n-> 3313     return [x.numpy() for x in tensors]\r\n   3314   elif ops.inside_function():  # pylint: disable=protected-access\r\n   3315     raise RuntimeError('Cannot get value inside Tensorflow graph function.')\r\n\r\nAttributeError: 'TrackableWeightHandler' object has no attribute 'numpy'\r\n\r\n>>> model.save('model.tf', save_format='tf')\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/preprocessing/text_vectorization.py in fail(_)\r\n    295     def fail(_):\r\n    296       raise NotImplementedError(\r\n--> 297           \"Saving is not yet supported for TextVectorization layers.\")\r\n    298     self._table._list_extra_dependencies_for_serialization = fail  # pylint: disable=protected-access\r\n    299 \r\n\r\nNotImplementedError: Saving is not yet supported for TextVectorization layers.\r\n```\r\n\r\nThis is on a nightly TF version `2.2.0-dev20200122`. Is there a workaround?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/206", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/206/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/206/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/206/events", "html_url": "https://github.com/tensorflow/text/issues/206", "id": 547808731, "node_id": "MDU6SXNzdWU1NDc4MDg3MzE=", "number": 206, "title": "TextVectorization layer vs TensorFlow Text", "user": {"login": "dzlab", "id": 1645304, "node_id": "MDQ6VXNlcjE2NDUzMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1645304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzlab", "html_url": "https://github.com/dzlab", "followers_url": "https://api.github.com/users/dzlab/followers", "following_url": "https://api.github.com/users/dzlab/following{/other_user}", "gists_url": "https://api.github.com/users/dzlab/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzlab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzlab/subscriptions", "organizations_url": "https://api.github.com/users/dzlab/orgs", "repos_url": "https://api.github.com/users/dzlab/repos", "events_url": "https://api.github.com/users/dzlab/events{/privacy}", "received_events_url": "https://api.github.com/users/dzlab/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-01-10T01:09:55Z", "updated_at": "2020-01-30T23:29:01Z", "closed_at": "2020-01-30T23:29:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "The latest TF version 2.1 added a new Keras layer for text processing in the graph which is `TextVectorization` . This layers seems to support custom tokenization and all typical preprocessing stuff ([here a detailed article on how to use it](https://dzlab.github.io/dltips/en/tensorflow/textvectorization-preprocessing/)). \r\n```python\r\nvectorize_layer = TextVectorization(\r\n    standardize=custom_standardization,\r\n    max_tokens=max_features,\r\n    output_mode='int',\r\n    output_sequence_length=400)\r\n```\r\nWhat does this means for TF Text which now still have to be used with `ToDense` layer as very few layers support RaggedTensors? And when to use each one of the two?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/202", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/202/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/202/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/202/events", "html_url": "https://github.com/tensorflow/text/issues/202", "id": 543293494, "node_id": "MDU6SXNzdWU1NDMyOTM0OTQ=", "number": 202, "title": "how to deal with raggedtensor in the model output", "user": {"login": "dzlab", "id": 1645304, "node_id": "MDQ6VXNlcjE2NDUzMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1645304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzlab", "html_url": "https://github.com/dzlab", "followers_url": "https://api.github.com/users/dzlab/followers", "following_url": "https://api.github.com/users/dzlab/following{/other_user}", "gists_url": "https://api.github.com/users/dzlab/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzlab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzlab/subscriptions", "organizations_url": "https://api.github.com/users/dzlab/orgs", "repos_url": "https://api.github.com/users/dzlab/repos", "events_url": "https://api.github.com/users/dzlab/events{/privacy}", "received_events_url": "https://api.github.com/users/dzlab/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694864, "node_id": "MDU6TGFiZWwxMzgyNjk0ODY0", "url": "https://api.github.com/repos/tensorflow/text/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-28T23:37:49Z", "updated_at": "2020-02-14T01:55:53Z", "closed_at": "2020-02-14T01:55:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a seq2seq model like this\r\n```python\r\nmodel = Sequential([\r\n  InputLayer(input_shape=(None,), dtype='int64', ragged=True),\r\n  tftext.keras.layers.ToDense(pad_value=0, mask=True),\r\n  Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True),\r\n  LSTM(n_units),\r\n  RepeatVector(tar_timesteps),\r\n  LSTM(n_units, return_sequences=True),\r\n  TimeDistributed(Dense(tar_vocab, activation='softmax'))\r\n])\r\n```\r\nAnd I am build the dataset from a pair of engilish-german sentences like this\r\n```python\r\ndef basic_preprocess(src, dst):\r\n  # Preprocess\r\n  rt_src = preprocess(src)\r\n  rt_dst = preprocess(dst)\r\n  # Encode tokens\r\n  features = tf.ragged.map_flat_values(en_vocab_table.lookup, rt_src)\r\n  labels = tf.ragged.map_flat_values(ge_vocab_table.lookup, rt_dst)\r\n\r\n  return features, labels\r\n```\r\nMy problem is that when I fit the model I get the following error as the output is ragged (while input is not longer ragged)\r\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/util/nest.py in assert_same_structure(nest1, nest2, check_types, expand_composites)\r\n    317     _pywrap_tensorflow.AssertSameStructure(nest1, nest2, check_types,\r\n--> 318                                            expand_composites)\r\n    319   except (ValueError, TypeError) as e:\r\n\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: type=TensorSpec str=TensorSpec(shape=(None,), dtype=tf.int64, name=None)\r\n\r\nSecond structure: type=RaggedTensor str=tf.RaggedTensor(values=Tensor(\"input_1/flat_values:0\", shape=(None,), dtype=int64), row_splits=Tensor(\"input_1/row_splits_0:0\", shape=(None,), dtype=int64))\r\n\r\nMore specifically: Substructure \"type=RaggedTensor str=tf.RaggedTensor(values=Tensor(\"input_1/flat_values:0\", shape=(None,), dtype=int64), row_splits=Tensor(\"input_1/row_splits_0:0\", shape=(None,), dtype=int64))\" is a sequence, while substructure \"type=TensorSpec str=TensorSpec(shape=(None,), dtype=tf.int64, name=None)\" is not\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n```\r\nHow should I fix this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/200", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/200/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/200/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/200/events", "html_url": "https://github.com/tensorflow/text/issues/200", "id": 538467106, "node_id": "MDU6SXNzdWU1Mzg0NjcxMDY=", "number": 200, "title": "Op type not registered 'RegexSplitWithOffsets'", "user": {"login": "HichemMaiza", "id": 11610734, "node_id": "MDQ6VXNlcjExNjEwNzM0", "avatar_url": "https://avatars3.githubusercontent.com/u/11610734?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HichemMaiza", "html_url": "https://github.com/HichemMaiza", "followers_url": "https://api.github.com/users/HichemMaiza/followers", "following_url": "https://api.github.com/users/HichemMaiza/following{/other_user}", "gists_url": "https://api.github.com/users/HichemMaiza/gists{/gist_id}", "starred_url": "https://api.github.com/users/HichemMaiza/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HichemMaiza/subscriptions", "organizations_url": "https://api.github.com/users/HichemMaiza/orgs", "repos_url": "https://api.github.com/users/HichemMaiza/repos", "events_url": "https://api.github.com/users/HichemMaiza/events{/privacy}", "received_events_url": "https://api.github.com/users/HichemMaiza/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694860, "node_id": "MDU6TGFiZWwxMzgyNjk0ODYw", "url": "https://api.github.com/repos/tensorflow/text/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-12-16T15:02:27Z", "updated_at": "2020-02-14T01:57:38Z", "closed_at": "2020-02-14T01:57:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "Environment\r\n-----------------\r\nOS:\r\n---- \r\nUbuntu : Release 18.04\r\npython : 3.6.9\r\n\r\nDependencies versions:\r\n------------------------------\r\ntensorflow  --  2.0.0\r\ntensorflow-text  -- 2.0.1\r\n\r\nError :\r\n--------\r\n```\r\n2019-12-16 14:59:30.379512: W external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at partitioned_function_ops.cc:113 : Not found: Op type not registered 'RegexSplitWithOffsets' in binary running on pc. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n```\r\nError and Pipeline Description\r\n----------------------------------------\r\nI am using BertTokenizer in a tensorflow.keras.layers.Layer custom class\r\n\r\nTraining  `model.fit` --> works fine \r\nEvaluating `model.evaluate`--> works fine \r\nSaving `model.save` --> works fine\r\nloading using `model.load` --> works fine \r\nserving with tensorflow serving --> ERROR \r\n\r\nWhen using tensorflow serving I get the `Not found: Op type not registered 'RegexSplitWithOffsets' ` error \r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/199", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/199/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/199/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/199/events", "html_url": "https://github.com/tensorflow/text/issues/199", "id": 536652851, "node_id": "MDU6SXNzdWU1MzY2NTI4NTE=", "number": 199, "title": "tokenizer doesn't work with tf.distribute.Strategy", "user": {"login": "terrykong", "id": 7576060, "node_id": "MDQ6VXNlcjc1NzYwNjA=", "avatar_url": "https://avatars3.githubusercontent.com/u/7576060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/terrykong", "html_url": "https://github.com/terrykong", "followers_url": "https://api.github.com/users/terrykong/followers", "following_url": "https://api.github.com/users/terrykong/following{/other_user}", "gists_url": "https://api.github.com/users/terrykong/gists{/gist_id}", "starred_url": "https://api.github.com/users/terrykong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/terrykong/subscriptions", "organizations_url": "https://api.github.com/users/terrykong/orgs", "repos_url": "https://api.github.com/users/terrykong/repos", "events_url": "https://api.github.com/users/terrykong/events{/privacy}", "received_events_url": "https://api.github.com/users/terrykong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694858, "node_id": "MDU6TGFiZWwxMzgyNjk0ODU4", "url": "https://api.github.com/repos/tensorflow/text/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-12-11T22:36:59Z", "updated_at": "2020-01-16T00:31:16Z", "closed_at": "2020-01-16T00:31:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi guys,\r\n\r\nMy environment is tensorflow==2.0.0 and tensorflow_text==2.0.1\r\n\r\nI'm wondering if there's a way to get tensorflow text to work with tensorflow's distributed strategies. Here's a minimal example that doesn't work for me. Note that if I remove tf.function, I can iterate through the dataset, but then i'm in eager mode and can't take advantage of executing things in a graph.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_text as text\r\n\r\ndocs = tf.data.Dataset.from_tensor_slices([['Never tell me the odds.'],\r\n                                           [\"It's a trap!\"]])\r\ntokenizer = text.WhitespaceTokenizer()\r\ntokenized_docs = docs.map(lambda x: tokenizer.tokenize(x))\r\n\r\ndef print_dataset(dataset):\r\n    for x in dataset:\r\n        tf.print(x)\r\nprint_dataset(tokenized_docs)\r\ntf.function(print_dataset)(tokenized_docs)\r\n\r\nstrategy = tf.distribute.OneDeviceStrategy(device='/cpu:0')\r\ndistributed_dataset = strategy.experimental_distribute_dataset(tokenized_docs)\r\nwith strategy.scope():\r\n    @tf.function\r\n    def foo(dataset):\r\n        for x in dataset:\r\n            tf.print(x)\r\n\r\nfoo(distributed_dataset)\r\n\r\n# OUTPUT\r\n'''\r\n2019-12-11 22:33:24.268738: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-12-11 22:33:24.297320: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500000000 Hz\r\n2019-12-11 22:33:24.305256: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4d16340 executing computations on platform Host. Devices:\r\n2019-12-11 22:33:24.305312: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\r\nInstructions for updating:\r\n`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\r\n<tf.RaggedTensor [[b'Never', b'tell', b'me', b'the', b'odds.']]>\r\n<tf.RaggedTensor [[b\"It's\", b'a', b'trap!']]>\r\ntf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))\r\ntf.RaggedTensor(values=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:1\", shape=(None,), dtype=string), row_splits=Tensor(\"RaggedFromVariant/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 48, in <module>\r\n    foo(distributed_dataset)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\r\n    *args, **kwds))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 905, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nTypeError: in converted code:\r\n\r\n    test.py:45 foo  *\r\n        for x in dataset:\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:337 for_stmt\r\n        return custom_handler(extra_test, body, init_vars)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py:416 _autograph_for_loop\r\n        self.reduce((constant_op.constant(0),), reduce_body_with_dummy_state)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py:422 reduce\r\n        has_data, data = _get_next_as_optional(iterator, self._strategy)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py:200 _get_next_as_optional\r\n        iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py:878 get_next_as_list\r\n        lambda: _dummy_tensor_fn(data.value_structure))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507 new_func\r\n        return func(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py:1174 cond\r\n        return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/cond_v2.py:91 cond_v2\r\n        op_return_value=pred)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py:915 func_graph_from_py_func\r\n        func_outputs = python_func(*func_args, **func_kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py:878 <lambda>\r\n        lambda: _dummy_tensor_fn(data.value_structure))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py:801 _dummy_tensor_fn\r\n        result.append(create_dummy_tensor(feature_shape, feature_type))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py:784 create_dummy_tensor\r\n        for dim in feature_shape.dims:\r\n\r\n    TypeError: 'NoneType' object is not iterable\r\n\r\n'''\r\n```\r\n\r\nRemoving the tokenizer seems to work\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_text as text\r\n\r\ndocs = tf.data.Dataset.from_tensor_slices([['Never tell me the odds.'],\r\n                                           [\"It's a trap!\"]])\r\n\r\ndef print_dataset(dataset):\r\n    for x in dataset:\r\n        tf.print(x)\r\nprint_dataset(docs)\r\ntf.function(print_dataset)(docs)\r\n\r\nstrategy = tf.distribute.OneDeviceStrategy(device='/cpu:0')\r\ndistributed_dataset = strategy.experimental_distribute_dataset(docs)\r\nwith strategy.scope():\r\n    @tf.function\r\n    def foo(dataset):\r\n        for x in dataset:\r\n            tf.print(x)\r\n\r\nfoo(distributed_dataset)\r\n\r\n# OUTPUT\r\n'''\r\n2019-12-11 22:30:47.173794: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2019-12-11 22:30:47.202302: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500000000 Hz\r\n2019-12-11 22:30:47.210319: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3369120 executing computations on platform Host. Devices:\r\n2019-12-11 22:30:47.210378: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n[\"Never tell me the odds.\"]\r\n[\"It\\'s a trap!\"]\r\n[\"Never tell me the odds.\"]\r\n[\"It\\'s a trap!\"]\r\n[\"Never tell me the odds.\"]\r\n[\"It\\'s a trap!\"]\r\n'''\r\n```\r\n\r\nAny help or guidance would be appreciated", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/198", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/198/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/198/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/198/events", "html_url": "https://github.com/tensorflow/text/issues/198", "id": 536447358, "node_id": "MDU6SXNzdWU1MzY0NDczNTg=", "number": 198, "title": "2.1.0 RC builds", "user": {"login": "connorbrinton", "id": 1848731, "node_id": "MDQ6VXNlcjE4NDg3MzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1848731?v=4", "gravatar_id": "", "url": "https://api.github.com/users/connorbrinton", "html_url": "https://github.com/connorbrinton", "followers_url": "https://api.github.com/users/connorbrinton/followers", "following_url": "https://api.github.com/users/connorbrinton/following{/other_user}", "gists_url": "https://api.github.com/users/connorbrinton/gists{/gist_id}", "starred_url": "https://api.github.com/users/connorbrinton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/connorbrinton/subscriptions", "organizations_url": "https://api.github.com/users/connorbrinton/orgs", "repos_url": "https://api.github.com/users/connorbrinton/repos", "events_url": "https://api.github.com/users/connorbrinton/events{/privacy}", "received_events_url": "https://api.github.com/users/connorbrinton/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-11T15:33:09Z", "updated_at": "2020-01-06T23:53:33Z", "closed_at": "2020-01-06T23:53:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "First of all, thanks for maintaining TF Text! \ud83d\ude04\r\n\r\nAre there any plans to build release candidate releases for TF Text? Release candidate builds ([2.1.0rc0](https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0-rc0) and [2.1.0rc1](https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0-rc1)) have been published for the main TensorFlow package, but corresponding releases aren't available yet for TF Text. Instructions for installing TF Text state:\r\n\r\n> When installing TF Text with pip install, please note the version of TensorFlow you are running, as you should specify the corresponding version of TF Text.\r\n\r\nIf release candidate builds could be created, that would be super helpful for me, since I'm unable to easily use TF 2.0.0 due to [these changes](https://github.com/tensorflow/tensorflow/pull/32758) not making it into the release \ud83d\ude05", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/196", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/196/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/196/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/196/events", "html_url": "https://github.com/tensorflow/text/issues/196", "id": 534638860, "node_id": "MDU6SXNzdWU1MzQ2Mzg4NjA=", "number": 196, "title": "Are convolution layers supported?", "user": {"login": "dzlab", "id": 1645304, "node_id": "MDQ6VXNlcjE2NDUzMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1645304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dzlab", "html_url": "https://github.com/dzlab", "followers_url": "https://api.github.com/users/dzlab/followers", "following_url": "https://api.github.com/users/dzlab/following{/other_user}", "gists_url": "https://api.github.com/users/dzlab/gists{/gist_id}", "starred_url": "https://api.github.com/users/dzlab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dzlab/subscriptions", "organizations_url": "https://api.github.com/users/dzlab/orgs", "repos_url": "https://api.github.com/users/dzlab/repos", "events_url": "https://api.github.com/users/dzlab/events{/privacy}", "received_events_url": "https://api.github.com/users/dzlab/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-09T01:18:09Z", "updated_at": "2019-12-11T19:11:30Z", "closed_at": "2019-12-11T19:11:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have the following model\r\n```\r\nmodel = tf.keras.Sequential([\r\n  InputLayer(input_shape=(None,), dtype='int64', ragged=True),\r\n  tftext.keras.layers.ToDense(pad_value=0, mask=True),\r\n  Embedding(vocab_size, n_units),\r\n  Conv1D(filters=32, kernel_size=8, activation='relu'),\r\n  MaxPooling1D(pool_size=2),\r\n  Flatten(),\r\n  Dense(10, activation='relu'),\r\n  Dense(1, activation='sigmoid')\r\n])\r\n```\r\nIt fails with following error\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-32-0787290fce6e> in <module>()\r\n      7   Flatten(),\r\n      8   Dense(10, activation='relu'),\r\n----> 9   Dense(1, activation='sigmoid')\r\n     10 ])\r\n     11 model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\r\n\r\n6 frames\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/sequential.py in __init__(self, layers, name)\r\n    112       tf_utils.assert_no_legacy_layers(layers)\r\n    113       for layer in layers:\r\n--> 114         self.add(layer)\r\n    115 \r\n    116   @property\r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/sequential.py in add(self, layer)\r\n    194       # If the model is being built continuously on top of an input layer:\r\n    195       # refresh its output.\r\n--> 196       output_tensor = layer(self.outputs[0])\r\n    197       if len(nest.flatten(output_tensor)) != 1:\r\n    198         raise TypeError('All layers in a Sequential model '\r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    815           # Build layer if applicable (if the `build` method has been\r\n    816           # overridden).\r\n--> 817           self._maybe_build(inputs)\r\n    818           cast_inputs = self._maybe_cast_inputs(inputs)\r\n    819 \r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py in _maybe_build(self, inputs)\r\n   2139         # operations.\r\n   2140         with tf_utils.maybe_init_scope(self):\r\n-> 2141           self.build(input_shapes)\r\n   2142       # We must set self.built since user defined build functions are not\r\n   2143       # constrained to set self.built.\r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/layers/core.py in build(self, input_shape)\r\n   1013     input_shape = tensor_shape.TensorShape(input_shape)\r\n   1014     if tensor_shape.dimension_value(input_shape[-1]) is None:\r\n-> 1015       raise ValueError('The last dimension of the inputs to `Dense` '\r\n   1016                        'should be defined. Found `None`.')\r\n   1017     last_dim = tensor_shape.dimension_value(input_shape[-1])\r\n\r\nValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/192", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/192/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/192/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/192/events", "html_url": "https://github.com/tensorflow/text/issues/192", "id": 530248046, "node_id": "MDU6SXNzdWU1MzAyNDgwNDY=", "number": 192, "title": "import fails: \"undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs\"", "user": {"login": "moreymat", "id": 2861042, "node_id": "MDQ6VXNlcjI4NjEwNDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2861042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/moreymat", "html_url": "https://github.com/moreymat", "followers_url": "https://api.github.com/users/moreymat/followers", "following_url": "https://api.github.com/users/moreymat/following{/other_user}", "gists_url": "https://api.github.com/users/moreymat/gists{/gist_id}", "starred_url": "https://api.github.com/users/moreymat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/moreymat/subscriptions", "organizations_url": "https://api.github.com/users/moreymat/orgs", "repos_url": "https://api.github.com/users/moreymat/repos", "events_url": "https://api.github.com/users/moreymat/events{/privacy}", "received_events_url": "https://api.github.com/users/moreymat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2019-11-29T09:41:51Z", "updated_at": "2020-08-03T05:23:05Z", "closed_at": "2020-01-06T23:56:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "I encountered this bug which is most probably a duplicate of #30 that has been closed.\r\nIs it related to https://github.com/tensorflow/text/issues/160#issuecomment-556558082 ?\r\n\r\n**System information**\r\n* Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 LTS\r\n* Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n* TensorFlow installed from (source or binary): binary\r\n* TensorFlow version (use command below): 2.0.0\r\n* Python version: Anaconda python 3.7.5\r\n* CUDA/cuDNN version: None\r\n* GPU model and memory: None\r\n\r\n**Describe the current behavior**\r\nError on importing tensorflow-text making it impossible to be imported.\r\n\r\n**Describe the expected behavior**\r\nLibrary can be effortlessly imported and used.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nI created a new minimal environment using\r\n\r\n```sh\r\nconda create -n tf-test tensorflow python=3.7\r\nconda activate tf-test\r\npip install tensorflow-text\r\n```\r\n\r\nthen, when trying to import tensorflow_text the following error appears\r\n\r\n```console\r\n$ python\r\nPython 3.7.5 (default, Oct 25 2019, 15:51:11) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> import tensorflow_text as text\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/mathieu/miniconda3/envs/tf-test/lib/python3.7/site-packages/tensorflow_text/__init__.py\", line 21, in <module>\r\n    from tensorflow_text.python import metrics\r\n  File \"/home/mathieu/miniconda3/envs/tf-test/lib/python3.7/site-packages/tensorflow_text/python/metrics/__init__.py\", line 20, in <module>\r\n    from tensorflow_text.python.metrics.text_similarity_metric_ops import *\r\n  File \"/home/mathieu/miniconda3/envs/tf-test/lib/python3.7/site-packages/tensorflow_text/python/metrics/text_similarity_metric_ops.py\", line 28, in <module>\r\n    gen_text_similarity_metric_ops = load_library.load_op_library(resource_loader.get_path_to_datafile('_text_similarity_metric_ops.so'))\r\n  File \"/home/mathieu/miniconda3/envs/tf-test/lib/python3.7/site-packages/tensorflow_core/python/framework/load_library.py\", line 61, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/mathieu/miniconda3/envs/tf-test/lib/python3.7/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/181", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/181/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/181/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/181/events", "html_url": "https://github.com/tensorflow/text/issues/181", "id": 523880552, "node_id": "MDU6SXNzdWU1MjM4ODA1NTI=", "number": 181, "title": "BertTokenizer: Example?", "user": {"login": "iLikeToCodeZ", "id": 22101853, "node_id": "MDQ6VXNlcjIyMTAxODUz", "avatar_url": "https://avatars2.githubusercontent.com/u/22101853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iLikeToCodeZ", "html_url": "https://github.com/iLikeToCodeZ", "followers_url": "https://api.github.com/users/iLikeToCodeZ/followers", "following_url": "https://api.github.com/users/iLikeToCodeZ/following{/other_user}", "gists_url": "https://api.github.com/users/iLikeToCodeZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/iLikeToCodeZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iLikeToCodeZ/subscriptions", "organizations_url": "https://api.github.com/users/iLikeToCodeZ/orgs", "repos_url": "https://api.github.com/users/iLikeToCodeZ/repos", "events_url": "https://api.github.com/users/iLikeToCodeZ/events{/privacy}", "received_events_url": "https://api.github.com/users/iLikeToCodeZ/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694864, "node_id": "MDU6TGFiZWwxMzgyNjk0ODY0", "url": "https://api.github.com/repos/tensorflow/text/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "thuang513", "id": 556234, "node_id": "MDQ6VXNlcjU1NjIzNA==", "avatar_url": "https://avatars0.githubusercontent.com/u/556234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thuang513", "html_url": "https://github.com/thuang513", "followers_url": "https://api.github.com/users/thuang513/followers", "following_url": "https://api.github.com/users/thuang513/following{/other_user}", "gists_url": "https://api.github.com/users/thuang513/gists{/gist_id}", "starred_url": "https://api.github.com/users/thuang513/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thuang513/subscriptions", "organizations_url": "https://api.github.com/users/thuang513/orgs", "repos_url": "https://api.github.com/users/thuang513/repos", "events_url": "https://api.github.com/users/thuang513/events{/privacy}", "received_events_url": "https://api.github.com/users/thuang513/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "thuang513", "id": 556234, "node_id": "MDQ6VXNlcjU1NjIzNA==", "avatar_url": "https://avatars0.githubusercontent.com/u/556234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thuang513", "html_url": "https://github.com/thuang513", "followers_url": "https://api.github.com/users/thuang513/followers", "following_url": "https://api.github.com/users/thuang513/following{/other_user}", "gists_url": "https://api.github.com/users/thuang513/gists{/gist_id}", "starred_url": "https://api.github.com/users/thuang513/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thuang513/subscriptions", "organizations_url": "https://api.github.com/users/thuang513/orgs", "repos_url": "https://api.github.com/users/thuang513/repos", "events_url": "https://api.github.com/users/thuang513/events{/privacy}", "received_events_url": "https://api.github.com/users/thuang513/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2019-11-16T18:41:57Z", "updated_at": "2020-04-27T19:00:45Z", "closed_at": "2020-04-27T19:00:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there an example on how to use the BertTokenizer?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/174", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/174/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/174/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/174/events", "html_url": "https://github.com/tensorflow/text/issues/174", "id": 522978992, "node_id": "MDU6SXNzdWU1MjI5Nzg5OTI=", "number": 174, "title": "Unable to train model with Keras API and tensorflow_text", "user": {"login": "jdeason23", "id": 5685149, "node_id": "MDQ6VXNlcjU2ODUxNDk=", "avatar_url": "https://avatars1.githubusercontent.com/u/5685149?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdeason23", "html_url": "https://github.com/jdeason23", "followers_url": "https://api.github.com/users/jdeason23/followers", "following_url": "https://api.github.com/users/jdeason23/following{/other_user}", "gists_url": "https://api.github.com/users/jdeason23/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdeason23/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdeason23/subscriptions", "organizations_url": "https://api.github.com/users/jdeason23/orgs", "repos_url": "https://api.github.com/users/jdeason23/repos", "events_url": "https://api.github.com/users/jdeason23/events{/privacy}", "received_events_url": "https://api.github.com/users/jdeason23/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694864, "node_id": "MDU6TGFiZWwxMzgyNjk0ODY0", "url": "https://api.github.com/repos/tensorflow/text/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-11-14T16:46:07Z", "updated_at": "2020-01-06T23:58:53Z", "closed_at": "2020-01-06T23:58:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Trying to train a model using the example from the README file, but it doesn't work: \r\n\r\n    import tensorflow as tf\r\n    import tensorflow_text as text\r\n    model = tf.keras.Sequential([\r\n    tf.keras.layers.InputLayer(input_shape=(None,), dtype='int32', ragged=True),\r\n    text.keras.layers.ToDense(pad_value=0, mask=True),\r\n    tf.keras.layers.Embedding(100, 16),\r\n    tf.keras.layers.LSTM(32),\r\n    tf.keras.layers.Dense(32, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n    ])\r\n\r\n\r\nERROR:\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: type=TensorSpec str=TensorSpec(shape=(), dtype=tf.string, name=None)\r\n\r\nSecond structure: type=RaggedTensor str=tf.RaggedTensor(values=Tensor(\"input_1/flat_values:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"input_1/row_splits_0:0\", shape=(None,), dtype=int64))\r\n\r\nMore specifically: Substructure \"type=RaggedTensor str=tf.RaggedTensor(values=Tensor(\"input_1/flat_values:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"input_1/row_splits_0:0\", shape=(None,), dtype=int64))\" is a sequence, while substructure \"type=TensorSpec str=TensorSpec(shape=(), dtype=tf.string, name=None)\" is not\r\nEntire first structure:\r\n.\r\nEntire second structure:\r\n.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/173", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/173/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/173/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/173/events", "html_url": "https://github.com/tensorflow/text/issues/173", "id": 522728792, "node_id": "MDU6SXNzdWU1MjI3Mjg3OTI=", "number": 173, "title": "some bugs when using tensorflow 1.x", "user": {"login": "desperadoola", "id": 30496727, "node_id": "MDQ6VXNlcjMwNDk2NzI3", "avatar_url": "https://avatars3.githubusercontent.com/u/30496727?v=4", "gravatar_id": "", "url": "https://api.github.com/users/desperadoola", "html_url": "https://github.com/desperadoola", "followers_url": "https://api.github.com/users/desperadoola/followers", "following_url": "https://api.github.com/users/desperadoola/following{/other_user}", "gists_url": "https://api.github.com/users/desperadoola/gists{/gist_id}", "starred_url": "https://api.github.com/users/desperadoola/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/desperadoola/subscriptions", "organizations_url": "https://api.github.com/users/desperadoola/orgs", "repos_url": "https://api.github.com/users/desperadoola/repos", "events_url": "https://api.github.com/users/desperadoola/events{/privacy}", "received_events_url": "https://api.github.com/users/desperadoola/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694860, "node_id": "MDU6TGFiZWwxMzgyNjk0ODYw", "url": "https://api.github.com/repos/tensorflow/text/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2019-11-14T09:27:19Z", "updated_at": "2020-02-14T18:49:46Z", "closed_at": "2020-02-14T18:49:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "tensorflow_version=1.15\r\n\r\nuse BertTokenizer will cause \r\n\r\n```AttributeError: 'RaggedTensor' object has no attribute 'merge_dims'```\r\n\r\nand use BasicTokenizer and set lower_case=True will cause \r\n\r\n```tensorflow.python.framework.errors_impl.InternalError: U_FILE_ACCESS_ERROR: Could not retrieve ICU NFKC_CaseFold normalizer [Op:CaseFoldUTF8]```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/164", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/164/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/164/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/164/events", "html_url": "https://github.com/tensorflow/text/issues/164", "id": 521521848, "node_id": "MDU6SXNzdWU1MjE1MjE4NDg=", "number": 164, "title": "Error: `U_FILE_ACCESS_ERROR` when build by bazel as `http_archive`", "user": {"login": "Alpus", "id": 10693285, "node_id": "MDQ6VXNlcjEwNjkzMjg1", "avatar_url": "https://avatars0.githubusercontent.com/u/10693285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alpus", "html_url": "https://github.com/Alpus", "followers_url": "https://api.github.com/users/Alpus/followers", "following_url": "https://api.github.com/users/Alpus/following{/other_user}", "gists_url": "https://api.github.com/users/Alpus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alpus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alpus/subscriptions", "organizations_url": "https://api.github.com/users/Alpus/orgs", "repos_url": "https://api.github.com/users/Alpus/repos", "events_url": "https://api.github.com/users/Alpus/events{/privacy}", "received_events_url": "https://api.github.com/users/Alpus/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-12T12:29:48Z", "updated_at": "2019-11-14T08:38:14Z", "closed_at": "2019-11-14T08:38:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I build `tensorflow/text` from branch `2.0` by `bazel` as a `http_archive`. When I try to use `CaseFoldUTF8Op ` op, I get an error:\r\n\r\n```\r\nU_FILE_ACCESS_ERROR: Could not retrieve ICU NFKC_CaseFold normalizer [[{{node CaseFoldUTF8/CaseFoldUTF8}}]]\r\n```\r\n\r\nIt looks like logic related with [normalization_data.c](https://github.com/tensorflow/text/blob/master/third_party/icu/data/normalization_data.c) doesn't work, but I can't understand why.\r\n\r\nI use bazel `0.24.1`\r\n\r\nDo you have any suggestions?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/158", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/158/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/158/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/158/events", "html_url": "https://github.com/tensorflow/text/issues/158", "id": 520276618, "node_id": "MDU6SXNzdWU1MjAyNzY2MTg=", "number": 158, "title": "Invalid regex pattern during tokenization", "user": {"login": "hanneshapke", "id": 1234819, "node_id": "MDQ6VXNlcjEyMzQ4MTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1234819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hanneshapke", "html_url": "https://github.com/hanneshapke", "followers_url": "https://api.github.com/users/hanneshapke/followers", "following_url": "https://api.github.com/users/hanneshapke/following{/other_user}", "gists_url": "https://api.github.com/users/hanneshapke/gists{/gist_id}", "starred_url": "https://api.github.com/users/hanneshapke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hanneshapke/subscriptions", "organizations_url": "https://api.github.com/users/hanneshapke/orgs", "repos_url": "https://api.github.com/users/hanneshapke/repos", "events_url": "https://api.github.com/users/hanneshapke/events{/privacy}", "received_events_url": "https://api.github.com/users/hanneshapke/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-08T23:09:17Z", "updated_at": "2019-11-20T23:24:00Z", "closed_at": "2019-11-20T23:24:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "When using the Bert or Wordpiece tokenizer, I encounter the error `Invalid pattern (\\p{Whitespace}+|[!-/]|[:-@]|[\\[-`]|[{-~] ...`.\r\n\r\ntensorflow-text version is 2.0.0. \r\n\r\nI thought the issue might be the vocab table, therefore I tried to replicate the BertTokenizer test from the repo. But also this code example fails.\r\n\r\n[I created a Colab version for the issue](https://colab.research.google.com/drive/1MpOGneRpPajB8RixhDbPD5U8BEe4Sg89)\r\n\r\nI am not sure if it is a bug or a problem with my tokenizer setup.\r\n\r\nThank you for any insights! ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/155", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/155/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/155/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/155/events", "html_url": "https://github.com/tensorflow/text/issues/155", "id": 518969725, "node_id": "MDU6SXNzdWU1MTg5Njk3MjU=", "number": 155, "title": "Converting Ragged Tensor of Word Pieces to bert input", "user": {"login": "r-wheeler", "id": 5184858, "node_id": "MDQ6VXNlcjUxODQ4NTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/5184858?v=4", "gravatar_id": "", "url": "https://api.github.com/users/r-wheeler", "html_url": "https://github.com/r-wheeler", "followers_url": "https://api.github.com/users/r-wheeler/followers", "following_url": "https://api.github.com/users/r-wheeler/following{/other_user}", "gists_url": "https://api.github.com/users/r-wheeler/gists{/gist_id}", "starred_url": "https://api.github.com/users/r-wheeler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/r-wheeler/subscriptions", "organizations_url": "https://api.github.com/users/r-wheeler/orgs", "repos_url": "https://api.github.com/users/r-wheeler/repos", "events_url": "https://api.github.com/users/r-wheeler/events{/privacy}", "received_events_url": "https://api.github.com/users/r-wheeler/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-11-07T00:33:50Z", "updated_at": "2020-01-25T04:34:44Z", "closed_at": "2019-11-07T11:38:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there an example of how to convert the ragged tensors returned by `WordpieceTokenizer` into the correct (dense padded) format to use with bert (or bert on tensorflow hub) that is compatible with `tf.function`? \r\n\r\nFor example: \r\n\r\nWith the bert preprocessing \r\n`inputs = [['test this', 'and me too']`\r\n\r\nWould become three dense tensors of `input_ids, input_masks`, and `segement_ids` \r\n\r\n```\r\n(<tf.Tensor: id=5315, shape=(1, 48), dtype=int32, numpy=\r\n array([[ 101, 2774, 1142, 1105, 1143, 1315,  102,    0,    0,    0,    0,\r\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\r\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\r\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\r\n            0,    0,    0,    0]], dtype=int32)>,\r\n <tf.Tensor: id=5316, shape=(1, 48), dtype=int32, numpy=\r\n array([[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n         0, 0, 0, 0]], dtype=int32)>,\r\n <tf.Tensor: id=5317, shape=(1, 48), dtype=int32, numpy=\r\n array([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n         0, 0, 0, 0]], dtype=int32)>)\r\n```\r\n\r\nUsing eager mode its straight forward to implement naively: \r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_text as tf_text\r\n\r\nwp_tokenizer = tf_text.WordpieceTokenizer(vocab_table,\r\n                                       token_out_type=tf.int64)\r\n\r\nws_tokenizer = tf_text.WhitespaceTokenizer()\r\n\r\n\r\n# a low effort implementation of berts tokenizer\r\n@tf.function\r\ndef tokenizer_fn(x):\r\n    ws = ws_tokenizer.tokenize(x)\r\n    wp = wp_tokenizer.tokenize(ws)\r\n    return tf.cast(wp, tf.int32)\r\n\r\ndef bert_featureize(features):\r\n    \"\"\"Convert the raw text into the three tensors returned by bert preprocessing\"\"\"\r\n    \r\n    CLS = tf.constant([101], dtype=tf.int32)\r\n    SEP = tf.constant([102], dtype=tf.int32)\r\n    \r\n    # (B, Word, Word Piece)\r\n    # `take me to letter g` -> `<tf.RaggedTensor [[12882, 28304, 10376], \r\n    #                                             [10155], [30839], [27908], [10105], [34109]]>`\r\n    wp_tokens = tokenizer_fn(features)\r\n    input_ids = [] \r\n    input_masks = []\r\n    segment_ids = []\r\n    \r\n    # iterate over batch, flattening pieces back to word level, padding, etc\r\n    for tensor in wp_tokens:\r\n\r\n        ids = tf.concat([CLS, tensor.flat_values, SEP], axis=0)\r\n        length = len(ids)\r\n        padding = tf.zeros(ModelKeys.MAX_SEQ_LEN - length, tf.int32)\r\n        input_id = tf.concat([ids,padding],axis=0)\r\n        input_mask = tf.where((input_id == 0) | \r\n                              (input_id == ModelKeys.CLS_ID) | \r\n                              (input_id == ModelKeys.SEP_ID),\r\n                              0, \r\n                              tf.ones(ModelKeys.MAX_SEQ_LEN, tf.int32))\r\n        \r\n        input_mask = tf.cast(input_mask, tf.int32) \r\n        segment_id = tf.cast(input_id > 0, tf.int32)\r\n        input_ids.append(input_id)\r\n        input_masks.append(input_mask)\r\n        segment_ids.append(segment_id)\r\n    return tf.stack(input_ids), tf.stack(input_masks), tf.stack(segment_ids)\r\n\r\ninput_ids, input_masks, segment_ids =bert_featureize([['test this', 'and me too']])\r\n\r\n(<tf.Tensor: id=5315, shape=(1, 48), dtype=int32, numpy=\r\n array([[ 101, 2774, 1142, 1105, 1143, 1315,  102,    0,    0,    0,    0,\r\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\r\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\r\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\r\n            0,    0,    0,    0]], dtype=int32)>,\r\n <tf.Tensor: id=5316, shape=(1, 48), dtype=int32, numpy=\r\n array([[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n         0, 0, 0, 0]], dtype=int32)>,\r\n <tf.Tensor: id=5317, shape=(1, 48), dtype=int32, numpy=\r\n array([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n         0, 0, 0, 0]], dtype=int32)>)\r\n\r\n# a bert tensorflow hub module\r\nembeddings = module(input_ids, input_masks, segment_ids)\r\n# \r\n```\r\nHowever decorating `bert_featurize` with  `tf.function` does not correctly work \r\n\r\n```\r\n  ValueError: slice index 1 of dimension 0 out of bounds. for 'RaggedGetItem_1/strided_slice_2' (op: 'StridedSlice') with input shapes: [1], [1], [1], [1] and with computed input tensors: input[1] = <1>, input[2] = <2>, input[3] = <1>.\r\n```\r\n\r\nWe previously used a custom c++ tensorflow op that performed creating the input_ids etc as part of the graph but are looking to deprecate that now that this has been released. \r\n\r\nThanks!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/146", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/146/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/146/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/146/events", "html_url": "https://github.com/tensorflow/text/issues/146", "id": 516814391, "node_id": "MDU6SXNzdWU1MTY4MTQzOTE=", "number": 146, "title": "Should BasicTokenizer add [CLS] token?", "user": {"login": "lapolonio", "id": 1810412, "node_id": "MDQ6VXNlcjE4MTA0MTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1810412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lapolonio", "html_url": "https://github.com/lapolonio", "followers_url": "https://api.github.com/users/lapolonio/followers", "following_url": "https://api.github.com/users/lapolonio/following{/other_user}", "gists_url": "https://api.github.com/users/lapolonio/gists{/gist_id}", "starred_url": "https://api.github.com/users/lapolonio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lapolonio/subscriptions", "organizations_url": "https://api.github.com/users/lapolonio/orgs", "repos_url": "https://api.github.com/users/lapolonio/repos", "events_url": "https://api.github.com/users/lapolonio/events{/privacy}", "received_events_url": "https://api.github.com/users/lapolonio/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-03T11:28:04Z", "updated_at": "2019-11-05T11:12:21Z", "closed_at": "2019-11-05T11:12:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "The basic test here: https://github.com/tensorflow/text/blob/master/tensorflow_text/python/ops/bert_tokenizer_test.py#L180 shows that the `[CLS]` token isn't added.\r\n\r\nWhile the official Bert repo shows the token added: https://github.com/tensorflow/models/blob/master/official/nlp/bert/classifier_data_lib.py#L335\r\n\r\nIs this a purposeful difference? If so why?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/142", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/142/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/142/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/142/events", "html_url": "https://github.com/tensorflow/text/issues/142", "id": 511483707, "node_id": "MDU6SXNzdWU1MTE0ODM3MDc=", "number": 142, "title": "RaggedTensor requires merge_dims method", "user": {"login": "nicain", "id": 113055, "node_id": "MDQ6VXNlcjExMzA1NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/113055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nicain", "html_url": "https://github.com/nicain", "followers_url": "https://api.github.com/users/nicain/followers", "following_url": "https://api.github.com/users/nicain/following{/other_user}", "gists_url": "https://api.github.com/users/nicain/gists{/gist_id}", "starred_url": "https://api.github.com/users/nicain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nicain/subscriptions", "organizations_url": "https://api.github.com/users/nicain/orgs", "repos_url": "https://api.github.com/users/nicain/repos", "events_url": "https://api.github.com/users/nicain/events{/privacy}", "received_events_url": "https://api.github.com/users/nicain/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-10-23T17:59:51Z", "updated_at": "2019-11-02T04:22:31Z", "closed_at": "2019-11-02T04:22:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "On this line:\r\nhttps://github.com/tensorflow/text/blob/15ffafec84080d1c0accd7d4d4be17dd5497d299/tensorflow_text/python/ops/bert_tokenizer.py#L125\r\n\r\nRaggedTensor uses the merge_dims method.  However, this feature is currently not deployed in tf 2.0; it looks like it was added here: https://github.com/tensorflow/tensorflow/commit/6f29f5cbd16d65db399b96e956e6cd0a9ab8555c\r\n\r\nbut has yet to be deployed.\r\n\r\nMinimal reproducing example:\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_text as tft\r\n\r\nnum_oov_buckets = 3\r\ninitializer = tf.lookup.KeyValueTensorInitializer(['Hello', 'World'], [0, 1], value_dtype=tf.int64)\r\ntable = tf.lookup.StaticVocabularyTable(initializer, num_oov_buckets)\r\n\r\ndata = tf.constant(['World Hello missing'])\r\ntok = tft.BertTokenizer(table)\r\n\r\nsession = tf.compat.v1.Session()\r\ntf.compat.v1.tables_initializer()\r\n\r\noutput = tok.tokenize(data)\r\n\r\nprint(output[0][0].eval(session=session))\r\nprint(output[0][1].eval(session=session))\r\nprint(output[0][2].eval(session=session))\r\n```\r\n\r\nTraceback:\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_text/python/ops/bert_tokenizer.py\", line 195, in tokenize\r\n    tokens = self._basic_tokenizer.tokenize(text_input)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_text/python/ops/bert_tokenizer.py\", line 126, in tokenize\r\n    return final_tokens.merge_dims(-2, -1)\r\nAttributeError: 'RaggedTensor' object has no attribute 'merge_dims'", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/130", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/130/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/130/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/130/events", "html_url": "https://github.com/tensorflow/text/issues/130", "id": 506448756, "node_id": "MDU6SXNzdWU1MDY0NDg3NTY=", "number": 130, "title": "Run model using `WhitespaceTokenizer` from SavedModel Graph Error", "user": {"login": "eggie5", "id": 1122, "node_id": "MDQ6VXNlcjExMjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/1122?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eggie5", "html_url": "https://github.com/eggie5", "followers_url": "https://api.github.com/users/eggie5/followers", "following_url": "https://api.github.com/users/eggie5/following{/other_user}", "gists_url": "https://api.github.com/users/eggie5/gists{/gist_id}", "starred_url": "https://api.github.com/users/eggie5/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eggie5/subscriptions", "organizations_url": "https://api.github.com/users/eggie5/orgs", "repos_url": "https://api.github.com/users/eggie5/repos", "events_url": "https://api.github.com/users/eggie5/events{/privacy}", "received_events_url": "https://api.github.com/users/eggie5/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694864, "node_id": "MDU6TGFiZWwxMzgyNjk0ODY0", "url": "https://api.github.com/repos/tensorflow/text/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-10-14T05:06:19Z", "updated_at": "2020-03-05T23:16:09Z", "closed_at": "2020-01-07T00:00:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm using this for some simple tokenization in an Estimator text classifier model. When I try to run my model from SavedModel export, I get this error: `KeyError: 'WhitespaceTokenizeWithOffsets'`\r\n\r\n* TF: 1.14.0\r\n* TF-text: 0.1.0\r\n\r\nI export my model like this:\r\n\r\n```python\r\ndef serving_input_receiver_fn():\r\n    \"\"\"A function that takes no argument and returns a\r\n    `tf.estimator.export.ServingInputReceiver\"\"\"\r\n    \r\n    #1 parse the proto w/ the query string\r\n    #2 tokenize the query as \"query\"\r\n    #3 embedding picks up \"query\"\r\n    \r\n    serialized_tf_example = tf.placeholder(\r\n        dtype=tf.string,\r\n        shape=[None],\r\n        name='input_example_tensor')\r\n    receiver_tensors = {'examples': serialized_tf_example}\r\n    feature_spec = {'query': tf.FixedLenFeature(1, dtype=tf.string)}\r\n    features = tf.parse_example(serialized_tf_example, feature_spec)\r\n    \r\n    sparse_tokens = tokenizer.tokenize(features[\"query\"]).to_sparse()\r\n    \r\n    features = {'tokens': sparse_tokens}\r\n    \r\n    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\r\n\r\nclassifier.export_saved_model(\"exports/estimators-BOW-test\", serving_input_receiver_fn)\r\n```\r\n\r\nHowever, when I go to test my model, gets an error:\r\n\r\n```python\r\ntag_set = \"serve\"\r\nsaved_model_dir = \"exports/estimators-BOW-test/1571023056/\"\r\noutput_tensor_names_sorted = [\"dnn/head/Tile:0\",\r\n                              \"dnn/head/predictions/probabilities:0\"]\r\n\r\ninput_examples = [\"taco bell\", \"taco\", \"korean\", \"hancos\", \"tacos\", \"mashed potatoes\"]\r\nproto_str = make_examples(input_examples, \"query\")\r\ninputs_feed_dict = {\"input_example_tensor:0\": proto_str}\r\n\r\nCLASS_NAMES = np.array([\"CUISINE\", \"DISH\", \"RESTAURANT\", \"ADDRESS\"])\r\n\r\nwith tf.Session(graph=tf.Graph()) as sess:\r\n    loader.load(sess, tag_set.split(','), saved_model_dir)\r\n    outputs = sess.run(output_tensor_names_sorted,\r\n                       feed_dict=inputs_feed_dict)\r\n    for inputs, outputs in zip(input_examples, outputs[1]):\r\n        print(inputs, CLASS_NAMES[np.argmax(outputs)])\r\n```\r\n\r\nError:\r\n\r\n```\r\nKeyError: 'WhitespaceTokenizeWithOffsets'\r\n```\r\n\r\nI can make this error go away, if in my python process I import:\r\n\r\n```\r\nimport tensorflow_text as text\r\n```\r\n\r\nWhat is happening? Shouldn't all these ops be on the graph, so for example I could run this in Java or TF Serving(non-python env)??", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/116", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/116/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/116/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/116/events", "html_url": "https://github.com/tensorflow/text/issues/116", "id": 502165437, "node_id": "MDU6SXNzdWU1MDIxNjU0Mzc=", "number": 116, "title": "does the wordpiece tool the same with the bert one?", "user": {"login": "RyanHuangNLP", "id": 49582480, "node_id": "MDQ6VXNlcjQ5NTgyNDgw", "avatar_url": "https://avatars1.githubusercontent.com/u/49582480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RyanHuangNLP", "html_url": "https://github.com/RyanHuangNLP", "followers_url": "https://api.github.com/users/RyanHuangNLP/followers", "following_url": "https://api.github.com/users/RyanHuangNLP/following{/other_user}", "gists_url": "https://api.github.com/users/RyanHuangNLP/gists{/gist_id}", "starred_url": "https://api.github.com/users/RyanHuangNLP/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RyanHuangNLP/subscriptions", "organizations_url": "https://api.github.com/users/RyanHuangNLP/orgs", "repos_url": "https://api.github.com/users/RyanHuangNLP/repos", "events_url": "https://api.github.com/users/RyanHuangNLP/events{/privacy}", "received_events_url": "https://api.github.com/users/RyanHuangNLP/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-03T16:20:27Z", "updated_at": "2019-10-19T00:23:15Z", "closed_at": "2019-10-19T00:23:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Can I use this script to generate the vocab.txt to train bert [code](https://github.com/tensorflow/text/blob/master/tools/wordpiece_vocab/generate_vocab.py)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/114", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/114/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/114/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/114/events", "html_url": "https://github.com/tensorflow/text/issues/114", "id": 500742297, "node_id": "MDU6SXNzdWU1MDA3NDIyOTc=", "number": 114, "title": "Build from source instructions", "user": {"login": "mfojtak", "id": 13848117, "node_id": "MDQ6VXNlcjEzODQ4MTE3", "avatar_url": "https://avatars2.githubusercontent.com/u/13848117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mfojtak", "html_url": "https://github.com/mfojtak", "followers_url": "https://api.github.com/users/mfojtak/followers", "following_url": "https://api.github.com/users/mfojtak/following{/other_user}", "gists_url": "https://api.github.com/users/mfojtak/gists{/gist_id}", "starred_url": "https://api.github.com/users/mfojtak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mfojtak/subscriptions", "organizations_url": "https://api.github.com/users/mfojtak/orgs", "repos_url": "https://api.github.com/users/mfojtak/repos", "events_url": "https://api.github.com/users/mfojtak/events{/privacy}", "received_events_url": "https://api.github.com/users/mfojtak/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2019-10-01T08:29:05Z", "updated_at": "2019-11-21T00:28:13Z", "closed_at": "2019-11-21T00:28:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "The current pypi package is a bit old and there's no instruction how to build a latest one from source.\r\nAlso, is there a nightly build somewhere?\r\n\r\nThanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/97", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/97/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/97/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/97/events", "html_url": "https://github.com/tensorflow/text/issues/97", "id": 492608271, "node_id": "MDU6SXNzdWU0OTI2MDgyNzE=", "number": 97, "title": "import TensorFlow_text failure (Reason: image not found)", "user": {"login": "ethanwang27", "id": 3361433, "node_id": "MDQ6VXNlcjMzNjE0MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/3361433?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ethanwang27", "html_url": "https://github.com/ethanwang27", "followers_url": "https://api.github.com/users/ethanwang27/followers", "following_url": "https://api.github.com/users/ethanwang27/following{/other_user}", "gists_url": "https://api.github.com/users/ethanwang27/gists{/gist_id}", "starred_url": "https://api.github.com/users/ethanwang27/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ethanwang27/subscriptions", "organizations_url": "https://api.github.com/users/ethanwang27/orgs", "repos_url": "https://api.github.com/users/ethanwang27/repos", "events_url": "https://api.github.com/users/ethanwang27/events{/privacy}", "received_events_url": "https://api.github.com/users/ethanwang27/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-09-12T06:20:42Z", "updated_at": "2020-07-02T16:45:44Z", "closed_at": "2019-10-19T00:28:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/ethan/venv/nlp_env/lib/python3.7/site-packages/tensorflow_text/__init__.py\", line 20, in <module>\r\n    from tensorflow_text.python.ops import *\r\n  File \"/Users/ethan/venv/nlp_env/lib/python3.7/site-packages/tensorflow_text/python/ops/__init__.py\", line 19, in <module>\r\n    from tensorflow_text.python.ops.greedy_constrained_sequence_op import greedy_constrained_sequence\r\n  File \"/Users/ethan/venv/nlp_env/lib/python3.7/site-packages/tensorflow_text/python/ops/greedy_constrained_sequence_op.py\", line 34, in <module>\r\n    gen_constrained_sequence_op = load_library.load_op_library(resource_loader.get_path_to_datafile('_constrained_sequence_op.so'))\r\n  File \"/Users/ethan/venv/nlp_env/lib/python3.7/site-packages/tensorflow_core/python/framework/load_library.py\", line 61, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: dlopen(/Users/ethan/venv/nlp_env/lib/python3.7/site-packages/tensorflow_text/python/ops/_constrained_sequence_op.so, 6): Library not loaded: @rpath/libtensorflow_framework.1.dylib\r\n  Referenced from: /Users/ethan/venv/nlp_env/lib/python3.7/site-packages/tensorflow_text/python/ops/_constrained_sequence_op.so\r\n  Reason: image not found\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/89", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/89/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/89/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/89/events", "html_url": "https://github.com/tensorflow/text/issues/89", "id": 489699727, "node_id": "MDU6SXNzdWU0ODk2OTk3Mjc=", "number": 89, "title": "No matching distribution found for tensorflow-text", "user": {"login": "QUENTINNE", "id": 30227994, "node_id": "MDQ6VXNlcjMwMjI3OTk0", "avatar_url": "https://avatars1.githubusercontent.com/u/30227994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/QUENTINNE", "html_url": "https://github.com/QUENTINNE", "followers_url": "https://api.github.com/users/QUENTINNE/followers", "following_url": "https://api.github.com/users/QUENTINNE/following{/other_user}", "gists_url": "https://api.github.com/users/QUENTINNE/gists{/gist_id}", "starred_url": "https://api.github.com/users/QUENTINNE/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/QUENTINNE/subscriptions", "organizations_url": "https://api.github.com/users/QUENTINNE/orgs", "repos_url": "https://api.github.com/users/QUENTINNE/repos", "events_url": "https://api.github.com/users/QUENTINNE/events{/privacy}", "received_events_url": "https://api.github.com/users/QUENTINNE/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2019-09-05T11:44:02Z", "updated_at": "2020-07-28T14:56:03Z", "closed_at": "2019-10-19T00:30:07Z", "author_association": "NONE", "active_lock_reason": null, "body": " **I failed to install tensorflow-text.** \r\n\r\nWhen I enter `pip install -U tensorflow-text`\r\n\r\nThere was an error: \r\n\r\n> Could not find a version that satisfies the requirement tensorflow-text (from versions: )\r\n> No matching distribution found for tensorflow-text\r\n\r\n- Python 3.5.4  [MSC v.1900 64 bit (AMD64)] on win32\r\n- Tensorflow 2.0.0rc0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/85", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/85/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/85/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/85/events", "html_url": "https://github.com/tensorflow/text/issues/85", "id": 487288620, "node_id": "MDU6SXNzdWU0ODcyODg2MjA=", "number": 85, "title": "add \"step\" and \"drop_remainder\" param to \"sliding_window\"", "user": {"login": "EternalMoment", "id": 9221193, "node_id": "MDQ6VXNlcjkyMjExOTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/9221193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EternalMoment", "html_url": "https://github.com/EternalMoment", "followers_url": "https://api.github.com/users/EternalMoment/followers", "following_url": "https://api.github.com/users/EternalMoment/following{/other_user}", "gists_url": "https://api.github.com/users/EternalMoment/gists{/gist_id}", "starred_url": "https://api.github.com/users/EternalMoment/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EternalMoment/subscriptions", "organizations_url": "https://api.github.com/users/EternalMoment/orgs", "repos_url": "https://api.github.com/users/EternalMoment/repos", "events_url": "https://api.github.com/users/EternalMoment/events{/privacy}", "received_events_url": "https://api.github.com/users/EternalMoment/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1382694860, "node_id": "MDU6TGFiZWwxMzgyNjk0ODYw", "url": "https://api.github.com/repos/tensorflow/text/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-30T05:10:31Z", "updated_at": "2020-01-09T16:41:46Z", "closed_at": "2020-01-09T16:41:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey team,\r\n\r\nFor the current `sliding_window` function, would you consider add a `step` param, which indicates the number of steps moving forward for the next window?\r\n\r\nThe `drop_remainder' = True param will drop windows which have length less than width.\r\n\r\nFor example:\r\nwidth=2, step=2, drop_remainder=False\r\n[1,2,3,4,5]  => (1,2) (3,4) (5)\r\n\r\nwidth=2, step=2, drop_remainder=True\r\n[1,2,3,4,5]  => (1,2) (3,4) \r\n\r\nthanks!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/84", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/84/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/84/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/84/events", "html_url": "https://github.com/tensorflow/text/issues/84", "id": 487265418, "node_id": "MDU6SXNzdWU0ODcyNjU0MTg=", "number": 84, "title": "Tokenizer TF.Data Transform Crashes ", "user": {"login": "luischinchillagarcia", "id": 50338632, "node_id": "MDQ6VXNlcjUwMzM4NjMy", "avatar_url": "https://avatars3.githubusercontent.com/u/50338632?v=4", "gravatar_id": "", "url": "https://api.github.com/users/luischinchillagarcia", "html_url": "https://github.com/luischinchillagarcia", "followers_url": "https://api.github.com/users/luischinchillagarcia/followers", "following_url": "https://api.github.com/users/luischinchillagarcia/following{/other_user}", "gists_url": "https://api.github.com/users/luischinchillagarcia/gists{/gist_id}", "starred_url": "https://api.github.com/users/luischinchillagarcia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/luischinchillagarcia/subscriptions", "organizations_url": "https://api.github.com/users/luischinchillagarcia/orgs", "repos_url": "https://api.github.com/users/luischinchillagarcia/repos", "events_url": "https://api.github.com/users/luischinchillagarcia/events{/privacy}", "received_events_url": "https://api.github.com/users/luischinchillagarcia/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-08-30T03:19:34Z", "updated_at": "2019-10-19T00:31:09Z", "closed_at": "2019-10-19T00:31:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "When using the .apply method as a transformation for a tf.data object on to a text tokenizer, it crashes all Colab sessions (both in TF 1.x and 2.0). Here is a sample taken from the official colab notebook.\r\n\r\n\r\n```\r\ndocs = tf.data.Dataset.from_tensor_slices([['Never tell me the odds.'],\r\n                                           [\"It's a trap!\"]])\r\ntokenizer = text.WhitespaceTokenizer()\r\ntokenized_docs = docs.map(lambda x: tokenizer.tokenize(x))\r\niterator = tokenized_docs.make_one_shot_iterator()\r\nprint(iterator.get_next().to_list())\r\nprint(iterator.get_next().to_list())\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/72", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/72/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/72/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/72/events", "html_url": "https://github.com/tensorflow/text/issues/72", "id": 477272239, "node_id": "MDU6SXNzdWU0NzcyNzIyMzk=", "number": 72, "title": "Error with string output wordpiece tokenization", "user": {"login": "matthen", "id": 1408110, "node_id": "MDQ6VXNlcjE0MDgxMTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1408110?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthen", "html_url": "https://github.com/matthen", "followers_url": "https://api.github.com/users/matthen/followers", "following_url": "https://api.github.com/users/matthen/following{/other_user}", "gists_url": "https://api.github.com/users/matthen/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthen/subscriptions", "organizations_url": "https://api.github.com/users/matthen/orgs", "repos_url": "https://api.github.com/users/matthen/repos", "events_url": "https://api.github.com/users/matthen/events{/privacy}", "received_events_url": "https://api.github.com/users/matthen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-06T09:32:05Z", "updated_at": "2019-08-16T18:22:35Z", "closed_at": "2019-08-16T18:22:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I am finding an error when trying to do wordpiece tokenization, with string subtoken output:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_text as tf_text\r\n\r\nsess = tf.InteractiveSession()\r\ny = tf.constant([\"ab\", \"a\", \"c\"], dtype=tf.string)\r\nvocab = tf.lookup.KeyValueTensorInitializer(\r\n    keys=y, values=y,\r\n    key_dtype=tf.string,\r\n    value_dtype=tf.string,\r\n)\r\nvocab_lookup_table = tf.lookup.StaticHashTable(vocab, \"\")\r\ntokenizer = tf_text.WordpieceTokenizer(\r\n    vocab_lookup_table=vocab_lookup_table,\r\n    token_out_type=tf.string,\r\n    unknown_token=None,\r\n    suffix_indicator=\"\",\r\n)\r\nsess.run(tf.tables_initializer())\r\nprint(\r\n    sess.run(tokenizer.tokenize([\"abc\", \"ad\"]))\r\n)\r\n```\r\n\r\nI would expect the output `[[\"ab\", \"c\"], [\"a\", \"d\"]]`, but actually see:\r\n\r\n```\r\nF tensorflow/core/framework/tensor.cc:624] Check failed: dtype() == expected_dtype (9 vs. 7) string expected, got int64\r\nAbort trap: 6\r\n```\r\n\r\ntensorflow_text version 0.1.0rc2, tensorflow version 1.14.0", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/71", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/71/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/71/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/71/events", "html_url": "https://github.com/tensorflow/text/issues/71", "id": 477197279, "node_id": "MDU6SXNzdWU0NzcxOTcyNzk=", "number": 71, "title": "Potential optimization for LongestMatchStartingAt in WordpieceTokenizer?", "user": {"login": "matthen", "id": 1408110, "node_id": "MDQ6VXNlcjE0MDgxMTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1408110?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthen", "html_url": "https://github.com/matthen", "followers_url": "https://api.github.com/users/matthen/followers", "following_url": "https://api.github.com/users/matthen/following{/other_user}", "gists_url": "https://api.github.com/users/matthen/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthen/subscriptions", "organizations_url": "https://api.github.com/users/matthen/orgs", "repos_url": "https://api.github.com/users/matthen/repos", "events_url": "https://api.github.com/users/matthen/events{/privacy}", "received_events_url": "https://api.github.com/users/matthen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-08-06T06:39:52Z", "updated_at": "2019-08-27T19:20:36Z", "closed_at": "2019-08-27T19:20:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently the code uses a maximum word length, and refuses to tokenize longer words. The `LongestMatchStartingAt` helper function considers all string prefixes starting with the entire word.\r\n\r\nIf we instead passed the maximum subtoken length, then perhaps `LongestMatchStartingAt` could consider prefixes of at most that length. This could speed up this function and might mean we don't need to set a maximum word length.\r\n\r\nSorry if I have misunderstood something!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/70", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/70/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/70/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/70/events", "html_url": "https://github.com/tensorflow/text/issues/70", "id": 476015195, "node_id": "MDU6SXNzdWU0NzYwMTUxOTU=", "number": 70, "title": "WordpieceTokenizer vocab_lookup_table initialization", "user": {"login": "EternalMoment", "id": 9221193, "node_id": "MDQ6VXNlcjkyMjExOTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/9221193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EternalMoment", "html_url": "https://github.com/EternalMoment", "followers_url": "https://api.github.com/users/EternalMoment/followers", "following_url": "https://api.github.com/users/EternalMoment/following{/other_user}", "gists_url": "https://api.github.com/users/EternalMoment/gists{/gist_id}", "starred_url": "https://api.github.com/users/EternalMoment/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EternalMoment/subscriptions", "organizations_url": "https://api.github.com/users/EternalMoment/orgs", "repos_url": "https://api.github.com/users/EternalMoment/repos", "events_url": "https://api.github.com/users/EternalMoment/events{/privacy}", "received_events_url": "https://api.github.com/users/EternalMoment/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-02T06:18:00Z", "updated_at": "2019-08-06T04:40:00Z", "closed_at": "2019-08-06T04:40:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey team,\r\n\r\nHow could I initialize a `vocab_lookup_table` in `WordpieceTokenizer`. It would be great to add this into the current documentation. Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/61", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/61/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/61/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/61/events", "html_url": "https://github.com/tensorflow/text/issues/61", "id": 473381592, "node_id": "MDU6SXNzdWU0NzMzODE1OTI=", "number": 61, "title": "tensorflow-text crashes in google colab", "user": {"login": "kpe", "id": 2535923, "node_id": "MDQ6VXNlcjI1MzU5MjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/2535923?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kpe", "html_url": "https://github.com/kpe", "followers_url": "https://api.github.com/users/kpe/followers", "following_url": "https://api.github.com/users/kpe/following{/other_user}", "gists_url": "https://api.github.com/users/kpe/gists{/gist_id}", "starred_url": "https://api.github.com/users/kpe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kpe/subscriptions", "organizations_url": "https://api.github.com/users/kpe/orgs", "repos_url": "https://api.github.com/users/kpe/repos", "events_url": "https://api.github.com/users/kpe/events{/privacy}", "received_events_url": "https://api.github.com/users/kpe/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2019-07-26T14:16:35Z", "updated_at": "2019-08-02T08:45:15Z", "closed_at": "2019-07-31T08:33:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "When executed in Google Colab, this code crashes the session:\r\n```\r\n!pip install tensorflow_text\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_text as text\r\n\r\ndocs = tf.data.Dataset.from_tensor_slices([['Never tell me the odds.'], [\"It's a trap!\"]])\r\ntokenizer = text.WhitespaceTokenizer()\r\ntokenized_docs = docs.map(lambda x: tokenizer.tokenize(x))\r\niterator = tokenized_docs.make_one_shot_iterator()\r\nprint(iterator.get_next().to_list())\r\n```\r\n\r\nIt also SegFaults when executed locally.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/39", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/39/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/39/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/39/events", "html_url": "https://github.com/tensorflow/text/issues/39", "id": 463856585, "node_id": "MDU6SXNzdWU0NjM4NTY1ODU=", "number": 39, "title": "Tensorflow text incompatible with Tensorflow 2.0.0-beta1", "user": {"login": "maxpoulain", "id": 11405559, "node_id": "MDQ6VXNlcjExNDA1NTU5", "avatar_url": "https://avatars0.githubusercontent.com/u/11405559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxpoulain", "html_url": "https://github.com/maxpoulain", "followers_url": "https://api.github.com/users/maxpoulain/followers", "following_url": "https://api.github.com/users/maxpoulain/following{/other_user}", "gists_url": "https://api.github.com/users/maxpoulain/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxpoulain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxpoulain/subscriptions", "organizations_url": "https://api.github.com/users/maxpoulain/orgs", "repos_url": "https://api.github.com/users/maxpoulain/repos", "events_url": "https://api.github.com/users/maxpoulain/events{/privacy}", "received_events_url": "https://api.github.com/users/maxpoulain/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-07-03T16:52:40Z", "updated_at": "2019-08-26T20:33:23Z", "closed_at": "2019-08-01T19:24:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi ! \r\n\r\nI just installed tensorflow==2.0.0-beta1 and I get the following issue :\r\n\r\n```\r\nERROR: tensorflow-text 1.0.0b0 has requirement tensorflow==2.0.0b0, but you'll have tensorflow 2.0.0b1 which is incompatible.\r\n```\r\n\r\nHow can I resolve this issue ? \r\n\r\nThanks,\r\n\r\nMaxime", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/38", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/38/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/38/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/38/events", "html_url": "https://github.com/tensorflow/text/issues/38", "id": 462351354, "node_id": "MDU6SXNzdWU0NjIzNTEzNTQ=", "number": 38, "title": "Error: Could not retrieve ICU NFKC normalizer", "user": {"login": "Guitaricet", "id": 2821124, "node_id": "MDQ6VXNlcjI4MjExMjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/2821124?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Guitaricet", "html_url": "https://github.com/Guitaricet", "followers_url": "https://api.github.com/users/Guitaricet/followers", "following_url": "https://api.github.com/users/Guitaricet/following{/other_user}", "gists_url": "https://api.github.com/users/Guitaricet/gists{/gist_id}", "starred_url": "https://api.github.com/users/Guitaricet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Guitaricet/subscriptions", "organizations_url": "https://api.github.com/users/Guitaricet/orgs", "repos_url": "https://api.github.com/users/Guitaricet/repos", "events_url": "https://api.github.com/users/Guitaricet/events{/privacy}", "received_events_url": "https://api.github.com/users/Guitaricet/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-29T23:38:45Z", "updated_at": "2019-08-01T19:33:46Z", "closed_at": "2019-08-01T19:33:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "**System information**\r\n\r\n  * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n  * OS Platform and Distribution: MacOS 10.14.5\r\n  * TensorFlow installed from (source or binary): binary\r\n  * TensorFlow version: 2.0.0b0\r\n  * Python version: Python 3.7.2\r\n  * CUDA/cuDNN version: None\r\n  * GPU model and memory: None\r\n\r\n**Describe the current behavior**\r\nError on calling normalize_utf8\r\n\r\n**Describe the expected behavior**\r\nnormalize_utf8 should not fail\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_text as text\r\ntf.enable_eager_execution()\r\n\r\nprint(text.normalize_utf8(['\u00c4ffin']))\r\n```\r\n\r\n**Error**\r\n\r\n```python\r\n/usr/local/lib/python3.7/site-packages/tensorflow_text/python/ops/normalize_ops.py in normalize_utf8(input, normalization_form, name)\r\n     87       return input_tensor.with_flat_values(result)\r\n     88     else:\r\n---> 89       return gen_normalize_ops.normalize_utf8(input_tensor, normalization_form)\r\n\r\n<string> in normalize_utf8(input, normalization_form, name)\r\n\r\n/usr/local/lib/python3.7/site-packages/six.py in raise_from(value, from_value)\r\n\r\nInternalError: U_FILE_ACCESS_ERROR: Could not retrieve ICU NFKC normalizer [Op:NormalizeUTF8]\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/30", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/30/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/30/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/30/events", "html_url": "https://github.com/tensorflow/text/issues/30", "id": 461129768, "node_id": "MDU6SXNzdWU0NjExMjk3Njg=", "number": 30, "title": "undefined symbol: _ZN10tensorflow7strings6StrCatERKNS0_8AlphaNumES3_ error while importing tensorflow_text", "user": {"login": "colonder", "id": 16627326, "node_id": "MDQ6VXNlcjE2NjI3MzI2", "avatar_url": "https://avatars2.githubusercontent.com/u/16627326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colonder", "html_url": "https://github.com/colonder", "followers_url": "https://api.github.com/users/colonder/followers", "following_url": "https://api.github.com/users/colonder/following{/other_user}", "gists_url": "https://api.github.com/users/colonder/gists{/gist_id}", "starred_url": "https://api.github.com/users/colonder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colonder/subscriptions", "organizations_url": "https://api.github.com/users/colonder/orgs", "repos_url": "https://api.github.com/users/colonder/repos", "events_url": "https://api.github.com/users/colonder/events{/privacy}", "received_events_url": "https://api.github.com/users/colonder/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-26T18:56:14Z", "updated_at": "2019-10-19T00:34:22Z", "closed_at": "2019-10-19T00:34:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Kubuntu 18.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0b0\r\n- Python version: Anaconda python 3.7.3\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n**Describe the current behavior**\r\nError on importing `tensorflow-text` making it impossible to be imported.\r\n\r\n**Describe the expected behavior**\r\nLibrary can be effortlessly imported and used.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nI created a new environment using\r\n```\r\nconda create --name tensorflow python=3.7 numpy matplotlib scikit-learn pandas scipy\r\nconda activate tensorflow\r\npip install tensorflow-text\r\n```\r\nthen, when trying to import `tensorflow_text` the following error appears\r\n```\r\n$ python\r\nPython 3.7.3 (default, Mar 27 2019, 22:11:17) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> import tensorflow_text as text\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_text/__init__.py\", line 20, in <module>\r\n    from tensorflow_text.python.ops import *\r\n  File \"/home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_text/python/ops/__init__.py\", line 19, in <module>\r\n    from tensorflow_text.python.ops.greedy_constrained_sequence_op import greedy_constrained_sequence\r\n  File \"/home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_text/python/ops/greedy_constrained_sequence_op.py\", line 34, in <module>\r\n    gen_constrained_sequence_op = load_library.load_op_library(resource_loader.get_path_to_datafile('_constrained_sequence_op.so'))\r\n  File \"/home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/load_library.py\", line 61, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/kuba/.anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_text/python/ops/_constrained_sequence_op.so: undefined symbol: _ZN10tensorflow7strings6StrCatERKNS0_8AlphaNumES3_\r\n>>>\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/28", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/28/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/28/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/28/events", "html_url": "https://github.com/tensorflow/text/issues/28", "id": 461058822, "node_id": "MDU6SXNzdWU0NjEwNTg4MjI=", "number": 28, "title": "Please fix setup.py to allow tensorflow-gpu", "user": {"login": "sbarman-mi9", "id": 14152255, "node_id": "MDQ6VXNlcjE0MTUyMjU1", "avatar_url": "https://avatars3.githubusercontent.com/u/14152255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sbarman-mi9", "html_url": "https://github.com/sbarman-mi9", "followers_url": "https://api.github.com/users/sbarman-mi9/followers", "following_url": "https://api.github.com/users/sbarman-mi9/following{/other_user}", "gists_url": "https://api.github.com/users/sbarman-mi9/gists{/gist_id}", "starred_url": "https://api.github.com/users/sbarman-mi9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sbarman-mi9/subscriptions", "organizations_url": "https://api.github.com/users/sbarman-mi9/orgs", "repos_url": "https://api.github.com/users/sbarman-mi9/repos", "events_url": "https://api.github.com/users/sbarman-mi9/events{/privacy}", "received_events_url": "https://api.github.com/users/sbarman-mi9/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "broken", "id": 34356, "node_id": "MDQ6VXNlcjM0MzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/34356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/broken", "html_url": "https://github.com/broken", "followers_url": "https://api.github.com/users/broken/followers", "following_url": "https://api.github.com/users/broken/following{/other_user}", "gists_url": "https://api.github.com/users/broken/gists{/gist_id}", "starred_url": "https://api.github.com/users/broken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/broken/subscriptions", "organizations_url": "https://api.github.com/users/broken/orgs", "repos_url": "https://api.github.com/users/broken/repos", "events_url": "https://api.github.com/users/broken/events{/privacy}", "received_events_url": "https://api.github.com/users/broken/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-06-26T16:04:46Z", "updated_at": "2019-07-15T17:18:44Z", "closed_at": "2019-07-12T00:11:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Please fix setup.py to allow tensorflow-gpu:\r\n\r\nOld: \r\ninstall_requires=[\r\n        'tensorflow==2.0.0b0',\r\n   ],\r\n\r\nNew:\r\ninstall_requires=[\r\n        'tensorflow-gpu >=2.0.0b0',\r\n ],\r\nextras_require = [ 'tensorflow >=2.0.0b0', ]\r\n\r\n\r\nThanks,\r\nSnehasish", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/27", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/27/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/27/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/27/events", "html_url": "https://github.com/tensorflow/text/issues/27", "id": 460350591, "node_id": "MDU6SXNzdWU0NjAzNTA1OTE=", "number": 27, "title": "vocab_lookup_table must be a LookupInterface", "user": {"login": "chikubee", "id": 25073753, "node_id": "MDQ6VXNlcjI1MDczNzUz", "avatar_url": "https://avatars2.githubusercontent.com/u/25073753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chikubee", "html_url": "https://github.com/chikubee", "followers_url": "https://api.github.com/users/chikubee/followers", "following_url": "https://api.github.com/users/chikubee/following{/other_user}", "gists_url": "https://api.github.com/users/chikubee/gists{/gist_id}", "starred_url": "https://api.github.com/users/chikubee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chikubee/subscriptions", "organizations_url": "https://api.github.com/users/chikubee/orgs", "repos_url": "https://api.github.com/users/chikubee/repos", "events_url": "https://api.github.com/users/chikubee/events{/privacy}", "received_events_url": "https://api.github.com/users/chikubee/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-25T10:48:56Z", "updated_at": "2019-06-28T05:29:10Z", "closed_at": "2019-06-25T16:51:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Couldn't run the wordpiece tokenizer, \r\nvocab_lookup_table must be a LookupInterface\r\nwhat is the format of the file it is looking for? \r\nAny Leads?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/25", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/25/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/25/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/25/events", "html_url": "https://github.com/tensorflow/text/issues/25", "id": 459019301, "node_id": "MDU6SXNzdWU0NTkwMTkzMDE=", "number": 25, "title": "Tensorflow 1.x support?", "user": {"login": "matthen", "id": 1408110, "node_id": "MDQ6VXNlcjE0MDgxMTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1408110?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthen", "html_url": "https://github.com/matthen", "followers_url": "https://api.github.com/users/matthen/followers", "following_url": "https://api.github.com/users/matthen/following{/other_user}", "gists_url": "https://api.github.com/users/matthen/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthen/subscriptions", "organizations_url": "https://api.github.com/users/matthen/orgs", "repos_url": "https://api.github.com/users/matthen/repos", "events_url": "https://api.github.com/users/matthen/events{/privacy}", "received_events_url": "https://api.github.com/users/matthen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-21T05:44:42Z", "updated_at": "2019-08-01T19:36:24Z", "closed_at": "2019-08-01T19:36:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Firstly, thanks for this code! It makes serializing and sharing text-based models much easier. We currently use custom ops for e.g. subword tokenization and would love to switch over to the one in this repo, facilitating sharing models over tf hub etc.\r\n\r\nIs there any plan to support tensorflow 1.x versions? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/16", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/16/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/16/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/16/events", "html_url": "https://github.com/tensorflow/text/issues/16", "id": 455015710, "node_id": "MDU6SXNzdWU0NTUwMTU3MTA=", "number": 16, "title": "List of Languages Supported (E.g. English)", "user": {"login": "nicholaslaw", "id": 24500912, "node_id": "MDQ6VXNlcjI0NTAwOTEy", "avatar_url": "https://avatars3.githubusercontent.com/u/24500912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nicholaslaw", "html_url": "https://github.com/nicholaslaw", "followers_url": "https://api.github.com/users/nicholaslaw/followers", "following_url": "https://api.github.com/users/nicholaslaw/following{/other_user}", "gists_url": "https://api.github.com/users/nicholaslaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nicholaslaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nicholaslaw/subscriptions", "organizations_url": "https://api.github.com/users/nicholaslaw/orgs", "repos_url": "https://api.github.com/users/nicholaslaw/repos", "events_url": "https://api.github.com/users/nicholaslaw/events{/privacy}", "received_events_url": "https://api.github.com/users/nicholaslaw/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-12T05:16:52Z", "updated_at": "2019-06-12T17:45:37Z", "closed_at": "2019-06-12T17:45:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I just wanted to ask what are the languages supported by Tensorflow.text? From what I can see thus far, English, Chinese and German are supported. Thanks for answering! :)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/15", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/15/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/15/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/15/events", "html_url": "https://github.com/tensorflow/text/issues/15", "id": 455006188, "node_id": "MDU6SXNzdWU0NTUwMDYxODg=", "number": 15, "title": "windows 10 support", "user": {"login": "alanpurple", "id": 4515120, "node_id": "MDQ6VXNlcjQ1MTUxMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/4515120?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alanpurple", "html_url": "https://github.com/alanpurple", "followers_url": "https://api.github.com/users/alanpurple/followers", "following_url": "https://api.github.com/users/alanpurple/following{/other_user}", "gists_url": "https://api.github.com/users/alanpurple/gists{/gist_id}", "starred_url": "https://api.github.com/users/alanpurple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alanpurple/subscriptions", "organizations_url": "https://api.github.com/users/alanpurple/orgs", "repos_url": "https://api.github.com/users/alanpurple/repos", "events_url": "https://api.github.com/users/alanpurple/events{/privacy}", "received_events_url": "https://api.github.com/users/alanpurple/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-12T04:27:35Z", "updated_at": "2019-06-12T18:00:27Z", "closed_at": "2019-06-12T18:00:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "windows 10 support? scheduled or not?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/text/issues/13", "repository_url": "https://api.github.com/repos/tensorflow/text", "labels_url": "https://api.github.com/repos/tensorflow/text/issues/13/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/text/issues/13/comments", "events_url": "https://api.github.com/repos/tensorflow/text/issues/13/events", "html_url": "https://github.com/tensorflow/text/issues/13", "id": 454926632, "node_id": "MDU6SXNzdWU0NTQ5MjY2MzI=", "number": 13, "title": "unichr() and xrange() were removed in Python 3", "user": {"login": "cclauss", "id": 3709715, "node_id": "MDQ6VXNlcjM3MDk3MTU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3709715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cclauss", "html_url": "https://github.com/cclauss", "followers_url": "https://api.github.com/users/cclauss/followers", "following_url": "https://api.github.com/users/cclauss/following{/other_user}", "gists_url": "https://api.github.com/users/cclauss/gists{/gist_id}", "starred_url": "https://api.github.com/users/cclauss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cclauss/subscriptions", "organizations_url": "https://api.github.com/users/cclauss/orgs", "repos_url": "https://api.github.com/users/cclauss/repos", "events_url": "https://api.github.com/users/cclauss/events{/privacy}", "received_events_url": "https://api.github.com/users/cclauss/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-06-11T22:12:53Z", "updated_at": "2019-08-01T19:47:24Z", "closed_at": "2019-08-01T19:36:39Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "[flake8](http://flake8.pycqa.org) testing of https://github.com/tensorflow/text on Python 3.7.1\r\n\r\n$ __flake8 . --count --select=E9,F63,F72,F82 --show-source --statistics__\r\n```\r\n./tensorflow_text/python/ops/string_ops.py:29:12: F821 undefined name 'unichr'\r\n    return unichr(codepoint)\r\n           ^\r\n./tensorflow_text/python/ops/wordpiece_tokenizer_test.py:142:19: F821 undefined name 'xrange'\r\n  for docs_idx in xrange(len(tokens)):\r\n                  ^\r\n./tensorflow_text/python/ops/wordpiece_tokenizer_test.py:144:23: F821 undefined name 'xrange'\r\n    for tokens_idx in xrange(len(tokens[docs_idx])):\r\n                      ^\r\n3     F821 undefined name 'unichr'\r\n3\r\n```\r\n__E901,E999,F821,F822,F823__ are the \"_showstopper_\" [flake8](http://flake8.pycqa.org) issues that can halt the runtime with a SyntaxError, NameError, etc. These 5 are different from most other flake8 issues which are merely \"style violations\" -- useful for readability but they do not effect runtime safety.\r\n* F821: undefined name `name`\r\n* F822: undefined name `name` in `__all__`\r\n* F823: local variable name referenced before assignment\r\n* E901: SyntaxError or IndentationError\r\n* E999: SyntaxError -- failed to compile a file into an Abstract Syntax Tree\r\n", "performed_via_github_app": null, "score": 1.0}]}