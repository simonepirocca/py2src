{"total_count": 1325, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3102", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3102/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3102/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3102/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3102", "id": 683998091, "node_id": "MDU6SXNzdWU2ODM5OTgwOTE=", "number": 3102, "title": "Error when Implementing training_epoch_end() for GAN example", "user": {"login": "unknownue", "id": 42018661, "node_id": "MDQ6VXNlcjQyMDE4NjYx", "avatar_url": "https://avatars3.githubusercontent.com/u/42018661?v=4", "gravatar_id": "", "url": "https://api.github.com/users/unknownue", "html_url": "https://github.com/unknownue", "followers_url": "https://api.github.com/users/unknownue/followers", "following_url": "https://api.github.com/users/unknownue/following{/other_user}", "gists_url": "https://api.github.com/users/unknownue/gists{/gist_id}", "starred_url": "https://api.github.com/users/unknownue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/unknownue/subscriptions", "organizations_url": "https://api.github.com/users/unknownue/orgs", "repos_url": "https://api.github.com/users/unknownue/repos", "events_url": "https://api.github.com/users/unknownue/events{/privacy}", "received_events_url": "https://api.github.com/users/unknownue/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-08-22T13:30:42Z", "updated_at": "2020-08-22T14:19:45Z", "closed_at": "2020-08-22T14:19:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Go to [GAN example](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=P0bSmCw57aV5)\r\n2. Install latest version of pytorch-lightning (0.9.0)\r\n```shell\r\npip install pytorch-lightning==0.9.0\r\n```\r\n3. Implement training_epoch_end() method for GAN class\r\n```python\r\ndef training_epoch_end(self, outputs):\r\n    return outputs\r\n```\r\n\r\n4. Run training code cell\r\n```python\r\ngan_model = GAN(hparams)\r\n\r\ntrainer = pl.Trainer(gpus=1)    \r\ntrainer.fit(gan_model)   \r\n```\r\n5. See error\r\n```\r\n    138         # all keys not progress_bar or log are candidates for callbacks\r\n    139         callback_metrics = {}\r\n--> 140         for k, v in output.items():\r\n    141             if k not in ['progress_bar', 'log', 'hiddens']:\r\n    142                 callback_metrics[k] = v\r\n\r\nAttributeError: 'list' object has no attribute 'items'\r\n```\r\n\r\n### Expected behavior\r\n\r\nNo Error\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3083", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3083/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3083/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3083/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3083", "id": 683118693, "node_id": "MDU6SXNzdWU2ODMxMTg2OTM=", "number": 3083, "title": "TrainResult not found in pl installed from conda", "user": {"login": "fishyai", "id": 45679966, "node_id": "MDQ6VXNlcjQ1Njc5OTY2", "avatar_url": "https://avatars2.githubusercontent.com/u/45679966?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fishyai", "html_url": "https://github.com/fishyai", "followers_url": "https://api.github.com/users/fishyai/followers", "following_url": "https://api.github.com/users/fishyai/following{/other_user}", "gists_url": "https://api.github.com/users/fishyai/gists{/gist_id}", "starred_url": "https://api.github.com/users/fishyai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fishyai/subscriptions", "organizations_url": "https://api.github.com/users/fishyai/orgs", "repos_url": "https://api.github.com/users/fishyai/repos", "events_url": "https://api.github.com/users/fishyai/events{/privacy}", "received_events_url": "https://api.github.com/users/fishyai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1840917107, "node_id": "MDU6TGFiZWwxODQwOTE3MTA3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/documentation", "name": "documentation", "color": "0075ca", "default": true, "description": "Improvements or additions to documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-20T21:53:17Z", "updated_at": "2020-08-21T18:51:37Z", "closed_at": "2020-08-20T22:02:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udcda Documentation\r\nHi all,\r\n\r\nI'm going through the tutorials on how to set up lightning and the docs say to use a class called pl.TrainResult, but this class doesn't seem to exist in the version on conda. Is this a new feature?\r\n\r\nThanks!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3053", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3053/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3053/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3053/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3053", "id": 682147076, "node_id": "MDU6SXNzdWU2ODIxNDcwNzY=", "number": 3053, "title": "load_from_checkpoint() doesn't work when a LightningModule inherits from typing.Generic", "user": {"login": "yukw777", "id": 2057325, "node_id": "MDQ6VXNlcjIwNTczMjU=", "avatar_url": "https://avatars2.githubusercontent.com/u/2057325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yukw777", "html_url": "https://github.com/yukw777", "followers_url": "https://api.github.com/users/yukw777/followers", "following_url": "https://api.github.com/users/yukw777/following{/other_user}", "gists_url": "https://api.github.com/users/yukw777/gists{/gist_id}", "starred_url": "https://api.github.com/users/yukw777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yukw777/subscriptions", "organizations_url": "https://api.github.com/users/yukw777/orgs", "repos_url": "https://api.github.com/users/yukw777/repos", "events_url": "https://api.github.com/users/yukw777/events{/privacy}", "received_events_url": "https://api.github.com/users/yukw777/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 0, "created_at": "2020-08-19T20:11:59Z", "updated_at": "2020-08-20T11:19:12Z", "closed_at": "2020-08-20T11:19:12Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nWhen a LightningModule with saved hyperparameters inherits from `typing.Generic`, hyperparameters saved in the checkpoint file are not loaded automatically, causing an error. When `load_from_checkpoint()` calls `inspect.signature()` to gather the list of arguments of the LightningModule that inherits from `typing.Generic`, `inspect.signature()` returns `['args', 'kwds']` instead of the actual arguments, because `typing.Generic` implements an empty `__new__()` (the execution path ends up here: https://github.com/python/cpython/blob/3.8/Lib/inspect.py#L2324). As a result, PL filters out all the saved hyperparameters from the checkpoint, which results in an error when trying to instantiate the LightningModule. I'd assume this would happen when a LightningModule inherits from any class that implements `__new__()` such as `abc.ABC`.\r\n\r\n### To Reproduce\r\nCreate a LightningModule that inherits from `typing.Generic` with some hyperparameters, fit it, then try to load it from a checkpoint.\r\n\r\n\r\n#### Code sample\r\n```python\r\nimport torch\r\nimport torch.nn.functional as F\r\nimport pytorch_lightning as pl\r\n\r\nfrom typing import Generic, TypeVar\r\nfrom torch.utils.data import DataLoader\r\n\r\nT = TypeVar(\"T\")\r\n\r\n\r\nclass GenericLitClassifier(Generic[T], pl.LightningModule):\r\n    def __init__(self, dim):\r\n        super().__init__()\r\n        self.l1 = torch.nn.Linear(28 * 28, dim)\r\n        self.save_hyperparameters()\r\n\r\n    def forward(self, x):\r\n        return torch.relu(self.l1(x.view(x.size(0), -1)))\r\n\r\n    def training_step(self, batch, batch_nb):\r\n        x, y = batch\r\n        loss = F.cross_entropy(self(x), y)\r\n        tensorboard_logs = {\"train_loss\": loss}\r\n        return {\"loss\": loss, \"log\": tensorboard_logs}\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=0.02)\r\n\r\n\r\nclass LitClassifier(GenericLitClassifier[str]):\r\n    pass\r\n\r\n\r\nclass Dataset:\r\n    def __getitem__(self, idx):\r\n        return torch.ones(1, 784), 1\r\n\r\n    def __len__(self):\r\n        return 5\r\n\r\n\r\ntrain_loader = DataLoader(Dataset(), batch_size=2)\r\nmodel = LitClassifier(10)\r\ntrainer = pl.Trainer(max_epochs=5)\r\ntrainer.fit(model, train_loader)\r\n\r\nfor path, _ in trainer.checkpoint_callback.best_k_models.items():\r\n    lm = LitClassifier.load_from_checkpoint(path)\r\n```\r\n\r\n### Expected behavior\r\n\r\nEven when a LightningModule inherits from any class that implements `__new__()` (e.g. `typing.Generic`), its hyperparameters should be loaded automatically from a checkpoint.\r\n\r\n\r\n### Environment\r\n\r\n```\r\n* CUDA:\r\n        - GPU:\r\n        - available:         False\r\n        - version:           None\r\n* Packages:\r\n        - numpy:             1.19.1\r\n        - pyTorch_debug:     False\r\n        - pyTorch_version:   1.5.1\r\n        - pytorch-lightning: 0.8.5\r\n        - tensorboard:       2.3.0\r\n        - tqdm:              4.48.2\r\n* System:\r\n        - OS:                Darwin\r\n        - architecture:\r\n                - 64bit\r\n                - \r\n        - processor:         i386\r\n        - python:            3.7.7\r\n        - version:           Darwin Kernel Version 18.7.0: Mon Apr 27 20:09:39 PDT 2020; root:xnu-4903.278.35~1/RELEASE_X86_64\r\n```\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3051", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3051/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3051/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3051/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3051", "id": 681946797, "node_id": "MDU6SXNzdWU2ODE5NDY3OTc=", "number": 3051, "title": "How to scheduler.step() after every batch", "user": {"login": "benihime91", "id": 52747515, "node_id": "MDQ6VXNlcjUyNzQ3NTE1", "avatar_url": "https://avatars3.githubusercontent.com/u/52747515?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benihime91", "html_url": "https://github.com/benihime91", "followers_url": "https://api.github.com/users/benihime91/followers", "following_url": "https://api.github.com/users/benihime91/following{/other_user}", "gists_url": "https://api.github.com/users/benihime91/gists{/gist_id}", "starred_url": "https://api.github.com/users/benihime91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benihime91/subscriptions", "organizations_url": "https://api.github.com/users/benihime91/orgs", "repos_url": "https://api.github.com/users/benihime91/repos", "events_url": "https://api.github.com/users/benihime91/events{/privacy}", "received_events_url": "https://api.github.com/users/benihime91/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-19T15:43:16Z", "updated_at": "2020-08-19T16:57:47Z", "closed_at": "2020-08-19T16:57:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I want to make use of schedulers like `torch.optim.lr_scheduler.CyclicLR` & `torch.optim.lr_scheduler.OneCycleLR` \r\nhttps://pytorch.org/docs/stable/optim.html\r\nThese schedulers require `scheduler.step()` to be callled after each `batch`. \r\nHow to achieve this is `PyTorchLightning`?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3050", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3050/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3050/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3050/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3050", "id": 681894778, "node_id": "MDU6SXNzdWU2ODE4OTQ3Nzg=", "number": 3050, "title": "The speed of training is slow", "user": {"login": "jovenwayfarer", "id": 47921506, "node_id": "MDQ6VXNlcjQ3OTIxNTA2", "avatar_url": "https://avatars1.githubusercontent.com/u/47921506?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jovenwayfarer", "html_url": "https://github.com/jovenwayfarer", "followers_url": "https://api.github.com/users/jovenwayfarer/followers", "following_url": "https://api.github.com/users/jovenwayfarer/following{/other_user}", "gists_url": "https://api.github.com/users/jovenwayfarer/gists{/gist_id}", "starred_url": "https://api.github.com/users/jovenwayfarer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jovenwayfarer/subscriptions", "organizations_url": "https://api.github.com/users/jovenwayfarer/orgs", "repos_url": "https://api.github.com/users/jovenwayfarer/repos", "events_url": "https://api.github.com/users/jovenwayfarer/events{/privacy}", "received_events_url": "https://api.github.com/users/jovenwayfarer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-08-19T14:39:09Z", "updated_at": "2020-08-19T14:58:14Z", "closed_at": "2020-08-19T14:55:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello everyone, I want to calculate custom metric at end of training step.\r\n```    \r\ndef training_step(self, batch, batch_idx):\r\n        image, mask = batch\r\n        mask = mask.unsqueeze(1)\r\n        output = self.forward(image)\r\n        loss = self.loss(output,mask)\r\n        \r\n        train_preds = output.detach().cpu()\r\n        train_targets = mask.detach().cpu()\r\n        dice = metric(train_preds, train_targets, 1024, 0.5, 3500)\r\n```\r\nwhere metric is the following function:\r\n```\r\ndef post_process(probability, threshold, min_size):\r\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\r\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\r\n    predictions = np.zeros((1024, 1024), np.float32)\r\n    num = 0\r\n    for c in range(1, num_component):\r\n        p = (component == c)\r\n        if p.sum() > min_size:\r\n            predictions[p] = 1\r\n            num += 1\r\n    return predictions, num\r\n\r\ndef metric(probability, truth, imgsize, prob_threshold, min_object_size):\r\n    '''Calculates dice of positive and negative images seperately'''\r\n    '''probability and truth must be torch tensors'''\r\n    batch_size = len(truth)\r\n    with torch.no_grad():\r\n\r\n        # probability = probability.view(batch_size, -1)\r\n        truth = truth.view(batch_size, -1)  # torch.Size([4, 1048576])\r\n        # assert(probability.shape == truth.shape)\r\n        t = (truth > 0.5).float()\r\n        # print(probability.shape, truth.shape)\r\n\r\n        if min_object_size:\r\n            probability = probability.numpy()[:, 0, :, :]  # torch.Size([4, 1, 1024, 1024]) --> [4, 1024, 1024]\r\n            for i, prob in enumerate(probability):\r\n                predict, num_predict = post_process(prob, prob_threshold, min_object_size)\r\n                if num_predict == 0:\r\n                    probability[i, :, :] = 0\r\n                else:\r\n                    probability[i, :, :] = predict\r\n            p = torch.from_numpy(probability)\r\n            p = p.view(batch_size, -1).float()  # torch.Size([4, 1048576])\r\n        else:\r\n            probability = probability.view(batch_size, -1)\r\n            p = (probability > prob_threshold).float()\r\n\r\n        EPS = 1e-6\r\n        intersection = torch.sum(p * t, dim=1)\r\n        union = torch.sum(p, dim=1) + torch.sum(t, dim=1) + EPS\r\n        dice = (2*(intersection + EPS) / union).mean()\r\n        if dice > 1:\r\n            dice = 1\r\n\r\n    return dice\r\n```\r\nwhen I don't calculate the metric it runs well.\r\nWhat could be the problem?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3046", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3046/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3046/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3046/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3046", "id": 681555206, "node_id": "MDU6SXNzdWU2ODE1NTUyMDY=", "number": 3046, "title": "MLFlowLogger throws a JSONDecodeError", "user": {"login": "srib", "id": 8744288, "node_id": "MDQ6VXNlcjg3NDQyODg=", "avatar_url": "https://avatars0.githubusercontent.com/u/8744288?v=4", "gravatar_id": "", "url": "https://api.github.com/users/srib", "html_url": "https://github.com/srib", "followers_url": "https://api.github.com/users/srib/followers", "following_url": "https://api.github.com/users/srib/following{/other_user}", "gists_url": "https://api.github.com/users/srib/gists{/gist_id}", "starred_url": "https://api.github.com/users/srib/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/srib/subscriptions", "organizations_url": "https://api.github.com/users/srib/orgs", "repos_url": "https://api.github.com/users/srib/repos", "events_url": "https://api.github.com/users/srib/events{/privacy}", "received_events_url": "https://api.github.com/users/srib/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}, {"id": 1800433344, "node_id": "MDU6TGFiZWwxODAwNDMzMzQ0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/information%20needed", "name": "information needed", "color": "b673dd", "default": false, "description": "need more information about this"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-19T05:22:50Z", "updated_at": "2020-08-19T14:40:54Z", "closed_at": "2020-08-19T14:40:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n#### Code sample\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\n\r\n```python\r\nfrom pytorch_lightning import Trainer\r\nfrom pytorch_lightning.loggers import MLFlowLogger\r\nmlflow_logger = MLFlowLogger(experiment_name=\"test-experiment\", tracking_uri=\"URI_HERE\")\r\nt = Trainer(logger=mlflow_logger)\r\nt.logger.experiment_id\r\n```\r\nthrows a `JSONDecodeError` exception.\r\n```python\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/loggers/mlflow.py\", line 120, in experiment_id\r\n    _ = self.experiment\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py\", line 421, in experiment\r\n    return get_experiment() or DummyExperiment()\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py\", line 13, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py\", line 420, in get_experiment\r\n    return fn(self)\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/pytorch_lightning/loggers/mlflow.py\", line 98, in experiment\r\n    expt = self._mlflow_client.get_experiment_by_name(self._experiment_name)\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/mlflow/tracking/client.py\", line 154, in get_experiment_by_name\r\n    return self._tracking_client.get_experiment_by_name(name)\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py\", line 114, in get_experiment_by_name\r\n    return self.store.get_experiment_by_name(name)\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/mlflow/store/tracking/rest_store.py\", line 219, in get_experiment_by_name\r\n    response_proto = self._call_endpoint(GetExperimentByName, req_body)\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/mlflow/store/tracking/rest_store.py\", line 32, in _call_endpoint\r\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\r\n  File \"/envs/pl_env/lib/python3.7/site-packages/mlflow/utils/rest_utils.py\", line 145, in call_endpoint\r\n    js_dict = json.loads(response.text)\r\n  File \"/envs/pl_env/lib/python3.7/json/__init__.py\", line 348, in loads\r\n    return _default_decoder.decode(s)\r\n  File \"/envs/pl_env/lib/python3.7/json/decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n  File \"/envs/pl_env/lib/python3.7/json/decoder.py\", line 355, in raw_decode\r\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\n```\r\n### Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n### Environment\r\nEnvironment details\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.6.0\r\n - PyTorch Lightning Version: 0.9.0rc12\r\n - OS (e.g., Linux): Linux\r\n - How you installed PyTorch (`conda`, `pip`, source): conda\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.7.7\r\n - CUDA/cuDNN version: Not relevant\r\n - GPU models and configuration: Not relevant\r\n - Any other relevant information: Not relevant\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3041", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3041/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3041/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3041/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3041", "id": 681349265, "node_id": "MDU6SXNzdWU2ODEzNDkyNjU=", "number": 3041, "title": "RuntimeError: No `loss` value in the dictionary returned from `model.training_step()` with pytorch lightning", "user": {"login": "GuptaVishu2002", "id": 32040675, "node_id": "MDQ6VXNlcjMyMDQwNjc1", "avatar_url": "https://avatars3.githubusercontent.com/u/32040675?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GuptaVishu2002", "html_url": "https://github.com/GuptaVishu2002", "followers_url": "https://api.github.com/users/GuptaVishu2002/followers", "following_url": "https://api.github.com/users/GuptaVishu2002/following{/other_user}", "gists_url": "https://api.github.com/users/GuptaVishu2002/gists{/gist_id}", "starred_url": "https://api.github.com/users/GuptaVishu2002/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GuptaVishu2002/subscriptions", "organizations_url": "https://api.github.com/users/GuptaVishu2002/orgs", "repos_url": "https://api.github.com/users/GuptaVishu2002/repos", "events_url": "https://api.github.com/users/GuptaVishu2002/events{/privacy}", "received_events_url": "https://api.github.com/users/GuptaVishu2002/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-18T21:20:18Z", "updated_at": "2020-08-19T03:49:38Z", "closed_at": "2020-08-19T03:49:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n#### What is your question?\r\nI am trying to run a custom dataset using Pytorch lightning but am not able to do so due to the following error.\r\nThe input is an array with the shape as (n, m). Can anyone tell me what am I doing wrong?\r\n\r\n`Traceback (most recent call last):\r\n  File \"TestNet.py\", line 285, in <module>\r\n    trainer.fit(model)\r\n  File /path/to/pytorch/lib64/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1003, in fit\r\n    results = self.single_gpu_train(model)\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/pytorch_lightning/trainer/distrib_parts.py\", line 186, in single_gpu_train\r\n    results = self.run_pretrain_routine(model)\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1213, in run_pretrain_routine\r\n    self.train()\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 370, in train\r\n    self.run_training_epoch()\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 452, in run_training_epoch\r\n    batch_output = self.run_training_batch(batch, batch_idx)\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 632, in run_training_batch\r\n    self.hiddens\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 783, in optimizer_closure\r\n    training_step_output = self.process_output(training_step_output, train=True)\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/pytorch_lightning/trainer/logging.py\", line 159, in process_output\r\n    'No `loss` value in the dictionary returned from `model.training_step()`.'\r\nRuntimeError: No `loss` value in the dictionary returned from `model.training_step()`.\r\nException ignored in: <object repr() failed>\r\nTraceback (most recent call last):\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/tqdm/std.py\", line 1086, in __del__\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/tqdm/std.py\", line 1293, in close\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/tqdm/std.py\", line 1471, in display\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/tqdm/std.py\", line 1089, in __repr__\r\n  File \"/path/to/pytorch/lib64/python3.6/site-packages/tqdm/std.py\", line 1433, in format_dict\r\nTypeError: 'NoneType' object is not iterable`\r\n\r\n#### Code\r\nI have the training_step and the other functions as below\r\n\r\n`def training_step(self, train_batch, batch_idx):\r\n        x, y = train_batch\r\n        logits = self.forward(x)\r\n        loss = F.l1_loss(logits, y)\r\n        tensorboard_logs = {'train_loss': loss}\r\n        return {'train_loss': loss, 'log': tensorboard_logs}\r\n\r\n    def validation_step(self, val_batch, batch_idx):\r\n        x, y = val_batch\r\n        logits = self.forward(x)\r\n        loss = F.l1_loss(logits, y)\r\n        return {'val_loss': loss}\r\n\r\n    def validation_epoch_end(self, outputs):\r\n        # called at the end of the validation epoch\r\n        # outputs is an array with what you returned in validation_step for each batch\r\n        # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \r\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n        tensorboard_logs = {'val_loss': avg_loss}\r\n        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\r\n\r\n    def test_step(self, test_batch, batch_nb):\r\n        x, y = test_batch\r\n        logits = self.forward(x)\r\n        loss = F.l1_loss(logits, y)\r\n        correct = torch.sum(logits == y.data)\r\n        \r\n        # I want to visualize my predictions vs my actuals so here I'm going to \r\n        # add these lines to extract the data for plotting later on\r\n        predictions_pred.append(logits)\r\n        predictions_actual.append(y.data)\r\n        return {'test_loss': loss, 'test_correct': correct, 'logits': logits}\r\n\r\n    def test_epoch_end(self, outputs):\r\n        # called at the end of the test epoch\r\n        # outputs is an array with what you returned in test_step for each batch\r\n        # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \r\n        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\r\n        logs = {'test_loss': avg_loss}      \r\n        return {'avg_test_loss': avg_loss, 'log': logs, 'progress_bar': logs }    \r\n\r\n    def train_dataloader(self):\r\n        train_dataset = TensorDataset(torch.tensor(new_x_train).float(), torch.tensor(new_y_train).float())\r\n        train_loader = DataLoader(dataset = train_dataset, batch_size = 32)\r\n        return train_loader\r\n\r\n    def val_dataloader(self):\r\n        val_dataset = TensorDataset(torch.tensor(new_x_val).float(), torch.tensor(new_y_val).float())\r\n        val_loader = DataLoader(dataset = val_dataset, batch_size = 32)\r\n        return val_loader\r\n\r\n    def test_dataloader(self):\r\n        test_dataset = TensorDataset(torch.tensor(new_x_test).float(), torch.tensor(new_y_test).float())\r\n        test_loader = DataLoader(dataset = test_dataset, batch_size = 32)\r\n        return test_loader\r\n\r\n    def configure_optimizers(self):\r\n        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\r\n        return optimizer`\r\n\r\nI have defined the custom dataset outside of the Pytorch Lightning Module with new_x_train, new_y_train as input, and label for the training set. The naming is similar for validation as well as the test set.\r\n#### What's your environment?\r\n\r\n - OS:  Linux\r\n - Packaging pip", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3036", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3036/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3036/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3036/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3036", "id": 681184431, "node_id": "MDU6SXNzdWU2ODExODQ0MzE=", "number": 3036, "title": "freeze TB to 2.2.0", "user": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "teddykoker", "id": 11153048, "node_id": "MDQ6VXNlcjExMTUzMDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11153048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teddykoker", "html_url": "https://github.com/teddykoker", "followers_url": "https://api.github.com/users/teddykoker/followers", "following_url": "https://api.github.com/users/teddykoker/following{/other_user}", "gists_url": "https://api.github.com/users/teddykoker/gists{/gist_id}", "starred_url": "https://api.github.com/users/teddykoker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teddykoker/subscriptions", "organizations_url": "https://api.github.com/users/teddykoker/orgs", "repos_url": "https://api.github.com/users/teddykoker/repos", "events_url": "https://api.github.com/users/teddykoker/events{/privacy}", "received_events_url": "https://api.github.com/users/teddykoker/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "teddykoker", "id": 11153048, "node_id": "MDQ6VXNlcjExMTUzMDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11153048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teddykoker", "html_url": "https://github.com/teddykoker", "followers_url": "https://api.github.com/users/teddykoker/followers", "following_url": "https://api.github.com/users/teddykoker/following{/other_user}", "gists_url": "https://api.github.com/users/teddykoker/gists{/gist_id}", "starred_url": "https://api.github.com/users/teddykoker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teddykoker/subscriptions", "organizations_url": "https://api.github.com/users/teddykoker/orgs", "repos_url": "https://api.github.com/users/teddykoker/repos", "events_url": "https://api.github.com/users/teddykoker/events{/privacy}", "received_events_url": "https://api.github.com/users/teddykoker/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 1, "created_at": "2020-08-18T16:43:27Z", "updated_at": "2020-08-18T20:26:18Z", "closed_at": "2020-08-18T20:26:18Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3034", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3034/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3034/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3034/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3034", "id": 681099773, "node_id": "MDU6SXNzdWU2ODEwOTk3NzM=", "number": 3034, "title": "Distributed Data Training", "user": {"login": "bluesky314", "id": 35393972, "node_id": "MDQ6VXNlcjM1MzkzOTcy", "avatar_url": "https://avatars2.githubusercontent.com/u/35393972?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bluesky314", "html_url": "https://github.com/bluesky314", "followers_url": "https://api.github.com/users/bluesky314/followers", "following_url": "https://api.github.com/users/bluesky314/following{/other_user}", "gists_url": "https://api.github.com/users/bluesky314/gists{/gist_id}", "starred_url": "https://api.github.com/users/bluesky314/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bluesky314/subscriptions", "organizations_url": "https://api.github.com/users/bluesky314/orgs", "repos_url": "https://api.github.com/users/bluesky314/repos", "events_url": "https://api.github.com/users/bluesky314/events{/privacy}", "received_events_url": "https://api.github.com/users/bluesky314/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}, {"id": 1800433344, "node_id": "MDU6TGFiZWwxODAwNDMzMzQ0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/information%20needed", "name": "information needed", "color": "b673dd", "default": false, "description": "need more information about this"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 12, "created_at": "2020-08-18T14:43:33Z", "updated_at": "2020-08-19T23:12:04Z", "closed_at": "2020-08-19T23:12:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nimport pytorch_lightning as pl\r\nclass LightningModel(pl.LightningModule):\r\n\r\n    def __init__(self):\r\n        super(LightningModel, self).__init__()\r\n        # not the best model...\r\n        self.model = U2NET(3, 1)\r\n\r\n    def forward(self, x):\r\n        # called with self(x)\r\n        return self.model(x)\r\n\r\n    def training_step(self, batch, batch_nb):\r\n        # REQUIRED\r\n        x = batch['image'].float() \r\n        labels_v=batch['label'].double() \r\n        \r\n        d0, d1, d2, d3, d4, d5, d6 = self(x)\r\n        d0, d1, d2, d3, d4, d5, d6,loss2, loss = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v)\r\n        \r\n        tensorboard_logs = {'train_loss': loss}\r\n        return {'loss': loss, 'log': tensorboard_logs}\r\n\r\n\r\n    def configure_optimizers(self):\r\n\r\n        opt=torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0) \r\n#         scheduler=CombineCos(opt,0.2,lr,lr,5e-4,len(self.train_dataloader()),100)\r\n        return opt\r\n\r\n    def train_dataloader(self):\r\n        loaders=get_loader([size,size])\r\n        return loaders['train']\r\n\r\n\r\n    \r\ntrain_loader = get_loader([size,size])['train']\r\nmodel = LightningModel()\r\n\r\ntrainer = pl.Trainer(gpus=1)\r\ntrainer.fit(model, train_loader)\r\n\r\n```\r\n\r\nI want to do Distributed Training with 2 gpus with data parallel. \r\nThis works just fine with one gpu. But when I do `trainer = pl.Trainer(gpus=2)` or `trainer = pl.Trainer(gpus=[0,1])` I get an error:\r\n![Screen Shot 2020-08-18 at 8 12 18 PM](https://user-images.githubusercontent.com/35393972/90527485-37be1b00-e18f-11ea-9f79-cfc3e55e5e78.png)\r\n\r\n\r\nSystem\r\n - 3.6\r\n - Linux\r\n - pip\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - 10.1\r\n - Nvidia-100\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3033", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3033/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3033/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3033/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3033", "id": 680808603, "node_id": "MDU6SXNzdWU2ODA4MDg2MDM=", "number": 3033, "title": "0.9.0 rc16  tensorboard 2.3.0 can't find hparams data", "user": {"login": "xiadingZ", "id": 16729275, "node_id": "MDQ6VXNlcjE2NzI5Mjc1", "avatar_url": "https://avatars1.githubusercontent.com/u/16729275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiadingZ", "html_url": "https://github.com/xiadingZ", "followers_url": "https://api.github.com/users/xiadingZ/followers", "following_url": "https://api.github.com/users/xiadingZ/following{/other_user}", "gists_url": "https://api.github.com/users/xiadingZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiadingZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiadingZ/subscriptions", "organizations_url": "https://api.github.com/users/xiadingZ/orgs", "repos_url": "https://api.github.com/users/xiadingZ/repos", "events_url": "https://api.github.com/users/xiadingZ/events{/privacy}", "received_events_url": "https://api.github.com/users/xiadingZ/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2065663816, "node_id": "MDU6TGFiZWwyMDY1NjYzODE2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Important", "name": "Important", "color": "FFD700", "default": false, "description": "High important task, global impact"}, {"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}, {"id": 1800433344, "node_id": "MDU6TGFiZWwxODAwNDMzMzQ0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/information%20needed", "name": "information needed", "color": "b673dd", "default": false, "description": "need more information about this"}], "state": "closed", "locked": false, "assignee": {"login": "teddykoker", "id": 11153048, "node_id": "MDQ6VXNlcjExMTUzMDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11153048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teddykoker", "html_url": "https://github.com/teddykoker", "followers_url": "https://api.github.com/users/teddykoker/followers", "following_url": "https://api.github.com/users/teddykoker/following{/other_user}", "gists_url": "https://api.github.com/users/teddykoker/gists{/gist_id}", "starred_url": "https://api.github.com/users/teddykoker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teddykoker/subscriptions", "organizations_url": "https://api.github.com/users/teddykoker/orgs", "repos_url": "https://api.github.com/users/teddykoker/repos", "events_url": "https://api.github.com/users/teddykoker/events{/privacy}", "received_events_url": "https://api.github.com/users/teddykoker/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "teddykoker", "id": 11153048, "node_id": "MDQ6VXNlcjExMTUzMDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11153048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teddykoker", "html_url": "https://github.com/teddykoker", "followers_url": "https://api.github.com/users/teddykoker/followers", "following_url": "https://api.github.com/users/teddykoker/following{/other_user}", "gists_url": "https://api.github.com/users/teddykoker/gists{/gist_id}", "starred_url": "https://api.github.com/users/teddykoker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teddykoker/subscriptions", "organizations_url": "https://api.github.com/users/teddykoker/orgs", "repos_url": "https://api.github.com/users/teddykoker/repos", "events_url": "https://api.github.com/users/teddykoker/events{/privacy}", "received_events_url": "https://api.github.com/users/teddykoker/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-18T08:37:23Z", "updated_at": "2020-08-18T17:54:02Z", "closed_at": "2020-08-18T17:54:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "tensorboard version: 2.3.0\r\npytorch-lightning version: 0.9.0 rc16\r\n\r\nmy code:\r\n```\r\nclass Video_Base(pl.LightningModule):\r\n    def __init__(self, hparams, *args, **kwargs):\r\n        self.hparams = hparams\r\n```\r\ntensorbord 2.2.0 is ok, 2.3.0 can't show hparams, says no hparams data found", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3032", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3032/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3032/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3032/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3032", "id": 680766734, "node_id": "MDU6SXNzdWU2ODA3NjY3MzQ=", "number": 3032, "title": "Epoch counting is one-off in multiple instances", "user": {"login": "AAnoosheh", "id": 5615503, "node_id": "MDQ6VXNlcjU2MTU1MDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/5615503?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AAnoosheh", "html_url": "https://github.com/AAnoosheh", "followers_url": "https://api.github.com/users/AAnoosheh/followers", "following_url": "https://api.github.com/users/AAnoosheh/following{/other_user}", "gists_url": "https://api.github.com/users/AAnoosheh/gists{/gist_id}", "starred_url": "https://api.github.com/users/AAnoosheh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AAnoosheh/subscriptions", "organizations_url": "https://api.github.com/users/AAnoosheh/orgs", "repos_url": "https://api.github.com/users/AAnoosheh/repos", "events_url": "https://api.github.com/users/AAnoosheh/events{/privacy}", "received_events_url": "https://api.github.com/users/AAnoosheh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 3, "created_at": "2020-08-18T07:32:29Z", "updated_at": "2020-08-20T10:27:49Z", "closed_at": "2020-08-20T10:27:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "\ud83d\udc1b Bug\r\n\r\nTwo issues occur:\r\n\r\n1. The final epoch does not save a checkpoint during training.\r\n2. Resuming from a checkpoint N will start the epochs at N+2.\r\n\r\n### Expected behavior\r\n\r\n1. Final checkpoint should save a .ckpt file, as usual.\r\n2. Should resume from epoch N+1.\r\n\r\n### Environment\r\n\r\n```\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- Tesla V100-DGXS-16GB\r\n\t\t- Tesla V100-DGXS-16GB\r\n\t\t- Tesla V100-DGXS-16GB\r\n\t\t- Tesla V100-DGXS-16GB\r\n\t- available:         True\r\n\t- version:           10.1\r\n* Packages:\r\n\t- numpy:             1.18.1\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0\r\n\t- pytorch-lightning: 0.9.0rc12\r\n\t- tensorboard:       2.2.1\r\n\t- tqdm:              4.46.1\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t-\r\n\t- processor:         x86_64\r\n\t- python:            3.7.7\r\n\t- version:           #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3030", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3030/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3030/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3030/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3030", "id": 680700827, "node_id": "MDU6SXNzdWU2ODA3MDA4Mjc=", "number": 3030, "title": "Incorrect default cuda device when using single gpu other than cuda:0", "user": {"login": "manipopopo", "id": 14799222, "node_id": "MDQ6VXNlcjE0Nzk5MjIy", "avatar_url": "https://avatars2.githubusercontent.com/u/14799222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manipopopo", "html_url": "https://github.com/manipopopo", "followers_url": "https://api.github.com/users/manipopopo/followers", "following_url": "https://api.github.com/users/manipopopo/following{/other_user}", "gists_url": "https://api.github.com/users/manipopopo/gists{/gist_id}", "starred_url": "https://api.github.com/users/manipopopo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manipopopo/subscriptions", "organizations_url": "https://api.github.com/users/manipopopo/orgs", "repos_url": "https://api.github.com/users/manipopopo/repos", "events_url": "https://api.github.com/users/manipopopo/events{/privacy}", "received_events_url": "https://api.github.com/users/manipopopo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 2, "created_at": "2020-08-18T05:21:13Z", "updated_at": "2020-08-18T23:28:36Z", "closed_at": "2020-08-18T23:28:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nThe default `cuda` is not set properly to the `trainer.root_gpu` in single-GPU mode. The tensors created with `device='cuda'` will be placed on the incorrect gpu, and the dataloader will acquire memory on the incorrect gpu when `pin_memory=True`.\r\n\r\nMaybe we'll need to add\r\n`torch.cuda.set_device(self.trainer.root_gpu)` to https://github.com/PyTorchLightning/pytorch-lightning/blob/5dfc7b157e7febab692036b7392dac8b52f41b87/pytorch_lightning/accelerators/gpu_backend.py#L24\r\nas `DDPBackend` did:\r\n\r\nhttps://github.com/PyTorchLightning/pytorch-lightning/blob/5dfc7b157e7febab692036b7392dac8b52f41b87/pytorch_lightning/accelerators/ddp_backend.py#L195\r\n\r\n### To Reproduce\r\n\r\nRunning the following code will get \r\n\r\n`RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0!`\r\n\r\n#### Code sample\r\n\r\n```python\r\nimport pytorch_lightning as pl\r\nimport torch\r\nfrom torch import nn\r\nfrom torch.utils import data\r\n\r\n\r\nclass Dataset(data.Dataset):\r\n\r\n  def __getitem__(self, item):\r\n    return torch.zeros(1)\r\n\r\n  def __len__(self):\r\n    return 5\r\n\r\n\r\nclass Model(pl.LightningModule):\r\n\r\n  def __init__(self, *args, **kwargs):\r\n    super().__init__(*args, **kwargs)\r\n    self.x = nn.Parameter(torch.zeros(1))\r\n\r\n  def forward(self, *args, **kwargs):\r\n    return self.x\r\n\r\n  def training_step(self, *args, **kwargs):\r\n    return self.x + torch.zeros(1, device='cuda')  # RuntimeError.\r\n\r\n  def train_dataloader(self):\r\n    return data.DataLoader(Dataset(), num_workers=1, pin_memory=True)\r\n\r\n  def configure_optimizers(self):\r\n    return torch.optim.SGD(self.parameters(), 1.0)\r\n\r\n\r\nif __name__ == '__main__':\r\n  trainer = pl.Trainer(gpus=[1], num_sanity_val_steps=0, max_epochs=1)\r\n  model = Model()\r\n  trainer.fit(model)\r\n\r\n```\r\n\r\n### Expected behavior\r\n\r\nNo `RuntimeError` occurs.\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t- available:\r\n\t- version:\r\n* Packages:\r\n\t- numpy:             1.18.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0\r\n\t- pytorch-lightning: 0.9.0rc16\r\n\t- tensorboard:       2.3.0\r\n\t- tqdm:              4.48.2\r\n* System:\r\n\t- OS:                Windows\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- WindowsPE\r\n\t- processor:\r\n\t- python:            3.7.3\r\n\t- version:           10.0.18362\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3029", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3029/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3029/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3029/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3029", "id": 680673457, "node_id": "MDU6SXNzdWU2ODA2NzM0NTc=", "number": 3029, "title": "torchelastic multinode training fail", "user": {"login": "mutasem-mattar", "id": 8367757, "node_id": "MDQ6VXNlcjgzNjc3NTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/8367757?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mutasem-mattar", "html_url": "https://github.com/mutasem-mattar", "followers_url": "https://api.github.com/users/mutasem-mattar/followers", "following_url": "https://api.github.com/users/mutasem-mattar/following{/other_user}", "gists_url": "https://api.github.com/users/mutasem-mattar/gists{/gist_id}", "starred_url": "https://api.github.com/users/mutasem-mattar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mutasem-mattar/subscriptions", "organizations_url": "https://api.github.com/users/mutasem-mattar/orgs", "repos_url": "https://api.github.com/users/mutasem-mattar/repos", "events_url": "https://api.github.com/users/mutasem-mattar/events{/privacy}", "received_events_url": "https://api.github.com/users/mutasem-mattar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 3, "created_at": "2020-08-18T04:08:23Z", "updated_at": "2020-08-20T16:30:57Z", "closed_at": "2020-08-19T23:14:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to run a 2 node distributed training on kubernetes cluster. I am using pytorch lightning with torchelastic. However I keep getting `RuntimeError: NCCL error in:  invalid argument, NCCL version 2.4.8`. I tried to run the code without pytorch lightning the code works fine.  Here is the logs from the two worker nodes\r\n\r\n**Packages:**\r\n```\r\n       - torchelastic: 0.2.0\r\n        - pyTorch_version:   1.6.0\r\n        - pytorch-lightning: 0.8.5\r\n```\r\n\r\n**worker-0**\r\n```\r\nRunning torchelastic.distributed.launch with args: ['/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py', '--rdzv_backend=etcd', '--rdzv_endpoint=etcd-service:2379', '--rdzv_id=mnist12', '--nnodes=1:2', '--nproc_per_node=1', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']\r\n[INFO] 2020-08-18 05:25:52,881 launch: Running torchelastic.distributed.launch with args: ['/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py', '--rdzv_backend=etcd', '--rdzv_endpoint=etcd-service:2379', '--rdzv_id=mnist12', '--nnodes=1:2', '--nproc_per_node=1', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']\r\n[INFO] 2020-08-18 05:25:52,882 launch: Using nproc_per_node=1.\r\nINFO 2020-08-18 05:25:52,888 Etcd machines: ['http://0.0.0.0:2379']\r\n[default] starting workers for function: wrapper_fn\r\n[INFO] 2020-08-18 05:25:53,661 api: [default] starting workers for function: wrapper_fn\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:25:53,661 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:25:53,661 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:25:53,670 New rendezvous state created: {'status': 'joinable', 'version': '1', 'participants': []}\r\nINFO 2020-08-18 05:25:53,756 Joined rendezvous version 1 as rank 0. Full state: {'status': 'joinable', 'version': '1', 'participants': [0]}\r\nINFO 2020-08-18 05:25:53,756 Rank 0 is responsible for join last call.\r\nINFO 2020-08-18 05:25:53,823 Rank 0 finished join last call.\r\nINFO 2020-08-18 05:25:53,823 Waiting for remaining peers.\r\nINFO 2020-08-18 05:25:53,825 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:25:53,843 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:25:53,891 Rendezvous version 1 is complete. Final state: {'status': 'final', 'version': '1', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:25:53,892 Creating EtcdStore as the c10d::Store implementation\r\n/opt/conda/lib/python3.7/site-packages/torchelastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\r\n  \"This is an experimental API and will be changed in future.\", FutureWarning\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=0\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-0\r\n\tmaster_port=55169\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:25:53,905 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=0\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-0\r\n\tmaster_port=55169\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:25:53,905 api: [default] Starting worker group\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: WORLD_SIZE environment variable (2) is not equal to the computed world size (1). Ignored.\r\n  warnings.warn(*args, **kwargs)\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 1 processes\r\n----------------------------------------------------------------------------------------------------\r\nmnist12-worker-0:26:26 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.60.90<0>\r\nmnist12-worker-0:26:26 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-0:26:26 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-0:26:26 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.60.90<0>\r\nNCCL version 2.4.8+cuda10.1\r\nmnist12-worker-0:26:34 [0] NCCL INFO Setting affinity for GPU 0 to 0f\r\nmnist12-worker-0:26:34 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees enabled up to size -2\r\nmnist12-worker-0:26:34 [0] NCCL INFO comm 0x7f5438002280 rank 0 nranks 1 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n\r\n  | Name      | Type             | Params\r\n-----------------------------------------------\r\n0 | model     | ResNet           | 11 M\r\n1 | criterion | CrossEntropyLoss | 0\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n[default] Detected 1 new nodes from group_rank=0; will restart worker group\r\n[INFO] 2020-08-18 05:26:08,936 api: [default] Detected 1 new nodes from group_rank=0; will restart worker group\r\n[default] Stopping worker group\r\n[INFO] 2020-08-18 05:26:08,936 api: [default] Stopping worker group\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:26:09,195 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:26:09,196 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:09,200 Observed existing rendezvous state: {'status': 'final', 'version': '1', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1'], 'num_workers_waiting': 1}\r\nINFO 2020-08-18 05:26:09,232 Added self to waiting list. Rendezvous full state: {\"status\": \"final\", \"version\": \"1\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1\"], \"num_workers_waiting\": 2}\r\nINFO 2020-08-18 05:26:13,992 Keep-alive key /torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1 is not renewed.\r\nINFO 2020-08-18 05:26:13,992 Rendevous version 1 is incomplete.\r\nINFO 2020-08-18 05:26:13,992 Attempting to destroy it.\r\nINFO 2020-08-18 05:26:13,995 Rendezvous attempt failed, will retry. Reason: Compare failed : [{\"status\": \"final\", \"version\": \"1\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1\"], \"num_workers_waiting\": 2} != {\"status\": \"setup\"}]\r\nINFO 2020-08-18 05:26:14,996 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:15,000 Observed existing rendezvous state: {'status': 'joinable', 'version': '2', 'participants': [0]}\r\nINFO 2020-08-18 05:26:15,031 Joined rendezvous version 2 as rank 1. Full state: {'status': 'frozen', 'version': '2', 'participants': [0, 1], 'keep_alives': []}\r\nINFO 2020-08-18 05:26:15,032 Waiting for remaining peers.\r\nINFO 2020-08-18 05:26:15,033 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:26:15,051 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:26:15,104 Rendezvous version 2 is complete. Final state: {'status': 'final', 'version': '2', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1', '/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_0'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:15,104 Creating EtcdStore as the c10d::Store implementation\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=0\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=40213\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:26:15,114 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=0\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=40213\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:26:15,114 api: [default] Starting worker group\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/1\r\nEpoch 1:   2%|\u258f         | 32/1720 [00:09<07:57,  3.54it/s, loss=6.834, v_num=0]mnist12-worker-0:46:46 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.60.90<0>\r\nmnist12-worker-0:46:46 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-0:46:46 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-0:46:46 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.60.90<0>\r\n\r\nmnist12-worker-0:46:46 [0] init.cc:981 NCCL WARN Invalid rank requested : 1/1\r\nTraceback (most recent call last):\r\n  File \"/workspace/script.py\", line 236, in <module>\r\n    run_cli()\r\n  File \"/workspace/script.py\", line 232, in run_cli\r\n    main(args)\r\n  File \"/workspace/script.py\", line 211, in main\r\n    trainer.fit(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in fit\r\n    self.ddp_train(process_idx=task, q=None, model=model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 557, in ddp_train\r\n    model = model.configure_ddp(model, device_ids)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\", line 899, in configure_ddp\r\n    find_unused_parameters=True\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 333, in __init__\r\n    self.broadcast_bucket_size)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 549, in _distributed_broadcast_coalesced\r\n    dist._broadcast_coalesced(self.process_group, tensors, buffer_size)\r\nRuntimeError: NCCL error in: /opt/conda/conda-bld/pytorch_1595629403081/work/torch/lib/c10d/../c10d/NCCLUtils.hpp:82, invalid argument, NCCL version 2.4.8\r\n[default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[ERROR] 2020-08-18 05:26:25,134 local_elastic_agent: [default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[default] Worker group FAILED. 3/3 attempts left; will restart worker group\r\n[INFO] 2020-08-18 05:26:25,134 api: [default] Worker group FAILED. 3/3 attempts left; will restart worker group\r\n[default] Stopping worker group\r\n[INFO] 2020-08-18 05:26:25,134 api: [default] Stopping worker group\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:26:25,134 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:26:25,134 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:25,138 Observed existing rendezvous state: {'status': 'final', 'version': '2', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1', '/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_0'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:25,164 Added self to waiting list. Rendezvous full state: {\"status\": \"final\", \"version\": \"2\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1\", \"/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_0\"], \"num_workers_waiting\": 1}\r\nINFO 2020-08-18 05:26:35,491 Keep-alive key /torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1 is not renewed.\r\nINFO 2020-08-18 05:26:35,491 Rendevous version 2 is incomplete.\r\nINFO 2020-08-18 05:26:35,492 Attempting to destroy it.\r\nINFO 2020-08-18 05:26:35,494 Rendezvous attempt failed, will retry. Reason: Compare failed : [{\"status\": \"final\", \"version\": \"2\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1\", \"/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_0\"], \"num_workers_waiting\": 2} != {\"status\": \"setup\"}]\r\nINFO 2020-08-18 05:26:36,494 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:36,498 Observed existing rendezvous state: {'status': 'joinable', 'version': '3', 'participants': [0]}\r\nINFO 2020-08-18 05:26:36,538 Joined rendezvous version 3 as rank 1. Full state: {'status': 'frozen', 'version': '3', 'participants': [0, 1], 'keep_alives': []}\r\nINFO 2020-08-18 05:26:36,538 Waiting for remaining peers.\r\nINFO 2020-08-18 05:26:36,540 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:26:36,635 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:26:36,637 Rendezvous version 3 is complete. Final state: {'status': 'final', 'version': '3', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:36,638 Creating EtcdStore as the c10d::Store implementation\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=38529\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:26:36,647 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=38529\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:26:36,647 api: [default] Starting worker group\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/1\r\nmnist12-worker-0:58:58 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.60.90<0>\r\nmnist12-worker-0:58:58 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-0:58:58 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-0:58:58 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.60.90<0>\r\n\r\nmnist12-worker-0:58:58 [0] init.cc:981 NCCL WARN Invalid rank requested : 1/1\r\nTraceback (most recent call last):\r\n  File \"/workspace/script.py\", line 236, in <module>\r\n    run_cli()\r\n  File \"/workspace/script.py\", line 232, in run_cli\r\n    main(args)\r\n  File \"/workspace/script.py\", line 211, in main\r\n    trainer.fit(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in fit\r\n    self.ddp_train(process_idx=task, q=None, model=model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 557, in ddp_train\r\n    model = model.configure_ddp(model, device_ids)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\", line 899, in configure_ddp\r\n    find_unused_parameters=True\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 333, in __init__\r\n    self.broadcast_bucket_size)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 549, in _distributed_broadcast_coalesced\r\n    dist._broadcast_coalesced(self.process_group, tensors, buffer_size)\r\nRuntimeError: NCCL error in: /opt/conda/conda-bld/pytorch_1595629403081/work/torch/lib/c10d/../c10d/NCCLUtils.hpp:82, invalid argument, NCCL version 2.4.8\r\n[default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[ERROR] 2020-08-18 05:26:46,661 local_elastic_agent: [default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[default] Worker group FAILED. 2/3 attempts left; will restart worker group\r\n[INFO] 2020-08-18 05:26:46,662 api: [default] Worker group FAILED. 2/3 attempts left; will restart worker group\r\n[default] Stopping worker group\r\n[INFO] 2020-08-18 05:26:46,662 api: [default] Stopping worker group\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:26:46,662 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:26:46,662 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:46,665 Observed existing rendezvous state: {'status': 'final', 'version': '3', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:46,730 Added self to waiting list. Rendezvous full state: {\"status\": \"final\", \"version\": \"3\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1\"], \"num_workers_waiting\": 1}\r\nINFO 2020-08-18 05:26:56,992 Keep-alive key /torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1 is not renewed.\r\nINFO 2020-08-18 05:26:56,992 Rendevous version 3 is incomplete.\r\nINFO 2020-08-18 05:26:56,992 Attempting to destroy it.\r\nINFO 2020-08-18 05:26:56,994 Rendezvous attempt failed, will retry. Reason: Compare failed : [{\"status\": \"final\", \"version\": \"3\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1\"], \"num_workers_waiting\": 2} != {\"status\": \"setup\"}]\r\nINFO 2020-08-18 05:26:57,995 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:57,999 Observed existing rendezvous state: {'status': 'joinable', 'version': '4', 'participants': [0]}\r\nINFO 2020-08-18 05:26:58,015 Joined rendezvous version 4 as rank 1. Full state: {'status': 'frozen', 'version': '4', 'participants': [0, 1], 'keep_alives': []}\r\nINFO 2020-08-18 05:26:58,015 Waiting for remaining peers.\r\nINFO 2020-08-18 05:26:58,016 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:26:58,116 Confirm membership CAS unsuccessful, retrying\r\nINFO 2020-08-18 05:26:58,196 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:26:58,198 Rendezvous version 4 is complete. Final state: {'status': 'final', 'version': '4', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:58,198 Creating EtcdStore as the c10d::Store implementation\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=2\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=41561\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:26:58,207 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=2\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=41561\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:26:58,207 api: [default] Starting worker group\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/1\r\nmnist12-worker-0:70:70 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.60.90<0>\r\nmnist12-worker-0:70:70 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-0:70:70 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-0:70:70 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.60.90<0>\r\n\r\nmnist12-worker-0:70:70 [0] init.cc:981 NCCL WARN Invalid rank requested : 1/1\r\nTraceback (most recent call last):\r\n  File \"/workspace/script.py\", line 236, in <module>\r\n    run_cli()\r\n  File \"/workspace/script.py\", line 232, in run_cli\r\n    main(args)\r\n  File \"/workspace/script.py\", line 211, in main\r\n    trainer.fit(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in fit\r\n    self.ddp_train(process_idx=task, q=None, model=model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 557, in ddp_train\r\n    model = model.configure_ddp(model, device_ids)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\", line 899, in configure_ddp\r\n    find_unused_parameters=True\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 333, in __init__\r\n    self.broadcast_bucket_size)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 549, in _distributed_broadcast_coalesced\r\n    dist._broadcast_coalesced(self.process_group, tensors, buffer_size)\r\nRuntimeError: NCCL error in: /opt/conda/conda-bld/pytorch_1595629403081/work/torch/lib/c10d/../c10d/NCCLUtils.hpp:82, invalid argument, NCCL version 2.4.8\r\n[default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[ERROR] 2020-08-18 05:27:08,227 local_elastic_agent: [default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[default] Worker group FAILED. 1/3 attempts left; will restart worker group\r\n[INFO] 2020-08-18 05:27:08,227 api: [default] Worker group FAILED. 1/3 attempts left; will restart worker group\r\n[default] Stopping worker group\r\n[INFO] 2020-08-18 05:27:08,227 api: [default] Stopping worker group\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:27:08,227 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:27:08,227 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:27:08,231 Observed existing rendezvous state: {'status': 'final', 'version': '4', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:27:08,257 Added self to waiting list. Rendezvous full state: {\"status\": \"final\", \"version\": \"4\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1\"], \"num_workers_waiting\": 1}\r\nINFO 2020-08-18 05:27:18,492 Keep-alive key /torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1 is not renewed.\r\nINFO 2020-08-18 05:27:18,492 Rendevous version 4 is incomplete.\r\nINFO 2020-08-18 05:27:18,492 Attempting to destroy it.\r\nINFO 2020-08-18 05:27:18,494 Rendezvous attempt failed, will retry. Reason: Compare failed : [{\"status\": \"final\", \"version\": \"4\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1\"], \"num_workers_waiting\": 2} != {\"status\": \"setup\"}]\r\nINFO 2020-08-18 05:27:19,495 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:27:19,499 Observed existing rendezvous state: {'status': 'joinable', 'version': '5', 'participants': [0]}\r\nINFO 2020-08-18 05:27:19,506 Joined rendezvous version 5 as rank 1. Full state: {'status': 'frozen', 'version': '5', 'participants': [0, 1], 'keep_alives': []}\r\nINFO 2020-08-18 05:27:19,507 Waiting for remaining peers.\r\nINFO 2020-08-18 05:27:19,508 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:27:19,606 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:27:19,607 Rendezvous version 5 is complete. Final state: {'status': 'final', 'version': '5', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_5/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_5/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:27:19,608 Creating EtcdStore as the c10d::Store implementation\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=3\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=33769\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:27:19,618 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=3\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=33769\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:27:19,618 api: [default] Starting worker group\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/1\r\nmnist12-worker-0:82:82 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.60.90<0>\r\nmnist12-worker-0:82:82 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-0:82:82 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-0:82:82 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.60.90<0>\r\n\r\nmnist12-worker-0:82:82 [0] init.cc:981 NCCL WARN Invalid rank requested : 1/1\r\nTraceback (most recent call last):\r\n  File \"/workspace/script.py\", line 236, in <module>\r\n    run_cli()\r\n  File \"/workspace/script.py\", line 232, in run_cli\r\n    main(args)\r\n  File \"/workspace/script.py\", line 211, in main\r\n    trainer.fit(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in fit\r\n    self.ddp_train(process_idx=task, q=None, model=model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 557, in ddp_train\r\n    model = model.configure_ddp(model, device_ids)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\", line 899, in configure_ddp\r\n    find_unused_parameters=True\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 333, in __init__\r\n    self.broadcast_bucket_size)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 549, in _distributed_broadcast_coalesced\r\n    dist._broadcast_coalesced(self.process_group, tensors, buffer_size)\r\nRuntimeError: NCCL error in: /opt/conda/conda-bld/pytorch_1595629403081/work/torch/lib/c10d/../c10d/NCCLUtils.hpp:82, invalid argument, NCCL version 2.4.8\r\n[default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[ERROR] 2020-08-18 05:27:29,637 local_elastic_agent: [default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\nLocal worker group finished (WorkerState.FAILED). Waiting 300 seconds for other agents to finish\r\n[INFO] 2020-08-18 05:27:29,637 api: Local worker group finished (WorkerState.FAILED). Waiting 300 seconds for other agents to finish\r\n```\r\n\r\n**Worker-1**\r\n```\r\nRunning torchelastic.distributed.launch with args: ['/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py', '--rdzv_backend=etcd', '--rdzv_endpoint=etcd-service:2379', '--rdzv_id=mnist12', '--nnodes=1:2', '--nproc_per_node=1', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']\r\n[INFO] 2020-08-18 05:25:52,909 launch: Running torchelastic.distributed.launch with args: ['/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py', '--rdzv_backend=etcd', '--rdzv_endpoint=etcd-service:2379', '--rdzv_id=mnist12', '--nnodes=1:2', '--nproc_per_node=1', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']\r\n[INFO] 2020-08-18 05:25:52,910 launch: Using nproc_per_node=1.\r\nINFO 2020-08-18 05:25:52,914 Etcd machines: ['http://0.0.0.0:2379']\r\n[default] starting workers for function: wrapper_fn\r\n[INFO] 2020-08-18 05:25:53,722 api: [default] starting workers for function: wrapper_fn\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:25:53,723 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:25:53,723 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:25:53,725 Observed existing rendezvous state: {'status': 'joinable', 'version': '1', 'participants': []}\r\nINFO 2020-08-18 05:25:53,821 Joined rendezvous version 1 as rank 1. Full state: {'status': 'frozen', 'version': '1', 'participants': [0, 1], 'keep_alives': []}\r\nINFO 2020-08-18 05:25:53,822 Waiting for remaining peers.\r\nINFO 2020-08-18 05:25:53,822 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:25:53,890 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:25:53,891 Rendezvous version 1 is complete. Final state: {'status': 'final', 'version': '1', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:25:53,891 Creating EtcdStore as the c10d::Store implementation\r\n/opt/conda/lib/python3.7/site-packages/torchelastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\r\n  \"This is an experimental API and will be changed in future.\", FutureWarning\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=0\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-0\r\n\tmaster_port=55169\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:25:53,902 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=0\r\n\tgroup_rank=1\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-0\r\n\tmaster_port=55169\r\n\tworkers={'local_ranks': [0], 'global_ranks': [1], 'role_ranks': [1], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:25:53,902 api: [default] Starting worker group\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/1\r\nmnist12-worker-1:24:24 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.65.152<0>\r\nmnist12-worker-1:24:24 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-1:24:24 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-1:24:24 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.65.152<0>\r\n\r\nmnist12-worker-1:24:24 [0] init.cc:981 NCCL WARN Invalid rank requested : 1/1\r\nTraceback (most recent call last):\r\n  File \"/workspace/script.py\", line 236, in <module>\r\n    run_cli()\r\n  File \"/workspace/script.py\", line 232, in run_cli\r\n    main(args)\r\n  File \"/workspace/script.py\", line 211, in main\r\n    trainer.fit(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in fit\r\n    self.ddp_train(process_idx=task, q=None, model=model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 557, in ddp_train\r\n    model = model.configure_ddp(model, device_ids)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\", line 899, in configure_ddp\r\n    find_unused_parameters=True\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 333, in __init__\r\n    self.broadcast_bucket_size)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py\", line 549, in _distributed_broadcast_coalesced\r\n    dist._broadcast_coalesced(self.process_group, tensors, buffer_size)\r\nRuntimeError: NCCL error in: /opt/conda/conda-bld/pytorch_1595629403081/work/torch/lib/c10d/../c10d/NCCLUtils.hpp:82, invalid argument, NCCL version 2.4.8\r\n[default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[ERROR] 2020-08-18 05:26:03,919 local_elastic_agent: [default] Worker group failed\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 224, in _monitor_workers\r\n    if self._process_context.join(timeout=-1):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException:\r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/agent/server/local_elastic_agent.py\", line 101, in _wrap\r\n    ret = fn(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torchelastic/distributed/launch.py\", line 401, in wrapper_fn\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', '/workspace/script.py', '--gpus=1', '--distributed_backend=ddp', '--num_workers=0', '--replace_sampler_ddp=False']' returned non-zero exit status 1.\r\n\r\n[default] Worker group FAILED. 3/3 attempts left; will restart worker group\r\n[INFO] 2020-08-18 05:26:03,919 api: [default] Worker group FAILED. 3/3 attempts left; will restart worker group\r\n[default] Stopping worker group\r\n[INFO] 2020-08-18 05:26:03,920 api: [default] Stopping worker group\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:26:03,920 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:26:03,920 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:03,922 Observed existing rendezvous state: {'status': 'final', 'version': '1', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:03,975 Added self to waiting list. Rendezvous full state: {\"status\": \"final\", \"version\": \"1\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1\"], \"num_workers_waiting\": 1}\r\nINFO 2020-08-18 05:26:13,990 Keep-alive key /torchelastic/p2p/run_mnist12/rdzv/v_1/rank_1 is not renewed.\r\nINFO 2020-08-18 05:26:13,990 Rendevous version 1 is incomplete.\r\nINFO 2020-08-18 05:26:13,990 Attempting to destroy it.\r\nINFO 2020-08-18 05:26:13,991 Destroyed rendezvous version 1 successfully.\r\nINFO 2020-08-18 05:26:13,991 Previously existing rendezvous state changed. Will re-try joining.\r\nINFO 2020-08-18 05:26:13,991 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:13,996 New rendezvous state created: {'status': 'joinable', 'version': '2', 'participants': []}\r\nINFO 2020-08-18 05:26:14,087 Joined rendezvous version 2 as rank 0. Full state: {'status': 'joinable', 'version': '2', 'participants': [0]}\r\nINFO 2020-08-18 05:26:14,087 Rank 0 is responsible for join last call.\r\nINFO 2020-08-18 05:26:15,032 Rank 0 finished join last call.\r\nINFO 2020-08-18 05:26:15,032 Waiting for remaining peers.\r\nINFO 2020-08-18 05:26:15,033 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:26:15,103 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:26:15,104 Rendezvous version 2 is complete. Final state: {'status': 'final', 'version': '2', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1', '/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_0'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:15,104 Creating EtcdStore as the c10d::Store implementation\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=40213\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:26:15,111 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=40213\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:26:15,111 api: [default] Starting worker group\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: WORLD_SIZE environment variable (2) is not equal to the computed world size (1). Ignored.\r\n  warnings.warn(*args, **kwargs)\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 1 processes\r\n----------------------------------------------------------------------------------------------------\r\nmnist12-worker-1:36:36 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.65.152<0>\r\nmnist12-worker-1:36:36 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-1:36:36 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-1:36:36 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.65.152<0>\r\nNCCL version 2.4.8+cuda10.1\r\nmnist12-worker-1:36:44 [0] NCCL INFO Setting affinity for GPU 0 to 0f\r\nmnist12-worker-1:36:44 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees enabled up to size -2\r\nmnist12-worker-1:36:44 [0] NCCL INFO comm 0x7f9f6c002280 rank 0 nranks 1 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n\r\n  | Name      | Type             | Params\r\n-----------------------------------------------\r\n0 | model     | ResNet           | 11 M\r\n1 | criterion | CrossEntropyLoss | 0\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n[default] Detected 1 new nodes from group_rank=0; will restart worker group\r\n[INFO] 2020-08-18 05:26:30,134 api: [default] Detected 1 new nodes from group_rank=0; will restart worker group\r\n[default] Stopping worker group\r\n[INFO] 2020-08-18 05:26:30,134 api: [default] Stopping worker group\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:26:30,391 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:26:30,391 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:30,393 Observed existing rendezvous state: {'status': 'final', 'version': '2', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1', '/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_0'], 'num_workers_waiting': 1}\r\nINFO 2020-08-18 05:26:30,434 Added self to waiting list. Rendezvous full state: {\"status\": \"final\", \"version\": \"2\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1\", \"/torchelastic/p2p/run_mnist12/rdzv/v_2/rank_0\"], \"num_workers_waiting\": 2}\r\nINFO 2020-08-18 05:26:35,490 Keep-alive key /torchelastic/p2p/run_mnist12/rdzv/v_2/rank_1 is not renewed.\r\nINFO 2020-08-18 05:26:35,490 Rendevous version 2 is incomplete.\r\nINFO 2020-08-18 05:26:35,490 Attempting to destroy it.\r\nINFO 2020-08-18 05:26:35,491 Destroyed rendezvous version 2 successfully.\r\nINFO 2020-08-18 05:26:35,491 Previously existing rendezvous state changed. Will re-try joining.\r\nINFO 2020-08-18 05:26:35,491 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:35,495 New rendezvous state created: {'status': 'joinable', 'version': '3', 'participants': []}\r\nINFO 2020-08-18 05:26:35,563 Joined rendezvous version 3 as rank 0. Full state: {'status': 'joinable', 'version': '3', 'participants': [0]}\r\nINFO 2020-08-18 05:26:35,563 Rank 0 is responsible for join last call.\r\nINFO 2020-08-18 05:26:36,539 Rank 0 finished join last call.\r\nINFO 2020-08-18 05:26:36,539 Waiting for remaining peers.\r\nINFO 2020-08-18 05:26:36,539 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:26:36,610 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:26:36,635 Rendezvous version 3 is complete. Final state: {'status': 'final', 'version': '3', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:36,635 Creating EtcdStore as the c10d::Store implementation\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=38529\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:26:36,644 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=38529\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:26:36,644 api: [default] Starting worker group\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: WORLD_SIZE environment variable (2) is not equal to the computed world size (1). Ignored.\r\n  warnings.warn(*args, **kwargs)\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 1 processes\r\n----------------------------------------------------------------------------------------------------\r\nEpoch 1:   2%|\u258f         | 31/1720 [00:08<08:02,  3.50it/s, loss=6.841, v_num=0]mnist12-worker-1:56:56 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.65.152<0>\r\nmnist12-worker-1:56:56 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-1:56:56 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-1:56:56 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.65.152<0>\r\nNCCL version 2.4.8+cuda10.1\r\nmnist12-worker-1:56:64 [0] NCCL INFO Setting affinity for GPU 0 to 0f\r\nmnist12-worker-1:56:64 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees enabled up to size -2\r\nmnist12-worker-1:56:64 [0] NCCL INFO comm 0x7f0e80002280 rank 0 nranks 1 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n\r\n  | Name      | Type             | Params\r\n-----------------------------------------------\r\n0 | model     | ResNet           | 11 M\r\n1 | criterion | CrossEntropyLoss | 0\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n[default] Detected 1 new nodes from group_rank=0; will restart worker group\r\n[INFO] 2020-08-18 05:26:51,666 api: [default] Detected 1 new nodes from group_rank=0; will restart worker group\r\n[default] Stopping worker group\r\n[INFO] 2020-08-18 05:26:51,666 api: [default] Stopping worker group\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:26:51,937 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:26:51,937 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:51,940 Observed existing rendezvous state: {'status': 'final', 'version': '3', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1'], 'num_workers_waiting': 1}\r\nINFO 2020-08-18 05:26:51,951 Added self to waiting list. Rendezvous full state: {\"status\": \"final\", \"version\": \"3\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1\"], \"num_workers_waiting\": 2}\r\nINFO 2020-08-18 05:26:56,990 Keep-alive key /torchelastic/p2p/run_mnist12/rdzv/v_3/rank_1 is not renewed.\r\nINFO 2020-08-18 05:26:56,990 Rendevous version 3 is incomplete.\r\nINFO 2020-08-18 05:26:56,990 Attempting to destroy it.\r\nINFO 2020-08-18 05:26:56,992 Destroyed rendezvous version 3 successfully.\r\nINFO 2020-08-18 05:26:56,992 Previously existing rendezvous state changed. Will re-try joining.\r\nINFO 2020-08-18 05:26:56,992 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:26:56,996 New rendezvous state created: {'status': 'joinable', 'version': '4', 'participants': []}\r\nINFO 2020-08-18 05:26:57,043 Joined rendezvous version 4 as rank 0. Full state: {'status': 'joinable', 'version': '4', 'participants': [0]}\r\nINFO 2020-08-18 05:26:57,044 Rank 0 is responsible for join last call.\r\nINFO 2020-08-18 05:26:58,015 Rank 0 finished join last call.\r\nINFO 2020-08-18 05:26:58,015 Waiting for remaining peers.\r\nINFO 2020-08-18 05:26:58,016 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:26:58,114 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:26:58,196 Rendezvous version 4 is complete. Final state: {'status': 'final', 'version': '4', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:26:58,196 Creating EtcdStore as the c10d::Store implementation\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=41561\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:26:58,205 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=41561\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:26:58,205 api: [default] Starting worker group\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: WORLD_SIZE environment variable (2) is not equal to the computed world size (1). Ignored.\r\n  warnings.warn(*args, **kwargs)\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 1 processes\r\n----------------------------------------------------------------------------------------------------\r\nEpoch 1:   2%|\u258f         | 31/1720 [00:08<08:00,  3.52it/s, loss=6.832, v_num=1]mnist12-worker-1:76:76 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.65.152<0>\r\nmnist12-worker-1:76:76 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-1:76:76 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-1:76:76 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.65.152<0>\r\nNCCL version 2.4.8+cuda10.1\r\nmnist12-worker-1:76:84 [0] NCCL INFO Setting affinity for GPU 0 to 0f\r\nmnist12-worker-1:76:84 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees enabled up to size -2\r\nmnist12-worker-1:76:84 [0] NCCL INFO comm 0x7faf24002280 rank 0 nranks 1 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n\r\n  | Name      | Type             | Params\r\n-----------------------------------------------\r\n0 | model     | ResNet           | 11 M\r\n1 | criterion | CrossEntropyLoss | 0\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n[default] Detected 1 new nodes from group_rank=0; will restart worker group\r\n[INFO] 2020-08-18 05:27:13,224 api: [default] Detected 1 new nodes from group_rank=0; will restart worker group\r\n[default] Stopping worker group\r\n[INFO] 2020-08-18 05:27:13,224 api: [default] Stopping worker group\r\n[default] Rendezvous'ing worker group\r\n[INFO] 2020-08-18 05:27:13,492 api: [default] Rendezvous'ing worker group\r\nINFO 2020-08-18 05:27:13,492 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:27:13,495 Observed existing rendezvous state: {'status': 'final', 'version': '4', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1'], 'num_workers_waiting': 1}\r\nINFO 2020-08-18 05:27:13,536 Added self to waiting list. Rendezvous full state: {\"status\": \"final\", \"version\": \"4\", \"participants\": [0, 1], \"keep_alives\": [\"/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_0\", \"/torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1\"], \"num_workers_waiting\": 2}\r\nINFO 2020-08-18 05:27:18,490 Keep-alive key /torchelastic/p2p/run_mnist12/rdzv/v_4/rank_1 is not renewed.\r\nINFO 2020-08-18 05:27:18,490 Rendevous version 4 is incomplete.\r\nINFO 2020-08-18 05:27:18,490 Attempting to destroy it.\r\nINFO 2020-08-18 05:27:18,491 Destroyed rendezvous version 4 successfully.\r\nINFO 2020-08-18 05:27:18,491 Previously existing rendezvous state changed. Will re-try joining.\r\nINFO 2020-08-18 05:27:18,491 Attempting to join next rendezvous\r\nINFO 2020-08-18 05:27:18,496 New rendezvous state created: {'status': 'joinable', 'version': '5', 'participants': []}\r\nINFO 2020-08-18 05:27:18,546 Joined rendezvous version 5 as rank 0. Full state: {'status': 'joinable', 'version': '5', 'participants': [0]}\r\nINFO 2020-08-18 05:27:18,546 Rank 0 is responsible for join last call.\r\nINFO 2020-08-18 05:27:19,507 Rank 0 finished join last call.\r\nINFO 2020-08-18 05:27:19,507 Waiting for remaining peers.\r\nINFO 2020-08-18 05:27:19,508 All peers arrived. Confirming membership.\r\nINFO 2020-08-18 05:27:19,519 Waiting for confirmations from all peers.\r\nINFO 2020-08-18 05:27:19,605 Rendezvous version 5 is complete. Final state: {'status': 'final', 'version': '5', 'participants': [0, 1], 'keep_alives': ['/torchelastic/p2p/run_mnist12/rdzv/v_5/rank_0', '/torchelastic/p2p/run_mnist12/rdzv/v_5/rank_1'], 'num_workers_waiting': 0}\r\nINFO 2020-08-18 05:27:19,606 Creating EtcdStore as the c10d::Store implementation\r\n[default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=33769\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[INFO] 2020-08-18 05:27:19,615 api: [default] Rendezvous complete for workers.\r\nResult:\r\n\trestart_count=1\r\n\tgroup_rank=0\r\n\tgroup_world_size=2\r\n\tmaster_addr=mnist12-worker-1\r\n\tmaster_port=33769\r\n\tworkers={'local_ranks': [0], 'global_ranks': [0], 'role_ranks': [0], 'world_size': 2, 'role_world_size': 2}\r\n\r\n[default] Starting worker group\r\n[INFO] 2020-08-18 05:27:19,615 api: [default] Starting worker group\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: WORLD_SIZE environment variable (2) is not equal to the computed world size (1). Ignored.\r\n  warnings.warn(*args, **kwargs)\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 1 processes\r\n----------------------------------------------------------------------------------------------------\r\nEpoch 1:   2%|\u258f         | 31/1720 [00:08<08:04,  3.48it/s, loss=6.837, v_num=2]mnist12-worker-1:96:96 [0] NCCL INFO Bootstrap : Using [0]eth0:192.168.65.152<0>\r\nmnist12-worker-1:96:96 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\n\r\nmnist12-worker-1:96:96 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\r\nmnist12-worker-1:96:96 [0] NCCL INFO NET/Socket : Using [0]eth0:192.168.65.152<0>\r\nNCCL version 2.4.8+cuda10.1\r\nmnist12-worker-1:96:104 [0] NCCL INFO Setting affinity for GPU 0 to 0f\r\nmnist12-worker-1:96:104 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees enabled up to size -2\r\nmnist12-worker-1:96:104 [0] NCCL INFO comm 0x7f0970002280 rank 0 nranks 1 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n\r\n  | Name      | Type             | Params\r\n-----------------------------------------------\r\n0 | model     | ResNet           | 11 M\r\n1 | criterion | CrossEntropyLoss | 0\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\r\n  warnings.warn(*args, **kwargs)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3027", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3027/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3027/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3027/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3027", "id": 680611026, "node_id": "MDU6SXNzdWU2ODA2MTEwMjY=", "number": 3027, "title": "parsing of track_grad_norm when passed as argument", "user": {"login": "tshrjn", "id": 8372098, "node_id": "MDQ6VXNlcjgzNzIwOTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/8372098?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tshrjn", "html_url": "https://github.com/tshrjn", "followers_url": "https://api.github.com/users/tshrjn/followers", "following_url": "https://api.github.com/users/tshrjn/following{/other_user}", "gists_url": "https://api.github.com/users/tshrjn/gists{/gist_id}", "starred_url": "https://api.github.com/users/tshrjn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tshrjn/subscriptions", "organizations_url": "https://api.github.com/users/tshrjn/orgs", "repos_url": "https://api.github.com/users/tshrjn/repos", "events_url": "https://api.github.com/users/tshrjn/events{/privacy}", "received_events_url": "https://api.github.com/users/tshrjn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 3, "created_at": "2020-08-18T00:52:56Z", "updated_at": "2020-08-20T22:13:50Z", "closed_at": "2020-08-20T17:49:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When using ` Trainer.from_argparse_args` & passing `track_grad_norm` as cli arg.\r\nFollowing error is thrown:\r\n\r\n```\r\ntrack_grad_norm can be an int, a float or 'inf' (infinity norm).\r\n```\r\n### To Reproduce\r\n\r\nRun `python demo.py --gpus \"1,\" --track_grad_norm 2`\r\n\r\n#### Code sample\r\n```\r\nimport argparse\r\nfrom pytorch_lightning import Trainer\r\nfrom pl_bolts.models.gans import BasicGAN\r\n\r\ntrainer = Trainer()\r\n\r\nparser = argparse.ArgumentParser(description='demo')\r\nparser = trainer.add_argparse_args(parser)\r\nargs = parser.parse_args()\r\n\r\nmodel = BasicGAN(args)\r\ntrainer = Trainer.from_argparse_args(args)\r\ntrainer.fit(model)\r\n```\r\n\r\n### Environment\r\n\r\n```\r\n* CUDA:\r\n        - GPU:\r\n                - GeForce RTX 2080 Ti\r\n        - available:         True\r\n        - version:           10.2\r\n* Packages:\r\n        - numpy:             1.18.1\r\n        - pyTorch_debug:     False\r\n        - pyTorch_version:   1.6.0\r\n        - pytorch-lightning: 0.9.0rc16\r\n        - tensorboard:       2.2.0\r\n        - tqdm:              4.45.0\r\n* System:\r\n        - OS:                Linux\r\n        - architecture:\r\n                - 64bit\r\n                -\r\n        - processor:         x86_64\r\n        - python:            3.6.10\r\n        - version:           #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3025", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3025/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3025/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3025/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3025", "id": 680574984, "node_id": "MDU6SXNzdWU2ODA1NzQ5ODQ=", "number": 3025, "title": "Auto-scaling batch-size not compatible with half precision training", "user": {"login": "iantimmis", "id": 18040600, "node_id": "MDQ6VXNlcjE4MDQwNjAw", "avatar_url": "https://avatars0.githubusercontent.com/u/18040600?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iantimmis", "html_url": "https://github.com/iantimmis", "followers_url": "https://api.github.com/users/iantimmis/followers", "following_url": "https://api.github.com/users/iantimmis/following{/other_user}", "gists_url": "https://api.github.com/users/iantimmis/gists{/gist_id}", "starred_url": "https://api.github.com/users/iantimmis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iantimmis/subscriptions", "organizations_url": "https://api.github.com/users/iantimmis/orgs", "repos_url": "https://api.github.com/users/iantimmis/repos", "events_url": "https://api.github.com/users/iantimmis/events{/privacy}", "received_events_url": "https://api.github.com/users/iantimmis/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 2, "created_at": "2020-08-17T23:02:32Z", "updated_at": "2020-08-19T20:41:34Z", "closed_at": "2020-08-19T20:41:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- A clear and concise description of what the bug is. -->\r\n\r\nUsing `precision=16` and `auto_scale_batch_size=True` yields `'NoneType' object has no attribute 'state_dict'` error\r\n\r\n### Expected behavior\r\n\r\nLargest batch size should be found when using 16 bit precision\r\n\r\n### Environment\r\n- PyTorch Version (e.g., 1.0): 1.6\r\n - OS (e.g., Linux): Windows 10\r\n - How you installed PyTorch (`conda`, `pip`, source): conda\r\n - Python version: 3.8\r\n - CUDA/cuDNN version: 10/7\r\n - GPU models and configuration: 2080ti", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3022", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3022/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3022/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3022/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3022", "id": 680547131, "node_id": "MDU6SXNzdWU2ODA1NDcxMzE=", "number": 3022, "title": "How to specify which particular networks/weights to save when training GANs", "user": {"login": "kushalchordiya216", "id": 34130680, "node_id": "MDQ6VXNlcjM0MTMwNjgw", "avatar_url": "https://avatars2.githubusercontent.com/u/34130680?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kushalchordiya216", "html_url": "https://github.com/kushalchordiya216", "followers_url": "https://api.github.com/users/kushalchordiya216/followers", "following_url": "https://api.github.com/users/kushalchordiya216/following{/other_user}", "gists_url": "https://api.github.com/users/kushalchordiya216/gists{/gist_id}", "starred_url": "https://api.github.com/users/kushalchordiya216/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kushalchordiya216/subscriptions", "organizations_url": "https://api.github.com/users/kushalchordiya216/orgs", "repos_url": "https://api.github.com/users/kushalchordiya216/repos", "events_url": "https://api.github.com/users/kushalchordiya216/events{/privacy}", "received_events_url": "https://api.github.com/users/kushalchordiya216/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-08-17T21:51:12Z", "updated_at": "2020-08-18T19:33:41Z", "closed_at": "2020-08-18T19:33:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n### Before asking:   \r\n1. search the issues.   \r\n2. search the docs.    \r\n\r\n<!-- If you still can't find what you need: -->\r\n\r\n#### What is your question?\r\nif my model consists of my models consist of several independent modules, how to save only specific modules during training. For instance, I have the following two models\r\n\r\n#### Code\r\n\r\n    class PreTrainGenModel(pl.LightningModule):\r\n        def __init__(self):\r\n            super().__init__()\r\n            self.netG = Generator()\r\n            self.VGG = PerceptionNet()\r\n\r\n    class GAN(pl.LightningModule):\r\n        def __init__(self, hparams):\r\n              super(GAN, self).__init__()\r\n              self.hparams = hparams\r\n              self.netG: nn.Module = Generator()\r\n              self.netD: nn.Module = Discriminator()\r\n              self.perceptual = PerceptionNet()\r\n\r\n<!-- Please paste a code snippet if your question requires it! -->   \r\n\r\nGenerator, Discriminator and PerceptionNet are ordinary PyTorch nn. Module classes, where I've defined my network architectures\r\nThe pretrainGenClass pre trains my generator (it's just an experimental approach I'm trying) The perception net model is basically just a frozen VGG_19 graph, that I'm using to calculate a content loss between the real and fake images. \r\n\r\nI first want to train PreTrainGen, which only updates weights of the net, since perception net (VGG) graph is frozen. however, when I save it, the checkpoint state_dict also contains weights of the frozen VGG model, and hence I cannot directly load it, Generator class while training the GAN, since the model state_dict does not match the checkpoint state_dict\r\nI'm assuming even for the GAN training, the checkpoint will save all weights, including the discriminator, which is not what I want during inference.\r\n\r\n#### What have you tried?\r\nI have considered the obvious approach of not including the PerceptionNet inside the lightning module definition, since it's not a part of the computation graph anyway, and while this admittedly solves the issue for pretraining, the saved checkpoint for GAN will still have the discriminator weights coupled with the generator weights. \r\nI know the inference can still be done if the forward method of the lightning module is written correctly, but I would much rather prefer if there was a cleaner way to specify exactly which of the models I want to save during training of GANs or any other model that might have multiple independent modules inside.\r\n\r\nI have also considered filtering out the parts of the checkpoint state_dict that correspond to the VGG net and only load the netG weights, but that approach seems even clunkier.\r\nAny help would be greatly appreciated, I'm still new to pytorch lightning, but I've scoured the docs and examples, and haven't found anything that answers my questions yet\r\n#### What's your environment?\r\n\r\n - OS: Linux\r\n - Packaging pip\r\n - Version  0.9.0.rc15\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3019", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3019/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3019/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3019/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3019", "id": 680381700, "node_id": "MDU6SXNzdWU2ODAzODE3MDA=", "number": 3019, "title": "Results gathering with varying tensor shapes (e.g. last batch)", "user": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-08-17T16:53:33Z", "updated_at": "2020-08-19T00:27:49Z", "closed_at": "2020-08-19T00:27:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nResults object reduction when batch sizes are different won't work because torch.stack get's different input shapes. This can happen if your dataloader returns a smaller batch for the last iteration, for example.\r\n\r\n```python\r\ndef recursive_stack(result: MutableMapping):\r\n    for k, v in result.items():\r\n        if isinstance(v, dict):\r\n            recursive_stack(v)\r\n        if isinstance(v, list) and len(v) > 0 and isinstance(v[0], torch.Tensor):\r\n            v = torch.stack(v)\r\n            result[k] = v\r\n```\r\n\r\nContext\r\nFrom slack discussion by @artgor \r\nhttps://pytorch-lightning.slack.com/archives/CRBLFHY79/p1597604494424600\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3017", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3017/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3017/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3017/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3017", "id": 680368864, "node_id": "MDU6SXNzdWU2ODAzNjg4NjQ=", "number": 3017, "title": "Allow adding metric names to checkpoint files with Result objects.", "user": {"login": "edenlightning", "id": 66261195, "node_id": "MDQ6VXNlcjY2MjYxMTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/66261195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edenlightning", "html_url": "https://github.com/edenlightning", "followers_url": "https://api.github.com/users/edenlightning/followers", "following_url": "https://api.github.com/users/edenlightning/following{/other_user}", "gists_url": "https://api.github.com/users/edenlightning/gists{/gist_id}", "starred_url": "https://api.github.com/users/edenlightning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edenlightning/subscriptions", "organizations_url": "https://api.github.com/users/edenlightning/orgs", "repos_url": "https://api.github.com/users/edenlightning/repos", "events_url": "https://api.github.com/users/edenlightning/events{/privacy}", "received_events_url": "https://api.github.com/users/edenlightning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 0, "created_at": "2020-08-17T16:39:46Z", "updated_at": "2020-08-20T00:34:10Z", "closed_at": "2020-08-20T00:34:10Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Before the results object, you were able to specify which metric values should be part of the checkpoint's file name, but with results object that is not possible any more.\r\nWe should add options to change the checkpoint file name.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3015", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3015/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3015/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3015/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3015", "id": 680230183, "node_id": "MDU6SXNzdWU2ODAyMzAxODM=", "number": 3015, "title": "The right place for an \"essential\" callback", "user": {"login": "ujjwalx", "id": 24596957, "node_id": "MDQ6VXNlcjI0NTk2OTU3", "avatar_url": "https://avatars1.githubusercontent.com/u/24596957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ujjwalx", "html_url": "https://github.com/ujjwalx", "followers_url": "https://api.github.com/users/ujjwalx/followers", "following_url": "https://api.github.com/users/ujjwalx/following{/other_user}", "gists_url": "https://api.github.com/users/ujjwalx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ujjwalx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ujjwalx/subscriptions", "organizations_url": "https://api.github.com/users/ujjwalx/orgs", "repos_url": "https://api.github.com/users/ujjwalx/repos", "events_url": "https://api.github.com/users/ujjwalx/events{/privacy}", "received_events_url": "https://api.github.com/users/ujjwalx/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-17T13:19:31Z", "updated_at": "2020-08-20T21:35:47Z", "closed_at": "2020-08-20T21:35:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n#### What is your question?\r\nI am currently using an ordinal loss formulation that cuts up a real-valued output space into regions using ```cutpoints```. Each region is linked to a discrete ordered label. After the backward (optimizer step), the model requires ```cutpoints``` to be re-arranged in an ascending order. I've provided a brief snippet from the original author on how to achieve this using vanilla pytorch (library :  [spacecutter](https://github.com/EthanRosenthal/spacecutter))\r\n\r\n```python\r\ndef ascension_callback(margin=0.0, min_val=-1.0e6):\r\n\r\n    def _clip(module):\r\n        if isinstance(module, LogisticCumulativeLink):\r\n            cutpoints = module.cutpoints.data\r\n            for i in range(cutpoints.shape[0] - 1):\r\n                cutpoints[i].clamp_(\r\n                    min_val, cutpoints[i + 1] - margin\r\n                )\r\n    \r\n    return _clip\r\n\r\ncallback = ascension_callback()\r\n\r\n# In your training loop, do the following:\r\n\r\nfor data in data_iterator:\r\n    # Calculate loss\r\n    # Step optimizer\r\n    model.apply(callback)\r\n```\r\n#### What have you tried?\r\n\r\nTo achieve this in pytorch-lightning, I converted the original callback code to the form below :\r\n\r\n```python\r\nclass AscensionCallback(Callback):\r\n    \"\"\"\r\n    Ensure that each cutpoint is ordered in ascending value.\r\n    e.g.\r\n\r\n    .. < cutpoint[i - 1] < cutpoint[i] < cutpoint[i + 1] < ...\r\n\r\n    This is done by clipping the cutpoint values at the end of a batch gradient\r\n    update. By no means is this an efficient way to do things, but it works out\r\n    of the box with stochastic gradient descent.\r\n\r\n    Parameters\r\n    ----------\r\n    margin : float, (default=0.0)\r\n        The minimum value between any two adjacent cutpoints.\r\n        e.g. enforce that cutpoint[i - 1] + margin < cutpoint[i]\r\n    min_val : float, (default=-1e6)\r\n        Minimum value that the smallest cutpoint may take.\r\n    \"\"\"\r\n\r\n    def __init__(self, margin: float = 0.0, min_val: float = -1.0e6) -> None:\r\n        super().__init__()\r\n        self.margin = margin\r\n        self.min_val = min_val\r\n\r\n    def clip(self, module: Module) -> None:\r\n        # NOTE: Only works for LogisticCumulativeLink right now\r\n        # We assume the cutpoints parameters are called `cutpoints`.\r\n        if isinstance(module, LogisticCumulativeLink):\r\n            cutpoints = module.cutpoints.data\r\n            for i in range(cutpoints.shape[0] - 1):\r\n                cutpoints[i].clamp_(self.min_val, cutpoints[i + 1] - self.margin)\r\n\r\n    def on_batch_end(self, trainer, pl_module):\r\n        pl_module.model.apply(self.clip)\r\n```\r\nI then call it using the trainer like so:\r\n\r\n```python\r\ntrainer = Trainer.from_argparse_args(args, callbacks=[AscensionCallback()])\r\n```\r\n\r\n#### Questions?\r\n\r\n1. The documentation suggests using callbacks for non-essential code. In this case, the callback is essential and directly modifies the cutpoints. Are callbacks the right way to do something like this?\r\n\r\n2. If not, how can I incorporate this into the main LightningModule such that the clip function is called after optimizer step during training. In which function do I place a call to this \"AscensionCallback()\"\r\n\r\n#### What's your environment?\r\n\r\n - OS: Ubuntu 20.04.1 LTS\r\n - Packaging : pip\r\n - Version : 0.8.5\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3012", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3012/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3012/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3012/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3012", "id": 680068739, "node_id": "MDU6SXNzdWU2ODAwNjg3Mzk=", "number": 3012, "title": "TrainResult doesn't log to tensorboard by default", "user": {"login": "xiadingZ", "id": 16729275, "node_id": "MDQ6VXNlcjE2NzI5Mjc1", "avatar_url": "https://avatars1.githubusercontent.com/u/16729275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiadingZ", "html_url": "https://github.com/xiadingZ", "followers_url": "https://api.github.com/users/xiadingZ/followers", "following_url": "https://api.github.com/users/xiadingZ/following{/other_user}", "gists_url": "https://api.github.com/users/xiadingZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiadingZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiadingZ/subscriptions", "organizations_url": "https://api.github.com/users/xiadingZ/orgs", "repos_url": "https://api.github.com/users/xiadingZ/repos", "events_url": "https://api.github.com/users/xiadingZ/events{/privacy}", "received_events_url": "https://api.github.com/users/xiadingZ/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "teddykoker", "id": 11153048, "node_id": "MDQ6VXNlcjExMTUzMDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11153048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teddykoker", "html_url": "https://github.com/teddykoker", "followers_url": "https://api.github.com/users/teddykoker/followers", "following_url": "https://api.github.com/users/teddykoker/following{/other_user}", "gists_url": "https://api.github.com/users/teddykoker/gists{/gist_id}", "starred_url": "https://api.github.com/users/teddykoker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teddykoker/subscriptions", "organizations_url": "https://api.github.com/users/teddykoker/orgs", "repos_url": "https://api.github.com/users/teddykoker/repos", "events_url": "https://api.github.com/users/teddykoker/events{/privacy}", "received_events_url": "https://api.github.com/users/teddykoker/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "teddykoker", "id": 11153048, "node_id": "MDQ6VXNlcjExMTUzMDQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11153048?v=4", "gravatar_id": "", "url": "https://api.github.com/users/teddykoker", "html_url": "https://github.com/teddykoker", "followers_url": "https://api.github.com/users/teddykoker/followers", "following_url": "https://api.github.com/users/teddykoker/following{/other_user}", "gists_url": "https://api.github.com/users/teddykoker/gists{/gist_id}", "starred_url": "https://api.github.com/users/teddykoker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/teddykoker/subscriptions", "organizations_url": "https://api.github.com/users/teddykoker/orgs", "repos_url": "https://api.github.com/users/teddykoker/repos", "events_url": "https://api.github.com/users/teddykoker/events{/privacy}", "received_events_url": "https://api.github.com/users/teddykoker/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 5, "created_at": "2020-08-17T09:01:13Z", "updated_at": "2020-08-18T20:04:30Z", "closed_at": "2020-08-18T20:04:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is my code:\r\n```\r\n        result = pl.TrainResult(minimize=loss)\r\n        result.log('train_loss', loss, prog_bar=True)\r\n```\r\ntensorboard logger doesn't show `train_loss`.  \r\n`EvalResult` is normal, it can log to tensorboard by default.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3005", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3005/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3005/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/3005/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/3005", "id": 679764145, "node_id": "MDU6SXNzdWU2Nzk3NjQxNDU=", "number": 3005, "title": "`type_as` bug in the doc of LightningModule", "user": {"login": "szywise", "id": 19483628, "node_id": "MDQ6VXNlcjE5NDgzNjI4", "avatar_url": "https://avatars3.githubusercontent.com/u/19483628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/szywise", "html_url": "https://github.com/szywise", "followers_url": "https://api.github.com/users/szywise/followers", "following_url": "https://api.github.com/users/szywise/following{/other_user}", "gists_url": "https://api.github.com/users/szywise/gists{/gist_id}", "starred_url": "https://api.github.com/users/szywise/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/szywise/subscriptions", "organizations_url": "https://api.github.com/users/szywise/orgs", "repos_url": "https://api.github.com/users/szywise/repos", "events_url": "https://api.github.com/users/szywise/events{/privacy}", "received_events_url": "https://api.github.com/users/szywise/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1840917107, "node_id": "MDU6TGFiZWwxODQwOTE3MTA3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/documentation", "name": "documentation", "color": "0075ca", "default": true, "description": "Improvements or additions to documentation"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 2, "created_at": "2020-08-16T14:27:57Z", "updated_at": "2020-08-18T21:51:40Z", "closed_at": "2020-08-18T21:51:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nWhen I run [this line of code](https://github.com/PyTorchLightning/pytorch-lightning/blame/master/docs/source/lightning-module.rst#L54) in the doc, it complains that `type_as` shouldn't be given a `str`.\r\n\r\n### To Reproduce\r\n#### Code sample\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\nThe last line of the following code\r\n```python\r\nx = torch.zeros(2, device='cpu')\r\nnew_x = torch.zeros(3, device='cuda:0')\r\nnew_x = new_x.type_as(x.type())\r\n```\r\ngives this error:\r\n```plain\r\nTypeError: type_as(): argument 'other' (position 1) must be Tensor, not str\r\n```\r\n\r\n### Expected behavior\r\n\r\nCast `new_x` to the same type as `x`.\r\n\r\nA potential fix:\r\n```python\r\nnew_x = new_x.type_as(x)\r\n```\r\n\r\n### Environment\r\n\r\n```plain\r\n* CUDA:\r\n        - GPU:\r\n                - GeForce RTX 2080\r\n                - GeForce RTX 2080\r\n        - available:         True\r\n        - version:           10.2\r\n* Packages:\r\n        - numpy:             1.18.5\r\n        - pyTorch_debug:     False\r\n        - pyTorch_version:   1.5.1\r\n        - pytorch-lightning: 0.9.0rc5\r\n        - tensorboard:       2.2.2\r\n        - tqdm:              4.47.0\r\n* System:\r\n        - OS:                Linux\r\n        - architecture:\r\n                - 64bit\r\n                - ELF\r\n        - processor:         x86_64\r\n        - python:            3.8.3\r\n        - version:           #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2993", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2993/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2993/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2993/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2993", "id": 679668215, "node_id": "MDU6SXNzdWU2Nzk2NjgyMTU=", "number": 2993, "title": "Average loss calculated by pl is different from manual average loss", "user": {"login": "dreamgonfly", "id": 2340721, "node_id": "MDQ6VXNlcjIzNDA3MjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/2340721?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dreamgonfly", "html_url": "https://github.com/dreamgonfly", "followers_url": "https://api.github.com/users/dreamgonfly/followers", "following_url": "https://api.github.com/users/dreamgonfly/following{/other_user}", "gists_url": "https://api.github.com/users/dreamgonfly/gists{/gist_id}", "starred_url": "https://api.github.com/users/dreamgonfly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dreamgonfly/subscriptions", "organizations_url": "https://api.github.com/users/dreamgonfly/orgs", "repos_url": "https://api.github.com/users/dreamgonfly/repos", "events_url": "https://api.github.com/users/dreamgonfly/events{/privacy}", "received_events_url": "https://api.github.com/users/dreamgonfly/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-16T01:10:07Z", "updated_at": "2020-08-17T12:08:48Z", "closed_at": "2020-08-17T12:08:48Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nValidation loss reported by pytorch-lightning on progress bar is different from manually averaged validation loss.\r\n\r\nI'm not sure if it's a bug or an intended behavior, but I cannot understand why two values are different.\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Run the below code\r\n2. Observe printed average val loss\r\n\r\n![image](https://user-images.githubusercontent.com/2340721/90324307-f1f32e00-dfa7-11ea-92d6-6549943a7b43.png)\r\n\r\n1 epoch:\r\nval loss on progress bar: 0.962\r\nmanually averaged val loss: 1.2909\r\n\r\n2 epoch:\r\nval loss on progress bar: 0.946\r\nmanually averaged val loss: 1.2527\r\n\r\n\r\n#### Code sample\r\n```python\r\nimport os\r\n\r\nimport torch\r\nfrom torch.nn import functional as F\r\nfrom torch.utils.data import DataLoader\r\nfrom torchvision.datasets import MNIST\r\nfrom torchvision import transforms\r\nimport pytorch_lightning as pl\r\n\r\n\r\nclass MNISTModel(pl.LightningModule):\r\n    def __init__(self):\r\n        super(MNISTModel, self).__init__()\r\n        # not the best model...\r\n        self.l1 = torch.nn.Linear(28 * 28, 10)\r\n        self.val_losses = []\r\n\r\n    def forward(self, x):\r\n        # called with self(x)\r\n        return torch.relu(self.l1(x.view(x.size(0), -1)))\r\n\r\n    def training_step(self, batch, batch_nb):\r\n        # REQUIRED\r\n        x, y = batch\r\n        y_hat = self(x)\r\n        loss = F.cross_entropy(y_hat, y)\r\n        tensorboard_logs = {\"train_loss\": loss}\r\n        return {\"loss\": loss, \"log\": tensorboard_logs}\r\n\r\n    def validation_step(self, batch, batch_nb):\r\n        # OPTIONAL\r\n        x, y = batch\r\n        y_hat = self(x)\r\n        val_loss = F.cross_entropy(y_hat, y)\r\n        self.val_losses.append(val_loss.item())\r\n        return {\r\n            \"loss\": val_loss,\r\n            \"progress_bar\": {\"val_loss\": val_loss},\r\n            \"log\": {\"val_loss\": val_loss},\r\n        }\r\n\r\n    def on_validation_epoch_end(self):\r\n        print(\"average val loss\", sum(self.val_losses) / len(self.val_losses))\r\n        self.val_losses = []\r\n\r\n    def configure_optimizers(self):\r\n        # REQUIRED\r\n        # can return multiple optimizers and learning_rate schedulers\r\n        # (LBFGS it is automatically supported, no need for closure function)\r\n        return torch.optim.Adam(self.parameters(), lr=0.02)\r\n\r\n    def train_dataloader(self):\r\n        # REQUIRED\r\n        return DataLoader(\r\n            MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()),\r\n            batch_size=32,\r\n        )\r\n\r\n    def val_dataloader(self):\r\n        # OPTIONAL\r\n        return DataLoader(\r\n            MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()),\r\n            batch_size=32,\r\n        )\r\n\r\n\r\nmnist_model = MNISTModel()\r\n\r\n# most basic trainer, uses good defaults (1 gpu)\r\ntrainer = pl.Trainer(gpus=1)\r\ntrainer.fit(mnist_model)\r\n\r\n```\r\n### Expected behavior\r\n\r\nval losses manually calculated should match the one reported by progress bar of pytorch-lightning\r\n\r\n### Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py\r\n# For security purposes, please check the contents of collect_env_details.py before running it.\r\npython collect_env_details.py\r\n```\r\n\r\n - PyTorch Version: 1.6\r\n - OS (e.g., Linux): Base Docker image: nvidia/cuda:10.2-cudnn7-devel-ubuntu18.04\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source): None\r\n - Python version: 3.8\r\n - CUDA/cuDNN version: CUDA 10.2, cudnn 7\r\n - GPU models and configuration: Titan RTX\r\n - Any other relevant information:\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2992", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2992/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2992/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2992/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2992", "id": 679650015, "node_id": "MDU6SXNzdWU2Nzk2NTAwMTU=", "number": 2992, "title": "Gradient Clipping for discriminator only", "user": {"login": "VasudevGupta7", "id": 53136577, "node_id": "MDQ6VXNlcjUzMTM2NTc3", "avatar_url": "https://avatars2.githubusercontent.com/u/53136577?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VasudevGupta7", "html_url": "https://github.com/VasudevGupta7", "followers_url": "https://api.github.com/users/VasudevGupta7/followers", "following_url": "https://api.github.com/users/VasudevGupta7/following{/other_user}", "gists_url": "https://api.github.com/users/VasudevGupta7/gists{/gist_id}", "starred_url": "https://api.github.com/users/VasudevGupta7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VasudevGupta7/subscriptions", "organizations_url": "https://api.github.com/users/VasudevGupta7/orgs", "repos_url": "https://api.github.com/users/VasudevGupta7/repos", "events_url": "https://api.github.com/users/VasudevGupta7/events{/privacy}", "received_events_url": "https://api.github.com/users/VasudevGupta7/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-15T22:15:31Z", "updated_at": "2020-08-16T07:55:05Z", "closed_at": "2020-08-16T07:55:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "How can I clip the weights for only discriminator while training GAN?\r\n\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2991", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2991/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2991/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2991/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2991", "id": 679639329, "node_id": "MDU6SXNzdWU2Nzk2MzkzMjk=", "number": 2991, "title": "Calling pl.TrainResult causes an exception", "user": {"login": "xhlulu", "id": 21180505, "node_id": "MDQ6VXNlcjIxMTgwNTA1", "avatar_url": "https://avatars2.githubusercontent.com/u/21180505?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xhlulu", "html_url": "https://github.com/xhlulu", "followers_url": "https://api.github.com/users/xhlulu/followers", "following_url": "https://api.github.com/users/xhlulu/following{/other_user}", "gists_url": "https://api.github.com/users/xhlulu/gists{/gist_id}", "starred_url": "https://api.github.com/users/xhlulu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xhlulu/subscriptions", "organizations_url": "https://api.github.com/users/xhlulu/orgs", "repos_url": "https://api.github.com/users/xhlulu/repos", "events_url": "https://api.github.com/users/xhlulu/events{/privacy}", "received_events_url": "https://api.github.com/users/xhlulu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1840917107, "node_id": "MDU6TGFiZWwxODQwOTE3MTA3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/documentation", "name": "documentation", "color": "0075ca", "default": true, "description": "Improvements or additions to documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-15T20:45:52Z", "updated_at": "2020-08-16T08:17:09Z", "closed_at": "2020-08-16T08:17:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "[The docs](https://pytorch-lightning.readthedocs.io/en/latest/loggers.html) shows the following code snippet:\r\n```\r\ndef training_step(self, batch, batch_idx):\r\n    loss = ...\r\n\r\n    result = pl.TrainResult(minimize=loss)\r\n    result.log('train_loss', loss)\r\n    return result\r\n```\r\n\r\nHowever, calling `pl.TrainResult` in v0.8.5 causes an exception:\r\n```\r\nAttributeError: module 'pytorch_lightning' has no attribute 'TrainResult'\r\n```\r\n\r\nThis happened with:\r\n* Torch: 1.5.1\r\n* Environment: Kaggle kernels", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2989", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2989/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2989/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2989/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2989", "id": 679615782, "node_id": "MDU6SXNzdWU2Nzk2MTU3ODI=", "number": 2989, "title": "\"limit_train_batches\" not receiving float value", "user": {"login": "asrafulashiq", "id": 4235357, "node_id": "MDQ6VXNlcjQyMzUzNTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/4235357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asrafulashiq", "html_url": "https://github.com/asrafulashiq", "followers_url": "https://api.github.com/users/asrafulashiq/followers", "following_url": "https://api.github.com/users/asrafulashiq/following{/other_user}", "gists_url": "https://api.github.com/users/asrafulashiq/gists{/gist_id}", "starred_url": "https://api.github.com/users/asrafulashiq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asrafulashiq/subscriptions", "organizations_url": "https://api.github.com/users/asrafulashiq/orgs", "repos_url": "https://api.github.com/users/asrafulashiq/repos", "events_url": "https://api.github.com/users/asrafulashiq/events{/privacy}", "received_events_url": "https://api.github.com/users/asrafulashiq/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "Borda", "id": 6035284, "node_id": "MDQ6VXNlcjYwMzUyODQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/6035284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Borda", "html_url": "https://github.com/Borda", "followers_url": "https://api.github.com/users/Borda/followers", "following_url": "https://api.github.com/users/Borda/following{/other_user}", "gists_url": "https://api.github.com/users/Borda/gists{/gist_id}", "starred_url": "https://api.github.com/users/Borda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Borda/subscriptions", "organizations_url": "https://api.github.com/users/Borda/orgs", "repos_url": "https://api.github.com/users/Borda/repos", "events_url": "https://api.github.com/users/Borda/events{/privacy}", "received_events_url": "https://api.github.com/users/Borda/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Borda", "id": 6035284, "node_id": "MDQ6VXNlcjYwMzUyODQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/6035284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Borda", "html_url": "https://github.com/Borda", "followers_url": "https://api.github.com/users/Borda/followers", "following_url": "https://api.github.com/users/Borda/following{/other_user}", "gists_url": "https://api.github.com/users/Borda/gists{/gist_id}", "starred_url": "https://api.github.com/users/Borda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Borda/subscriptions", "organizations_url": "https://api.github.com/users/Borda/orgs", "repos_url": "https://api.github.com/users/Borda/repos", "events_url": "https://api.github.com/users/Borda/events{/privacy}", "received_events_url": "https://api.github.com/users/Borda/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-08-15T17:46:23Z", "updated_at": "2020-08-20T17:49:35Z", "closed_at": "2020-08-20T17:49:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nerror: argument --limit_train_batches: invalid int value: '0.3'\r\n\r\n### To Reproduce\r\n Just put any float value after '--limit_train_batches' or '--val_check_interval'\r\n\r\nI am using the latest master branch. 0.9.rc14\r\n\r\nI think this issue is related to the fix of #2943 ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2984", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2984/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2984/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2984/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2984", "id": 679485646, "node_id": "MDU6SXNzdWU2Nzk0ODU2NDY=", "number": 2984, "title": "CrossEntropyLoss with weights", "user": {"login": "johngrabner", "id": 8209285, "node_id": "MDQ6VXNlcjgyMDkyODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8209285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/johngrabner", "html_url": "https://github.com/johngrabner", "followers_url": "https://api.github.com/users/johngrabner/followers", "following_url": "https://api.github.com/users/johngrabner/following{/other_user}", "gists_url": "https://api.github.com/users/johngrabner/gists{/gist_id}", "starred_url": "https://api.github.com/users/johngrabner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/johngrabner/subscriptions", "organizations_url": "https://api.github.com/users/johngrabner/orgs", "repos_url": "https://api.github.com/users/johngrabner/repos", "events_url": "https://api.github.com/users/johngrabner/events{/privacy}", "received_events_url": "https://api.github.com/users/johngrabner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-08-15T02:46:24Z", "updated_at": "2020-08-15T22:43:28Z", "closed_at": "2020-08-15T09:49:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I need weights in CrossEntropyLoss (actually multiple, but the same issue).  The documentation talks about tensors copied from other tensors, but there is no tensor to copy from in the init.  So I'm stuck.\r\nTo make the weights unquestionably simple, I use ones.\r\n\r\n```\r\nclass JJG_Transformer(pl.LightningModule):\r\n\r\n    def __init__(self, alphanet_plus_2, letter_weights_per_position):\r\n        super(JJG_Transformer, self).__init__()\r\n        self.criterions = []\r\n        for weight in self.letter_weights_per_position:\r\n            weight = torch.ones((94))\r\n            self.criterions.append( torch.nn.CrossEntropyLoss(weight=weight) )\r\n    def validation_step(self, batch, batch_idx):\r\n        batch_im, batch_true_value_NT, batch_letter_transformer_input = batch\r\n        out_NTA = self(batch_im, batch_letter_transformer_input)\r\n        loss0 = self.criterions[0](out_NTA[:,0,:], batch_true_value_NT[:,0])\r\n        loss1 = self.criterions[1](out_NTA[:,1,:], batch_true_value_NT[:,1])\r\n        loss = loss0 + loss1\r\n        tensorboard_logs = {'val_loss': loss, 'val_loss0': loss0, 'val_loss1':loss1}\r\n        return {'val_loss': loss, 'log': tensorboard_logs}\r\n\r\n```\r\n\r\n  ```\r\nFile \"/home/john/Documents/GitHub/Offline_Handwriting_Recognition/Solutions/Aug2020_simple_transformer/src/kiss_transformer.py\", line 254, in <module>\r\n    trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/states.py\", line 34, in wrapped_fn\r\n    result = fn(self, *args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1017, in fit\r\n    self.accelerator_backend.train(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_backend.py\", line 56, in train\r\n    self.ddp_train(process_idx=self.task_idx, mp_queue=None, model=model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_backend.py\", line 219, in ddp_train\r\n    results = self.trainer.run_pretrain_routine(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1196, in run_pretrain_routine\r\n    self._run_sanity_check(ref_model, model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1229, in _run_sanity_check\r\n    eval_results = self._evaluate(model, self.val_dataloaders, max_batches, False)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 325, in _evaluate\r\n    output = self.evaluation_forward(model, batch, batch_idx, dataloader_idx, test_mode)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 609, in evaluation_forward\r\n    output = model(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py\", line 160, in forward\r\n    output = self.module.validation_step(*inputs[0], **kwargs[0])\r\n  File \"/home/john/Documents/GitHub/Offline_Handwriting_Recognition/Solutions/Aug2020_simple_transformer/src/kiss_transformer.py\", line 128, in validation_step\r\n    loss0 = self.criterions[0](out_NTA[:,0,:], batch_true_value_NT[:,0])\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\", line 948, in forward\r\n    ignore_index=self.ignore_index, reduction=self.reduction)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 2422, in cross_entropy\r\n    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 2218, in nll_loss\r\n    ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\r\nRuntimeError: Expected object of device type cuda but got device type cpu for argument #3 'weight' in call to _thnn_nll_loss_forward\r\nTraceback (most recent call last):\r\n  File \"kiss_transformer.py\", line 254, in <module>\r\n    trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/states.py\", line 34, in wrapped_fn\r\n    result = fn(self, *args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1030, in fit\r\n    results = self.accelerator_backend.spawn_ddp_children(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_backend.py\", line 118, in spawn_ddp_children\r\n    results = self.ddp_train(local_rank, mp_queue=None, model=model, is_master=True)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_backend.py\", line 219, in ddp_train\r\n    results = self.trainer.run_pretrain_routine(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1196, in run_pretrain_routine\r\n    self._run_sanity_check(ref_model, model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1229, in _run_sanity_check\r\n    eval_results = self._evaluate(model, self.val_dataloaders, max_batches, False)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 325, in _evaluate\r\n    output = self.evaluation_forward(model, batch, batch_idx, dataloader_idx, test_mode)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 609, in evaluation_forward\r\n    output = model(*args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py\", line 160, in forward\r\n    output = self.module.validation_step(*inputs[0], **kwargs[0])\r\n  File \"kiss_transformer.py\", line 128, in validation_step\r\n    loss0 = self.criterions[0](out_NTA[:,0,:], batch_true_value_NT[:,0])\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\", line 948, in forward\r\n    ignore_index=self.ignore_index, reduction=self.reduction)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 2422, in cross_entropy\r\n    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 2218, in nll_loss\r\n    ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\r\nRuntimeError: Expected object of device type cuda but got device type cpu for argument #3 'weight' in call to _thnn_nll_loss_forward\r\n```\r\n\r\n```\r\ntrainer = pl.Trainer( gpus=[0, 1],  \r\n                accumulate_grad_batches=16, \r\n                max_epochs=500, \r\n                check_val_every_n_epoch=1, \r\n                distributed_backend='ddp', \r\n```\r\n\r\npl__version__ 0.9.0rc12\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2979", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2979/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2979/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2979/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2979", "id": 679257024, "node_id": "MDU6SXNzdWU2NzkyNTcwMjQ=", "number": 2979, "title": "AttributeError: module 'pytorch_lightning' has no attribute 'TrainResult'", "user": {"login": "francoisruty", "id": 2826004, "node_id": "MDQ6VXNlcjI4MjYwMDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/2826004?v=4", "gravatar_id": "", "url": "https://api.github.com/users/francoisruty", "html_url": "https://github.com/francoisruty", "followers_url": "https://api.github.com/users/francoisruty/followers", "following_url": "https://api.github.com/users/francoisruty/following{/other_user}", "gists_url": "https://api.github.com/users/francoisruty/gists{/gist_id}", "starred_url": "https://api.github.com/users/francoisruty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/francoisruty/subscriptions", "organizations_url": "https://api.github.com/users/francoisruty/orgs", "repos_url": "https://api.github.com/users/francoisruty/repos", "events_url": "https://api.github.com/users/francoisruty/events{/privacy}", "received_events_url": "https://api.github.com/users/francoisruty/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-08-14T16:07:51Z", "updated_at": "2020-08-15T13:04:45Z", "closed_at": "2020-08-14T17:06:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nFollowing https://pytorch-lightning.readthedocs.io/en/latest/new-project.html\r\nI tried to log loss values to Tensorboard:\r\n\r\ndef training_step(self, batch, batch_idx):\r\n    loss = ...\r\n    result = pl.TrainResult(minimize=loss)\r\n    result.log('train_loss', loss)\r\n    return result\r\n\r\n\r\nIt seems module \"TrainResult\" is not present in pytorch-lighting, I'm using latest version (0.8.5)\r\n\r\nAfter browsing various github and SO issues I tried \r\nimport TrainResult from pytorch_lightning\r\n\r\nbut it still doesn't work\r\n\r\n### To Reproduce\r\n\r\nJust follow example in https://pytorch-lightning.readthedocs.io/en/latest/new-project.html\r\n\r\ndef training_step(self, batch, batch_idx):\r\n    loss = ...\r\n    result = pl.TrainResult(minimize=loss)\r\n    result.log('train_loss', loss)\r\n    return result\r\n\r\n\r\n### Expected behavior\r\n\r\nI expect code sample in documentation to work (not crash when importing a pytorch-lightning module)\r\n\r\n### Environment\r\n\r\n\r\n - PyTorch Version (e.g., 1.0): 1.5.0\r\n - OS (e.g., Linux): linux\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - Build command you used (if compiling from source): N/A\r\n - Python version: 3.6.9\r\n - CUDA/cuDNN version: docker image nvidia/cuda:10.2-cudnn7-devel-ubuntu18.04\r\n - GPU models and configuration: Nvidia GTI 1080\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2977", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2977/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2977/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2977/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2977", "id": 679132481, "node_id": "MDU6SXNzdWU2NzkxMzI0ODE=", "number": 2977, "title": "Would it be possible to have a boiler template codebase for Pytorch-lighthing / Sagemaker training, serving ?", "user": {"login": "tchaton", "id": 12861981, "node_id": "MDQ6VXNlcjEyODYxOTgx", "avatar_url": "https://avatars0.githubusercontent.com/u/12861981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tchaton", "html_url": "https://github.com/tchaton", "followers_url": "https://api.github.com/users/tchaton/followers", "following_url": "https://api.github.com/users/tchaton/following{/other_user}", "gists_url": "https://api.github.com/users/tchaton/gists{/gist_id}", "starred_url": "https://api.github.com/users/tchaton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tchaton/subscriptions", "organizations_url": "https://api.github.com/users/tchaton/orgs", "repos_url": "https://api.github.com/users/tchaton/repos", "events_url": "https://api.github.com/users/tchaton/events{/privacy}", "received_events_url": "https://api.github.com/users/tchaton/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-08-14T12:44:22Z", "updated_at": "2020-08-16T14:46:13Z", "closed_at": "2020-08-15T10:48:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\n\r\n### Motivation\r\n\r\nIn production env, Pytorch Lightning seems like a great option. I was wondering if you could provide a boiler template for serving / training with Sagemaker integration. \r\n\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\n### Pitch\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n### Alternatives\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, if any. -->\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2976", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2976/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2976/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2976/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2976", "id": 679052833, "node_id": "MDU6SXNzdWU2NzkwNTI4MzM=", "number": 2976, "title": "How to use ReduceLROnPlateau methon in matster branch version?", "user": {"login": "invisprints", "id": 15833553, "node_id": "MDQ6VXNlcjE1ODMzNTUz", "avatar_url": "https://avatars3.githubusercontent.com/u/15833553?v=4", "gravatar_id": "", "url": "https://api.github.com/users/invisprints", "html_url": "https://github.com/invisprints", "followers_url": "https://api.github.com/users/invisprints/followers", "following_url": "https://api.github.com/users/invisprints/following{/other_user}", "gists_url": "https://api.github.com/users/invisprints/gists{/gist_id}", "starred_url": "https://api.github.com/users/invisprints/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/invisprints/subscriptions", "organizations_url": "https://api.github.com/users/invisprints/orgs", "repos_url": "https://api.github.com/users/invisprints/repos", "events_url": "https://api.github.com/users/invisprints/events{/privacy}", "received_events_url": "https://api.github.com/users/invisprints/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 18, "created_at": "2020-08-14T10:09:20Z", "updated_at": "2020-08-18T06:35:22Z", "closed_at": "2020-08-16T15:37:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "#### What is your question?\r\nI find the log design has changed a lot between version 0.8.5 and master branch [0c26468](https://github.com/PyTorchLightning/pytorch-lightning/tree/0c264689cb566582ac47333d8b7192d656e19440)\r\nI got the error message when I follow the [docs logging-from-a-lightningmodule](https://pytorch-lightning.readthedocs.io/en/latest/loggers.html#logging-from-a-lightningmodule) to modify the log code.\r\n\r\nerror message:\r\n```\r\nMisconfigurationException: ReduceLROnPlateau conditioned on metric val_loss which is not available. Available metrics are: val_early_stop_on,val_checkpoint_on,epoch,checkpoint_on. Condition can be set using `monitor` key in lr scheduler dict\r\n```\r\n\r\n\r\n#### Code\r\n```python\r\ndef configure_optimizers(self):\r\n    optimizer = torch.optim.Adam(self.parameters(), lr = 0.01)\r\n    scheduler = ReduceLROnPlateau(optimizer, patience=10)\r\n    return [optimizer], [scheduler]\r\n\r\ndef validation_step(self, batch, batch_nb):\r\n    x, y = batch\r\n    \r\n    y_hat = self(x)    \r\n    loss = F.l1_loss(y, y_hat)\r\n    result = pl.EvalResult()\r\n    result.log('val_step_loss', loss)\r\n    return result\r\n\r\ndef validation_epoch_end(self, outputs):\r\n    avg_loss = outputs.val_step_loss.mean()\r\n    result = pl.EvalResult()\r\n    result.log('val_loss', avg_loss)\r\n    return result\r\n```\r\nI wonder if I should defined `validation_epoch_end` like above, **if there are any example about how to use `ReduceLROnPlateau` in a right way?**\r\n\r\n#### What's your environment?\r\n\r\n - OS: Ubuntu 18.04\r\n - Packaging pip\r\n - Version 0.9.0 rc 12 master branch [0c26468](https://github.com/PyTorchLightning/pytorch-lightning/tree/0c264689cb566582ac47333d8b7192d656e19440)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2975", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2975/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2975/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2975/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2975", "id": 678987069, "node_id": "MDU6SXNzdWU2Nzg5ODcwNjk=", "number": 2975, "title": "Confusion on random transformation for same batch", "user": {"login": "amitness", "id": 8587189, "node_id": "MDQ6VXNlcjg1ODcxODk=", "avatar_url": "https://avatars3.githubusercontent.com/u/8587189?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amitness", "html_url": "https://github.com/amitness", "followers_url": "https://api.github.com/users/amitness/followers", "following_url": "https://api.github.com/users/amitness/following{/other_user}", "gists_url": "https://api.github.com/users/amitness/gists{/gist_id}", "starred_url": "https://api.github.com/users/amitness/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amitness/subscriptions", "organizations_url": "https://api.github.com/users/amitness/orgs", "repos_url": "https://api.github.com/users/amitness/repos", "events_url": "https://api.github.com/users/amitness/events{/privacy}", "received_events_url": "https://api.github.com/users/amitness/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-08-14T08:16:14Z", "updated_at": "2020-08-14T12:17:13Z", "closed_at": "2020-08-14T12:11:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi @williamFalcon,\r\n\r\nI have been trying to overfit SimCLR on a single batch containing 2 images. I added breakpoints and noticed that each time the same batch is loaded on subsequent epochs, the transformation applied is different. Is this expected? \r\n\r\nMy expected result was that random transformations are applied once at start of training and same transformation for certain batch would persist across epochs. Not sure if this is a bug or I have a wrong understanding of the way DataLoaders work?\r\n\r\nHere is a minimal example with \r\n```\r\nfrom pl_bolts.models.self_supervised import SimCLR\r\nimport pytorch_lightning as pl\r\n\r\npl.seed_everything(42)\r\n\r\nmodel = SimCLR(data_dir='/tmp', batch_size=2)\r\n\r\ntrainer = pl.Trainer(gpus=1, \r\n                     overfit_batches=1,\r\n                     deterministic=True)\r\ntrainer.fit(model)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2972", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2972/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2972/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2972/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2972", "id": 678895115, "node_id": "MDU6SXNzdWU2Nzg4OTUxMTU=", "number": 2972, "title": "TrainResult/EvalResult does not log properly with on_step=True and on_epoch=True", "user": {"login": "sykrn", "id": 40594982, "node_id": "MDQ6VXNlcjQwNTk0OTgy", "avatar_url": "https://avatars0.githubusercontent.com/u/40594982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sykrn", "html_url": "https://github.com/sykrn", "followers_url": "https://api.github.com/users/sykrn/followers", "following_url": "https://api.github.com/users/sykrn/following{/other_user}", "gists_url": "https://api.github.com/users/sykrn/gists{/gist_id}", "starred_url": "https://api.github.com/users/sykrn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sykrn/subscriptions", "organizations_url": "https://api.github.com/users/sykrn/orgs", "repos_url": "https://api.github.com/users/sykrn/repos", "events_url": "https://api.github.com/users/sykrn/events{/privacy}", "received_events_url": "https://api.github.com/users/sykrn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-14T04:51:02Z", "updated_at": "2020-08-15T12:36:01Z", "closed_at": "2020-08-15T12:36:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n\r\nHere the minimal code in Colab: [here](https://colab.research.google.com/drive/10m_a8_M7lJcY_a_7sKf2_Gi_sECReNaX?usp=sharing)\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n#### OR:\r\n\r\n#### Code sample\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\n```python\r\nimport os\r\n\r\nimport torch\r\nfrom torch.nn import functional as F\r\nfrom torch.utils.data import DataLoader\r\nfrom torchvision.datasets import MNIST\r\nfrom torchvision import transforms\r\nimport pytorch_lightning as pl\r\n\r\n\r\n\r\nfrom pytorch_lightning.metrics.functional import accuracy\r\nfrom pytorch_lightning import TrainResult,EvalResult\r\n\r\nclass MNISTModel(pl.LightningModule):\r\n\r\n    def __init__(self):\r\n        super(MNISTModel, self).__init__()\r\n        self.l1 = torch.nn.Linear(28 * 28, 10)\r\n\r\n    def forward(self, x):\r\n        return torch.relu(self.l1(x.view(x.size(0), -1)))\r\n\r\n    def training_step(self, batch, batch_nb):\r\n        x, y = batch\r\n        y_hat = self(x)\r\n        loss = F.cross_entropy(y_hat, y)\r\n        acc = accuracy(y_hat, y)\r\n        result = TrainResult(minimize=loss)\r\n        result.log('tr_loss',loss,prog_bar=True,on_step=True,on_epoch=True)\r\n        result.log('tr_acc',acc,prog_bar=True,on_step=True,on_epoch=True)      \r\n        return result\r\n\r\n    def validation_step(self, batch, batch_nb):\r\n        x, y = batch\r\n        y_hat = self(x)\r\n        loss = F.cross_entropy(y_hat, y)\r\n        acc = accuracy(y_hat, y)\r\n        result = EvalResult(checkpoint_on=loss,early_stop_on=loss)\r\n        result.log('val_loss',loss,prog_bar=True,on_step=True,on_epoch=True)\r\n        result.log('val_acc',acc,prog_bar=True,on_step=True,on_epoch=True)        \r\n        return result\r\n\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.AdamW(self.parameters(), lr=0.02)\r\n\r\ntrain_loader = DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()),shuffle=True, batch_size=32)\r\nval_loader = DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)\r\nmnist_model = MNISTModel()\r\ntrainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=20,max_epochs=5)    \r\ntrainer.fit(mnist_model, train_loader,val_loader) \r\n```\r\n\r\n### Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nThe `step_val_loss` graph on **Tensorboard** should have $n_batch\\times epochs$ items (the number of step), but it looks like the same as number of epoch (only few of them).\r\n### Environment\r\n\r\nYou can get the script and run it with this PL version 0.9.0.rc12, I used the master version here.\r\n```\r\n!pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade\r\n```\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\nIn another experiment, I found in the `step_tr_loss` also not logging properly (looks like on_epoch=True with different values)\r\n\r\nHope someone can help this problem. Or is there any logical error in mycode?\r\nbecause, I always upgrade the PL version to master :D, ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2971", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2971/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2971/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2971/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2971", "id": 678875771, "node_id": "MDU6SXNzdWU2Nzg4NzU3NzE=", "number": 2971, "title": "TensorBoardLogger not saving hparams without metrics", "user": {"login": "s-rog", "id": 55400948, "node_id": "MDQ6VXNlcjU1NDAwOTQ4", "avatar_url": "https://avatars0.githubusercontent.com/u/55400948?v=4", "gravatar_id": "", "url": "https://api.github.com/users/s-rog", "html_url": "https://github.com/s-rog", "followers_url": "https://api.github.com/users/s-rog/followers", "following_url": "https://api.github.com/users/s-rog/following{/other_user}", "gists_url": "https://api.github.com/users/s-rog/gists{/gist_id}", "starred_url": "https://api.github.com/users/s-rog/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/s-rog/subscriptions", "organizations_url": "https://api.github.com/users/s-rog/orgs", "repos_url": "https://api.github.com/users/s-rog/repos", "events_url": "https://api.github.com/users/s-rog/events{/privacy}", "received_events_url": "https://api.github.com/users/s-rog/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-14T03:50:00Z", "updated_at": "2020-08-14T06:42:42Z", "closed_at": "2020-08-14T06:42:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\n`log_hyperparams` for `TensorBoardLogger` saves no data with default `metrics=None`, only hparam entries/names show up in sidebar\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n```\r\nimport pytorch_lightning as pl\r\nlogger = pl.loggers.TensorBoardLogger(\"./test_logs\")\r\ntest_dict = {\"test\":0}\r\nlogger.log_hyperparams(test_dict)                      ## no data saved\r\nlogger.log_hyperparams(test_dict, test_dict)           ## works\r\nlogger.log_metrics(test_dict)                          ## works\r\nlogger.experiment.add_hparams(test_dict, test_dict)    ## works but saves in a different events file\r\n```\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n### Expected behavior\r\nhparams data is saved and viewable via tensorboard with default args\r\n\r\n### Proposed solution\r\nFor default hparams logging without metrics, add a placeholder metric? I can do a PR if this is appropriate.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2958", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2958/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2958/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2958/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2958", "id": 678626411, "node_id": "MDU6SXNzdWU2Nzg2MjY0MTE=", "number": 2958, "title": "Make it easy to disable logging/checkpoints", "user": {"login": "import-antigravity", "id": 24441495, "node_id": "MDQ6VXNlcjI0NDQxNDk1", "avatar_url": "https://avatars2.githubusercontent.com/u/24441495?v=4", "gravatar_id": "", "url": "https://api.github.com/users/import-antigravity", "html_url": "https://github.com/import-antigravity", "followers_url": "https://api.github.com/users/import-antigravity/followers", "following_url": "https://api.github.com/users/import-antigravity/following{/other_user}", "gists_url": "https://api.github.com/users/import-antigravity/gists{/gist_id}", "starred_url": "https://api.github.com/users/import-antigravity/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/import-antigravity/subscriptions", "organizations_url": "https://api.github.com/users/import-antigravity/orgs", "repos_url": "https://api.github.com/users/import-antigravity/repos", "events_url": "https://api.github.com/users/import-antigravity/events{/privacy}", "received_events_url": "https://api.github.com/users/import-antigravity/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-13T17:47:54Z", "updated_at": "2020-08-13T18:02:29Z", "closed_at": "2020-08-13T18:02:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n\r\nIntroduce an easy way to disable logging and checkpoints for `Trainer` instances.\r\n\r\n### Motivation\r\n\r\nSometimes when training a model you don't want to keep any logs or checkpoints, and there doesn't appear to be an obvious way to do that.\r\n\r\n### Pitch\r\n\r\nThe most obvious way to implement this would be to make it so when `log_save_interval=0` the logger never writes to the disk.\r\n\r\n### Alternatives\r\n\r\nAs I understand it the current way to do this would be to make some sort of dummy class which inherits `LightningLoggerBase` but doesn't actually do anything. This strikes me as unnecessarily involved.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2956", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2956/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2956/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2956/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2956", "id": 678620699, "node_id": "MDU6SXNzdWU2Nzg2MjA2OTk=", "number": 2956, "title": "'NoneType' object has no attribute 'lower'  while training on TPU", "user": {"login": "lezwon", "id": 6305654, "node_id": "MDQ6VXNlcjYzMDU2NTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/6305654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lezwon", "html_url": "https://github.com/lezwon", "followers_url": "https://api.github.com/users/lezwon/followers", "following_url": "https://api.github.com/users/lezwon/following{/other_user}", "gists_url": "https://api.github.com/users/lezwon/gists{/gist_id}", "starred_url": "https://api.github.com/users/lezwon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lezwon/subscriptions", "organizations_url": "https://api.github.com/users/lezwon/orgs", "repos_url": "https://api.github.com/users/lezwon/repos", "events_url": "https://api.github.com/users/lezwon/events{/privacy}", "received_events_url": "https://api.github.com/users/lezwon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-13T17:37:50Z", "updated_at": "2020-08-13T22:57:24Z", "closed_at": "2020-08-13T22:57:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\ndistributed_backend is not set to 'tpu' which breaks it here: line https://github.com/PyTorchLightning/pytorch-lightning/blob/2c935d048e69a2890889dea768ecceb0252cf321/pytorch_lightning/trainer/distrib_data_parallel.py#L412\r\n\r\n\r\ndistributed_backend has to be explicitly specified in Trainer params to have it working which is misleading from the docs: https://pytorch-lightning.readthedocs.io/en/latest/tpu.html#distributed-backend-with-tpu\r\n\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nhttps://www.kaggle.com/lezwon/lightning-mnist-tpu\r\n\r\n\r\n### Expected behavior\r\n\r\nShould automatically set `distributed_backend` and train successfully.\r\n\r\n### Additional context\r\n\r\nRelated to : \r\nhttps://github.com/PyTorchLightning/pytorch-lightning/issues/2698#issuecomment-671665202\r\nhttps://github.com/PyTorchLightning/pytorch-lightning/issues/2812#issuecomment-668659590\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2955", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2955/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2955/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2955/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2955", "id": 678614277, "node_id": "MDU6SXNzdWU2Nzg2MTQyNzc=", "number": 2955, "title": "Using IterableDatasets without __len__ for Training", "user": {"login": "SiddhantRanade", "id": 7589861, "node_id": "MDQ6VXNlcjc1ODk4NjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/7589861?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SiddhantRanade", "html_url": "https://github.com/SiddhantRanade", "followers_url": "https://api.github.com/users/SiddhantRanade/followers", "following_url": "https://api.github.com/users/SiddhantRanade/following{/other_user}", "gists_url": "https://api.github.com/users/SiddhantRanade/gists{/gist_id}", "starred_url": "https://api.github.com/users/SiddhantRanade/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SiddhantRanade/subscriptions", "organizations_url": "https://api.github.com/users/SiddhantRanade/orgs", "repos_url": "https://api.github.com/users/SiddhantRanade/repos", "events_url": "https://api.github.com/users/SiddhantRanade/events{/privacy}", "received_events_url": "https://api.github.com/users/SiddhantRanade/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-13T17:26:43Z", "updated_at": "2020-08-13T21:06:18Z", "closed_at": "2020-08-13T21:06:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Calling `fit(model, trainloader, evalloader)` internally calls `enforce_datamodule_dataloader_override`. This function \r\nhas the if statement `if (train_dataloader or val_dataloaders) and datamodule:`. https://github.com/PyTorchLightning/pytorch-lightning/blob/2c935d048e69a2890889dea768ecceb0252cf321/pytorch_lightning/trainer/configuration_validator.py#L13\r\n\r\nThis is similar to the PR #1560, the problem is that the `if(dl)` translates to `if(bool(dl))`, but there's no dataloader.__bool__ so bool() uses dataloader.__len__ > 0. But... dataloader.__len__ uses IterableDataset.__len__ for IterableDatasets for which __len__ is undefined.\r\n\r\nThe fix is also the same, the `if dl` should be replaced by `if dl is not None`.\r\n\r\nI will open a PR fixing this.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2953", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2953/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2953/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2953/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2953", "id": 678553993, "node_id": "MDU6SXNzdWU2Nzg1NTM5OTM=", "number": 2953, "title": "Best Practice to log images in vision tasks", "user": {"login": "Haydnspass", "id": 16120273, "node_id": "MDQ6VXNlcjE2MTIwMjcz", "avatar_url": "https://avatars1.githubusercontent.com/u/16120273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Haydnspass", "html_url": "https://github.com/Haydnspass", "followers_url": "https://api.github.com/users/Haydnspass/followers", "following_url": "https://api.github.com/users/Haydnspass/following{/other_user}", "gists_url": "https://api.github.com/users/Haydnspass/gists{/gist_id}", "starred_url": "https://api.github.com/users/Haydnspass/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Haydnspass/subscriptions", "organizations_url": "https://api.github.com/users/Haydnspass/orgs", "repos_url": "https://api.github.com/users/Haydnspass/repos", "events_url": "https://api.github.com/users/Haydnspass/events{/privacy}", "received_events_url": "https://api.github.com/users/Haydnspass/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-13T16:05:15Z", "updated_at": "2020-08-14T00:04:38Z", "closed_at": "2020-08-14T00:04:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What is the best practice to log images?**\r\n\r\nIs there a standard procedure to log output images from the validation set to any kind of logger (e.g. Tensorboard)?\r\n\r\nUsually, I like to log a number of outputs of say over the epochs to see how the prediction evolves. \r\nMoreover, I pick a number of random samples and log them. \r\n\r\nI am not quite sure how to do this with Pytorch Lightning and whether there is a common way to do it.\r\n\r\nIf not maybe I could help? My suggestion would be\r\n- Add a Callback for logging images\r\n- Get the indices of the samples one wants to log\r\n- Cache these samples in `validation_step`\r\n- Let the Callback log these images in `on_epoch_end` method\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2952", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2952/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2952/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2952/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2952", "id": 678546902, "node_id": "MDU6SXNzdWU2Nzg1NDY5MDI=", "number": 2952, "title": "Global Step Graph looks incorrect?", "user": {"login": "shreyaskamathkm", "id": 16343884, "node_id": "MDQ6VXNlcjE2MzQzODg0", "avatar_url": "https://avatars2.githubusercontent.com/u/16343884?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shreyaskamathkm", "html_url": "https://github.com/shreyaskamathkm", "followers_url": "https://api.github.com/users/shreyaskamathkm/followers", "following_url": "https://api.github.com/users/shreyaskamathkm/following{/other_user}", "gists_url": "https://api.github.com/users/shreyaskamathkm/gists{/gist_id}", "starred_url": "https://api.github.com/users/shreyaskamathkm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shreyaskamathkm/subscriptions", "organizations_url": "https://api.github.com/users/shreyaskamathkm/orgs", "repos_url": "https://api.github.com/users/shreyaskamathkm/repos", "events_url": "https://api.github.com/users/shreyaskamathkm/events{/privacy}", "received_events_url": "https://api.github.com/users/shreyaskamathkm/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-13T15:54:44Z", "updated_at": "2020-08-14T00:06:02Z", "closed_at": "2020-08-14T00:06:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\nWhile using wandb logger, the global steps graph looks incorrect. Not really sure if this is a expected behavior? I think the previous RC didn't have this problem.\r\n\r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nThe graph should be a straight line and should not drop as seen in the figure below:\r\n\r\n\r\n### To Reproduce\r\n\r\nJust including wandb logger in the trainer.\r\n\r\n![image](https://user-images.githubusercontent.com/16343884/90157446-bebc5f00-dd5b-11ea-95bb-6a911452dbda.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2951", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2951/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2951/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2951/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2951", "id": 678545516, "node_id": "MDU6SXNzdWU2Nzg1NDU1MTY=", "number": 2951, "title": "Document fixes: early_stop_checkpoint is not an valid argument for pl.Trainer", "user": {"login": "louis2889184", "id": 32589903, "node_id": "MDQ6VXNlcjMyNTg5OTAz", "avatar_url": "https://avatars1.githubusercontent.com/u/32589903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/louis2889184", "html_url": "https://github.com/louis2889184", "followers_url": "https://api.github.com/users/louis2889184/followers", "following_url": "https://api.github.com/users/louis2889184/following{/other_user}", "gists_url": "https://api.github.com/users/louis2889184/gists{/gist_id}", "starred_url": "https://api.github.com/users/louis2889184/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/louis2889184/subscriptions", "organizations_url": "https://api.github.com/users/louis2889184/orgs", "repos_url": "https://api.github.com/users/louis2889184/repos", "events_url": "https://api.github.com/users/louis2889184/events{/privacy}", "received_events_url": "https://api.github.com/users/louis2889184/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1840917107, "node_id": "MDU6TGFiZWwxODQwOTE3MTA3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/documentation", "name": "documentation", "color": "0075ca", "default": true, "description": "Improvements or additions to documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-13T15:52:47Z", "updated_at": "2020-08-13T21:25:57Z", "closed_at": "2020-08-13T21:25:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udcda Documentation\r\n\r\nIn `pytorch-lightning/docs/source/new-project.rst`, there is an example demonstrating how to use `Trainer`. However, `early_stop_checkpoint` is not a valid argument for `Trainer`. I also found that `early_stop_checkpoint` only appears here in the whole repo. Therefore, we might need to remove it from the doc.\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2946", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2946/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2946/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2946/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2946", "id": 678395376, "node_id": "MDU6SXNzdWU2NzgzOTUzNzY=", "number": 2946, "title": "Neptune logger with a validation epoch end conflict due to the 'epoch' key added on the fly.", "user": {"login": "morgangiraud", "id": 1278248, "node_id": "MDQ6VXNlcjEyNzgyNDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1278248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/morgangiraud", "html_url": "https://github.com/morgangiraud", "followers_url": "https://api.github.com/users/morgangiraud/followers", "following_url": "https://api.github.com/users/morgangiraud/following{/other_user}", "gists_url": "https://api.github.com/users/morgangiraud/gists{/gist_id}", "starred_url": "https://api.github.com/users/morgangiraud/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/morgangiraud/subscriptions", "organizations_url": "https://api.github.com/users/morgangiraud/orgs", "repos_url": "https://api.github.com/users/morgangiraud/repos", "events_url": "https://api.github.com/users/morgangiraud/events{/privacy}", "received_events_url": "https://api.github.com/users/morgangiraud/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-13T12:23:36Z", "updated_at": "2020-08-15T15:46:09Z", "closed_at": "2020-08-15T12:36:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi everybody! First thanks for this lib, it is very handy!\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nWhen using pytorch lightning in conjunction with the neptune logger, one can see this kind of error popping every time an epoch ends:\r\n`\r\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment SOC-114. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: e4e2635d-b707-46fa-9a1b-996dd009790f. Invalid point: InputChannelValue(timestamp=2020-08-13T11:55:38.422Z, x=5.0, numericValue=2.0, textValue=null, image', type=None) (metricId: 'e4e2635d-b707-46fa-9a1b-996dd009790f', x: 5.0) Skipping 1 values.\r\n`\r\n\r\nthe import part in this error is the following line: `X-coordinates must be strictly increasing`\r\n\r\nThis is because, in `trainer/logging.py`, the `epoch` key is added on the fly on line 69: \r\n```python\r\nscalar_metrics['epoch'] = self.current_epoch\r\n```\r\n\r\nBut why does Neptune complains?\r\n\r\nIf you log all the timesteps (using `row_log_interval = 1`), at the end of an epoch, 2 calls are emitted to the logger: One to log the training logs and one for the validation logs. \r\nBoth of those have the same `step` value which is the current training `step` value. Since the key `epoch` is duplicated in both those calls, Neptune receives the key `epoch` twice with the same `step` value leading to the exception.\r\n\r\n### To Reproduce\r\n\r\nlaunch training with:\r\n- Neptune logger\r\n- training logs\r\n- validation logs\r\n- row_log_interval=1\r\n\r\n### Expected behaviour\r\n\r\nDon't add the `epoch` key on the fly which force the logger to log it.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2943", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2943/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2943/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2943/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2943", "id": 678237753, "node_id": "MDU6SXNzdWU2NzgyMzc3NTM=", "number": 2943, "title": "Issue with pl.Trainer.from_argparse_args(...)", "user": {"login": "amitness", "id": 8587189, "node_id": "MDQ6VXNlcjg1ODcxODk=", "avatar_url": "https://avatars3.githubusercontent.com/u/8587189?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amitness", "html_url": "https://github.com/amitness", "followers_url": "https://api.github.com/users/amitness/followers", "following_url": "https://api.github.com/users/amitness/following{/other_user}", "gists_url": "https://api.github.com/users/amitness/gists{/gist_id}", "starred_url": "https://api.github.com/users/amitness/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amitness/subscriptions", "organizations_url": "https://api.github.com/users/amitness/orgs", "repos_url": "https://api.github.com/users/amitness/repos", "events_url": "https://api.github.com/users/amitness/events{/privacy}", "received_events_url": "https://api.github.com/users/amitness/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-13T08:02:34Z", "updated_at": "2020-08-14T01:44:57Z", "closed_at": "2020-08-14T01:44:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Use `parser = pl.Trainer.add_argparse_args(parser)`\r\n2. Run `python main.py --overfit_batches 1` \r\n3. The training runs over the whole dataset instead of running on a single batch\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n![Screenshot from 2020-08-13 13-45-55](https://user-images.githubusercontent.com/8587189/90109358-6ab97680-dd6b-11ea-92d9-f1d47aea8435.png)\r\n\r\n\r\n#### Code sample\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\n\r\n### Expected behavior\r\nOnly one batch should have run.\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- Tesla P100-PCIE-16GB\r\n\t- available:         True\r\n\t- version:           10.1\r\n* Packages:\r\n\t- numpy:             1.18.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0+cu101\r\n\t- pytorch-lightning: 0.8.5\r\n\t- tensorboard:       2.3.0\r\n\t- tqdm:              4.41.1\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.6.9\r\n\t- version:           #1 SMP Thu Jul 23 08:00:38 PDT 2020\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2942", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2942/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2942/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2942/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2942", "id": 678146368, "node_id": "MDU6SXNzdWU2NzgxNDYzNjg=", "number": 2942, "title": "ddp_backend in 0.9.0rc12 fails if no CUDA_VISIBLE_DEVICES found", "user": {"login": "ananthsub", "id": 2382532, "node_id": "MDQ6VXNlcjIzODI1MzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/2382532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananthsub", "html_url": "https://github.com/ananthsub", "followers_url": "https://api.github.com/users/ananthsub/followers", "following_url": "https://api.github.com/users/ananthsub/following{/other_user}", "gists_url": "https://api.github.com/users/ananthsub/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananthsub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananthsub/subscriptions", "organizations_url": "https://api.github.com/users/ananthsub/orgs", "repos_url": "https://api.github.com/users/ananthsub/repos", "events_url": "https://api.github.com/users/ananthsub/events{/privacy}", "received_events_url": "https://api.github.com/users/ananthsub/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/milestone/6", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/milestones/6/labels", "id": 5063791, "node_id": "MDk6TWlsZXN0b25lNTA2Mzc5MQ==", "number": 6, "title": "0.9.0", "description": "", "creator": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 199, "state": "closed", "created_at": "2020-02-02T14:36:28Z", "updated_at": "2020-08-20T22:13:59Z", "due_on": null, "closed_at": "2020-08-20T22:13:59Z"}, "comments": 5, "created_at": "2020-08-13T04:47:43Z", "updated_at": "2020-08-14T09:37:22Z", "closed_at": "2020-08-14T09:37:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nIn ddp_backend, training immediately fails if the environment variable CUDA_VISIBLE_DEVICES isn't set. This line should handle the None case gracefully: https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_backend.py#L90\r\n\r\n### To Reproduce\r\nStart a run using ddp on CPU. This was discovered using torchelastic to launch\r\n\r\n\r\n#### Code sample\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\n\r\n### Expected behavior\r\nThis shouldn't crash if the environment variable isn't set. We could default to `num_gpus = 0` in this case. \r\nReplacing the line above with something like this could work:\r\n\r\n`num_gpus = os.environ.get('CUDA_VISIBLE_DEVICES', []).split(',').__len__()\r\n`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2941", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2941/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2941/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2941/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2941", "id": 678052540, "node_id": "MDU6SXNzdWU2NzgwNTI1NDA=", "number": 2941, "title": "Custom Checkpoint callback for multiple models", "user": {"login": "kowshikthopalli", "id": 18579857, "node_id": "MDQ6VXNlcjE4NTc5ODU3", "avatar_url": "https://avatars0.githubusercontent.com/u/18579857?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kowshikthopalli", "html_url": "https://github.com/kowshikthopalli", "followers_url": "https://api.github.com/users/kowshikthopalli/followers", "following_url": "https://api.github.com/users/kowshikthopalli/following{/other_user}", "gists_url": "https://api.github.com/users/kowshikthopalli/gists{/gist_id}", "starred_url": "https://api.github.com/users/kowshikthopalli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kowshikthopalli/subscriptions", "organizations_url": "https://api.github.com/users/kowshikthopalli/orgs", "repos_url": "https://api.github.com/users/kowshikthopalli/repos", "events_url": "https://api.github.com/users/kowshikthopalli/events{/privacy}", "received_events_url": "https://api.github.com/users/kowshikthopalli/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-13T00:09:54Z", "updated_at": "2020-08-13T02:04:12Z", "closed_at": "2020-08-13T02:04:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n### Before asking:   \r\n1. search the issues.   \r\n2. search the docs.    \r\n\r\n<!-- If you still can't find what you need: -->\r\n\r\n#### What is your question?\r\nI am looking to write my own callback for checkpointing for a list of models I initialize in __init__(). \r\n#### Code\r\nI created 10 timeseries models and 1 image model lets say. Each model inherits Lightningmodule. \r\nSo LITFusionExp has 11 models.\r\nWhen I save the checkpoint I can only see cnn_model's checkpoint and not ts_models. \r\nHowever, I can see that trainer updates my ts_models. \r\nThe problem thus is when I reload the checkpoint all the ts_models are just randomly initialized. How to save ts_models too? \r\nThanks for the help\r\n\r\n<!-- Please paste a code snippet if your question requires it! -->  \r\n \r\n```\r\nclass LITFusionExp(LightningModule):\r\n    def __init__(self,hparams):\r\n        \r\n        super().__init__()\r\n        \r\n       \r\n        self.ts_models = [ Conv1dmultivariate(input_channels=10).cuda() for _ in range(10)]                \r\n    \r\n        self.cnn_model = LITConvAEexp(hparams)\r\ntrainer.fit(LITFusionExp())\r\ntrainer .save('mypath.ckpt')\r\n###\r\nmy_ckpt= torch.load( 'mypath.ckpt')\r\n#my_ckpt['state_dict'] has only keys with respect to CNN model\r\n```\r\n\r\n\r\n#### What's your environment?\r\n\r\n - OS:  Linux\r\n - Packaging [e.g. conda]\r\n - Version [e.g. 0.8.5]\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2940", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2940/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2940/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2940/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2940", "id": 678050873, "node_id": "MDU6SXNzdWU2NzgwNTA4NzM=", "number": 2940, "title": "2-GPU `ddp` -- hparams are static for GPU1 when training in a k-fold loop", "user": {"login": "brandenkmurray", "id": 8684326, "node_id": "MDQ6VXNlcjg2ODQzMjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/8684326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brandenkmurray", "html_url": "https://github.com/brandenkmurray", "followers_url": "https://api.github.com/users/brandenkmurray/followers", "following_url": "https://api.github.com/users/brandenkmurray/following{/other_user}", "gists_url": "https://api.github.com/users/brandenkmurray/gists{/gist_id}", "starred_url": "https://api.github.com/users/brandenkmurray/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brandenkmurray/subscriptions", "organizations_url": "https://api.github.com/users/brandenkmurray/orgs", "repos_url": "https://api.github.com/users/brandenkmurray/repos", "events_url": "https://api.github.com/users/brandenkmurray/events{/privacy}", "received_events_url": "https://api.github.com/users/brandenkmurray/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-13T00:04:52Z", "updated_at": "2020-08-14T01:51:06Z", "closed_at": "2020-08-14T01:51:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nWhen training a k-fold CV loop using 2 GPUs with `ddp`, the models on GPU0 will correctly change folds each iteration, but GPU0 is always given fold 0 i.e. the `hparams` are static.\r\n\r\n### To Reproduce\r\n\r\nColab is here (but you'll need multiple GPUs to reproduce: https://colab.research.google.com/drive/1xr_JPDhf5UmHYUfmhZSrwQDanQbKYBcD?usp=sharing\r\n\r\nI've copied the output below. During the TrainSystem __init__ I print out the fold and `hparams`. Notice that the for each iteration the first GPU gets the correct fold, but the second GPU is always using `fold=0`.\r\n\r\n```\r\nimport os\r\nimport sys\r\nimport gc\r\n\r\nimport cv2\r\nimport numpy as np\r\nimport pandas as pd\r\nimport pickle as pkl\r\nfrom argparse import ArgumentParser\r\nimport argparse\r\nfrom tqdm import tqdm\r\nfrom PIL import Image\r\nImage.MAX_IMAGE_PIXELS = 1000000000000\r\n\r\nfrom torch import nn\r\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler\r\nimport torch.nn.functional as F\r\nfrom torchvision import transforms\r\nfrom torchvision.transforms import functional as TF\r\nfrom torchvision.datasets import MNIST\r\nimport torch\r\n\r\nimport pytorch_lightning as pl\r\nfrom pytorch_lightning import Trainer\r\nfrom pytorch_lightning.callbacks import EarlyStopping\r\n#from pytorch_lightning.logging import TensorBoardLogger, TestTubeLogger\r\nfrom pytorch_lightning.loggers import  TestTubeLogger, TensorBoardLogger\r\nfrom efficientnet_pytorch import EfficientNet\r\n\r\nIMG_HEIGHT = 300\r\nIMG_WIDTH = 300\r\n\r\ndef parse_args(args):\r\n\r\n    parser = argparse.ArgumentParser()\r\n\r\n    parser.add_argument(\"--backbone\",\r\n                        help=\"Backbone to use\",\r\n                        type=str,\r\n                        default=\"efficientnet-b4\")\r\n    parser.add_argument(\"--backbone_weights\",\r\n                        type=str,\r\n                        default=\"imagenet\")\r\n    parser.add_argument(\"--batch_size\",\r\n                        help=\"Batch size\",\r\n                        type=int,\r\n                        default=12)\r\n    parser.add_argument(\"--acc_grad\",\r\n                        help=\"Accumulate gradient for acc_grad epochs\",\r\n                        type=int,\r\n                        default=4)\r\n    parser.add_argument(\"--gpus\",\r\n                        help=\"GPUs to use. Either an int or comma-separated list e.g. '0,1,2'\",\r\n                        type=int,\r\n                        default=1)\r\n    parser.add_argument(\"--num_workers\",\r\n                        help=\"Number of workers to use in DataLoader.\",\r\n                        type=int,\r\n                        default=8)    \r\n\r\n    args = parser.parse_args(args)\r\n    return(args)\r\n\r\n\r\ndef accuracy(output, target, topk=(1,)):\r\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\r\n    with torch.no_grad():\r\n        maxk = max(topk)\r\n        batch_size = target.size(0)\r\n\r\n        _, pred = output.topk(maxk, 1, True, True)\r\n        pred = pred.t()\r\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\r\n\r\n        res = []\r\n        for k in topk:\r\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\r\n            res.append(correct_k.mul_(100.0 / batch_size))\r\n        return res\r\n\r\n\r\nclass TrainSystem(pl.LightningModule):\r\n\r\n    def __init__(self, hparams, test_data=None):\r\n        super(TrainSystem, self).__init__()\r\n\r\n        self.hparams = hparams\r\n        print(f'Fold: {self.hparams.fold}')\r\n        print(self.hparams)\r\n        self.model = EfficientNet.from_pretrained(self.hparams.backbone, advprop=False, num_classes=self.hparams.n_classes)\r\n        self.model = self.model.float()\r\n\r\n    def forward(self, x):\r\n        out = self.model(x)\r\n        return out\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        out = self.forward(x)\r\n        if isinstance(out, dict):\r\n            out = out['out']\r\n        celoss = nn.CrossEntropyLoss()\r\n        loss = celoss(out, y)\r\n        tensorboard_logs = {'train_loss': loss}\r\n        return {'loss': loss, 'log': tensorboard_logs}\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        out = self.forward(x)\r\n        if isinstance(out, dict):\r\n            out = out['out']\r\n        celoss = nn.CrossEntropyLoss()\r\n        loss = celoss(out, y)\r\n        out_max = torch.argmax(out, dim=1)\r\n#         if batch_idx % 10 == 0:\r\n#             print('out: ', out)\r\n#             print(\"out_max: \", out_max)\r\n#             print(\"y: \", y)\r\n        acc = accuracy(out, y)[0]\r\n        return {'val_loss': loss,\r\n               'val_acc': acc}\r\n\r\n    def validation_end(self, outputs):\r\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\r\n        print(avg_acc)\r\n        tensorboard_logs = {'val_loss': avg_loss,\r\n                           'val_acc': avg_acc}\r\n        return {'avg_val_loss': avg_loss, \r\n                'avg_val_acc': avg_acc,\r\n                'log': tensorboard_logs}\r\n            \r\n    def test_step(self, batch, batch_idx):\r\n        # OPTIONAL\r\n        x, y = batch\r\n        out = self.forward(x)\r\n        if isinstance(out, dict):\r\n            out = out['out']\r\n        celoss = nn.CrossEntropyLoss()\r\n        loss = celoss(out, y)\r\n        out_max = torch.argmax(out, dim=1)\r\n#         if batch_idx % 10 == 0:\r\n#             print('out: ', out)\r\n#             print(\"out_max: \", out_max)\r\n#             print(\"y: \", y)\r\n        acc = accuracy(out, y)[0]\r\n        return {'test_loss': loss,\r\n               'test_acc': acc}\r\n\r\n    def test_end(self, outputs):\r\n        # OPTIONAL\r\n        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\r\n        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\r\n        print(avg_acc)\r\n        tensorboard_logs = {'test_loss': avg_loss,\r\n                           'test_acc': avg_acc}\r\n        return {'avg_test_loss': avg_loss, \r\n                'avg_test_acc': avg_acc,\r\n                'log': tensorboard_logs}\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\r\n\r\n    def train_dataloader(self):\r\n        # REQUIRED\r\n        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.Compose([transforms.Resize((IMG_WIDTH, IMG_HEIGHT)), transforms.Grayscale(3), transforms.ToTensor()])), batch_size=self.hparams.batch_size, num_workers=self.hparams.num_workers, shuffle=True, pin_memory=True, drop_last=True)\r\n\r\n    def val_dataloader(self):\r\n        # OPTIONAL\r\n        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.Compose([transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),transforms.Grayscale(3), transforms.ToTensor()])), batch_size=self.hparams.batch_size, num_workers=self.hparams.num_workers, shuffle=False, pin_memory=True, drop_last=True)\r\n\r\n    def test_dataloader(self):\r\n        # OPTIONAL\r\n        return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.Compose([transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),transforms.Grayscale(3), transforms.ToTensor()])), batch_size=self.hparams.batch_size, num_workers=self.hparams.num_workers, shuffle=False, pin_memory=True, drop_last=False)\r\n\r\n\r\n\r\nargs = ['--backbone', 'efficientnet-b0','--batch_size','24','--acc_grad','1','--gpus','2']\r\nargs = parse_args(args)\r\nprint(args)\r\n    \r\nout_dir = f\"./saved/chk/classifier_{args.backbone}\"\r\nfor fold in range(5):\r\n  hparams = argparse.Namespace(**{'fold': fold, \r\n                                  'backbone': args.backbone,\r\n                                      'encoder_weights': args.backbone_weights,\r\n                                      'lr': 0.0001,\r\n                                      'resize': (IMG_WIDTH, IMG_HEIGHT),\r\n                                      'n_classes': 10,\r\n                                      'batch_size': args.batch_size,\r\n                                      'num_workers': args.num_workers})\r\n\r\n  logger = TestTubeLogger(\r\n                          save_dir=out_dir,\r\n                          name='lightning_logs'\r\n                      )\r\n\r\n\r\n  trainer = Trainer(logger=logger,\r\n                            #default_save_path=out_dir,\r\n                            accumulate_grad_batches=args.acc_grad,\r\n                            #early_stop_callback=early_stop_callback,\r\n                            #use_amp=False,\r\n                            #amp_level=32,\r\n                            gpus=args.gpus,\r\n                            max_steps=20,\r\n                            max_epochs=1,\r\n                            distributed_backend='ddp') \r\n\r\n  model = TrainSystem(hparams)\r\n\r\n  trainer.fit(model)\r\n        \r\n```\r\n\r\n```\r\nNamespace(acc_grad=1, backbone='efficientnet-b0', backbone_weights='imagenet', batch_size=24, gpus=2, num_workers=8)\r\nGPU available: True, used: True\r\nTPU available: False, using: 0 TPU cores\r\nCUDA_VISIBLE_DEVICES: [0,1]\r\nFold: 0\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            0\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\nNamespace(acc_grad=1, backbone='efficientnet-b0', backbone_weights='imagenet', batch_size=24, gpus=2, num_workers=8)\r\nFold: 0\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            0\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 2 processes\r\n----------------------------------------------------------------------------------------------------\r\n\r\n  | Name  | Type         | Params\r\n---------------------------------------\r\n0 | model | EfficientNet | 4 M   \r\nValidation sanity check: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1.0 [00:01<00:00,  1.03s/it]tensor(12.5000, device='cuda:0')\r\ntensor(8.3333, device='cuda:1')                                                                                                                               \r\nEpoch 1:   1%|\u258b                                                                                        | 20/2500 [00:09<20:02,  2.06it/s, loss=2.097, v_num=8]\r\nGPU available: True, used: True\r\nTPU available: False, using: 0 TPU cores\r\nUsing environment variable NODE_RANK for node rank (0).\r\nCUDA_VISIBLE_DEVICES: [0,1]\r\nFold: 1\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            1\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\n\r\nFold: 0\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            0\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 2 processes\r\n----------------------------------------------------------------------------------------------------\r\n\r\n  | Name  | Type         | Params\r\n---------------------------------------\r\n0 | model | EfficientNet | 4 M   \r\nValidation sanity check: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1.0 [00:00<00:00,  1.68it/s]tensor(8.3333, device='cuda:0')\r\ntensor(4.1667, device='cuda:1')                                                                                                                               \r\nEpoch 1:   1%|\u258b                                                                                        | 20/2500 [00:09<20:11,  2.05it/s, loss=2.137, v_num=9]\r\nGPU available: True, used: True\r\nTPU available: False, using: 0 TPU cores\r\nUsing environment variable NODE_RANK for node rank (0).\r\nCUDA_VISIBLE_DEVICES: [0,1]\r\nFold: 2\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            2\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\n\r\nNamespace(acc_grad=1, backbone='efficientnet-b0', backbone_weights='imagenet', batch_size=24, gpus=2, num_workers=8)\r\nFold: 0\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            0\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 2 processes\r\n----------------------------------------------------------------------------------------------------\r\n\r\n  | Name  | Type         | Params\r\n---------------------------------------\r\n0 | model | EfficientNet | 4 M   \r\nValidation sanity check: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1.0 [00:00<00:00,  1.66it/s]tensor(0., device='cuda:0')\r\ntensor(4.1667, device='cuda:1')                                                                                                                               \r\nEpoch 1:   1%|\u258b                                                                                       | 20/2500 [00:09<20:02,  2.06it/s, loss=2.129, v_num=10]\r\nGPU available: True, used: True\r\nTPU available: False, using: 0 TPU cores\r\nUsing environment variable NODE_RANK for node rank (0).\r\nCUDA_VISIBLE_DEVICES: [0,1]\r\nFold: 3\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            3\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\n\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\r\nNamespace(acc_grad=1, backbone='efficientnet-b0', backbone_weights='imagenet', batch_size=24, gpus=2, num_workers=8)\r\nFold: 0\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            0\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 2 processes\r\n----------------------------------------------------------------------------------------------------\r\n\r\n  | Name  | Type         | Params\r\n---------------------------------------\r\n0 | model | EfficientNet | 4 M   \r\nValidation sanity check: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1.0 [00:00<00:00,  1.99it/s]tensor(8.3333, device='cuda:0')\r\ntensor(8.3333, device='cuda:1')                                                                                                                               \r\nEpoch 1:   1%|\u258b                                                                                       | 20/2500 [00:09<19:46,  2.09it/s, loss=2.139, v_num=11]\r\nGPU available: True, used: True\r\nTPU available: False, using: 0 TPU cores\r\nUsing environment variable NODE_RANK for node rank (0).\r\nCUDA_VISIBLE_DEVICES: [0,1]\r\nFold: 4\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            4\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\n\r\nNamespace(acc_grad=1, backbone='efficientnet-b0', backbone_weights='imagenet', batch_size=24, gpus=2, num_workers=8)\r\nFold: 0\r\n\"backbone\":        efficientnet-b0\r\n\"batch_size\":      24\r\n\"encoder_weights\": imagenet\r\n\"fold\":            0\r\n\"lr\":              0.0001\r\n\"n_classes\":       10\r\n\"num_workers\":     8\r\n\"resize\":          (300, 300)\r\nLoaded pretrained weights for efficientnet-b0\r\ninitializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\r\ninitializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\r\n----------------------------------------------------------------------------------------------------\r\ndistributed_backend=ddp\r\nAll DDP processes registered. Starting ddp with 2 processes\r\n----------------------------------------------------------------------------------------------------\r\n\r\n  | Name  | Type         | Params\r\n---------------------------------------\r\n0 | model | EfficientNet | 4 M   \r\nValidation sanity check: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1.0 [00:00<00:00,  1.45it/s]tensor(8.3333, device='cuda:0')\r\ntensor(12.5000, device='cuda:1')                                                                                                                              \r\nEpoch 1:   1%|\u258b                                                                                       | 20/2500 [00:09<20:02,  2.06it/s, loss=2.145, v_num=12]\r\n```\r\n\r\n### Expected behavior\r\n\r\nI expect both GPUs to get the same fold.\r\n\r\n### Environment\r\n\r\n - PyTorch Version (e.g., 1.0): 1.4\r\n - OS (e.g., Linux): Ubuntu 18.04\r\n - How you installed PyTorch (`conda`, `pip`, source): `conda`\r\n - Build command you used (if compiling from source):\r\n - Python version: 3.7.6\r\n - CUDA/cuDNN version: 11.0\r\n - GPU models and configuration: 2x1080ti\r\n - Any other relevant information: pytorch-lightning 0.9.0rc12\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2939", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2939/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2939/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2939/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2939", "id": 678028105, "node_id": "MDU6SXNzdWU2NzgwMjgxMDU=", "number": 2939, "title": "mlflow checkpoints in the wrong location ", "user": {"login": "david-waterworth", "id": 5028974, "node_id": "MDQ6VXNlcjUwMjg5NzQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/5028974?v=4", "gravatar_id": "", "url": "https://api.github.com/users/david-waterworth", "html_url": "https://github.com/david-waterworth", "followers_url": "https://api.github.com/users/david-waterworth/followers", "following_url": "https://api.github.com/users/david-waterworth/following{/other_user}", "gists_url": "https://api.github.com/users/david-waterworth/gists{/gist_id}", "starred_url": "https://api.github.com/users/david-waterworth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/david-waterworth/subscriptions", "organizations_url": "https://api.github.com/users/david-waterworth/orgs", "repos_url": "https://api.github.com/users/david-waterworth/repos", "events_url": "https://api.github.com/users/david-waterworth/events{/privacy}", "received_events_url": "https://api.github.com/users/david-waterworth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-12T22:58:48Z", "updated_at": "2020-08-15T10:54:07Z", "closed_at": "2020-08-15T10:54:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm not sure if I'm doing something wrong, I'm using mlflow instead of tensorboard as a logger. I've used the defaults i.e.\r\n\r\n```\r\nmlflow = loggers.MLFlowLogger()\r\ntrainer = pl.Trainer.from_argparse_args(args, logger=mlflow)\r\n```\r\n\r\nI'm ending up with the following folder structure\r\n\r\n\\mlflow\r\n\\mlflow\\1\r\n\\mlflow\\1\\\\{guid}\\artifacts\r\n\\mlflow\\1\\\\{guid}\\metrics\r\n\\mlflow\\1\\\\{guid}\\params\r\n\\mlflow\\1\\\\{guid}\\meta.yaml\r\n**\\1\\\\{guid}\\checkpoints**\r\n\r\ni.e. the checkpoints are in the wrong location, they should be in the `\\mlflow` folder. \r\n\r\nPerhaps this is an mlflow rather than pytorch-lightning issue? \r\n\r\nI'm using pytorch-lightning 0.8.5 on macos running in python 3.7.6\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2938", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2938/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2938/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2938/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2938", "id": 678025848, "node_id": "MDU6SXNzdWU2NzgwMjU4NDg=", "number": 2938, "title": "EOFError exception raised when using max_steps in distributed training", "user": {"login": "bryant1410", "id": 3905501, "node_id": "MDQ6VXNlcjM5MDU1MDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/3905501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bryant1410", "html_url": "https://github.com/bryant1410", "followers_url": "https://api.github.com/users/bryant1410/followers", "following_url": "https://api.github.com/users/bryant1410/following{/other_user}", "gists_url": "https://api.github.com/users/bryant1410/gists{/gist_id}", "starred_url": "https://api.github.com/users/bryant1410/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bryant1410/subscriptions", "organizations_url": "https://api.github.com/users/bryant1410/orgs", "repos_url": "https://api.github.com/users/bryant1410/repos", "events_url": "https://api.github.com/users/bryant1410/events{/privacy}", "received_events_url": "https://api.github.com/users/bryant1410/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-12T22:52:31Z", "updated_at": "2020-08-15T12:25:39Z", "closed_at": "2020-08-15T12:25:39Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nWhen using `max_steps` to stop a distributed training (`ddp`) in the middle of an epoch, the following exception is raised:\r\n\r\n```\r\nEpoch 1364:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588              | 7/11 [00:11<00:06,  1.62s/it, loss=2.057, v_num=13, lr=2.47e-11]\r\nException in thread Thread-4:\r\nTraceback (most recent call last):\r\n  File \"***/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n    self.run()\r\n  File \"***/lib/python3.8/threading.py\", line 870, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"***/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\r\n    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\r\n  File \"***/lib/python3.8/multiprocessing/queues.py\", line 116, in get\r\n    return _ForkingPickler.loads(res)\r\n  File \"***/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\r\n    fd = df.detach()\r\n  File \"***/lib/python3.8/multiprocessing/resource_sharer.py\", line 57, in detach\r\n    with _resource_sharer.get_connection(self._id) as conn:\r\n  File \"***/lib/python3.8/multiprocessing/resource_sharer.py\", line 87, in get_connection\r\n    c = Client(address, authkey=process.current_process().authkey)\r\n  File \"***/lib/python3.8/multiprocessing/connection.py\", line 508, in Client\r\n    answer_challenge(c, authkey)\r\n  File \"***/lib/python3.8/multiprocessing/connection.py\", line 752, in answer_challenge\r\n    message = connection.recv_bytes(256)         # reject large message\r\n  File \"***/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\r\n    buf = self._recv_bytes(maxlength)\r\n  File \"***/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\r\n    buf = self._recv(4)\r\n  File \"***/lib/python3.8/multiprocessing/connection.py\", line 383, in _recv\r\n    raise EOFError\r\nEOFError\r\n```\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Train some model in distributed mode (`ddp`) such that `num_steps` is defined in the trainer, and it stops training in the middle of an epoch.\r\n\r\n### Expected behavior\r\n\r\nThe training should end without any error.\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- Tesla V100-SXM2-16GB\r\n\t\t- Tesla V100-SXM2-16GB\r\n\t\t- Tesla V100-SXM2-16GB\r\n\t\t- Tesla V100-SXM2-16GB\r\n\t\t- Tesla V100-SXM2-16GB\r\n\t\t- Tesla V100-SXM2-16GB\r\n\t\t- Tesla V100-SXM2-16GB\r\n\t\t- Tesla V100-SXM2-16GB\r\n\t- available:         True\r\n\t- version:           10.1\r\n* Packages:\r\n\t- numpy:             1.18.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0\r\n\t- pytorch-lightning: 0.9.0rc12\r\n\t- tensorboard:       2.3.0\r\n\t- tqdm:              4.47.0\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- ELF\r\n\t- processor:         x86_64\r\n\t- python:            3.8.5\r\n\t- version:           #25~18.04.1-Ubuntu SMP Fri Jun 5 15:18:30 UTC 2020\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2936", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2936/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2936/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2936/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2936", "id": 677897112, "node_id": "MDU6SXNzdWU2Nzc4OTcxMTI=", "number": 2936, "title": "Trainer \"optimizers\" attribute is None when saving checkpoint and callbacks list is not empty", "user": {"login": "import-antigravity", "id": 24441495, "node_id": "MDQ6VXNlcjI0NDQxNDk1", "avatar_url": "https://avatars2.githubusercontent.com/u/24441495?v=4", "gravatar_id": "", "url": "https://api.github.com/users/import-antigravity", "html_url": "https://github.com/import-antigravity", "followers_url": "https://api.github.com/users/import-antigravity/followers", "following_url": "https://api.github.com/users/import-antigravity/following{/other_user}", "gists_url": "https://api.github.com/users/import-antigravity/gists{/gist_id}", "starred_url": "https://api.github.com/users/import-antigravity/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/import-antigravity/subscriptions", "organizations_url": "https://api.github.com/users/import-antigravity/orgs", "repos_url": "https://api.github.com/users/import-antigravity/repos", "events_url": "https://api.github.com/users/import-antigravity/events{/privacy}", "received_events_url": "https://api.github.com/users/import-antigravity/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-08-12T18:38:40Z", "updated_at": "2020-08-15T11:47:43Z", "closed_at": "2020-08-15T11:47:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI'm training a GAN and I'm running a few custom callbacks as well. When the model attempts to save at the end of the first epoch, it crashes. Here's the very strange thing: I have the exact same code in a Jupyter notebook and the error doesn't occur.\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nThe bug does not occur when the `callbacks` list passed into the trainer is empty. None of the callbacks I'm using have anything to do with saving checkpoints, they're all for logging certain things about the model. Enabling any one of them causes the error. Running the exact same code in Jupyter results in no crashes.\r\n\r\nStack trace:\r\n\r\n```\r\nTraceback (most recent call last):\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588-| 98.33% [590/600 00:05<00:00 loss: -0.558, v_num: 1, d_loss: -1.120, g_loss: -0.016]\r\n  File \"mnist-dense-gan-convergence.py\", line 55, in <module>\r\n    main(args)\r\n  File \"mnist-dense-gan-convergence.py\", line 45, in main\r\n    trainer.fit(gan)\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1044, in fit\r\n    results = self.run_pretrain_routine(model)\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1213, in run_pretrain_routine\r\n    self.train()\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 370, in train\r\n    self.run_training_epoch()\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 502, in run_training_epoch\r\n    self.check_checkpoint_callback(should_check_val)\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 513, in check_checkpoint_callback\r\n    [c.on_validation_end(self, self.get_model()) for c in checkpoint_callbacks]\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 513, in <listcomp>\r\n    [c.on_validation_end(self, self.get_model()) for c in checkpoint_callbacks]\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py\", line 12, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 309, in on_validation_end\r\n    self._do_check_save(filepath, current, epoch)\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 346, in _do_check_save\r\n    self._save_model(filepath)\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 168, in _save_model\r\n    self.save_function(filepath, self.save_weights_only)\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_io.py\", line 268, in save_checkpoint\r\n    checkpoint = self.dump_checkpoint(weights_only)\r\n  File \"/Users/robbie/.conda/envs/ganresearch/lib/python3.7/site-packages/pytorch_lightning/trainer/training_io.py\", line 350, in dump_checkpoint\r\n    for i, optimizer in enumerate(self.optimizers):\r\nTypeError: 'NoneType' object is not iterable\r\n```\r\n\r\n\r\n#### Code sample\r\n\r\nHere is the relevant part of my setup code:\r\n\r\n```python\r\ninception_callback = GANInceptionScorer(classifier, logits=True, sample_size=1000, input_shape=(-1, 1, 28, 28))\r\n\r\nlog_dir = os.path.abspath('../logs/mnist-dense-gan-convergence')\r\n\r\nparams = ParameterMatrixCallback()\r\n\r\ncallbacks = [\r\n    GANProgressBar(),\r\n    GANTensorboardImageView(),\r\n    params,\r\n    inception_callback\r\n]\r\n\r\ntrainer_args = {\r\n        'max_epochs': 100,\r\n        'default_root_dir': log_dir,\r\n        'callbacks': callbacks,\r\n        'progress_bar_refresh_rate': 0\r\n    }\r\n\r\n    print(log_dir)\r\n    try:\r\n        trainer = Trainer(gpus=1, **trainer_args)\r\n    except MisconfigurationException:\r\n        trainer = Trainer(**trainer_args)\r\n\r\n    trainer.fit(gan)\r\n```\r\n\r\n### Expected behavior\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n### Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py\r\n# For security purposes, please check the contents of collect_env_details.py before running it.\r\npython collect_env_details.py\r\n```\r\n\r\nand the same code in Jupyter:\r\n```python\r\ninception_callback = GANInceptionScorer(classifier, logits=True, sample_size=1000, input_shape=(-1, 1, 28, 28))\r\n\r\nlog_dir = os.path.abspath('../logs/mnist-gan-dense')\r\n\r\nparams = ParameterMatrixCallback()\r\n\r\ntrainer_args = {\r\n    'max_epochs': 200, \r\n    'callbacks': [GANProgressBar(), GANTensorboardImageView(n=4), params, inception_callback],\r\n    'progress_bar_refresh_rate': 0, \r\n    'default_root_dir': log_dir\r\n}\r\n\r\nt = Trainer(**trainer_args)\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0): 1.3.1\r\n - OS (e.g., Linux): macOS\r\n - How you installed PyTorch (`conda`, `pip`, source): conda\r\n - Python version: 3.7\r\n - Any other relevant information: pytorch-lightning 0.8.5", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2935", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2935/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2935/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2935/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2935", "id": 677895737, "node_id": "MDU6SXNzdWU2Nzc4OTU3Mzc=", "number": 2935, "title": "Option to run dataloader on single process for distributed training", "user": {"login": "davidkartchner", "id": 10689167, "node_id": "MDQ6VXNlcjEwNjg5MTY3", "avatar_url": "https://avatars2.githubusercontent.com/u/10689167?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidkartchner", "html_url": "https://github.com/davidkartchner", "followers_url": "https://api.github.com/users/davidkartchner/followers", "following_url": "https://api.github.com/users/davidkartchner/following{/other_user}", "gists_url": "https://api.github.com/users/davidkartchner/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidkartchner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidkartchner/subscriptions", "organizations_url": "https://api.github.com/users/davidkartchner/orgs", "repos_url": "https://api.github.com/users/davidkartchner/repos", "events_url": "https://api.github.com/users/davidkartchner/events{/privacy}", "received_events_url": "https://api.github.com/users/davidkartchner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-12T18:36:08Z", "updated_at": "2020-08-18T13:56:20Z", "closed_at": "2020-08-18T13:56:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "#### What is your question?\r\nIs there a way to run dataloading on a single process for DDP distributed training?  As is, pytorch-lightning creates a different dataloader on each process.  While this is fine with a normal dataloader that uses a distributed sampler, I am using an `IterableDataset` and my batches are duplicated on every GPU, rendering multi-GPU training useless.  I would like to be able to sequentially submit batches to each GPU so that they can all simply use batches from the same IterableDataset.  Documentation from [DistributedDataParallel](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html) indicates that this is supported behavior\r\n\r\n\r\n#### What have you tried?\r\nI have tried all of the different data utilities offered in pytorch-lightning, including the new LightningDataModule in the latest release.  All of them seem to duplicate the dataloader on each GPU, leading to duplicate batches.\r\n\r\n#### What's your environment?\r\n\r\n - OS: Linux\r\n - Packaging: pip\r\n - Version: 0.9.0rc2\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2934", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2934/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2934/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2934/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2934", "id": 677797032, "node_id": "MDU6SXNzdWU2Nzc3OTcwMzI=", "number": 2934, "title": "warm up LR causes crash", "user": {"login": "johngrabner", "id": 8209285, "node_id": "MDQ6VXNlcjgyMDkyODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8209285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/johngrabner", "html_url": "https://github.com/johngrabner", "followers_url": "https://api.github.com/users/johngrabner/followers", "following_url": "https://api.github.com/users/johngrabner/following{/other_user}", "gists_url": "https://api.github.com/users/johngrabner/gists{/gist_id}", "starred_url": "https://api.github.com/users/johngrabner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/johngrabner/subscriptions", "organizations_url": "https://api.github.com/users/johngrabner/orgs", "repos_url": "https://api.github.com/users/johngrabner/repos", "events_url": "https://api.github.com/users/johngrabner/events{/privacy}", "received_events_url": "https://api.github.com/users/johngrabner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-08-12T15:46:14Z", "updated_at": "2020-08-15T17:08:52Z", "closed_at": "2020-08-15T12:05:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "My resnet encoder and transformer decoder are not training well.  So trying all kinds of stuff.\r\nLatest attempt to improve is to use a warmup learning rate as described here: \r\n[https://github.com/PyTorchLightning/pytorch-lightning/blob/master/docs/source/optimizers.rst](url)\r\n\r\nMy code is an exact copy:\r\n```\r\n    def optimizer_step(self, epoch_nb, batch_nb, optimizer, optimizer_i, opt_closure):\r\n        if self.trainer.global_step < 500:\r\n            lr_scale = min(1., float(self.trainer.global_step + 1) / 500.)\r\n            for pg in optimizer.param_groups:\r\n                pg['lr'] = lr_scale * self.hparams.learning_rate\r\n\r\n                print(f\"lr={pg['lr']}\")\r\n        optimizer.step()\r\n        optimizer.zero_grad()\r\n```\r\n\r\nThe crash is as follows:\r\n```\r\nEpoch 1:   0%|\u258d                                                                                                                     | 15/3544 [00:27<1:48:33,  1.85s/it, loss=nan, v_num=19]Traceback (most recent call last):\r\n  File \"kiss_transformer.py\", line 539, in <module>\r\n    trainer.fit(model, train_loader)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/states.py\", line 34, in wrapped_fn\r\n    result = fn(self, *args, **kwargs)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in fit\r\n    self.accelerator_backend.train(model, nprocs=self.num_processes)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_spawn_backend.py\", line 42, in train\r\n    mp.spawn(self.ddp_train, nprocs=nprocs, args=(self.mp_queue, model,))\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 200, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 158, in start_processes\r\n    while not context.join():\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\r\n    raise Exception(msg)\r\nException: \r\n\r\n-- Process 0 terminated with the following error:\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\r\n    fn(i, *args)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_spawn_backend.py\", line 154, in ddp_train\r\n    results = self.trainer.run_pretrain_routine(model)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1211, in run_pretrain_routine\r\n    self.train()\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 393, in train\r\n    self.run_training_epoch()\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 490, in run_training_epoch\r\n    batch_output = self.run_training_batch(batch, batch_idx)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 887, in run_training_batch\r\n    grad_norm_dic = self.run_batch_backward_pass(split_batch, batch_idx, opt_idx, optimizer)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 948, in run_batch_backward_pass\r\n    self.call_optimizer_step(optimizer, opt_idx, batch_idx, split_batch)\r\n  File \"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\", line 986, in call_optimizer_step\r\n    using_native_amp=native_amp)\r\nTypeError: optimizer_step() got an unexpected keyword argument 'using_native_amp'\r\n\r\n```\r\n\r\nI have tried both these versions and same crash:\r\n```\r\n#RUN pip install pytorch-lightning==0.8.5\r\nRUN pip install pytorch-lightning==0.9.0rc12\r\n```\r\n\r\nNot that I believe these things are related, but my code has the following:\r\n```\r\n        trainer = pl.Trainer(gpus=[0, 1],  accumulate_grad_batches=16, callbacks=[lr_logger]) #  \r\n        trainer.fit(model, train_loader)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2928", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2928/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2928/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2928/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2928", "id": 677492013, "node_id": "MDU6SXNzdWU2Nzc0OTIwMTM=", "number": 2928, "title": "is limit_train_batches shuffle or random", "user": {"login": "qmpzzpmq", "id": 21037898, "node_id": "MDQ6VXNlcjIxMDM3ODk4", "avatar_url": "https://avatars1.githubusercontent.com/u/21037898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qmpzzpmq", "html_url": "https://github.com/qmpzzpmq", "followers_url": "https://api.github.com/users/qmpzzpmq/followers", "following_url": "https://api.github.com/users/qmpzzpmq/following{/other_user}", "gists_url": "https://api.github.com/users/qmpzzpmq/gists{/gist_id}", "starred_url": "https://api.github.com/users/qmpzzpmq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qmpzzpmq/subscriptions", "organizations_url": "https://api.github.com/users/qmpzzpmq/orgs", "repos_url": "https://api.github.com/users/qmpzzpmq/repos", "events_url": "https://api.github.com/users/qmpzzpmq/events{/privacy}", "received_events_url": "https://api.github.com/users/qmpzzpmq/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-12T08:13:07Z", "updated_at": "2020-08-13T10:30:14Z", "closed_at": "2020-08-13T10:30:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "hi, I am using limit_train_batches . If it is set, is it means a subdataset of whole train dataset ? similar with torch.utils.data.random_split", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2924", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2924/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2924/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2924/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2924", "id": 677363160, "node_id": "MDU6SXNzdWU2NzczNjMxNjA=", "number": 2924, "title": "Smaller last batch skews Train/EvalResult", "user": {"login": "huyvnphan", "id": 13726207, "node_id": "MDQ6VXNlcjEzNzI2MjA3", "avatar_url": "https://avatars3.githubusercontent.com/u/13726207?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huyvnphan", "html_url": "https://github.com/huyvnphan", "followers_url": "https://api.github.com/users/huyvnphan/followers", "following_url": "https://api.github.com/users/huyvnphan/following{/other_user}", "gists_url": "https://api.github.com/users/huyvnphan/gists{/gist_id}", "starred_url": "https://api.github.com/users/huyvnphan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huyvnphan/subscriptions", "organizations_url": "https://api.github.com/users/huyvnphan/orgs", "repos_url": "https://api.github.com/users/huyvnphan/repos", "events_url": "https://api.github.com/users/huyvnphan/events{/privacy}", "received_events_url": "https://api.github.com/users/huyvnphan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-12T03:57:39Z", "updated_at": "2020-08-12T12:02:01Z", "closed_at": "2020-08-12T12:02:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\nSupported weighted average for Result\r\n### Motivation\r\nThe last batch of dataloader is usually smaller than a regular batch. Hence simply average the statistic of all batches will skew the epoch statistic.\r\n_For example_    \r\n```\r\nresult.log('accuracy', 0.7) # batch size 256\r\nresult.log('accuracy', 0.8) # batch size 256\r\nresult.log('accuracy', 0.9) # batch size 10 (last batch)\r\n```\r\nWrong epoch accuracy =` (0.7 + 0.8 + 0.9) / 3`\r\nCorrect epoch accuracy = `(256 * 0.7 + 256 * 0.8 + 10 * 0.9) / ( 256 + 256 + 10)`\r\n\r\n### Pitch\r\n\r\nSupport input for weight, or batch size in Result\r\n`result.log('accuracy', 0.7, batch_size) \r\n`\r\n### Alternatives\r\n\r\nI don't see any alternatives other than switch back the the old way of using training/validation_epoch_end and do the weighted average manually there.\r\n### Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2923", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2923/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2923/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2923/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2923", "id": 677306925, "node_id": "MDU6SXNzdWU2NzczMDY5MjU=", "number": 2923, "title": "Documentation ", "user": {"login": "johngrabner", "id": 8209285, "node_id": "MDQ6VXNlcjgyMDkyODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/8209285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/johngrabner", "html_url": "https://github.com/johngrabner", "followers_url": "https://api.github.com/users/johngrabner/followers", "following_url": "https://api.github.com/users/johngrabner/following{/other_user}", "gists_url": "https://api.github.com/users/johngrabner/gists{/gist_id}", "starred_url": "https://api.github.com/users/johngrabner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/johngrabner/subscriptions", "organizations_url": "https://api.github.com/users/johngrabner/orgs", "repos_url": "https://api.github.com/users/johngrabner/repos", "events_url": "https://api.github.com/users/johngrabner/events{/privacy}", "received_events_url": "https://api.github.com/users/johngrabner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-12T01:26:54Z", "updated_at": "2020-08-14T01:07:20Z", "closed_at": "2020-08-14T00:19:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Documentation at [https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.callbacks.lr_logger.html](url)\r\nsays:\r\n```\r\n>>> from pytorch_lightning import Trainer\r\n>>> from pytorch_lightning.callbacks import LearningRateLogger\r\n>>> lr_logger = LearningRateLogger(logging_interval='step')\r\n>>> trainer = Trainer(callbacks=[lr_logger])\r\n```\r\nThe above results in error\r\nTraceback (most recent call last):\r\n```\r\n  File \"kiss_transformer.py\", line 523, in <module>\r\n    lr_logger = LearningRateLogger(logging_interval='step')\r\nTypeError: __init__() got an unexpected keyword argument 'logging_interval'\r\n```\r\n\r\nWhen I drop logging_interval='step'\r\n\r\nIt logs on tensorboard step 0, but I would like all steps, the same as in [logging_interval='step'](URL) example from RedEyed.\r\n\r\n```\r\ndef configure_optimizers(self):\r\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\r\n\r\n        def lr_foo(epoch):\r\n            if epoch < self.hparams.warm_up_step:\r\n                # warm up lr\r\n                lr_scale = 0.1 ** (self.hparams.warm_up_step - epoch)\r\n            else:\r\n                lr_scale = 0.95 ** epoch\r\n\r\n            return lr_scale\r\n\r\n        scheduler = torch.optim.lr_scheduler.LambdaLR(\r\n            optimizer,\r\n            lr_lambda=lr_foo\r\n        )\r\n\r\n        return [optimizer], [scheduler]\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2916", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2916/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2916/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2916/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2916", "id": 676983581, "node_id": "MDU6SXNzdWU2NzY5ODM1ODE=", "number": 2916, "title": "ModelCheckpoint with custom filepath don't support training on multiple nodes", "user": {"login": "angshine", "id": 23130908, "node_id": "MDQ6VXNlcjIzMTMwOTA4", "avatar_url": "https://avatars3.githubusercontent.com/u/23130908?v=4", "gravatar_id": "", "url": "https://api.github.com/users/angshine", "html_url": "https://github.com/angshine", "followers_url": "https://api.github.com/users/angshine/followers", "following_url": "https://api.github.com/users/angshine/following{/other_user}", "gists_url": "https://api.github.com/users/angshine/gists{/gist_id}", "starred_url": "https://api.github.com/users/angshine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/angshine/subscriptions", "organizations_url": "https://api.github.com/users/angshine/orgs", "repos_url": "https://api.github.com/users/angshine/repos", "events_url": "https://api.github.com/users/angshine/events{/privacy}", "received_events_url": "https://api.github.com/users/angshine/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-11T15:41:05Z", "updated_at": "2020-08-12T10:31:18Z", "closed_at": "2020-08-12T10:31:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nWhen training on multiple nodes using `ModelCheckpoint` with custom `filepath`, it will raise `FileExistsError` caused by the following line of code: [model_checkpoint.py#L127](https://github.com/PyTorchLightning/pytorch-lightning/blob/97e6f35b34437c89d422bd440dca4a8d2c4d5a9f/pytorch_lightning/callbacks/model_checkpoint.py#L127). \r\n\r\nMaybe a try-except block is needed?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2915", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2915/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2915/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2915/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2915", "id": 676923544, "node_id": "MDU6SXNzdWU2NzY5MjM1NDQ=", "number": 2915, "title": "add graph to Tensorboard logger", "user": {"login": "Borda", "id": 6035284, "node_id": "MDQ6VXNlcjYwMzUyODQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/6035284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Borda", "html_url": "https://github.com/Borda", "followers_url": "https://api.github.com/users/Borda/followers", "following_url": "https://api.github.com/users/Borda/following{/other_user}", "gists_url": "https://api.github.com/users/Borda/gists{/gist_id}", "starred_url": "https://api.github.com/users/Borda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Borda/subscriptions", "organizations_url": "https://api.github.com/users/Borda/orgs", "repos_url": "https://api.github.com/users/Borda/repos", "events_url": "https://api.github.com/users/Borda/events{/privacy}", "received_events_url": "https://api.github.com/users/Borda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090690, "node_id": "MDU6TGFiZWwxMjk3MDkwNjkw", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/good%20first%20issue", "name": "good first issue", "color": "aacc24", "default": true, "description": "Good for newcomers"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-11T14:27:10Z", "updated_at": "2020-08-19T23:08:47Z", "closed_at": "2020-08-19T23:08:47Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n\r\nadding a graph to TB logger as it is shown here\r\nhttps://www.learnopencv.com/tensorboard-with-pytorch-lightning/\r\nmaybe also add histograms...\r\n\r\n### Motivation\r\n\r\n![image](https://user-images.githubusercontent.com/6035284/89909431-581a3280-dbef-11ea-9969-1d5ff15107ac.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2909", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2909/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2909/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2909/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2909", "id": 676551633, "node_id": "MDU6SXNzdWU2NzY1NTE2MzM=", "number": 2909, "title": "load_from_checkpoint: TypeError: __init__() missing 1 required positional argument", "user": {"login": "siahuat0727", "id": 17688111, "node_id": "MDQ6VXNlcjE3Njg4MTEx", "avatar_url": "https://avatars3.githubusercontent.com/u/17688111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/siahuat0727", "html_url": "https://github.com/siahuat0727", "followers_url": "https://api.github.com/users/siahuat0727/followers", "following_url": "https://api.github.com/users/siahuat0727/following{/other_user}", "gists_url": "https://api.github.com/users/siahuat0727/gists{/gist_id}", "starred_url": "https://api.github.com/users/siahuat0727/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/siahuat0727/subscriptions", "organizations_url": "https://api.github.com/users/siahuat0727/orgs", "repos_url": "https://api.github.com/users/siahuat0727/repos", "events_url": "https://api.github.com/users/siahuat0727/events{/privacy}", "received_events_url": "https://api.github.com/users/siahuat0727/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-08-11T03:30:02Z", "updated_at": "2020-08-11T11:38:31Z", "closed_at": "2020-08-11T11:38:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n#### What is your question?\r\n\r\nload_from_checkpoint: TypeError: __init__() missing 1 required positional argument\r\n\r\nI have read the issues before, but the things different is **my `LightningModule` is inherited from my self-defined `LightningModule`.**\r\n\r\nHow to solve this problem or what is the best practice better suited to my needs?\r\n\r\n#### Code\r\n\r\nTo reproduce the error:\r\n\r\n```python\r\nimport os\r\nimport torch\r\nfrom torch.nn import functional as F\r\nfrom torch.utils.data import DataLoader\r\nfrom torchvision.datasets import MNIST\r\nfrom torchvision import transforms\r\nimport pytorch_lightning as pl\r\nfrom pytorch_lightning import Trainer\r\n\r\nfrom argparse import Namespace\r\n\r\nclass _LitModel(pl.LightningModule):\r\n\r\n    def __init__(self, hparams):\r\n        super().__init__()\r\n        if isinstance(hparams, dict):\r\n            hparams = Namespace(**hparams)\r\n        self.hparams = hparams\r\n        self.l1 = torch.nn.Linear(28 * 28, hparams.classes)\r\n\r\n    def forward(self, x):\r\n        return torch.relu(self.l1(x.view(x.size(0), -1)))\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        y_hat = self(x)\r\n        loss = F.cross_entropy(y_hat, y)\r\n        tensorboard_logs = {'train_loss': loss}\r\n        return {'loss': loss, 'log': tensorboard_logs}\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        y_hat = self(x)\r\n        loss = F.cross_entropy(y_hat, y)\r\n        return {'val_loss': loss}\r\n\r\n    def validation_epoch_end(self, outputs):\r\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n        return {'val_loss': avg_loss}\r\n\r\n    def configure_optimizers(self):\r\n        return torch.optim.Adam(self.parameters(), lr=0.001)\r\n\r\nclass LitModel(_LitModel):\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n\r\nfrom argparse import ArgumentParser\r\nparser = ArgumentParser()\r\nparser.add_argument('--classes', type=int, default=10)\r\nparser.add_argument('--checkpoint', type=str, default=None)\r\nhparams = parser.parse_args()\r\n\r\nmnist_train = MNIST(os.getcwd(), train=True, download=True,\r\n                    transform=transforms.ToTensor())\r\nmnist_train = DataLoader(mnist_train, num_workers=1)\r\nmnist_val = MNIST(os.getcwd(), train=False, download=False,\r\n                  transform=transforms.ToTensor())\r\nmnist_val = DataLoader(mnist_val, num_workers=1)\r\n\r\n# A bit weird here. I just want to show `load_from_checkpoint` will fail.\r\nif hparams.checkpoint is None:\r\n    model = LitModel(hparams)\r\nelse:\r\n    model = LitModel.load_from_checkpoint(hparams.checkpoint)\r\n\r\ntrainer = Trainer(max_epochs=2, limit_train_batches=2,\r\n                  limit_val_batches=2, progress_bar_refresh_rate=0)\r\ntrainer.fit(model, mnist_train, mnist_val)\r\n```\r\n\r\n#### Error msg\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 64, in <module>\r\n    model = LitModel.load_from_checkpoint(hparams.checkpoint)\r\n  File \"/home/siahuat0727/.local/lib/python3.8/site-packages/pytorch_lightning/core/saving.py\", line 138, in load_from_checkpoint\r\n    model = cls._load_model_state(checkpoint, *args, **kwargs)\r\n  File \"/home/siahuat0727/.local/lib/python3.8/site-packages/pytorch_lightning/core/saving.py\", line 174, in _load_model_state\r\n    model = cls(*cls_args, **cls_kwargs)\r\n  File \"main.py\", line 46, in __init__\r\n    super().__init__(*args, **kwargs)\r\nTypeError: __init__() missing 1 required positional argument: 'hparams'\r\n```\r\n\r\n#### How to run to get the error\r\n\r\n```bash\r\n$ python3 main.py \r\n$ python3 main.py --checkpoint lightning_logs/version_0/checkpoints/epoch\\=1.ckpt\r\n```\r\n\r\n\r\n#### What's your environment?\r\n\r\n - OS: Linux\r\n - Packaging: pip\r\n - Version 0.9.0rc12\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2902", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2902/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2902/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2902/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2902", "id": 676021715, "node_id": "MDU6SXNzdWU2NzYwMjE3MTU=", "number": 2902, "title": "Optimizer initialization with DDP", "user": {"login": "PhilJd", "id": 16101605, "node_id": "MDQ6VXNlcjE2MTAxNjA1", "avatar_url": "https://avatars2.githubusercontent.com/u/16101605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PhilJd", "html_url": "https://github.com/PhilJd", "followers_url": "https://api.github.com/users/PhilJd/followers", "following_url": "https://api.github.com/users/PhilJd/following{/other_user}", "gists_url": "https://api.github.com/users/PhilJd/gists{/gist_id}", "starred_url": "https://api.github.com/users/PhilJd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PhilJd/subscriptions", "organizations_url": "https://api.github.com/users/PhilJd/orgs", "repos_url": "https://api.github.com/users/PhilJd/repos", "events_url": "https://api.github.com/users/PhilJd/events{/privacy}", "received_events_url": "https://api.github.com/users/PhilJd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1862633788, "node_id": "MDU6TGFiZWwxODYyNjMzNzg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/discussion", "name": "discussion", "color": "f29579", "default": false, "description": "Open discussion -> towards a conclusion"}, {"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-08-10T10:09:51Z", "updated_at": "2020-08-12T10:35:00Z", "closed_at": "2020-08-12T10:35:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n#### What is your question?\r\nI would have expected optimizers to always be initialized after parameters have been moved to their destination device.\r\nHowever, some ddp backends such as\r\n[ddp_backend](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_backend.py#L174),             [ddp_spawn_backend](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_spawn_backend.py#L115),            [ddp2_backend](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp2_backend.py#L111)\r\ninitialize the optimizer with the CPU parameters before moving the model to the GPU while others such as [gpu_backend](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/gpu_backend.py#L39) pass the GPU parameters.\r\n\r\nI'm currently trying to understand two things: \r\n(1) Where does the linking from the CPU to GPU parameters happen?\r\n(2) Is it actually necessary to initialize the optimizer before moving to the specific device or could it be done afterwards? (Most tutorials initialize the optimizer *after* placing the parameters on the corresponding device, e.g.  [this one](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#basic-use-case))\r\n\r\nThe reason I'm asking is that I did some parameter/gradient bending to be views into other tensors. This does not work with the current implementation as the optimizer keeps the reference to the CPU parameters with these tweaks but works fine when adapting the pytorch_lightning code by moving the optimizer creation after the model has been moved to the correct device.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2901", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2901/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2901/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2901/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2901", "id": 675915259, "node_id": "MDU6SXNzdWU2NzU5MTUyNTk=", "number": 2901, "title": "0.9.0-rc5 make program stuck on slurm+ddp, when using Accuracy", "user": {"login": "xiadingZ", "id": 16729275, "node_id": "MDQ6VXNlcjE2NzI5Mjc1", "avatar_url": "https://avatars1.githubusercontent.com/u/16729275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiadingZ", "html_url": "https://github.com/xiadingZ", "followers_url": "https://api.github.com/users/xiadingZ/followers", "following_url": "https://api.github.com/users/xiadingZ/following{/other_user}", "gists_url": "https://api.github.com/users/xiadingZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiadingZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiadingZ/subscriptions", "organizations_url": "https://api.github.com/users/xiadingZ/orgs", "repos_url": "https://api.github.com/users/xiadingZ/repos", "events_url": "https://api.github.com/users/xiadingZ/events{/privacy}", "received_events_url": "https://api.github.com/users/xiadingZ/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2020-08-10T06:57:59Z", "updated_at": "2020-08-17T03:26:20Z", "closed_at": "2020-08-17T03:26:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n## \ud83d\udc1b Bug\r\n\r\nafter upgrading to 0.9.0-rc5 from rc4, my program stucks on val loop, no error message. train loop is normal.\r\nall difference between train/val loop is my val loop use 'Accuracy' TensorMetric\r\n\r\nI'm not sure it's because of 'Accuracy' or bugs in 'validation_step'.\r\nmy program use ddp + slurm, normal in 0.9.0-rc4\r\n\r\n - PyTorch Version (e.g., 1.0): 1.5.0\r\n - Any other relevant information: slurm\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2896", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2896/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2896/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2896/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2896", "id": 675766042, "node_id": "MDU6SXNzdWU2NzU3NjYwNDI=", "number": 2896, "title": "unexpected keyword argument 'amp_type' in trainer __init__() ", "user": {"login": "JanRuettinger", "id": 8582703, "node_id": "MDQ6VXNlcjg1ODI3MDM=", "avatar_url": "https://avatars1.githubusercontent.com/u/8582703?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JanRuettinger", "html_url": "https://github.com/JanRuettinger", "followers_url": "https://api.github.com/users/JanRuettinger/followers", "following_url": "https://api.github.com/users/JanRuettinger/following{/other_user}", "gists_url": "https://api.github.com/users/JanRuettinger/gists{/gist_id}", "starred_url": "https://api.github.com/users/JanRuettinger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JanRuettinger/subscriptions", "organizations_url": "https://api.github.com/users/JanRuettinger/orgs", "repos_url": "https://api.github.com/users/JanRuettinger/repos", "events_url": "https://api.github.com/users/JanRuettinger/events{/privacy}", "received_events_url": "https://api.github.com/users/JanRuettinger/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}, {"id": 1800433344, "node_id": "MDU6TGFiZWwxODAwNDMzMzQ0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/information%20needed", "name": "information needed", "color": "b673dd", "default": false, "description": "need more information about this"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-08-09T20:25:39Z", "updated_at": "2020-08-15T12:28:04Z", "closed_at": "2020-08-15T12:27:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nVersions used: \r\n- Pytorch: 1.6.0\r\n- Pytorch Lightning: 0.9.12rc.\r\n\r\n```\r\ntrainer = Trainer(amp_type='apex', ...)\r\n```\r\nError message: `__init__() got an unexpected keyword argument 'amp_type'`\r\n\r\n### To Reproduce\r\nInit trainer as shown above.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2891", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2891/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2891/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2891/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2891", "id": 675636445, "node_id": "MDU6SXNzdWU2NzU2MzY0NDU=", "number": 2891, "title": "The total number of batches shows by the progress bar of the sanity check is wrong", "user": {"login": "manipopopo", "id": 14799222, "node_id": "MDQ6VXNlcjE0Nzk5MjIy", "avatar_url": "https://avatars2.githubusercontent.com/u/14799222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manipopopo", "html_url": "https://github.com/manipopopo", "followers_url": "https://api.github.com/users/manipopopo/followers", "following_url": "https://api.github.com/users/manipopopo/following{/other_user}", "gists_url": "https://api.github.com/users/manipopopo/gists{/gist_id}", "starred_url": "https://api.github.com/users/manipopopo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manipopopo/subscriptions", "organizations_url": "https://api.github.com/users/manipopopo/orgs", "repos_url": "https://api.github.com/users/manipopopo/repos", "events_url": "https://api.github.com/users/manipopopo/events{/privacy}", "received_events_url": "https://api.github.com/users/manipopopo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-08-09T04:52:31Z", "updated_at": "2020-08-22T04:07:28Z", "closed_at": "2020-08-22T04:07:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nThe `total` of the sanity check progress bar is set by\r\nhttps://github.com/PyTorchLightning/pytorch-lightning/blob/4d0406ec8bf1c9147b34eb607411b78a9cd28243/pytorch_lightning/callbacks/progress.py#L296\r\n\r\nThe progress bar will always show `trainer.num_sanity_val_steps` even if  the length of the validation `DataLoader` is less than `trainer.num_sanity_val_steps`.\r\n\r\nMaybe the `total` could be computed by\r\n```python\r\nfrom pytorch_lightning.trainer import data_loading\r\n\r\nnum_full_val_dataloader_batches = [\r\n    len(dataloader) if data_loading._has_len(dataloader) else float('inf')\r\n    for dataloader in trainer.val_dataloaders\r\n]\r\nself.val_progress_bar.total = convert_inf(\r\n    sum(min(num_batches, trainer.num_sanity_val_steps)\r\n            for num_batches in num_full_val_dataloader_batches))\r\n```\r\n\r\nWe use the private function `data_loading._has_len` to check if `dataloader` has `__len__`, maybe we could make `data_loading._has_len` public. \r\n\r\nOr we could make `num_full_val_dataloader_batches` (and `num_full_train_dataloader_batches`) a member variable of `Trainer` and update the value in `pytorch_lightning.trainer.data_loading.TrainerDataLoadingMixin`. \r\n\r\n### To Reproduce\r\n\r\nThe progress bar of the sanity check in the following code (`num_sanity_val_steps == 999` and `len(val_data_loader) == 10`) shows\r\n```\r\nValidation sanity check:   1%|          | 9/999 [00:09<16:31,  1.00s/it]`\r\n```\r\n\r\n#### Code sample\r\n```python\r\nimport time\r\n\r\nimport pytorch_lightning as pl\r\nfrom torch.utils import data\r\n\r\n\r\nclass Dataset(data.Dataset):\r\n\r\n  def __init__(self, length):\r\n    self._elements = list(range(length))\r\n\r\n  def __getitem__(self, item):\r\n    return self._elements[item]\r\n\r\n  def __len__(self):\r\n    return len(self._elements)\r\n\r\n\r\nclass Model(pl.LightningModule):\r\n\r\n  def forward(self, *args, **kwargs):\r\n    pass\r\n\r\n  def training_step(self, *args, **kwargs):\r\n    pass\r\n\r\n  def train_dataloader(self):\r\n    pass\r\n\r\n  def configure_optimizers(self):\r\n    pass\r\n\r\n  def validation_step(self, *args, **kwargs):\r\n    time.sleep(1)\r\n    return pl.EvalResult()\r\n\r\n\r\nif __name__ == '__main__':\r\n  model = Model()\r\n\r\n  val_dataset_length = 10\r\n  val_dataset = Dataset(val_dataset_length)\r\n  val_data_loader = data.DataLoader(val_dataset)\r\n\r\n  trainer = pl.Trainer(num_sanity_val_steps=999, limit_val_batches=999,\r\n                       max_epochs=0)\r\n  trainer.fit(model, val_dataloaders=val_data_loader)\r\n\r\n```\r\n### Expected behavior\r\nThe program above should be\r\n```\r\nValidation sanity check: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10<00:00,  1.00s/it]\r\n```\r\n### Environment\r\n* CUDA:\r\n\t- GPU:\r\n\t- available:\r\n\t- version:\r\n* Packages:\r\n\t- numpy:             1.18.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0+cpu\r\n\t- pytorch-lightning: 0.9.0rc11\r\n\t- tensorboard:       1.15.0\r\n\t- tqdm:              4.48.2\r\n* System:\r\n\t- OS:                Windows\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- WindowsPE\r\n\t- processor:\r\n\t- python:            3.7.3\r\n\t- version:           10.0.18362\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2888", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2888/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2888/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2888/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2888", "id": 675529958, "node_id": "MDU6SXNzdWU2NzU1Mjk5NTg=", "number": 2888, "title": "Understanding the Progress Bar", "user": {"login": "matthaeusheer", "id": 8364783, "node_id": "MDQ6VXNlcjgzNjQ3ODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/8364783?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthaeusheer", "html_url": "https://github.com/matthaeusheer", "followers_url": "https://api.github.com/users/matthaeusheer/followers", "following_url": "https://api.github.com/users/matthaeusheer/following{/other_user}", "gists_url": "https://api.github.com/users/matthaeusheer/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthaeusheer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthaeusheer/subscriptions", "organizations_url": "https://api.github.com/users/matthaeusheer/orgs", "repos_url": "https://api.github.com/users/matthaeusheer/repos", "events_url": "https://api.github.com/users/matthaeusheer/events{/privacy}", "received_events_url": "https://api.github.com/users/matthaeusheer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-08T14:01:20Z", "updated_at": "2020-08-08T14:42:38Z", "closed_at": "2020-08-08T14:42:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "I train on MNIST with data loaders defined below (full train / test sets with `batch_size=128`).  \r\n`'val_check_interval': 0.1`, so per training epoch, I have 10 validation runs.  \r\n\r\nNow:\r\n- 10000 (test) images / 128 (batch_size) = 78.125, so steps such as 54/79 do make sense.  \r\n- 60000 (train) images / 128 (batch_size) = 468.75, so I'd expect something like 120/469.  \r\n\r\nWhat is the \"1259\" representing in the progress bar? I can observe in tensorboard, that the epoch number goes up at exactly 459.\r\n```\r\nValidating:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 54/79 [00:08<00:03,  6.57it/s]\r\nEpoch 4:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 976/1259 [04:01<01:09,  4.05it/s, loss=19279.273, v_num=0]\r\n```\r\n\r\n#### Code\r\n##### Data Loaders\r\n```python\r\n    def train_dataloader(self) -> DataLoader:\r\n        \"\"\"Pytorch-lightning function.\"\"\"\r\n        transform = torchvision.transforms.Compose([torchvision.transforms.Resize((32, 32)),\r\n                                                    torchvision.transforms.ToTensor()])\r\n        train_set = torchvision.datasets.MNIST(root=DATA_DIR_PATH / 'mnist_data',\r\n                                               train=True,\r\n                                               download=True,\r\n                                               transform=transform)\r\n        return DataLoader(train_set,\r\n                          batch_size=128,\r\n                          shuffle=True,\r\n                          num_workers=0)\r\n\r\n    def val_dataloader(self) -> DataLoader:\r\n        \"\"\"Pytorch-lightning function.\"\"\"\r\n        transform = torchvision.transforms.Compose([torchvision.transforms.Resize((32, 32)),\r\n                                                    torchvision.transforms.ToTensor()])\r\n        val_set = torchvision.datasets.MNIST(root=DATA_DIR_PATH / 'mnist_data',\r\n                                             train=False,\r\n                                             download=True,\r\n                                             transform=transform)\r\n        return DataLoader(val_set,\r\n                          batch_size=128,\r\n                          shuffle=False,\r\n                          num_workers=0)\r\n```\r\n#### What's your environment?\r\n - OS: Ubuntu 20.04\r\n - Packaging: pipenv\r\n - Lightning Version: 0.8.5\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2886", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2886/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2886/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2886/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2886", "id": 675513527, "node_id": "MDU6SXNzdWU2NzU1MTM1Mjc=", "number": 2886, "title": "is it better to return num_classes in get_num_classes()?", "user": {"login": "aiyolo", "id": 12464091, "node_id": "MDQ6VXNlcjEyNDY0MDkx", "avatar_url": "https://avatars0.githubusercontent.com/u/12464091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aiyolo", "html_url": "https://github.com/aiyolo", "followers_url": "https://api.github.com/users/aiyolo/followers", "following_url": "https://api.github.com/users/aiyolo/following{/other_user}", "gists_url": "https://api.github.com/users/aiyolo/gists{/gist_id}", "starred_url": "https://api.github.com/users/aiyolo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aiyolo/subscriptions", "organizations_url": "https://api.github.com/users/aiyolo/orgs", "repos_url": "https://api.github.com/users/aiyolo/repos", "events_url": "https://api.github.com/users/aiyolo/events{/privacy}", "received_events_url": "https://api.github.com/users/aiyolo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-08-08T11:51:18Z", "updated_at": "2020-08-08T16:57:17Z", "closed_at": "2020-08-08T16:57:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "if `num_classes != num_all_classes`, I think it is better to return `num_classes` rather than raise an error\r\n\r\nhttps://github.com/PyTorchLightning/pytorch-lightning/blob/f798cffd02a0b6cbdc3033c981501c1a0c4677bd/pytorch_lightning/metrics/functional/classification.py#L67-L92\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2883", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2883/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2883/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2883/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2883", "id": 675487693, "node_id": "MDU6SXNzdWU2NzU0ODc2OTM=", "number": 2883, "title": "When the parameter gpus of Trainer> 1, _pickle.PicklingError:", "user": {"login": "guangmingjian", "id": 20612185, "node_id": "MDQ6VXNlcjIwNjEyMTg1", "avatar_url": "https://avatars3.githubusercontent.com/u/20612185?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guangmingjian", "html_url": "https://github.com/guangmingjian", "followers_url": "https://api.github.com/users/guangmingjian/followers", "following_url": "https://api.github.com/users/guangmingjian/following{/other_user}", "gists_url": "https://api.github.com/users/guangmingjian/gists{/gist_id}", "starred_url": "https://api.github.com/users/guangmingjian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guangmingjian/subscriptions", "organizations_url": "https://api.github.com/users/guangmingjian/orgs", "repos_url": "https://api.github.com/users/guangmingjian/repos", "events_url": "https://api.github.com/users/guangmingjian/events{/privacy}", "received_events_url": "https://api.github.com/users/guangmingjian/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2020-08-08T08:31:21Z", "updated_at": "2020-08-09T18:09:27Z", "closed_at": "2020-08-09T18:09:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n### Before asking:   \r\n1. search the issues.   \r\n2. search the docs.    \r\n\r\n<!-- If you still can't find what you need: -->\r\n\r\n#### What is your question?\r\nI have 4 GPUs, only Trainer(gpus=1,row_log_interval=10,max_epochs=100) can run normally. But the cpu utilization rate is extremely low, 40 cores only use 1 core. When the parameter gpus=2, the following error will occur.\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/mingjian/pythoncode/GNNPyg/test/testskorch.py\", line 51, in <module>\r\n    trainer.fit(model, train_loader)\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 988, in fit\r\n    results = self.__run_ddp_spawn(model, nprocs=self.num_processes)\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1068, in __run_ddp_spawn\r\n    mp.spawn(self.ddp_train, nprocs=nprocs, args=(q, model, ))\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 200, in spawn\r\n    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 149, in start_processes\r\n    process.start()\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/multiprocessing/process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\r\n    return Popen(process_obj)\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File \"/home/mingjian/anaconda3/envs/python36/lib/python3.6/multiprocessing/reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\n_pickle.PicklingError: Can't pickle typing.Union[torch.Tensor, NoneType]: it's not the same object as typing.Union\r\n#### Code\r\n`trainer = Trainer(gpus=2,row_log_interval=10,max_epochs=100)\r\ntrainer.fit(model, train_loader)`\r\n<!-- Please paste a code snippet if your question requires it! -->   \r\n\r\n#### What have you tried?\r\n\r\n#### What's your environment?\r\n\r\n - OS: [ Linux,Ubuntu 16]\r\n - Packaging [pip]\r\n - Version [0.8.5]\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2882", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2882/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2882/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2882/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2882", "id": 675433112, "node_id": "MDU6SXNzdWU2NzU0MzMxMTI=", "number": 2882, "title": "Int num_sanity_val_steps is always replaced by float limit_val_batches", "user": {"login": "manipopopo", "id": 14799222, "node_id": "MDQ6VXNlcjE0Nzk5MjIy", "avatar_url": "https://avatars2.githubusercontent.com/u/14799222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manipopopo", "html_url": "https://github.com/manipopopo", "followers_url": "https://api.github.com/users/manipopopo/followers", "following_url": "https://api.github.com/users/manipopopo/following{/other_user}", "gists_url": "https://api.github.com/users/manipopopo/gists{/gist_id}", "starred_url": "https://api.github.com/users/manipopopo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manipopopo/subscriptions", "organizations_url": "https://api.github.com/users/manipopopo/orgs", "repos_url": "https://api.github.com/users/manipopopo/repos", "events_url": "https://api.github.com/users/manipopopo/events{/privacy}", "received_events_url": "https://api.github.com/users/manipopopo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1862633788, "node_id": "MDU6TGFiZWwxODYyNjMzNzg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/discussion", "name": "discussion", "color": "f29579", "default": false, "description": "Open discussion -> towards a conclusion"}, {"id": 1297090690, "node_id": "MDU6TGFiZWwxMjk3MDkwNjkw", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/good%20first%20issue", "name": "good first issue", "color": "aacc24", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2020-08-08T05:16:15Z", "updated_at": "2020-08-21T18:11:31Z", "closed_at": "2020-08-21T18:11:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "The type annotations of `num_sanity_val_steps:` and `limit_val_batches` are `int` and `Union[int, float]` for _percent_ or _`num_batches`_. The minimum of _percent_ and _`num_batches`_ will be _percent_. (except when `num_batches==0`)\r\nhttps://github.com/PyTorchLightning/pytorch-lightning/blob/a59e140ee814d8818d121405582133cf6b767e1a/pytorch_lightning/trainer/trainer.py#L461\r\n\r\nMaybe we can remove the dependency of `limit_val_batches` from `num_sanity_val_steps` and revert to    \r\nhttps://github.com/PyTorchLightning/pytorch-lightning/blob/1e68968ed7fb9b8f73df148dd48194d469655ea3/pytorch_lightning/trainer/trainer.py#L491\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2868", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2868/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2868/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2868/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2868", "id": 675175963, "node_id": "MDU6SXNzdWU2NzUxNzU5NjM=", "number": 2868, "title": "Throw warning for changing val_loss", "user": {"login": "edenlightning", "id": 66261195, "node_id": "MDQ6VXNlcjY2MjYxMTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/66261195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edenlightning", "html_url": "https://github.com/edenlightning", "followers_url": "https://api.github.com/users/edenlightning/followers", "following_url": "https://api.github.com/users/edenlightning/following{/other_user}", "gists_url": "https://api.github.com/users/edenlightning/gists{/gist_id}", "starred_url": "https://api.github.com/users/edenlightning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edenlightning/subscriptions", "organizations_url": "https://api.github.com/users/edenlightning/orgs", "repos_url": "https://api.github.com/users/edenlightning/repos", "events_url": "https://api.github.com/users/edenlightning/events{/privacy}", "received_events_url": "https://api.github.com/users/edenlightning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2222900514, "node_id": "MDU6TGFiZWwyMjIyOTAwNTE0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/allowed_pre_1.0", "name": "allowed_pre_1.0", "color": "91e23b", "default": false, "description": ""}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090690, "node_id": "MDU6TGFiZWwxMjk3MDkwNjkw", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/good%20first%20issue", "name": "good first issue", "color": "aacc24", "default": true, "description": "Good for newcomers"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}, {"id": 1893143017, "node_id": "MDU6TGFiZWwxODkzMTQzMDE3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/let's%20do%20it!", "name": "let's do it!", "color": "12d1b1", "default": false, "description": "approved to implement"}], "state": "closed", "locked": false, "assignee": {"login": "shivin7", "id": 14182606, "node_id": "MDQ6VXNlcjE0MTgyNjA2", "avatar_url": "https://avatars0.githubusercontent.com/u/14182606?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivin7", "html_url": "https://github.com/shivin7", "followers_url": "https://api.github.com/users/shivin7/followers", "following_url": "https://api.github.com/users/shivin7/following{/other_user}", "gists_url": "https://api.github.com/users/shivin7/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivin7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivin7/subscriptions", "organizations_url": "https://api.github.com/users/shivin7/orgs", "repos_url": "https://api.github.com/users/shivin7/repos", "events_url": "https://api.github.com/users/shivin7/events{/privacy}", "received_events_url": "https://api.github.com/users/shivin7/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivin7", "id": 14182606, "node_id": "MDQ6VXNlcjE0MTgyNjA2", "avatar_url": "https://avatars0.githubusercontent.com/u/14182606?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivin7", "html_url": "https://github.com/shivin7", "followers_url": "https://api.github.com/users/shivin7/followers", "following_url": "https://api.github.com/users/shivin7/following{/other_user}", "gists_url": "https://api.github.com/users/shivin7/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivin7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivin7/subscriptions", "organizations_url": "https://api.github.com/users/shivin7/orgs", "repos_url": "https://api.github.com/users/shivin7/repos", "events_url": "https://api.github.com/users/shivin7/events{/privacy}", "received_events_url": "https://api.github.com/users/shivin7/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-08-07T17:53:24Z", "updated_at": "2020-08-17T14:29:29Z", "closed_at": "2020-08-17T14:29:29Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Add warning to user that when changing val_loss to another keyword it will break checkpointing, early stopping, and other features relying on it. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2864", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2864/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2864/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2864/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2864", "id": 675055052, "node_id": "MDU6SXNzdWU2NzUwNTUwNTI=", "number": 2864, "title": "Some questions about checkpoints and learning rate", "user": {"login": "jovenwayfarer", "id": 47921506, "node_id": "MDQ6VXNlcjQ3OTIxNTA2", "avatar_url": "https://avatars1.githubusercontent.com/u/47921506?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jovenwayfarer", "html_url": "https://github.com/jovenwayfarer", "followers_url": "https://api.github.com/users/jovenwayfarer/followers", "following_url": "https://api.github.com/users/jovenwayfarer/following{/other_user}", "gists_url": "https://api.github.com/users/jovenwayfarer/gists{/gist_id}", "starred_url": "https://api.github.com/users/jovenwayfarer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jovenwayfarer/subscriptions", "organizations_url": "https://api.github.com/users/jovenwayfarer/orgs", "repos_url": "https://api.github.com/users/jovenwayfarer/repos", "events_url": "https://api.github.com/users/jovenwayfarer/events{/privacy}", "received_events_url": "https://api.github.com/users/jovenwayfarer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "SkafteNicki", "id": 24896311, "node_id": "MDQ6VXNlcjI0ODk2MzEx", "avatar_url": "https://avatars1.githubusercontent.com/u/24896311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SkafteNicki", "html_url": "https://github.com/SkafteNicki", "followers_url": "https://api.github.com/users/SkafteNicki/followers", "following_url": "https://api.github.com/users/SkafteNicki/following{/other_user}", "gists_url": "https://api.github.com/users/SkafteNicki/gists{/gist_id}", "starred_url": "https://api.github.com/users/SkafteNicki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SkafteNicki/subscriptions", "organizations_url": "https://api.github.com/users/SkafteNicki/orgs", "repos_url": "https://api.github.com/users/SkafteNicki/repos", "events_url": "https://api.github.com/users/SkafteNicki/events{/privacy}", "received_events_url": "https://api.github.com/users/SkafteNicki/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "SkafteNicki", "id": 24896311, "node_id": "MDQ6VXNlcjI0ODk2MzEx", "avatar_url": "https://avatars1.githubusercontent.com/u/24896311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SkafteNicki", "html_url": "https://github.com/SkafteNicki", "followers_url": "https://api.github.com/users/SkafteNicki/followers", "following_url": "https://api.github.com/users/SkafteNicki/following{/other_user}", "gists_url": "https://api.github.com/users/SkafteNicki/gists{/gist_id}", "starred_url": "https://api.github.com/users/SkafteNicki/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SkafteNicki/subscriptions", "organizations_url": "https://api.github.com/users/SkafteNicki/orgs", "repos_url": "https://api.github.com/users/SkafteNicki/repos", "events_url": "https://api.github.com/users/SkafteNicki/events{/privacy}", "received_events_url": "https://api.github.com/users/SkafteNicki/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2020-08-07T14:30:47Z", "updated_at": "2020-08-22T13:13:47Z", "closed_at": "2020-08-22T13:13:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "How to pass learning rate to progression bar and how to choose metric for saving model weights? Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2862", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2862/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2862/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2862/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2862", "id": 674987526, "node_id": "MDU6SXNzdWU2NzQ5ODc1MjY=", "number": 2862, "title": "Metrics error due to inplace operation, \"computation has been modified by an inplace operation\". ", "user": {"login": "sykrn", "id": 40594982, "node_id": "MDQ6VXNlcjQwNTk0OTgy", "avatar_url": "https://avatars0.githubusercontent.com/u/40594982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sykrn", "html_url": "https://github.com/sykrn", "followers_url": "https://api.github.com/users/sykrn/followers", "following_url": "https://api.github.com/users/sykrn/following{/other_user}", "gists_url": "https://api.github.com/users/sykrn/gists{/gist_id}", "starred_url": "https://api.github.com/users/sykrn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sykrn/subscriptions", "organizations_url": "https://api.github.com/users/sykrn/orgs", "repos_url": "https://api.github.com/users/sykrn/repos", "events_url": "https://api.github.com/users/sykrn/events{/privacy}", "received_events_url": "https://api.github.com/users/sykrn/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-08-07T12:37:41Z", "updated_at": "2020-08-08T10:42:53Z", "closed_at": "2020-08-08T10:01:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey, @williamFalcon, I got a new error since I upgraded the library today.\r\nI used the accuracy metric, but got an error.\r\n\r\n### Code sample:\r\n```\r\n# in lightning module\r\ndef training_step(self, batch, batch_idx):\r\n        x, y = batch\r\n        y_hat = self(x)\r\n        loss = F.cross_entropy(y_hat, y)\r\n        acc = accuracy(y_hat, y)      # from the functional metric classification\r\n        tensorboard_logs = {'train_loss': loss}\r\n        return {'loss': loss, 'log': tensorboard_logs}\r\n```\r\n\r\n\r\n### Error msg:\r\n```\r\nRuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.LongTensor [32]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).\r\n```\r\n\r\n### Can be *solved* using `.clone()` method.\r\nHowever, when I clone the `y` before feeding to the accuracy function, no error was shown.\r\n```\r\nacc = accuracy(y_hat, y.clone())\r\n````\r\nBut, it's inconvenience if user has to do it manually, isn't it? \r\nActually, I can use the code above without `clone` before I upgrade to the latest. So, it might due to the latest update/rebase causing this error.\r\n\r\n> The same error shown for `f1_score` metric.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2859", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2859/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2859/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2859/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2859", "id": 674916255, "node_id": "MDU6SXNzdWU2NzQ5MTYyNTU=", "number": 2859, "title": "Failing docker-Conda build", "user": {"login": "Borda", "id": 6035284, "node_id": "MDQ6VXNlcjYwMzUyODQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/6035284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Borda", "html_url": "https://github.com/Borda", "followers_url": "https://api.github.com/users/Borda/followers", "following_url": "https://api.github.com/users/Borda/following{/other_user}", "gists_url": "https://api.github.com/users/Borda/gists{/gist_id}", "starred_url": "https://api.github.com/users/Borda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Borda/subscriptions", "organizations_url": "https://api.github.com/users/Borda/orgs", "repos_url": "https://api.github.com/users/Borda/repos", "events_url": "https://api.github.com/users/Borda/events{/privacy}", "received_events_url": "https://api.github.com/users/Borda/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "Borda", "id": 6035284, "node_id": "MDQ6VXNlcjYwMzUyODQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/6035284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Borda", "html_url": "https://github.com/Borda", "followers_url": "https://api.github.com/users/Borda/followers", "following_url": "https://api.github.com/users/Borda/following{/other_user}", "gists_url": "https://api.github.com/users/Borda/gists{/gist_id}", "starred_url": "https://api.github.com/users/Borda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Borda/subscriptions", "organizations_url": "https://api.github.com/users/Borda/orgs", "repos_url": "https://api.github.com/users/Borda/repos", "events_url": "https://api.github.com/users/Borda/events{/privacy}", "received_events_url": "https://api.github.com/users/Borda/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Borda", "id": 6035284, "node_id": "MDQ6VXNlcjYwMzUyODQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/6035284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Borda", "html_url": "https://github.com/Borda", "followers_url": "https://api.github.com/users/Borda/followers", "following_url": "https://api.github.com/users/Borda/following{/other_user}", "gists_url": "https://api.github.com/users/Borda/gists{/gist_id}", "starred_url": "https://api.github.com/users/Borda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Borda/subscriptions", "organizations_url": "https://api.github.com/users/Borda/orgs", "repos_url": "https://api.github.com/users/Borda/repos", "events_url": "https://api.github.com/users/Borda/events{/privacy}", "received_events_url": "https://api.github.com/users/Borda/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-08-07T10:17:24Z", "updated_at": "2020-08-07T13:29:11Z", "closed_at": "2020-08-07T13:29:10Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nthere seems to be some connection issue while creating Conda env\r\n\r\n### To Reproduce\r\n\r\nhttps://github.com/PyTorchLightning/pytorch-lightning/runs/957741187\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2857", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2857/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2857/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2857/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2857", "id": 674667764, "node_id": "MDU6SXNzdWU2NzQ2Njc3NjQ=", "number": 2857, "title": "This is really a bad idea. what if someone really don't want to sample/shuffle their data during training.", "user": {"login": "chu-NMSU", "id": 2889205, "node_id": "MDQ6VXNlcjI4ODkyMDU=", "avatar_url": "https://avatars0.githubusercontent.com/u/2889205?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chu-NMSU", "html_url": "https://github.com/chu-NMSU", "followers_url": "https://api.github.com/users/chu-NMSU/followers", "following_url": "https://api.github.com/users/chu-NMSU/following{/other_user}", "gists_url": "https://api.github.com/users/chu-NMSU/gists{/gist_id}", "starred_url": "https://api.github.com/users/chu-NMSU/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chu-NMSU/subscriptions", "organizations_url": "https://api.github.com/users/chu-NMSU/orgs", "repos_url": "https://api.github.com/users/chu-NMSU/repos", "events_url": "https://api.github.com/users/chu-NMSU/events{/privacy}", "received_events_url": "https://api.github.com/users/chu-NMSU/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1840917107, "node_id": "MDU6TGFiZWwxODQwOTE3MTA3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/documentation", "name": "documentation", "color": "0075ca", "default": true, "description": "Improvements or additions to documentation"}, {"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-06T23:58:03Z", "updated_at": "2020-08-07T07:08:43Z", "closed_at": "2020-08-07T00:14:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/PyTorchLightning/pytorch-lightning/blob/633cf76c686357c88f2d6397fa316ed710004184/pytorch_lightning/trainer/data_loading.py#L146", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2844", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2844/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2844/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2844/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2844", "id": 673947361, "node_id": "MDU6SXNzdWU2NzM5NDczNjE=", "number": 2844, "title": "Tensorboard logger fails to save model OmegaConf hparams ", "user": {"login": "ananthsub", "id": 2382532, "node_id": "MDQ6VXNlcjIzODI1MzI=", "avatar_url": "https://avatars1.githubusercontent.com/u/2382532?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananthsub", "html_url": "https://github.com/ananthsub", "followers_url": "https://api.github.com/users/ananthsub/followers", "following_url": "https://api.github.com/users/ananthsub/following{/other_user}", "gists_url": "https://api.github.com/users/ananthsub/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananthsub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananthsub/subscriptions", "organizations_url": "https://api.github.com/users/ananthsub/orgs", "repos_url": "https://api.github.com/users/ananthsub/repos", "events_url": "https://api.github.com/users/ananthsub/events{/privacy}", "received_events_url": "https://api.github.com/users/ananthsub/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "yukw777", "id": 2057325, "node_id": "MDQ6VXNlcjIwNTczMjU=", "avatar_url": "https://avatars2.githubusercontent.com/u/2057325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yukw777", "html_url": "https://github.com/yukw777", "followers_url": "https://api.github.com/users/yukw777/followers", "following_url": "https://api.github.com/users/yukw777/following{/other_user}", "gists_url": "https://api.github.com/users/yukw777/gists{/gist_id}", "starred_url": "https://api.github.com/users/yukw777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yukw777/subscriptions", "organizations_url": "https://api.github.com/users/yukw777/orgs", "repos_url": "https://api.github.com/users/yukw777/repos", "events_url": "https://api.github.com/users/yukw777/events{/privacy}", "received_events_url": "https://api.github.com/users/yukw777/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "yukw777", "id": 2057325, "node_id": "MDQ6VXNlcjIwNTczMjU=", "avatar_url": "https://avatars2.githubusercontent.com/u/2057325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yukw777", "html_url": "https://github.com/yukw777", "followers_url": "https://api.github.com/users/yukw777/followers", "following_url": "https://api.github.com/users/yukw777/following{/other_user}", "gists_url": "https://api.github.com/users/yukw777/gists{/gist_id}", "starred_url": "https://api.github.com/users/yukw777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yukw777/subscriptions", "organizations_url": "https://api.github.com/users/yukw777/orgs", "repos_url": "https://api.github.com/users/yukw777/repos", "events_url": "https://api.github.com/users/yukw777/events{/privacy}", "received_events_url": "https://api.github.com/users/yukw777/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2020-08-06T01:26:00Z", "updated_at": "2020-08-07T13:13:22Z", "closed_at": "2020-08-07T13:13:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nThe Tensorboard logger fails to log module hyperparameters configured with `OmegaConf`. This happens when updating the logger `hparams` here: \r\n\r\n- The trainer calls the logger's `log_hyperparams` [here](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L1141): \r\n- Inside `log_hyperparams` the logger's hparams are updated [here](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/loggers/tensorboard.py#L115). This causes the hparams type to now be `dict` instead of `DictConfig`\r\n- As a result, this branch in `[save_hparams_to_yaml](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/core/saving.py#L330-L333)` is never triggered\r\n\r\nThis is the stacktrace when logging hyperparams: https://gist.github.com/ananthsub/7acfdb0e0f551ed030f05f7674c37b46\r\n\r\n\r\n### To Reproduce\r\n\r\n\r\n#### Code sample\r\nA hacky fix would be something like changing the hparams update to use this inside the tensorboard logger:\r\n\r\n```\r\nif isinstance(params, Container):\r\n   self.hparams = OmegaConf.merge(self.hparams, params)\r\nelse:\r\n    self.hparams.update(params)\r\n```\r\n\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\n\r\n### Expected behavior\r\n\r\n### Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py\r\n# For security purposes, please check the contents of collect_env_details.py before running it.\r\npython collect_env_details.py\r\n```\r\n\r\n - PyTorch Version (e.g., 1.0):\r\n - OS (e.g., Linux):\r\n - How you installed PyTorch (`conda`, `pip`, source):\r\n - Build command you used (if compiling from source):\r\n - Python version:\r\n - CUDA/cuDNN version:\r\n - GPU models and configuration:\r\n - Any other relevant information:\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2837", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2837/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2837/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2837/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2837", "id": 673727952, "node_id": "MDU6SXNzdWU2NzM3Mjc5NTI=", "number": 2837, "title": "Trainer.on_gpu incorrectly set to False when specifying `gpus=0`", "user": {"login": "pgeez", "id": 1369475, "node_id": "MDQ6VXNlcjEzNjk0NzU=", "avatar_url": "https://avatars2.githubusercontent.com/u/1369475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pgeez", "html_url": "https://github.com/pgeez", "followers_url": "https://api.github.com/users/pgeez/followers", "following_url": "https://api.github.com/users/pgeez/following{/other_user}", "gists_url": "https://api.github.com/users/pgeez/gists{/gist_id}", "starred_url": "https://api.github.com/users/pgeez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pgeez/subscriptions", "organizations_url": "https://api.github.com/users/pgeez/orgs", "repos_url": "https://api.github.com/users/pgeez/repos", "events_url": "https://api.github.com/users/pgeez/events{/privacy}", "received_events_url": "https://api.github.com/users/pgeez/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1840917107, "node_id": "MDU6TGFiZWwxODQwOTE3MTA3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/documentation", "name": "documentation", "color": "0075ca", "default": true, "description": "Improvements or additions to documentation"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2020-08-05T17:42:56Z", "updated_at": "2020-08-18T10:11:13Z", "closed_at": "2020-08-08T15:50:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nWhen creating a trainer with the arg `gpus=0`, the field `on_gpu` is always set `False`, even on machines with CUDA available.\r\n\r\nThe existing logic for `on_gpu` is:\r\n\r\n```\r\nself.on_gpu = True if (gpus and torch.cuda.is_available()) else False\r\n```\r\n\r\nis buggy because `0` is \"falsy\". It should probably be:\r\n\r\n```\r\nself.on_gpu = gpus is not None and torch.cuda.is_available()\r\n```\r\n\r\n### To Reproduce\r\n\r\n```\r\ntrainer = trainer.Trainer(gpus=0, ...)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2825", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2825/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2825/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2825/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2825", "id": 672969036, "node_id": "MDU6SXNzdWU2NzI5NjkwMzY=", "number": 2825, "title": "Generalize i/o to other storage systems", "user": {"login": "edenlightning", "id": 66261195, "node_id": "MDQ6VXNlcjY2MjYxMTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/66261195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edenlightning", "html_url": "https://github.com/edenlightning", "followers_url": "https://api.github.com/users/edenlightning/followers", "following_url": "https://api.github.com/users/edenlightning/following{/other_user}", "gists_url": "https://api.github.com/users/edenlightning/gists{/gist_id}", "starred_url": "https://api.github.com/users/edenlightning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edenlightning/subscriptions", "organizations_url": "https://api.github.com/users/edenlightning/orgs", "repos_url": "https://api.github.com/users/edenlightning/repos", "events_url": "https://api.github.com/users/edenlightning/events{/privacy}", "received_events_url": "https://api.github.com/users/edenlightning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 2222900514, "node_id": "MDU6TGFiZWwyMjIyOTAwNTE0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/allowed_pre_1.0", "name": "allowed_pre_1.0", "color": "91e23b", "default": false, "description": ""}, {"id": 1862633788, "node_id": "MDU6TGFiZWwxODYyNjMzNzg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/discussion", "name": "discussion", "color": "f29579", "default": false, "description": "Open discussion -> towards a conclusion"}, {"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1800433344, "node_id": "MDU6TGFiZWwxODAwNDMzMzQ0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/information%20needed", "name": "information needed", "color": "b673dd", "default": false, "description": "need more information about this"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-04T17:50:41Z", "updated_at": "2020-08-18T17:11:36Z", "closed_at": "2020-08-18T17:11:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n\r\n### Motivation\r\n\r\nSupport checkpointing from storage systems, facebook is using this -> https://github.com/facebookresearch/fvcore/blob/master/fvcore/common/file_io.py\r\n\r\nSolution should be similar to what is[ proposed here](https://github.com/PyTorchLightning/pytorch-lightning/pull/2175).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2820", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2820/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2820/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2820/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2820", "id": 672675788, "node_id": "MDU6SXNzdWU2NzI2NzU3ODg=", "number": 2820, "title": "Do multiple optimizer steps in one training step", "user": {"login": "paudom", "id": 37597137, "node_id": "MDQ6VXNlcjM3NTk3MTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/37597137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paudom", "html_url": "https://github.com/paudom", "followers_url": "https://api.github.com/users/paudom/followers", "following_url": "https://api.github.com/users/paudom/following{/other_user}", "gists_url": "https://api.github.com/users/paudom/gists{/gist_id}", "starred_url": "https://api.github.com/users/paudom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paudom/subscriptions", "organizations_url": "https://api.github.com/users/paudom/orgs", "repos_url": "https://api.github.com/users/paudom/repos", "events_url": "https://api.github.com/users/paudom/events{/privacy}", "received_events_url": "https://api.github.com/users/paudom/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-08-04T10:13:06Z", "updated_at": "2020-08-10T08:10:17Z", "closed_at": "2020-08-10T08:10:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "#### What is your question?\r\nHi!, I'm currently trying to train a GAN with some regularization and I would need to perform multiple optimizer steps with different losses in one single training step. \r\n\r\nMy intuition tells me to define the `optimizer_step` function, but I keep finding errors and I don't know what I am doing wrong. \r\n- `RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation`\r\n- `RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time`\r\n\r\n#### Code\r\n```python\r\ndef training_step(self, batch, batch_idx, optimizer_idx):\r\n    real_img = batch\r\n    batch_size = rela_img.shape[0]\r\n    z = torch.randn(batch_size, self.latent_dim).to(self.device)\r\n\r\n    # Train Discriminator \r\n    if optimizer_idx == 0:\r\n        fake_img = self.generator(z)\r\n        fake_pred = self.discriminator(fake_img)\r\n        real_pred = self.discriminator(real_img)\r\n        d_loss = losses.d_loss(real_pred, fake_pred)\r\n        if batch_idx % self.args.d_regularize_every == 0:\r\n            real_img.requires_grad = True\r\n            real_pred = self.discriminator(real_img)\r\n            self.d_reg_loss = losses.d_reg_loss(real_pred, real_img)\r\n        return {'loss': d_loss}\r\n\r\n    # Train Generator\r\n    if optimizer_idx == 1:\r\n        fake_img = self.generator(z)\r\n        fake_pred = self.discriminator(fake_img)\r\n        g_loss = losses.g_loss(fake_pred)\r\n        if batch_idx % self.args.g_regularize_every == 0:\r\n             self.g_reg_loss = losses.g_reg_loss(fake_img, z)\r\n        return {'loss':g_loss}\r\n\r\ndef optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, *args, **kwargs):\r\n     # Step using d_loss or g_loss\r\n     super().optimizer_step(epoch, batch_idx, optimizer, optimizer_idx, *args, **kwargs)\r\n     if optimizer_idx == 0:\r\n         self.discriminator.zero_grad()\r\n         self.d_reg_loss.backward()\r\n         super().optimizer_step(epoch, batch_idx, optimizer, optimizer_idx, *args, **kwargs)\r\n     if optimizer_idx == 1:\r\n         self.generator.zero_grad()\r\n         self.g_reg_loss.backward()\r\n         super().optimizer_step(epoch, batch_idx, optimizer, optimizer_idx, *args, **kwargs)\r\n```\r\n#### What have you tried?\r\nI have tried to directly return the regularization losses instead of the normal losses. But then some at some steps instead of optimizing using the logistic loss I only optimize using the regularization loss. While I would like to always optimize at least one time and then optimize again at some steps. \r\n\r\nIs it possible with lightning? Or I am doing something wrong?\r\n\r\n#### What's your environment?\r\n - OS: MacOS\r\n - Packaging: pip\r\n - Version: 0.8.4\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2818", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2818/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2818/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2818/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2818", "id": 672637538, "node_id": "MDU6SXNzdWU2NzI2Mzc1Mzg=", "number": 2818, "title": "Issue with resume_from_checkpoint (on CPU and GPU)", "user": {"login": "GuillaumeRochette", "id": 11836548, "node_id": "MDQ6VXNlcjExODM2NTQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/11836548?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GuillaumeRochette", "html_url": "https://github.com/GuillaumeRochette", "followers_url": "https://api.github.com/users/GuillaumeRochette/followers", "following_url": "https://api.github.com/users/GuillaumeRochette/following{/other_user}", "gists_url": "https://api.github.com/users/GuillaumeRochette/gists{/gist_id}", "starred_url": "https://api.github.com/users/GuillaumeRochette/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GuillaumeRochette/subscriptions", "organizations_url": "https://api.github.com/users/GuillaumeRochette/orgs", "repos_url": "https://api.github.com/users/GuillaumeRochette/repos", "events_url": "https://api.github.com/users/GuillaumeRochette/events{/privacy}", "received_events_url": "https://api.github.com/users/GuillaumeRochette/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-04T09:12:51Z", "updated_at": "2020-08-04T09:28:35Z", "closed_at": "2020-08-04T09:28:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nHi,\r\n\r\nI've upgraded recently pytorch-lightning from 0.7.5 to 0.8.5, and I have encountered an issue with the ```resume_from_checkpoint``` from the Trainer class.\r\n\r\n### To Reproduce\r\n\r\nThe dummy example below shows the behaviour:\r\n\r\n1. Run the script for a few loops in order to create a first checkpoint.\r\n2. Stop.\r\n3. Re-run the code, it should resume from the previously created checkpoint.\r\n\r\nThis script works well and resume properly in 0.7.5, however it does not for 0.8.5.\r\n\r\n#### Code sample\r\n\r\n```py\r\nfrom munch import Munch\r\nfrom pathlib import Path\r\n\r\nimport torch\r\n\r\nfrom torch.utils.data import Dataset, DataLoader\r\nfrom torch.nn import Linear, MSELoss\r\nfrom torch.optim import Adam\r\n\r\nfrom pytorch_lightning import LightningModule, Trainer\r\n\r\n\r\nclass MyDataset(Dataset):\r\n    def __init__(self, n):\r\n        self.n = n\r\n\r\n    def __len__(self):\r\n        return self.n\r\n\r\n    def __getitem__(self, item):\r\n        x = torch.randn(1)\r\n        y = 1.5 * x + 2\r\n        return {\r\n            \"x\": x,\r\n            \"y\": y,\r\n        }\r\n\r\n\r\nclass MyModule(LightningModule):\r\n    def __init__(self):\r\n        super(MyModule, self).__init__()\r\n        self.model = Linear(in_features=1, out_features=1)\r\n        self.criterion = MSELoss()\r\n\r\n    def configure_optimizers(self):\r\n        return Adam(self.model.parameters())\r\n\r\n    def forward(self, x):\r\n        x = self.model(x)\r\n        return x\r\n\r\n    def training_step(self, input, batch_idx):\r\n        input = Munch.fromDict(input)\r\n\r\n        output = Munch()\r\n        output.y = self(input.x)\r\n\r\n        loss = self.criterion(input=output.y, target=input.y)\r\n        return {\"loss\": loss}\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    dataset = MyDataset(n=2 ** 15)\r\n    train_dataloader = DataLoader(dataset, batch_size=32, num_workers=8)\r\n\r\n    model = MyModule()\r\n\r\n    path = Path(\"/home/guillaume/projects/test/models/scratch\")\r\n\r\n    checkpoints = sorted(path.rglob(\"*.ckpt\"))\r\n    if checkpoints:\r\n        checkpoint = checkpoints[-1]\r\n    else:\r\n        checkpoint = None\r\n    print(checkpoint)\r\n\r\n    trainer = Trainer(\r\n        default_root_dir=path,\r\n        gpus=1,\r\n        auto_select_gpus=True,\r\n        resume_from_checkpoint=checkpoint,\r\n    )\r\n\r\n    trainer.fit(model=model, train_dataloader=train_dataloader)\r\n\r\n```\r\n\r\n```err\r\nGPU available: True, used: True\r\nTPU available: False, using: 0 TPU cores\r\nCUDA_VISIBLE_DEVICES: [0]\r\n\r\n  | Name      | Type    | Params\r\n--------------------------------------\r\n0 | model     | Linear  | 2     \r\n1 | criterion | MSELoss | 0     \r\nTraceback (most recent call last):\r\n  File \"/home/guillaume/projects/test/src/scratch.py\", line 75, in <module>\r\n    trainer.fit(model=model, train_dataloader=train_dataloader)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1003, in fit\r\n    results = self.single_gpu_train(model)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py\", line 186, in single_gpu_train\r\n    results = self.run_pretrain_routine(model)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1160, in run_pretrain_routine\r\n    self.restore_weights(model)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/training_io.py\", line 182, in restore_weights\r\n    self.restore(self.resume_from_checkpoint, on_gpu=self.on_gpu)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/training_io.py\", line 295, in restore\r\n    checkpoint = pl_load(checkpoint_path, map_location=lambda storage, loc: storage)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/utilities/cloud_io.py\", line 8, in load\r\n    if urlparse(path_or_url).scheme == '' or Path(path_or_url).drive:  # no scheme or with a drive letter\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/urllib/parse.py\", line 367, in urlparse\r\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/urllib/parse.py\", line 123, in _coerce_args\r\n    return _decode_args(args) + (_encode_result,)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/urllib/parse.py\", line 107, in _decode_args\r\n    return tuple(x.decode(encoding, errors) if x else '' for x in args)\r\n  File \"/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/urllib/parse.py\", line 107, in <genexpr>\r\n    return tuple(x.decode(encoding, errors) if x else '' for x in args)\r\nAttributeError: 'PosixPath' object has no attribute 'decode'\r\n```\r\n\r\n### Expected behavior\r\n\r\nThis exact same code works well with pytorch-lightning: 0.7.5, which is the version I used previously.\r\n\r\n### Environment\r\n\r\n```\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- GeForce GTX 970\r\n\t- available:         True\r\n\t- version:           10.2\r\n* Packages:\r\n\t- numpy:             1.19.1\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0\r\n\t- pytorch-lightning: 0.8.5\r\n\t- tensorboard:       2.3.0\r\n\t- tqdm:              4.48.2\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.7.7\r\n\t- version:           #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2816", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2816/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2816/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2816/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2816", "id": 672528597, "node_id": "MDU6SXNzdWU2NzI1Mjg1OTc=", "number": 2816, "title": "When is `on_validation_epoch_start` / `on_validation_epoch_end` being called?", "user": {"login": "siahuat0727", "id": 17688111, "node_id": "MDQ6VXNlcjE3Njg4MTEx", "avatar_url": "https://avatars3.githubusercontent.com/u/17688111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/siahuat0727", "html_url": "https://github.com/siahuat0727", "followers_url": "https://api.github.com/users/siahuat0727/followers", "following_url": "https://api.github.com/users/siahuat0727/following{/other_user}", "gists_url": "https://api.github.com/users/siahuat0727/gists{/gist_id}", "starred_url": "https://api.github.com/users/siahuat0727/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/siahuat0727/subscriptions", "organizations_url": "https://api.github.com/users/siahuat0727/orgs", "repos_url": "https://api.github.com/users/siahuat0727/repos", "events_url": "https://api.github.com/users/siahuat0727/events{/privacy}", "received_events_url": "https://api.github.com/users/siahuat0727/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-08-04T06:02:26Z", "updated_at": "2020-08-06T01:30:04Z", "closed_at": "2020-08-06T01:30:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n<!-- If you still can't find what you need: -->\r\n\r\n#### What is your question?\r\n\r\nWhen is `on_validation_epoch_start` / `on_validation_epoch_end` being called?\r\nIt there a doc that explains the order of the callback function being called?\r\n\r\nI need a callback function that will be called at the end of every validation epoch.\r\nI read the [callback docs](https://pytorch-lightning.readthedocs.io/en/latest/callbacks.html) and I think `on_validation_epoch_end` is the target function I need to override. But after my trial and error, I found that it is `on_validation_end` that meets my needs.\r\n\r\n\r\n#### What have you tried?\r\n\r\nAnd I found that on the latest version, nobody will call `on_validation_epoch_start` except the function `on_validation_epoch_start` itself in \"callback_hook.py\". Is it means that `on_validation_epoch_start` will never be called?\r\n\r\n```\r\n~/pytorch-lightning$ grep -rH \"on_validation_epoch_start\"\r\npytorch_lightning/core/hooks.py:    def on_validation_epoch_start(self) -> None:\r\npytorch_lightning/callbacks/base.py:    def on_validation_epoch_start(self, trainer, pl_module):\r\npytorch_lightning/trainer/callback_hook.py:    def on_validation_epoch_start(self):\r\npytorch_lightning/trainer/callback_hook.py:            callback.on_validation_epoch_start(self, self.get_model())\r\n```\r\n\r\n\r\n#### What's your environment?\r\n\r\n - OS: Linux\r\n - Packaging: pip\r\n - Version: 0.9.0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2815", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2815/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2815/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2815/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2815", "id": 672526835, "node_id": "MDU6SXNzdWU2NzI1MjY4MzU=", "number": 2815, "title": "Shouldn't LightningDataModule inherit abc.ABC to have @abstractmethod decorator works properly ?", "user": {"login": "roytseng-tw", "id": 5027936, "node_id": "MDQ6VXNlcjUwMjc5MzY=", "avatar_url": "https://avatars3.githubusercontent.com/u/5027936?v=4", "gravatar_id": "", "url": "https://api.github.com/users/roytseng-tw", "html_url": "https://github.com/roytseng-tw", "followers_url": "https://api.github.com/users/roytseng-tw/followers", "following_url": "https://api.github.com/users/roytseng-tw/following{/other_user}", "gists_url": "https://api.github.com/users/roytseng-tw/gists{/gist_id}", "starred_url": "https://api.github.com/users/roytseng-tw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/roytseng-tw/subscriptions", "organizations_url": "https://api.github.com/users/roytseng-tw/orgs", "repos_url": "https://api.github.com/users/roytseng-tw/repos", "events_url": "https://api.github.com/users/roytseng-tw/events{/privacy}", "received_events_url": "https://api.github.com/users/roytseng-tw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2244367919, "node_id": "MDU6TGFiZWwyMjQ0MzY3OTE5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/data", "name": "data", "color": "d38a45", "default": false, "description": "data, datasets datamodule, ..."}, {"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": {"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2020-08-04T05:58:01Z", "updated_at": "2020-08-18T06:08:22Z", "closed_at": "2020-08-18T06:08:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/PyTorchLightning/pytorch-lightning/blob/a55c481d5d27028bd34024705d79cbea66c48d32/pytorch_lightning/core/datamodule.py#L89\r\n\r\nTo ensure all abstract methods are overridden, one should inherit `abc.ABC` or set `metaclass=abc.ABCMeta`.\r\nLike below,\r\n```python\r\nclass _DataModuleWrapperABCMeta(_DataModuleWrapper, ABCMeta):\r\n    pass\r\n\r\n\r\nclass LightningDataModule(metaclass=_DataModuleWrapperABCMeta):  # pragma: no cover\r\n```\r\nHowever, this way will require user to explicitly define all three (train/val/test) dataloaders, even if some are not actually needed.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2808", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2808/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2808/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2808/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2808", "id": 672196775, "node_id": "MDU6SXNzdWU2NzIxOTY3NzU=", "number": 2808, "title": "NumpyMetric not mapping back to GPU in multi-GPU training", "user": {"login": "jcreinhold", "id": 5241441, "node_id": "MDQ6VXNlcjUyNDE0NDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/5241441?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcreinhold", "html_url": "https://github.com/jcreinhold", "followers_url": "https://api.github.com/users/jcreinhold/followers", "following_url": "https://api.github.com/users/jcreinhold/following{/other_user}", "gists_url": "https://api.github.com/users/jcreinhold/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcreinhold/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcreinhold/subscriptions", "organizations_url": "https://api.github.com/users/jcreinhold/orgs", "repos_url": "https://api.github.com/users/jcreinhold/repos", "events_url": "https://api.github.com/users/jcreinhold/events{/privacy}", "received_events_url": "https://api.github.com/users/jcreinhold/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-03T16:29:26Z", "updated_at": "2020-08-04T17:17:15Z", "closed_at": "2020-08-04T17:17:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI created a NumpyMetric class for an involved metric that requires numpy operations; however, the metric fails when training on multiple GPUs. After some debugging, this appears to be due to the resulting tensor not being mapped back to the appropriate GPU (or any GPU for that matter).\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Define a NumpyMetric class\r\n```python\r\nclass MyNumpyMetric(NumpyMetric):\r\n    def forward(self, y_hat, y):\r\n        # complicated numpy stuff (no calls to .cpu() or .cuda() or .to() or anything like that)\r\n        return metric\r\n```\r\n2. Instantiate it in the `__init__` and `validation_step` of my PyTorchLightning module, e.g.,\r\n```python\r\nclass MyNetwork(pl.LightningModule):\r\n    def __init__(self, args):\r\n        # other init stuff\r\n        self.my_metric = MyNumpyMetric('my_metric')\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        # other validation stuff\r\n        my_metric = self.my_metric(y_hat, y)  # where y_hat and y are tensors, no .cpu(), .cuda(), .to() called on either\r\n        out_dict = dict(val_my_metric=my_metric)\r\n        return out_dict\r\n```\r\n3. Run:\r\n```python\r\nmodel = MyNetwork(args)\r\ntrainer = Trainer(\r\n    benchmark=True,\r\n    check_val_every_n_epoch=1,\r\n    accumulate_grad_batches=1,\r\n    min_epochs=n_epochs,\r\n    max_epochs=n_epochs,\r\n    fast_dev_run=False,\r\n    gpus=2,\r\n    distributed_backend='dp'\r\n)\r\ntrainer.fit(model)\r\n```\r\n4. See:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"./tiramisu3d.py\", line 574, in <module>\r\n    trainer.fit(model)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 997, in fit\r\n    results = self.dp_train(model)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/pytorch_lightning/trainer/distrib_parts.py\", line 270, in dp_train\r\n    result = self.run_pretrain_routine(model)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1193, in run_pretrain_routine\r\n    eval_results = self._evaluate(model,\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 293, in _evaluate\r\n    output = self.evaluation_forward(model, batch, batch_idx, dataloader_idx, test_mode)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 444, in evaluation_forward\r\n    output = model(*args)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 550, in __call__\r\n    result = self.forward(*input, **kwargs)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py\", line 66, in forward\r\n    return self.gather(outputs, self.output_device)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 168, in gather\r\n    return gather(outputs, output_device, dim=self.dim)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\", line 68, in gather\r\n    res = gather_map(outputs)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\", line 61, in gather_map\r\n    return type(out)(((k, gather_map([d[k] for d in outputs]))\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\", line 61, in <genexpr>\r\n    return type(out)(((k, gather_map([d[k] for d in outputs]))\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\", line 55, in gather_map\r\n    return Gather.apply(target_device, dim, *outputs)\r\n  File \"/iacl/pg20/jacobr/miniconda3/envs/msseg-9.2/lib/python3.8/site-packages/torch/nn/parallel/_functions.py\", line 54, in forward\r\n    assert all(map(lambda i: i.is_cuda, inputs))\r\n```\r\n\r\n#### Code sample\r\nI will try to do this soon.\r\n\r\n### Expected behavior\r\nI expected no error to occur. The documentation states: \"[NumpyMetric] already handles DDP sync and input/output conversions.\" However, this doesn't appear to be the case in my implementation.\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- Tesla M40 24GB\r\n\t\t- Tesla M40 24GB\r\n\t- available:         True\r\n\t- version:           9.2\r\n* Packages:\r\n\t- numpy:             1.18.5\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.5.1\r\n\t- pytorch-lightning: 0.8.5\r\n\t- tensorboard:       2.3.0\r\n\t- tqdm:              4.48.0\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- ELF\r\n\t- processor:         x86_64\r\n\t- python:            3.8.3\r\n\t- version:           #1 SMP Wed Sep 26 11:06:22 UTC 2018\r\n\r\n### Additional context\r\n\r\nPyTorch and PyTorch Lightning were installed with conda (along with all of the other packages).\r\n\r\nI was able to work around this error by adding the following `.to()` call to the validation step:\r\n\r\n```python\r\ndef validation_step(self, batch, batch_idx):\r\n    # other validation stuff\r\n    my_metric = self.my_metric(y_hat, y)\r\n    my_metric = my_metric.to(y_hat.device)\r\n    out_dict = dict(val_my_metric=my_metric)\r\n    return out_dict\r\n```\r\n\r\nI presume, however, that this is not the intended way to use the NumpyMetric class.\r\n\r\nFWIW, I briefly looked at the code to see if I could just submit a PR with the fix (if this isn't user error), but it wasn't clear to me where the best places to look were. If you point me in the right direction, I might be able to submit a PR with the fix.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2807", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2807/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2807/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2807/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2807", "id": 671980322, "node_id": "MDU6SXNzdWU2NzE5ODAzMjI=", "number": 2807, "title": "Issue with running multiple models in PyTorch Lightning", "user": {"login": "epiicme", "id": 31699257, "node_id": "MDQ6VXNlcjMxNjk5MjU3", "avatar_url": "https://avatars1.githubusercontent.com/u/31699257?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epiicme", "html_url": "https://github.com/epiicme", "followers_url": "https://api.github.com/users/epiicme/followers", "following_url": "https://api.github.com/users/epiicme/following{/other_user}", "gists_url": "https://api.github.com/users/epiicme/gists{/gist_id}", "starred_url": "https://api.github.com/users/epiicme/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epiicme/subscriptions", "organizations_url": "https://api.github.com/users/epiicme/orgs", "repos_url": "https://api.github.com/users/epiicme/repos", "events_url": "https://api.github.com/users/epiicme/events{/privacy}", "received_events_url": "https://api.github.com/users/epiicme/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2020-08-03T10:38:36Z", "updated_at": "2020-08-19T20:08:45Z", "closed_at": "2020-08-16T15:19:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nI am developing a system which needs to train dozens of individual models (>50) using Lightning, each with their own TensorBoard plots and logs. My current implementation has one Trainer object per model and it seems like I'm running into an error when I go over ~90 Trainer objects. Interestingly, the error only appears when I run the .test() method, not during .fit().\r\n\r\nAs I just started with Lightning, I am not sure if having one Trainer/model is the best approach. However, I require individual plots from each model, and it seems that if I use a single trainer for multiple models the results get overridden.\r\n### To Reproduce\r\n\r\nSteps to reproduce the behaviour:\r\n\r\n1.Define more than 90 Trainer objects, each with their own model.\r\n2. Run training for each model.\r\n3. Run testing for each model.\r\n4. See error\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"lightning/main_2.py\", line 193, in <module>\r\n    main()\r\n  File \"lightning/main_2.py\", line 174, in main\r\n    new_trainer.test(model=new_model, test_dataloaders=te_loader)\r\n  File \"\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1279, in test\r\n    results = self.__test_given_model(model, test_dataloaders)\r\n  File \"\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1343, in __test_given_model\r\n    self.set_random_port(force=True)\r\n  File \"\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\pytorch_lightning\\trainer\\distrib_data_parallel.py\", line 398, in set_random_port\r\n    default_port = RANDOM_PORTS[-1]\r\nIndexError: index -1 is out of bounds for axis 0 with size 0\r\n```\r\n#### Code sample\r\nDefining the Trainer objects:\r\n```\r\nfor i in range(args[\"num_users\"]):\r\n    trainer_list_0.append(Trainer(max_epochs=args[\"epochs\"], gpus=1, default_root_dir=args[\"save_path\"],\r\n                                          fast_dev_run=args[\"fast_dev_run\"], weights_summary=None))\r\n    trainer_list_1.append(Trainer(max_epochs=args[\"epochs\"], gpus=1, default_root_dir=args[\"save_path\"],\r\n                                            fast_dev_run=args[\"fast_dev_run\"], weights_summary=None))\r\n    trainer_list_2.append(Trainer(max_epochs=args[\"epochs\"], gpus=1, default_root_dir=args[\"save_path\"],\r\n                                            fast_dev_run=args[\"fast_dev_run\"], weights_summary=None))\r\n```\r\nTraining:\r\n```\r\nfor i in range(args[\"num_users\"]):\r\n    trainer_list_0[i].fit(model_list_0[i], train_dataloader=dataloader_list[i],\r\n                                      val_dataloaders=val_loader)\r\n    trainer_list_1[i].fit(model_list_1[i], train_dataloader=dataloader_list[i],\r\n                                        val_dataloaders=val_loader)\r\n    trainer_list_2[i].fit(model_list_2[i], train_dataloader=dataloader_list[i],\r\n                                        val_dataloaders=val_loader)\r\n```\r\nTesting:\r\n```\r\nfor i in range(args[\"num_users\"]):\r\n    trainer_list_0[i].test(test_dataloaders=te_loader)\r\n    trainer_list_1[i].test(test_dataloaders=te_loader)\r\n    trainer_list_2[i].test(test_dataloaders=te_loader)\r\n```\r\n### Expected behaviour\r\n\r\nI expected the code to work without crashing.\r\n\r\n### Environment\r\n\r\n - PyTorch Version (e.g., 1.0): 1.4\r\n - OS (e.g., Linux): Windows 10 Pro 2004\r\n - How you installed PyTorch (`conda`, `pip`, source): conda\r\n - Python version: 3.7.6\r\n - CUDA/cuDNN version: CUDA 10.1/cuDNN 7.0\r\n - GPU models and configuration: RTX 2060 Super", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2799", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2799/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2799/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2799/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2799", "id": 671629348, "node_id": "MDU6SXNzdWU2NzE2MjkzNDg=", "number": 2799, "title": "how to run m validation batches after running every n training batches?", "user": {"login": "benwu232", "id": 3946864, "node_id": "MDQ6VXNlcjM5NDY4NjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/3946864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/benwu232", "html_url": "https://github.com/benwu232", "followers_url": "https://api.github.com/users/benwu232/followers", "following_url": "https://api.github.com/users/benwu232/following{/other_user}", "gists_url": "https://api.github.com/users/benwu232/gists{/gist_id}", "starred_url": "https://api.github.com/users/benwu232/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/benwu232/subscriptions", "organizations_url": "https://api.github.com/users/benwu232/orgs", "repos_url": "https://api.github.com/users/benwu232/repos", "events_url": "https://api.github.com/users/benwu232/events{/privacy}", "received_events_url": "https://api.github.com/users/benwu232/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}, {"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-02T14:47:12Z", "updated_at": "2020-08-08T01:45:49Z", "closed_at": "2020-08-03T16:38:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n\r\n\r\nFor example, I'm runing a model on a big dataset. After every 10000 training batches, I'd like to run 1000 validation batches to  check the avg_traning_loss and avg_val_loss. \r\n\r\nI tried val_check_interval but it just run all validation dataset, which is too big and time consuming. How to validate only part of the validation data?\r\n\r\nThis is similar to #2534 with something different. \r\n\r\nThanks a lot!\r\nBen \r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2795", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2795/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2795/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2795/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2795", "id": 671457574, "node_id": "MDU6SXNzdWU2NzE0NTc1NzQ=", "number": 2795, "title": "EvalResult doesn't do mean_of_gpus if using TensorMetric", "user": {"login": "xiadingZ", "id": 16729275, "node_id": "MDQ6VXNlcjE2NzI5Mjc1", "avatar_url": "https://avatars1.githubusercontent.com/u/16729275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiadingZ", "html_url": "https://github.com/xiadingZ", "followers_url": "https://api.github.com/users/xiadingZ/followers", "following_url": "https://api.github.com/users/xiadingZ/following{/other_user}", "gists_url": "https://api.github.com/users/xiadingZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiadingZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiadingZ/subscriptions", "organizations_url": "https://api.github.com/users/xiadingZ/orgs", "repos_url": "https://api.github.com/users/xiadingZ/repos", "events_url": "https://api.github.com/users/xiadingZ/events{/privacy}", "received_events_url": "https://api.github.com/users/xiadingZ/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-02T03:34:39Z", "updated_at": "2020-08-15T12:38:20Z", "closed_at": "2020-08-15T12:38:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "I want to use new `AccuracyMetric`, it can automatically sync in ddp, but it doesn't divide by `word_size`. In manually mode, I can  divide it by `word_size` by hand in `validation_epoch_end`. But if I use `EvalResult`, how to do this? It only do `mean`  across batches, but no across gpus.\r\n This is original code:\r\n```\r\n    def validation_epoch_end(self, outputs):\r\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\r\n        avg_acc = avg_acc / self.trainer.world_size\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2788", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2788/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2788/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2788/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2788", "id": 670842905, "node_id": "MDU6SXNzdWU2NzA4NDI5MDU=", "number": 2788, "title": "Enable option to use Apex when PyTorch 1.6 is installed", "user": {"login": "Anjum48", "id": 13783303, "node_id": "MDQ6VXNlcjEzNzgzMzAz", "avatar_url": "https://avatars1.githubusercontent.com/u/13783303?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Anjum48", "html_url": "https://github.com/Anjum48", "followers_url": "https://api.github.com/users/Anjum48/followers", "following_url": "https://api.github.com/users/Anjum48/following{/other_user}", "gists_url": "https://api.github.com/users/Anjum48/gists{/gist_id}", "starred_url": "https://api.github.com/users/Anjum48/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Anjum48/subscriptions", "organizations_url": "https://api.github.com/users/Anjum48/orgs", "repos_url": "https://api.github.com/users/Anjum48/repos", "events_url": "https://api.github.com/users/Anjum48/events{/privacy}", "received_events_url": "https://api.github.com/users/Anjum48/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2245077676, "node_id": "MDU6TGFiZWwyMjQ1MDc3Njc2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/API", "name": "API", "color": "7b6bd3", "default": false, "description": ""}, {"id": 2222900514, "node_id": "MDU6TGFiZWwyMjIyOTAwNTE0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/allowed_pre_1.0", "name": "allowed_pre_1.0", "color": "91e23b", "default": false, "description": ""}, {"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090690, "node_id": "MDU6TGFiZWwxMjk3MDkwNjkw", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/good%20first%20issue", "name": "good first issue", "color": "aacc24", "default": true, "description": "Good for newcomers"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}, {"id": 1893143017, "node_id": "MDU6TGFiZWwxODkzMTQzMDE3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/let's%20do%20it!", "name": "let's do it!", "color": "12d1b1", "default": false, "description": "approved to implement"}], "state": "closed", "locked": false, "assignee": {"login": "edenlightning", "id": 66261195, "node_id": "MDQ6VXNlcjY2MjYxMTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/66261195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edenlightning", "html_url": "https://github.com/edenlightning", "followers_url": "https://api.github.com/users/edenlightning/followers", "following_url": "https://api.github.com/users/edenlightning/following{/other_user}", "gists_url": "https://api.github.com/users/edenlightning/gists{/gist_id}", "starred_url": "https://api.github.com/users/edenlightning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edenlightning/subscriptions", "organizations_url": "https://api.github.com/users/edenlightning/orgs", "repos_url": "https://api.github.com/users/edenlightning/repos", "events_url": "https://api.github.com/users/edenlightning/events{/privacy}", "received_events_url": "https://api.github.com/users/edenlightning/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "edenlightning", "id": 66261195, "node_id": "MDQ6VXNlcjY2MjYxMTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/66261195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edenlightning", "html_url": "https://github.com/edenlightning", "followers_url": "https://api.github.com/users/edenlightning/followers", "following_url": "https://api.github.com/users/edenlightning/following{/other_user}", "gists_url": "https://api.github.com/users/edenlightning/gists{/gist_id}", "starred_url": "https://api.github.com/users/edenlightning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edenlightning/subscriptions", "organizations_url": "https://api.github.com/users/edenlightning/orgs", "repos_url": "https://api.github.com/users/edenlightning/repos", "events_url": "https://api.github.com/users/edenlightning/events{/privacy}", "received_events_url": "https://api.github.com/users/edenlightning/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-08-01T12:48:13Z", "updated_at": "2020-08-08T09:07:33Z", "closed_at": "2020-08-08T09:07:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\n\r\nCurrently, if PyTorch 1.6 is installed, PyTorch Lightning will use native AMP by default. It would be useful to have an option to force PL to use Apex if needed, which is not currently possible\r\n\r\n### Motivation\r\n\r\nNative AMP is great but under certain conditions may perform differently to Apex. For debugging purposes and backwards compatibility, having the option to still use Apex might be useful.\r\n\r\nIn my particular problem, I needed to roll back to PT 1.5 since I was seeing different behaviour between the two. Having the option to switch between the two AMP methods would make it easier to diagnose my issue.\r\n\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\n### Pitch\r\n\r\nHave a flag to force the Trainer to use Apex over native AMP\r\n\r\n<!-- A clear and concise description of what you want to happen. -->", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2782", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2782/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2782/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2782/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2782", "id": 670064713, "node_id": "MDU6SXNzdWU2NzAwNjQ3MTM=", "number": 2782, "title": "Use of shell=True could lead to shell injection", "user": {"login": "bkhakshoor", "id": 11509648, "node_id": "MDQ6VXNlcjExNTA5NjQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/11509648?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bkhakshoor", "html_url": "https://github.com/bkhakshoor", "followers_url": "https://api.github.com/users/bkhakshoor/followers", "following_url": "https://api.github.com/users/bkhakshoor/following{/other_user}", "gists_url": "https://api.github.com/users/bkhakshoor/gists{/gist_id}", "starred_url": "https://api.github.com/users/bkhakshoor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bkhakshoor/subscriptions", "organizations_url": "https://api.github.com/users/bkhakshoor/orgs", "repos_url": "https://api.github.com/users/bkhakshoor/repos", "events_url": "https://api.github.com/users/bkhakshoor/events{/privacy}", "received_events_url": "https://api.github.com/users/bkhakshoor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1851720487, "node_id": "MDU6TGFiZWwxODUxNzIwNDg3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Priority", "name": "Priority", "color": "d10a56", "default": false, "description": "High priority task"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ananyahjha93", "id": 7491256, "node_id": "MDQ6VXNlcjc0OTEyNTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7491256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananyahjha93", "html_url": "https://github.com/ananyahjha93", "followers_url": "https://api.github.com/users/ananyahjha93/followers", "following_url": "https://api.github.com/users/ananyahjha93/following{/other_user}", "gists_url": "https://api.github.com/users/ananyahjha93/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananyahjha93/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananyahjha93/subscriptions", "organizations_url": "https://api.github.com/users/ananyahjha93/orgs", "repos_url": "https://api.github.com/users/ananyahjha93/repos", "events_url": "https://api.github.com/users/ananyahjha93/events{/privacy}", "received_events_url": "https://api.github.com/users/ananyahjha93/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-07-31T17:56:06Z", "updated_at": "2020-08-02T03:25:57Z", "closed_at": "2020-08-02T03:25:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "File: pytorch_lightning/trainer/training_io.py\r\nLine Number: 227-233\r\nRelevant Code: \r\n\r\n`            # find job id\r\n            job_id = os.environ['SLURM_JOB_ID']\r\n            cmd = 'scontrol requeue {}'.format(job_id)\r\n\r\n            # requeue job\r\n            log.info(f'requeing job {job_id}...')\r\n            result = call(cmd, shell=True)`\r\n\r\nFrom [here](https://docs.python.org/2/library/subprocess.html), \"Executing shell commands that incorporate unsanitized input from an untrusted source makes a program vulnerable to shell injection, a serious security flaw which can result in arbitrary command execution. For this reason, the use of shell=True is strongly discouraged in cases where the command string is constructed from external input...shell=False disables all shell based features, but does not suffer from this vulnerability\"\r\n\r\nMeaning anything that can set the SLURM_JOB_ID environment variable can perform code execution.\r\n\r\nThe documentation also describes why you might need/want shell=True, \"This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user\u2019s home directory.\"\r\n\r\nLooking at the code above, it doesn't look like we need any of these features and we can switch to shell=False with no change in functionality while gaining the security benefits of shell=False.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2768", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2768/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2768/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2768/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2768", "id": 669117292, "node_id": "MDU6SXNzdWU2NjkxMTcyOTI=", "number": 2768, "title": "to_categorical should go before get_num_classes in metrics/functional/classification.py", "user": {"login": "pwwang", "id": 1188067, "node_id": "MDQ6VXNlcjExODgwNjc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1188067?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pwwang", "html_url": "https://github.com/pwwang", "followers_url": "https://api.github.com/users/pwwang/followers", "following_url": "https://api.github.com/users/pwwang/following{/other_user}", "gists_url": "https://api.github.com/users/pwwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/pwwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pwwang/subscriptions", "organizations_url": "https://api.github.com/users/pwwang/orgs", "repos_url": "https://api.github.com/users/pwwang/repos", "events_url": "https://api.github.com/users/pwwang/events{/privacy}", "received_events_url": "https://api.github.com/users/pwwang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2237141533, "node_id": "MDU6TGFiZWwyMjM3MTQxNTMz", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Metrics", "name": "Metrics", "color": "ef4ae1", "default": false, "description": ""}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-30T19:30:34Z", "updated_at": "2020-08-02T03:24:20Z", "closed_at": "2020-08-02T03:24:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "https://github.com/PyTorchLightning/pytorch-lightning/blob/d18b9ef9d95ffd92591f767808cc497af5bd4e1c/pytorch_lightning/metrics/functional/classification.py#L174-L178\r\n\r\n`to_categorical` should go before `get_num_classes`, since `get_num_classes` assumes `pred` has already been turned into categories (it is doing `int(pred.max().detach().item() + 1)`).\r\n\r\nWarnings are raised now and then with current code, for example:\r\n```\r\nUserWarning: You have set 10 number of classes if different from predicted (xx) and target (10) number of classes\r\n```\r\n\r\nIf logits are passed in directly for metrics.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2766", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2766/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2766/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2766/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2766", "id": 668869717, "node_id": "MDU6SXNzdWU2Njg4Njk3MTc=", "number": 2766, "title": "Speed up gradient norm clipping.", "user": {"login": "PhilJd", "id": 16101605, "node_id": "MDQ6VXNlcjE2MTAxNjA1", "avatar_url": "https://avatars2.githubusercontent.com/u/16101605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PhilJd", "html_url": "https://github.com/PhilJd", "followers_url": "https://api.github.com/users/PhilJd/followers", "following_url": "https://api.github.com/users/PhilJd/following{/other_user}", "gists_url": "https://api.github.com/users/PhilJd/gists{/gist_id}", "starred_url": "https://api.github.com/users/PhilJd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PhilJd/subscriptions", "organizations_url": "https://api.github.com/users/PhilJd/orgs", "repos_url": "https://api.github.com/users/PhilJd/repos", "events_url": "https://api.github.com/users/PhilJd/events{/privacy}", "received_events_url": "https://api.github.com/users/PhilJd/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-30T15:29:14Z", "updated_at": "2020-07-30T15:53:25Z", "closed_at": "2020-07-30T15:53:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\nImprove the speed of gradient clipping.\r\n\r\n### Motivation\r\nI've noticed that clipping the gradients is quite slow, e.g., for a ResNet50 model (with some minor extensions) gradient clipping takes ~207 ms. The major bottlenecks are the `torch.where` computation within a loop and the manual norm computation.\r\n\r\n### Pitch\r\nWith slight modifications that don't hurt readability and work well on TPU,\r\ngrad_norm can be computed in ~75ms, i.e.,  2.7x as fast. For implementation details see the PR I'm going to link in a second.\r\n\r\nReproduce: Train any model you've got lying around with gradient_clip_val=0.1 and take a look at the trace timeline ;)\r\n\r\nAs a reference, here's a before and after comparison for my model (trace after 40 warmup steps):\r\nCurrent:\r\n![image](https://user-images.githubusercontent.com/16101605/88942052-09cd7100-d28a-11ea-93db-73c72e350ac4.png)\r\n\r\nWith speed improvements:\r\n![image](https://user-images.githubusercontent.com/16101605/88941994-f4584700-d289-11ea-9c72-668a8b8d227e.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2765", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2765/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2765/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2765/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2765", "id": 668827045, "node_id": "MDU6SXNzdWU2Njg4MjcwNDU=", "number": 2765, "title": "Add a test case for running trainer.test without trainer.fit on DDP", "user": {"login": "edenlightning", "id": 66261195, "node_id": "MDQ6VXNlcjY2MjYxMTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/66261195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edenlightning", "html_url": "https://github.com/edenlightning", "followers_url": "https://api.github.com/users/edenlightning/followers", "following_url": "https://api.github.com/users/edenlightning/following{/other_user}", "gists_url": "https://api.github.com/users/edenlightning/gists{/gist_id}", "starred_url": "https://api.github.com/users/edenlightning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edenlightning/subscriptions", "organizations_url": "https://api.github.com/users/edenlightning/orgs", "repos_url": "https://api.github.com/users/edenlightning/repos", "events_url": "https://api.github.com/users/edenlightning/events{/privacy}", "received_events_url": "https://api.github.com/users/edenlightning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2237125337, "node_id": "MDU6TGFiZWwyMjM3MTI1MzM3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/DDP", "name": "DDP", "color": "33cc77", "default": false, "description": ""}, {"id": 2065663816, "node_id": "MDU6TGFiZWwyMDY1NjYzODE2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Important", "name": "Important", "color": "FFD700", "default": false, "description": "High important task, global impact"}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}, {"id": 1851722664, "node_id": "MDU6TGFiZWwxODUxNzIyNjY0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/tests%20/%20CI", "name": "tests / CI", "color": "2b2199", "default": false, "description": "Continuous integration"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-30T14:55:50Z", "updated_at": "2020-08-16T15:19:58Z", "closed_at": "2020-08-16T15:19:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\n\r\nRunning trainer.test(model) using DDp without running trainer.fit hangs.\r\n\r\n### To Reproduce\r\n\r\n```\r\nimport pytorch_lightning as pl\r\nimport torch\r\nfrom torch.utils.data import DataLoader, Dataset\r\nclass RandomDataset(Dataset):\r\n    def __init__(self, num_samples=100, dim=5):\r\n        self.num_samples = num_samples\r\n        self.dim = dim\r\n    def __len__(self):\r\n        return self.num_samples\r\n    def __getitem__(self, item):\r\n        x = torch.rand(self.dim)\r\n        y = x.sum()\r\n        return x, y\r\nclass Model(pl.LightningModule):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        self.layer = torch.nn.Linear(5, 1)\r\n    def forward(self, x):\r\n        y = self.layer(x)\r\n        return y\r\n    def configure_optimizers(self):\r\n        optimizer = torch.optim.Adam(self.parameters(), lr=0.1)\r\n        return optimizer\r\n    def train_dataloader(self):\r\n        return DataLoader(\r\n            dataset=RandomDataset(num_samples=100, dim=5),\r\n            batch_size=32,\r\n        )\r\n    def test_dataloader(self):\r\n        return DataLoader(\r\n            dataset=RandomDataset(num_samples=64, dim=5),\r\n            batch_size=8\r\n        )\r\n    def training_step(self, batch, batch_idx, optimizer_idx=0):\r\n        x, y = batch\r\n        x = x.view(-1, 5)\r\n        y = y.view(-1, 1)\r\n        y_dash = self(x)\r\n        loss = ((y - y_dash) ** 2).sum()\r\n        return {'loss': loss, 'log': {'train_loss': loss / x.size(0)}}\r\n    def test_step(self, batch, batch_idx, dataloader_idx=0):\r\n        return self.training_step(batch, batch_idx)\r\n    def test_epoch_end(self, outputs):\r\n        loss = torch.stack([log['loss'] for log in outputs]).mean()\r\n        return {'test_loss': loss}\r\nif __name__ == '__main__':\r\n    model = Model()\r\n    trainer = pl.Trainer(\r\n        max_steps=20,\r\n        amp_level='O1',\r\n        gpus=2,\r\n        precision=16,\r\n        distributed_backend='ddp'\r\n    )\r\n    # comment below / remove comment below\r\n    # trainer.fit(model)\r\n    trainer.test(model)\r\n```\r\n\r\n### Expected behavior\r\nShould be able to run test with DDP.\r\n\r\n### Environment\r\n\r\n - PyTorch Version (e.g., 1.0): 1.5\r\n - PL: 0.8.5\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2763", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2763/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2763/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2763/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2763", "id": 668668932, "node_id": "MDU6SXNzdWU2Njg2Njg5MzI=", "number": 2763, "title": "Docs : Introduction Guide, test_dataloader wrong sequence length in random_split", "user": {"login": "codeloop", "id": 17523722, "node_id": "MDQ6VXNlcjE3NTIzNzIy", "avatar_url": "https://avatars0.githubusercontent.com/u/17523722?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codeloop", "html_url": "https://github.com/codeloop", "followers_url": "https://api.github.com/users/codeloop/followers", "following_url": "https://api.github.com/users/codeloop/following{/other_user}", "gists_url": "https://api.github.com/users/codeloop/gists{/gist_id}", "starred_url": "https://api.github.com/users/codeloop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codeloop/subscriptions", "organizations_url": "https://api.github.com/users/codeloop/orgs", "repos_url": "https://api.github.com/users/codeloop/repos", "events_url": "https://api.github.com/users/codeloop/events{/privacy}", "received_events_url": "https://api.github.com/users/codeloop/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1840917107, "node_id": "MDU6TGFiZWwxODQwOTE3MTA3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/documentation", "name": "documentation", "color": "0075ca", "default": true, "description": "Improvements or additions to documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-30T12:22:44Z", "updated_at": "2020-07-31T09:38:43Z", "closed_at": "2020-07-31T09:38:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "[Docs : Introduction Guide](https://pytorch-lightning.readthedocs.io/en/stable/introduction_guide.html#testing), test_dataloader \r\nFor the MNIST dataset, The training set contains 60000 examples, and the test set 10000 examples.\r\n while creating the test_dataloader, in the code\r\n```\r\nmnist_train = MNIST(os.getcwd(), train=False, download=False, transform=transform)\r\n```\r\nthe train is set to false, so it reads from the test set which only has 10000 examples, hence the next step causes it to fail as we make a split of 55k & 5k examples.\r\n```\r\n_, mnist_val = random_split(mnist_train, [55000, 5000])\r\n```\r\nwith error\r\n```\r\nValueError: Sum of input lengths does not equal the length of the input dataset!\r\n```\r\n\r\nbest way to resolve it would be to remove the random_split call & return the complete test data from the test_dataloadet", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2761", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2761/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2761/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2761/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2761", "id": 668658453, "node_id": "MDU6SXNzdWU2Njg2NTg0NTM=", "number": 2761, "title": "0.8.1 keeps writing into \"version_0\" folder instead of creating new version_1/2/3... ", "user": {"login": "AAnoosheh", "id": 5615503, "node_id": "MDQ6VXNlcjU2MTU1MDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/5615503?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AAnoosheh", "html_url": "https://github.com/AAnoosheh", "followers_url": "https://api.github.com/users/AAnoosheh/followers", "following_url": "https://api.github.com/users/AAnoosheh/following{/other_user}", "gists_url": "https://api.github.com/users/AAnoosheh/gists{/gist_id}", "starred_url": "https://api.github.com/users/AAnoosheh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AAnoosheh/subscriptions", "organizations_url": "https://api.github.com/users/AAnoosheh/orgs", "repos_url": "https://api.github.com/users/AAnoosheh/repos", "events_url": "https://api.github.com/users/AAnoosheh/events{/privacy}", "received_events_url": "https://api.github.com/users/AAnoosheh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1800433344, "node_id": "MDU6TGFiZWwxODAwNDMzMzQ0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/information%20needed", "name": "information needed", "color": "b673dd", "default": false, "description": "need more information about this"}], "state": "closed", "locked": false, "assignee": {"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "awaelchli", "id": 5495193, "node_id": "MDQ6VXNlcjU0OTUxOTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/5495193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awaelchli", "html_url": "https://github.com/awaelchli", "followers_url": "https://api.github.com/users/awaelchli/followers", "following_url": "https://api.github.com/users/awaelchli/following{/other_user}", "gists_url": "https://api.github.com/users/awaelchli/gists{/gist_id}", "starred_url": "https://api.github.com/users/awaelchli/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awaelchli/subscriptions", "organizations_url": "https://api.github.com/users/awaelchli/orgs", "repos_url": "https://api.github.com/users/awaelchli/repos", "events_url": "https://api.github.com/users/awaelchli/events{/privacy}", "received_events_url": "https://api.github.com/users/awaelchli/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-07-30T12:09:05Z", "updated_at": "2020-08-04T21:08:59Z", "closed_at": "2020-08-04T21:08:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "0.7.6 (I believe) would properly create a new \"version_X\" folder per run, but since upgrading to 0.8.1, it no longer does this.\r\n\r\nHere's my logging-related code in my train script, which are then passed onto Trainer:\r\n```\r\n    # custom logging directory\r\n    logger = pl.loggers.TestTubeLogger(\r\n        save_dir=logging_dir,\r\n        name=args.name\r\n    )\r\n    log_ckpt = pl.callbacks.ModelCheckpoint(save_top_k=-1, verbose=True)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2753", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2753/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2753/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2753/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2753", "id": 667996267, "node_id": "MDU6SXNzdWU2Njc5OTYyNjc=", "number": 2753, "title": "Correctly using IoU and ConfusionMatrix", "user": {"login": "remisphere", "id": 37183535, "node_id": "MDQ6VXNlcjM3MTgzNTM1", "avatar_url": "https://avatars3.githubusercontent.com/u/37183535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/remisphere", "html_url": "https://github.com/remisphere", "followers_url": "https://api.github.com/users/remisphere/followers", "following_url": "https://api.github.com/users/remisphere/following{/other_user}", "gists_url": "https://api.github.com/users/remisphere/gists{/gist_id}", "starred_url": "https://api.github.com/users/remisphere/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/remisphere/subscriptions", "organizations_url": "https://api.github.com/users/remisphere/orgs", "repos_url": "https://api.github.com/users/remisphere/repos", "events_url": "https://api.github.com/users/remisphere/events{/privacy}", "received_events_url": "https://api.github.com/users/remisphere/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2237141533, "node_id": "MDU6TGFiZWwyMjM3MTQxNTMz", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Metrics", "name": "Metrics", "color": "ef4ae1", "default": false, "description": ""}, {"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": {"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-07-29T17:00:23Z", "updated_at": "2020-07-30T16:07:02Z", "closed_at": "2020-07-30T11:53:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n### Before asking:   \r\n- [x] search the issues.\r\n    - related: #2724\r\n- [x] search the docs.\r\n    - related: [confusion_matrix](https://pytorch-lightning.readthedocs.io/en/latest/metrics.html#confusion-matrix-f), [iou](https://pytorch-lightning.readthedocs.io/en/latest/metrics.html#iou-f)\r\n\r\n<!-- If you still can't find what you need: -->\r\n\r\n#### What is your question?\r\nHello,\r\nI've been trying to use the [IoU](url) and [ConfusionMatrix](url) metrics for semantic segmentation, but I can't wrap my head around their implementation in PL and their intended usage.\r\nThey seem to assume that every class is present in at least the prediction or the target [[1](https://github.com/PyTorchLightning/pytorch-lightning/blob/0.9.0rc3/pytorch_lightning/metrics/functional/classification.py#L957), [2](https://github.com/PyTorchLightning/pytorch-lightning/blob/0.9.0rc3/pytorch_lightning/metrics/functional/classification.py#L174-L175), [**3**](https://github.com/PyTorchLightning/pytorch-lightning/blob/0.9.0rc3/pytorch_lightning/metrics/functional/classification.py#L85-L93)] (*actually it looks for the max class index*), which is a rather strange expectation to me.\r\nWith this assumption, they have variable return sizes, depending on what classes are missing in the batch (this was noticed by #2724).\r\nIoU has a `num_classes` argument, but it is only used to throw warnings if the above expectation is not met.\r\nThe docs give very basic examples that are not in the context of a training loop and are thus outside the scope of computing the metrics over several batches.\r\n\r\nHow then do I get the IoUs (or confusion matrix) on my dataset, since it's not possible to average them as they don't have the same shape?\r\n\r\n#### What have you tried?\r\nFor IoU, using the default `reduction='elementwise_mean'` prevent crashing, but I then get the mean IoU over the classes, and that is not what I want.\r\n\r\n#### What's your environment?\r\n\r\n - OS: Linux\r\n - Packaging: pip\r\n - Version: 0.9.0rc3\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2751", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2751/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2751/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2751/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2751", "id": 667883984, "node_id": "MDU6SXNzdWU2Njc4ODM5ODQ=", "number": 2751, "title": "[DataModule] Datamodule setup in docs shows non-existent stage arg", "user": {"login": "ydcjeff", "id": 32727188, "node_id": "MDQ6VXNlcjMyNzI3MTg4", "avatar_url": "https://avatars3.githubusercontent.com/u/32727188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ydcjeff", "html_url": "https://github.com/ydcjeff", "followers_url": "https://api.github.com/users/ydcjeff/followers", "following_url": "https://api.github.com/users/ydcjeff/following{/other_user}", "gists_url": "https://api.github.com/users/ydcjeff/gists{/gist_id}", "starred_url": "https://api.github.com/users/ydcjeff/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ydcjeff/subscriptions", "organizations_url": "https://api.github.com/users/ydcjeff/orgs", "repos_url": "https://api.github.com/users/ydcjeff/repos", "events_url": "https://api.github.com/users/ydcjeff/events{/privacy}", "received_events_url": "https://api.github.com/users/ydcjeff/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1840917107, "node_id": "MDU6TGFiZWwxODQwOTE3MTA3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/documentation", "name": "documentation", "color": "0075ca", "default": true, "description": "Improvements or additions to documentation"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-29T14:20:23Z", "updated_at": "2020-07-31T16:12:40Z", "closed_at": "2020-07-31T16:12:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n### To Reproduce\r\n\r\n[Colab Minimal code](https://colab.research.google.com/drive/1nzVh8xeEGLOJvSZ0Ih7WccNHgI1gDzaD?usp=sharing)\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n\r\n### Expected behavior\r\n\r\nDataModule should call `prepare_data` and `setup`\r\n\r\n### Environment\r\n\r\n- Colab\r\n\r\n### Additional context\r\n\r\nPL Version: 0.9.0rc3\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2749", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2749/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2749/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2749/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2749", "id": 667760404, "node_id": "MDU6SXNzdWU2Njc3NjA0MDQ=", "number": 2749, "title": "[DataModule] PyTorch datasets as DataModules out of the box", "user": {"login": "InCogNiTo124", "id": 12953598, "node_id": "MDQ6VXNlcjEyOTUzNTk4", "avatar_url": "https://avatars2.githubusercontent.com/u/12953598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/InCogNiTo124", "html_url": "https://github.com/InCogNiTo124", "followers_url": "https://api.github.com/users/InCogNiTo124/followers", "following_url": "https://api.github.com/users/InCogNiTo124/following{/other_user}", "gists_url": "https://api.github.com/users/InCogNiTo124/gists{/gist_id}", "starred_url": "https://api.github.com/users/InCogNiTo124/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/InCogNiTo124/subscriptions", "organizations_url": "https://api.github.com/users/InCogNiTo124/orgs", "repos_url": "https://api.github.com/users/InCogNiTo124/repos", "events_url": "https://api.github.com/users/InCogNiTo124/events{/privacy}", "received_events_url": "https://api.github.com/users/InCogNiTo124/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2065663816, "node_id": "MDU6TGFiZWwyMDY1NjYzODE2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Important", "name": "Important", "color": "FFD700", "default": false, "description": "High important task, global impact"}, {"id": 1862633788, "node_id": "MDU6TGFiZWwxODYyNjMzNzg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/discussion", "name": "discussion", "color": "f29579", "default": false, "description": "Open discussion -> towards a conclusion"}, {"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "InCogNiTo124", "id": 12953598, "node_id": "MDQ6VXNlcjEyOTUzNTk4", "avatar_url": "https://avatars2.githubusercontent.com/u/12953598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/InCogNiTo124", "html_url": "https://github.com/InCogNiTo124", "followers_url": "https://api.github.com/users/InCogNiTo124/followers", "following_url": "https://api.github.com/users/InCogNiTo124/following{/other_user}", "gists_url": "https://api.github.com/users/InCogNiTo124/gists{/gist_id}", "starred_url": "https://api.github.com/users/InCogNiTo124/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/InCogNiTo124/subscriptions", "organizations_url": "https://api.github.com/users/InCogNiTo124/orgs", "repos_url": "https://api.github.com/users/InCogNiTo124/repos", "events_url": "https://api.github.com/users/InCogNiTo124/events{/privacy}", "received_events_url": "https://api.github.com/users/InCogNiTo124/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "InCogNiTo124", "id": 12953598, "node_id": "MDQ6VXNlcjEyOTUzNTk4", "avatar_url": "https://avatars2.githubusercontent.com/u/12953598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/InCogNiTo124", "html_url": "https://github.com/InCogNiTo124", "followers_url": "https://api.github.com/users/InCogNiTo124/followers", "following_url": "https://api.github.com/users/InCogNiTo124/following{/other_user}", "gists_url": "https://api.github.com/users/InCogNiTo124/gists{/gist_id}", "starred_url": "https://api.github.com/users/InCogNiTo124/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/InCogNiTo124/subscriptions", "organizations_url": "https://api.github.com/users/InCogNiTo124/orgs", "repos_url": "https://api.github.com/users/InCogNiTo124/repos", "events_url": "https://api.github.com/users/InCogNiTo124/events{/privacy}", "received_events_url": "https://api.github.com/users/InCogNiTo124/received_events", "type": "User", "site_admin": false}, {"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2020-07-29T11:12:17Z", "updated_at": "2020-07-29T20:29:46Z", "closed_at": "2020-07-29T20:29:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\nPyTorch already has datasets (MNIST, CIFAR, etc). It would be very convenient to provide those datasets out of the box as DataModules\r\n\r\n### Motivation\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\nTo reduce the boilerplate. I mean, if I had the possibility not to reimplement / copy-paste the same code again, I would rather not do that, and I'd use the already implemented solutions. The entire PyTorchLightning was built with this in mind, so this is only natural.\r\n\r\n### Pitch\r\n<!-- A clear and concise description of what you want to happen. -->\r\nTo have the ability to write something along the lines of\r\n```python3\r\nimport pytorch_lightning as pl\r\nimport pytorch_lightning.datasets as pld\r\n\r\n# implementation of model and trainer instantiation\r\ntrainer.fit(model, pld.MNIST())\r\n```\r\n\r\n### Alternatives\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, if any. -->\r\nAlternatively, it could be implemented as a PyTorchLightning Bolt, instead of here.\r\n\r\n### Additional context\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\nNone", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2742", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2742/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2742/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2742/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2742", "id": 667185915, "node_id": "MDU6SXNzdWU2NjcxODU5MTU=", "number": 2742, "title": "[DataModule] `prepare_data()` and `setup()` not called", "user": {"login": "remisphere", "id": 37183535, "node_id": "MDQ6VXNlcjM3MTgzNTM1", "avatar_url": "https://avatars3.githubusercontent.com/u/37183535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/remisphere", "html_url": "https://github.com/remisphere", "followers_url": "https://api.github.com/users/remisphere/followers", "following_url": "https://api.github.com/users/remisphere/following{/other_user}", "gists_url": "https://api.github.com/users/remisphere/gists{/gist_id}", "starred_url": "https://api.github.com/users/remisphere/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/remisphere/subscriptions", "organizations_url": "https://api.github.com/users/remisphere/orgs", "repos_url": "https://api.github.com/users/remisphere/repos", "events_url": "https://api.github.com/users/remisphere/events{/privacy}", "received_events_url": "https://api.github.com/users/remisphere/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 2244367919, "node_id": "MDU6TGFiZWwyMjQ0MzY3OTE5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/data", "name": "data", "color": "d38a45", "default": false, "description": "data, datasets datamodule, ..."}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "nateraw", "id": 32437151, "node_id": "MDQ6VXNlcjMyNDM3MTUx", "avatar_url": "https://avatars0.githubusercontent.com/u/32437151?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateraw", "html_url": "https://github.com/nateraw", "followers_url": "https://api.github.com/users/nateraw/followers", "following_url": "https://api.github.com/users/nateraw/following{/other_user}", "gists_url": "https://api.github.com/users/nateraw/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateraw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateraw/subscriptions", "organizations_url": "https://api.github.com/users/nateraw/orgs", "repos_url": "https://api.github.com/users/nateraw/repos", "events_url": "https://api.github.com/users/nateraw/events{/privacy}", "received_events_url": "https://api.github.com/users/nateraw/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-28T15:54:40Z", "updated_at": "2020-08-02T00:17:58Z", "closed_at": "2020-08-02T00:17:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nIt seems that when using DataModule to separate training logic and data loading,\r\nof the [five methods](https://pytorch-lightning.readthedocs.io/en/latest/datamodules.html#methods) that should be called that are\r\n`prepare_data()`, `setup()`, `train_dataloader()`, `val_dataloader()` and `test_dataloader()`,\r\nonly the last three are actually used, witch is problematic since the datasets used by the data-loaders should be assigned in the `setup()`.\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\nRun this:\r\n#### Code sample\r\n```python\r\nimport torch\r\nfrom pytorch_lightning import LightningDataModule\r\nfrom pytorch_lightning.core.lightning import LightningModule\r\nfrom pytorch_lightning.trainer import Trainer\r\nfrom torch.nn import L1Loss, Linear\r\nfrom torch.optim import SGD\r\nfrom torch.utils.data import DataLoader\r\n\r\n\r\nclass MyDataModule(LightningDataModule):\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n\r\n    def prepare_data(self):\r\n        print('in prepare_data, '\r\n              'this should be called before train_dataloader() but is not.')\r\n\r\n    def setup(self, stage):\r\n        print('in setup, '\r\n              'this should be called before train_dataloader() but is not.')\r\n        self.train_dataset = 'whatever'\r\n\r\n    def train_dataloader(self):\r\n        print('in train_dataloader')\r\n        return DataLoader(self.train_dataset)\r\n\r\n\r\nclass MyLightningModule(LightningModule):\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer = Linear(1, 1)\r\n        self.loss_function = L1Loss()\r\n\r\n    def forward(self, x):\r\n        return self.layer(x)\r\n\r\n    def configure_optimizers(self):\r\n        return SGD(self.parameters(), lr=0.01)\r\n\r\n    def training_step(self, batch, batch_idx):\r\n        print(\"you won't even get here\")\r\n        raise NotImplementedError\r\n\r\n\r\ndata_module = MyDataModule()\r\nmodel = MyLightningModule()\r\ntrainer = Trainer(gpus=1)\r\ntrainer.fit(model, data_module)\r\n```\r\nthis gives `AttributeError: 'MyDataModule' object has no attribute 'train_dataset'`.\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\n\r\n### Expected behavior\r\nWhen entering `train_dataloader()`, `prepare_data()` and `setup()` should already have been executed, and thus the `train_dataset` attribute should exist.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n### Additional context\r\n\r\nIMHO, it comes from [**here**](https://github.com/PyTorchLightning/pytorch-lightning/blob/590e7fb1fd1729b732128b3b96c919ebdf524077/pytorch_lightning/trainer/trainer.py#L1161-L1167)\r\n\r\n### Environment\r\n\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- GeForce RTX 2080 Ti\r\n\t\t- GeForce RTX 2080 Ti\r\n\t- available:         True\r\n\t- version:           10.1\r\n* Packages:\r\n\t- numpy:             1.19.1\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.5.1+cu101\r\n\t- pytorch-lightning: 0.9.0rc2\r\n\t- tensorboard:       2.3.0\r\n\t- tqdm:              4.48.0\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t- processor:         x86_64\r\n\t- python:            3.7.6\r\n\t- version:           #41-Ubuntu SMP Tue Dec 3 00:27:35 UTC 2019\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2737", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2737/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2737/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2737/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2737", "id": 667161436, "node_id": "MDU6SXNzdWU2NjcxNjE0MzY=", "number": 2737, "title": "How to configure steps of multiple optimizers for GANs", "user": {"login": "sergevkim", "id": 6839130, "node_id": "MDQ6VXNlcjY4MzkxMzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/6839130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sergevkim", "html_url": "https://github.com/sergevkim", "followers_url": "https://api.github.com/users/sergevkim/followers", "following_url": "https://api.github.com/users/sergevkim/following{/other_user}", "gists_url": "https://api.github.com/users/sergevkim/gists{/gist_id}", "starred_url": "https://api.github.com/users/sergevkim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sergevkim/subscriptions", "organizations_url": "https://api.github.com/users/sergevkim/orgs", "repos_url": "https://api.github.com/users/sergevkim/repos", "events_url": "https://api.github.com/users/sergevkim/events{/privacy}", "received_events_url": "https://api.github.com/users/sergevkim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-28T15:22:06Z", "updated_at": "2020-07-29T05:46:58Z", "closed_at": "2020-07-29T05:46:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\ude80 Feature\r\nCustom number of steps in generator and discriminator\r\n\r\n### Motivation\r\nI've spent a lot of time looking for some example of using different number of steps for G and D, but I didn't find anything.\r\nHowever, GANs are very capricious. Is it possible to append this feature?\r\n\r\nMaybe I missed it. Can you give me an example of how to use it?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2733", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2733/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2733/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2733/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2733", "id": 666864335, "node_id": "MDU6SXNzdWU2NjY4NjQzMzU=", "number": 2733, "title": "AttributeError: module 'pytorch_lightning' has no attribute 'LightningDataModule'", "user": {"login": "odats", "id": 944379, "node_id": "MDQ6VXNlcjk0NDM3OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/944379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/odats", "html_url": "https://github.com/odats", "followers_url": "https://api.github.com/users/odats/followers", "following_url": "https://api.github.com/users/odats/following{/other_user}", "gists_url": "https://api.github.com/users/odats/gists{/gist_id}", "starred_url": "https://api.github.com/users/odats/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/odats/subscriptions", "organizations_url": "https://api.github.com/users/odats/orgs", "repos_url": "https://api.github.com/users/odats/repos", "events_url": "https://api.github.com/users/odats/events{/privacy}", "received_events_url": "https://api.github.com/users/odats/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-28T08:16:04Z", "updated_at": "2020-08-16T22:31:15Z", "closed_at": "2020-07-28T19:53:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "Name: pytorch-lightning\r\nVersion: 0.8.5\r\n\r\n<img width=\"670\" alt=\"Screenshot 2020-07-28 at 11 13 38\" src=\"https://user-images.githubusercontent.com/944379/88638111-b6112b00-d0c3-11ea-88dd-f07947d21986.png\">\r\n\r\nfollowing latest doc: https://pytorch-lightning.readthedocs.io/_/downloads/en/latest/pdf/", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2730", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2730/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2730/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2730/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2730", "id": 666666981, "node_id": "MDU6SXNzdWU2NjY2NjY5ODE=", "number": 2730, "title": "Horovod and Native Amp not work", "user": {"login": "zhenhuahu", "id": 11988890, "node_id": "MDQ6VXNlcjExOTg4ODkw", "avatar_url": "https://avatars3.githubusercontent.com/u/11988890?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhenhuahu", "html_url": "https://github.com/zhenhuahu", "followers_url": "https://api.github.com/users/zhenhuahu/followers", "following_url": "https://api.github.com/users/zhenhuahu/following{/other_user}", "gists_url": "https://api.github.com/users/zhenhuahu/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhenhuahu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhenhuahu/subscriptions", "organizations_url": "https://api.github.com/users/zhenhuahu/orgs", "repos_url": "https://api.github.com/users/zhenhuahu/repos", "events_url": "https://api.github.com/users/zhenhuahu/events{/privacy}", "received_events_url": "https://api.github.com/users/zhenhuahu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-28T00:29:43Z", "updated_at": "2020-07-29T20:22:15Z", "closed_at": "2020-07-29T20:22:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "##\ud83d\udc1b Bug\r\nI'm no sure if there is a bug. But when I was tryng to use Horovod as backend to do native amp in PyTorch 1.6, Lightning always points to the function that uses apex amp instead.\r\n\r\n### To Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Go to 'trainer/distrib_parts.py'\r\n2. Run '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n![torch16_horovod_error](https://user-images.githubusercontent.com/11988890/88603491-12803600-d043-11ea-8b9b-31193cf900e3.png)\r\n\r\n\r\n#### Code sample\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\ntrainer = pl.Trainer(gpus=1, num_nodes = 1, distributed_backend='horovod', precision = 16)\r\ntrainer.fit(generator, train_dataloader=train_loader, val_dataloaders=val_loader)\r\n\r\nI tried to run it like: horovodrun  --verbose -np 32 -H server1-0:8,server2-0:8,server3-0:8,server4-0:8     python file.py\r\n### Expected behavior\r\n\r\nUse native amp when trying to launch Horovod in PyTorch 1.6.\r\n\r\n### Environment\r\n\r\nPlease copy and paste the output from our\r\n[environment collection script](https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py)\r\n(or fill out the checklist below manually).\r\n\r\nYou can get the script and run it with:\r\n```\r\nwget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py\r\n# For security purposes, please check the contents of collect_env_details.py before running it.\r\npython collect_env_details.py\r\n```\r\n CUDA:\r\n\t- GPU:\r\n\t\t- Tesla V100-SXM2-32GB\r\n\t\t- Tesla V100-SXM2-32GB\r\n\t\t- Tesla V100-SXM2-32GB\r\n\t\t- Tesla V100-SXM2-32GB\r\n\t\t- Tesla V100-SXM2-32GB\r\n\t\t- Tesla V100-SXM2-32GB\r\n\t\t- Tesla V100-SXM2-32GB\r\n\t\t- Tesla V100-SXM2-32GB\r\n\t- available:         True\r\n\t- version:           10.1\r\n* Packages:\r\n\t- numpy:             1.19.1\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.6.0.dev20200623+cu101\r\n\t- pytorch-lightning: 0.8.5\r\n\t- tensorboard:       2.3.0\r\n\t- tqdm:              4.48.0\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- \r\n\t- processor:         x86_64\r\n\t- python:            3.6.9\r\n\t- version:           #83~16.04.1-Ubuntu SMP Wed Dec 18 04:56:23 UTC 2019\r\n\r\n - How you installed PyTorch (`conda`, `pip`, source): pip\r\n - cuDNN version: 7.6.5\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2725", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2725/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2725/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2725/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2725", "id": 666427337, "node_id": "MDU6SXNzdWU2NjY0MjczMzc=", "number": 2725, "title": "How to access wandb logging directory from lightning?", "user": {"login": "topshik", "id": 6764141, "node_id": "MDQ6VXNlcjY3NjQxNDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6764141?v=4", "gravatar_id": "", "url": "https://api.github.com/users/topshik", "html_url": "https://github.com/topshik", "followers_url": "https://api.github.com/users/topshik/followers", "following_url": "https://api.github.com/users/topshik/following{/other_user}", "gists_url": "https://api.github.com/users/topshik/gists{/gist_id}", "starred_url": "https://api.github.com/users/topshik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/topshik/subscriptions", "organizations_url": "https://api.github.com/users/topshik/orgs", "repos_url": "https://api.github.com/users/topshik/repos", "events_url": "https://api.github.com/users/topshik/events{/privacy}", "received_events_url": "https://api.github.com/users/topshik/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2253758944, "node_id": "MDU6TGFiZWwyMjUzNzU4OTQ0", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/Logger", "name": "Logger", "color": "f2b6b0", "default": false, "description": ""}, {"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-27T16:33:29Z", "updated_at": "2020-08-04T20:26:22Z", "closed_at": "2020-08-02T19:41:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "## I want to solve simple task: store .yaml config file in the same folder where checkpoints are saved\r\n\r\nI'm using following tools:\r\n1. lightning\r\n2. hydra for reading configs\r\n3. lightning wandb logging interface\r\n\r\nI see following options:\r\n1. save everything with hydra to it's `outputs` directory. \r\n  Pros: directory is easily accessible with `os.getcwd()`, so everything can be managed manually if needed\r\n  Cons: wandb logs are in the separate folder; default checkpoints directory is another (third already) directory, automatically created by lightning\r\n2. save logs, config.yaml and checkpoints to local wandb run directory\r\n  Pros: everything you need is in one place and can be easily analysed or accessed, not spawning to much separate logging directories\r\n  Cons: directory with wandb logs is not accessible from runtime (or, better say, hidden very well), so I can't save anything there. Despite it is possible to set wandb directory manually, I don't want to do it, because it will force me to recreate it for every model launch.\r\n\r\nI've tried to google hardly, searching for the best solution, which works with checkpointing callback and wandb logger, but I ended up with saving both checkpoints and .yaml file to hydra directory, which is created for current run.\r\n\r\nMy current solution is bad, because it stores different logging entities in different places. Moreover, DDP spawns two hydra folders for a run, but that's for another issue, I suppose.\r\n\r\n#### Code\r\n```\r\n@hydra.main(config_path=\"train-config.yaml\", strict=False)\r\ndef train(config: DictConfig) -> None:\r\n    config.hydra_base_dir = os.getcwd()\r\n    original_wd = hydra.utils.get_original_cwd()\r\n    os.chdir(original_wd)\r\n\r\n    checkpoint_callback = ModelCheckpoint(\r\n        filepath=config.hydra_base_dir,\r\n        save_top_k=3,\r\n        verbose=True,\r\n        monitor=\"val_loss\",\r\n        mode=\"min\",\r\n    )\r\n    shutil.copy2(\"train-config.yaml\", os.path.join(config.hydra_base_dir, \"train-config.yaml\"))\r\n\r\n    wandb_logger = WandbLogger(\r\n        offline=False,\r\n    )\r\n\r\n    model = MyModel(config)\r\n\r\n    trainer = pl.Trainer(\r\n        max_epochs=config.train.max_epochs,\r\n        gpus=config.train.n_gpu,\r\n        auto_select_gpus=True,\r\n        distributed_backend=\"ddp\",\r\n        checkpoint_callback=checkpoint_callback,\r\n        logger=wandb_logger,\r\n    )\r\n\r\n    trainer.fit(model)\r\n\r\n```\r\n\r\n### P.S.\r\n1. I know that wandb saves configs locally to it's folder, but it is still separate from checkpoints. Moreover, it stores config in the format, which should be processed to acquire the structre of original config file.\r\n2. I also know that lightning checkpoint contains model parameters in `hparams` field, but the goal is to store run config in the separate file. \r\n\r\n#### Environment?\r\n\r\n - OS: Ubuntu 18.04\r\n - Conda, Python 3.7.7\r\n - hydra-core==0.11.3\r\n- pytorch-lightning==0.8.5\r\n- wandb==0.9.3\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2722", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2722/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2722/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2722/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2722", "id": 666150427, "node_id": "MDU6SXNzdWU2NjYxNTA0Mjc=", "number": 2722, "title": "Slow accuracy metric", "user": {"login": "Diuven", "id": 9127047, "node_id": "MDQ6VXNlcjkxMjcwNDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/9127047?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Diuven", "html_url": "https://github.com/Diuven", "followers_url": "https://api.github.com/users/Diuven/followers", "following_url": "https://api.github.com/users/Diuven/following{/other_user}", "gists_url": "https://api.github.com/users/Diuven/gists{/gist_id}", "starred_url": "https://api.github.com/users/Diuven/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Diuven/subscriptions", "organizations_url": "https://api.github.com/users/Diuven/orgs", "repos_url": "https://api.github.com/users/Diuven/repos", "events_url": "https://api.github.com/users/Diuven/events{/privacy}", "received_events_url": "https://api.github.com/users/Diuven/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090688, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg4", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "justusschock", "id": 12886177, "node_id": "MDQ6VXNlcjEyODg2MTc3", "avatar_url": "https://avatars1.githubusercontent.com/u/12886177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justusschock", "html_url": "https://github.com/justusschock", "followers_url": "https://api.github.com/users/justusschock/followers", "following_url": "https://api.github.com/users/justusschock/following{/other_user}", "gists_url": "https://api.github.com/users/justusschock/gists{/gist_id}", "starred_url": "https://api.github.com/users/justusschock/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justusschock/subscriptions", "organizations_url": "https://api.github.com/users/justusschock/orgs", "repos_url": "https://api.github.com/users/justusschock/repos", "events_url": "https://api.github.com/users/justusschock/events{/privacy}", "received_events_url": "https://api.github.com/users/justusschock/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2020-07-27T09:52:56Z", "updated_at": "2020-08-06T09:40:36Z", "closed_at": "2020-08-06T09:40:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nAccuracy class from metrics.classification is too slow, compared to pytorch vanilla implementation.\r\n\r\n\r\n### To Reproduce\r\n\r\nTry the following demo code.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well -->\r\n\r\n\r\n#### Code sample\r\n<!-- Ideally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. -->\r\n\r\n\r\n```python3\r\nfrom time import time\r\nimport torch\r\nfrom pytorch_lightning.metrics.classification import Accuracy\r\n\r\n\r\ndef test_acc(pred, targ, get_acc, steps=1000, rep=10):\r\n    tsum, mean_res = 0, []\r\n    for i in range(rep):\r\n        res = []\r\n        ts = time()\r\n        for j in range(steps):\r\n            res.append(get_acc(pred, targ))\r\n        te = time()\r\n        tsum += te - ts\r\n        mean_acc = torch.stack(res).mean().item()\r\n        mean_res.append(mean_acc)\r\n    \r\n    return (tsum / rep), mean_res\r\n\r\n\r\ndef demo(batch_size=32, num_classes=10, device='cuda', steps=100, rep=5):\r\n    print(\"Testing  bs: %d,  num_cls: %d,  device: %s,  steps: %d,  rep: %d\" % (batch_size, num_classes, device, steps, rep))\r\n\r\n    pred = torch.randint(0, num_classes, (batch_size, )).to(device=device)\r\n    targ = torch.randint(0, num_classes, (batch_size, )).to(device=device)\r\n\r\n    pl_acc = Accuracy(num_classes=num_classes)\r\n    def pt_acc(pred, targ):\r\n        return pred.eq(targ).to(dtype=torch.float).mean()\r\n\r\n    pl_time, pl_res = test_acc(pred, targ, pl_acc, steps, rep)\r\n    pt_time, pt_res = test_acc(pred, targ, pt_acc, steps, rep)\r\n\r\n    if pl_res != pt_res:\r\n        print(\"Results mismatch!\")\r\n    print(\"Lightning: %2.6fs\" % pl_time)\r\n    print(\"Vanilla  : %2.6fs\" % pt_time)\r\n    print(\"\")\r\n\r\nif __name__ == \"__main__\":\r\n    demo(32, 10)\r\n    demo(512, 10)\r\n    demo(32, 100)\r\n    demo(512, 100)\r\n    demo(32, 1000)\r\n    demo(512, 1000)\r\n\r\n    demo(32, 10, 'cpu')\r\n    demo(512, 10, 'cpu')\r\n    demo(32, 100, 'cpu')\r\n    demo(512, 100, 'cpu')\r\n    demo(32, 1000, 'cpu')\r\n    demo(512, 1000, 'cpu')\r\n```\r\n\r\nOn my machine, the results are like the following.\r\n\r\n```\r\nTesting  bs: 32,  num_cls: 10,  device: cuda,  steps: 100,  rep: 5\r\nLightning: 0.378017s\r\nVanilla  : 0.002766s\r\n\r\nTesting  bs: 512,  num_cls: 10,  device: cuda,  steps: 100,  rep: 5\r\nLightning: 0.372391s\r\nVanilla  : 0.002776s\r\n\r\nTesting  bs: 32,  num_cls: 100,  device: cuda,  steps: 100,  rep: 5\r\nLightning: 3.346141s\r\nVanilla  : 0.002812s\r\n\r\nTesting  bs: 512,  num_cls: 100,  device: cuda,  steps: 100,  rep: 5\r\nLightning: 3.335049s\r\nVanilla  : 0.002660s\r\n\r\nTesting  bs: 32,  num_cls: 1000,  device: cuda,  steps: 100,  rep: 5\r\nLightning: 32.751692s\r\nVanilla  : 0.002666s\r\n\r\nTesting  bs: 512,  num_cls: 1000,  device: cuda,  steps: 100,  rep: 5\r\nLightning: 32.967594s\r\nVanilla  : 0.002762s\r\n\r\nTesting  bs: 32,  num_cls: 10,  device: cpu,  steps: 100,  rep: 5\r\nLightning: 0.128131s\r\nVanilla  : 0.001317s\r\n\r\nTesting  bs: 512,  num_cls: 10,  device: cpu,  steps: 100,  rep: 5\r\nLightning: 0.128481s\r\nVanilla  : 0.001403s\r\n\r\nTesting  bs: 32,  num_cls: 100,  device: cpu,  steps: 100,  rep: 5\r\nLightning: 1.117403s\r\nVanilla  : 0.001275s\r\n\r\nTesting  bs: 512,  num_cls: 100,  device: cpu,  steps: 100,  rep: 5\r\nLightning: 1.166188s\r\nVanilla  : 0.001330s\r\n\r\nTesting  bs: 32,  num_cls: 1000,  device: cpu,  steps: 100,  rep: 5\r\nLightning: 10.927701s\r\nVanilla  : 0.001229s\r\n\r\nTesting  bs: 512,  num_cls: 1000,  device: cpu,  steps: 100,  rep: 5\r\nLightning: 11.560013s\r\nVanilla  : 0.001310s\r\n```\r\n\r\n100x ~ 10000x more time is needed for pl's accuracy, depending on the num_classes argument.\r\n\r\n### Expected behavior\r\n\r\nPytorch-lightning's accuracy function should take similar time compared to the pytorch vanilla implementation, and it should not depend on num_classes too much.\r\n\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n### Environment\r\n\r\n```\r\n* CUDA:\r\n\t- GPU:\r\n\t\t- GeForce GTX 1050 Ti\r\n\t- available:         True\r\n\t- version:           10.2\r\n* Packages:\r\n\t- numpy:             1.19.0\r\n\t- pyTorch_debug:     False\r\n\t- pyTorch_version:   1.5.1\r\n\t- pytorch-lightning: 0.8.1\r\n\t- tensorboard:       2.2.2\r\n\t- tqdm:              4.47.0\r\n* System:\r\n\t- OS:                Linux\r\n\t- architecture:\r\n\t\t- 64bit\r\n\t\t- ELF\r\n\t- processor:         x86_64\r\n\t- python:            3.6.9\r\n\t- version:           #46~18.04.1-Ubuntu SMP Fri Jul 10 07:21:24 UTC 2020\r\n```\r\n\r\nI tested the same code from two other machines (each with 2080 ti and with V100), and they give similar results.\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\nI'm not sure this issue falls into the bug report or the feature request category. Please relocate this as you like. :)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2720", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2720/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2720/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2720/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2720", "id": 666003455, "node_id": "MDU6SXNzdWU2NjYwMDM0NTU=", "number": 2720, "title": "Does Pytorch-Lightning have a multiprocessing (or Joblib) module?", "user": {"login": "leockl", "id": 57784789, "node_id": "MDQ6VXNlcjU3Nzg0Nzg5", "avatar_url": "https://avatars2.githubusercontent.com/u/57784789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leockl", "html_url": "https://github.com/leockl", "followers_url": "https://api.github.com/users/leockl/followers", "following_url": "https://api.github.com/users/leockl/following{/other_user}", "gists_url": "https://api.github.com/users/leockl/gists{/gist_id}", "starred_url": "https://api.github.com/users/leockl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leockl/subscriptions", "organizations_url": "https://api.github.com/users/leockl/orgs", "repos_url": "https://api.github.com/users/leockl/repos", "events_url": "https://api.github.com/users/leockl/events{/privacy}", "received_events_url": "https://api.github.com/users/leockl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-27T06:02:27Z", "updated_at": "2020-07-31T15:08:16Z", "closed_at": "2020-07-31T15:08:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \u2753 Questions and Help\r\n\r\n#### What is your question?\r\n\r\nI have been googling around but can't seem to find if there is a `multiprocessing` module available in Pytorch-Lightning, just like how Pytorch has a `torch.multiprocessing` module.\r\n\r\nDoes anyone know if Pytorch-Lightning has this (or a `Joblib` similar) module? I am looking for a Pytorch-Lightning module which allows me to parallelize over multiple GPUs\r\n\r\nMany thanks in advance.\r\n\r\nPs. Sorry if this this the wrong place to post this question. I have posted the same question in Stackoverflow, but haven't received a reply. \r\n\r\n**Edit:** To be more specific, I am looking for a `multiprocessing` module in Pytorch-Lightning which allows me to parallelize over multiple GPUs on non-neural network computations, such as:\r\n```\r\nimport numpy as np\r\nimport torch\r\nfrom torch.multiprocessing import Pool\r\n\r\nX = np.array([[1, 3, 2, 3], [2, 3, 5, 6], [1, 2, 3, 4]])\r\nX = torch.DoubleTensor(X)\r\n\r\ndef X_power_func(j):\r\n    X_power = X.cuda()**j\r\n    return X_power\r\n\r\nif __name__ == '__main__':\r\n  with Pool(processes = 2) as p:   # Parallelizing over 2 GPUs\r\n    results = p.map(X_power_func, range(4))\r\n\r\nresults\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2717", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2717/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2717/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2717/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2717", "id": 665927177, "node_id": "MDU6SXNzdWU2NjU5MjcxNzc=", "number": 2717, "title": "TensorBoard logging in validation_step and test_step", "user": {"login": "Ceceu", "id": 11181748, "node_id": "MDQ6VXNlcjExMTgxNzQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11181748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ceceu", "html_url": "https://github.com/Ceceu", "followers_url": "https://api.github.com/users/Ceceu/followers", "following_url": "https://api.github.com/users/Ceceu/following{/other_user}", "gists_url": "https://api.github.com/users/Ceceu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ceceu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ceceu/subscriptions", "organizations_url": "https://api.github.com/users/Ceceu/orgs", "repos_url": "https://api.github.com/users/Ceceu/repos", "events_url": "https://api.github.com/users/Ceceu/events{/privacy}", "received_events_url": "https://api.github.com/users/Ceceu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-27T02:21:03Z", "updated_at": "2020-08-14T21:56:52Z", "closed_at": "2020-08-03T22:58:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "Even defining the log in all steps of the PL model:\r\n\r\n```python\r\n    def training_step(self, batch, batch_idx):\r\n        ...\r\n        # TensorBoard logging\r\n        log = {\"train_loss\": train_loss, \"train_mrr\": train_mrr}\r\n        return {'loss': train_loss, \"log\":log}\r\n\r\n    def test_step(self, batch, batch_idx):\r\n        ...\r\n        # TensorBoard logging\r\n        log = {\"test_loss\": test_loss, \"test_mrr\": test_mrr}\r\n        return {'test_loss': test_loss, 'log': log}\r\n\r\n    def validation_step(self, batch, batch_idx):\r\n        ...\r\n        # TensorBoard logging\r\n        log = {\"val_loss\": val_loss, \"val_mrr\": val_mrr}\r\n        return {'val_loss': val_loss, 'log': log}\r\n```\r\n\r\nI could visualize only the `train_loss` and `train_mrr` on TensorBoard. I mean, `test_loss` and `test_mrr` do not appear in TesorBoard. Similar behavior happens with `val_loss` and `val_mrr`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2716", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2716/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2716/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2716/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2716", "id": 665923433, "node_id": "MDU6SXNzdWU2NjU5MjM0MzM=", "number": 2716, "title": "Live long and prosper", "user": {"login": "Ceceu", "id": 11181748, "node_id": "MDQ6VXNlcjExMTgxNzQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11181748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ceceu", "html_url": "https://github.com/Ceceu", "followers_url": "https://api.github.com/users/Ceceu/followers", "following_url": "https://api.github.com/users/Ceceu/following{/other_user}", "gists_url": "https://api.github.com/users/Ceceu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ceceu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ceceu/subscriptions", "organizations_url": "https://api.github.com/users/Ceceu/orgs", "repos_url": "https://api.github.com/users/Ceceu/repos", "events_url": "https://api.github.com/users/Ceceu/events{/privacy}", "received_events_url": "https://api.github.com/users/Ceceu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-27T02:10:01Z", "updated_at": "2020-07-31T15:03:01Z", "closed_at": "2020-07-31T15:03:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "This issue is just to thank the PyTorch Lightning team. \r\n\r\nEven though my beginner knowledge over Pytorch and other Deep Learning frameworks, I was able to easily implement a quite complex model that is clearly written and completely reproducible.  \r\n\r\nI hope to contribute in some way in the near future.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2715", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2715/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2715/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2715/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2715", "id": 665835081, "node_id": "MDU6SXNzdWU2NjU4MzUwODE=", "number": 2715, "title": "When I call Trainer.test it calls both \"test\" and \"fit\" stages of setup - should it just be \"test\"", "user": {"login": "jloveric", "id": 5200721, "node_id": "MDQ6VXNlcjUyMDA3MjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5200721?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jloveric", "html_url": "https://github.com/jloveric", "followers_url": "https://api.github.com/users/jloveric/followers", "following_url": "https://api.github.com/users/jloveric/following{/other_user}", "gists_url": "https://api.github.com/users/jloveric/gists{/gist_id}", "starred_url": "https://api.github.com/users/jloveric/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jloveric/subscriptions", "organizations_url": "https://api.github.com/users/jloveric/orgs", "repos_url": "https://api.github.com/users/jloveric/repos", "events_url": "https://api.github.com/users/jloveric/events{/privacy}", "received_events_url": "https://api.github.com/users/jloveric/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "jloveric", "id": 5200721, "node_id": "MDQ6VXNlcjUyMDA3MjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5200721?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jloveric", "html_url": "https://github.com/jloveric", "followers_url": "https://api.github.com/users/jloveric/followers", "following_url": "https://api.github.com/users/jloveric/following{/other_user}", "gists_url": "https://api.github.com/users/jloveric/gists{/gist_id}", "starred_url": "https://api.github.com/users/jloveric/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jloveric/subscriptions", "organizations_url": "https://api.github.com/users/jloveric/orgs", "repos_url": "https://api.github.com/users/jloveric/repos", "events_url": "https://api.github.com/users/jloveric/events{/privacy}", "received_events_url": "https://api.github.com/users/jloveric/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jloveric", "id": 5200721, "node_id": "MDQ6VXNlcjUyMDA3MjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5200721?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jloveric", "html_url": "https://github.com/jloveric", "followers_url": "https://api.github.com/users/jloveric/followers", "following_url": "https://api.github.com/users/jloveric/following{/other_user}", "gists_url": "https://api.github.com/users/jloveric/gists{/gist_id}", "starred_url": "https://api.github.com/users/jloveric/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jloveric/subscriptions", "organizations_url": "https://api.github.com/users/jloveric/orgs", "repos_url": "https://api.github.com/users/jloveric/repos", "events_url": "https://api.github.com/users/jloveric/events{/privacy}", "received_events_url": "https://api.github.com/users/jloveric/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-26T18:26:50Z", "updated_at": "2020-07-31T15:31:23Z", "closed_at": "2020-07-31T15:31:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "## \ud83d\udc1b Bug\r\nWhen I call Trainer.test it calls both \"test\" and \"fit\" stages of \"setup\" function.  Shouldn't it just call test?\r\n\r\n### To Reproduce\r\n\r\nYou can actually look through the code to see that this will happen since self.fit() is called.  Follow trainer.test() then choose the function self.__test_given_model(model, test_dataloaders) and then self.fit(model) is called.  Also, you can just print out \"stage\" in the setup function and you will see both \"fit\" and \"test\" are called when trainer.test(model=model, test_dataloaders=dataloaders) is called.  I'm using the \"fit\" value for training, should I be using something else?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2714", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2714/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2714/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2714/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2714", "id": 665824062, "node_id": "MDU6SXNzdWU2NjU4MjQwNjI=", "number": 2714, "title": "Logging loss, metric, and figure to TensorBoard (over train, test and validation step)", "user": {"login": "Ceceu", "id": 11181748, "node_id": "MDQ6VXNlcjExMTgxNzQ4", "avatar_url": "https://avatars2.githubusercontent.com/u/11181748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ceceu", "html_url": "https://github.com/Ceceu", "followers_url": "https://api.github.com/users/Ceceu/followers", "following_url": "https://api.github.com/users/Ceceu/following{/other_user}", "gists_url": "https://api.github.com/users/Ceceu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ceceu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ceceu/subscriptions", "organizations_url": "https://api.github.com/users/Ceceu/orgs", "repos_url": "https://api.github.com/users/Ceceu/repos", "events_url": "https://api.github.com/users/Ceceu/events{/privacy}", "received_events_url": "https://api.github.com/users/Ceceu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1297090692, "node_id": "MDU6TGFiZWwxMjk3MDkwNjky", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/question", "name": "question", "color": "d876e3", "default": true, "description": "Further information is requested"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-07-26T17:21:12Z", "updated_at": "2020-08-03T22:58:58Z", "closed_at": "2020-08-03T22:58:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\nIn my research project the `training_step`, `test_step` and `validation_step_step` is implemented as follows:\r\n\r\n```python\r\n    def training_step(self, batch, batch_idx):\r\n        x1, x2 = batch[\"x1\"], batch[\"x2\"]\r\n        predict = self(x1, x2)\r\n        loss = self.loss_fn(predict, self.train_target)\r\n        figure, mrr_metric = self.mrr(predict) # custom metric\r\n        return {'loss': loss, 'progress_bar': {'test_mrr': mrr_metric}}\r\n```\r\n\r\nBut I couldn't find an approach to logging the `loss` value neither the `mrr_metric` using a logger like TensorBoard. \r\nIt would also be interesting to save the `figure` generated by the metrics in the logger as well.\r\n\r\nCurrently, the trainer is configured as:\r\n\r\n```python\r\n    tb_logger = pl_loggers.TensorBoardLogger(cfg.logs.path)\r\n    model = JointEncoder(config=cfg)\r\n\r\n    trainer = Trainer(\r\n         max_epochs=cfg.train.max_epochs,\r\n        gpus=1,\r\n        logger=tb_logger\r\n    )\r\n    trainer.fit(model)\r\n```\r\n\r\nHowever, after the training, I was not able to visualize even the loss variation on the TensorBoard.\r\n\r\nAny direction on this? \r\nThank you in advance.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2703", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2703/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2703/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/2703/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/2703", "id": 665598028, "node_id": "MDU6SXNzdWU2NjU1OTgwMjg=", "number": 2703, "title": "`replace_sampler_ddp` doesn't create a shuffled sampler", "user": {"login": "ibeltagy", "id": 2287797, "node_id": "MDQ6VXNlcjIyODc3OTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/2287797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibeltagy", "html_url": "https://github.com/ibeltagy", "followers_url": "https://api.github.com/users/ibeltagy/followers", "following_url": "https://api.github.com/users/ibeltagy/following{/other_user}", "gists_url": "https://api.github.com/users/ibeltagy/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibeltagy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibeltagy/subscriptions", "organizations_url": "https://api.github.com/users/ibeltagy/orgs", "repos_url": "https://api.github.com/users/ibeltagy/repos", "events_url": "https://api.github.com/users/ibeltagy/events{/privacy}", "received_events_url": "https://api.github.com/users/ibeltagy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2237125337, "node_id": "MDU6TGFiZWwyMjM3MTI1MzM3", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/DDP", "name": "DDP", "color": "33cc77", "default": false, "description": ""}, {"id": 1297090686, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg2", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/bug%20/%20fix", "name": "bug / fix", "color": "d73a4a", "default": false, "description": "Something isn't working"}, {"id": 1297090689, "node_id": "MDU6TGFiZWwxMjk3MDkwNjg5", "url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-25T14:49:27Z", "updated_at": "2020-08-02T03:22:58Z", "closed_at": "2020-08-02T03:22:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "<!-- \r\n### Common bugs:\r\n1. Tensorboard not showing in Jupyter-notebook see [issue 79](https://github.com/PyTorchLightning/pytorch-lightning/issues/79).    \r\n2. PyTorch 1.1.0 vs 1.2.0 support [see FAQ](https://github.com/PyTorchLightning/pytorch-lightning#faq)    \r\n-->\r\n\r\n## \ud83d\udc1b Bug\r\n\r\nThe `DistributedSampler` created using `replace_sampler_ddp` is not shuffled. Check the `kwargs` [here](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/data_loading.py#L195)\r\n\r\n### Expected behavior\r\n\r\nIf training dataloader, create a shuffled `DistributedSampler`, else create a non-shuffled sampler. Even though the `train` flag is passed to the function [here](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/data_loading.py#L146), it is ignored. \r\n\r\n### Environment\r\n\r\npytorch-lightning master", "performed_via_github_app": null, "score": 1.0}]}