{"total_count": 189, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/dask/dask-ml/issues/726", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/726/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/726/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/726/events", "html_url": "https://github.com/dask/dask-ml/issues/726", "id": 678774750, "node_id": "MDU6SXNzdWU2Nzg3NzQ3NTA=", "number": 726, "title": "OnehotEncoder should accept `categories` for dask dataframe", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-13T22:39:42Z", "updated_at": "2020-08-17T18:08:56Z", "closed_at": "2020-08-17T18:08:56Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Right now we raise with `ValueError: Cannot specify 'categories' with DataFrame input. Use a categorical dtype instead`, since we really want people to use Categorical, since it's impossible to get the wrong output shape with that. But perhaps we should trust the user?\r\n\r\nWill add an example later.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/721", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/721/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/721/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/721/events", "html_url": "https://github.com/dask/dask-ml/issues/721", "id": 674842707, "node_id": "MDU6SXNzdWU2NzQ4NDI3MDc=", "number": 721, "title": "HyperbandSearchCV not allow 3D input", "user": {"login": "sim-san", "id": 7436938, "node_id": "MDQ6VXNlcjc0MzY5Mzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/7436938?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sim-san", "html_url": "https://github.com/sim-san", "followers_url": "https://api.github.com/users/sim-san/followers", "following_url": "https://api.github.com/users/sim-san/following{/other_user}", "gists_url": "https://api.github.com/users/sim-san/gists{/gist_id}", "starred_url": "https://api.github.com/users/sim-san/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sim-san/subscriptions", "organizations_url": "https://api.github.com/users/sim-san/orgs", "repos_url": "https://api.github.com/users/sim-san/repos", "events_url": "https://api.github.com/users/sim-san/events{/privacy}", "received_events_url": "https://api.github.com/users/sim-san/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-07T08:08:12Z", "updated_at": "2020-08-09T20:12:40Z", "closed_at": "2020-08-09T20:12:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\r\n\r\nin this line the algorithm checks the input data:\r\nhttps://github.com/dask/dask-ml/blob/6eac8a0e48d09ee2670802cf9f48de63e2593460/dask_ml/model_selection/_split.py#L151\r\nAnd does not allow input data with more than two dimensions.\r\n\r\nmy suggestion is to add the following parameters to `check_array()`:\r\n- `ensure_2d=False`\r\n- `allow_nd=True`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/712", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/712/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/712/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/712/events", "html_url": "https://github.com/dask/dask-ml/issues/712", "id": 665428341, "node_id": "MDU6SXNzdWU2NjU0MjgzNDE=", "number": 712, "title": "CountVectorizer.fit_transform fails with remote vocabulary", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-24T21:29:48Z", "updated_at": "2020-08-05T18:20:51Z", "closed_at": "2020-08-05T18:20:51Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```python\r\nIn [1]: import dask.bag as db\r\n\r\nIn [2]: import dask_ml.feature_extraction.text\r\n\r\nIn [3]: from dask.distributed import Client\r\n   ...: client = Client()\r\nIn [4]: vocab = {\"foo\": 0, \"bar\": 1}\r\n\r\nIn [6]: remote_vocab, = client.scatter((vocab,), broadcast=True)\r\n\r\nIn [7]: vect = dask_ml.feature_extraction.text.CountVectorizer(vocabulary=remote_vocab)\r\n\r\nIn [8]: bag = db.from_sequence(['foo bar', 'foo', 'bar'], npartitions=2)\r\n\r\nIn [9]: vect.fit_transform(bag)\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-9-f0e608066e3c> in <module>\r\n----> 1 vect.fit_transform(bag)\r\n\r\n~/sandbox/dask-ml/dask_ml/feature_extraction/text.py in fit_transform(self, raw_documents, y)\r\n    188             vocabulary_ = vocabulary.compute()\r\n    189\r\n--> 190         n_features = len(vocabulary_)\r\n    191         result = raw_documents.map_partitions(\r\n    192             _count_vectorizer_transform, vocabulary_for_transform, params\r\n\r\nTypeError: object of type 'Future' has no len()\r\n```\r\n\r\nJust `transform` works fine.\r\n\r\n```python\r\nIn [10]: vect.transform(bag)\r\nOut[10]: dask.array<from-bag-_count_vectorizer_transform, shape=(nan, 2), dtype=int64, chunksize=(nan, 2), chunktype=scipy.csr_matrix>\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/710", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/710/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/710/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/710/events", "html_url": "https://github.com/dask/dask-ml/issues/710", "id": 665392232, "node_id": "MDU6SXNzdWU2NjUzOTIyMzI=", "number": 710, "title": "from dask_ml.model_selection import train_test_split gives ImportError: cannot import name 'check_is_fitted' from'dask_ml._compat'", "user": {"login": "smhfps", "id": 67973625, "node_id": "MDQ6VXNlcjY3OTczNjI1", "avatar_url": "https://avatars2.githubusercontent.com/u/67973625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smhfps", "html_url": "https://github.com/smhfps", "followers_url": "https://api.github.com/users/smhfps/followers", "following_url": "https://api.github.com/users/smhfps/following{/other_user}", "gists_url": "https://api.github.com/users/smhfps/gists{/gist_id}", "starred_url": "https://api.github.com/users/smhfps/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smhfps/subscriptions", "organizations_url": "https://api.github.com/users/smhfps/orgs", "repos_url": "https://api.github.com/users/smhfps/repos", "events_url": "https://api.github.com/users/smhfps/events{/privacy}", "received_events_url": "https://api.github.com/users/smhfps/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-24T20:12:24Z", "updated_at": "2020-07-24T20:37:47Z", "closed_at": "2020-07-24T20:37:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "**This command**:\r\n```python\r\nfrom dask_ml.model_selection import train_test_split\r\n```\r\n**Gives this error**:\r\n```python\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-64-eed36e49e44b> in <module>\r\n      1 import dask.array as da\r\n      2 from dask_ml.datasets import make_regression\r\n----> 3 from dask_ml.model_selection import train_test_split\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask_ml\\model_selection\\__init__.py in <module>\r\n      4 on the underlying estimators being used.\r\n      5 \"\"\"\r\n----> 6 from ._hyperband import HyperbandSearchCV\r\n      7 from ._incremental import IncrementalSearchCV, InverseDecaySearchCV\r\n      8 from ._search import GridSearchCV, RandomizedSearchCV, check_cv, compute_n_splits\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask_ml\\model_selection\\_hyperband.py in <module>\r\n      9 from tornado import gen\r\n     10 \r\n---> 11 from ._incremental import BaseIncrementalSearchCV\r\n     12 from ._successive_halving import SuccessiveHalvingSearchCV\r\n     13 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask_ml\\model_selection\\_incremental.py in <module>\r\n     26 from tornado import gen\r\n     27 \r\n---> 28 from .._compat import check_is_fitted, dummy_context\r\n     29 from .._utils import LoggingContext\r\n     30 from ..utils import check_array\r\n\r\nImportError: cannot import name 'check_is_fitted' from 'dask_ml._compat' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask_ml\\_compat.py)\r\n\r\n```\r\n\r\n**Importing from sklearn works just fine.**\r\n```python \r\nfrom sklearn.model_selection import train_test_split\r\n```\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2.11.0\r\n- Python version: 3.7.7\r\n- Operating System: Windows 10\r\n- Install method (conda, pip, source): Conda\r\n\r\nHow can I fix this error?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/708", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/708/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/708/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/708/events", "html_url": "https://github.com/dask/dask-ml/issues/708", "id": 664350246, "node_id": "MDU6SXNzdWU2NjQzNTAyNDY=", "number": 708, "title": "RandomSearchCV and GridSearchCV are not working with GLM-based estimators with dask.distributed scheduler", "user": {"login": "adriankastrau-kinesso", "id": 60221107, "node_id": "MDQ6VXNlcjYwMjIxMTA3", "avatar_url": "https://avatars1.githubusercontent.com/u/60221107?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adriankastrau-kinesso", "html_url": "https://github.com/adriankastrau-kinesso", "followers_url": "https://api.github.com/users/adriankastrau-kinesso/followers", "following_url": "https://api.github.com/users/adriankastrau-kinesso/following{/other_user}", "gists_url": "https://api.github.com/users/adriankastrau-kinesso/gists{/gist_id}", "starred_url": "https://api.github.com/users/adriankastrau-kinesso/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adriankastrau-kinesso/subscriptions", "organizations_url": "https://api.github.com/users/adriankastrau-kinesso/orgs", "repos_url": "https://api.github.com/users/adriankastrau-kinesso/repos", "events_url": "https://api.github.com/users/adriankastrau-kinesso/events{/privacy}", "received_events_url": "https://api.github.com/users/adriankastrau-kinesso/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2020-07-23T10:07:19Z", "updated_at": "2020-07-24T14:03:49Z", "closed_at": "2020-07-24T14:03:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "<!-- Please include a self-contained copy-pastable example that generates the issue if possible.\r\n\r\nPlease be concise with code posted. See guidelines below on how to provide a good bug report:\r\n\r\n- Craft Minimal Bug Reports http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports\r\n- Minimal Complete Verifiable Examples https://stackoverflow.com/help/mcve\r\n\r\nBug reports that follow these guidelines are easier to diagnose, and so are often handled much more quickly.\r\n-->\r\n\r\n**What happened**:\r\n\r\nRandomSearchCV and GridSearchCV are not working with GLM-based estimators\r\n\r\n**What you expected to happen**:\r\n\r\nReturn the best estimator from RandomSearchCV with dask-ml implementation of Logistic Regression on two seperate dask workers running as docker containers\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nfrom dask.distributed import Client, LocalCluster\r\nfrom dask_ml.linear_model import LogisticRegression\r\nfrom dask_ml.model_selection import RandomizedSearchCV\r\nfrom dask_ml.datasets import make_classification\r\nfrom scipy.stats import uniform\r\nimport dask\r\n\r\nclient = Client(\"scheduler:8786\")\r\n\r\nlogisticEstimator = LogisticRegression()\r\nparams = {\"C\": uniform(0.01, 0.02)}\r\n\r\ntrained_model = RandomizedSearchCV(estimator=logisticEstimator,\r\n                                       param_distributions=params,\r\n                                       n_iter=30,\r\n                                       n_jobs=-1,\r\n                                       cv=5,\r\n                                       error_score=0)\r\nX, y = make_classification(n_samples=100, n_features=50, random_state=1, chunks=500)\r\nX, y = dask.persist(X, y)\r\n\r\ntrained_model.fit(X, y)\r\n```\r\n\r\nError traceback:\r\n```python\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-74-7662e6a874c3> in <module>\r\n----> 1 trained_model.fit(X, y)\r\n\r\n/opt/conda/lib/python3.8/site-packages/dask_ml/model_selection/_search.py in fit(self, X, y, groups, **fit_params)\r\n   1302             dsk, keys = build_refit_graph(estimator, X, y, best_params, fit_params)\r\n   1303 \r\n-> 1304             out = scheduler(dsk, keys, num_workers=n_jobs)\r\n   1305             self.best_estimator_ = out[0]\r\n   1306 \r\n\r\n/opt/conda/lib/python3.8/site-packages/distributed/client.py in get(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\r\n   2686                     should_rejoin = False\r\n   2687             try:\r\n-> 2688                 results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n   2689             finally:\r\n   2690                 for f in futures.values():\r\n\r\n/opt/conda/lib/python3.8/site-packages/distributed/client.py in gather(self, futures, errors, direct, asynchronous)\r\n   1980             else:\r\n   1981                 local_worker = None\r\n-> 1982             return self.sync(\r\n   1983                 self._gather,\r\n   1984                 futures,\r\n\r\n/opt/conda/lib/python3.8/site-packages/distributed/client.py in sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\r\n    830             return future\r\n    831         else:\r\n--> 832             return sync(\r\n    833                 self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\r\n    834             )\r\n\r\n/opt/conda/lib/python3.8/site-packages/distributed/utils.py in sync(loop, func, callback_timeout, *args, **kwargs)\r\n    337     if error[0]:\r\n    338         typ, exc, tb = error[0]\r\n--> 339         raise exc.with_traceback(tb)\r\n    340     else:\r\n    341         return result[0]\r\n\r\n/opt/conda/lib/python3.8/site-packages/distributed/utils.py in f()\r\n    321             if callback_timeout is not None:\r\n    322                 future = asyncio.wait_for(future, callback_timeout)\r\n--> 323             result[0] = yield future\r\n    324         except Exception as exc:\r\n    325             error[0] = sys.exc_info()\r\n\r\n/opt/conda/lib/python3.8/site-packages/tornado/gen.py in run(self)\r\n    733 \r\n    734                     try:\r\n--> 735                         value = future.result()\r\n    736                     except Exception:\r\n    737                         exc_info = sys.exc_info()\r\n\r\n/opt/conda/lib/python3.8/site-packages/distributed/client.py in _gather(self, futures, errors, direct, local_worker)\r\n   1845                             exc = CancelledError(key)\r\n   1846                         else:\r\n-> 1847                             raise exception.with_traceback(traceback)\r\n   1848                         raise exc\r\n   1849                     if errors == \"skip\":\r\n\r\n/opt/conda/lib/python3.8/site-packages/dask_ml/model_selection/methods.py in fit_best()\r\n    450 def fit_best(estimator, params, X, y, fit_params):\r\n    451     estimator = copy_estimator(estimator).set_params(**params)\r\n--> 452     estimator.fit(X, y, **fit_params)\r\n    453     return estimator\r\n\r\n/opt/conda/lib/python3.8/site-packages/dask_ml/linear_model/glm.py in fit()\r\n    185         solver_kwargs = self._get_solver_kwargs()\r\n    186 \r\n--> 187         self._coef = algorithms._solvers[self.solver](X, y, **solver_kwargs)\r\n    188         if self.fit_intercept:\r\n    189             self.coef_ = self._coef[:-1]\r\n\r\n/opt/conda/lib/python3.8/site-packages/dask_glm/utils.py in normalize_inputs()\r\n     24             mean = mean if len(intercept_idx[0]) else np.zeros(mean.shape)\r\n     25             Xn = (X - mean) / std\r\n---> 26             out = algo(Xn, y, *args, **kwargs).copy()\r\n     27             i_adj = np.sum(out * mean / std)\r\n     28             out[intercept_idx] -= i_adj\r\n\r\n/opt/conda/lib/python3.8/site-packages/dask_glm/algorithms.py in admm()\r\n    263                                            fprime=fprime) for\r\n    264                      xx, yy, bb, uu in zip(XD, yD, betas, u)]\r\n--> 265         new_betas = np.array(da.compute(*new_betas))\r\n    266 \r\n    267         beta_hat = over_relax * new_betas + (1 - over_relax) * z\r\n\r\n/opt/conda/lib/python3.8/site-packages/dask/base.py in compute()\r\n    433         return args\r\n    434 \r\n--> 435     schedule = get_scheduler(\r\n    436         scheduler=kwargs.pop(\"scheduler\", None),\r\n    437         collections=collections,\r\n\r\n/opt/conda/lib/python3.8/site-packages/dask/base.py in get_scheduler()\r\n   1034 \r\n   1035     if config.get(\"scheduler\", None):\r\n-> 1036         return get_scheduler(scheduler=config.get(\"scheduler\", None))\r\n   1037 \r\n   1038     if config.get(\"get\", None):\r\n\r\n/opt/conda/lib/python3.8/site-packages/dask/base.py in get_scheduler()\r\n   1019         elif \"Client\" in type(scheduler).__name__ and hasattr(scheduler, \"get\"):\r\n   1020             return scheduler.get\r\n-> 1021         elif scheduler.lower() in named_schedulers:\r\n   1022             return named_schedulers[scheduler.lower()]\r\n   1023         elif scheduler.lower() in (\"dask.distributed\", \"distributed\"):\r\n\r\nAttributeError: 'dict' object has no attribute 'lower'\r\n```\r\n\r\n\r\n**Anything else we need to know?**:\r\nIt's working fine, when I'm using LocalCluster()\r\n\r\n\r\n**Environment**:\r\nDump from client.get_versions():\r\n\r\n```\r\n{'scheduler': {'host': {'python': '3.8.3.final.0',\r\n   'python-bits': 64,\r\n   'OS': 'Linux',\r\n   'OS-release': '4.15.0-112-generic',\r\n   'machine': 'x86_64',\r\n   'processor': '',\r\n   'byteorder': 'little',\r\n   'LC_ALL': 'C.UTF-8',\r\n   'LANG': 'C.UTF-8'},\r\n  'packages': {'python': '3.8.3.final.0',\r\n   'dask': '2.21.0',\r\n   'distributed': '2.21.0',\r\n   'msgpack': '1.0.0',\r\n   'cloudpickle': '1.5.0',\r\n   'tornado': '6.0.4',\r\n   'toolz': '0.10.0',\r\n   'numpy': '1.18.4',\r\n   'lz4': '2.2.1',\r\n   'blosc': '1.7.0'}},\r\n 'workers': {'tcp://172.18.0.3:45817': {'host': {'python': '3.8.3.final.0',\r\n    'python-bits': 64,\r\n    'OS': 'Linux',\r\n    'OS-release': '4.15.0-112-generic',\r\n    'machine': 'x86_64',\r\n    'processor': '',\r\n    'byteorder': 'little',\r\n    'LC_ALL': 'C.UTF-8',\r\n    'LANG': 'C.UTF-8'},\r\n   'packages': {'python': '3.8.3.final.0',\r\n    'dask': '2.21.0',\r\n    'distributed': '2.21.0',\r\n    'msgpack': '1.0.0',\r\n    'cloudpickle': '1.5.0',\r\n    'tornado': '6.0.4',\r\n    'toolz': '0.10.0',\r\n    'numpy': '1.18.4',\r\n    'lz4': '2.2.1',\r\n    'blosc': '1.7.0'}},\r\n  'tcp://172.18.0.4:34919': {'host': {'python': '3.8.3.final.0',\r\n    'python-bits': 64,\r\n    'OS': 'Linux',\r\n    'OS-release': '4.15.0-112-generic',\r\n    'machine': 'x86_64',\r\n    'processor': '',\r\n    'byteorder': 'little',\r\n    'LC_ALL': 'C.UTF-8',\r\n    'LANG': 'C.UTF-8'},\r\n   'packages': {'python': '3.8.3.final.0',\r\n    'dask': '2.21.0',\r\n    'distributed': '2.21.0',\r\n    'msgpack': '1.0.0',\r\n    'cloudpickle': '1.5.0',\r\n    'tornado': '6.0.4',\r\n    'toolz': '0.10.0',\r\n    'numpy': '1.18.4',\r\n    'lz4': '2.2.1',\r\n    'blosc': '1.7.0'}}},\r\n 'client': {'host': {'python': '3.8.3.final.0',\r\n   'python-bits': 64,\r\n   'OS': 'Linux',\r\n   'OS-release': '4.15.0-112-generic',\r\n   'machine': 'x86_64',\r\n   'processor': '',\r\n   'byteorder': 'little',\r\n   'LC_ALL': 'C.UTF-8',\r\n   'LANG': 'C.UTF-8'},\r\n  'packages': {'python': '3.8.3.final.0',\r\n   'dask': '2.21.0',\r\n   'distributed': '2.21.0',\r\n   'msgpack': '1.0.0',\r\n   'cloudpickle': '1.5.0',\r\n   'tornado': '6.0.4',\r\n   'toolz': '0.10.0',\r\n   'numpy': '1.18.4',\r\n   'lz4': '2.2.1',\r\n   'blosc': '1.7.0'}}}\r\n```\r\n\r\nNote: installed via conda", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/704", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/704/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/704/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/704/events", "html_url": "https://github.com/dask/dask-ml/issues/704", "id": 663061115, "node_id": "MDU6SXNzdWU2NjMwNjExMTU=", "number": 704, "title": "update contributing guideline to match dask", "user": {"login": "raybellwaves", "id": 17162724, "node_id": "MDQ6VXNlcjE3MTYyNzI0", "avatar_url": "https://avatars0.githubusercontent.com/u/17162724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raybellwaves", "html_url": "https://github.com/raybellwaves", "followers_url": "https://api.github.com/users/raybellwaves/followers", "following_url": "https://api.github.com/users/raybellwaves/following{/other_user}", "gists_url": "https://api.github.com/users/raybellwaves/gists{/gist_id}", "starred_url": "https://api.github.com/users/raybellwaves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raybellwaves/subscriptions", "organizations_url": "https://api.github.com/users/raybellwaves/orgs", "repos_url": "https://api.github.com/users/raybellwaves/repos", "events_url": "https://api.github.com/users/raybellwaves/events{/privacy}", "received_events_url": "https://api.github.com/users/raybellwaves/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-21T14:29:20Z", "updated_at": "2020-07-24T13:10:14Z", "closed_at": "2020-07-24T13:10:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Could add the `python -m pip install --no-deps -e .` line somewhere around here https://ml.dask.org/contributing.html#creating-an-environment to match the dask instructions https://docs.dask.org/en/latest/develop.html#install\r\n\r\nCould also create a symbolic link from environment-3.8.yaml (instead of 3.7?) to environment-latest.yaml.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/700", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/700/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/700/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/700/events", "html_url": "https://github.com/dask/dask-ml/issues/700", "id": 657352219, "node_id": "MDU6SXNzdWU2NTczNTIyMTk=", "number": 700, "title": "Add datasets to API documentation", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 976945495, "node_id": "MDU6TGFiZWw5NzY5NDU0OTU=", "url": "https://api.github.com/repos/dask/dask-ml/labels/Documentation", "name": "Documentation", "color": "0e8a16", "default": false, "description": ""}, {"id": 731685853, "node_id": "MDU6TGFiZWw3MzE2ODU4NTM=", "url": "https://api.github.com/repos/dask/dask-ml/labels/good%20first%20issue", "name": "good first issue", "color": "b60205", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-15T13:30:31Z", "updated_at": "2020-07-21T19:02:27Z", "closed_at": "2020-07-21T19:02:26Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Right now `dask_ml.datasets` isn't included in the API docs at https://ml.dask.org/modules/api.html. Need to add them to `docs/source/modules/api.rst`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/693", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/693/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/693/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/693/events", "html_url": "https://github.com/dask/dask-ml/issues/693", "id": 651957404, "node_id": "MDU6SXNzdWU2NTE5NTc0MDQ=", "number": 693, "title": "Update documentation build docs", "user": {"login": "raybellwaves", "id": 17162724, "node_id": "MDQ6VXNlcjE3MTYyNzI0", "avatar_url": "https://avatars0.githubusercontent.com/u/17162724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raybellwaves", "html_url": "https://github.com/raybellwaves", "followers_url": "https://api.github.com/users/raybellwaves/followers", "following_url": "https://api.github.com/users/raybellwaves/following{/other_user}", "gists_url": "https://api.github.com/users/raybellwaves/gists{/gist_id}", "starred_url": "https://api.github.com/users/raybellwaves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raybellwaves/subscriptions", "organizations_url": "https://api.github.com/users/raybellwaves/orgs", "repos_url": "https://api.github.com/users/raybellwaves/repos", "events_url": "https://api.github.com/users/raybellwaves/events{/privacy}", "received_events_url": "https://api.github.com/users/raybellwaves/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-07T03:08:02Z", "updated_at": "2020-07-07T11:50:04Z", "closed_at": "2020-07-07T11:50:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Update https://ml.dask.org/contributing.html#documentation to be more in line with https://docs.dask.org/en/latest/develop.html#contributing-to-documentation\r\n\r\nIn addition I just tried to run\r\n```\r\nconda env create -f ci/environment-docs.yaml --name=dask-ml-dev-docs\r\ncd docs\r\nmake html\r\n```\r\nand got\r\n```\r\n(dask-ml-dev-docs) Ray@UM-404XFVH4 docs % make html\r\nRunning Sphinx v1.8.5\r\n\r\nConfiguration error:\r\nThere is a programmable error in your configuration file:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda3/envs/dask-ml-dev-docs/lib/python3.6/site-packages/sphinx/config.py\", line 368, in eval_config_file\r\n    execfile_(filename, namespace)\r\n  File \"/opt/anaconda3/envs/dask-ml-dev-docs/lib/python3.6/site-packages/sphinx/util/pycompat.py\", line 150, in execfile_\r\n    exec_(code, _globals)\r\n  File \"/Users/Ray/Documents/PYTHON_dev/dask-ml/docs/source/conf.py\", line 23, in <module>\r\n    from dask_ml import __version__ as version\r\nModuleNotFoundError: No module named 'dask_ml'\r\n\r\nmake: *** [html] Error 2\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/690", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/690/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/690/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/690/events", "html_url": "https://github.com/dask/dask-ml/issues/690", "id": 650622561, "node_id": "MDU6SXNzdWU2NTA2MjI1NjE=", "number": 690, "title": "add squared arg to mean_squared_error", "user": {"login": "raybellwaves", "id": 17162724, "node_id": "MDQ6VXNlcjE3MTYyNzI0", "avatar_url": "https://avatars0.githubusercontent.com/u/17162724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raybellwaves", "html_url": "https://github.com/raybellwaves", "followers_url": "https://api.github.com/users/raybellwaves/followers", "following_url": "https://api.github.com/users/raybellwaves/following{/other_user}", "gists_url": "https://api.github.com/users/raybellwaves/gists{/gist_id}", "starred_url": "https://api.github.com/users/raybellwaves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raybellwaves/subscriptions", "organizations_url": "https://api.github.com/users/raybellwaves/orgs", "repos_url": "https://api.github.com/users/raybellwaves/repos", "events_url": "https://api.github.com/users/raybellwaves/events{/privacy}", "received_events_url": "https://api.github.com/users/raybellwaves/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-03T14:12:00Z", "updated_at": "2020-07-24T13:10:48Z", "closed_at": "2020-07-24T13:10:48Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Was going though @jacobtomlinson dask tutorial and I saw\r\n\r\n```\r\nfrom dask_ml.metrics import mean_squared_error\r\nfrom math import sqrt\r\n\r\nsqrt(mean_squared_error(y_test, y_predicted))\r\n```\r\n\r\nWonder if it's possible to add the squared arg - same as scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html; https://github.com/scikit-learn/scikit-learn/blob/fd237278e/sklearn/metrics/_regression.py#L266)\r\n\r\nMay be a one line addition?\r\n\r\nhttps://github.com/dask/dask-ml/blob/e5a2f2735be3f52b85dcb5d81d43ce0e5449becb/dask_ml/metrics/regression.py#L32\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/689", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/689/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/689/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/689/events", "html_url": "https://github.com/dask/dask-ml/issues/689", "id": 648655377, "node_id": "MDU6SXNzdWU2NDg2NTUzNzc=", "number": 689, "title": "CountVectorizer for text preprocessing", "user": {"login": "jrdzha", "id": 12738689, "node_id": "MDQ6VXNlcjEyNzM4Njg5", "avatar_url": "https://avatars1.githubusercontent.com/u/12738689?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrdzha", "html_url": "https://github.com/jrdzha", "followers_url": "https://api.github.com/users/jrdzha/followers", "following_url": "https://api.github.com/users/jrdzha/following{/other_user}", "gists_url": "https://api.github.com/users/jrdzha/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrdzha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrdzha/subscriptions", "organizations_url": "https://api.github.com/users/jrdzha/orgs", "repos_url": "https://api.github.com/users/jrdzha/repos", "events_url": "https://api.github.com/users/jrdzha/events{/privacy}", "received_events_url": "https://api.github.com/users/jrdzha/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 941078681, "node_id": "MDU6TGFiZWw5NDEwNzg2ODE=", "url": "https://api.github.com/repos/dask/dask-ml/labels/Algorithm", "name": "Algorithm", "color": "bfdadc", "default": false, "description": "Implement a new algorithm"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2020-07-01T04:07:29Z", "updated_at": "2020-07-24T20:21:26Z", "closed_at": "2020-07-24T20:21:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I understand why hash seems to be a better solution for distributed text preprocessing, but I also need a way to make my features human-readable. It seems like spark has a [CountVectorizer](https://spark.apache.org/docs/latest/ml-features#countvectorizer). Would it be possible to implement one for dask-ml?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/685", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/685/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/685/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/685/events", "html_url": "https://github.com/dask/dask-ml/issues/685", "id": 642387564, "node_id": "MDU6SXNzdWU2NDIzODc1NjQ=", "number": 685, "title": "Unable to reproduce OneHotEncoder example from the docs", "user": {"login": "SultanOrazbayev", "id": 20208402, "node_id": "MDQ6VXNlcjIwMjA4NDAy", "avatar_url": "https://avatars0.githubusercontent.com/u/20208402?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SultanOrazbayev", "html_url": "https://github.com/SultanOrazbayev", "followers_url": "https://api.github.com/users/SultanOrazbayev/followers", "following_url": "https://api.github.com/users/SultanOrazbayev/following{/other_user}", "gists_url": "https://api.github.com/users/SultanOrazbayev/gists{/gist_id}", "starred_url": "https://api.github.com/users/SultanOrazbayev/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SultanOrazbayev/subscriptions", "organizations_url": "https://api.github.com/users/SultanOrazbayev/orgs", "repos_url": "https://api.github.com/users/SultanOrazbayev/repos", "events_url": "https://api.github.com/users/SultanOrazbayev/events{/privacy}", "received_events_url": "https://api.github.com/users/SultanOrazbayev/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-20T14:34:15Z", "updated_at": "2020-06-23T18:15:59Z", "closed_at": "2020-06-23T18:15:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "This example from the [API reference](https://ml.dask.org/modules/api.html?highlight=onehotencoder#dask_ml.preprocessing.OneHotEncoder) returns an error:\r\n\r\n```python\r\nfrom dask_ml.preprocessing import OneHotEncoder\r\nimport numpy as np\r\nimport dask.array as da\r\nenc = OneHotEncoder()\r\nX = da.from_array(np.array([['A'], ['B'], ['A'], ['C']]), chunks=2)\r\nenc.fit(X)\r\nenc.categories_\r\nenc.transform(X)\r\n```\r\n\r\nThis is the traceback:\r\n\r\n<details>\r\n\r\n```python\r\nValueErrorTraceback (most recent call last)\r\n<ipython-input-1-f54891b18539> in <module>\r\n      6 enc.fit(X)\r\n      7 enc.categories_\r\n----> 8 enc.transform(X)\r\n\r\n~/myenv/lib/python3.7/site-packages/dask_ml/preprocessing/_encoders.py in transform(self, X)\r\n    211         self, X: Union[ArrayLike, DataFrameType]\r\n    212     ) -> Union[ArrayLike, DataFrameType]:\r\n--> 213         return self._transform(X)\r\n    214 \r\n    215     def _transform_new(\r\n\r\n~/myenv/lib/python3.7/site-packages/dask_ml/preprocessing/_encoders.py in _transform(self, X, handle_unknown)\r\n    243                 for i in range(n_features)\r\n    244             ]\r\n--> 245             X = da.concatenate(Xs, axis=1)\r\n    246 \r\n    247             if not self.sparse:\r\n\r\n~/myenv/lib/python3.7/site-packages/dask/array/core.py in concatenate(seq, axis, allow_unknown_chunksizes)\r\n   3480         raise ValueError(\"Need array(s) to concatenate\")\r\n   3481 \r\n-> 3482     meta = np.concatenate([meta_from_array(s) for s in seq], axis=axis)\r\n   3483 \r\n   3484     # Promote types to match meta\r\n\r\n<__array_function__ internals> in concatenate(*args, **kwargs)\r\n\r\nValueError: zero-dimensional arrays cannot be concatenated\r\n```\r\n\r\n</details>\r\n\r\n**Environment**:\r\n\r\n- Dask version: 2.19.0\r\n- numpy version: 1.18.5\r\n- Python version: 3.7.6\r\n- Install method (conda, pip, source): conda\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/683", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/683/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/683/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/683/events", "html_url": "https://github.com/dask/dask-ml/issues/683", "id": 640424560, "node_id": "MDU6SXNzdWU2NDA0MjQ1NjA=", "number": 683, "title": "Dask ml with light gbm And gridsearchcv Assertion error", "user": {"login": "Sajjad1989", "id": 58667644, "node_id": "MDQ6VXNlcjU4NjY3NjQ0", "avatar_url": "https://avatars1.githubusercontent.com/u/58667644?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sajjad1989", "html_url": "https://github.com/Sajjad1989", "followers_url": "https://api.github.com/users/Sajjad1989/followers", "following_url": "https://api.github.com/users/Sajjad1989/following{/other_user}", "gists_url": "https://api.github.com/users/Sajjad1989/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sajjad1989/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sajjad1989/subscriptions", "organizations_url": "https://api.github.com/users/Sajjad1989/orgs", "repos_url": "https://api.github.com/users/Sajjad1989/repos", "events_url": "https://api.github.com/users/Sajjad1989/events{/privacy}", "received_events_url": "https://api.github.com/users/Sajjad1989/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-17T13:01:58Z", "updated_at": "2020-08-05T20:35:28Z", "closed_at": "2020-08-05T20:35:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Lgbm=daskgridcv (model,Param grid)\r\nWith joblib.parallel_backend('dask')\r\n      Lgbm.fit(strain,ytrain)\r\n\r\n\r\nI get assertion Error could anyone please let me know why I am I getting this error\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/680", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/680/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/680/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/680/events", "html_url": "https://github.com/dask/dask-ml/issues/680", "id": 633466368, "node_id": "MDU6SXNzdWU2MzM0NjYzNjg=", "number": 680, "title": "XGBoost with GridSearchCV fails", "user": {"login": "rmg55", "id": 8303580, "node_id": "MDQ6VXNlcjgzMDM1ODA=", "avatar_url": "https://avatars0.githubusercontent.com/u/8303580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmg55", "html_url": "https://github.com/rmg55", "followers_url": "https://api.github.com/users/rmg55/followers", "following_url": "https://api.github.com/users/rmg55/following{/other_user}", "gists_url": "https://api.github.com/users/rmg55/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmg55/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmg55/subscriptions", "organizations_url": "https://api.github.com/users/rmg55/orgs", "repos_url": "https://api.github.com/users/rmg55/repos", "events_url": "https://api.github.com/users/rmg55/events{/privacy}", "received_events_url": "https://api.github.com/users/rmg55/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-07T14:34:38Z", "updated_at": "2020-06-08T11:38:23Z", "closed_at": "2020-06-08T11:38:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am hoping to use the dask_ml GridSearchCV algorithm to tune an xgboost model, but running into an error.\r\n\r\nI am able to get gridsearchcv to complete with standard scikit-learn as well as setting the scikit-learn backend to dask. However, when I try to use the dask_ml gridsearchcv version, I get an error. Below is a minimal reproducible example\r\n\r\n### Relevant Software Versions:\r\n```\r\nsklearn: 0.23.1\r\ndask: 2.18.0\r\ndask_ml: 1.5.0\r\nxgboost: 1.0.2\r\n```\r\n\r\n### Example Code:\r\n```python\r\nfrom sklearn.model_selection import GridSearchCV as sk_GridSearchCV\r\nimport xgboost as xgb\r\nfrom dask_ml.model_selection import GridSearchCV as d_GridSearchCV\r\nfrom sklearn.ensemble import RandomForestRegressor\r\nimport dask\r\nfrom dask import dataframe as ddf\r\nfrom dask import array as da\r\nfrom dask.distributed import Client, LocalCluster\r\nfrom dask_ml.datasets import make_regression\r\nimport joblib\r\n\r\n#Dask Distributed\r\ncluster = LocalCluster(n_workers=2,threads_per_worker=2)\r\ncl = Client(cluster)\r\ncl\r\n\r\n#Training Data\r\nX_train,Y_train = make_regression(n_samples=2000,n_features=50,chunks=(1000,50))\r\n\r\n#Define Model and param space\r\nmodel = xgb.XGBRegressor(learning_rate=0.1,max_depth=10,colsample_bytree=.5,gamma =.3)\r\nparams = [{'n_estimators': [50, 100, 150, 200]}]\r\n\r\n#Gridsearch on Models 3 ways\r\n#This Works\r\nsearch_skstandard = sk_GridSearchCV(model,param_grid=params,cv=3,error_score=-99,n_jobs=2).fit(X_train.compute(),Y_train.compute())\r\nprint('Standard sklearn gridsearch: '+str(search_skstandard.best_score_))\r\n\r\n#This works\r\nsearch_sk_dask = sk_GridSearchCV(model,param_grid=params,cv=3,error_score=-99,n_jobs=2)\r\nwith joblib.parallel_backend('dask'):\r\n    search_sk_dask.fit(X_train.compute(), Y_train.compute())\r\nprint('sklearn gridsearch with Dask backend: '+str(search_sk_dask.best_score_))\r\n    \r\n#This Fails\r\nsearch_dask = d_GridSearchCV(model,param_grid=params,cv=3,scheduler=cl).fit(X_train,Y_train)\r\nprint('Dask gridsearch: '+str(search_dask.best_score_))\r\n```\r\n\r\nOuput:\r\n```\r\nStandard sklearn gridsearch: 0.6725983752684392\r\nsklearn gridsearch with Dask backend: 0.6725983752684392\r\n---------------------------------------------------------------------------\r\nXGBoostError                              Traceback (most recent call last)\r\n<ipython-input-4-3d8cc0738e28> in <module>\r\n     34 \r\n     35 #This Fails\r\n---> 36 search_dask = d_GridSearchCV(model,param_grid=params,cv=3,scheduler=cl).fit(X_train,Y_train)\r\n     37 print('Dask gridsearch: '+str(search_dask.best_score_))\r\n\r\n/opt/conda/envs/py_geo/lib/python3.7/site-packages/dask_ml/model_selection/_search.py in fit(self, X, y, groups, **fit_params)\r\n   1240             error_score=error_score,\r\n   1241             return_train_score=self.return_train_score,\r\n-> 1242             cache_cv=self.cache_cv,\r\n   1243         )\r\n   1244 \r\n\r\n/opt/conda/envs/py_geo/lib/python3.7/site-packages/dask_ml/model_selection/_search.py in build_cv_graph(estimator, cv, scorer, candidate_params, X, y, groups, fit_params, iid, error_score, return_train_score, cache_cv)\r\n    208     fields, tokens, params = normalize_params(candidate_params)\r\n    209     main_token = tokenize(\r\n--> 210         normalize_estimator(estimator),\r\n    211         fields,\r\n    212         params,\r\n\r\n/opt/conda/envs/py_geo/lib/python3.7/site-packages/dask_ml/model_selection/_normalize.py in normalize_estimator(est)\r\n     36                 continue\r\n     37             try:\r\n---> 38                 val = getattr(est, attr)\r\n     39             except (sklearn.exceptions.NotFittedError, AttributeError):\r\n     40                 continue\r\n\r\n/opt/conda/envs/py_geo/lib/python3.7/site-packages/xgboost/sklearn.py in coef_(self)\r\n    713             raise AttributeError('Coefficients are not defined for Booster type {}'\r\n    714                                  .format(self.booster))\r\n--> 715         b = self.get_booster()\r\n    716         coef = np.array(json.loads(b.get_dump(dump_format='json')[0])['weight'])\r\n    717         # Logic for multiclass classification\r\n\r\n/opt/conda/envs/py_geo/lib/python3.7/site-packages/xgboost/sklearn.py in get_booster(self)\r\n    269         \"\"\"\r\n    270         if self._Booster is None:\r\n--> 271             raise XGBoostError('need to call fit or load_model beforehand')\r\n    272         return self._Booster\r\n    273 \r\n\r\nXGBoostError: need to call fit or load_model beforehand\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/678", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/678/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/678/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/678/events", "html_url": "https://github.com/dask/dask-ml/issues/678", "id": 631258362, "node_id": "MDU6SXNzdWU2MzEyNTgzNjI=", "number": 678, "title": "Pytest complaining on CI about \"mocker in a context not supported\"", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-05T02:09:14Z", "updated_at": "2020-06-05T15:06:59Z", "closed_at": "2020-06-05T15:06:59Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "For the tests `tests/test_incremental.py::test_replace_scoring[SGDClassifier-fit_kwargs0-accuracy]` and `tests/test_incremental.py::test_replace_scoring[SGDRegressor-fit_kwargs1-r2]`.\r\n\r\nHere's the error produced at the end:\r\n\r\n```\r\nValueError: Using mocker in a with context is not supported. https://github.com/pytest-dev/pytest-mock#note-about-usage-as-context-manager\r\n```\r\n\r\nThe link is https://github.com/pytest-dev/pytest-mock#note-about-usage-as-context-manager. The full traceback:\r\n\r\n```\r\n2020-06-05T01:54:58.5879474Z ___________ test_replace_scoring[SGDClassifier-fit_kwargs0-accuracy] ___________\r\n2020-06-05T01:54:58.5879901Z \r\n2020-06-05T01:54:58.5880365Z estimator = <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\r\n2020-06-05T01:54:58.5880922Z fit_kwargs = {'classes': [0, 1]}, scoring = 'accuracy'\r\n2020-06-05T01:54:58.5881424Z xy_classification = (dask.array<normal, shape=(100, 20), dtype=float64, chunksize=(10, 20), chunktype=numpy.ndarray>, dask.array<astype, shape=(100,), dtype=int64, chunksize=(10,), chunktype=numpy.ndarray>)\r\n2020-06-05T01:54:58.5881951Z mocker = <pytest_mock.plugin.MockFixture object at 0x7fce2d98b400>\r\n2020-06-05T01:54:58.5882178Z \r\n2020-06-05T01:54:58.5882385Z     @pytest.mark.parametrize(\r\n2020-06-05T01:54:58.5882626Z         \"estimator, fit_kwargs, scoring\",\r\n2020-06-05T01:54:58.5882967Z         [(SGDClassifier, {\"classes\": [0, 1]}, \"accuracy\"), (SGDRegressor, {}, \"r2\")],\r\n2020-06-05T01:54:58.5883248Z     )\r\n2020-06-05T01:54:58.5883565Z     def test_replace_scoring(estimator, fit_kwargs, scoring, xy_classification, mocker):\r\n2020-06-05T01:54:58.5883906Z         X, y = xy_classification\r\n2020-06-05T01:54:58.5884384Z         inc = Incremental(estimator(max_iter=1000, random_state=0, tol=1e-3))\r\n2020-06-05T01:54:58.5884734Z         inc.fit(X, y, **fit_kwargs)\r\n2020-06-05T01:54:58.5884942Z     \r\n2020-06-05T01:54:58.5885200Z         patch = mocker.patch.object(dask_ml.wrappers, \"get_scorer\")\r\n2020-06-05T01:54:58.5885470Z >       with patch:\r\n2020-06-05T01:54:58.5885645Z \r\n2020-06-05T01:54:58.5885869Z tests/test_incremental.py:183: \r\n2020-06-05T01:54:58.5886162Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n2020-06-05T01:54:58.5886736Z /usr/share/miniconda/envs/dask-ml-test/lib/python3.6/unittest/mock.py:939: in __call__\r\n2020-06-05T01:54:58.5887095Z     return _mock_self._mock_call(*args, **kwargs)\r\n2020-06-05T01:54:58.5887425Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n2020-06-05T01:54:58.5887678Z \r\n2020-06-05T01:54:58.5888096Z _mock_self = <MagicMock name='get_scorer.__enter__' id='140522247884696'>\r\n2020-06-05T01:54:58.5888427Z args = (), kwargs = {}\r\n2020-06-05T01:54:58.5889063Z self = <MagicMock name='get_scorer.__enter__' id='140522247884696'>\r\n2020-06-05T01:54:58.5889475Z _call = call(), seen = {94764811168560}, do_method_calls = False\r\n2020-06-05T01:54:58.5890034Z method_call_name = '__enter__', mock_call_name = '__enter__', is_a_call = False\r\n2020-06-05T01:54:58.5890409Z _new_parent = None, this_mock_call = call.__enter__()\r\n2020-06-05T01:54:58.5890622Z \r\n2020-06-05T01:54:58.5890849Z     def _mock_call(_mock_self, *args, **kwargs):\r\n2020-06-05T01:54:58.5891129Z         self = _mock_self\r\n2020-06-05T01:54:58.5891347Z         self.called = True\r\n2020-06-05T01:54:58.5891586Z         self.call_count += 1\r\n2020-06-05T01:54:58.5891781Z     \r\n2020-06-05T01:54:58.5891971Z         # handle call_args\r\n2020-06-05T01:54:58.5892233Z         _call = _Call((args, kwargs), two=True)\r\n2020-06-05T01:54:58.5892490Z         self.call_args = _call\r\n2020-06-05T01:54:58.5892747Z         self.call_args_list.append(_call)\r\n2020-06-05T01:54:58.5892963Z     \r\n2020-06-05T01:54:58.5893166Z         seen = set()\r\n2020-06-05T01:54:58.5893354Z     \r\n2020-06-05T01:54:58.5893572Z         # initial stuff for method_calls:\r\n2020-06-05T01:54:58.5893871Z         do_method_calls = self._mock_parent is not None\r\n2020-06-05T01:54:58.5894145Z         method_call_name = self._mock_name\r\n2020-06-05T01:54:58.5894378Z     \r\n2020-06-05T01:54:58.5894593Z         # initial stuff for mock_calls:\r\n2020-06-05T01:54:58.5894873Z         mock_call_name = self._mock_new_name\r\n2020-06-05T01:54:58.5895308Z         is_a_call = mock_call_name == '()'\r\n2020-06-05T01:54:58.5895777Z         self.mock_calls.append(_Call(('', args, kwargs)))\r\n2020-06-05T01:54:58.5896056Z     \r\n2020-06-05T01:54:58.5896279Z         # follow up the chain of mocks:\r\n2020-06-05T01:54:58.5896560Z         _new_parent = self._mock_new_parent\r\n2020-06-05T01:54:58.5896827Z         while _new_parent is not None:\r\n2020-06-05T01:54:58.5897154Z     \r\n2020-06-05T01:54:58.5897386Z             # handle method_calls:\r\n2020-06-05T01:54:58.5897703Z             if do_method_calls:\r\n2020-06-05T01:54:58.5898033Z                 _new_parent.method_calls.append(_Call((method_call_name, args, kwargs)))\r\n2020-06-05T01:54:58.5898388Z                 do_method_calls = _new_parent._mock_parent is not None\r\n2020-06-05T01:54:58.5898702Z                 if do_method_calls:\r\n2020-06-05T01:54:58.5899229Z                     method_call_name = _new_parent._mock_name + '.' + method_call_name\r\n2020-06-05T01:54:58.5901464Z     \r\n2020-06-05T01:54:58.5901774Z             # handle mock_calls:\r\n2020-06-05T01:54:58.5902063Z             this_mock_call = _Call((mock_call_name, args, kwargs))\r\n2020-06-05T01:54:58.5902391Z             _new_parent.mock_calls.append(this_mock_call)\r\n2020-06-05T01:54:58.5902624Z     \r\n2020-06-05T01:54:58.5902863Z             if _new_parent._mock_new_name:\r\n2020-06-05T01:54:58.5903130Z                 if is_a_call:\r\n2020-06-05T01:54:58.5903635Z                     dot = ''\r\n2020-06-05T01:54:58.5903906Z                 else:\r\n2020-06-05T01:54:58.5904293Z                     dot = '.'\r\n2020-06-05T01:54:58.5904780Z                 is_a_call = _new_parent._mock_new_name == '()'\r\n2020-06-05T01:54:58.5905139Z                 mock_call_name = _new_parent._mock_new_name + dot + mock_call_name\r\n2020-06-05T01:54:58.5905423Z     \r\n2020-06-05T01:54:58.5905644Z             # follow the parental chain:\r\n2020-06-05T01:54:58.5905937Z             _new_parent = _new_parent._mock_new_parent\r\n2020-06-05T01:54:58.5906164Z     \r\n2020-06-05T01:54:58.5906562Z             # check we're not in an infinite loop:\r\n2020-06-05T01:54:58.5906925Z             # ( use ids here so as not to call __hash__ on the mocks)\r\n2020-06-05T01:54:58.5907222Z             _new_parent_id = id(_new_parent)\r\n2020-06-05T01:54:58.5907510Z             if _new_parent_id in seen:\r\n2020-06-05T01:54:58.5907750Z                 break\r\n2020-06-05T01:54:58.5907990Z             seen.add(_new_parent_id)\r\n2020-06-05T01:54:58.5908203Z     \r\n2020-06-05T01:54:58.5908399Z         effect = self.side_effect\r\n2020-06-05T01:54:58.5908669Z         if effect is not None:\r\n2020-06-05T01:54:58.5908929Z             if _is_exception(effect):\r\n2020-06-05T01:54:58.5909198Z >               raise effect\r\n2020-06-05T01:54:58.5909837Z E               ValueError: Using mocker in a with context is not supported. https://github.com/pytest-dev/pytest-mock#note-about-usage-as-context-manager\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/673", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/673/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/673/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/673/events", "html_url": "https://github.com/dask/dask-ml/issues/673", "id": 624904196, "node_id": "MDU6SXNzdWU2MjQ5MDQxOTY=", "number": 673, "title": "Flaky Incremental Model Selection tests", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-26T13:56:30Z", "updated_at": "2020-05-28T12:57:59Z", "closed_at": "2020-05-28T12:57:59Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`tests/model_selection/test_incremental.py::test_gridsearch` and `tests/model_selection/test_incremental.py::test_transform` occasionally fail on CI.\r\n\r\nhttps://dev.azure.com/dask-dev/dask/_build/results?buildId=1154&view=logs&j=2eab4704-62a3-55d0-a524-46b534a6e811&t=24a2918a-3d47-54f3-09aa-2db1b58035d7&l=549\r\n\r\n```\r\n================================== FAILURES ===================================\r\n_______________________________ test_gridsearch _______________________________\r\n\r\n    def test_func():\r\n---------------------------- Captured stderr call -----------------------------\r\ndistributed.scheduler - ERROR - Couldn't gather keys {'_score-4d2165fa-45ff-4705-90a5-5c464fb49b2a': [], '_score-d139b189-4b59-4823-a75e-76613308362a': [], '_score-2de29df9-0e9f-4d81-8032-4b41d918fb18': [], '_score-35f12ba1-3806-4b51-8307-a42da6d043ef': [], '_score-2dc00b23-6a1b-4312-8b97-a05a9d1c391c': [], '_score-fb91dd67-dee3-4e81-9bf6-1384f42bd993': []} state: [None, None, None, None, None, None] workers: []\r\nNoneType: None\r\ndistributed.scheduler - ERROR - Workers don't have promised key: [], _score-4d2165fa-45ff-4705-90a5-5c464fb49b2a\r\nNoneType: None\r\ndistributed.scheduler - ERROR - Workers don't have promised key: [], _score-d139b189-4b59-4823-a75e-76613308362a\r\nNoneType: None\r\ndistributed.scheduler - ERROR - Workers don't have promised key: [], _score-2de29df9-0e9f-4d81-8032-4b41d918fb18\r\nNoneType: None\r\ndistributed.scheduler - ERROR - Workers don't have promised key: [], _score-35f12ba1-3806-4b51-8307-a42da6d043ef\r\nNoneType: None\r\ndistributed.scheduler - ERROR - Workers don't have promised key: [], _score-2dc00b23-6a1b-4312-8b97-a05a9d1c391c\r\nNoneType: None\r\ndistributed.scheduler - ERROR - Workers don't have promised key: [], _score-fb91dd67-dee3-4e81-9bf6-1384f42bd993\r\nNoneType: None\r\ndistributed.client - WARNING - Couldn't gather 6 keys, rescheduling {'_score-4d2165fa-45ff-4705-90a5-5c464fb49b2a': (), '_score-d139b189-4b59-4823-a75e-76613308362a': (), '_score-2de29df9-0e9f-4d81-8032-4b41d918fb18': (), '_score-35f12ba1-3806-4b51-8307-a42da6d043ef': (), '_score-2dc00b23-6a1b-4312-8b97-a05a9d1c391c': (), '_score-fb91dd67-dee3-4e81-9bf6-1384f42bd993': ()}\r\ntornado.application - ERROR - Exception after Future was cancelled\r\nTraceback (most recent call last):\r\n  File \"C:\\Miniconda\\envs\\dask-ml-test\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\r\n    yielded = self.gen.throw(*exc_info)  # type: ignore\r\n  File \"D:\\a\\1\\s\\tests\\model_selection\\test_incremental.py\", line 405, in test_gridsearch\r\n    yield search.fit(X, y, classes=[0, 1])\r\n  File \"C:\\Miniconda\\envs\\dask-ml-test\\lib\\site-packages\\tornado\\gen.py\", line 735, in run\r\n    value = future.result()\r\n  File \"C:\\Miniconda\\envs\\dask-ml-test\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\r\n    yielded = self.gen.throw(*exc_info)  # type: ignore\r\n  File \"D:\\a\\1\\s\\dask_ml\\model_selection\\_incremental.py\", line 625, in _fit\r\n    prefix=self.prefix,\r\n  File \"C:\\Miniconda\\envs\\dask-ml-test\\lib\\site-packages\\tornado\\gen.py\", line 735, in run\r\n    value = future.result()\r\n  File \"C:\\Miniconda\\envs\\dask-ml-test\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\r\n    yielded = self.gen.throw(*exc_info)  # type: ignore\r\n  File \"D:\\a\\1\\s\\dask_ml\\model_selection\\_incremental.py\", line 297, in _fit\r\n    scores = yield client.gather(scores)\r\n  File \"C:\\Miniconda\\envs\\dask-ml-test\\lib\\site-packages\\tornado\\gen.py\", line 735, in run\r\n    value = future.result()\r\n  File \"C:\\Miniconda\\envs\\dask-ml-test\\lib\\site-packages\\distributed\\client.py\", line 1865, in _gather\r\n    self._send_to_scheduler({\"op\": \"report-key\", \"key\": key})\r\n  File \"C:\\Miniconda\\envs\\dask-ml-test\\lib\\site-packages\\distributed\\client.py\", line 960, in _send_to_scheduler\r\n    \"Message: %s\" % (self.status, msg)\r\nException: Tried sending message after closing.  Status: closed\r\nMessage: {'op': 'report-key', 'key': '_score-4d2165fa-45ff-4705-90a5-5c464fb49b2a'}\r\n```\r\n\r\n\r\nThe errors on the scheduler about seem related.\r\n\r\n```\r\ndistributed.scheduler - ERROR - Workers don't have promised key: [], _score-4d2165fa-45ff-4705-90a5-5c464fb49b2a\r\n```\r\n\r\nBut I can't reproduce this locally.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/667", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/667/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/667/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/667/events", "html_url": "https://github.com/dask/dask-ml/issues/667", "id": 619129049, "node_id": "MDU6SXNzdWU2MTkxMjkwNDk=", "number": 667, "title": "GridSearchCV fails with XGBoost models", "user": {"login": "moneygeek", "id": 3093597, "node_id": "MDQ6VXNlcjMwOTM1OTc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3093597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/moneygeek", "html_url": "https://github.com/moneygeek", "followers_url": "https://api.github.com/users/moneygeek/followers", "following_url": "https://api.github.com/users/moneygeek/following{/other_user}", "gists_url": "https://api.github.com/users/moneygeek/gists{/gist_id}", "starred_url": "https://api.github.com/users/moneygeek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/moneygeek/subscriptions", "organizations_url": "https://api.github.com/users/moneygeek/orgs", "repos_url": "https://api.github.com/users/moneygeek/repos", "events_url": "https://api.github.com/users/moneygeek/events{/privacy}", "received_events_url": "https://api.github.com/users/moneygeek/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 21, "created_at": "2020-05-15T17:27:17Z", "updated_at": "2020-06-09T13:25:29Z", "closed_at": "2020-06-01T14:37:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "The following code fails:\r\n\r\n```\r\nimport numpy as np\r\nfrom dask_ml.model_selection import GridSearchCV, KFold\r\nfrom dask_xgboost import XGBClassifier\r\n\r\nx = np.random.randn(100, 2)\r\ny = np.random.randint(0, 1, 100)\r\n\r\nparams = {'max_depth': [2, 3]}\r\n\r\nclf = GridSearchCV(XGBClassifier(), params, cv=KFold(n_splits=2), scoring='neg_mean_squared_error')\r\nclf.fit(x, y)\r\n```\r\n\r\nStack trace:\r\n```\r\n  File \"/home/jin/anaconda3/envs/ml-gpu/lib/python3.6/site-packages/dask_ml/model_selection/_normalize.py\", line 38, in normalize_estimator\r\n    val = getattr(est, attr)\r\n  File \"/home/jin/anaconda3/envs/ml-gpu/lib/python3.6/site-packages/xgboost/sklearn.py\", line 536, in feature_importances_\r\n    b = self.get_booster()\r\n  File \"/home/jin/anaconda3/envs/ml-gpu/lib/python3.6/site-packages/xgboost/sklearn.py\", line 200, in get_booster\r\n    raise XGBoostError('need to call fit or load_model beforehand')\r\nxgboost.core.XGBoostError: need to call fit or load_model beforehand\r\n```\r\n\r\nThe error arises because the `normalize_estimator` function is trying to get the 'feature_importances_' attribute of the xgb model, but the attribute doesn't exist unless the model has already been trained. The `normalize_estimator` function I believe should gloss over this error, but it doesn't because it's not catching the `XGBoostError` error type.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/665", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/665/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/665/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/665/events", "html_url": "https://github.com/dask/dask-ml/issues/665", "id": 618595191, "node_id": "MDU6SXNzdWU2MTg1OTUxOTE=", "number": 665, "title": "Error trying to run random search for a random forest ", "user": {"login": "sami2ahmed", "id": 22098871, "node_id": "MDQ6VXNlcjIyMDk4ODcx", "avatar_url": "https://avatars3.githubusercontent.com/u/22098871?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sami2ahmed", "html_url": "https://github.com/sami2ahmed", "followers_url": "https://api.github.com/users/sami2ahmed/followers", "following_url": "https://api.github.com/users/sami2ahmed/following{/other_user}", "gists_url": "https://api.github.com/users/sami2ahmed/gists{/gist_id}", "starred_url": "https://api.github.com/users/sami2ahmed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sami2ahmed/subscriptions", "organizations_url": "https://api.github.com/users/sami2ahmed/orgs", "repos_url": "https://api.github.com/users/sami2ahmed/repos", "events_url": "https://api.github.com/users/sami2ahmed/events{/privacy}", "received_events_url": "https://api.github.com/users/sami2ahmed/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-14T23:27:16Z", "updated_at": "2020-05-15T16:00:15Z", "closed_at": "2020-05-15T01:43:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "#### Why does this matter\r\nAs far as I can tell, the code I show below is evidence of a case where `sklearn.RandomizedSearchCV()` succeeds and `dask_ml.model_selection.RandomizedSearchCV()` fails, on the same data and same input parameters. I think searching over hyperparameters for a tree-based model is a powerful use case for `dask-ml`, and right now I'm unable to do so with dask's `RandomizedSearchCV()`.\r\n####\r\n\r\nI'm able to get the same random search to work in SKlearn but switching over to Dask I'm getting this strange error. \r\n\r\n```\r\nimport dask_ml.model_selection as dml\r\nfrom sklearn.ensemble import RandomForestClassifier\r\n\r\nrfc = RandomForestClassifier()\r\ndml_random = dml.RandomizedSearchCV(rfc, param_distributions=random_grid, n_iter = 100, cv = 3, random_state=255, scheduler=client)\r\ndml_random.fit(X,y)\r\n```\r\n\r\nI have a cluster running with a few workers, definitely more than enough memory to complete the search. Full traceback below: \r\n\r\n```\r\nWARNING:dask_ml.model_selection._search:('randomforestclassifier-fit-score-b6fdd73c33455e10b804d2b4fd41dff9', 95, 0) has failed... retrying\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<timed exec> in <module>\r\n\r\n/srv/conda/envs/saturn/lib/python3.7/site-packages/dask_ml/model_selection/_search.py in fit(self, X, y, groups, **fit_params)\r\n   1264                     else:\r\n   1265                         logger.warning(\"{} has failed... retrying\".format(future.key))\r\n-> 1266                         future.retry()\r\n   1267                         ac.add(future)\r\n   1268 \r\n\r\n/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py in retry(self, **kwargs)\r\n    311         Client.retry\r\n    312         \"\"\"\r\n--> 313         return self.client.retry([self], **kwargs)\r\n    314 \r\n    315     def cancelled(self):\r\n\r\n/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py in retry(self, futures, asynchronous)\r\n   2120         futures: list of Futures\r\n   2121         \"\"\"\r\n-> 2122         return self.sync(self._retry, futures, asynchronous=asynchronous)\r\n   2123 \r\n   2124     @gen.coroutine\r\n\r\n/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py in sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\r\n    767         else:\r\n    768             return sync(\r\n--> 769                 self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\r\n    770             )\r\n    771 \r\n\r\n/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/utils.py in sync(loop, func, callback_timeout, *args, **kwargs)\r\n    333     if error[0]:\r\n    334         typ, exc, tb = error[0]\r\n--> 335         raise exc.with_traceback(tb)\r\n    336     else:\r\n    337         return result[0]\r\n\r\n/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/utils.py in f()\r\n    317             if callback_timeout is not None:\r\n    318                 future = gen.with_timeout(timedelta(seconds=callback_timeout), future)\r\n--> 319             result[0] = yield future\r\n    320         except Exception as exc:\r\n    321             error[0] = sys.exc_info()\r\n\r\n/srv/conda/envs/saturn/lib/python3.7/site-packages/tornado/gen.py in run(self)\r\n    733 \r\n    734                     try:\r\n--> 735                         value = future.result()\r\n    736                     except Exception:\r\n    737                         exc_info = sys.exc_info()\r\n\r\n/srv/conda/envs/saturn/lib/python3.7/site-packages/distributed/client.py in _retry(self, futures)\r\n   2109         response = await self.scheduler.retry(keys=keys, client=self.id)\r\n   2110         for key in response:\r\n-> 2111             st = self.futures[key]\r\n   2112             st.retry()\r\n   2113 \r\n\r\nKeyError: 'cv-split-b6fdd73c33455e10b804d2b4fd41dff9'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/663", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/663/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/663/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/663/events", "html_url": "https://github.com/dask/dask-ml/issues/663", "id": 613391520, "node_id": "MDU6SXNzdWU2MTMzOTE1MjA=", "number": 663, "title": "Add Python 3.8 CI / support", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-06T15:03:09Z", "updated_at": "2020-05-26T14:47:38Z", "closed_at": "2020-05-26T14:47:38Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Numba supports Python 3.8 now so we can support it too.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/660", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/660/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/660/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/660/events", "html_url": "https://github.com/dask/dask-ml/issues/660", "id": 613332413, "node_id": "MDU6SXNzdWU2MTMzMzI0MTM=", "number": 660, "title": "Use keyword only arguments", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 731685853, "node_id": "MDU6TGFiZWw3MzE2ODU4NTM=", "url": "https://api.github.com/repos/dask/dask-ml/labels/good%20first%20issue", "name": "good first issue", "color": "b60205", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-06T13:45:14Z", "updated_at": "2020-05-26T18:49:07Z", "closed_at": "2020-05-26T18:49:06Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Scikit-learn 0.24 will warn if parameters are passed an Estimator's init by position rather than keyword. We'll need to update all our uses.\r\n\r\nhttps://dev.azure.com/dask-dev/dask/_build/results?buildId=1080&view=logs&j=d699f7f7-fbb1-5fe7-7f49-16a980a27dcf&t=47702d4b-eb38-52c1-7644-7bfb10716412", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/658", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/658/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/658/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/658/events", "html_url": "https://github.com/dask/dask-ml/issues/658", "id": 612660112, "node_id": "MDU6SXNzdWU2MTI2NjAxMTI=", "number": 658, "title": "BaseEstimator tokenization may cause issues for fitted models", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-05T14:46:27Z", "updated_at": "2020-05-05T18:21:55Z", "closed_at": "2020-05-05T18:21:55Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "In https://github.com/dask/dask-ml/blob/master/dask_ml/model_selection/_normalize.py#L18-L24, we register a tokenizer for scikit-learn models that inherit from BaseEstimator. This can cause issues when we have multiple instances of the same model that have been fitted to different pieces of data (as in https://github.com/dask/dask-ml/pull/657).\r\n\r\n```python\r\nIn [8]: import dask\r\n   ...: import sklearn.datasets\r\n   ...: import sklearn.linear_model\r\n   ...: import dask_ml.model_selection._normalize\r\n   ...:\r\n   ...: m1 = sklearn.linear_model.LogisticRegression(random_state=0)\r\n   ...: m2 = sklearn.linear_model.LogisticRegression(random_state=0)\r\n   ...:\r\n   ...: # Not fitted, fine for these to match\r\n   ...: assert dask.base.tokenize(m1) == dask.base.tokenize(m2)\r\n   ...:\r\n   ...: X1, y1 = sklearn.datasets.make_classification()\r\n   ...: X2, y2 = sklearn.datasets.make_classification()\r\n   ...: m1.fit(X1, y1)\r\n   ...: m2.fit(X2, y2)\r\n   ...:\r\n   ...: # After fitting, these should be different!\r\n   ...: assert dask.base.tokenize(m1) != dask.base.tokenize(m2)\r\n   ...:\r\n   ...:\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-8-590215541e34> in <module>\r\n     16\r\n     17 # After fitting, these should be different!\r\n---> 18 assert dask.base.tokenize(m1) != dask.base.tokenize(m2)\r\n     19\r\n\r\nAssertionError:\r\n```\r\n\r\nI think that `normalize_estimator` should also (try to) hash things like `coef_`. Since this is supposed to work for arbitrary estimators, the safest thing to do is tokenize any attribute ending in `_`. We might exclude selected attributes like `GridSearchCV.cv_results_`, since those include things that are incidental (like the time it took to train a specific split).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/655", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/655/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/655/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/655/events", "html_url": "https://github.com/dask/dask-ml/issues/655", "id": 611331210, "node_id": "MDU6SXNzdWU2MTEzMzEyMTA=", "number": 655, "title": " Importing ABC directly from collections was deprecated and will be removed in Python 3.10. Use collections.abc", "user": {"login": "tirkarthi", "id": 3972343, "node_id": "MDQ6VXNlcjM5NzIzNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3972343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tirkarthi", "html_url": "https://github.com/tirkarthi", "followers_url": "https://api.github.com/users/tirkarthi/followers", "following_url": "https://api.github.com/users/tirkarthi/following{/other_user}", "gists_url": "https://api.github.com/users/tirkarthi/gists{/gist_id}", "starred_url": "https://api.github.com/users/tirkarthi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tirkarthi/subscriptions", "organizations_url": "https://api.github.com/users/tirkarthi/orgs", "repos_url": "https://api.github.com/users/tirkarthi/repos", "events_url": "https://api.github.com/users/tirkarthi/events{/privacy}", "received_events_url": "https://api.github.com/users/tirkarthi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-03T04:40:02Z", "updated_at": "2020-05-04T13:21:16Z", "closed_at": "2020-05-04T13:21:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```\r\ndask_ml/utils.py\r\n5:from collections import Sequence\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/654", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/654/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/654/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/654/events", "html_url": "https://github.com/dask/dask-ml/issues/654", "id": 610761015, "node_id": "MDU6SXNzdWU2MTA3NjEwMTU=", "number": 654, "title": "Dask-ml imputer cannot covert NA values", "user": {"login": "ks233ever", "id": 42351537, "node_id": "MDQ6VXNlcjQyMzUxNTM3", "avatar_url": "https://avatars1.githubusercontent.com/u/42351537?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ks233ever", "html_url": "https://github.com/ks233ever", "followers_url": "https://api.github.com/users/ks233ever/followers", "following_url": "https://api.github.com/users/ks233ever/following{/other_user}", "gists_url": "https://api.github.com/users/ks233ever/gists{/gist_id}", "starred_url": "https://api.github.com/users/ks233ever/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ks233ever/subscriptions", "organizations_url": "https://api.github.com/users/ks233ever/orgs", "repos_url": "https://api.github.com/users/ks233ever/repos", "events_url": "https://api.github.com/users/ks233ever/events{/privacy}", "received_events_url": "https://api.github.com/users/ks233ever/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2020-05-01T03:38:38Z", "updated_at": "2020-05-08T20:04:25Z", "closed_at": "2020-05-08T20:04:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm running the following code;\r\n\r\nfrom dask_ml import impute\r\nimputer = impute.SimpleImputer(strategy='mean')\r\nX = imputer.fit_transform(X_pred).compute()\r\nX_pred is a dask distributed dataframe of 371 columns which are float64 and int64\r\n\r\nThis returns a ValueError --\r\nValueError: Cannot convert non-finite values (NA or inf) to integer\r\n\r\nExpected Outcome: convert NA to integer \r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/647", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/647/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/647/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/647/events", "html_url": "https://github.com/dask/dask-ml/issues/647", "id": 601893385, "node_id": "MDU6SXNzdWU2MDE4OTMzODU=", "number": 647, "title": "dask_ml.model_selection.GridSearchCV throwing error \"assert not is_dask_collection(x)\" even when inputs are dask dataframes", "user": {"login": "SonyFrancis", "id": 62931282, "node_id": "MDQ6VXNlcjYyOTMxMjgy", "avatar_url": "https://avatars0.githubusercontent.com/u/62931282?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SonyFrancis", "html_url": "https://github.com/SonyFrancis", "followers_url": "https://api.github.com/users/SonyFrancis/followers", "following_url": "https://api.github.com/users/SonyFrancis/following{/other_user}", "gists_url": "https://api.github.com/users/SonyFrancis/gists{/gist_id}", "starred_url": "https://api.github.com/users/SonyFrancis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SonyFrancis/subscriptions", "organizations_url": "https://api.github.com/users/SonyFrancis/orgs", "repos_url": "https://api.github.com/users/SonyFrancis/repos", "events_url": "https://api.github.com/users/SonyFrancis/events{/privacy}", "received_events_url": "https://api.github.com/users/SonyFrancis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-17T11:07:36Z", "updated_at": "2020-04-27T13:48:14Z", "closed_at": "2020-04-27T13:48:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am getting this issue even when my inputs to the dask_ml.model_selection.GridSearchCV function is a dask dataframe\r\n\r\nCode below:\r\nimport dask\r\nimport joblib\r\nimport numpy as np\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom dask_ml.preprocessing import StandardScaler\r\nfrom dask_ml.preprocessing import Categorizer, OrdinalEncoder\r\nfrom dask.distributed import Client\r\n\r\ndata = pd.DataFrame({\"x0\":[1,1,2,2,2,2,2,1,1], \"x1\":[1,1,3,5,5,5,5,1,1],\r\n\"x2\": [1.5,2.6,0,0,0,0,0,1.3,3.7], \"x3\":[1,1,1,1,2,1,2,1,1], \"x4\" :[\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"Y\",\"N\"],\r\n\"x5\" :[151,239,236,193,193,193,193,163,229], \"x6\":[239,246,236,193,193,193,193,229,7],\r\n\"x7\":[1,1,1,2,2,2,2,1,1], \"x8\":[7,14,4.5,3.5,52,3.5,52,6.5,13.5],\r\n\"x9\":[0.5,0.5,0.5,0.5,0,0.5,0,0.5,0.5], \"x10\":[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5],\r\n\"x11\":[1.65,1,0,0,0,0,0,1.25,3.7], \"x12\":[0,0,0,0,0,5.76,0,0,0],\r\n\"x13\":[0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3], \"target\":[9.95,16.3,5.8,7.55,55.55,13.31,55.55,9.05,18.5]})\r\ndata = dd.from_pandas(data,npartitions=1)\r\n\r\nlabel_vars = ['x0', 'x1', 'x3', 'x4', 'x7', 'x9', 'x10', 'x13']\r\nnumeric_vars = ['x2', 'x5', 'x6', 'x8', 'x11', 'x12']\r\ncat = Categorizer(columns=label_vars)\r\ndata= cat.fit_transform(data)\r\n\r\nen = OrdinalEncoder(columns=label_vars)\r\ndata = en.fit_transform(data)\r\n\r\nsc = StandardScaler()\r\ndata[numeric_vars] = sc.fit_transform(data[numeric_vars])\r\n\r\nX=data.drop([\"target\"], axis = 1)\r\ny=data[\"target\"]\r\nclient = Client(processes=False)\r\nwith joblib.parallel_backend('dask'):\r\n     model1 = RandomForestRegressor()\r\n     params = {'max_depth': [3,4,5], 'n_estimators':[100,200,300,400,500], 'min_samples_split':\r\n                    [2,3,4,5,6], 'min_samples_leaf': [1, 3]}\r\n     model = GridSearchCV(model1,params)\r\n     model.fit(X,y)\r\n\r\n#----------------------Error----------------------------#\r\nX-type:<class 'dask.dataframe.core.DataFrame'>, Y-type:<class 'dask.dataframe.core.Series'>\r\nTraceback (most recent call last):\r\nFile \".\\testing_dask_inprogress.py\", line 290, in\r\nmodel.fit(X,y)\r\nFile \"C:\\Users\\SONY\\miniconda3\\lib\\site-packages\\dask_ml\\model_selection_search.py\", line 1233, in fit\r\ncache_cv=self.cache_cv,\r\nFile \"C:\\Users\\SONY\\miniconda3\\lib\\site-packages\\dask_ml\\model_selection_search.py\", line 203, in build_cv_graph\r\nX_name, y_name, groups_name = to_keys(dsk, X, y, groups)\r\nFile \"C:\\Users\\SONY\\miniconda3\\lib\\site-packages\\dask_ml\\model_selection\\utils.py\", line 87, in to_keys\r\nassert not is_dask_collection(x)\r\nAssertionError", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/641", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/641/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/641/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/641/events", "html_url": "https://github.com/dask/dask-ml/issues/641", "id": 598506584, "node_id": "MDU6SXNzdWU1OTg1MDY1ODQ=", "number": 641, "title": "Rendering issue with examples", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-12T15:12:31Z", "updated_at": "2020-04-13T19:13:57Z", "closed_at": "2020-04-13T19:13:57Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "On https://ml.dask.org/xgboost.html#how-this-works:\r\n\r\n<img width=\"724\" alt=\"Screen Shot 2020-04-12 at 10 11 33 AM\" src=\"https://user-images.githubusercontent.com/1320475/79072310-ea590b00-7ccf-11ea-8dcc-dc6694b122f4.png\">\r\n\r\nI believe \"examples/xgboost\" is supposed to provide a link to dask-examples.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/639", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/639/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/639/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/639/events", "html_url": "https://github.com/dask/dask-ml/issues/639", "id": 598121406, "node_id": "MDU6SXNzdWU1OTgxMjE0MDY=", "number": 639, "title": "yield tests were removed in pytest 4.0 ", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-10T22:26:50Z", "updated_at": "2020-04-11T02:12:31Z", "closed_at": "2020-04-11T02:12:31Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "While working on #528, I'm implementing some tests in the `dask-ml-test` environment in `ci/environment-3.7.yaml`. When I run my new test, I get the below warning about \"yield tests being removed in pytest 4.0\". This means my test is effectively ignored.\r\n\r\n``` shell\r\n$ pytest -k \"invalid_verb\" --pdb\r\nplatform darwin -- Python 3.7.6, pytest-5.4.1, py-1.8.1, pluggy-0.13.0 -- /Users/scott/anaconda3/envs/dask-ml-test/bin/python\r\ncachedir: .pytest_cache\r\nrootdir: /Users/scott/Developer/stsievert/dask-ml, inifile: setup.cfg\r\nplugins: azurepipelines-0.8.0, mock-3.0.0, cov-2.8.1\r\ncollected 623 items / 622 deselected / 1 selected\r\n##vso[task.logissue type=warning;]yield tests were removed in pytest 4.0 - test_invalid_verbosity will be ignored\r\n\r\ntests/model_selection/test_incremental.py::test_invalid_verbosity XFAIL [100%]##vso[results.publish type=JUnit;runTitle='Pytest results';]/Users/scott/Developer/stsievert/dask-ml/test-output.xml\r\n##vso[task.logissue type=warning;]Coverage XML was not created, skipping upload.\r\n\r\n\r\n=========================== warnings summary ===========================\r\ntests/model_selection/test_incremental.py:672\r\n  tests/model_selection/test_incremental.py:672: PytestCollectionWarning: yield tests were removed in pytest 4.0 - test_invalid_verbosity will be ignored\r\n    def test_invalid_verbosity():\r\n\r\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\r\n- generated xml file: /Users/scott/Developer/stsievert/dask-ml/test-output.xml -\r\n====================== slowest 10 test durations =======================\r\n\r\n(0.00 durations hidden.  Use -vv to show these durations.)\r\n======================= short test summary info ========================\r\nXFAIL tests/model_selection/test_incremental.py::test_invalid_verbosity\r\n  reason: [NOTRUN] yield tests were removed in pytest 4.0 - test_invalid_verbosity will be ignored\r\n```\r\n\r\nThere are 68 `yield`s in `tests/model_selection`, 74 in `tests`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/633", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/633/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/633/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/633/events", "html_url": "https://github.com/dask/dask-ml/issues/633", "id": 591960614, "node_id": "MDU6SXNzdWU1OTE5NjA2MTQ=", "number": 633, "title": "Linting issues not failing CI", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-01T14:28:48Z", "updated_at": "2020-05-12T15:32:06Z", "closed_at": "2020-05-12T15:32:06Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://dev.azure.com/dask-dev/dask/_build/results?buildId=818&view=logs&j=34469798-9dec-5482-c96c-ad1eda9ec58d&t=3856b5af-eaa9-56ed-b4cc-e7b6fad51231&l=12 / https://github.com/dask/dask-ml/pull/630#issuecomment-607283125.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/628", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/628/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/628/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/628/events", "html_url": "https://github.com/dask/dask-ml/issues/628", "id": 587746864, "node_id": "MDU6SXNzdWU1ODc3NDY4NjQ=", "number": 628, "title": "Support DataFrame in IncrementalSearchCV", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-25T14:41:26Z", "updated_at": "2020-08-05T21:52:15Z", "closed_at": "2020-08-05T21:52:15Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://stackoverflow.com/questions/60846247/this-estimator-does-not-support-dask-dataframes\r\n\r\n```python\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom distributed import Client\r\nfrom sklearn.linear_model import SGDClassifier\r\nfrom dask_ml.model_selection import IncrementalSearchCV\r\n\r\ndf = pd.DataFrame({\"A\": [1, 2, 3, 4, 5], \"B\": [0, 0, 1, 1, 1]})\r\nddf = dd.from_pandas(df, 2)\r\nX = df[[\"A\"]]\r\ny = df['B']\r\n\r\nmodel = SGDClassifier()\r\nparams = dict(alpha=[0.1, 1])\r\nsearch = IncrementalSearchCV(model, params)\r\n\r\nclient = Client()\r\n\r\nsearch.fit(X, y)\r\n```\r\n\r\nIf we accept dask dataframes\r\n\r\n```diff\r\ndiff --git a/dask_ml/model_selection/_incremental.py b/dask_ml/model_selection/_incremental.py\r\nindex 48f43be9..3219f8c1 100644\r\n--- a/dask_ml/model_selection/_incremental.py\r\n+++ b/dask_ml/model_selection/_incremental.py\r\n@@ -447,8 +447,8 @@ class BaseIncrementalSearchCV(ParallelPostFit):\r\n                 )\r\n             )\r\n \r\n-        X = self._check_array(X)\r\n-        y = self._check_array(y, ensure_2d=False)\r\n+        X = self._check_array(X, accept_dask_dataframe=True)\r\n+        y = self._check_array(y, ensure_2d=False, accept_dask_dataframe=True)\r\n         scorer = check_scoring(self.estimator, scoring=self.scoring)\r\n         return X, y, scorer\r\n \r\n```\r\n\r\nWe fail at\r\n\r\n```pytb\r\n~/sandbox/dask-ml/dask_ml/model_selection/_incremental.py in _fit(self, X, y, **fit_params)\r\n    556     def _fit(self, X, y, **fit_params):\r\n    557         X, y, scorer = self._validate_parameters(X, y)\r\n--> 558         X_train, X_test, y_train, y_test = self._get_train_test_split(X, y)\r\n    559 \r\n    560         results = yield fit(\r\n\r\n~/sandbox/dask-ml/dask_ml/model_selection/_incremental.py in _get_train_test_split(self, X, y, **kwargs)\r\n    484         \"\"\"\r\n    485         if self.test_size is None:\r\n--> 486             test_size = min(0.2, 1 / X.npartitions)\r\n    487         else:\r\n    488             test_size = self.test_size\r\n\r\nAttributeError: 'numpy.ndarray' object has no attribute 'npartitions'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/624", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/624/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/624/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/624/events", "html_url": "https://github.com/dask/dask-ml/issues/624", "id": 579292617, "node_id": "MDU6SXNzdWU1NzkyOTI2MTc=", "number": 624, "title": "OneHotEncoder inverse_transform with datetime64[ns] does not preserve other column dtypes", "user": {"login": "jocelynjyl", "id": 8165187, "node_id": "MDQ6VXNlcjgxNjUxODc=", "avatar_url": "https://avatars3.githubusercontent.com/u/8165187?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jocelynjyl", "html_url": "https://github.com/jocelynjyl", "followers_url": "https://api.github.com/users/jocelynjyl/followers", "following_url": "https://api.github.com/users/jocelynjyl/following{/other_user}", "gists_url": "https://api.github.com/users/jocelynjyl/gists{/gist_id}", "starred_url": "https://api.github.com/users/jocelynjyl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jocelynjyl/subscriptions", "organizations_url": "https://api.github.com/users/jocelynjyl/orgs", "repos_url": "https://api.github.com/users/jocelynjyl/repos", "events_url": "https://api.github.com/users/jocelynjyl/events{/privacy}", "received_events_url": "https://api.github.com/users/jocelynjyl/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-03-11T14:09:53Z", "updated_at": "2020-03-23T17:03:18Z", "closed_at": "2020-03-23T17:03:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm not sure if this is an issue with dask, dask-ml or something else altogether. I've noticed after calling inverse_transform where the dataframe contains a column of datetime64[ns], the non-categorical columns all become 'object' type. \r\n\r\nAs a side effect, you can't directly do df.to_parquet('output') on the inverse_transform dataframe. df.compute().to_parquet('output') works sometimes.  \r\n\r\nVersion info: \r\n>>> dask.__version__\r\n'2.10.1'\r\n>>> dask_ml.__version__\r\n'1.2.0'\r\n\r\nErrors I've seen so far: \r\n```\r\nValueError: Error converting column \"id\" to bytes using encoding UTF8. Original error: bad argument type for built-in operation\r\n```\r\n```\r\nValueError: Don't know how to convert data type: datetime64[ns, UTC]\r\n```\r\n\r\nMinimal code example: \r\nFollowing an example found here: [https://github.com/dask/dask-ml/issues/362#issuecomment-420283078]\r\n\r\n```\r\nimport dask.dataframe as dd\r\nfrom dask_ml.preprocessing import DummyEncoder, Categorizer\r\n\r\ndf = dd.demo.make_timeseries()\r\ndf.x = dd.to_datetime(df.x)\r\ncat = Categorizer(columns=['name'])\r\nde = DummyEncoder()\r\ndf_cat = cat.fit_transform(df)\r\nencoded = de.fit_transform(df_cat)\r\ndecoded = de.inverse_transform(encoded.values)\r\n\r\n>>> df\r\nDask DataFrame Structure:\r\n                   id    name               x        y\r\nnpartitions=11                                        \r\n2000-01-31      int64  object  datetime64[ns]  float64\r\n2000-02-29        ...     ...             ...      ...\r\n...               ...     ...             ...      ...\r\n2000-11-30        ...     ...             ...      ...\r\n2000-12-31        ...     ...             ...      ...\r\nDask Name: assign, 44 tasks\r\n>>> decoded\r\nDask DataFrame Structure:\r\n                    id             name       x       y\r\nnpartitions=11                                         \r\n0               object  category[known]  object  object\r\n250560             ...              ...     ...     ...\r\n...                ...              ...     ...     ...\r\n2626560            ...              ...     ...     ...\r\n2894399            ...              ...     ...     ...\r\nDask Name: getitem, 275 tasks\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/621", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/621/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/621/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/621/events", "html_url": "https://github.com/dask/dask-ml/issues/621", "id": 571765358, "node_id": "MDU6SXNzdWU1NzE3NjUzNTg=", "number": 621, "title": "SearchCV: memory issues on workers", "user": {"login": "IanQS", "id": 6968573, "node_id": "MDQ6VXNlcjY5Njg1NzM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6968573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IanQS", "html_url": "https://github.com/IanQS", "followers_url": "https://api.github.com/users/IanQS/followers", "following_url": "https://api.github.com/users/IanQS/following{/other_user}", "gists_url": "https://api.github.com/users/IanQS/gists{/gist_id}", "starred_url": "https://api.github.com/users/IanQS/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IanQS/subscriptions", "organizations_url": "https://api.github.com/users/IanQS/orgs", "repos_url": "https://api.github.com/users/IanQS/repos", "events_url": "https://api.github.com/users/IanQS/events{/privacy}", "received_events_url": "https://api.github.com/users/IanQS/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-02-27T01:39:42Z", "updated_at": "2020-04-08T17:15:46Z", "closed_at": "2020-04-08T17:15:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey all! \r\n \r\n# Scenario\r\n\r\nSay I have 50 workers and the number of combinations of parameters from doing my `SearchCV` is also 50. My workers are dying out and it SEEMS like only 30 or 40 of them are getting \"saturated\" while the rest sit idly.\r\n\r\n# My hypothesis\r\n\r\nThis makes me think that some workers are being made to do multiple training jobs since, in theory, a single \"dataset\" on the worker shouldn't cause an error but if it were to double in size, it would. \r\n\r\n# Questions\r\n\r\nIf my hypothesis is correct is it possible to schedule it via something like [dask worker resources](https://distributed.readthedocs.io/en/latest/resources.html#worker-resources) with `dask-ml`? \r\n\r\nOr would I need to manually do it on my own by combining `dask-delayed` and doing manual resource management from the link above? \r\n\r\n---\r\n\r\nIf my hypothesis is wrong, do you know what the issue might be? Happy to provide logs or errors but I'm not sure what is or isn't relevant\r\n\r\nThank you so much for your time! ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/618", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/618/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/618/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/618/events", "html_url": "https://github.com/dask/dask-ml/issues/618", "id": 569348843, "node_id": "MDU6SXNzdWU1NjkzNDg4NDM=", "number": 618, "title": "disambiguation between xgboost.dask vs dask-ml xgboost", "user": {"login": "sandys", "id": 76883, "node_id": "MDQ6VXNlcjc2ODgz", "avatar_url": "https://avatars2.githubusercontent.com/u/76883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sandys", "html_url": "https://github.com/sandys", "followers_url": "https://api.github.com/users/sandys/followers", "following_url": "https://api.github.com/users/sandys/following{/other_user}", "gists_url": "https://api.github.com/users/sandys/gists{/gist_id}", "starred_url": "https://api.github.com/users/sandys/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sandys/subscriptions", "organizations_url": "https://api.github.com/users/sandys/orgs", "repos_url": "https://api.github.com/users/sandys/repos", "events_url": "https://api.github.com/users/sandys/events{/privacy}", "received_events_url": "https://api.github.com/users/sandys/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-22T15:22:37Z", "updated_at": "2020-02-25T19:26:35Z", "closed_at": "2020-02-25T19:26:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "The recent 1.0.0 release of xgboost brings the xgboost.dask interface .\r\nA relevant example is here - https://github.com/dmlc/xgboost/blob/master/demo/dask/sklearn_cpu_training.py\r\n\r\nthe related documentation is here - https://xgboost.readthedocs.io/en/latest/tutorials/dask.html\r\n\r\nthere are intertwined usecases - e.g. xgb.dask.DaskDMatrix vs the work being done in https://github.com/dask/dask-ml/issues/605 \r\n\r\nHow do you see both these projects co-existing ? will one subsume the other ? we are currently on dask-ml and wondering which direction to go in.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/617", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/617/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/617/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/617/events", "html_url": "https://github.com/dask/dask-ml/issues/617", "id": 569230603, "node_id": "MDU6SXNzdWU1NjkyMzA2MDM=", "number": 617, "title": "IncrementalPCA", "user": {"login": "fujiisoup", "id": 6815844, "node_id": "MDQ6VXNlcjY4MTU4NDQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/6815844?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fujiisoup", "html_url": "https://github.com/fujiisoup", "followers_url": "https://api.github.com/users/fujiisoup/followers", "following_url": "https://api.github.com/users/fujiisoup/following{/other_user}", "gists_url": "https://api.github.com/users/fujiisoup/gists{/gist_id}", "starred_url": "https://api.github.com/users/fujiisoup/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fujiisoup/subscriptions", "organizations_url": "https://api.github.com/users/fujiisoup/orgs", "repos_url": "https://api.github.com/users/fujiisoup/repos", "events_url": "https://api.github.com/users/fujiisoup/events{/privacy}", "received_events_url": "https://api.github.com/users/fujiisoup/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-02-21T23:13:05Z", "updated_at": "2020-04-08T15:42:45Z", "closed_at": "2020-04-08T15:42:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi all,\r\n\r\nAlthough dask-ml already has PCA and wrappers.Incremented, but there is no IncrementalPCA.\r\nIs this in the scope of development?\r\n\r\nWith dask-ml's PCA, we can handle large data, but if the data is too large, some approximated algorithms may be necessary.\r\nWith wrappers.Incremental, we could use scikit-learn's IncrementalPCA, but it internally uses scipy.linalg.svd, which won't run with large feature size of data.\r\n\r\nFor me it would be nicer if dask-ml has dask-compatible IncrementalPCA.\r\n\r\nI implemented it in my folk, most part of which is stolen from scikit-learn but uses dask.array.linalg.svd_compressed internally.\r\nIf it is in the scope, I will clean it a bit and send a PR.\r\n\r\nThank you!\r\n\r\ncc:\r\n@demaheim\r\n@yasahi-hpc", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/607", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/607/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/607/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/607/events", "html_url": "https://github.com/dask/dask-ml/issues/607", "id": 558572736, "node_id": "MDU6SXNzdWU1NTg1NzI3MzY=", "number": 607, "title": "Add mild type annotations", "user": {"login": "mrocklin", "id": 306380, "node_id": "MDQ6VXNlcjMwNjM4MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/306380?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrocklin", "html_url": "https://github.com/mrocklin", "followers_url": "https://api.github.com/users/mrocklin/followers", "following_url": "https://api.github.com/users/mrocklin/following{/other_user}", "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions", "organizations_url": "https://api.github.com/users/mrocklin/orgs", "repos_url": "https://api.github.com/users/mrocklin/repos", "events_url": "https://api.github.com/users/mrocklin/events{/privacy}", "received_events_url": "https://api.github.com/users/mrocklin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 731685853, "node_id": "MDU6TGFiZWw3MzE2ODU4NTM=", "url": "https://api.github.com/repos/dask/dask-ml/labels/good%20first%20issue", "name": "good first issue", "color": "b60205", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-02-01T17:45:25Z", "updated_at": "2020-04-02T17:45:36Z", "closed_at": "2020-04-02T17:45:36Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I'm looking through the model selection code and I find myself curious what the various inputs and outputs are to functions.  This might be a bit of our codebase that could use with some mild type annotations.  \r\n\r\nThis might be a good activity for someone who wanted to become familiar with the Dask-ML codebase.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/604", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/604/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/604/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/604/events", "html_url": "https://github.com/dask/dask-ml/issues/604", "id": 555067242, "node_id": "MDU6SXNzdWU1NTUwNjcyNDI=", "number": 604, "title": "Does randomized TruncatedSVD really work on big, non-skinny datasets?", "user": {"login": "georgeblck", "id": 6574368, "node_id": "MDQ6VXNlcjY1NzQzNjg=", "avatar_url": "https://avatars2.githubusercontent.com/u/6574368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgeblck", "html_url": "https://github.com/georgeblck", "followers_url": "https://api.github.com/users/georgeblck/followers", "following_url": "https://api.github.com/users/georgeblck/following{/other_user}", "gists_url": "https://api.github.com/users/georgeblck/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgeblck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgeblck/subscriptions", "organizations_url": "https://api.github.com/users/georgeblck/orgs", "repos_url": "https://api.github.com/users/georgeblck/repos", "events_url": "https://api.github.com/users/georgeblck/events{/privacy}", "received_events_url": "https://api.github.com/users/georgeblck/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-01-25T10:06:17Z", "updated_at": "2020-01-29T17:45:39Z", "closed_at": "2020-01-29T00:54:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to calculate a TruncatedSVD on data that is too big to fit in memory. The original `sklearn.decomposition` implementation does not work in any case, so I have been trying to use the dask-ml version (that is based on the `dask.array.linalg.svd_compressed` algorithm).\r\n\r\nHere is a minimal code that uses data similar to mine and gets killed because of too much RAM; depending on your locally available RAM the dimensions of the dataset might have to be adapted.\r\n\r\n```\r\nimport dask_ml.decomposition ## version 1.2.0\r\nimport dask.array as da  ## version 2.9.2\r\nimport numpy as np\r\n\r\n# Create Random data\r\nbigData = da.random.random((70000, 500000)).astype(np.float32).rechunk('auto')\r\n# Fit the SVD\r\nsvd = dask_ml.decomposition.TruncatedSVD(4000, \"randomized\")\r\nsvd.fit(test)\r\nsmallDat = svd.transform(test)\r\n```\r\n\r\nMaybe this is connected to  #401 or I just don't understand the use cases of dask? Or maybe I am chunking my data wrong?\r\n\r\nThanks in advance for any help!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/597", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/597/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/597/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/597/events", "html_url": "https://github.com/dask/dask-ml/issues/597", "id": 545153208, "node_id": "MDU6SXNzdWU1NDUxNTMyMDg=", "number": 597, "title": "import dask_ml.cluster raises a ModuleNotFoundError from sklearn", "user": {"login": "petermorrow", "id": 9690235, "node_id": "MDQ6VXNlcjk2OTAyMzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9690235?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petermorrow", "html_url": "https://github.com/petermorrow", "followers_url": "https://api.github.com/users/petermorrow/followers", "following_url": "https://api.github.com/users/petermorrow/following{/other_user}", "gists_url": "https://api.github.com/users/petermorrow/gists{/gist_id}", "starred_url": "https://api.github.com/users/petermorrow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petermorrow/subscriptions", "organizations_url": "https://api.github.com/users/petermorrow/orgs", "repos_url": "https://api.github.com/users/petermorrow/repos", "events_url": "https://api.github.com/users/petermorrow/events{/privacy}", "received_events_url": "https://api.github.com/users/petermorrow/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-01-03T20:37:21Z", "updated_at": "2020-01-06T20:54:11Z", "closed_at": "2020-01-06T20:54:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\n$ pip install dask-ml\r\n$ python\r\n>>> import dask_ml.cluster\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/peter/.virtualenvs/DASK/lib/python3.7/site-packages/dask_ml/cluster/__init__.py\", line 3, in <module>\r\n    from .k_means import KMeans  # noqa\r\n  File \"/Users/peter/.virtualenvs/DASK/lib/python3.7/site-packages/dask_ml/cluster/k_means.py\", line 23, in <module>\r\n    from ._compat import _k_init\r\n  File \"/Users/peter/.virtualenvs/DASK/lib/python3.7/site-packages/dask_ml/cluster/_compat.py\", line 4, in <module>\r\n    from sklearn.cluster._k_means import _k_init\r\nModuleNotFoundError: No module named 'sklearn.cluster._k_means'\r\n>>>\r\n```\r\n\r\nIt looks like this issue is related to the latest version of scikit-learn deprecating that module, because installing with the previous version of scikit-learn works.\r\n\r\n```\r\n$ pip install dask-ml==1.1.1 scikit-learn==0.21.*\r\n$ python\r\n>>> import dask_ml.cluster\r\n>>>\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/593", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/593/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/593/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/593/events", "html_url": "https://github.com/dask/dask-ml/issues/593", "id": 539032514, "node_id": "MDU6SXNzdWU1MzkwMzI1MTQ=", "number": 593, "title": "Is `nearest_neighbors` available in spectral clustering?", "user": {"login": "yl-1993", "id": 4398342, "node_id": "MDQ6VXNlcjQzOTgzNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4398342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yl-1993", "html_url": "https://github.com/yl-1993", "followers_url": "https://api.github.com/users/yl-1993/followers", "following_url": "https://api.github.com/users/yl-1993/following{/other_user}", "gists_url": "https://api.github.com/users/yl-1993/gists{/gist_id}", "starred_url": "https://api.github.com/users/yl-1993/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yl-1993/subscriptions", "organizations_url": "https://api.github.com/users/yl-1993/orgs", "repos_url": "https://api.github.com/users/yl-1993/repos", "events_url": "https://api.github.com/users/yl-1993/events{/privacy}", "received_events_url": "https://api.github.com/users/yl-1993/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-12-17T12:21:16Z", "updated_at": "2019-12-18T16:06:00Z", "closed_at": "2019-12-18T16:06:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "In the [document of spectral clustering](https://github.com/dask/dask-ml/blob/92aca8c2166912d0ca80d118628f47ba943779c6/dask_ml/cluster/spectral.py#L53), it states to support `nearest_neighbors' and 'precomputed'. But it seems that the spectral clustering actually supports [these four metrics](https://github.com/dask/dask-ml/blob/92aca8c2166912d0ca80d118628f47ba943779c6/dask_ml/metrics/pairwise.py#L155).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/592", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/592/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/592/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/592/events", "html_url": "https://github.com/dask/dask-ml/issues/592", "id": 535498687, "node_id": "MDU6SXNzdWU1MzU0OTg2ODc=", "number": 592, "title": "dask_ml.decomposition.PCA: ValueError with data > 1 TB", "user": {"login": "demaheim", "id": 50140057, "node_id": "MDQ6VXNlcjUwMTQwMDU3", "avatar_url": "https://avatars1.githubusercontent.com/u/50140057?v=4", "gravatar_id": "", "url": "https://api.github.com/users/demaheim", "html_url": "https://github.com/demaheim", "followers_url": "https://api.github.com/users/demaheim/followers", "following_url": "https://api.github.com/users/demaheim/following{/other_user}", "gists_url": "https://api.github.com/users/demaheim/gists{/gist_id}", "starred_url": "https://api.github.com/users/demaheim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/demaheim/subscriptions", "organizations_url": "https://api.github.com/users/demaheim/orgs", "repos_url": "https://api.github.com/users/demaheim/repos", "events_url": "https://api.github.com/users/demaheim/events{/privacy}", "received_events_url": "https://api.github.com/users/demaheim/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-12-10T05:13:54Z", "updated_at": "2019-12-12T17:00:47Z", "closed_at": "2019-12-12T12:23:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When I do `dask_ml.decomposition.PCA().fit(x)`, where the array `x` has a size > 1 TB, I get the error `ValueError: output array is read-only`.\r\n\r\nI use\r\n```\r\ndask-ml                   1.1.1\r\ndistributed               2.9.0\r\n```\r\n\r\nThe script\r\n```python\r\nfrom dask_jobqueue import SLURMCluster\r\nfrom dask.distributed import Client\r\nfrom dask_ml.decomposition import PCA\r\nimport dask.array as da\r\n\r\ncluster = SLURMCluster()\r\nnb_workers = 58\r\ncluster.scale(nb_workers)\r\nclient = Client(cluster)\r\nclient.wait_for_workers(nb_workers)\r\n\r\nx = da.random.random((1000000, 140000), chunks=(100000, 2000))\r\npca = PCA(n_components=64)\r\npca.fit(x)\r\n```\r\ngives the error\r\n```\r\nTraceback (most recent call last):\r\n  File \"value_error.py\", line 48, in <module>\r\n    pca.fit(x)\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/dask_ml/decomposition/pca.py\", line 190, in fit\r\n    self._fit(X)\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/dask_ml/decomposition/pca.py\", line 338, in _fit\r\n    raise e\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/dask_ml/decomposition/pca.py\", line 325, in _fit\r\n    singular_values,\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/dask/base.py\", line 436, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/distributed/client.py\", line 2573, in get\r\n    results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/distributed/client.py\", line 1873, in gather\r\n    asynchronous=asynchronous,\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/distributed/client.py\", line 768, in sync\r\n    self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/distributed/utils.py\", line 334, in sync\r\n    raise exc.with_traceback(tb)\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/distributed/utils.py\", line 318, in f\r\n    result[0] = yield future\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\r\n    value = future.result()\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/distributed/client.py\", line 1729, in _gather\r\n    raise exception.with_traceback(traceback)\r\n  File \"/home/dheim/miniconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\", line 516, in svd_flip\r\n    v *= signs[:, np.newaxis]\r\nValueError: output array is read-only\r\n```\r\nNote that\r\n- If I use `x = da.random.random((1000000, 130000), chunks=(100000, 2000))` (1.0 TB), the error does not appear.\r\n- When I look at the dashboard, the PCA seems to run fine and the error appears at the very end of the computation.\r\n- I temporarily fixed the error in `extmath.py` by changing\r\n```diff\r\ndef svd_flip(u, v, u_based_decision=True):\r\n    if u_based_decision:\r\n        # columns of u, rows of v\r\n        max_abs_cols = np.argmax(np.abs(u), axis=0)\r\n        signs = np.sign(u[max_abs_cols, range(u.shape[1])])\r\n        u *= signs\r\n-        v *= signs[:, np.newaxis]\r\n+        v_copy = np.copy(v)\r\n+        v_copy *= signs[:, np.newaxis]\r\n+        return u, v_copy\r\n    else:\r\n```\r\nI think this is not a good fix because I assume that the array `v` is blocked by another function.\r\nIs there another way to fix the error?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/591", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/591/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/591/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/591/events", "html_url": "https://github.com/dask/dask-ml/issues/591", "id": 534899366, "node_id": "MDU6SXNzdWU1MzQ4OTkzNjY=", "number": 591, "title": "import dask_ml.joblib raises error", "user": {"login": "kwunlyou", "id": 1352316, "node_id": "MDQ6VXNlcjEzNTIzMTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1352316?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kwunlyou", "html_url": "https://github.com/kwunlyou", "followers_url": "https://api.github.com/users/kwunlyou/followers", "following_url": "https://api.github.com/users/kwunlyou/following{/other_user}", "gists_url": "https://api.github.com/users/kwunlyou/gists{/gist_id}", "starred_url": "https://api.github.com/users/kwunlyou/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kwunlyou/subscriptions", "organizations_url": "https://api.github.com/users/kwunlyou/orgs", "repos_url": "https://api.github.com/users/kwunlyou/repos", "events_url": "https://api.github.com/users/kwunlyou/events{/privacy}", "received_events_url": "https://api.github.com/users/kwunlyou/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-09T12:31:13Z", "updated_at": "2020-01-06T21:01:41Z", "closed_at": "2020-01-06T21:01:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "running `import dask_ml.joblib` will raise an error as\r\n\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-1-63a6aa9c7464> in <module>\r\n----> 1 import dask_ml.joblib  # registers joblib plugin\r\n\r\n/usr/local/lib/python3.6/dist-packages/dask_ml/joblib.py in <module>\r\n----> 1 import distributed.joblib  # noqa\r\n\r\nModuleNotFoundError: No module named 'distributed.joblib'\r\n```\r\n\r\n```\r\ndask-ml              1.1.1\r\ndistributed          2.9.0\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/587", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/587/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/587/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/587/events", "html_url": "https://github.com/dask/dask-ml/issues/587", "id": 526140502, "node_id": "MDU6SXNzdWU1MjYxNDA1MDI=", "number": 587, "title": "Included conda environment is not suitable on a Mac", "user": {"login": "datajanko", "id": 11876547, "node_id": "MDQ6VXNlcjExODc2NTQ3", "avatar_url": "https://avatars0.githubusercontent.com/u/11876547?v=4", "gravatar_id": "", "url": "https://api.github.com/users/datajanko", "html_url": "https://github.com/datajanko", "followers_url": "https://api.github.com/users/datajanko/followers", "following_url": "https://api.github.com/users/datajanko/following{/other_user}", "gists_url": "https://api.github.com/users/datajanko/gists{/gist_id}", "starred_url": "https://api.github.com/users/datajanko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/datajanko/subscriptions", "organizations_url": "https://api.github.com/users/datajanko/orgs", "repos_url": "https://api.github.com/users/datajanko/repos", "events_url": "https://api.github.com/users/datajanko/events{/privacy}", "received_events_url": "https://api.github.com/users/datajanko/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-20T19:59:00Z", "updated_at": "2019-11-20T21:11:53Z", "closed_at": "2019-11-20T21:11:53Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hey, I just wanted to use the provided conda environment file and found several issues:\r\n\r\nFirstly, not all dependencies are installed on a Mac:\r\n```\r\nImportError while loading conftest '/Users/jankoch/Projects/own/dask-ml/tests/conftest.py'.\r\ntests/conftest.py:4: in <module>\r\n    import dask.dataframe as dd\r\n//miniconda3/envs/dask-ml-dev/lib/python3.6/site-packages/dask/dataframe/__init__.py:55: in <module>\r\n    raise ImportError(str(e) + \"\\n\\n\" + msg)\r\nE   ImportError: fsspec is required to use any file-system functionality. Please install using\r\nE   conda install -c conda-forge 'fsspec>=0.3.3'\r\nE   or\r\nE   pip install 'fsspec>=0.3.3'\r\nE\r\nE   Dask dataframe requirements are not installed.\r\nE\r\nE   Please either conda or pip install as follows:\r\nE\r\nE     conda install dask                     # either conda install\r\nE     pip install dask[dataframe] --upgrade  # or pip install\r\n```\r\n\r\nsecondly, when trying to install pre-commit (which occasionally is better to install via conda). A lot of packages need to be updated.\r\n\r\nIs anybody having similar experiences?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/585", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/585/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/585/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/585/events", "html_url": "https://github.com/dask/dask-ml/issues/585", "id": 525039713, "node_id": "MDU6SXNzdWU1MjUwMzk3MTM=", "number": 585, "title": "dask-searchcv mentioned in dask-ml docs", "user": {"login": "lebedov", "id": 218546, "node_id": "MDQ6VXNlcjIxODU0Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/218546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lebedov", "html_url": "https://github.com/lebedov", "followers_url": "https://api.github.com/users/lebedov/followers", "following_url": "https://api.github.com/users/lebedov/following{/other_user}", "gists_url": "https://api.github.com/users/lebedov/gists{/gist_id}", "starred_url": "https://api.github.com/users/lebedov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lebedov/subscriptions", "organizations_url": "https://api.github.com/users/lebedov/orgs", "repos_url": "https://api.github.com/users/lebedov/repos", "events_url": "https://api.github.com/users/lebedov/events{/privacy}", "received_events_url": "https://api.github.com/users/lebedov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-19T14:20:56Z", "updated_at": "2019-11-20T13:33:25Z", "closed_at": "2019-11-20T13:33:24Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "It appears that dask-searchcv is still explicitly mentioned in some parts of the dask-ml documentation (e.g., [here](https://github.com/dask/dask-ml/blame/master/docs/source/hyper-parameter-search.rst#L57)) despite having been merged.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/578", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/578/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/578/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/578/events", "html_url": "https://github.com/dask/dask-ml/issues/578", "id": 516357685, "node_id": "MDU6SXNzdWU1MTYzNTc2ODU=", "number": 578, "title": "Sklearn pipeline and cross_val_score don't work for some transformers", "user": {"login": "magehex", "id": 57193292, "node_id": "MDQ6VXNlcjU3MTkzMjky", "avatar_url": "https://avatars0.githubusercontent.com/u/57193292?v=4", "gravatar_id": "", "url": "https://api.github.com/users/magehex", "html_url": "https://github.com/magehex", "followers_url": "https://api.github.com/users/magehex/followers", "following_url": "https://api.github.com/users/magehex/following{/other_user}", "gists_url": "https://api.github.com/users/magehex/gists{/gist_id}", "starred_url": "https://api.github.com/users/magehex/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/magehex/subscriptions", "organizations_url": "https://api.github.com/users/magehex/orgs", "repos_url": "https://api.github.com/users/magehex/repos", "events_url": "https://api.github.com/users/magehex/events{/privacy}", "received_events_url": "https://api.github.com/users/magehex/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-11-01T21:32:48Z", "updated_at": "2019-11-04T11:39:55Z", "closed_at": "2019-11-04T11:39:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\n```\r\nfrom sklearn.pipeline import make_pipeline\r\nfrom sklearn.model_selection import cross_val_score\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\nfrom dask_ml.decomposition import PCA\r\nfrom dask_ml.wrappers import ParallelPostFit\r\nfrom dask_ml.preprocessing import StandardScaler\r\n\r\nclf = ParallelPostFit(estimator=GradientBoostingClassifier(), scoring='accuracy')\r\n\r\npipe = make_pipeline(PCA(),clf)\r\npipe = make_pipeline(StandardScaler(),clf)\r\n\r\nmysc = cross_val_score(pipe, dataset.iloc[:,:-1], dataset.iloc[:,-1])\r\n```\r\nWork for pipe = make_pipeline(StandardScaler(),clf) but not for pipe = make_pipeline(PCA(),clf)\r\nGot the error:\r\nAttributeError: 'DataFrame' object has no attribute 'chunks'\r\n\r\nIf I use RobustScaler() instead of StandardScaler():\r\nAttributeError: 'int' object has no attribute 'ndim'\r\n\r\nHow can I fix this problem?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/576", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/576/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/576/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/576/events", "html_url": "https://github.com/dask/dask-ml/issues/576", "id": 515465800, "node_id": "MDU6SXNzdWU1MTU0NjU4MDA=", "number": 576, "title": "Mac 10.15 Assertion failed", "user": {"login": "tinyms", "id": 331649, "node_id": "MDQ6VXNlcjMzMTY0OQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/331649?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tinyms", "html_url": "https://github.com/tinyms", "followers_url": "https://api.github.com/users/tinyms/followers", "following_url": "https://api.github.com/users/tinyms/following{/other_user}", "gists_url": "https://api.github.com/users/tinyms/gists{/gist_id}", "starred_url": "https://api.github.com/users/tinyms/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tinyms/subscriptions", "organizations_url": "https://api.github.com/users/tinyms/orgs", "repos_url": "https://api.github.com/users/tinyms/repos", "events_url": "https://api.github.com/users/tinyms/events{/privacy}", "received_events_url": "https://api.github.com/users/tinyms/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-10-31T14:13:03Z", "updated_at": "2019-11-01T02:28:29Z", "closed_at": "2019-11-01T02:28:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "when `from dask_ml.cluster import KMeans` and run throw:\r\n\r\nAssertion failed: (PassInf && \"Expected all immutable passes to be initialized\"), function addImmutablePass, file /Users/buildbot/miniconda3/conda-bld/llvmdev_1556270736866/work/lib/IR/LegacyPassManager.cpp, line 849.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/575", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/575/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/575/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/575/events", "html_url": "https://github.com/dask/dask-ml/issues/575", "id": 514985068, "node_id": "MDU6SXNzdWU1MTQ5ODUwNjg=", "number": 575, "title": "ColumnTransformer is broken in Version 1.1.0 wheel on pypi", "user": {"login": "fdion", "id": 1105325, "node_id": "MDQ6VXNlcjExMDUzMjU=", "avatar_url": "https://avatars3.githubusercontent.com/u/1105325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fdion", "html_url": "https://github.com/fdion", "followers_url": "https://api.github.com/users/fdion/followers", "following_url": "https://api.github.com/users/fdion/following{/other_user}", "gists_url": "https://api.github.com/users/fdion/gists{/gist_id}", "starred_url": "https://api.github.com/users/fdion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fdion/subscriptions", "organizations_url": "https://api.github.com/users/fdion/orgs", "repos_url": "https://api.github.com/users/fdion/repos", "events_url": "https://api.github.com/users/fdion/events{/privacy}", "received_events_url": "https://api.github.com/users/fdion/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-30T21:11:42Z", "updated_at": "2019-10-31T02:36:56Z", "closed_at": "2019-10-31T02:35:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "There is an issue with the wheel archive of dask_ml version 1.1.0, found on pypi:\r\n\r\n[dask_ml-1.1.0-py3-none-any.whl](https://files.pythonhosted.org/packages/52/c7/c69664dd30c8da1275e23bda3e00d9d1b3244ac9cc6527d0e804a8ea5758/dask_ml-1.1.0-py3-none-any.whl)\r\n\r\nGithub and the tar.gz archive of v.1.1.0 are ok. ColumnTransformer inherits from a class that exists:\r\n\r\n[_column_transformer.py#L12](https://github.com/dask/dask-ml/blob/master/dask_ml/compose/_column_transformer.py#L12)\r\n\r\nBut the wheel file has this on line 12 of the _column_transformer.py file:\r\n\r\n`class ColumnTransformer(sklearn.compose.ColumnTrasformer):`\r\n\r\nIt should say `sklearn.compose.ColumnTransformer`. It is missing the n.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/574", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/574/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/574/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/574/events", "html_url": "https://github.com/dask/dask-ml/issues/574", "id": 514909462, "node_id": "MDU6SXNzdWU1MTQ5MDk0NjI=", "number": 574, "title": "HashingVectorizer has the wrong meta", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-10-30T18:58:57Z", "updated_at": "2019-11-02T19:05:52Z", "closed_at": "2019-11-02T19:05:52Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```python\r\nIn [2]: import dask_ml.feature_extraction\r\n\r\nn [3]: vect = dask_ml.feature_extraction.text.HashingVectorizer()\r\n   ...:\r\n\r\nIn [4]: import dask.bag as db\r\n\r\nIn [5]: out = vect.fit_transform(db.from_sequence(['a list', 'of documents']))\r\n\r\nIn [6]: out\r\nOut[6]: dask.array<concatenate, shape=(nan, 1048576), dtype=float64, chunksize=(nan, 1048576), chunktype=numpy.ndarray>\r\n\r\nIn [8]: out._meta\r\nOut[8]: array([], shape=(0, 0), dtype=float64)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/564", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/564/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/564/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/564/events", "html_url": "https://github.com/dask/dask-ml/issues/564", "id": 514044670, "node_id": "MDU6SXNzdWU1MTQwNDQ2NzA=", "number": 564, "title": "Contributing docs doesn't include method to build docs", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-29T16:14:33Z", "updated_at": "2019-12-02T21:51:48Z", "closed_at": "2019-12-02T21:51:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I followed the guidelines at https://ml.dask.org/contributing.html:\r\n\r\n```\r\n$ conda env create -f ci/environment-3.7.yaml --name=dask-ml-dev\r\n$ python -m pip install -e \".[dev]\"\r\n```\r\n\r\nThis worked. I made some documentation changes, so I had to build the docs. Typing `make html` in the `docs/` directory yielded some errors, and I had to install extra packages:\r\n\r\n```\r\n$ cd docs\r\n$ make html\r\n$  pip install IPython\r\n$ make html\r\n$ pip install jupyter_client\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/562", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/562/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/562/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/562/events", "html_url": "https://github.com/dask/dask-ml/issues/562", "id": 512199003, "node_id": "MDU6SXNzdWU1MTIxOTkwMDM=", "number": 562, "title": "PolynomialFeatures does not preserve index", "user": {"login": "jtilly", "id": 6807275, "node_id": "MDQ6VXNlcjY4MDcyNzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/6807275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jtilly", "html_url": "https://github.com/jtilly", "followers_url": "https://api.github.com/users/jtilly/followers", "following_url": "https://api.github.com/users/jtilly/following{/other_user}", "gists_url": "https://api.github.com/users/jtilly/gists{/gist_id}", "starred_url": "https://api.github.com/users/jtilly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jtilly/subscriptions", "organizations_url": "https://api.github.com/users/jtilly/orgs", "repos_url": "https://api.github.com/users/jtilly/repos", "events_url": "https://api.github.com/users/jtilly/events{/privacy}", "received_events_url": "https://api.github.com/users/jtilly/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-24T21:50:40Z", "updated_at": "2019-10-25T20:33:51Z", "closed_at": "2019-10-25T20:33:51Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When using the `PolynomialFeatures` transformer with `preserve_dataframe=True`, we lose the index of the data frame. \r\n\r\n```python\r\nimport pandas as pd\r\nfrom dask_ml.preprocessing import PolynomialFeatures\r\n\r\ndf = pd.DataFrame({\"x\": [1, 2]}, index=[2, 3])\r\nPolynomialFeatures(degree=1, preserve_dataframe=True).fit_transform(df)\r\n#>     1    x\r\n#>0  1.0  1.0\r\n#>1  1.0  2.0\r\n```\r\n\r\nThe correct output should be\r\n```python\r\n#>     1    x\r\n#>2  1.0  1.0\r\n#>3  1.0  2.0\r\n```\r\n\r\nSame problem occurs with dask data frames.\r\n\r\nTo fix this, I would like to add `index=X.index` to\r\nhttps://github.com/dask/dask-ml/blob/17568750c85c2cbc3c41b22a4b3498006cd0ed67/dask_ml/preprocessing/data.py#L993\r\nand \r\nhttps://github.com/dask/dask-ml/blob/17568750c85c2cbc3c41b22a4b3498006cd0ed67/dask_ml/preprocessing/data.py#L998\r\n\r\nHappy to send the PR. Just want to make sure I'm not missing anything or that there's a reason for the current behavior.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/560", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/560/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/560/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/560/events", "html_url": "https://github.com/dask/dask-ml/issues/560", "id": 511041670, "node_id": "MDU6SXNzdWU1MTEwNDE2NzA=", "number": 560, "title": "sklearnDev CI tests failing on sklearn.preprocessing.label module", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-10-23T03:04:15Z", "updated_at": "2019-10-25T16:07:50Z", "closed_at": "2019-10-25T16:07:50Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Here's a traceback from #528 \r\n\r\n``` python\r\n______________ ERROR collecting tests/preprocessing/test_label.py ______________\r\ntests/preprocessing/test_label.py:10: in <module>\r\n    import dask_ml.preprocessing as dpp\r\ndask_ml/preprocessing/__init__.py:3: in <module>\r\n    from ._encoders import OneHotEncoder\r\ndask_ml/preprocessing/_encoders.py:10: in <module>\r\n    from .label import _encode, _encode_dask_array\r\ndask_ml/preprocessing/label.py:10: in <module>\r\n    from sklearn.preprocessing import label as sklabel\r\n/usr/share/miniconda/envs/dask-ml-t\u2026\r\n/usr/share/miniconda/envs/dask-ml-test/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: in _raise_dep_warning_if_not_pytest\r\n    warnings.warn(message, DeprecationWarning)\r\nE   DeprecationWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22\r\n and will be removed in version 0.24. The corresponding classes / functions should instead be\r\n imported from sklearn.preprocessing. Anything that cannot be imported from\r\n sklearn.preprocessing is now part of the private API.\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/556", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/556/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/556/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/556/events", "html_url": "https://github.com/dask/dask-ml/issues/556", "id": 504687530, "node_id": "MDU6SXNzdWU1MDQ2ODc1MzA=", "number": 556, "title": "Numpy random() augmentation error in Dask-ML K-means", "user": {"login": "cjnolet", "id": 1242464, "node_id": "MDQ6VXNlcjEyNDI0NjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1242464?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjnolet", "html_url": "https://github.com/cjnolet", "followers_url": "https://api.github.com/users/cjnolet/followers", "following_url": "https://api.github.com/users/cjnolet/following{/other_user}", "gists_url": "https://api.github.com/users/cjnolet/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjnolet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjnolet/subscriptions", "organizations_url": "https://api.github.com/users/cjnolet/orgs", "repos_url": "https://api.github.com/users/cjnolet/repos", "events_url": "https://api.github.com/users/cjnolet/events{/privacy}", "received_events_url": "https://api.github.com/users/cjnolet/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-10-09T14:25:06Z", "updated_at": "2019-10-20T01:08:02Z", "closed_at": "2019-10-20T01:08:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm getting a strange error in cuML's kmeans MNMG notebook when I run the following code (with 0.10):\r\n\r\n```\r\nimport numpy as np\r\n\r\nimport pandas as pd\r\nimport cudf as gd\r\n\r\nfrom dask.distributed import Client, wait\r\nfrom dask_cuda import LocalCUDACluster\r\n\r\ncluster = LocalCUDACluster(threads_per_worker=1)\r\nclient = Client(cluster)\r\n\r\nfrom dask_ml.cluster import KMeans as skKMeans\r\n\r\nfrom cuml.dask.datasets import make_blobs\r\nfrom cuml.dask.common import to_dask_df\r\n\r\nfrom sklearn.metrics import adjusted_rand_score\r\n\r\n%matplotlib inline\r\nimport matplotlib.pyplot as plt\r\n\r\nfrom cuml.dask.cluster.kmeans import KMeans as cumlKMeans\r\n\r\nn_samples = 10000\r\nn_features = 2\r\n\r\nn_total_partitions = len(list(client.has_what().keys()))\r\n\r\nX_cudf, Y_cudf = make_blobs(n_samples, \r\n                            n_features,\r\n                            centers = 5, \r\n                            n_parts = n_total_partitions,\r\n                            cluster_std=1.0,\r\n                            random_state=10,\r\n                            verbose=True)\r\n\r\nwait(X_cudf)\r\n\r\nX_df = to_dask_df(X_cudf)\r\n\r\nwait(X_df)\r\n\r\n%%time\r\nkmeans_sk = skKMeans(init=\"k-means||\",\r\n                     n_clusters=5,\r\n                     n_jobs=-1)\r\nkmeans_sk.fit(X_df)\r\n```\r\n\r\nThe stack trace I'm getting seems to indicate that the error might be related to a class being registered by Dask to optimize random sampling:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<timed exec> in <module>\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/dask_ml/cluster/k_means.py in fit(self, X, y)\r\n    197             max_iter=self.max_iter,\r\n    198             init_max_iter=self.init_max_iter,\r\n--> 199             tol=self.tol,\r\n    200         )\r\n    201         self.cluster_centers_ = centroids\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/dask_ml/cluster/k_means.py in k_means(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter, oversampling_factor, init_max_iter)\r\n    268         random_state=random_state,\r\n    269         oversampling_factor=oversampling_factor,\r\n--> 270         init_max_iter=init_max_iter,\r\n    271     )\r\n    272     if return_n_iter:\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/dask_ml/cluster/k_means.py in _kmeans_single_lloyd(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances, oversampling_factor, init_max_iter)\r\n    554             counts = da.maximum(counts, 1)\r\n    555             new_centers = new_centers / counts[:, None]\r\n--> 556             new_centers, = compute(new_centers)\r\n    557 \r\n    558             # Convergence check\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/dask/base.py in compute(*args, **kwargs)\r\n    434     keys = [x.__dask_keys__() for x in collections]\r\n    435     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 436     results = schedule(dsk, keys, **kwargs)\r\n    437     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    438 \r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/distributed/client.py in get(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\r\n   2537                     should_rejoin = False\r\n   2538             try:\r\n-> 2539                 results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n   2540             finally:\r\n   2541                 for f in futures.values():\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/distributed/client.py in gather(self, futures, errors, direct, asynchronous)\r\n   1837                 direct=direct,\r\n   1838                 local_worker=local_worker,\r\n-> 1839                 asynchronous=asynchronous,\r\n   1840             )\r\n   1841 \r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/distributed/client.py in sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\r\n    754         else:\r\n    755             return sync(\r\n--> 756                 self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\r\n    757             )\r\n    758 \r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/distributed/utils.py in sync(loop, func, callback_timeout, *args, **kwargs)\r\n    331     if error[0]:\r\n    332         typ, exc, tb = error[0]\r\n--> 333         raise exc.with_traceback(tb)\r\n    334     else:\r\n    335         return result[0]\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/distributed/utils.py in f()\r\n    315             if callback_timeout is not None:\r\n    316                 future = gen.with_timeout(timedelta(seconds=callback_timeout), future)\r\n--> 317             result[0] = yield future\r\n    318         except Exception as exc:\r\n    319             error[0] = sys.exc_info()\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/tornado/gen.py in run(self)\r\n    733 \r\n    734                     try:\r\n--> 735                         value = future.result()\r\n    736                     except Exception:\r\n    737                         exc_info = sys.exc_info()\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/distributed/client.py in _gather(self, futures, errors, direct, local_worker)\r\n   1693                             exc = CancelledError(key)\r\n   1694                         else:\r\n-> 1695                             raise exception.with_traceback(traceback)\r\n   1696                         raise exc\r\n   1697                     if errors == \"skip\":\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/dask/optimization.py in __call__()\r\n   1052         if not len(args) == len(self.inkeys):\r\n   1053             raise ValueError(\"Expected %d args, got %d\" % (len(self.inkeys), len(args)))\r\n-> 1054         return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n   1055 \r\n   1056     def __reduce__(self):\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/dask/core.py in get()\r\n    147     for key in toposort(dsk):\r\n    148         task = dsk[key]\r\n--> 149         result = _execute_task(task, cache)\r\n    150         cache[key] = result\r\n    151     result = _execute_task(out, cache)\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/dask/core.py in _execute_task()\r\n    117         func, args = arg[0], arg[1:]\r\n    118         args2 = [_execute_task(a, cache) for a in args]\r\n--> 119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n    121         return arg\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/dispatcher.py in _compile_for_args()\r\n    393                     e.patch_message(''.join(e.args) + help_msg)\r\n    394             # ignore the FULL_TRACEBACKS config, this needs reporting!\r\n--> 395             raise e\r\n    396 \r\n    397     def inspect_llvm(self, signature=None):\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/dispatcher.py in _compile_for_args()\r\n    350                 argtypes.append(self.typeof_pyval(a))\r\n    351         try:\r\n--> 352             return self.compile(tuple(argtypes))\r\n    353         except errors.TypingError as e:\r\n    354             # Intercept typing error that may be due to an argument\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/compiler_lock.py in _acquire_compile_lock()\r\n     30         def _acquire_compile_lock(*args, **kwargs):\r\n     31             with self:\r\n---> 32                 return func(*args, **kwargs)\r\n     33         return _acquire_compile_lock\r\n     34 \r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/dispatcher.py in compile()\r\n    691 \r\n    692             self._cache_misses[sig] += 1\r\n--> 693             cres = self._compiler.compile(args, return_type)\r\n    694             self.add_overload(cres)\r\n    695             self._cache.save_overload(sig, cres)\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/dispatcher.py in compile()\r\n     74 \r\n     75     def compile(self, args, return_type):\r\n---> 76         status, retval = self._compile_cached(args, return_type)\r\n     77         if status:\r\n     78             return retval\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/dispatcher.py in _compile_cached()\r\n     88 \r\n     89         try:\r\n---> 90             retval = self._compile_core(args, return_type)\r\n     91         except errors.TypingError as e:\r\n     92             self._failed_cache[key] = e\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/dispatcher.py in _compile_core()\r\n    106                                       args=args, return_type=return_type,\r\n    107                                       flags=flags, locals=self.locals,\r\n--> 108                                       pipeline_class=self.pipeline_class)\r\n    109         # Check typing error if object mode is used\r\n    110         if cres.typing_error is not None and not flags.enable_pyobject:\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/compiler.py in compile_extra()\r\n    969     \"\"\"\r\n    970     pipeline = pipeline_class(typingctx, targetctx, library,\r\n--> 971                               args, return_type, flags, locals)\r\n    972     return pipeline.compile_extra(func)\r\n    973 \r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/compiler.py in __init__()\r\n    284         # Make sure the environment is reloaded\r\n    285         config.reload_config()\r\n--> 286         typingctx.refresh()\r\n    287         targetctx.refresh()\r\n    288 \r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/typing/context.py in refresh()\r\n    143         Useful for third-party extensions.\r\n    144         \"\"\"\r\n--> 145         self.load_additional_registries()\r\n    146         # Some extensions may have augmented the builtin registry\r\n    147         self._load_builtins()\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/typing/context.py in load_additional_registries()\r\n    675         self.install_registry(mathdecl.registry)\r\n    676         self.install_registry(npydecl.registry)\r\n--> 677         self.install_registry(randomdecl.registry)\r\n    678         self.install_registry(setdecl.registry)\r\n    679         self.install_registry(dictdecl.registry)\r\n\r\n/share/conda/cuml2/lib/python3.7/site-packages/numba/typing/context.py in install_registry()\r\n    409                 if newty is None:\r\n    410                     raise TypeError(\"cannot augment %s with %s\"\r\n--> 411                                     % (existing, gty))\r\n    412                 self._remove_global(gv)\r\n    413                 self._insert_global(gv, newty)\r\n\r\nTypeError: cannot augment Function(np.random.random) with Function(np.random.random_sample)\r\n```\r\n\r\nThe code that I'm running is creating a `dask_cudf` by creating partitions across the workers that call `sklearn.datasets.make_blobs`. The `dask_cudf` is then converted to a `dask.Dataframe` with `Pandas` by converting all the underlying partitions from `cudf` to `pandas`. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/554", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/554/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/554/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/554/events", "html_url": "https://github.com/dask/dask-ml/issues/554", "id": 504191946, "node_id": "MDU6SXNzdWU1MDQxOTE5NDY=", "number": 554, "title": "cannot import name 'set_options' from 'dask'  (dask v2.5.2, dask_ml v1.0.0)", "user": {"login": "hoangthienan95", "id": 25307953, "node_id": "MDQ6VXNlcjI1MzA3OTUz", "avatar_url": "https://avatars3.githubusercontent.com/u/25307953?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hoangthienan95", "html_url": "https://github.com/hoangthienan95", "followers_url": "https://api.github.com/users/hoangthienan95/followers", "following_url": "https://api.github.com/users/hoangthienan95/following{/other_user}", "gists_url": "https://api.github.com/users/hoangthienan95/gists{/gist_id}", "starred_url": "https://api.github.com/users/hoangthienan95/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hoangthienan95/subscriptions", "organizations_url": "https://api.github.com/users/hoangthienan95/orgs", "repos_url": "https://api.github.com/users/hoangthienan95/repos", "events_url": "https://api.github.com/users/hoangthienan95/events{/privacy}", "received_events_url": "https://api.github.com/users/hoangthienan95/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-10-08T18:00:30Z", "updated_at": "2019-10-08T18:05:01Z", "closed_at": "2019-10-08T18:05:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "I came back to an old script and what worked before no longer worked?\r\n\r\n![image](https://user-images.githubusercontent.com/25307953/66420342-b117a980-e9d3-11e9-9ff7-661f521cbee1.png)\r\n\r\n\r\nConda list:\r\n```\r\n(learn-new-pkgs) anhoang@c4b13 /lab/corradin_cache$ conda list dask\r\n# packages in environment at /lab/corradin_data/FOR_AN/anaconda3/envs/learn-new-pkgs:\r\n#\r\n# Name                    Version                   Build  Channel\r\ndask                      2.5.2                      py_0    conda-forge\r\ndask-core                 2.5.2                      py_0    conda-forge\r\ndask-glm                  0.1.0                         0    conda-forge\r\ndask-jobqueue             0.6.3                      py_0    conda-forge\r\ndask-ml                   1.0.0                      py_1    conda-forge\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/551", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/551/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/551/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/551/events", "html_url": "https://github.com/dask/dask-ml/issues/551", "id": 502313211, "node_id": "MDU6SXNzdWU1MDIzMTMyMTE=", "number": 551, "title": "KMeans fails on blocks with no rows", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-10-03T21:41:01Z", "updated_at": "2019-10-22T15:17:03Z", "closed_at": "2019-10-22T15:17:03Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```python\r\n>>> import dask.array as da\r\n>>> import dask_ml.cluster\r\n>>> X = da.random.random((10, 4), chunks=((0, 5, 5), (4,)))\r\n>>> dask_ml.cluster.KMeans(n_clusters=2).fit(X)\r\n\r\n```\r\n\r\nraises with\r\n\r\n```pytb\r\nIn [10]: dask_ml.cluster.KMeans(n_clusters=2).fit(X)\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-10-2a2a0c1a5613> in <module>\r\n----> 1 dask_ml.cluster.KMeans(n_clusters=2).fit(X)\r\n\r\n~/sandbox/dask-ml/dask_ml/cluster/k_means.py in fit(self, X, y)\r\n    197             max_iter=self.max_iter,\r\n    198             init_max_iter=self.init_max_iter,\r\n--> 199             tol=self.tol,\r\n    200         )\r\n    201         self.cluster_centers_ = centroids\r\n\r\n~/sandbox/dask-ml/dask_ml/cluster/k_means.py in k_means(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter, oversampling_factor, init_max_iter)\r\n    268         random_state=random_state,\r\n    269         oversampling_factor=oversampling_factor,\r\n--> 270         init_max_iter=init_max_iter,\r\n    271     )\r\n    272     if return_n_iter:\r\n\r\n~/sandbox/dask-ml/dask_ml/cluster/k_means.py in _kmeans_single_lloyd(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances, oversampling_factor, init_max_iter)\r\n    521         oversampling_factor=oversampling_factor,\r\n    522         random_state=random_state,\r\n--> 523         max_iter=init_max_iter,\r\n    524     )\r\n    525     dt = X.dtype\r\n\r\n~/sandbox/dask-ml/dask_ml/cluster/k_means.py in k_init(X, n_clusters, init, random_state, max_iter, oversampling_factor)\r\n    359\r\n    360     if init == \"k-means||\":\r\n--> 361         return init_scalable(X, n_clusters, random_state, max_iter, oversampling_factor)\r\n    362     elif init == \"k-means++\":\r\n    363         return init_pp(X, n_clusters, random_state)\r\n\r\n~/sandbox/dask-ml/dask_ml/utils.py in wraps(*args, **kwargs)\r\n    334         def wraps(*args, **kwargs):\r\n    335             with _timer(f.__name__, _logger=logger, level=level):\r\n--> 336                 results = f(*args, **kwargs)\r\n    337             return results\r\n    338\r\n\r\n~/sandbox/dask-ml/dask_ml/cluster/k_means.py in init_scalable(X, n_clusters, random_state, max_iter, oversampling_factor)\r\n    411\r\n    412     # Step 2: Initialize cost\r\n--> 413     cost, = compute(evaluate_cost(X, centers))\r\n    414\r\n    415     if cost == 0:\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/base.py in compute(*args, **kwargs)\r\n    444     keys = [x.__dask_keys__() for x in collections]\r\n    445     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 446     results = schedule(dsk, keys, **kwargs)\r\n    447     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    448\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/threaded.py in get(dsk, result, cache, num_workers, pool, **kwargs)\r\n     80         get_id=_thread_get_id,\r\n     81         pack_exception=pack_exception,\r\n---> 82         **kwargs\r\n     83     )\r\n     84\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/local.py in get_async(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\r\n    489                         _execute_task(task, data)  # Re-execute locally\r\n    490                     else:\r\n--> 491                         raise_exception(exc, tb)\r\n    492                 res, worker_id = loads(res_info)\r\n    493                 state[\"cache\"][key] = res\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/compatibility.py in reraise(exc, tb)\r\n    128         if exc.__traceback__ is not tb:\r\n    129             raise exc.with_traceback(tb)\r\n--> 130         raise exc\r\n    131\r\n    132     import pickle as cPickle\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/local.py in execute_task(key, task_info, dumps, loads, get_id, pack_exception)\r\n    231     try:\r\n    232         task, data = loads(task_info)\r\n--> 233         result = _execute_task(task, data)\r\n    234         id = get_id()\r\n    235         result = dumps((result, id))\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in <listcomp>(.0)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in <listcomp>(.0)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in <listcomp>(.0)\r\n    116     elif istask(arg):\r\n    117         func, args = arg[0], arg[1:]\r\n--> 118         args2 = [_execute_task(a, cache) for a in args]\r\n    119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    117         func, args = arg[0], arg[1:]\r\n    118         args2 = [_execute_task(a, cache) for a in args]\r\n--> 119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n    121         return arg\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/optimization.py in __call__(self, *args)\r\n   1057         if not len(args) == len(self.inkeys):\r\n   1058             raise ValueError(\"Expected %d args, got %d\" % (len(self.inkeys), len(args)))\r\n-> 1059         return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\r\n   1060\r\n   1061     def __reduce__(self):\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in get(dsk, out, cache)\r\n    147     for key in toposort(dsk):\r\n    148         task = dsk[key]\r\n--> 149         result = _execute_task(task, cache)\r\n    150         cache[key] = result\r\n    151     result = _execute_task(out, cache)\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/core.py in _execute_task(arg, cache, dsk)\r\n    117         func, args = arg[0], arg[1:]\r\n    118         args2 = [_execute_task(a, cache) for a in args]\r\n--> 119         return func(*args2)\r\n    120     elif not ishashable(arg):\r\n    121         return arg\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/dask/compatibility.py in apply(func, args, kwargs)\r\n    105     def apply(func, args, kwargs=None):\r\n    106         if kwargs:\r\n--> 107             return func(*args, **kwargs)\r\n    108         else:\r\n    109             return func(*args)\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds)\r\n   1586         func = partial(distance.cdist, metric=metric, **kwds)\r\n   1587\r\n-> 1588     return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\r\n   1589\r\n   1590\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in _parallel_pairwise(X, Y, func, n_jobs, **kwds)\r\n   1204\r\n   1205     if effective_n_jobs(n_jobs) == 1:\r\n-> 1206         return func(X, Y, **kwds)\r\n   1207\r\n   1208     # enforce a threading backend to prevent data communication overhead\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in euclidean_distances(X, Y, Y_norm_squared, squared, X_norm_squared)\r\n    230     paired_distances : distances betweens pairs of elements of X and Y.\r\n    231     \"\"\"\r\n--> 232     X, Y = check_pairwise_arrays(X, Y)\r\n    233\r\n    234     # If norms are passed as float32, they are unused. If arrays are passed as\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in check_pairwise_arrays(X, Y, precomputed, dtype)\r\n    110     else:\r\n    111         X = check_array(X, accept_sparse='csr', dtype=dtype,\r\n--> 112                         estimator=estimator)\r\n    113         Y = check_array(Y, accept_sparse='csr', dtype=dtype,\r\n    114                         estimator=estimator)\r\n\r\n~/miniconda3/envs/dask-dev/lib/python3.7/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\r\n    548                              \" minimum of %d is required%s.\"\r\n    549                              % (n_samples, array.shape, ensure_min_samples,\r\n--> 550                                 context))\r\n    551\r\n    552     if ensure_min_features > 0 and array.ndim == 2:\r\n\r\nValueError: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by check_pairwise_arrays.\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/550", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/550/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/550/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/550/events", "html_url": "https://github.com/dask/dask-ml/issues/550", "id": 501577363, "node_id": "MDU6SXNzdWU1MDE1NzczNjM=", "number": 550, "title": "Incorrect warning in train_test_split", "user": {"login": "fonnesbeck", "id": 81476, "node_id": "MDQ6VXNlcjgxNDc2", "avatar_url": "https://avatars3.githubusercontent.com/u/81476?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fonnesbeck", "html_url": "https://github.com/fonnesbeck", "followers_url": "https://api.github.com/users/fonnesbeck/followers", "following_url": "https://api.github.com/users/fonnesbeck/following{/other_user}", "gists_url": "https://api.github.com/users/fonnesbeck/gists{/gist_id}", "starred_url": "https://api.github.com/users/fonnesbeck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fonnesbeck/subscriptions", "organizations_url": "https://api.github.com/users/fonnesbeck/orgs", "repos_url": "https://api.github.com/users/fonnesbeck/repos", "events_url": "https://api.github.com/users/fonnesbeck/events{/privacy}", "received_events_url": "https://api.github.com/users/fonnesbeck/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-10-02T15:52:53Z", "updated_at": "2019-10-11T18:12:31Z", "closed_at": "2019-10-11T18:12:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "When applying `train_test_split` to a `float64`-typed dataset, I get an erroneous warning that says there are mixed types:\r\n\r\n![image](https://user-images.githubusercontent.com/81476/66060002-8ffe1700-e502-11e9-9642-1316ce7485b7.png)\r\n\r\nUsing dask_ml version 1.0.0 on a GCS instance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/542", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/542/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/542/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/542/events", "html_url": "https://github.com/dask/dask-ml/issues/542", "id": 483162531, "node_id": "MDU6SXNzdWU0ODMxNjI1MzE=", "number": 542, "title": "Dask ML PCA - DataFrame error", "user": {"login": "j-grover", "id": 20989850, "node_id": "MDQ6VXNlcjIwOTg5ODUw", "avatar_url": "https://avatars2.githubusercontent.com/u/20989850?v=4", "gravatar_id": "", "url": "https://api.github.com/users/j-grover", "html_url": "https://github.com/j-grover", "followers_url": "https://api.github.com/users/j-grover/followers", "following_url": "https://api.github.com/users/j-grover/following{/other_user}", "gists_url": "https://api.github.com/users/j-grover/gists{/gist_id}", "starred_url": "https://api.github.com/users/j-grover/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/j-grover/subscriptions", "organizations_url": "https://api.github.com/users/j-grover/orgs", "repos_url": "https://api.github.com/users/j-grover/repos", "events_url": "https://api.github.com/users/j-grover/events{/privacy}", "received_events_url": "https://api.github.com/users/j-grover/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-08-21T02:09:28Z", "updated_at": "2019-10-30T15:27:18Z", "closed_at": "2019-10-30T15:27:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to run Dask ML PCA with a Dask DataFrame as an input and getting the following error:\r\n```\r\nX_reduced = pca.fit_transform(X)\r\n  File \"/anaconda3/envs/package-test/lib/python3.6/site-packages/dask_ml/decomposition/pca.py\", line 363, in fit_transform\r\n    U, S, V = self._fit(X)\r\n  File \"/anaconda3/envs/package-test/lib/python3.6/site-packages/dask_ml/decomposition/pca.py\", line 213, in _fit\r\n    if max(X.shape) <= 500:\r\n  File \"/anaconda3/envs/package-test/lib/python3.6/site-packages/dask/delayed.py\", line 546, in __bool__\r\n    raise TypeError(\"Truth of Delayed objects is not supported\")\r\nTypeError: Truth of Delayed objects is not supported\r\n```\r\n\r\nI realise the workaround is that the dataframe first be converted to a Dask Array but I would have expected a dataframe to work given that is the case for other Dask ML implementations such as StandardScaler, RobustScaler, etc.\r\n\r\nReproducible example:\r\n```\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom dask_ml.decomposition import PCA\r\n\r\n\r\nX = pd.DataFrame(\r\n    {\r\n        '0': [0, 0, 1, 1],\r\n        '1': [0, 0, 1, 1],\r\n        '2': [2, 4, 5, 2]\r\n    }\r\n)\r\nX = dd.from_pandas(X, npartitions=1)\r\n\r\npca = PCA(n_components=2)\r\nX_reduced = pca.fit_transform(X)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/539", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/539/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/539/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/539/events", "html_url": "https://github.com/dask/dask-ml/issues/539", "id": 482148954, "node_id": "MDU6SXNzdWU0ODIxNDg5NTQ=", "number": 539, "title": "Error with dask-seachcv.GridsearchCV", "user": {"login": "FritzPeleke", "id": 53652693, "node_id": "MDQ6VXNlcjUzNjUyNjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/53652693?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FritzPeleke", "html_url": "https://github.com/FritzPeleke", "followers_url": "https://api.github.com/users/FritzPeleke/followers", "following_url": "https://api.github.com/users/FritzPeleke/following{/other_user}", "gists_url": "https://api.github.com/users/FritzPeleke/gists{/gist_id}", "starred_url": "https://api.github.com/users/FritzPeleke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FritzPeleke/subscriptions", "organizations_url": "https://api.github.com/users/FritzPeleke/orgs", "repos_url": "https://api.github.com/users/FritzPeleke/repos", "events_url": "https://api.github.com/users/FritzPeleke/events{/privacy}", "received_events_url": "https://api.github.com/users/FritzPeleke/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-08-19T07:26:21Z", "updated_at": "2019-08-19T14:47:19Z", "closed_at": "2019-08-19T14:47:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "hello, when i try to run Gridsearch with sklearn on my laptop I get the parallelism error for n_jobs greater as 1. So I decided to turn to dask-searchcv and I can't get the best_params. I get a new error instead. Below are my error and the code\r\n\r\nError: \r\nImportError: cannot import name 'DeprecationDict' from 'sklearn.utils.deprecation' \r\n\r\ncode:\r\nimport numpy as np\r\nimport  pandas as pd\r\nimport matplotlib\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.datasets import fetch_openml\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\nfrom sklearn.metrics import confusion_matrix\r\nfrom  sklearn.model_selection import cross_val_predict,cross_val_score\r\n#from sklearn.model_selection import GridSearchCV\r\nfrom dask_searchcv import GridSearchCV\r\n\r\n\r\nnp.random.seed(42)\r\nmnist_data = fetch_openml('mnist_784')\r\ndata = mnist_data['data'].astype(np.int64)\r\nlabel = mnist_data['target'].astype(np.int64)\r\n#creating test data and shuffle data\r\nx_train = data[:60000]\r\nx_test = data[60000:]\r\ny_train = label[:60000]\r\ny_test = data[60000:]\r\nschuffler = np.random.permutation(len(x_train))\r\nx_train,y_train = x_train[schuffler],y_train[schuffler]\r\nknn_clf = KNeighborsClassifier()\r\nclassifier = knn_clf.fit(x_train,y_train)\r\nparam = {'n_neighbors': [3,4,5],'weights':['uniform','distance']}\r\n\r\n\r\n#using dask-search cv\r\nsearch = GridSearchCV(knn_clf,param,cv=3,n_jobs=-1)\r\nsearch.fit(x_train,y_train)\r\nprint(search.best_params_)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/537", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/537/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/537/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/537/events", "html_url": "https://github.com/dask/dask-ml/issues/537", "id": 481998474, "node_id": "MDU6SXNzdWU0ODE5OTg0NzQ=", "number": 537, "title": "ImportError: fsspec is required to use any file-system functionality", "user": {"login": "AnesBenmerzoug", "id": 27914730, "node_id": "MDQ6VXNlcjI3OTE0NzMw", "avatar_url": "https://avatars3.githubusercontent.com/u/27914730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AnesBenmerzoug", "html_url": "https://github.com/AnesBenmerzoug", "followers_url": "https://api.github.com/users/AnesBenmerzoug/followers", "following_url": "https://api.github.com/users/AnesBenmerzoug/following{/other_user}", "gists_url": "https://api.github.com/users/AnesBenmerzoug/gists{/gist_id}", "starred_url": "https://api.github.com/users/AnesBenmerzoug/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AnesBenmerzoug/subscriptions", "organizations_url": "https://api.github.com/users/AnesBenmerzoug/orgs", "repos_url": "https://api.github.com/users/AnesBenmerzoug/repos", "events_url": "https://api.github.com/users/AnesBenmerzoug/events{/privacy}", "received_events_url": "https://api.github.com/users/AnesBenmerzoug/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-08-18T14:12:19Z", "updated_at": "2019-08-19T11:23:15Z", "closed_at": "2019-08-19T11:23:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "On a fresh install of dask-ml, the following snippet:\r\n\r\n```python\r\nimport dask.array as da\r\nfrom dask_ml.linear_model import LogisticRegression\r\nfrom dask_ml.model_selection import train_test_split\r\nfrom sklearn.datasets import load_iris\r\n\r\nif __name__ == \"__main__\":\r\n    iris = load_iris()\r\n    X, y = iris.data, iris.target\r\n    X, y = da.from_array(X, chunks=len(X) // 5), da.from_array(y, chunks=len(y) // 5)\r\n    classifier = LogisticRegression(max_iter=max_iter, solver=solver, C=C)\r\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\r\n    classifier.fit(X_train, y_train)\r\n    score = classifier.score(X_test, y_test)\r\n```\r\n\r\ngives the error:\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 2, in <module>\r\n    from dask_ml.linear_model import LogisticRegression\r\n  File \"/home/koutetsu/projects/dask-ml-fsspec-error/venv/lib/python3.6/site-packages/dask_ml/linear_model/__init__.py\", line 4, in <module>\r\n    from .glm import LinearRegression, LogisticRegression, PoissonRegression\r\n  File \"/home/koutetsu/projects/dask-ml-fsspec-error/venv/lib/python3.6/site-packages/dask_ml/linear_model/glm.py\", line 17, in <module>\r\n    from ..utils import check_array\r\n  File \"/home/koutetsu/projects/dask-ml-fsspec-error/venv/lib/python3.6/site-packages/dask_ml/utils.py\", line 12, in <module>\r\n    import dask.dataframe as dd\r\n  File \"/home/koutetsu/projects/dask-ml-fsspec-error/venv/lib/python3.6/site-packages/dask/dataframe/__init__.py\", line 57, in <module>\r\n    raise ImportError(str(e) + \"\\n\\n\" + msg)\r\nImportError: fsspec is required to use any file-system functionality. Please install using\r\nconda install -c conda-forge 'fsspec>=0.3.3'\r\nor\r\npip install 'fsspec>=0.3.3'\r\n```\r\n\r\nChecking the [requirements](https://github.com/dask/dask-ml/blob/master/setup.py#L13-L24) of dask-ml shows that only array extras are install and that installing the dataframe extras in addition to that would solve this error\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/523", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/523/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/523/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/523/events", "html_url": "https://github.com/dask/dask-ml/issues/523", "id": 458674692, "node_id": "MDU6SXNzdWU0NTg2NzQ2OTI=", "number": 523, "title": "Model selection search stops with patience even if tol is invalid or too small", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-20T13:57:12Z", "updated_at": "2019-06-26T19:52:45Z", "closed_at": "2019-06-26T19:52:45Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When I create a `SuccessiveHalvingSearchCV` with a `tol` that is infeasible (e.g., `np.nan`), the search that *would* be performed is effected even though it shouldn't be.\r\n\r\nThis is best characterized by `SuccessiveHalvingSearchCV`, which has `metadata` and `metadata_` attributes to characterize the search that would be performed.\r\n\r\n``` python\r\nfrom sklearn.datasets import make_classification\r\nfrom sklearn.linear_model import SGDClassifier\r\nfrom dask_ml.model_selection import SuccessiveHalvingSearchCV\r\nfrom dask_ml.utils import ConstantFunction\r\n\r\nX, y = make_classification(n_samples=100, n_features=5)\r\n\r\nparams = {\"value\": np.random.RandomState(42).rand(1000)}\r\nmodel = ConstantFunction()\r\n\r\nsearch = SuccessiveHalvingSearchCV(\r\n    model, params, patience=2, tol=np.nan,\r\n    n_initial_parameters=20, n_initial_iter=2,\r\n)\r\nsearch.fit(X, y, classes=[0, 1])\r\n\r\nprint(search.metadata)   # {'partial_fit_calls': 88, 'n_models': 20, 'max_iter': 18}\r\nprint(search.metadata_)  # {'partial_fit_calls': 56, 'n_models': 20, 'max_iter': 6}\r\n```\r\n\r\nThis shouldn't happen; specifying a value of `tol=np.nan` should mean that plateaus are never detected. This should only record the score more frequently (once every two calls).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/521", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/521/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/521/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/521/events", "html_url": "https://github.com/dask/dask-ml/issues/521", "id": 457464806, "node_id": "MDU6SXNzdWU0NTc0NjQ4MDY=", "number": 521, "title": "xgbclassifier gives error with gridsearchcv and dask dataframes", "user": {"login": "sandys", "id": 76883, "node_id": "MDQ6VXNlcjc2ODgz", "avatar_url": "https://avatars2.githubusercontent.com/u/76883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sandys", "html_url": "https://github.com/sandys", "followers_url": "https://api.github.com/users/sandys/followers", "following_url": "https://api.github.com/users/sandys/following{/other_user}", "gists_url": "https://api.github.com/users/sandys/gists{/gist_id}", "starred_url": "https://api.github.com/users/sandys/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sandys/subscriptions", "organizations_url": "https://api.github.com/users/sandys/orgs", "repos_url": "https://api.github.com/users/sandys/repos", "events_url": "https://api.github.com/users/sandys/events{/privacy}", "received_events_url": "https://api.github.com/users/sandys/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 28, "created_at": "2019-06-18T12:55:21Z", "updated_at": "2020-06-17T13:08:59Z", "closed_at": "2020-03-02T15:31:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nimport dask.dataframe as dd\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom dask_ml.model_selection import GridSearchCV\r\nfrom dask_ml.xgboost import XGBClassifier\r\nfrom distributed import Client\r\nfrom sklearn.datasets import load_iris\r\n\r\nif __name__ == '__main__':\r\n\r\n    client = Client()\r\n\r\n    data = load_iris()\r\n\r\n    x = pd.DataFrame(data=data['data'], columns=data['feature_names'])\r\n    x = dd.from_pandas(x, npartitions=2)\r\n\r\n    y = pd.Series(data['target'])\r\n    y = dd.from_pandas(y, npartitions=2)\r\n\r\n    estimator = XGBClassifier(objective='multi:softmax', num_class=4)\r\n    grid_search = GridSearchCV(\r\n        estimator,\r\n        param_grid={\r\n            'n_estimators': np.arange(15, 105, 15)\r\n        },\r\n        scheduler='threads'\r\n    )\r\n\r\n    grid_search.fit(x, y)\r\n    results = pd.DataFrame(grid_search.cv_results_)\r\n    print(results.to_string())\r\n```\r\n\r\ngives this\r\n\r\n> Traceback (most recent call last):\r\n>   File \"d.py\", line 30, in <module>\r\n>     grid_search.fit(x, y)\r\n>   File \"/usr/local/lib/python3.7/site-packages/dask_ml/model_selection/_search.py\", line 1233, in fit\r\n>     cache_cv=self.cache_cv,\r\n>   File \"/usr/local/lib/python3.7/site-packages/dask_ml/model_selection/_search.py\", line 203, in build_cv_graph\r\n>     X_name, y_name, groups_name = to_keys(dsk, X, y, groups)\r\n>   File \"/usr/local/lib/python3.7/site-packages/dask_ml/model_selection/utils.py\", line 85, in to_keys\r\n>     assert not is_dask_collection(x)\r\n> AssertionError\r\n> ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/519", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/519/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/519/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/519/events", "html_url": "https://github.com/dask/dask-ml/issues/519", "id": 456211410, "node_id": "MDU6SXNzdWU0NTYyMTE0MTA=", "number": 519, "title": "Doc build failing", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-14T12:00:40Z", "updated_at": "2019-06-17T20:56:06Z", "closed_at": "2019-06-17T20:56:06Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://travis-ci.org/dask/dask-ml/jobs/545703082#L2613\r\n\r\nWould like to fix before the release (but I won't get to it today).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/517", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/517/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/517/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/517/events", "html_url": "https://github.com/dask/dask-ml/issues/517", "id": 453535016, "node_id": "MDU6SXNzdWU0NTM1MzUwMTY=", "number": 517, "title": "sklearn dev tests failing (deprecated argument to OneHotEncoder and QuantileTransformer)", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-07T14:12:04Z", "updated_at": "2019-06-10T23:12:26Z", "closed_at": "2019-06-10T23:12:25Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "`OneHotEncoder`'s `n_values` argument is deprecated pulled out in https://github.com/scikit-learn/scikit-learn/pull/13855 (and specifically [_encoders.py#L281][1]).\r\n\r\n\r\n\r\n[1]:https://github.com/scikit-learn/scikit-learn/pull/13855/files#diff-d12408664448c94dbd880579e1b2e4d9L218\r\n\r\nHere's some of the output from the Azure tests in #221:\r\n\r\ntests/compose/test_column_transformer.py:38: \r\n\r\n``` python-traceback\r\n>  #   def test_column_transformer():\r\n>               (dask_ml.preprocessing.OneHotEncoder(sparse=False), [\"A\"]),\r\n>         signature = {\r\n            \"n_values\": n_values,\r\n            \"categorical_features\": categorical_features,\r\n            \"categories\": categories,\r\n            \"drop\": drop,\r\n            \"sparse\": sparse,\r\n            \"dtype\": dtype,\r\n            \"handle_unknown\": handle_unknown,\r\n        }\r\n>       super(OneHotEncoder, self).__init__(**signature)\r\nE       TypeError: __init__() got an unexpected keyword argument 'n_values'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/516", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/516/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/516/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/516/events", "html_url": "https://github.com/dask/dask-ml/issues/516", "id": 450384986, "node_id": "MDU6SXNzdWU0NTAzODQ5ODY=", "number": 516, "title": "GridsearchCV with prescattered data", "user": {"login": "quasiben", "id": 1403768, "node_id": "MDQ6VXNlcjE0MDM3Njg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1403768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/quasiben", "html_url": "https://github.com/quasiben", "followers_url": "https://api.github.com/users/quasiben/followers", "following_url": "https://api.github.com/users/quasiben/following{/other_user}", "gists_url": "https://api.github.com/users/quasiben/gists{/gist_id}", "starred_url": "https://api.github.com/users/quasiben/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/quasiben/subscriptions", "organizations_url": "https://api.github.com/users/quasiben/orgs", "repos_url": "https://api.github.com/users/quasiben/repos", "events_url": "https://api.github.com/users/quasiben/events{/privacy}", "received_events_url": "https://api.github.com/users/quasiben/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-05-30T16:11:12Z", "updated_at": "2020-03-05T13:14:02Z", "closed_at": "2020-03-05T13:14:02Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "During a recent debug session with @TomAugspurger we thought that dask-ml could take advantage of data which was pre-scattered:\r\n\r\n> client.scatter(data, broadcast=True)\r\n\r\nCurrent understanding is that dask-ml will not take advantage of pre-scatter data as the call to `KFold` will chop up data and not see the cached data on the workers.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/512", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/512/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/512/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/512/events", "html_url": "https://github.com/dask/dask-ml/issues/512", "id": 448995712, "node_id": "MDU6SXNzdWU0NDg5OTU3MTI=", "number": 512, "title": "Types are appended to parameters in docstring", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-27T21:34:16Z", "updated_at": "2019-05-29T11:54:59Z", "closed_at": "2019-05-29T11:54:59Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "When I view the docs for `IncrementalSearchCV`, I see\r\n\r\n<img width=\"685\" alt=\"Screen Shot 2019-05-27 at 4 32 20 PM\" src=\"https://user-images.githubusercontent.com/1320475/58440031-f1caf200-80c6-11e9-88e8-30abf36087f3.png\">\r\n\r\nThis is especially confusing with attributes that end in `_`:\r\n\r\n<img width=\"653\" alt=\"Screen Shot 2019-05-27 at 4 31 31 PM\" src=\"https://user-images.githubusercontent.com/1320475/58440050-0ad3a300-80c7-11e9-9e49-e49dc095c6b5.png\">\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/509", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/509/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/509/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/509/events", "html_url": "https://github.com/dask/dask-ml/issues/509", "id": 445452854, "node_id": "MDU6SXNzdWU0NDU0NTI4NTQ=", "number": 509, "title": "sklearn-dev CI failing", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-17T13:51:00Z", "updated_at": "2019-05-20T17:08:43Z", "closed_at": "2019-05-20T17:08:43Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I've turned on nightly builds (https://dev.azure.com/dask-dev/dask/_build/results?buildId=70), this has been failing for a bit. I'm not sure how to send notifications / open a GH issue on failure.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/507", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/507/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/507/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/507/events", "html_url": "https://github.com/dask/dask-ml/issues/507", "id": 444922978, "node_id": "MDU6SXNzdWU0NDQ5MjI5Nzg=", "number": 507, "title": "model.score() returns MSE but the docstring states that it returns R2", "user": {"login": "daguito81", "id": 14969458, "node_id": "MDQ6VXNlcjE0OTY5NDU4", "avatar_url": "https://avatars3.githubusercontent.com/u/14969458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daguito81", "html_url": "https://github.com/daguito81", "followers_url": "https://api.github.com/users/daguito81/followers", "following_url": "https://api.github.com/users/daguito81/following{/other_user}", "gists_url": "https://api.github.com/users/daguito81/gists{/gist_id}", "starred_url": "https://api.github.com/users/daguito81/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daguito81/subscriptions", "organizations_url": "https://api.github.com/users/daguito81/orgs", "repos_url": "https://api.github.com/users/daguito81/repos", "events_url": "https://api.github.com/users/daguito81/events{/privacy}", "received_events_url": "https://api.github.com/users/daguito81/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-05-16T12:18:58Z", "updated_at": "2020-02-28T20:24:25Z", "closed_at": "2020-02-28T20:24:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "In dask_ml linear_models LinearRegression. If you use model.score(X_test, y_test) then you get back the Mean Squared Error instead of the R2 which is how sklearn's implementation does it. \r\nOn top of that the score method defined has a docstring that states that it returns the r2 score instead of the MSE. \r\n\r\nWe can see in the code here https://github.com/dask/dask-ml/blob/e1b21e6dbcfae8341d05d39544ab90dce21fdb2b/dask_ml/linear_model/glm.py#L304-L328\r\n\r\nThat the docstring says r2 score, but the method returns the mean_squared_error from dask_ml.utils.\r\n\r\nEither the docstring should be changed to reflect the real return value. Or the r2_score method should be defined and then use that on the rerturn statement of the score method", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/503", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/503/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/503/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/503/events", "html_url": "https://github.com/dask/dask-ml/issues/503", "id": 439050314, "node_id": "MDU6SXNzdWU0MzkwNTAzMTQ=", "number": 503, "title": "Fix sklearn dev on CI", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-05-01T02:37:40Z", "updated_at": "2019-05-01T03:09:18Z", "closed_at": "2019-05-01T03:09:18Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/499", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/499/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/499/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/499/events", "html_url": "https://github.com/dask/dask-ml/issues/499", "id": 437749327, "node_id": "MDU6SXNzdWU0Mzc3NDkzMjc=", "number": 499, "title": "Drop Python 2", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-26T16:23:05Z", "updated_at": "2019-05-24T12:59:43Z", "closed_at": "2019-05-24T12:59:43Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I think it's time.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/492", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/492/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/492/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/492/events", "html_url": "https://github.com/dask/dask-ml/issues/492", "id": 429773364, "node_id": "MDU6SXNzdWU0Mjk3NzMzNjQ=", "number": 492, "title": "LabelEncoder returning dask array when passing dask Series", "user": {"login": "henriqueribeiro", "id": 3909112, "node_id": "MDQ6VXNlcjM5MDkxMTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/3909112?v=4", "gravatar_id": "", "url": "https://api.github.com/users/henriqueribeiro", "html_url": "https://github.com/henriqueribeiro", "followers_url": "https://api.github.com/users/henriqueribeiro/followers", "following_url": "https://api.github.com/users/henriqueribeiro/following{/other_user}", "gists_url": "https://api.github.com/users/henriqueribeiro/gists{/gist_id}", "starred_url": "https://api.github.com/users/henriqueribeiro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/henriqueribeiro/subscriptions", "organizations_url": "https://api.github.com/users/henriqueribeiro/orgs", "repos_url": "https://api.github.com/users/henriqueribeiro/repos", "events_url": "https://api.github.com/users/henriqueribeiro/events{/privacy}", "received_events_url": "https://api.github.com/users/henriqueribeiro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-04-05T14:06:39Z", "updated_at": "2019-04-08T10:34:39Z", "closed_at": "2019-04-08T10:34:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Example:\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport dask.dataframe as dd\r\nfrom dask_ml.preprocessing import LabelEncoder\r\n\r\ndef generate_df(size):\r\n    d = {'categorical': np.random.choice(['A', 'B', 'C'], size=size)}\r\n\r\n    df = pd.DataFrame(d, dtype='category')\r\n    ddf = dd.from_pandas(df, 2)\r\n    return df, ddf\r\n\r\ndf, ddf = generate_df(10)\r\nuniques = pd.DataFrame(['A', 'B', 'C'], dtype='category')\r\nenc = LabelEncoder().fit(uniques)\r\ntype(enc.transform(ddf['categorical']))\r\n```\r\nOutput:\r\n```\r\ndask.array.core.Array\r\n```\r\n\r\nI believe it should return a dask Series right?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/490", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/490/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/490/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/490/events", "html_url": "https://github.com/dask/dask-ml/issues/490", "id": 429213118, "node_id": "MDU6SXNzdWU0MjkyMTMxMTg=", "number": 490, "title": "train_test_split documentation", "user": {"login": "r0f1", "id": 7324891, "node_id": "MDQ6VXNlcjczMjQ4OTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/7324891?v=4", "gravatar_id": "", "url": "https://api.github.com/users/r0f1", "html_url": "https://github.com/r0f1", "followers_url": "https://api.github.com/users/r0f1/followers", "following_url": "https://api.github.com/users/r0f1/following{/other_user}", "gists_url": "https://api.github.com/users/r0f1/gists{/gist_id}", "starred_url": "https://api.github.com/users/r0f1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/r0f1/subscriptions", "organizations_url": "https://api.github.com/users/r0f1/orgs", "repos_url": "https://api.github.com/users/r0f1/repos", "events_url": "https://api.github.com/users/r0f1/events{/privacy}", "received_events_url": "https://api.github.com/users/r0f1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-04T10:55:44Z", "updated_at": "2019-04-05T15:24:39Z", "closed_at": "2019-04-05T15:24:39Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\r\nThe documentation on [this page](https://dask-ml.readthedocs.io/en/latest/modules/generated/dask_ml.model_selection.train_test_split.html) has several issues. The arguments unter `dask_ml.model_selection.train_test_split` are not properly formatted, there are spelling mistakes (defualt instead of default), and the first two lines of the last code example are also not properly formatted. I tried to submit a pull request via clicking on the \"Edit on GitHub\" link at the top right corner of the page, but the button is also broken and leading me to a 404 error.\r\n\r\nWould be nice, if someone could tell me how to fix this documentation page.\r\nBest, Flo", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/488", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/488/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/488/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/488/events", "html_url": "https://github.com/dask/dask-ml/issues/488", "id": 427429365, "node_id": "MDU6SXNzdWU0Mjc0MjkzNjU=", "number": 488, "title": "Model selection tests are raising ImportError on scikit-learn master ", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-31T18:47:20Z", "updated_at": "2019-04-05T19:23:14Z", "closed_at": "2019-04-05T19:23:14Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Here's one traceback for  `tests/linear_model/test_glm.py` on Scikit-Learn master:\r\n\r\n``` python-traceback\r\ntests/linear_model/test_glm.py:13: in <module>\r\n    from dask_ml.model_selection import GridSearchCV\r\ndask_ml/model_selection/__init__.py:7: in <module>\r\n    from ._split import ShuffleSplit, KFold, train_test_split\r\ndask_ml/model_selection/_split.py:12: in <module>\r\n    from sklearn.model_selection._split import (\r\nE   ImportError: cannot import name '_validate_shuffle_split_init'\r\n```\r\n\r\nLooks like https://github.com/scikit-learn/scikit-learn/pull/13483/ removed `_validate_shuffle_split_init`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/486", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/486/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/486/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/486/events", "html_url": "https://github.com/dask/dask-ml/issues/486", "id": 424693477, "node_id": "MDU6SXNzdWU0MjQ2OTM0Nzc=", "number": 486, "title": "IncrementalSearchCV has no logging or verbosity", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-25T02:07:49Z", "updated_at": "2020-04-29T16:28:15Z", "closed_at": "2020-04-29T16:28:15Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "This would be nice to have. Scikit-Learn's RandomizedSearchCV has a `verbose` parameter; it'd be nice to mirror that in IncrementalSearchCV.\r\n\r\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/484", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/484/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/484/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/484/events", "html_url": "https://github.com/dask/dask-ml/issues/484", "id": 420809344, "node_id": "MDU6SXNzdWU0MjA4MDkzNDQ=", "number": 484, "title": "Windows installation issues", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars1.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-14T02:58:41Z", "updated_at": "2019-04-27T19:11:34Z", "closed_at": "2019-04-27T19:11:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "There are issues using the recommended \r\n```terminal\r\nconda env create -f ci/environment-3.6.yml --name=dask-ml-dev\r\n```\r\ncommand to create a development environment on Windows due to packages (e.g. `xgboost`) not supporting Windows (ref #482)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/482", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/482/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/482/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/482/events", "html_url": "https://github.com/dask/dask-ml/issues/482", "id": 420247637, "node_id": "MDU6SXNzdWU0MjAyNDc2Mzc=", "number": 482, "title": "Tests are Failing after installation ", "user": {"login": "atyamsriharsha", "id": 10818570, "node_id": "MDQ6VXNlcjEwODE4NTcw", "avatar_url": "https://avatars2.githubusercontent.com/u/10818570?v=4", "gravatar_id": "", "url": "https://api.github.com/users/atyamsriharsha", "html_url": "https://github.com/atyamsriharsha", "followers_url": "https://api.github.com/users/atyamsriharsha/followers", "following_url": "https://api.github.com/users/atyamsriharsha/following{/other_user}", "gists_url": "https://api.github.com/users/atyamsriharsha/gists{/gist_id}", "starred_url": "https://api.github.com/users/atyamsriharsha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/atyamsriharsha/subscriptions", "organizations_url": "https://api.github.com/users/atyamsriharsha/orgs", "repos_url": "https://api.github.com/users/atyamsriharsha/repos", "events_url": "https://api.github.com/users/atyamsriharsha/events{/privacy}", "received_events_url": "https://api.github.com/users/atyamsriharsha/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-03-12T23:18:08Z", "updated_at": "2019-04-27T19:11:34Z", "closed_at": "2019-04-27T19:11:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "After I followed the steps as given in the http://ml.dask.org/contributing.html, there are some tests which are failing after I execute the pytest tests/preprocessing . I am attaching the report for reference. Is the behaviour expected or did I miss a major step in setting up the module.\r\n![dask_test_error](https://user-images.githubusercontent.com/10818570/54242585-6471fb80-44e2-11e9-8f18-7f3008343169.png)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/478", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/478/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/478/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/478/events", "html_url": "https://github.com/dask/dask-ml/issues/478", "id": 419157377, "node_id": "MDU6SXNzdWU0MTkxNTczNzc=", "number": 478, "title": "Documentation link", "user": {"login": "MichaelSchroter", "id": 31654102, "node_id": "MDQ6VXNlcjMxNjU0MTAy", "avatar_url": "https://avatars2.githubusercontent.com/u/31654102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MichaelSchroter", "html_url": "https://github.com/MichaelSchroter", "followers_url": "https://api.github.com/users/MichaelSchroter/followers", "following_url": "https://api.github.com/users/MichaelSchroter/following{/other_user}", "gists_url": "https://api.github.com/users/MichaelSchroter/gists{/gist_id}", "starred_url": "https://api.github.com/users/MichaelSchroter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MichaelSchroter/subscriptions", "organizations_url": "https://api.github.com/users/MichaelSchroter/orgs", "repos_url": "https://api.github.com/users/MichaelSchroter/repos", "events_url": "https://api.github.com/users/MichaelSchroter/events{/privacy}", "received_events_url": "https://api.github.com/users/MichaelSchroter/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-10T07:49:32Z", "updated_at": "2019-03-15T20:18:15Z", "closed_at": "2019-03-15T20:18:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi All,\r\n\r\nThere is a link that does not open in [dask-ml](https://ml.dask.org/modules/generated/dask_ml.wrappers.Incremental.html#dask_ml.wrappers.Incremental) docs pages. In the page the [list of incremental learners](https://scikit-learn.org/stable/modules/scaling_strategies.html#incremental-learning#noqa) is broken. \r\n\r\nWould anyone be able to fix it\r\n\r\nThanks\r\n\r\nMichael", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/475", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/475/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/475/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/475/events", "html_url": "https://github.com/dask/dask-ml/issues/475", "id": 415524969, "node_id": "MDU6SXNzdWU0MTU1MjQ5Njk=", "number": 475, "title": "Support for scikit-optimize", "user": {"login": "sheljoy", "id": 12163410, "node_id": "MDQ6VXNlcjEyMTYzNDEw", "avatar_url": "https://avatars3.githubusercontent.com/u/12163410?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sheljoy", "html_url": "https://github.com/sheljoy", "followers_url": "https://api.github.com/users/sheljoy/followers", "following_url": "https://api.github.com/users/sheljoy/following{/other_user}", "gists_url": "https://api.github.com/users/sheljoy/gists{/gist_id}", "starred_url": "https://api.github.com/users/sheljoy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sheljoy/subscriptions", "organizations_url": "https://api.github.com/users/sheljoy/orgs", "repos_url": "https://api.github.com/users/sheljoy/repos", "events_url": "https://api.github.com/users/sheljoy/events{/privacy}", "received_events_url": "https://api.github.com/users/sheljoy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-02-28T09:27:58Z", "updated_at": "2019-04-30T11:34:59Z", "closed_at": "2019-04-30T11:34:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "scikit-optimize (https://github.com/scikit-optimize/scikit-optimize) supports the apis\r\nsklearn.externals.joblib.{Parallel, delayed}", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/473", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/473/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/473/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/473/events", "html_url": "https://github.com/dask/dask-ml/issues/473", "id": 414215481, "node_id": "MDU6SXNzdWU0MTQyMTU0ODE=", "number": 473, "title": "Update scikit-learn master build", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-25T17:19:36Z", "updated_at": "2019-03-08T12:03:30Z", "closed_at": "2019-03-08T12:03:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Right now we build scikit-learn master from source. We may be able to install with\r\n\r\n```\r\npip install --no-deps -f nightly.scikit-learn.org scikit-learn\r\n```\r\n\r\nhttps://twitter.com/amuellerml/status/1100052487304826880", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/465", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/465/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/465/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/465/events", "html_url": "https://github.com/dask/dask-ml/issues/465", "id": 411919850, "node_id": "MDU6SXNzdWU0MTE5MTk4NTA=", "number": 465, "title": "How to chunk dask array with unknown chunks", "user": {"login": "MichaelSchroter", "id": 31654102, "node_id": "MDQ6VXNlcjMxNjU0MTAy", "avatar_url": "https://avatars2.githubusercontent.com/u/31654102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MichaelSchroter", "html_url": "https://github.com/MichaelSchroter", "followers_url": "https://api.github.com/users/MichaelSchroter/followers", "following_url": "https://api.github.com/users/MichaelSchroter/following{/other_user}", "gists_url": "https://api.github.com/users/MichaelSchroter/gists{/gist_id}", "starred_url": "https://api.github.com/users/MichaelSchroter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MichaelSchroter/subscriptions", "organizations_url": "https://api.github.com/users/MichaelSchroter/orgs", "repos_url": "https://api.github.com/users/MichaelSchroter/repos", "events_url": "https://api.github.com/users/MichaelSchroter/events{/privacy}", "received_events_url": "https://api.github.com/users/MichaelSchroter/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2019-02-19T13:20:00Z", "updated_at": "2019-02-28T13:59:31Z", "closed_at": "2019-02-28T02:52:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi All,\r\n\r\nI have two dask arrays with shape `X:(nan, 42), y:(nan,)`. I my goal is to fit these into a `SGDRegressor` dask-ml model. However, when I use it I am given an error saying that `Cannot operate on Dask array with unknown chunk sizes`. #453\r\n\r\nCould anyone be able to tell me what should be done.\r\n\r\nThanks\r\n\r\nMichael", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/464", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/464/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/464/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/464/events", "html_url": "https://github.com/dask/dask-ml/issues/464", "id": 411796983, "node_id": "MDU6SXNzdWU0MTE3OTY5ODM=", "number": 464, "title": "Error importing \"IncrementalSearchCV\"", "user": {"login": "tanayag", "id": 16465642, "node_id": "MDQ6VXNlcjE2NDY1NjQy", "avatar_url": "https://avatars0.githubusercontent.com/u/16465642?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tanayag", "html_url": "https://github.com/tanayag", "followers_url": "https://api.github.com/users/tanayag/followers", "following_url": "https://api.github.com/users/tanayag/following{/other_user}", "gists_url": "https://api.github.com/users/tanayag/gists{/gist_id}", "starred_url": "https://api.github.com/users/tanayag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tanayag/subscriptions", "organizations_url": "https://api.github.com/users/tanayag/orgs", "repos_url": "https://api.github.com/users/tanayag/repos", "events_url": "https://api.github.com/users/tanayag/events{/privacy}", "received_events_url": "https://api.github.com/users/tanayag/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-02-19T08:15:12Z", "updated_at": "2019-02-21T21:43:31Z", "closed_at": "2019-02-21T21:43:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\n>>> from dask_ml.model_selection import IncrementalSearchCV\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nImportError: cannot import name 'IncrementalSearchCV'\r\n```\r\nWhen I am importing IncrementalSearchCV this is the error, and there is no traceback to track the problem!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/457", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/457/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/457/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/457/events", "html_url": "https://github.com/dask/dask-ml/issues/457", "id": 409932236, "node_id": "MDU6SXNzdWU0MDk5MzIyMzY=", "number": 457, "title": "Install in graphviz in the doc env", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-13T18:04:40Z", "updated_at": "2019-02-13T18:55:34Z", "closed_at": "2019-02-13T18:55:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Failure in https://travis-ci.org/dask/dask-ml/builds/492822701?utm_source=github_status&utm_medium=notification from not having graphviz.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/456", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/456/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/456/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/456/events", "html_url": "https://github.com/dask/dask-ml/issues/456", "id": 409926017, "node_id": "MDU6SXNzdWU0MDk5MjYwMTc=", "number": 456, "title": "Add CI job for oldest supported dependencies", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-13T17:48:45Z", "updated_at": "2019-02-25T14:57:09Z", "closed_at": "2019-02-25T14:57:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/454", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/454/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/454/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/454/events", "html_url": "https://github.com/dask/dask-ml/issues/454", "id": 409547612, "node_id": "MDU6SXNzdWU0MDk1NDc2MTI=", "number": 454, "title": "module 'dask' has no attribute 'sharedict'", "user": {"login": "akter-pi", "id": 46878387, "node_id": "MDQ6VXNlcjQ2ODc4Mzg3", "avatar_url": "https://avatars0.githubusercontent.com/u/46878387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akter-pi", "html_url": "https://github.com/akter-pi", "followers_url": "https://api.github.com/users/akter-pi/followers", "following_url": "https://api.github.com/users/akter-pi/following{/other_user}", "gists_url": "https://api.github.com/users/akter-pi/gists{/gist_id}", "starred_url": "https://api.github.com/users/akter-pi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akter-pi/subscriptions", "organizations_url": "https://api.github.com/users/akter-pi/orgs", "repos_url": "https://api.github.com/users/akter-pi/repos", "events_url": "https://api.github.com/users/akter-pi/events{/privacy}", "received_events_url": "https://api.github.com/users/akter-pi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-02-12T23:22:00Z", "updated_at": "2019-02-13T18:04:52Z", "closed_at": "2019-02-13T18:04:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi I am trying to use incremental from dask. My code is simple and following the existing example. My code is below. But I got error when it calls inc.fit and the error is \"AttributeError: module 'dask' has no attribute 'sharedict'\". I am using dask 1.1.1 and dask_ml 0.11.0\r\n\r\n``\r\n\r\nfrom dask.distributed import Client\r\nclient = Client()\r\n\r\nimport dask\r\n\r\nimport dask.dataframe as dd\r\nimport dask.array as da\r\n\r\ndf = dd.read_csv('BreastCancer.csv')\r\nX = df.drop(['Id','Class','Bare.nuclei'],axis=1)\r\ny = df['Class']=='benign'\r\n\r\nfrom dask_ml.model_selection import train_test_split\r\nX_train, X_test, y_train, y_test = train_test_split(X.to_dask_array(True), y.to_dask_array(True))\r\n\r\nX_train, X_test, y_train, y_test = dask.persist(X_train, X_test, y_train, y_test)\r\nclasses = da.unique(y_train).compute()\r\n\r\nfrom sklearn.linear_model import SGDClassifier\r\nest = SGDClassifier(loss='log', penalty='l2', tol=1e-3)\r\n\r\nfrom dask_ml.wrappers import Incremental\r\ninc = Incremental(est, scoring='accuracy')\r\n\r\ninc.fit(X_train, y_train, classes=classes)\r\n``\r\n\r\nThe error is\r\n`AttributeError                            Traceback (most recent call last)                 \r\n<ipython-input-1-19bb676669f5> in <module>                                                  \r\n     25 inc = Incremental(est, scoring='accuracy')                                          \r\n     26                                                                                     \r\n---> 27 inc.fit(X_train, y_train, classes=classes)                                          \r\n                                                                                            \r\n/mnt/d/PI.X/py3.5_venv/lib/python3.5/site-packages/dask_ml/wrappers.py in fit(self, X, y, **\r\nfit_kwargs)                                                                                 \r\n    462     def fit(self, X, y=None, **fit_kwargs):                                         \r\n    463         estimator = sklearn.base.clone(self.estimator)                              \r\n--> 464         self._fit_for_estimator(estimator, X, y, **fit_kwargs)                      \r\n    465         return self                                                                 \r\n    466                                                                                     \r\n                                                                                            \r\n/mnt/d/PI.X/py3.5_venv/lib/python3.5/site-packages/dask_ml/wrappers.py in _fit_f(self, estim\r\nator, X, y, **fit_kwargs)                                                                   \r\n    453                 random_state=self.random_state,                                     \r\n    454                 shuffle_blocks=self.shuffle_blocks,                                 \r\n--> 455                 **fit_kwargs                                                        \r\n    456             )                                                                       \r\n    457                                                                                     \r\n                                                                                            \r\n/mnt/d/PI.X/py3.5_venv/lib/python3.5/site-packages/dask_ml/_partial.py in fit(model, x, y, c\r\nompute, shuffle_blocks, random_state, **kwargs)                                             \r\n    195     )                                                                               \r\n    196                                                                                     \r\n--> 197     new_dsk = dask.sharedict.merge((name, dsk), x.dask, getattr(y, \"dask\", {}))     \r\n    198     value = Delayed((name, nblocks - 1), new_dsk)                                   \r\n    199                                                                                     \r\n                                                                                            \r\nAttributeError: module 'dask' has no attribute 'sharedict'                                  \r\n                                                                                            `\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/453", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/453/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/453/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/453/events", "html_url": "https://github.com/dask/dask-ml/issues/453", "id": 409250946, "node_id": "MDU6SXNzdWU0MDkyNTA5NDY=", "number": 453, "title": "type error when fitting X,y", "user": {"login": "MichaelSchroter", "id": 31654102, "node_id": "MDQ6VXNlcjMxNjU0MTAy", "avatar_url": "https://avatars2.githubusercontent.com/u/31654102?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MichaelSchroter", "html_url": "https://github.com/MichaelSchroter", "followers_url": "https://api.github.com/users/MichaelSchroter/followers", "following_url": "https://api.github.com/users/MichaelSchroter/following{/other_user}", "gists_url": "https://api.github.com/users/MichaelSchroter/gists{/gist_id}", "starred_url": "https://api.github.com/users/MichaelSchroter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MichaelSchroter/subscriptions", "organizations_url": "https://api.github.com/users/MichaelSchroter/orgs", "repos_url": "https://api.github.com/users/MichaelSchroter/repos", "events_url": "https://api.github.com/users/MichaelSchroter/events{/privacy}", "received_events_url": "https://api.github.com/users/MichaelSchroter/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-02-12T11:27:14Z", "updated_at": "2019-03-12T23:24:56Z", "closed_at": "2019-03-12T23:24:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi All,\r\n\r\nI have created the training set for machine learning and when trying to `fit` model it gives a value error.\r\n\r\nThe code and error is as follows.\r\n\r\nCode:\r\n\r\n`search.fit(train_final[X_cols_train], train_final['target'])`\r\n\r\noutput:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-105-9dea7c488bbf> in <module>\r\n----> 1 search.fit(train_final[X_cols_train], train_final['target'])\r\n\r\n~/env/lib/python3.5/site-packages/dask_ml/model_selection/_incremental.py in fit(self, X, y, **fit_params)\r\n    572             Additional partial fit keyword arguments for the estimator.\r\n    573         \"\"\"\r\n--> 574         return default_client().sync(self._fit, X, y, **fit_params)\r\n    575 \r\n    576     @if_delegate_has_method(delegate=(\"best_estimator_\", \"estimator\"))\r\n\r\n~/env/lib/python3.5/site-packages/distributed/client.py in sync(self, func, *args, **kwargs)\r\n    671             return future\r\n    672         else:\r\n--> 673             return sync(self.loop, func, *args, **kwargs)\r\n    674 \r\n    675     def __repr__(self):\r\n\r\n~/env/lib/python3.5/site-packages/distributed/utils.py in sync(loop, func, *args, **kwargs)\r\n    275             e.wait(10)\r\n    276     if error[0]:\r\n--> 277         six.reraise(*error[0])\r\n    278     else:\r\n    279         return result[0]\r\n\r\n~/env/lib/python3.5/site-packages/six.py in reraise(tp, value, tb)\r\n    691             if value.__traceback__ is not tb:\r\n    692                 raise value.with_traceback(tb)\r\n--> 693             raise value\r\n    694         finally:\r\n    695             value = None\r\n\r\n~/env/lib/python3.5/site-packages/distributed/utils.py in f()\r\n    260             if timeout is not None:\r\n    261                 future = gen.with_timeout(timedelta(seconds=timeout), future)\r\n--> 262             result[0] = yield future\r\n    263         except Exception as exc:\r\n    264             error[0] = sys.exc_info()\r\n\r\n~/env/lib/python3.5/site-packages/tornado/gen.py in run(self)\r\n   1131 \r\n   1132                     try:\r\n-> 1133                         value = future.result()\r\n   1134                     except Exception:\r\n   1135                         self.had_exception = True\r\n\r\n/usr/lib/python3.5/asyncio/futures.py in result(self)\r\n    291             self._tb_logger = None\r\n    292         if self._exception is not None:\r\n--> 293             raise self._exception\r\n    294         return self._result\r\n    295 \r\n\r\n~/env/lib/python3.5/site-packages/tornado/gen.py in wrapper(*args, **kwargs)\r\n    324                 try:\r\n    325                     orig_stack_contexts = stack_context._state.contexts\r\n--> 326                     yielded = next(result)\r\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\r\n    328                         yielded = _create_future()\r\n\r\n~/env/lib/python3.5/site-packages/dask_ml/model_selection/_incremental.py in _fit(self, X, y, **fit_params)\r\n    522     @gen.coroutine\r\n    523     def _fit(self, X, y, **fit_params):\r\n--> 524         X, y = self._check_array(X, y)\r\n    525 \r\n    526         X_train, X_test, y_train, y_test = self._get_train_test_split(X, y)\r\n\r\n~/env/lib/python3.5/site-packages/dask_ml/model_selection/_incremental.py in _check_array(self, X, y, **kwargs)\r\n    437         if isinstance(y, np.ndarray):\r\n    438             y = da.from_array(y, y.shape)\r\n--> 439         X = check_array(X, **kwargs)\r\n    440         kwargs[\"ensure_2d\"] = False\r\n    441         y = check_array(y, **kwargs)\r\n\r\n~/env/lib/python3.5/site-packages/dask_ml/utils.py in check_array(array, *args, **kwargs)\r\n    149     elif isinstance(array, dd.DataFrame):\r\n    150         if not accept_dask_dataframe:\r\n--> 151             raise TypeError(\"This estimator does not support dask dataframes.\")\r\n    152         # TODO: sample?\r\n    153         return array\r\n\r\nTypeError: This estimator does not support dask dataframes.\r\n```\r\n\r\nAlso I would like to know when fitting data do we need to re-code string values in columns (in categorical data) to numerical data. For example if there is a column with categories `a,b,c` do we have to re-code it as for example as `1,2,3`. Furthermore if we need to do so then how do we make sure that the test set also is re-coded in the same pattern such as 1 for a and 2 for b. \r\n\r\nThank you\r\n\r\nMichael \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/451", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/451/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/451/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/451/events", "html_url": "https://github.com/dask/dask-ml/issues/451", "id": 405098340, "node_id": "MDU6SXNzdWU0MDUwOTgzNDA=", "number": 451, "title": "fit something with parallel_backend is unreasonably slow", "user": {"login": "GuoHao150", "id": 35798699, "node_id": "MDQ6VXNlcjM1Nzk4Njk5", "avatar_url": "https://avatars2.githubusercontent.com/u/35798699?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GuoHao150", "html_url": "https://github.com/GuoHao150", "followers_url": "https://api.github.com/users/GuoHao150/followers", "following_url": "https://api.github.com/users/GuoHao150/following{/other_user}", "gists_url": "https://api.github.com/users/GuoHao150/gists{/gist_id}", "starred_url": "https://api.github.com/users/GuoHao150/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GuoHao150/subscriptions", "organizations_url": "https://api.github.com/users/GuoHao150/orgs", "repos_url": "https://api.github.com/users/GuoHao150/repos", "events_url": "https://api.github.com/users/GuoHao150/events{/privacy}", "received_events_url": "https://api.github.com/users/GuoHao150/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-01-31T06:20:11Z", "updated_at": "2019-05-10T15:53:18Z", "closed_at": "2019-01-31T07:36:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "I set up a Dask cluster and tries to reproduce the distributed Machine Learning tutorial from `https://github.com/dask/dask-tutorial/blob/master/08_machine_learning.ipynb`  when I run the command \r\n```\r\n%%time\r\nwith joblib.parallel_backend(\"dask\", scatter=[X, y]):\r\n    grid_search.fit(X, y)\r\n```\r\nit's not complete even after an hour and compare to the fitting without Dask as a backend I thought it's unreasonably slow. Since it does not give me an error message I wonder if anybody here could give me some advice. Thanks\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/446", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/446/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/446/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/446/events", "html_url": "https://github.com/dask/dask-ml/issues/446", "id": 400022801, "node_id": "MDU6SXNzdWU0MDAwMjI4MDE=", "number": 446, "title": "Tornado \"await wasn't used with future\" leads to KeyError", "user": {"login": "mfenner1", "id": 913036, "node_id": "MDQ6VXNlcjkxMzAzNg==", "avatar_url": "https://avatars3.githubusercontent.com/u/913036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mfenner1", "html_url": "https://github.com/mfenner1", "followers_url": "https://api.github.com/users/mfenner1/followers", "following_url": "https://api.github.com/users/mfenner1/following{/other_user}", "gists_url": "https://api.github.com/users/mfenner1/gists{/gist_id}", "starred_url": "https://api.github.com/users/mfenner1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mfenner1/subscriptions", "organizations_url": "https://api.github.com/users/mfenner1/orgs", "repos_url": "https://api.github.com/users/mfenner1/repos", "events_url": "https://api.github.com/users/mfenner1/events{/privacy}", "received_events_url": "https://api.github.com/users/mfenner1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2019-01-16T22:16:40Z", "updated_at": "2019-08-09T16:00:39Z", "closed_at": "2019-08-09T15:15:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Apologies if I'm missing something trivial (i.e., something is not implemented in dask-ml, etc).  \r\n\r\nI have what I hope is a simple test example to spin up and use `dask-ml`.  When running, I get the errors shown in `error.txt`.\r\n\r\n```\r\nfrom sklearn import (datasets, \r\n                     decomposition,\r\n                     metrics, \r\n                     model_selection as skms,\r\n                     neighbors,\r\n                     pipeline,\r\n                     preprocessing as skpre)\r\nimport numpy as np\r\n\r\nfrom dask.distributed import Client\r\nfrom sklearn.externals import joblib\r\nclient = Client()\r\n\r\nwith joblib.parallel_backend('dask'):\r\n    iris = datasets.load_iris()\r\n    ftrs, tgt = iris.data, iris.target\r\n    knn    = neighbors.KNeighborsClassifier()\r\n    pca    = decomposition.PCA()\r\n    scaler = skpre.StandardScaler()\r\n\r\n    pipe = pipeline.Pipeline(steps=[('scaler', scaler),\r\n                                    ('pca', pca), \r\n                                    ('knn', knn)])\r\n    cv_scores = skms.cross_val_score(pipe, ftrs, tgt, cv=10)\r\n\r\n```\r\n\r\nThis was with a fresh `conda install dask-ml` environment (off of the main conda channel).  Installing via `conda install -c conda-forge dask-ml` appeared to lead to the same version of `dask` so I didn't pursue that.  Some relevant software versions.\r\n```\r\ndask                      1.0.0                    py37_0  \r\ndask-core                 1.0.0                    py37_0  \r\ndask-glm                  0.2.0                    py37_0  \r\ndask-ml                   0.11.0                   py37_0 \r\ndistributed               1.25.2                   py37_0  \r\npython                    3.7.2                haf84260_0  \r\nscikit-learn              0.20.2           py37h27c97d8_0\r\n```  \r\n\r\n[error.txt](https://github.com/dask/dask-ml/files/2766275/error.txt)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/444", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/444/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/444/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/444/events", "html_url": "https://github.com/dask/dask-ml/issues/444", "id": 395984756, "node_id": "MDU6SXNzdWUzOTU5ODQ3NTY=", "number": 444, "title": "seeking guidance on setting up bleeding edge versions of packages to support dask-ml, etc.", "user": {"login": "ebo", "id": 601025, "node_id": "MDQ6VXNlcjYwMTAyNQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/601025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebo", "html_url": "https://github.com/ebo", "followers_url": "https://api.github.com/users/ebo/followers", "following_url": "https://api.github.com/users/ebo/following{/other_user}", "gists_url": "https://api.github.com/users/ebo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebo/subscriptions", "organizations_url": "https://api.github.com/users/ebo/orgs", "repos_url": "https://api.github.com/users/ebo/repos", "events_url": "https://api.github.com/users/ebo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-01-04T16:24:33Z", "updated_at": "2019-04-30T11:12:35Z", "closed_at": "2019-04-30T11:12:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have probably wasted a week or more tracking down various package version issues.\r\n\r\nBy the time I got the following code to work in my env:\r\n\r\n```\r\nfrom dask.distributed import Client\r\nfrom sklearn.externals.joblib import parallel_backend\r\n\r\nclient = Client()  # Connect to a Dask Cluster\r\n\r\nwith parallel_backend('dask'):\r\n   \\# Your normal scikit-learn code here\r\n```\r\n\r\nGeoviews or one of its dependencies was somehow broken and I lost all my visualization capabilities.  So I thought I would ask if the following should be expected to work:\r\n\r\nstarting from a clean Anaconda 3.7 install:\r\n\r\nconda update --all\r\n\r\n\\# create a new env\r\nconda create --name dev-env\r\nsource activate  dev-env\r\n\r\n\\# remove any of the packages that are installed by default:\r\nconda remove dask dask-glm dask-ml datashader distributed geoviews intake intake-xarray rasterio scikit-image scikit-learn xarray\r\n\r\n\\# git clone all the packages for: conda remove dask dask-glm dask-ml datashader distributed geoviews intake intake-xarray rasterio scikit-image scikit-learn xarray\r\n\r\n\\# for each package: in the above list:\r\ncd <package>\r\npython setup.py develop\r\n\r\n=============\r\n\r\nthis gives me the bleeding edge version of the packages.  \r\n\r\nIs there a better way to set this up?  I have tried using pip, but I had some early issues with an update overwriting the version.  This seemed to mostly work, but not always able to run the bleeding-edge git versions.\r\n\r\nAs a note, I think that the Managing Environments  <https://conda.io/docs/user-guide/tasks/manage-environments.html> documentation would likely be a good place for this information.  What I am looking for is how to install and run development packages of dask, distributed, xarray, and similar packages from their git source.  I will go back over the weekend and re-read \"Why you need Python environments and how to manage them with Conda\" <https://medium.freecodecamp.org/why-you-need-python-environments-and-how-to-manage-them-with-conda-85f155f4353c> and similar docs and see if I can come up with a way to get this all working well enough to consistently move forward.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/438", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/438/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/438/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/438/events", "html_url": "https://github.com/dask/dask-ml/issues/438", "id": 390148930, "node_id": "MDU6SXNzdWUzOTAxNDg5MzA=", "number": 438, "title": "Jupyter kernel dying using ParallelPostFit. Workers don't start.", "user": {"login": "svangogh", "id": 40142369, "node_id": "MDQ6VXNlcjQwMTQyMzY5", "avatar_url": "https://avatars1.githubusercontent.com/u/40142369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/svangogh", "html_url": "https://github.com/svangogh", "followers_url": "https://api.github.com/users/svangogh/followers", "following_url": "https://api.github.com/users/svangogh/following{/other_user}", "gists_url": "https://api.github.com/users/svangogh/gists{/gist_id}", "starred_url": "https://api.github.com/users/svangogh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/svangogh/subscriptions", "organizations_url": "https://api.github.com/users/svangogh/orgs", "repos_url": "https://api.github.com/users/svangogh/repos", "events_url": "https://api.github.com/users/svangogh/events{/privacy}", "received_events_url": "https://api.github.com/users/svangogh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2018-12-12T10:01:05Z", "updated_at": "2019-04-30T11:18:47Z", "closed_at": "2019-04-30T11:18:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'am trying to use ParallelPostFit to wrap around a RandomForestClassfier which I am using to segment very large images (terabyte order) on a HPC.\r\n\r\nclf = ParallelPostFit(RandomForestClassifier(criterion='gini', class_weight='balanced', n_estimators=100, n_jobs=-1)\r\n\r\nI start a client and a cluster as follows: \r\n\r\nfrom dask_jobqueue import SLURMCluster\r\ncluster = SLURMCluster(queue='day', walltime='24:00:00', memory='256 GB')\r\nfrom dask.distributed import Client\r\nclient = Client(cluster)\r\n\r\nUnfortunately, when I call clf.predict(X,y), the jupyter kernel dies before the workers even start computing something. It seems that the computations are carried out on the login node (which obviously has less RAM than the images I'm using). \r\n\r\nDo you have any suggestions what could cause this?\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/436", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/436/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/436/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/436/events", "html_url": "https://github.com/dask/dask-ml/issues/436", "id": 389550789, "node_id": "MDU6SXNzdWUzODk1NTA3ODk=", "number": 436, "title": "Allow dask arrays to be hstacked in ColumnTransformer", "user": {"login": "ryan-deak-zefr", "id": 25694465, "node_id": "MDQ6VXNlcjI1Njk0NDY1", "avatar_url": "https://avatars1.githubusercontent.com/u/25694465?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ryan-deak-zefr", "html_url": "https://github.com/ryan-deak-zefr", "followers_url": "https://api.github.com/users/ryan-deak-zefr/followers", "following_url": "https://api.github.com/users/ryan-deak-zefr/following{/other_user}", "gists_url": "https://api.github.com/users/ryan-deak-zefr/gists{/gist_id}", "starred_url": "https://api.github.com/users/ryan-deak-zefr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ryan-deak-zefr/subscriptions", "organizations_url": "https://api.github.com/users/ryan-deak-zefr/orgs", "repos_url": "https://api.github.com/users/ryan-deak-zefr/repos", "events_url": "https://api.github.com/users/ryan-deak-zefr/events{/privacy}", "received_events_url": "https://api.github.com/users/ryan-deak-zefr/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-12-11T00:52:47Z", "updated_at": "2018-12-19T18:48:11Z", "closed_at": "2018-12-19T18:48:11Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently dask Arrays cannot be concatenated in a ColumnTransformer.  It would be nice to allow this.  This issue is related to #365: \"*Silence UserWarning in* `ColumnTransformer._hstack`\".\r\n\r\n## Example Transformer\r\n\r\n```python\r\nfrom sklearn.base import BaseEstimator\r\n\r\n\r\n# Generator ensures the DataFrame shape has NaN in first dim.\r\ndef gen_ints(r, c):\r\n    for i in range(r):\r\n        yield i + np.arange(c)\r\n\r\n\r\n# Some basic transformer.\r\nclass SumTransformer(BaseEstimator):\r\n    def fit(self, X, y=None):\r\n        return self\r\n\r\n    def transform(self, X):\r\n        out = X.map_partitions(lambda x: x.values.sum(axis=-1).reshape(-1, 1))\r\n        return out\r\n```\r\n\r\n### Calling Code\r\n\r\n```python\r\nimport dask.bag as db\r\nimport sklearn\r\nimport dask_ml\r\n\r\ndef test_column_transformer_unk_chunksize():\r\n    cols = 3\r\n    rows = 4\r\n    a = 0x61  # character code for 'a'.\r\n    names = list(map(chr, a + np.arange(cols)))\r\n    x = db.from_sequence(gen_ints(rows, cols)).to_dataframe(columns=names)\r\n\r\n    features = sklearn.pipeline.Pipeline([\r\n        ('features', sklearn.pipeline.FeatureUnion([\r\n            ('ratios', dask_ml.compose.ColumnTransformer([\r\n                ('a_b', SumTransformer(), ['a', 'b']),\r\n                ('b_c', SumTransformer(), ['b', 'c'])\r\n            ]))\r\n        ]))\r\n    ])\r\n\r\n    # Checks:\r\n    #   ValueError: Tried to concatenate arrays with unknown shape (nan, 1).\r\n    #               To force concatenation pass allow_unknown_chunksizes=True.\r\n    out = features.fit_transform(x)\r\n\r\n    exp = np.array([[1, 3], [3, 5], [5, 7], [7, 9]], dtype=np.int32)\r\n    assert isinstance(out, np.ndarray)\r\n    np.testing.assert_array_equal(out, exp)\r\n```\r\n\r\nThis could be fixed by enabling `allow_unknown_chunksizes` in `_hstack`, but currently fails with the following exception:\r\n\r\n```\r\n\r\n../../venv/lib/python3.6/site-packages/sklearn/pipeline.py:300: in fit_transform\r\n    return last_step.fit_transform(Xt, y, **fit_params)\r\n../../venv/lib/python3.6/site-packages/sklearn/pipeline.py:793: in fit_transform\r\n    for name, trans, weight in self._iter())\r\n../../venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:917: in __call__\r\n    if self.dispatch_one_batch(iterator):\r\n../../venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:759: in dispatch_one_batch\r\n    self._dispatch(tasks)\r\n../../venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:716: in _dispatch\r\n    job = self._backend.apply_async(batch, callback=cb)\r\n../../venv/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py:182: in apply_async\r\n    result = ImmediateResult(func)\r\n../../venv/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py:549: in __init__\r\n    self.results = batch()\r\n../../venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:225: in __call__\r\n    for func, args, kwargs in self.items]\r\n../../venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:225: in <listcomp>\r\n    for func, args, kwargs in self.items]\r\n../../venv/lib/python3.6/site-packages/sklearn/pipeline.py:614: in _fit_transform_one\r\n    res = transformer.fit_transform(X, y, **fit_params)\r\n../../venv/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py:471: in fit_transform\r\n    return self._hstack(list(Xs))\r\n../../dask_ml/compose/_column_transformer.py:195: in _hstack\r\n    return da.hstack(Xs)\r\n../../venv/lib/python3.6/site-packages/dask/array/routines.py:111: in hstack\r\n    return concatenate(tup, axis=1)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nseq = [dask.array<lambda, shape=(nan, 1), dtype=int64, chunksize=(nan, 1)>, dask.array<lambda, shape=(nan, 1), dtype=int64, chunksize=(nan, 1)>]\r\naxis = 1, allow_unknown_chunksizes = False\r\n\r\n    def concatenate(seq, axis=0, allow_unknown_chunksizes=False):\r\n        \"\"\"\r\n        Concatenate arrays along an existing axis\r\n    \r\n        Given a sequence of dask Arrays form a new dask Array by stacking them\r\n        along an existing dimension (axis=0 by default)\r\n    \r\n        Parameters\r\n        ----------\r\n        seq: list of dask.arrays\r\n        axis: int\r\n            Dimension along which to align all of the arrays\r\n        allow_unknown_chunksizes: bool\r\n            Allow unknown chunksizes, such as come from converting from dask\r\n            dataframes.  Dask.array is unable to verify that chunks line up.  If\r\n            data comes from differently aligned sources then this can cause\r\n            unexpected results.\r\n    \r\n        Examples\r\n        --------\r\n    \r\n        Create slices\r\n    \r\n        >>> import dask.array as da\r\n        >>> import numpy as np\r\n    \r\n        >>> data = [from_array(np.ones((4, 4)), chunks=(2, 2))\r\n        ...          for i in range(3)]\r\n    \r\n        >>> x = da.concatenate(data, axis=0)\r\n        >>> x.shape\r\n        (12, 4)\r\n    \r\n        >>> da.concatenate(data, axis=1).shape\r\n        (4, 12)\r\n    \r\n        Result is a new dask Array\r\n    \r\n        See Also\r\n        --------\r\n        stack\r\n        \"\"\"\r\n        n = len(seq)\r\n        ndim = len(seq[0].shape)\r\n    \r\n        if axis < 0:\r\n            axis = ndim + axis\r\n        if axis >= ndim:\r\n            msg = (\"Axis must be less than than number of dimensions\"\r\n                   \"\\nData has %d dimensions, but got axis=%d\")\r\n            raise ValueError(msg % (ndim, axis))\r\n    \r\n        if n == 1:\r\n            return seq[0]\r\n    \r\n        if (not allow_unknown_chunksizes and\r\n            not all(i == axis or all(x.shape[i] == seq[0].shape[i] for x in seq)\r\n                    for i in range(ndim))):\r\n            if any(map(np.isnan, seq[0].shape)):\r\n                raise ValueError(\"Tried to concatenate arrays with unknown\"\r\n                                 \" shape %s.  To force concatenation pass\"\r\n                                 \" allow_unknown_chunksizes=True.\"\r\n>                                % str(seq[0].shape))\r\nE               ValueError: Tried to concatenate arrays with unknown shape (nan, 1).  To force concatenation pass allow_unknown_chunksizes=True.\r\n\r\n../../venv/lib/python3.6/site-packages/dask/array/core.py:2835: ValueError\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/435", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/435/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/435/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/435/events", "html_url": "https://github.com/dask/dask-ml/issues/435", "id": 388459006, "node_id": "MDU6SXNzdWUzODg0NTkwMDY=", "number": 435, "title": "Linear Regression hangs indefinitely", "user": {"login": "jdetle", "id": 10944582, "node_id": "MDQ6VXNlcjEwOTQ0NTgy", "avatar_url": "https://avatars1.githubusercontent.com/u/10944582?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdetle", "html_url": "https://github.com/jdetle", "followers_url": "https://api.github.com/users/jdetle/followers", "following_url": "https://api.github.com/users/jdetle/following{/other_user}", "gists_url": "https://api.github.com/users/jdetle/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdetle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdetle/subscriptions", "organizations_url": "https://api.github.com/users/jdetle/orgs", "repos_url": "https://api.github.com/users/jdetle/repos", "events_url": "https://api.github.com/users/jdetle/events{/privacy}", "received_events_url": "https://api.github.com/users/jdetle/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1341971987, "node_id": "MDU6TGFiZWwxMzQxOTcxOTg3", "url": "https://api.github.com/repos/dask/dask-ml/labels/Needs%20Info", "name": "Needs Info", "color": "4e1b91", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-12-07T00:45:17Z", "updated_at": "2019-05-01T18:31:03Z", "closed_at": "2019-05-01T18:30:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "Inside the dask-dev/dask-notebook Docker container,\r\nif I open a notebook, clean and compose a dataframe, and try to train using features from the frame, I can't get the computation to complete.\r\n```\r\nfrom dask_ml.linear_model import LinearRegression\r\n\r\ndef train_model(facts, features_cols, target):\r\n\t# Facts has ~ 90K columns\r\n    features = facts[features_cols].values\r\n    target = facts[[target]].values\r\n    model = LinearRegression()\r\n    model.fit(features, target)\r\n    return model\r\n```\r\n\r\nI can supply a minimum reproducible example if there isn't a clear issue with this code.\r\n\r\nI get this warning continually: \r\n\" distributed.worker - WARNING - Memory use is high but worker has no data to store to disk.  Perhaps some other process is leaking memory?  Process memory: 346.62 MB -- Worker memory limit: 523.97 MB \"\r\n\r\nI was thinking https://github.com/dask/distributed/issues/1866 might be related? I'm out of my element here, but I'm happy to help wherever I can.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/428", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/428/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/428/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/428/events", "html_url": "https://github.com/dask/dask-ml/issues/428", "id": 381922950, "node_id": "MDU6SXNzdWUzODE5MjI5NTA=", "number": 428, "title": "Docs typo for test_train_split?", "user": {"login": "karldw", "id": 12504708, "node_id": "MDQ6VXNlcjEyNTA0NzA4", "avatar_url": "https://avatars3.githubusercontent.com/u/12504708?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karldw", "html_url": "https://github.com/karldw", "followers_url": "https://api.github.com/users/karldw/followers", "following_url": "https://api.github.com/users/karldw/following{/other_user}", "gists_url": "https://api.github.com/users/karldw/gists{/gist_id}", "starred_url": "https://api.github.com/users/karldw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karldw/subscriptions", "organizations_url": "https://api.github.com/users/karldw/orgs", "repos_url": "https://api.github.com/users/karldw/repos", "events_url": "https://api.github.com/users/karldw/events{/privacy}", "received_events_url": "https://api.github.com/users/karldw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 976945495, "node_id": "MDU6TGFiZWw5NzY5NDU0OTU=", "url": "https://api.github.com/repos/dask/dask-ml/labels/Documentation", "name": "Documentation", "color": "0e8a16", "default": false, "description": ""}, {"id": 731685853, "node_id": "MDU6TGFiZWw3MzE2ODU4NTM=", "url": "https://api.github.com/repos/dask/dask-ml/labels/good%20first%20issue", "name": "good first issue", "color": "b60205", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-18T02:56:43Z", "updated_at": "2018-11-28T13:46:19Z", "closed_at": "2018-11-28T13:46:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "The [documentation for the `blockwise` argument](https://github.com/dask/dask-ml/blob/80785a9166b17bfde45f540c9f6a65eb558159e8/dask_ml/model_selection/_split.py#L379) of `train_test_split` says:\r\n\r\n>     blockwise : bool, optional.\r\n>         Whether to shuffle data only within blocks (True), or allow data to\r\n>         be shuffled between blocks (False). Shuffling between blocks can\r\n>         be much more expensive, especially in distributed environments.\r\n>         The default behavior depends on the types in arrays. For Dask Arrays,\r\n>         the default is True (data are not shuffled between blocks). For Dask\r\n>         DataFrames, the default and only allowed value is True (data are\r\n>         shuffled between blocks).\r\n\r\nShould that actually read \"For Dask DataFrames, the default and only allowed value is True (data are **not** shuffled between blocks).\"?\r\n\r\n```\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/427", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/427/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/427/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/427/events", "html_url": "https://github.com/dask/dask-ml/issues/427", "id": 377384416, "node_id": "MDU6SXNzdWUzNzczODQ0MTY=", "number": 427, "title": "CI Failures", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-05T12:44:50Z", "updated_at": "2018-12-02T02:53:39Z", "closed_at": "2018-12-02T02:53:39Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://circleci.com/gh/dask/dask-ml/2992?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n\r\nhttps://circleci.com/gh/dask/dask-ml/2992?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n\r\n```\r\n[flake8]\r\n./dask_ml/linear_model/glm.py:94:-1624: W605 invalid escape sequence '\\l'\r\n./dask_ml/model_selection/_search.py:1148:17: W504 line break after binary operator\r\n./tests/test_pca.py:376:30: W605 invalid escape sequence '\\('\r\n./tests/test_pca.py:378:25: W605 invalid escape sequence '\\)'\r\n./tests/test_pca.py:390:21: W605 invalid escape sequence '\\('\r\n./tests/test_pca.py:391:28: W605 invalid escape sequence '\\)'\r\nExited with code 1\r\n```\r\n\r\nhttps://circleci.com/gh/dask/dask-ml/2993?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n\r\n\r\n```pytb\r\n=================================== FAILURES ===================================\r\n_________________________ test_pipeline_feature_union __________________________\r\n\r\n    def test_pipeline_feature_union():\r\n        iris = load_iris()\r\n        X, y = iris.data, iris.target\r\n    \r\n        pca = PCA(random_state=0)\r\n        kbest = SelectKBest()\r\n        empty_union = FeatureUnion([(\"first\", None), (\"second\", None)])\r\n        empty_pipeline = Pipeline([(\"first\", None), (\"second\", None)])\r\n        scaling = Pipeline([(\"transform\", ScalingTransformer())])\r\n        svc = SVC(kernel=\"linear\", random_state=0)\r\n    \r\n        pipe = Pipeline(\r\n            [\r\n                (\"empty_pipeline\", empty_pipeline),\r\n                (\"scaling\", scaling),\r\n                (\"missing\", None),\r\n                (\r\n                    \"union\",\r\n                    FeatureUnion(\r\n                        [\r\n                            (\"pca\", pca),\r\n                            (\"missing\", None),\r\n                            (\"kbest\", kbest),\r\n                            (\"empty_union\", empty_union),\r\n                        ],\r\n                        transformer_weights={\"pca\": 0.5},\r\n                    ),\r\n                ),\r\n                (\"svc\", svc),\r\n            ]\r\n        )\r\n    \r\n        param_grid = dict(\r\n            scaling__transform__factor=[1, 2],\r\n            union__pca__n_components=[1, 2, 3],\r\n            union__kbest__k=[1, 2],\r\n            svc__C=[0.1, 1, 10],\r\n        )\r\n    \r\n        gs = GridSearchCV(pipe, param_grid=param_grid, cv=3, iid=True)\r\n>       gs.fit(X, y)\r\n\r\ntests/model_selection/dask_searchcv/test_model_selection.py:367: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/model_selection/_search.py:686: in fit\r\n    self._run_search(evaluate_candidates)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/model_selection/_search.py:1130: in _run_search\r\n    evaluate_candidates(ParameterGrid(self.param_grid))\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/model_selection/_search.py:675: in evaluate_candidates\r\n    cv.split(X, y, groups)))\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:983: in __call__\r\n    if self.dispatch_one_batch(iterator):\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:825: in dispatch_one_batch\r\n    self._dispatch(tasks)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:782: in _dispatch\r\n    job = self._backend.apply_async(batch, callback=cb)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py:182: in apply_async\r\n    result = ImmediateResult(func)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py:545: in __init__\r\n    self.results = batch()\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:261: in __call__\r\n    for func, args, kwargs in self.items]\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:261: in <listcomp>\r\n    for func, args, kwargs in self.items]\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: in _fit_and_score\r\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:589: in _score\r\n    return _multimetric_score(estimator, X_test, y_test, scorer)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:619: in _multimetric_score\r\n    score = scorer(estimator, X_test, y_test)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/metrics/scorer.py:228: in _passthrough_scorer\r\n    return estimator.score(*args, **kwargs)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/utils/metaestimators.py:118: in <lambda>\r\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/pipeline.py:519: in score\r\n    Xt = transform.transform(Xt)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/pipeline.py:834: in transform\r\n    for name, trans, weight in self._iter())\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:983: in __call__\r\n    if self.dispatch_one_batch(iterator):\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:825: in dispatch_one_batch\r\n    self._dispatch(tasks)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:782: in _dispatch\r\n    job = self._backend.apply_async(batch, callback=cb)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py:182: in apply_async\r\n    result = ImmediateResult(func)\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py:545: in __init__\r\n    self.results = batch()\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:261: in __call__\r\n    for func, args, kwargs in self.items]\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:261: in <listcomp>\r\n    for func, args, kwargs in self.items]\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/pipeline.py:617: in _transform_one\r\n    res = transformer.transform(X)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = PCA(copy=True, iterated_power='auto', n_components=1, random_state=0,\r\n  svd_solver='auto', tol=0.0, whiten=False)\r\nX = array([[-1.34536609,  1.4       ],\r\n       [-1.36108599,  1.4       ],\r\n       [-1.44888676,  1.3       ],\r\n       [-1.37... 5.        ],\r\n       [ 0.78648496,  5.1       ],\r\n       [ 0.94745888,  5.3       ],\r\n       [ 0.97076437,  5.5       ]])\r\n\r\n    def transform(self, X):\r\n        \"\"\"Apply dimensionality reduction to X.\r\n    \r\n        X is projected on the first principal components previously extracted\r\n        from a training set.\r\n    \r\n        Parameters\r\n        ----------\r\n        X : array-like, shape (n_samples, n_features)\r\n            New data, where n_samples is the number of samples\r\n            and n_features is the number of features.\r\n    \r\n        Returns\r\n        -------\r\n        X_new : array-like, shape (n_samples, n_components)\r\n    \r\n        Examples\r\n        --------\r\n    \r\n        >>> import numpy as np\r\n        >>> from sklearn.decomposition import IncrementalPCA\r\n        >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\r\n        >>> ipca = IncrementalPCA(n_components=2, batch_size=3)\r\n        >>> ipca.fit(X)\r\n        IncrementalPCA(batch_size=3, copy=True, n_components=2, whiten=False)\r\n        >>> ipca.transform(X) # doctest: +SKIP\r\n        \"\"\"\r\n        check_is_fitted(self, ['mean_', 'components_'], all_or_any=all)\r\n    \r\n        X = check_array(X)\r\n        if self.mean_ is not None:\r\n>           X = X - self.mean_\r\nE           ValueError: operands could not be broadcast together with shapes (51,2) (4,)\r\n\r\n/opt/conda/envs/dask-ml-test/lib/python3.6/site-packages/sklearn/decomposition/base.py:130: ValueError\r\n--------------------------- Captured stderr teardown ---------------------------\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/423", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/423/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/423/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/423/events", "html_url": "https://github.com/dask/dask-ml/issues/423", "id": 376075660, "node_id": "MDU6SXNzdWUzNzYwNzU2NjA=", "number": 423, "title": "IncrementalSearchCV should inherit from ParallelPostFit", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-31T17:23:17Z", "updated_at": "2018-12-21T15:34:30Z", "closed_at": "2018-12-21T15:34:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I haven't tried it out yet, but I think this should work.\r\n\r\nThat'd make the handling of `Incremental(...).score` and `IncrementalSearchCV(...).score` consistent.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/410", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/410/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/410/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/410/events", "html_url": "https://github.com/dask/dask-ml/issues/410", "id": 370185572, "node_id": "MDU6SXNzdWUzNzAxODU1NzI=", "number": 410, "title": "Can't import dask_ml.cluster", "user": {"login": "wmbm", "id": 15046836, "node_id": "MDQ6VXNlcjE1MDQ2ODM2", "avatar_url": "https://avatars3.githubusercontent.com/u/15046836?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wmbm", "html_url": "https://github.com/wmbm", "followers_url": "https://api.github.com/users/wmbm/followers", "following_url": "https://api.github.com/users/wmbm/following{/other_user}", "gists_url": "https://api.github.com/users/wmbm/gists{/gist_id}", "starred_url": "https://api.github.com/users/wmbm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wmbm/subscriptions", "organizations_url": "https://api.github.com/users/wmbm/orgs", "repos_url": "https://api.github.com/users/wmbm/repos", "events_url": "https://api.github.com/users/wmbm/events{/privacy}", "received_events_url": "https://api.github.com/users/wmbm/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-10-15T14:18:02Z", "updated_at": "2018-10-26T16:02:25Z", "closed_at": "2018-10-26T16:02:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Perhaps I uninstalled dask incorrectly, but it complains that dask doesn't exist\r\n\r\nI ran `conda install dask`\r\n\r\n```\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-4-c200d62133eb> in <module>()\r\n----> 1 import dask_ml.cluster\r\n\r\n~/miniconda3/envs/py36_data_science/lib/python3.6/site-packages/dask_ml/cluster/__init__.py in <module>()\r\n      1 \"\"\"Unsupervised Clustering Algorithms\"\"\"\r\n      2 \r\n----> 3 from .minibatch import PartialMiniBatchKMeans  # noqa\r\n      4 from .k_means import KMeans  # noqa\r\n      5 from .spectral import SpectralClustering  # noqa\r\n\r\n~/miniconda3/envs/py36_data_science/lib/python3.6/site-packages/dask_ml/cluster/minibatch.py in <module>()\r\n      4 from sklearn import cluster as _cluster\r\n      5 \r\n----> 6 from .._partial import _BigPartialFitMixin, _copy_partial_doc\r\n      7 \r\n      8 \r\n\r\n~/miniconda3/envs/py36_data_science/lib/python3.6/site-packages/dask_ml/_partial.py in <module>()\r\n      6 from abc import ABCMeta\r\n      7 \r\n----> 8 import dask\r\n      9 import numpy as np\r\n     10 import six\r\n\r\nModuleNotFoundError: No module named 'dask'\r\n```\r\n\r\n`import dask_ml` works fine\r\n\r\n`import dask_ml.cluster ` fails with the above error", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/403", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/403/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/403/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/403/events", "html_url": "https://github.com/dask/dask-ml/issues/403", "id": 369648629, "node_id": "MDU6SXNzdWUzNjk2NDg2Mjk=", "number": 403, "title": "Joblib example doesn't register dask's joblib", "user": {"login": "MilesCranmer", "id": 7593028, "node_id": "MDQ6VXNlcjc1OTMwMjg=", "avatar_url": "https://avatars2.githubusercontent.com/u/7593028?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MilesCranmer", "html_url": "https://github.com/MilesCranmer", "followers_url": "https://api.github.com/users/MilesCranmer/followers", "following_url": "https://api.github.com/users/MilesCranmer/following{/other_user}", "gists_url": "https://api.github.com/users/MilesCranmer/gists{/gist_id}", "starred_url": "https://api.github.com/users/MilesCranmer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MilesCranmer/subscriptions", "organizations_url": "https://api.github.com/users/MilesCranmer/orgs", "repos_url": "https://api.github.com/users/MilesCranmer/repos", "events_url": "https://api.github.com/users/MilesCranmer/events{/privacy}", "received_events_url": "https://api.github.com/users/MilesCranmer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-12T17:47:29Z", "updated_at": "2018-10-12T17:59:28Z", "closed_at": "2018-10-12T17:59:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "The joblib example here: http://ml.dask.org/joblib.html:\r\n\r\n```\r\nimport numpy as np\r\nfrom dask.distributed import Client\r\n\r\nfrom sklearn.externals import joblib\r\nfrom sklearn.datasets import load_digits\r\nfrom sklearn.model_selection import RandomizedSearchCV\r\nfrom sklearn.svm import SVC\r\n\r\nclient = Client(processes=False)             # create local cluster\r\n\r\ndigits = load_digits()\r\n\r\nparam_space = {\r\n    'C': np.logspace(-6, 6, 13),\r\n    'gamma': np.logspace(-8, 8, 17),\r\n    'tol': np.logspace(-4, -1, 4),\r\n    'class_weight': [None, 'balanced'],\r\n}\r\n\r\nmodel = SVC(kernel='rbf')\r\nsearch = RandomizedSearchCV(model, param_space, cv=3, n_iter=50, verbose=10)\r\n\r\nwith joblib.parallel_backend('dask'):\r\n    search.fit(digits.data, digits.target)\r\n```\r\n\r\nFails with a KeyError from 'dask' not being registered. It needs:\r\n\r\n```\r\nimport dask_ml.joblib  # registers joblib plugin\r\n```\r\n\r\nand the error does not occur. Is this correct? Can the example be updated?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/399", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/399/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/399/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/399/events", "html_url": "https://github.com/dask/dask-ml/issues/399", "id": 369114579, "node_id": "MDU6SXNzdWUzNjkxMTQ1Nzk=", "number": 399, "title": "Is it safe to replace _apply_partitionwise with map_partitions?", "user": {"login": "mrocklin", "id": 306380, "node_id": "MDQ6VXNlcjMwNjM4MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/306380?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrocklin", "html_url": "https://github.com/mrocklin", "followers_url": "https://api.github.com/users/mrocklin/followers", "following_url": "https://api.github.com/users/mrocklin/following{/other_user}", "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions", "organizations_url": "https://api.github.com/users/mrocklin/orgs", "repos_url": "https://api.github.com/users/mrocklin/repos", "events_url": "https://api.github.com/users/mrocklin/events{/privacy}", "received_events_url": "https://api.github.com/users/mrocklin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-11T13:12:11Z", "updated_at": "2018-10-31T13:52:12Z", "closed_at": "2018-10-31T13:52:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I'm not understanding why this code is here:\r\n\r\nhttps://github.com/dask/dask-ml/blob/90fbe69771926b7e43a5bef99d81e268dad63e7e/dask_ml/wrappers.py#L504-L522\r\n\r\nMy guess is that it resolves some deficiency in `map_partitions`.  Is that still true?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/397", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/397/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/397/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/397/events", "html_url": "https://github.com/dask/dask-ml/issues/397", "id": 368738875, "node_id": "MDU6SXNzdWUzNjg3Mzg4NzU=", "number": 397, "title": "Release", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-10T16:02:32Z", "updated_at": "2018-10-26T15:58:48Z", "closed_at": "2018-10-26T15:58:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We should do 0.10 soon. A couple blockers, will update docs.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/391", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/391/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/391/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/391/events", "html_url": "https://github.com/dask/dask-ml/issues/391", "id": 367815852, "node_id": "MDU6SXNzdWUzNjc4MTU4NTI=", "number": 391, "title": "Require scikit-learn>=0.20", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-08T14:25:48Z", "updated_at": "2018-10-08T16:43:35Z", "closed_at": "2018-10-08T16:43:35Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Any objections? I worry about confusion on things like `from dask_ml.compose import ColumnTransformer`, or some modules that have moved between 0.19 and 0.20.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/390", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/390/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/390/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/390/events", "html_url": "https://github.com/dask/dask-ml/issues/390", "id": 367602059, "node_id": "MDU6SXNzdWUzNjc2MDIwNTk=", "number": 390, "title": "KMeans.fit on uncertain lengths", "user": {"login": "mrocklin", "id": 306380, "node_id": "MDQ6VXNlcjMwNjM4MA==", "avatar_url": "https://avatars3.githubusercontent.com/u/306380?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrocklin", "html_url": "https://github.com/mrocklin", "followers_url": "https://api.github.com/users/mrocklin/followers", "following_url": "https://api.github.com/users/mrocklin/following{/other_user}", "gists_url": "https://api.github.com/users/mrocklin/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrocklin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrocklin/subscriptions", "organizations_url": "https://api.github.com/users/mrocklin/orgs", "repos_url": "https://api.github.com/users/mrocklin/repos", "events_url": "https://api.github.com/users/mrocklin/events{/privacy}", "received_events_url": "https://api.github.com/users/mrocklin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-10-07T22:49:04Z", "updated_at": "2018-10-08T19:34:23Z", "closed_at": "2018-10-08T19:34:23Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "This seems like a reasonable thing that ought to work.  Any ideas on how we could make this happen?\r\n\r\nhttps://stackoverflow.com/questions/52583316/how-to-pass-dask-dataframe-as-input-to-dask-ml-models\r\n\r\n```python\r\nimport dask.dataframe as dd\r\nimport pandas as pd\r\nfrom dask_ml.cluster import KMeans\r\n\r\ndf = dd.from_pandas(pd.DataFrame({'A': [1, 2, 3, 4, 5], \r\n                                  'B': [6, 7, 8, 9, 10]}),\r\n                    npartitions=2)\r\n\r\nkmeans = KMeans()\r\nkmeans.fit(df)\r\n```\r\n\r\n1.  Do we compute lengths explicitly but warn that we're doing so?\r\n2.  Do we actually need explicit lengths (I was somewhat surprised by this)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/388", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/388/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/388/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/388/events", "html_url": "https://github.com/dask/dask-ml/issues/388", "id": 367585127, "node_id": "MDU6SXNzdWUzNjc1ODUxMjc=", "number": 388, "title": "IncrementalSearchCV runs an adaptive algorithm by default", "user": {"login": "stsievert", "id": 1320475, "node_id": "MDQ6VXNlcjEzMjA0NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1320475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stsievert", "html_url": "https://github.com/stsievert", "followers_url": "https://api.github.com/users/stsievert/followers", "following_url": "https://api.github.com/users/stsievert/following{/other_user}", "gists_url": "https://api.github.com/users/stsievert/gists{/gist_id}", "starred_url": "https://api.github.com/users/stsievert/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stsievert/subscriptions", "organizations_url": "https://api.github.com/users/stsievert/orgs", "repos_url": "https://api.github.com/users/stsievert/repos", "events_url": "https://api.github.com/users/stsievert/events{/privacy}", "received_events_url": "https://api.github.com/users/stsievert/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2018-10-07T19:26:24Z", "updated_at": "2020-05-06T14:21:48Z", "closed_at": "2020-05-06T14:21:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "There are two dimensions in which model selection searches can vary:\r\n\r\n> Does the search...\r\n>\r\n> 1. use `partial_fit` or `fit`?\r\n> 2. use previous evaluations to choose which models to evaluate?\r\n>\r\n> (adapted from https://github.com/dask/dask-ml/pull/370#discussion_r221819839, which is a response to https://github.com/dask/dask-ml/pull/370#discussion_r221573023)\r\n\r\nI think (1) should be named \"incremental\" and (2) should be named \"adaptive\".\r\n\r\nCurrently, `IncrementalSearchCV` implements\r\n\r\n* a complex adaptive algorithm\r\n* stopping on plateau\r\n* an incremental search that's used with `_incremental.fit`.\r\n\r\nI'd like to clean the naming of `IncrementalSearchCV`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/385", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/385/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/385/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/385/events", "html_url": "https://github.com/dask/dask-ml/issues/385", "id": 367121915, "node_id": "MDU6SXNzdWUzNjcxMjE5MTU=", "number": 385, "title": "SimpleImputer strange behaviour", "user": {"login": "Keyeoh", "id": 1183823, "node_id": "MDQ6VXNlcjExODM4MjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1183823?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Keyeoh", "html_url": "https://github.com/Keyeoh", "followers_url": "https://api.github.com/users/Keyeoh/followers", "following_url": "https://api.github.com/users/Keyeoh/following{/other_user}", "gists_url": "https://api.github.com/users/Keyeoh/gists{/gist_id}", "starred_url": "https://api.github.com/users/Keyeoh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Keyeoh/subscriptions", "organizations_url": "https://api.github.com/users/Keyeoh/orgs", "repos_url": "https://api.github.com/users/Keyeoh/repos", "events_url": "https://api.github.com/users/Keyeoh/events{/privacy}", "received_events_url": "https://api.github.com/users/Keyeoh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-10-05T09:04:25Z", "updated_at": "2018-10-15T14:02:47Z", "closed_at": "2018-10-15T14:02:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am currently experiencing some weird errors while trying to port a pipeline from sklearn to dask. With respect to the SimpleImputer preprocessing class, I have noticed that the most_frequent strategy is currently implemented in such a way that the result is not what I think it should be. It reads:\r\n\r\n    def _fit_frame(self, X):\r\n        if self.strategy == \"mean\":\r\n            avg = X.mean(axis=0).values\r\n        elif self.strategy == \"median\":\r\n            avg = X.quantile().values\r\n        elif self.strategy == \"constant\":\r\n            avg = np.full(len(X.columns), self.fill_value)\r\n        else:\r\n            avg = [X[col].value_counts().nlargest(1).values for col in X.columns]\r\n            avg = np.concatenate(*dask.compute(avg))\r\n\r\n        self.statistics_ = pd.Series(dask.compute(avg)[0], index=X.columns)\r\n\r\nMy problem is with the following line:\r\n\r\n    avg = [X[col].value_counts().nlargest(1).values for col in X.columns]\r\n\r\nI have been debugging this part and the previous line returns the counts for the most frequent item, not the item itself, which can introduce some weird errors when dealing with categorical data.\r\n\r\nDoes anybody have an explanation for this? Or did I miss something? Any hint will be much appreciated.\r\n\r\nRegards.\r\nGus.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/384", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/384/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/384/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/384/events", "html_url": "https://github.com/dask/dask-ml/issues/384", "id": 366975737, "node_id": "MDU6SXNzdWUzNjY5NzU3Mzc=", "number": 384, "title": "Re-enable warnings from sklearn", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-04T21:21:54Z", "updated_at": "2018-10-08T16:43:35Z", "closed_at": "2018-10-08T16:43:35Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Disabled in https://github.com/dask/dask-ml/pull/382/files", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/383", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/383/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/383/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/383/events", "html_url": "https://github.com/dask/dask-ml/issues/383", "id": 366975547, "node_id": "MDU6SXNzdWUzNjY5NzU1NDc=", "number": 383, "title": "Compat with scikit-learn dev", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-04T21:21:22Z", "updated_at": "2018-10-08T16:43:35Z", "closed_at": "2018-10-08T16:43:35Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Handle removal of DeprecationDict (and the deprecation it was supporting).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/380", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/380/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/380/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/380/events", "html_url": "https://github.com/dask/dask-ml/issues/380", "id": 366803876, "node_id": "MDU6SXNzdWUzNjY4MDM4NzY=", "number": 380, "title": "ShuffleSplit makes same split for every iteration if random_state is set", "user": {"login": "humaneffect", "id": 41023345, "node_id": "MDQ6VXNlcjQxMDIzMzQ1", "avatar_url": "https://avatars1.githubusercontent.com/u/41023345?v=4", "gravatar_id": "", "url": "https://api.github.com/users/humaneffect", "html_url": "https://github.com/humaneffect", "followers_url": "https://api.github.com/users/humaneffect/followers", "following_url": "https://api.github.com/users/humaneffect/following{/other_user}", "gists_url": "https://api.github.com/users/humaneffect/gists{/gist_id}", "starred_url": "https://api.github.com/users/humaneffect/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/humaneffect/subscriptions", "organizations_url": "https://api.github.com/users/humaneffect/orgs", "repos_url": "https://api.github.com/users/humaneffect/repos", "events_url": "https://api.github.com/users/humaneffect/events{/privacy}", "received_events_url": "https://api.github.com/users/humaneffect/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-10-04T13:58:03Z", "updated_at": "2018-10-09T02:23:55Z", "closed_at": "2018-10-09T02:23:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi!\r\nShuffleSplit produces the same data split for every iteration when the random_state is set to a number. I would expect that each iteration would produce a different data split.\r\n\r\n```\r\nimport dask\r\nfrom dask_ml.model_selection import ShuffleSplit\r\nimport sklearn.datasets\r\n\r\nx, y = sklearn.datasets.make_classification(n_samples=10000, n_features=100, n_informative=50, n_clusters_per_class=5, n_classes=5)\r\nx = dask.array.from_array(x, chunks=(100,-1))\r\ny = dask.array.from_array(y, chunks=(100))\r\n\r\ncv = ShuffleSplit(n_splits=2, test_size=0.3, train_size=0.7, random_state=0)\r\nfor train_idx, test_idx in cv.split(X=x, y=y):\r\n    print(train_idx.compute())\r\n\r\n[  25    1   45 ... 9967 9951 9918]\r\n[  25    1   45 ... 9967 9951 9918]\r\n```\r\n\r\nNote: It works as expected if random_state is not set\r\n```\r\ncv = ShuffleSplit(n_splits=2, test_size=0.3, train_size=0.7)\r\nfor train_idx, test_idx in cv.split(X=x, y=y):\r\n    print(train_idx.compute())\r\n\r\n[  46   70   25 ... 9912 9907 9959]\r\n[   5   93   47 ... 9984 9929 9946]\r\n```\r\n\r\nThe issue seems to lie in `dask-ml/dask_ml/model_selection/_split.py` method `_split_blockwise(self, X):` wherein the rng is set to `rng = check_random_state(self.random_state)` for each new cross validation.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/379", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/379/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/379/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/379/events", "html_url": "https://github.com/dask/dask-ml/issues/379", "id": 366406060, "node_id": "MDU6SXNzdWUzNjY0MDYwNjA=", "number": 379, "title": "Possible bug in train_test_split()", "user": {"login": "Keyeoh", "id": 1183823, "node_id": "MDQ6VXNlcjExODM4MjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1183823?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Keyeoh", "html_url": "https://github.com/Keyeoh", "followers_url": "https://api.github.com/users/Keyeoh/followers", "following_url": "https://api.github.com/users/Keyeoh/following{/other_user}", "gists_url": "https://api.github.com/users/Keyeoh/gists{/gist_id}", "starred_url": "https://api.github.com/users/Keyeoh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Keyeoh/subscriptions", "organizations_url": "https://api.github.com/users/Keyeoh/orgs", "repos_url": "https://api.github.com/users/Keyeoh/repos", "events_url": "https://api.github.com/users/Keyeoh/events{/privacy}", "received_events_url": "https://api.github.com/users/Keyeoh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-10-03T15:47:29Z", "updated_at": "2019-04-27T19:11:34Z", "closed_at": "2019-04-27T19:11:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi everybody,\r\n\r\nWhile trying to use the train_test_split() implemented in dask-ml on a Dask DataFrame I have previously generated, I get the following error:\r\n\r\n> Traceback (most recent call last):\r\n  File \"<input>\", line 11, in <module>\r\n  File \"<input>\", line 116, in fit\r\n  File \"<input>\", line 97, in partition_train_test\r\n  File \"C:\\Users\\Y0644483\\AppData\\Local\\Continuum\\miniconda3\\envs\\poc_long\\lib\\site-packages\\dask_ml\\model_selection\\_split.py\", line 430, in train_test_split\r\n    rng = rng.randint(0, 2 ** 32)\r\n  File \"mtrand.pyx\", line 991, in mtrand.RandomState.randint\r\nValueError: high is out of bounds for int32\r\n\r\nLooking into the source code file _split.py, I have noticed the following:\r\n\r\n     rng = check_random_state(random_state)\r\n        rng = rng.randint(0, 2 ** 32)\r\n        return list(\r\n            itertools.chain.from_iterable(\r\n                arr.random_split([train_size, test_size], random_state=rng)\r\n                for arr in arrays\r\n            )\r\n        )\r\n\r\nIf I execute the following code, I can reproduce the same error:\r\n\r\n    import sklearn.utils\r\n    rng = sklearn.utils.check_random_state(2032)\r\n    rng.randint(0, 2 ** 32)\r\n    Traceback (most recent call last):\r\n      File \"<input>\", line 4, in <module>\r\n      File \"mtrand.pyx\", line 991, in mtrand.RandomState.randint\r\n    ValueError: high is out of bounds for int32\r\n\r\nWhich is easily fixed by supplying a dtype parameter:\r\n\r\n    rng.randint(0,2 ** 32, dtype='int64')\r\n    3653591254\r\n\r\nI do not know if there is something I am missing, but I thought it might be interesting to ask...\r\n\r\nAny help or hint would be much appreciated.\r\n\r\nRegards, and keep the good work!\r\n\r\nBTW, I am using a Conda environment with python 3.6.6, dask 0.19.2 and dask-ml 0.10.0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/dask/dask-ml/issues/378", "repository_url": "https://api.github.com/repos/dask/dask-ml", "labels_url": "https://api.github.com/repos/dask/dask-ml/issues/378/labels{/name}", "comments_url": "https://api.github.com/repos/dask/dask-ml/issues/378/comments", "events_url": "https://api.github.com/repos/dask/dask-ml/issues/378/events", "html_url": "https://github.com/dask/dask-ml/issues/378", "id": 365858827, "node_id": "MDU6SXNzdWUzNjU4NTg4Mjc=", "number": 378, "title": "KMeans Clustering Data Type Error", "user": {"login": "QuinnRAndersonDS", "id": 41114212, "node_id": "MDQ6VXNlcjQxMTE0MjEy", "avatar_url": "https://avatars0.githubusercontent.com/u/41114212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/QuinnRAndersonDS", "html_url": "https://github.com/QuinnRAndersonDS", "followers_url": "https://api.github.com/users/QuinnRAndersonDS/followers", "following_url": "https://api.github.com/users/QuinnRAndersonDS/following{/other_user}", "gists_url": "https://api.github.com/users/QuinnRAndersonDS/gists{/gist_id}", "starred_url": "https://api.github.com/users/QuinnRAndersonDS/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/QuinnRAndersonDS/subscriptions", "organizations_url": "https://api.github.com/users/QuinnRAndersonDS/orgs", "repos_url": "https://api.github.com/users/QuinnRAndersonDS/repos", "events_url": "https://api.github.com/users/QuinnRAndersonDS/events{/privacy}", "received_events_url": "https://api.github.com/users/QuinnRAndersonDS/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 731685853, "node_id": "MDU6TGFiZWw3MzE2ODU4NTM=", "url": "https://api.github.com/repos/dask/dask-ml/labels/good%20first%20issue", "name": "good first issue", "color": "b60205", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-10-02T11:44:01Z", "updated_at": "2019-03-08T12:02:38Z", "closed_at": "2019-03-08T12:02:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am attempting to execute the following code.\r\n\r\n##############################\r\nfrom sklearn.datasets import make_blobs\r\nfrom dask_ml.cluster import KMeans\r\n\r\nx, y = make_blobs(n_samples = 100000, n_features = 2)\r\n\r\nmodel = KMeans()\r\n\r\nmodel.fit(x)\r\n##############################\r\n\r\nBut it generates the following error.\r\n\r\n##############################\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"C:\\Users\\tl928yx\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\dask_ml\\cluster\\k_means.py\", line 199, in fit\r\n    tol=self.tol,\r\n  File \"C:\\Users\\tl928yx\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\dask_ml\\cluster\\k_means.py\", line 270, in k_means\r\n    init_max_iter=init_max_iter,\r\n  File \"C:\\Users\\tl928yx\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\dask_ml\\cluster\\k_means.py\", line 518, in _kmeans_single_lloyd\r\n    max_iter=init_max_iter,\r\n  File \"C:\\Users\\tl928yx\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\dask_ml\\cluster\\k_means.py\", line 361, in k_init\r\n    return init_scalable(X, n_clusters, random_state, max_iter, oversampling_factor)\r\n  File \"C:\\Users\\tl928yx\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\dask_ml\\utils.py\", line 334, in wraps\r\n    results = f(*args, **kwargs)\r\n  File \"C:\\Users\\tl928yx\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\dask_ml\\cluster\\k_means.py\", line 459, in init_scalable\r\n    rng2 = random_state.randint(0, 2 ** 32 - 1, chunks=()).compute().item()\r\n  File \"C:\\Users\\tl928yx\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\dask\\array\\random.py\", line 336, in randint\r\n    size=size, chunks=chunks)\r\n  File \"C:\\Users\\tl928yx\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\dask\\array\\random.py\", line 122, in _wrap\r\n    **small_kwargs).dtype\r\n  File \"mtrand.pyx\", line 991, in mtrand.RandomState.randint\r\nValueError: high is out of bounds for int32\r\n\r\n##############################\r\n\r\nPython Version 3.7.0\r\nDask Version 0.19.2\r\nDask_ml Version 0.10.0\r\nDask-glm Version 0.1.0\r\n\r\n##############################\r\n\r\nThank you", "performed_via_github_app": null, "score": 1.0}]}