{"total_count": 48, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/scrapy/parsel/issues/195", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/195/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/195/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/195/events", "html_url": "https://github.com/scrapy/parsel/issues/195", "id": 641996124, "node_id": "MDU6SXNzdWU2NDE5OTYxMjQ=", "number": 195, "title": "Ubuntu installation failure", "user": {"login": "reichaves", "id": 23701514, "node_id": "MDQ6VXNlcjIzNzAxNTE0", "avatar_url": "https://avatars3.githubusercontent.com/u/23701514?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reichaves", "html_url": "https://github.com/reichaves", "followers_url": "https://api.github.com/users/reichaves/followers", "following_url": "https://api.github.com/users/reichaves/following{/other_user}", "gists_url": "https://api.github.com/users/reichaves/gists{/gist_id}", "starred_url": "https://api.github.com/users/reichaves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reichaves/subscriptions", "organizations_url": "https://api.github.com/users/reichaves/orgs", "repos_url": "https://api.github.com/users/reichaves/repos", "events_url": "https://api.github.com/users/reichaves/events{/privacy}", "received_events_url": "https://api.github.com/users/reichaves/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-19T14:07:29Z", "updated_at": "2020-06-22T19:12:30Z", "closed_at": "2020-06-22T18:32:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello\r\n\r\nPlease, I have a difficulty installing the parsel\r\n\r\nI'm on a machine with Ubuntu 18.04 and python 3.8.2\r\n\r\nI installed with the command \"pip install parsel\", but when I call \"from parsel import Selector\" it still appears: ModuleNotFoundError: No module named 'parsel'  \r\n\r\nI also restarted the machine but the error continues. And when I install it again it appears: Requirement already satisfied\r\n\r\nPlease, in Ubuntu is there another way that should be used for installation?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/188", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/188/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/188/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/188/events", "html_url": "https://github.com/scrapy/parsel/issues/188", "id": 585866079, "node_id": "MDU6SXNzdWU1ODU4NjYwNzk=", "number": 188, "title": "remove() does not exist", "user": {"login": "philithomas", "id": 18591146, "node_id": "MDQ6VXNlcjE4NTkxMTQ2", "avatar_url": "https://avatars1.githubusercontent.com/u/18591146?v=4", "gravatar_id": "", "url": "https://api.github.com/users/philithomas", "html_url": "https://github.com/philithomas", "followers_url": "https://api.github.com/users/philithomas/followers", "following_url": "https://api.github.com/users/philithomas/following{/other_user}", "gists_url": "https://api.github.com/users/philithomas/gists{/gist_id}", "starred_url": "https://api.github.com/users/philithomas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/philithomas/subscriptions", "organizations_url": "https://api.github.com/users/philithomas/orgs", "repos_url": "https://api.github.com/users/philithomas/repos", "events_url": "https://api.github.com/users/philithomas/events{/privacy}", "received_events_url": "https://api.github.com/users/philithomas/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756374, "node_id": "MDU6TGFiZWwyMDM3NTYzNzQ=", "url": "https://api.github.com/repos/scrapy/parsel/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 1575802971, "node_id": "MDU6TGFiZWwxNTc1ODAyOTcx", "url": "https://api.github.com/repos/scrapy/parsel/labels/discuss", "name": "discuss", "color": "cc317c", "default": false, "description": ""}, {"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-23T01:25:45Z", "updated_at": "2020-06-24T11:17:51Z", "closed_at": "2020-06-24T11:17:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "I learned from the [API documentation](https://parsel.readthedocs.io/en/latest/parsel.html#parsel.selector.SelectorList.remove) that the SelectorList class contains a remove method. But I don't see it in v1.5.2.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/187", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/187/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/187/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/187/events", "html_url": "https://github.com/scrapy/parsel/issues/187", "id": 581120075, "node_id": "MDU6SXNzdWU1ODExMjAwNzU=", "number": 187, "title": "Why are original strings modified when parsed as Selector", "user": {"login": "hillerliao", "id": 5266745, "node_id": "MDQ6VXNlcjUyNjY3NDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/5266745?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hillerliao", "html_url": "https://github.com/hillerliao", "followers_url": "https://api.github.com/users/hillerliao/followers", "following_url": "https://api.github.com/users/hillerliao/following{/other_user}", "gists_url": "https://api.github.com/users/hillerliao/gists{/gist_id}", "starred_url": "https://api.github.com/users/hillerliao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hillerliao/subscriptions", "organizations_url": "https://api.github.com/users/hillerliao/orgs", "repos_url": "https://api.github.com/users/hillerliao/repos", "events_url": "https://api.github.com/users/hillerliao/events{/privacy}", "received_events_url": "https://api.github.com/users/hillerliao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756374, "node_id": "MDU6TGFiZWwyMDM3NTYzNzQ=", "url": "https://api.github.com/repos/scrapy/parsel/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-14T09:10:30Z", "updated_at": "2020-06-04T13:41:56Z", "closed_at": "2020-06-04T13:41:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "```python\r\n>>> import requests\r\n>>> from parsel import Selector\r\n>>> url = 'https://feed.businesswire.com/rss/home/?rss=G1QFDERJXkJeGVtYWA=='\r\n>>> response = requests.get(url)\r\n>>> posts = Selector(response.text).css('item')\r\n>>> post = posts[0]\r\n>>> print(post.extract())\r\n```\r\n```xml\r\n<item>\r\n<title>U.S. Bancorp Announces First Quarter Earnings Conference Call Details</title>\r\n<pubdate>Fri, 13 Mar 2020 21:59:00 UT</pubdate>\r\n<description>MINNEAPOLIS--(BUSINESS WIRE)--U.S. Bancorp (NYSE: USB) will release its first quarter 2020 earnings results before the market opens on Wednesday, April 15. At 8 a.m. CT, Chairman, President and Chief Executive Officer Andy Cecere and Vice Chairman and Chief Financial Officer Terry Dolan will host a conference call to review the financial results. The conference call will be available online or by telephone. Via internet: To access the webcast and presentation, visit U.S. Bancorp\u2019s website at us</description>\r\n<link>http://www.businesswire.com/news/home/20200313005538/en/U.S.-Bancorp-Announces-Quarter-Earnings-Conference-Call/?feedref=JjAwJuNHiystnCoBq_hl-fTiTHZ_tL7veK4k7YjFBuVdpTHRh3tVfOBYRO_O-9AIWJT50v2g3Ei-19qH0fyPszGrim8IhAkVNXbaI1AGppOzkqEXpa07kut2m9xviGvGqj7v8Jkr83IET3_poXLDvQ==\r\n<guid ispermalink=\"false\">20200313005538en</guid>\r\n</item>\r\n```\r\n```python\r\n>>> for line in response.text.splitlines():\r\n...     if 'http://www.businesswire.com/news/home/20200313005555/en/Dynex-Capital-Schedules-Market-Update-Call/?feedref=JjAwJuNHiystnCoBq_hl-fTiTHZ_tL7veK4k7YjFBuVdpTHRh3tVfOBYRO_O-9AIWJT50v2g3Ei-19qH0fyPszGrim8IhAkVNXbaI1AGppOzkqEXpa07kut2m9xviGvGqj7v8Jkr83IET3_poXLDvQ==' in line:\r\n...         print(line)\r\n... \r\n```\r\n```xml\r\n      <link>http://www.businesswire.com/news/home/20200313005555/en/Dynex-Capital-Schedules-Market-Update-Call/?feedref=JjAwJuNHiystnCoBq_hl-fTiTHZ_tL7veK4k7YjFBuVdpTHRh3tVfOBYRO_O-9AIWJT50v2g3Ei-19qH0fyPszGrim8IhAkVNXbaI1AGppOzkqEXpa07kut2m9xviGvGqj7v8Jkr83IET3_poXLDvQ==</link>\r\n```\r\n\r\n `</link>`  is missing when parsed.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/185", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/185/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/185/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/185/events", "html_url": "https://github.com/scrapy/parsel/issues/185", "id": 568845066, "node_id": "MDU6SXNzdWU1Njg4NDUwNjY=", "number": 185, "title": "docstring of scrapy.selector.Selector.css:8:Duplicate explicit target name: \"cssselect\"", "user": {"login": "nyov", "id": 438293, "node_id": "MDQ6VXNlcjQzODI5Mw==", "avatar_url": "https://avatars0.githubusercontent.com/u/438293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nyov", "html_url": "https://github.com/nyov", "followers_url": "https://api.github.com/users/nyov/followers", "following_url": "https://api.github.com/users/nyov/following{/other_user}", "gists_url": "https://api.github.com/users/nyov/gists{/gist_id}", "starred_url": "https://api.github.com/users/nyov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nyov/subscriptions", "organizations_url": "https://api.github.com/users/nyov/orgs", "repos_url": "https://api.github.com/users/nyov/repos", "events_url": "https://api.github.com/users/nyov/events{/privacy}", "received_events_url": "https://api.github.com/users/nyov/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}, {"id": 203756376, "node_id": "MDU6TGFiZWwyMDM3NTYzNzY=", "url": "https://api.github.com/repos/scrapy/parsel/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-21T09:43:01Z", "updated_at": "2020-04-16T20:35:12Z", "closed_at": "2020-04-16T20:35:12Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The line 279\r\n\r\nhttps://github.com/scrapy/parsel/blob/332b7e87ba046c48f8b17ea3a4064015f1f58ffe/parsel/selector.py#L277-L279\r\n\r\nappears to raise a warning in the scrapy build on Python 3.7 for the docs target:\r\n\r\nhttps://travis-ci.org/scrapy/scrapy/jobs/653351006#L345-L350\r\n```\r\nWarning, treated as error:\r\n\r\n/home/travis/build/scrapy/scrapy/.tox/docs/lib/python3.7/site-packages/parsel/selector.py:docstring of scrapy.selector.Selector.css:8:Duplicate explicit target name: \"cssselect\".\r\n\r\nERROR: InvocationError for command /home/travis/build/scrapy/scrapy/.tox/docs/bin/sphinx-build -W -b html . /home/travis/build/scrapy/scrapy/.tox/docs/tmp/html (exited with code 2)\r\n\r\n___________________________________ summary ____________________________________\r\n\r\nERROR:   docs: commands failed\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/183", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/183/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/183/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/183/events", "html_url": "https://github.com/scrapy/parsel/issues/183", "id": 559179353, "node_id": "MDU6SXNzdWU1NTkxNzkzNTM=", "number": 183, "title": "Missing documention of some parsel version", "user": {"login": "rennerocha", "id": 382887, "node_id": "MDQ6VXNlcjM4Mjg4Nw==", "avatar_url": "https://avatars3.githubusercontent.com/u/382887?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rennerocha", "html_url": "https://github.com/rennerocha", "followers_url": "https://api.github.com/users/rennerocha/followers", "following_url": "https://api.github.com/users/rennerocha/following{/other_user}", "gists_url": "https://api.github.com/users/rennerocha/gists{/gist_id}", "starred_url": "https://api.github.com/users/rennerocha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rennerocha/subscriptions", "organizations_url": "https://api.github.com/users/rennerocha/orgs", "repos_url": "https://api.github.com/users/rennerocha/repos", "events_url": "https://api.github.com/users/rennerocha/events{/privacy}", "received_events_url": "https://api.github.com/users/rennerocha/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756374, "node_id": "MDU6TGFiZWwyMDM3NTYzNzQ=", "url": "https://api.github.com/repos/scrapy/parsel/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-03T16:05:17Z", "updated_at": "2020-02-11T17:09:22Z", "closed_at": "2020-02-11T17:09:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Not all versions documentation are available in parsel's readthedocs page:\r\nhttps://parsel.readthedocs.io/en/latest/\r\n\r\n`stable` page is pointing to v1.5.2, but we don't have access to previous version after v1.4.0 (v1.5.0, v1.5.1 and direct link to v.1.5.2 are missing).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/182", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/182/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/182/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/182/events", "html_url": "https://github.com/scrapy/parsel/issues/182", "id": 559159258, "node_id": "MDU6SXNzdWU1NTkxNTkyNTg=", "number": 182, "title": "Removing elements Does not work", "user": {"login": "douglasbastos", "id": 5706580, "node_id": "MDQ6VXNlcjU3MDY1ODA=", "avatar_url": "https://avatars1.githubusercontent.com/u/5706580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/douglasbastos", "html_url": "https://github.com/douglasbastos", "followers_url": "https://api.github.com/users/douglasbastos/followers", "following_url": "https://api.github.com/users/douglasbastos/following{/other_user}", "gists_url": "https://api.github.com/users/douglasbastos/gists{/gist_id}", "starred_url": "https://api.github.com/users/douglasbastos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/douglasbastos/subscriptions", "organizations_url": "https://api.github.com/users/douglasbastos/orgs", "repos_url": "https://api.github.com/users/douglasbastos/repos", "events_url": "https://api.github.com/users/douglasbastos/events{/privacy}", "received_events_url": "https://api.github.com/users/douglasbastos/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-02-03T15:33:30Z", "updated_at": "2020-02-11T17:10:00Z", "closed_at": "2020-02-11T17:10:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the documentation at [https://parsel.readthedocs.io/en/latest/usage.html#removing-elements](https://parsel.readthedocs.io/en/latest/usage.html#removing-elements)\r\n\r\nI ran the code as described in the documentation and got the error that an argument is needed in the remove call.\r\n\r\nCode in Documentation\r\n```\r\n    doc = u\"\"\"\r\n    <article>\r\n        <div class=\"row\">Content paragraph...</div>\r\n        <div class=\"row\">\r\n            <div class=\"ad\">\r\n                Ad content...\r\n                <a href=\"http://...\">Link</a>\r\n            </div>\r\n        </div>\r\n        <div class=\"row\">More content...</div>\r\n    </article>\r\n    \"\"\"\r\n    sel = Selector(text=doc)\r\n    sel.xpath('//div/text()').getall()\r\n    sel.xpath('//div[@class=\"ad\"]').remove()\r\n\r\n```\r\n\r\nError:\r\n```\r\ndef Exec(exp, global_vars, local_vars=None):\r\n  File \"<input>\", line 1, in <module>\r\nTypeError: remove() takes exactly one argument (0 given)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/179", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/179/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/179/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/179/events", "html_url": "https://github.com/scrapy/parsel/issues/179", "id": 536694448, "node_id": "MDU6SXNzdWU1MzY2OTQ0NDg=", "number": 179, "title": "remove() takes exactly one argument", "user": {"login": "budlight", "id": 329613, "node_id": "MDQ6VXNlcjMyOTYxMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/329613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/budlight", "html_url": "https://github.com/budlight", "followers_url": "https://api.github.com/users/budlight/followers", "following_url": "https://api.github.com/users/budlight/following{/other_user}", "gists_url": "https://api.github.com/users/budlight/gists{/gist_id}", "starred_url": "https://api.github.com/users/budlight/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/budlight/subscriptions", "organizations_url": "https://api.github.com/users/budlight/orgs", "repos_url": "https://api.github.com/users/budlight/repos", "events_url": "https://api.github.com/users/budlight/events{/privacy}", "received_events_url": "https://api.github.com/users/budlight/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-12T00:52:25Z", "updated_at": "2019-12-12T01:05:48Z", "closed_at": "2019-12-12T01:05:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nIn [15]: import parsel                                                                           \r\n\r\nIn [16]: parsel.__version__                                                                      \r\nOut[16]: '1.5.2'\r\n\r\nIn [17]: sel = parsel.Selector(text=u'<html><body><ul><li>1</li><li>2</li><li>3</li></ul></body><\r\n    ...: /html>')                                                                                \r\n\r\nIn [18]: sel_list = sel.css('li')                                                                \r\n\r\nIn [19]: sel_list.remove()                                                                       \r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-19-0e7a1df215d1> in <module>\r\n----> 1 sel_list.remove()\r\nTypeError: remove() takes exactly one argument (0 given)\r\n```\r\n\r\nI get this on more than one virtual env on my local machine (OSX) using python 3.7.5\r\n\r\nRunning the test framework on the same machine for py37 it passes.  \r\n\r\nI tried the exact same setup on a ec2 micro instance using ubuntu 18.04 and it fails again.  \r\n<img width=\"961\" alt=\"Screenshot 2019-12-11 16 52 01\" src=\"https://user-images.githubusercontent.com/329613/70673195-957c8980-1c36-11ea-891f-bd2fb409573f.png\">\r\n\r\nLooks like maybe this feature has been added since the last release sort of confusing since it is in the docs.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/161", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/161/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/161/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/161/events", "html_url": "https://github.com/scrapy/parsel/issues/161", "id": 509413456, "node_id": "MDU6SXNzdWU1MDk0MTM0NTY=", "number": 161, "title": "Add support for :has from the CSS4 specification", "user": {"login": "parthjoshi2007", "id": 5803732, "node_id": "MDQ6VXNlcjU4MDM3MzI=", "avatar_url": "https://avatars2.githubusercontent.com/u/5803732?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parthjoshi2007", "html_url": "https://github.com/parthjoshi2007", "followers_url": "https://api.github.com/users/parthjoshi2007/followers", "following_url": "https://api.github.com/users/parthjoshi2007/following{/other_user}", "gists_url": "https://api.github.com/users/parthjoshi2007/gists{/gist_id}", "starred_url": "https://api.github.com/users/parthjoshi2007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parthjoshi2007/subscriptions", "organizations_url": "https://api.github.com/users/parthjoshi2007/orgs", "repos_url": "https://api.github.com/users/parthjoshi2007/repos", "events_url": "https://api.github.com/users/parthjoshi2007/events{/privacy}", "received_events_url": "https://api.github.com/users/parthjoshi2007/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-19T08:05:16Z", "updated_at": "2019-10-19T08:06:59Z", "closed_at": "2019-10-19T08:06:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was trying to determine the status of support for CSS4 selectors in scrapy but could not find any information. Is there any plan to add such support? I think the CSS4 working draft has some very useful extensions that other libraries like [soupsieve](https://facelessuser.github.io/soupsieve/), the CSS selector library used by Beautiful Soup, for example, already support.\r\n\r\nIn particular I would like to make the case for `:has` and possibly also `:is`. In the course of my experiments with scraping websites (for which scrapy is truly a lifesaver), I have come across several websites where I need to, just as an example, get the `p` tag after the `p` tag containing an `image`. See for example getting the job titles out of [this](http://www.ifciventure.com/directors-information) webpage. Using `:has` this would be trivial with `p:has(strong) + p` but it is not possible currently with parsel.\r\n\r\nAnd before people jump on me saying \"Hey! Just use XPath selectors\", I know that I could use XPath. But XPath selectors have a much steeper learning curve than CSS selectors and I can train people to use CSS much more easily than XPath.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/160", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/160/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/160/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/160/events", "html_url": "https://github.com/scrapy/parsel/issues/160", "id": 509140688, "node_id": "MDU6SXNzdWU1MDkxNDA2ODg=", "number": 160, "title": "[From Scrapy]: Incorrect XPath processing", "user": {"login": "chemiron", "id": 7299611, "node_id": "MDQ6VXNlcjcyOTk2MTE=", "avatar_url": "https://avatars2.githubusercontent.com/u/7299611?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chemiron", "html_url": "https://github.com/chemiron", "followers_url": "https://api.github.com/users/chemiron/followers", "following_url": "https://api.github.com/users/chemiron/following{/other_user}", "gists_url": "https://api.github.com/users/chemiron/gists{/gist_id}", "starred_url": "https://api.github.com/users/chemiron/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chemiron/subscriptions", "organizations_url": "https://api.github.com/users/chemiron/orgs", "repos_url": "https://api.github.com/users/chemiron/repos", "events_url": "https://api.github.com/users/chemiron/events{/privacy}", "received_events_url": "https://api.github.com/users/chemiron/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756376, "node_id": "MDU6TGFiZWwyMDM3NTYzNzY=", "url": "https://api.github.com/repos/scrapy/parsel/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-10-18T15:07:44Z", "updated_at": "2019-10-25T08:43:51Z", "closed_at": "2019-10-25T08:43:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Xpath `//h1` can't extract data correctly from `https://www.imdb.com/title/tt6757474/`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/150", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/150/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/150/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/150/events", "html_url": "https://github.com/scrapy/parsel/issues/150", "id": 492119332, "node_id": "MDU6SXNzdWU0OTIxMTkzMzI=", "number": 150, "title": "Feature requirement\uff1aget the texture between two tags", "user": {"login": "Hanoso", "id": 53322506, "node_id": "MDQ6VXNlcjUzMzIyNTA2", "avatar_url": "https://avatars2.githubusercontent.com/u/53322506?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hanoso", "html_url": "https://github.com/Hanoso", "followers_url": "https://api.github.com/users/Hanoso/followers", "following_url": "https://api.github.com/users/Hanoso/following{/other_user}", "gists_url": "https://api.github.com/users/Hanoso/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hanoso/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hanoso/subscriptions", "organizations_url": "https://api.github.com/users/Hanoso/orgs", "repos_url": "https://api.github.com/users/Hanoso/repos", "events_url": "https://api.github.com/users/Hanoso/events{/privacy}", "received_events_url": "https://api.github.com/users/Hanoso/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-11T09:25:34Z", "updated_at": "2019-09-13T03:54:58Z", "closed_at": "2019-09-13T03:54:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Let's directly see the code.\r\nview-source for example:\r\n```\r\n<span id='info'> \r\n    <span class='cl'> \r\n        <span>text1</span>\r\n        <a href=\"\">text2</a>\r\n        text3\r\n    </span>\r\n    <br 1>\r\n    <span class='cl'> text4</span> text5\r\n     <br 2>\r\n    <span class='cl'> \r\n        <span>text7</span>\r\n        <a href=\"\">text8</a>\r\n        text9\r\n    </span>\r\n    <br 3>\r\n    <span class='cl'> text10</span> text11\r\n     <br 4>\r\n    <span class='cl'> text12</span> text13\r\n     <br 5>\r\n</span>\r\n```\r\nWant to get the texture between `<br 1>` and `<span id='info'>` , how can parsel do?\r\n`want the output: [text1, text2, text3]`\r\nWant to get the texture between  `<br 3>` and `<br 4>` , how can parsel do?\r\n`want the output: [text10, text11]`\r\nI use Xpath (normal) and can't get the texture i need. \r\nSo , does parsel have the feature to get it? And if no, please add the feature.\r\nThank you in advance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/147", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/147/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/147/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/147/events", "html_url": "https://github.com/scrapy/parsel/issues/147", "id": 482286391, "node_id": "MDU6SXNzdWU0ODIyODYzOTE=", "number": 147, "title": "Selector.get() cannot return content that is too deep", "user": {"login": "tobads", "id": 26805927, "node_id": "MDQ6VXNlcjI2ODA1OTI3", "avatar_url": "https://avatars0.githubusercontent.com/u/26805927?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tobads", "html_url": "https://github.com/tobads", "followers_url": "https://api.github.com/users/tobads/followers", "following_url": "https://api.github.com/users/tobads/following{/other_user}", "gists_url": "https://api.github.com/users/tobads/gists{/gist_id}", "starred_url": "https://api.github.com/users/tobads/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tobads/subscriptions", "organizations_url": "https://api.github.com/users/tobads/orgs", "repos_url": "https://api.github.com/users/tobads/repos", "events_url": "https://api.github.com/users/tobads/events{/privacy}", "received_events_url": "https://api.github.com/users/tobads/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756374, "node_id": "MDU6TGFiZWwyMDM3NTYzNzQ=", "url": "https://api.github.com/repos/scrapy/parsel/labels/bug", "name": "bug", "color": "fc2929", "default": true, "description": null}, {"id": 861833020, "node_id": "MDU6TGFiZWw4NjE4MzMwMjA=", "url": "https://api.github.com/repos/scrapy/parsel/labels/upstream%20issue", "name": "upstream issue", "color": "ae26e0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-08-15T15:48:47Z", "updated_at": "2019-09-30T15:19:58Z", "closed_at": "2019-09-30T15:19:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "`response.xpath('//*[@id=\"prdDetail\"]').extract()`\r\nThis code should extract all content under `[@id=\"prdDetail\"]`\r\nBut it only extract a part of the content, some content exists in this label, but unable to extract them.\r\n\r\n![z](https://user-images.githubusercontent.com/26805927/63107021-b8fc3400-bfb6-11e9-8b9d-ca06572a1018.jpg)\r\n\r\n> 4015pt(1)_01_shop1_154555.jpg\r\n> 4015pt(1)_02_shop1_154556.jpg\r\n> 4015pt(1)_03_shop1_154558.jpg\r\n\r\nThese content under `[@id=\"prdDetail\"]` label, but just can't get them.\r\n\r\nFiles:\r\n[z.zip](https://github.com/scrapy/scrapy/files/3506157/z.zip)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/137", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/137/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/137/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/137/events", "html_url": "https://github.com/scrapy/parsel/issues/137", "id": 418327349, "node_id": "MDU6SXNzdWU0MTgzMjczNDk=", "number": 137, "title": "Allow Parsel to remove contents matching CSS/XPath selectors", "user": {"login": "ngirard", "id": 98098, "node_id": "MDQ6VXNlcjk4MDk4", "avatar_url": "https://avatars1.githubusercontent.com/u/98098?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ngirard", "html_url": "https://github.com/ngirard", "followers_url": "https://api.github.com/users/ngirard/followers", "following_url": "https://api.github.com/users/ngirard/following{/other_user}", "gists_url": "https://api.github.com/users/ngirard/gists{/gist_id}", "starred_url": "https://api.github.com/users/ngirard/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ngirard/subscriptions", "organizations_url": "https://api.github.com/users/ngirard/orgs", "repos_url": "https://api.github.com/users/ngirard/repos", "events_url": "https://api.github.com/users/ngirard/events{/privacy}", "received_events_url": "https://api.github.com/users/ngirard/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756376, "node_id": "MDU6TGFiZWwyMDM3NTYzNzY=", "url": "https://api.github.com/repos/scrapy/parsel/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-07T14:07:06Z", "updated_at": "2019-09-13T03:56:58Z", "closed_at": "2019-09-13T03:56:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Unless I'm mistaken, Parsel currently focuses on extracting parts of a document.\r\n\r\nMy need is to remove parts matching CSS/XPath selectors.\r\n\r\nCould Parsel be provided with such a feature ?\r\n\r\nThanks !", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/134", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/134/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/134/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/134/events", "html_url": "https://github.com/scrapy/parsel/issues/134", "id": 399297407, "node_id": "MDU6SXNzdWUzOTkyOTc0MDc=", "number": 134, "title": "Huge text extraction", "user": {"login": "StasDeep", "id": 17574404, "node_id": "MDQ6VXNlcjE3NTc0NDA0", "avatar_url": "https://avatars0.githubusercontent.com/u/17574404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/StasDeep", "html_url": "https://github.com/StasDeep", "followers_url": "https://api.github.com/users/StasDeep/followers", "following_url": "https://api.github.com/users/StasDeep/following{/other_user}", "gists_url": "https://api.github.com/users/StasDeep/gists{/gist_id}", "starred_url": "https://api.github.com/users/StasDeep/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/StasDeep/subscriptions", "organizations_url": "https://api.github.com/users/StasDeep/orgs", "repos_url": "https://api.github.com/users/StasDeep/repos", "events_url": "https://api.github.com/users/StasDeep/events{/privacy}", "received_events_url": "https://api.github.com/users/StasDeep/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-01-15T11:13:29Z", "updated_at": "2019-05-09T13:26:01Z", "closed_at": "2019-05-09T13:26:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "When dealing with huge text inside, parsel seems to close tags incorrectly.\r\nHere's what I've done in console (`scrapy shell https://www.immobilienscout24.de/Suche/S-/P-46/Haus-Kauf/Bayern`):\r\n\r\n```python\r\nfrom parsel import Selector\r\ns = Selector(response.text)\r\n# Get last 100 symbols of the script tag containing 'resultListModel:'\r\ns.xpath(f'//script[contains(text(),\"resultListModel:\")]').get()[-100:]\r\n# We will get this string:\r\n# 'istings\\\\/da3d4373-9dcc-4dbe-84bb-ae31d05dd057-1263509954.jpg\\\\/ORIG\\\\/legacy_thumbnail\\\\/%WIDT</script>'\r\n\r\n# Now let's try to find the line with 'resultListModel:' string\r\nlines = response.text.split('\\n')\r\ndata_str = next(l for l in lines if 'resultListModel:' in l)\r\n# And here let's find where we can find the last 100 symbols of the script tag contents\r\n# It gave me 9993218\r\ndata_str.find('istings\\\\/da3d4373-9dcc-4dbe-84bb-ae31d05dd057-1263509954.jpg\\\\/ORIG\\\\/legacy_thumbnail\\\\/%WIDT')\r\n# Let's look at this part of the text\r\ndata_str[9993218:9993400]\r\n# We will get this string (correct):\r\n# 'istings\\\\/da3d4373-9dcc-4dbe-84bb-ae31d05dd057-1263509954.jpg\\\\/ORIG\\\\/legacy_thumbnail\\\\/%WIDTH%x%HEIGHT%\\\\/format\\\\/jpg\\\\/quality\\\\/50\"},{\"@scale\":\"WHITE_FILLING\",\"@href\":\"https:\\\\/\\\\/pictur'\r\n```\r\n\r\nThe whole line that is stored in `data_str` is inside the `<script>` tag, but somehow it turns out that it is longer than all the contents:\r\n\r\n```python\r\nIn [20]: len(s.xpath(f'//script[contains(text(),\"resultListModel:\")]').get())\r\nOut[20]: 9999243\r\n\r\nIn [21]: len(data_str)\r\nOut[21]: 12004005\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/131", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/131/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/131/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/131/events", "html_url": "https://github.com/scrapy/parsel/issues/131", "id": 392701866, "node_id": "MDU6SXNzdWUzOTI3MDE4NjY=", "number": 131, "title": "Interactive demo for `parsel` code examples", "user": {"login": "martinzugnoni", "id": 1155573, "node_id": "MDQ6VXNlcjExNTU1NzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1155573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinzugnoni", "html_url": "https://github.com/martinzugnoni", "followers_url": "https://api.github.com/users/martinzugnoni/followers", "following_url": "https://api.github.com/users/martinzugnoni/following{/other_user}", "gists_url": "https://api.github.com/users/martinzugnoni/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinzugnoni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinzugnoni/subscriptions", "organizations_url": "https://api.github.com/users/martinzugnoni/orgs", "repos_url": "https://api.github.com/users/martinzugnoni/repos", "events_url": "https://api.github.com/users/martinzugnoni/events{/privacy}", "received_events_url": "https://api.github.com/users/martinzugnoni/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}, {"id": 203756376, "node_id": "MDU6TGFiZWwyMDM3NTYzNzY=", "url": "https://api.github.com/repos/scrapy/parsel/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-19T17:20:47Z", "updated_at": "2019-10-18T18:51:31Z", "closed_at": "2019-10-18T18:51:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello folks!\r\n\r\nI've been using `parsel` lately and found it really interesting. I'm even thinking about adding it in our curriculum to teach our students at https://rmotr.com/ (co-founder and teacher here). In our DS program we have a section of data scraping (we love Scrapy) and data cleaning, and this seems to be a very convenient library for that.\r\n\r\nWhile looking at the code examples in the README file and the docs I thought it would be great to provide some interactive demo that people can use to play with the library before committing to download and install it locally.\r\n\r\n> A demo is worth a thousand words \ud83d\ude09\r\n\r\nI spent some time compiling `parsel` examples into a Jupyter Notebook file, and adapted it in a way that we can open it with a small service we have at RMOTR to launch Jupyter environments online. Note that `parsel` and `requests` (both required in examples) are already installed when the env is loaded, so people can start using it right away.\r\n\r\nThe result is what you can see in my fork of the repo (see the new \"Demo\" section):\r\nhttps://github.com/martinzugnoni/parsel\r\n\r\nDo you think that having such interactive demo would help people to know and use `parsel`?\r\nLet's use this issue as a kick off to start a discussion. Nothing here is written in stone and we can change everything as you wish.\r\n\r\nI hope you like it, and I truly appreciate any feedback.\r\n\r\nthanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/123", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/123/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/123/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/123/events", "html_url": "https://github.com/scrapy/parsel/issues/123", "id": 367091371, "node_id": "MDU6SXNzdWUzNjcwOTEzNzE=", "number": 123, "title": "Content after null byte is dropped", "user": {"login": "peonone", "id": 859333, "node_id": "MDQ6VXNlcjg1OTMzMw==", "avatar_url": "https://avatars0.githubusercontent.com/u/859333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peonone", "html_url": "https://github.com/peonone", "followers_url": "https://api.github.com/users/peonone/followers", "following_url": "https://api.github.com/users/peonone/following{/other_user}", "gists_url": "https://api.github.com/users/peonone/gists{/gist_id}", "starred_url": "https://api.github.com/users/peonone/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peonone/subscriptions", "organizations_url": "https://api.github.com/users/peonone/orgs", "repos_url": "https://api.github.com/users/peonone/repos", "events_url": "https://api.github.com/users/peonone/events{/privacy}", "received_events_url": "https://api.github.com/users/peonone/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-05T07:28:29Z", "updated_at": "2018-10-29T17:03:12Z", "closed_at": "2018-10-29T17:03:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "For some specific URL, there is a null byte (`\\x00`) inside the response body, then all content after it gets dropped in the `lxml` element tree.\r\nHow about removing the null byte before sending it to `lxml`, then we will no longer need to add this logic in every project.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/122", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/122/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/122/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/122/events", "html_url": "https://github.com/scrapy/parsel/issues/122", "id": 365216334, "node_id": "MDU6SXNzdWUzNjUyMTYzMzQ=", "number": 122, "title": "functools32 dependency?", "user": {"login": "nyov", "id": 438293, "node_id": "MDQ6VXNlcjQzODI5Mw==", "avatar_url": "https://avatars0.githubusercontent.com/u/438293?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nyov", "html_url": "https://github.com/nyov", "followers_url": "https://api.github.com/users/nyov/followers", "following_url": "https://api.github.com/users/nyov/following{/other_user}", "gists_url": "https://api.github.com/users/nyov/gists{/gist_id}", "starred_url": "https://api.github.com/users/nyov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nyov/subscriptions", "organizations_url": "https://api.github.com/users/nyov/orgs", "repos_url": "https://api.github.com/users/nyov/repos", "events_url": "https://api.github.com/users/nyov/events{/privacy}", "received_events_url": "https://api.github.com/users/nyov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-09-30T11:12:54Z", "updated_at": "2018-10-01T23:55:45Z", "closed_at": "2018-10-01T23:55:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Isn't the functools32 dependency missing as a PY2 requirement?\r\nWondering how that builds correctly.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/118", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/118/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/118/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/118/events", "html_url": "https://github.com/scrapy/parsel/issues/118", "id": 352932546, "node_id": "MDU6SXNzdWUzNTI5MzI1NDY=", "number": 118, "title": "example in \"Ad-hoc namespaces references\" doesn't work", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-08-22T12:30:29Z", "updated_at": "2018-10-10T19:49:52Z", "closed_at": "2018-10-10T19:49:51Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "atom feed mentioned there doesn't seem to be available now.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/111", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/111/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/111/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/111/events", "html_url": "https://github.com/scrapy/parsel/issues/111", "id": 318816552, "node_id": "MDU6SXNzdWUzMTg4MTY1NTI=", "number": 111, "title": "[From Scrapy] selector.css is not working", "user": {"login": "m-usman-dar", "id": 10387002, "node_id": "MDQ6VXNlcjEwMzg3MDAy", "avatar_url": "https://avatars1.githubusercontent.com/u/10387002?v=4", "gravatar_id": "", "url": "https://api.github.com/users/m-usman-dar", "html_url": "https://github.com/m-usman-dar", "followers_url": "https://api.github.com/users/m-usman-dar/followers", "following_url": "https://api.github.com/users/m-usman-dar/following{/other_user}", "gists_url": "https://api.github.com/users/m-usman-dar/gists{/gist_id}", "starred_url": "https://api.github.com/users/m-usman-dar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/m-usman-dar/subscriptions", "organizations_url": "https://api.github.com/users/m-usman-dar/orgs", "repos_url": "https://api.github.com/users/m-usman-dar/repos", "events_url": "https://api.github.com/users/m-usman-dar/events{/privacy}", "received_events_url": "https://api.github.com/users/m-usman-dar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}, {"id": 203756376, "node_id": "MDU6TGFiZWwyMDM3NTYzNzY=", "url": "https://api.github.com/repos/scrapy/parsel/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-30T08:25:28Z", "updated_at": "2019-10-16T17:04:59Z", "closed_at": "2019-10-16T17:04:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am facing problem with `selector.css`, it not selecting node when I am using `.css()`, when I used `.xpath()` it is working fine. Web page and version of parsel mentioned down.\r\n\r\nversion = `parsel==1.3.1`\r\nUrl = https://www.clasohlson.com/uk/57-cm-Kettle-Barbecue/34-9444\r\ncss_selector = `.productIdVariant `\r\n\r\nNote: It is working while using `pup`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/98", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/98/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/98/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/98/events", "html_url": "https://github.com/scrapy/parsel/issues/98", "id": 245414805, "node_id": "MDU6SXNzdWUyNDU0MTQ4MDU=", "number": 98, "title": "Caching css_to_xpath()'s recently used patterns to improve efficiency", "user": {"login": "Parth-Vader", "id": 16269320, "node_id": "MDQ6VXNlcjE2MjY5MzIw", "avatar_url": "https://avatars2.githubusercontent.com/u/16269320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Parth-Vader", "html_url": "https://github.com/Parth-Vader", "followers_url": "https://api.github.com/users/Parth-Vader/followers", "following_url": "https://api.github.com/users/Parth-Vader/following{/other_user}", "gists_url": "https://api.github.com/users/Parth-Vader/gists{/gist_id}", "starred_url": "https://api.github.com/users/Parth-Vader/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Parth-Vader/subscriptions", "organizations_url": "https://api.github.com/users/Parth-Vader/orgs", "repos_url": "https://api.github.com/users/Parth-Vader/repos", "events_url": "https://api.github.com/users/Parth-Vader/events{/privacy}", "received_events_url": "https://api.github.com/users/Parth-Vader/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2017-07-25T14:11:22Z", "updated_at": "2018-06-29T17:57:23Z", "closed_at": "2018-06-29T17:57:22Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I profiled the scrapy-bench [spider](https://github.com/scrapy/scrapy-bench/blob/master/books/books/spiders/followall.py) which uses `response.css()` for extracting information.\r\n\r\nThe profiling results are [here](http://vmprof.com/#/30d2ce4b-3d2f-492a-b470-64a5ffab41e6?id=5,0,0,0,1,0,0,0&view=flames). The function css_to_xpath() takes 5% of the total time. \r\n\r\nWhen `response.xpath()`([profiling result](http://vmprof.com/#/393e2093-8c16-4373-b006-e14aeb7933c9?id=6,0,0,1,0,0,0&view=flames)) was used, the items extracted per second (benchmark result) was higher. \r\n\r\nHence, I'm proposing caching for the recently used patterns, so that the function takes lesser time.\r\nI'm working on a prototype for the same and will add the results for it too.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/94", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/94/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/94/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/94/events", "html_url": "https://github.com/scrapy/parsel/issues/94", "id": 239543448, "node_id": "MDU6SXNzdWUyMzk1NDM0NDg=", "number": 94, "title": "parsel-cli - parsel as a cli application", "user": {"login": "Granitosaurus", "id": 5476164, "node_id": "MDQ6VXNlcjU0NzYxNjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5476164?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Granitosaurus", "html_url": "https://github.com/Granitosaurus", "followers_url": "https://api.github.com/users/Granitosaurus/followers", "following_url": "https://api.github.com/users/Granitosaurus/following{/other_user}", "gists_url": "https://api.github.com/users/Granitosaurus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Granitosaurus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Granitosaurus/subscriptions", "organizations_url": "https://api.github.com/users/Granitosaurus/orgs", "repos_url": "https://api.github.com/users/Granitosaurus/repos", "events_url": "https://api.github.com/users/Granitosaurus/events{/privacy}", "received_events_url": "https://api.github.com/users/Granitosaurus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}, {"id": 203756376, "node_id": "MDU6TGFiZWwyMDM3NTYzNzY=", "url": "https://api.github.com/repos/scrapy/parsel/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-29T16:44:39Z", "updated_at": "2019-09-25T11:58:03Z", "closed_at": "2019-09-25T11:58:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've been working small cli parsel wrapper for iterpreting css and xpath selectiors (inspired by `scrapy shell`).\r\n\r\nhttps://github.com/granitosaurus/parsel-cli\r\n\r\nIt puts you straight into css or xpath interpreter mode (or embed python shell) and evaluates input css/xpath selectors using parsel.\r\n\r\nI think it's better off as standalone tool but maybe it's worth mentioning somewhere in readme :)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/91", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/91/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/91/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/91/events", "html_url": "https://github.com/scrapy/parsel/issues/91", "id": 234162292, "node_id": "MDU6SXNzdWUyMzQxNjIyOTI=", "number": 91, "title": "Misleading \"data=\" in Selector representation", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-07T10:23:14Z", "updated_at": "2019-07-11T17:37:17Z", "closed_at": "2019-07-11T17:37:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Motivation: https://stackoverflow.com/questions/44407581/python-scrapy-output-is-cut-off-hence-wount-let-me-correctly-build-queries\r\n\r\nWith\r\n```\r\n<Selector xpath='//div[@id=\"all_game_info\"]' data=u'<div id=\"all_game_info\" class=\"table_wrapper columns'>\r\n```\r\nthe user thought that the selector had only extracted `u'<div id=\"all_game_info\" class=\"table_wrapper columns'`\r\n\r\nSuggestions:\r\n\r\n* change `data=` to something like `data-preview=`\r\n* or add `...` at the end, indicate the length of extracted data maybe", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/84", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/84/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/84/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/84/events", "html_url": "https://github.com/scrapy/parsel/issues/84", "id": 227988241, "node_id": "MDU6SXNzdWUyMjc5ODgyNDE=", "number": 84, "title": "[idea] Flexible `replace_entities` on `Selector.re` and `Selector.extract`", "user": {"login": "starrify", "id": 388828, "node_id": "MDQ6VXNlcjM4ODgyOA==", "avatar_url": "https://avatars0.githubusercontent.com/u/388828?v=4", "gravatar_id": "", "url": "https://api.github.com/users/starrify", "html_url": "https://github.com/starrify", "followers_url": "https://api.github.com/users/starrify/followers", "following_url": "https://api.github.com/users/starrify/following{/other_user}", "gists_url": "https://api.github.com/users/starrify/gists{/gist_id}", "starred_url": "https://api.github.com/users/starrify/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/starrify/subscriptions", "organizations_url": "https://api.github.com/users/starrify/orgs", "repos_url": "https://api.github.com/users/starrify/repos", "events_url": "https://api.github.com/users/starrify/events{/privacy}", "received_events_url": "https://api.github.com/users/starrify/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/parsel/milestones/2", "html_url": "https://github.com/scrapy/parsel/milestone/2", "labels_url": "https://api.github.com/repos/scrapy/parsel/milestones/2/labels", "id": 2527234, "node_id": "MDk6TWlsZXN0b25lMjUyNzIzNA==", "number": 2, "title": "v1.2", "description": null, "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 12, "state": "open", "created_at": "2017-05-17T15:58:31Z", "updated_at": "2017-05-17T18:46:22Z", "due_on": null, "closed_at": null}, "comments": 1, "created_at": "2017-05-11T13:18:15Z", "updated_at": "2017-05-17T17:43:31Z", "closed_at": "2017-05-17T17:43:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "As of the latest commit (2c87fe4b), `Selector.extract` does not replace entities, while `Selector.re` does:\r\n```python\r\n>>> import parsel\r\n>>> sel = parsel.Selector(text=u'<script>{\"foo\":\"bar&quot;baz&quot;\"}</script>')\r\n>>> sel.css('script::text').extract_first()\r\nu'{\"foo\":\"bar&quot;baz&quot;\"}'\r\n>>> sel.css('script::text').re_first('(.*)')\r\nu'{\"foo\":\"bar\"baz\"\"}'\r\n```\r\n\r\nThe related code is at [line 72 of parsel/utils.py](https://github.com/scrapy/parsel/blob/2c87fe4b19fdaea99636ff2b23597325fcb555a5/parsel/utils.py#L72)\r\n\r\nHowever, in some specific cases (e.g. the example above), we may find it useful if:\r\n- [`Selector.re`](https://github.com/scrapy/parsel/blob/2c87fe4b19fdaea99636ff2b23597325fcb555a/parsel/selector.py#L241) does not replace entities.\r\n- [`Selector.extract`](https://github.com/scrapy/parsel/blob/2c87fe4b19fdaea99636ff2b23597325fcb555a/parsel/selector.py#L251) does replace entities.\r\n\r\nWhat do you think there're optional arguments to be added to both functions controlling behavior of `replace_entities`?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/65", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/65/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/65/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/65/events", "html_url": "https://github.com/scrapy/parsel/issues/65", "id": 189443494, "node_id": "MDU6SXNzdWUxODk0NDM0OTQ=", "number": 65, "title": "Release Parsel 1.1.0", "user": {"login": "eliasdorneles", "id": 37565, "node_id": "MDQ6VXNlcjM3NTY1", "avatar_url": "https://avatars0.githubusercontent.com/u/37565?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eliasdorneles", "html_url": "https://github.com/eliasdorneles", "followers_url": "https://api.github.com/users/eliasdorneles/followers", "following_url": "https://api.github.com/users/eliasdorneles/following{/other_user}", "gists_url": "https://api.github.com/users/eliasdorneles/gists{/gist_id}", "starred_url": "https://api.github.com/users/eliasdorneles/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eliasdorneles/subscriptions", "organizations_url": "https://api.github.com/users/eliasdorneles/orgs", "repos_url": "https://api.github.com/users/eliasdorneles/repos", "events_url": "https://api.github.com/users/eliasdorneles/events{/privacy}", "received_events_url": "https://api.github.com/users/eliasdorneles/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/parsel/milestones/1", "html_url": "https://github.com/scrapy/parsel/milestone/1", "labels_url": "https://api.github.com/repos/scrapy/parsel/milestones/1/labels", "id": 1869771, "node_id": "MDk6TWlsZXN0b25lMTg2OTc3MQ==", "number": 1, "title": "v1.1", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "open", "created_at": "2016-07-07T11:39:41Z", "updated_at": "2016-11-22T13:34:58Z", "due_on": null, "closed_at": null}, "comments": 7, "created_at": "2016-11-15T16:41:52Z", "updated_at": "2016-11-22T13:34:58Z", "closed_at": "2016-11-22T13:34:58Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I think it's time to do a release. :)\r\n\r\nThings to do before releasing:\r\n\r\n* [x] document css2xpath\r\n* [x] document using named variables\r\n* [x] update NEWS file\r\n* [x] Document CSS selectors extensions", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/62", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/62/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/62/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/62/events", "html_url": "https://github.com/scrapy/parsel/issues/62", "id": 183877879, "node_id": "MDU6SXNzdWUxODM4Nzc4Nzk=", "number": 62, "title": "I can not get blank text in td tag.", "user": {"login": "pc10201", "id": 8475089, "node_id": "MDQ6VXNlcjg0NzUwODk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8475089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pc10201", "html_url": "https://github.com/pc10201", "followers_url": "https://api.github.com/users/pc10201/followers", "following_url": "https://api.github.com/users/pc10201/following{/other_user}", "gists_url": "https://api.github.com/users/pc10201/gists{/gist_id}", "starred_url": "https://api.github.com/users/pc10201/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pc10201/subscriptions", "organizations_url": "https://api.github.com/users/pc10201/orgs", "repos_url": "https://api.github.com/users/pc10201/repos", "events_url": "https://api.github.com/users/pc10201/events{/privacy}", "received_events_url": "https://api.github.com/users/pc10201/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756378, "node_id": "MDU6TGFiZWwyMDM3NTYzNzg=", "url": "https://api.github.com/repos/scrapy/parsel/labels/invalid", "name": "invalid", "color": "e6e6e6", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-10-19T06:40:37Z", "updated_at": "2018-12-19T08:24:47Z", "closed_at": "2016-10-19T09:20:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\n# coding=utf-8\n\nfrom parsel import Selector\n\nhtml = u'''\n                        <table class=\"table table-bordered table-hover table-condensed\">\n                            <thead>\n                            <tr>\n                                <th>#</th>\n                                <th>code</th>\n                                <th>vendor</th>\n                                <th>name</th>\n                                <th>num</th>\n                            </tr>\n                            </thead>\n                            <tbody>\n                                <tr>\n                                    <th scope=\"row\">1750</th>\n                                    <td><a href=\"/exam/000-643\">000-643</a></td>\n                                    <td>IBM</td>\n                                    <td></td>\n                                    <td>45</td>\n                                </tr>\n                                </tbody>\n'''\n\nsel = Selector(text=html)\nprint sel.xpath('//tbody/tr//td/text()').extract()\nprint sel.xpath('//tbody/tr//td//text()').extract()\n```\n\noutput\n```[u'IBM', u'45']\n\n[u'000-643', u'IBM', u'45']```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/59", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/59/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/59/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/59/events", "html_url": "https://github.com/scrapy/parsel/issues/59", "id": 175515016, "node_id": "MDU6SXNzdWUxNzU1MTUwMTY=", "number": 59, "title": "SelectorList.css argument is named 'xpath'", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756377, "node_id": "MDU6TGFiZWwyMDM3NTYzNzc=", "url": "https://api.github.com/repos/scrapy/parsel/labels/help%20wanted", "name": "help wanted", "color": "159818", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/parsel/milestones/1", "html_url": "https://github.com/scrapy/parsel/milestone/1", "labels_url": "https://api.github.com/repos/scrapy/parsel/milestones/1/labels", "id": 1869771, "node_id": "MDk6TWlsZXN0b25lMTg2OTc3MQ==", "number": 1, "title": "v1.1", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "open", "created_at": "2016-07-07T11:39:41Z", "updated_at": "2016-11-22T13:34:58Z", "due_on": null, "closed_at": null}, "comments": 3, "created_at": "2016-09-07T14:20:07Z", "updated_at": "2016-11-18T15:13:09Z", "closed_at": "2016-11-18T15:13:09Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "What to you think about renaming SelectorList.css argument to 'query'? It would be a backwards incompatible change, but I doubt there is a lot of code which uses keyword argument for sel.css method.\n\nThere is a similar problem in Scrapy.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/56", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/56/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/56/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/56/events", "html_url": "https://github.com/scrapy/parsel/issues/56", "id": 173681694, "node_id": "MDU6SXNzdWUxNzM2ODE2OTQ=", "number": 56, "title": "LookupError: unknown encoding: 'unicode'", "user": {"login": "CABowers", "id": 14188483, "node_id": "MDQ6VXNlcjE0MTg4NDgz", "avatar_url": "https://avatars0.githubusercontent.com/u/14188483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CABowers", "html_url": "https://github.com/CABowers", "followers_url": "https://api.github.com/users/CABowers/followers", "following_url": "https://api.github.com/users/CABowers/following{/other_user}", "gists_url": "https://api.github.com/users/CABowers/gists{/gist_id}", "starred_url": "https://api.github.com/users/CABowers/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CABowers/subscriptions", "organizations_url": "https://api.github.com/users/CABowers/orgs", "repos_url": "https://api.github.com/users/CABowers/repos", "events_url": "https://api.github.com/users/CABowers/events{/privacy}", "received_events_url": "https://api.github.com/users/CABowers/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-08-29T01:49:13Z", "updated_at": "2016-08-29T13:06:11Z", "closed_at": "2016-08-29T01:54:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "When running on windows the error \"LookupError: unknown encoding: 'unicode'\" is thrown on line 226 of selector.py. This happened when scrapping from a webpage.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/53", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/53/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/53/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/53/events", "html_url": "https://github.com/scrapy/parsel/issues/53", "id": 170175405, "node_id": "MDU6SXNzdWUxNzAxNzU0MDU=", "number": 53, "title": "Get lxml node (HtmlElement)", "user": {"login": "mega7star", "id": 1462355, "node_id": "MDQ6VXNlcjE0NjIzNTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1462355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mega7star", "html_url": "https://github.com/mega7star", "followers_url": "https://api.github.com/users/mega7star/followers", "following_url": "https://api.github.com/users/mega7star/following{/other_user}", "gists_url": "https://api.github.com/users/mega7star/gists{/gist_id}", "starred_url": "https://api.github.com/users/mega7star/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mega7star/subscriptions", "organizations_url": "https://api.github.com/users/mega7star/orgs", "repos_url": "https://api.github.com/users/mega7star/repos", "events_url": "https://api.github.com/users/mega7star/events{/privacy}", "received_events_url": "https://api.github.com/users/mega7star/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2016-08-09T14:07:08Z", "updated_at": "2016-11-21T16:59:36Z", "closed_at": "2016-11-21T16:59:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is it possible to get `<class 'lxml.html.HtmlElement'>`. For example:\n\n``` python\nfrom parsel import Selector\nsel = Selector(\"<html><body> <div><h1>Header1</h1><p>any text..</p></div> </body></html>\")\nh1 = sel.xpath(\".//div/h1\").extract_first()\ntype(h1) # Why str? How get lxml.html.HtmlElement?\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/52", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/52/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/52/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/52/events", "html_url": "https://github.com/scrapy/parsel/issues/52", "id": 169890448, "node_id": "MDU6SXNzdWUxNjk4OTA0NDg=", "number": 52, "title": "Implement re_first for Selector", "user": {"login": "Tethik", "id": 298627, "node_id": "MDQ6VXNlcjI5ODYyNw==", "avatar_url": "https://avatars1.githubusercontent.com/u/298627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tethik", "html_url": "https://github.com/Tethik", "followers_url": "https://api.github.com/users/Tethik/followers", "following_url": "https://api.github.com/users/Tethik/following{/other_user}", "gists_url": "https://api.github.com/users/Tethik/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tethik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tethik/subscriptions", "organizations_url": "https://api.github.com/users/Tethik/orgs", "repos_url": "https://api.github.com/users/Tethik/repos", "events_url": "https://api.github.com/users/Tethik/events{/privacy}", "received_events_url": "https://api.github.com/users/Tethik/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-08-08T10:24:46Z", "updated_at": "2017-05-17T11:21:10Z", "closed_at": "2017-05-17T11:21:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Copied from https://github.com/scrapy/scrapy/issues/1907\n\nCurrently only SelectorList supports the re_first shortcut method. It would be useful to have this method in Selector too.\n\n``` python\nfrom scrapy.selector import Selector\n>>> body = '<html><body><span>good</span></body></html>'\n>>> Selector(text=body).re_first\nTraceback (most recent call last):\n  File \"<console>\", line 1, in <module>\nAttributeError: 'Selector' object has no attribute 're_first'\n```\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/46", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/46/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/46/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/46/events", "html_url": "https://github.com/scrapy/parsel/issues/46", "id": 167401097, "node_id": "MDU6SXNzdWUxNjc0MDEwOTc=", "number": 46, "title": "Missing copyright/license info/file", "user": {"login": "ghantoos", "id": 477561, "node_id": "MDQ6VXNlcjQ3NzU2MQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/477561?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghantoos", "html_url": "https://github.com/ghantoos", "followers_url": "https://api.github.com/users/ghantoos/followers", "following_url": "https://api.github.com/users/ghantoos/following{/other_user}", "gists_url": "https://api.github.com/users/ghantoos/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghantoos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghantoos/subscriptions", "organizations_url": "https://api.github.com/users/ghantoos/orgs", "repos_url": "https://api.github.com/users/ghantoos/repos", "events_url": "https://api.github.com/users/ghantoos/events{/privacy}", "received_events_url": "https://api.github.com/users/ghantoos/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-07-25T15:54:16Z", "updated_at": "2016-07-25T17:16:33Z", "closed_at": "2016-07-25T17:16:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\n\nI am working on packaging parsel for Debian. I got from the setup.py that it had a BSD license, but I am not sure which BSD license. The other scrapy related projects seem to have the BSD 3-clauses license.\n\nCould you confirm this or add the license file to the parsel repo?\n\nThanks in advance!\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/43", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/43/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/43/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/43/events", "html_url": "https://github.com/scrapy/parsel/issues/43", "id": 162747585, "node_id": "MDU6SXNzdWUxNjI3NDc1ODU=", "number": 43, "title": "Document behavior of HTML comments inside script tags", "user": {"login": "eliasdorneles", "id": 37565, "node_id": "MDQ6VXNlcjM3NTY1", "avatar_url": "https://avatars0.githubusercontent.com/u/37565?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eliasdorneles", "html_url": "https://github.com/eliasdorneles", "followers_url": "https://api.github.com/users/eliasdorneles/followers", "following_url": "https://api.github.com/users/eliasdorneles/following{/other_user}", "gists_url": "https://api.github.com/users/eliasdorneles/gists{/gist_id}", "starred_url": "https://api.github.com/users/eliasdorneles/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eliasdorneles/subscriptions", "organizations_url": "https://api.github.com/users/eliasdorneles/orgs", "repos_url": "https://api.github.com/users/eliasdorneles/repos", "events_url": "https://api.github.com/users/eliasdorneles/events{/privacy}", "received_events_url": "https://api.github.com/users/eliasdorneles/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}, {"id": 203756376, "node_id": "MDU6TGFiZWwyMDM3NTYzNzY=", "url": "https://api.github.com/repos/scrapy/parsel/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-06-28T17:58:14Z", "updated_at": "2019-10-02T10:15:40Z", "closed_at": "2019-10-02T10:15:40Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently, the parser ignores HTML comments inside script tags, treating them as part of the text element:\n\n```\n>>> import parsel\n>>> parsel.__version__\n'1.0.2'\n>>>\n>>> # comments inside random nodes...\n>>> node_with_comments = parsel.Selector(u'<node><!-- comment -->text here</node>')\n>>> node_with_comments.xpath('//comment()')\n[<Selector xpath='//comment()' data=u'<!-- comment -->'>]\n>>> node_with_comments.xpath('//text()')\n[<Selector xpath='//text()' data=u'text here'>]\n>>> # okay, looks good\n>>>\n>>> # now, with comments inside a script tag:\n>>> script_with_comments = parsel.Selector(u'<script><!-- comment -->alert(\"hello\")</script>')\n>>> script_with_comments.xpath('//comment()')\n[]\n>>> # oops, can't find the comments!\n>>> script_with_comments.xpath('//text()')\n[<Selector xpath='//text()' data=u'<!-- comment -->alert(\"hello\")'>]\n```\n\nLooks like it ignore comments inside the `<script>` tag, considering it all part of the text.\n\nThis is a problem because people are unable to easily strip HTML comments from the JavaScript code (which is often fed to a JS parser, like js2xml).\n\nChanging this would break backwards compatibility, but this looks like a bug to me.\n\nThoughts? Concerns?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/40", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/40/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/40/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/40/events", "html_url": "https://github.com/scrapy/parsel/issues/40", "id": 160564698, "node_id": "MDU6SXNzdWUxNjA1NjQ2OTg=", "number": 40, "title": "Selector.root is not an instance of lxml.html.HtmlElement even if parser is html", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2016-06-16T02:29:49Z", "updated_at": "2016-11-21T16:58:12Z", "closed_at": "2016-11-21T16:58:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I'm trying to use lxml.Cleaner without parsing response multiple times:\n\n``` py\nfrom lxml.html.clean import Cleaner\ncleaner = Cleaner()\nsel = parsel.Selector(\"<html><body><style>.p {width:10px}</style>hello</body></html>\"\ncleaner.clean_html(sel.root)\n```\n\nThis doesn't work because Cleaner needs a `lxml.html.HtmlElement` instance, while Selector.root is always `lxml.etree._Element`, so it doesn't have a required `.rewrite_links` method.\n\nWhy is lxml.etree.HtmlParser [used](https://github.com/scrapy/parsel/blob/fde9087b3bbc8adf54ad25b9ea68874054adaec2/parsel/selector.py#L20) for html and not lxml.html.HtmlParser?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/36", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/36/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/36/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/36/events", "html_url": "https://github.com/scrapy/parsel/issues/36", "id": 138877299, "node_id": "MDU6SXNzdWUxMzg4NzcyOTk=", "number": 36, "title": " Is it possible to modify the response content through Scrapy Selector? ", "user": {"login": "seaguest", "id": 498853, "node_id": "MDQ6VXNlcjQ5ODg1Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/498853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seaguest", "html_url": "https://github.com/seaguest", "followers_url": "https://api.github.com/users/seaguest/followers", "following_url": "https://api.github.com/users/seaguest/following{/other_user}", "gists_url": "https://api.github.com/users/seaguest/gists{/gist_id}", "starred_url": "https://api.github.com/users/seaguest/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seaguest/subscriptions", "organizations_url": "https://api.github.com/users/seaguest/orgs", "repos_url": "https://api.github.com/users/seaguest/repos", "events_url": "https://api.github.com/users/seaguest/events{/privacy}", "received_events_url": "https://api.github.com/users/seaguest/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-03-07T03:42:14Z", "updated_at": "2016-04-26T15:07:41Z", "closed_at": "2016-04-26T14:30:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using Scrapy to deep copy some content on one page, to crawl the content and download the images in that content and update the image original value accordingly.\n\nFor example I have:\n\n```\n<div class=\"A\">\n    <img original=\"example1.com/1/1.png\"></img>\n</div>\n```\n\nI need to download the image and update the new image original value\uff08for example to mysite.com/1/1.png\uff09, then save the content.\n\nwhat I will have finally is:\n\n```\n<div class=\"A\">\n    <img original=\"mysite.com/1/1.png\"></img>\n</div>\n```\n\nand image on my disk.\n\nIs it possible to modify the value through Selector?\n\nOr must I download the image first and update the \"original\" value separately? any better solution?\n\nAnother use case:\nIn some pages, some content are hidden by some CSS setting ( style=\"display:none\"),  or we want to do some preprocessing for some content, we will need to inspect the content and update it. \n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/35", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/35/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/35/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/35/events", "html_url": "https://github.com/scrapy/parsel/issues/35", "id": 138165783, "node_id": "MDU6SXNzdWUxMzgxNjU3ODM=", "number": 35, "title": "travis tests are failing on pypy", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-03-03T12:31:00Z", "updated_at": "2016-07-06T11:52:37Z", "closed_at": "2016-07-06T11:52:37Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "According to http://morepypy.blogspot.ru/2016/02/c-api-support-update.html lxml never really worked with pypy, but they should become compatible with pypy 4.1 and next lxml release. I think we should disable pypy tests for now.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/31", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/31/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/31/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/31/events", "html_url": "https://github.com/scrapy/parsel/issues/31", "id": 136671475, "node_id": "MDU6SXNzdWUxMzY2NzE0NzU=", "number": 31, "title": "Wrong docstring for Selector .extract()", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-02-26T11:30:18Z", "updated_at": "2016-03-22T11:35:34Z", "closed_at": "2016-03-22T11:35:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "See http://stackoverflow.com/a/35649597/\n\n[Docstring for `Selector` `.extract()` method](https://github.com/scrapy/parsel/blob/ae562c9a56450385cc50e8d28befcca13954b977/parsel/selector.py#L209) is wrong:\n\n```\n        \"\"\"\n        Serialize and return the matched nodes as a list of unicode strings.\n        Percent encoded content is unquoted.\n        \"\"\"\n```\n\nIt returns a single string, not a list of strings.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/30", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/30/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/30/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/30/events", "html_url": "https://github.com/scrapy/parsel/issues/30", "id": 136664046, "node_id": "MDU6SXNzdWUxMzY2NjQwNDY=", "number": 30, "title": "DOC Missing docs/docstrings for .re_first() and .extract_first()", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2016-02-26T10:58:20Z", "updated_at": "2016-03-22T11:36:05Z", "closed_at": "2016-03-22T11:36:05Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Triggered by this StackOverflow question: http://stackoverflow.com/q/35649461\n\nThe only place where `.extract_first()` purpose and behavior is mentioned is in the [\"Getting started\"](https://parsel.readthedocs.org/en/v1.0.1/usage.html#getting-started)\n\n`.re_first()` and `.extract_first()` methods have no docstring and do not appear in the [API reference](https://parsel.readthedocs.org/en/v1.0.1/usage.html#selectorlist-objects), only in the [`parsel.selector` module docs](https://parsel.readthedocs.org/en/v1.0.1/parsel.html#parsel.selector.SelectorList)\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/29", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/29/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/29/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/29/events", "html_url": "https://github.com/scrapy/parsel/issues/29", "id": 134615168, "node_id": "MDU6SXNzdWUxMzQ2MTUxNjg=", "number": 29, "title": "Support Zorba as an alternative XML/HTML processing engine", "user": {"login": "gerosalesc", "id": 6961010, "node_id": "MDQ6VXNlcjY5NjEwMTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/6961010?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gerosalesc", "html_url": "https://github.com/gerosalesc", "followers_url": "https://api.github.com/users/gerosalesc/followers", "following_url": "https://api.github.com/users/gerosalesc/following{/other_user}", "gists_url": "https://api.github.com/users/gerosalesc/gists{/gist_id}", "starred_url": "https://api.github.com/users/gerosalesc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gerosalesc/subscriptions", "organizations_url": "https://api.github.com/users/gerosalesc/orgs", "repos_url": "https://api.github.com/users/gerosalesc/repos", "events_url": "https://api.github.com/users/gerosalesc/events{/privacy}", "received_events_url": "https://api.github.com/users/gerosalesc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 203756376, "node_id": "MDU6TGFiZWwyMDM3NTYzNzY=", "url": "https://api.github.com/repos/scrapy/parsel/labels/enhancement", "name": "enhancement", "color": "84b6eb", "default": true, "description": null}, {"id": 1575809302, "node_id": "MDU6TGFiZWwxNTc1ODA5MzAy", "url": "https://api.github.com/repos/scrapy/parsel/labels/needs%20more%20info", "name": "needs more info", "color": "fef2c0", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-02-18T15:42:34Z", "updated_at": "2019-10-29T11:47:36Z", "closed_at": "2019-10-29T11:47:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "This has been troubling me for some time now but I would like this project to support a more powerful XML/HTML processing engine as an alternative to Lxml. The only contender for lxml in Python: [Zorba](https://github.com/28msec/zorba). But why?\n- Zorba supports [XQuery technology as well as JSONiq](http://zorba.28.io/documentation/latest/zorba/xml_json/).\n- Zorba has [Python bindings](http://docs.zorba.io.s3-website-us-east-1.amazonaws.com/3.0.0/python/). I know they are not precisely the best bindings ever but at least they exist.\n- I think XPath 1.0 is very limited for more complex structures.\n- Lxml extensions are ok but not that much when compared to XQuery capabilities by default.\n- Zorba can be hosted as a [service](https://github.com/28msec/28/blob/master/getting-started.md).\n\nIdeally, we should be able to use selectors with Zorba in this way:\n\n`Selector(response=response).xquery('...').extract()`\nor \n`response.selector.xquery('...').extract()`\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/28", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/28/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/28/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/28/events", "html_url": "https://github.com/scrapy/parsel/issues/28", "id": 132365751, "node_id": "MDU6SXNzdWUxMzIzNjU3NTE=", "number": 28, "title": "Document CSS selectors extensions", "user": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 323513902, "node_id": "MDU6TGFiZWwzMjM1MTM5MDI=", "url": "https://api.github.com/repos/scrapy/parsel/labels/docs", "name": "docs", "color": "bfdadc", "default": false, "description": ""}, {"id": 203756377, "node_id": "MDU6TGFiZWwyMDM3NTYzNzc=", "url": "https://api.github.com/repos/scrapy/parsel/labels/help%20wanted", "name": "help wanted", "color": "159818", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/scrapy/parsel/milestones/1", "html_url": "https://github.com/scrapy/parsel/milestone/1", "labels_url": "https://api.github.com/repos/scrapy/parsel/milestones/1/labels", "id": 1869771, "node_id": "MDk6TWlsZXN0b25lMTg2OTc3MQ==", "number": 1, "title": "v1.1", "description": "", "creator": {"login": "redapple", "id": 886296, "node_id": "MDQ6VXNlcjg4NjI5Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/886296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redapple", "html_url": "https://github.com/redapple", "followers_url": "https://api.github.com/users/redapple/followers", "following_url": "https://api.github.com/users/redapple/following{/other_user}", "gists_url": "https://api.github.com/users/redapple/gists{/gist_id}", "starred_url": "https://api.github.com/users/redapple/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redapple/subscriptions", "organizations_url": "https://api.github.com/users/redapple/orgs", "repos_url": "https://api.github.com/users/redapple/repos", "events_url": "https://api.github.com/users/redapple/events{/privacy}", "received_events_url": "https://api.github.com/users/redapple/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 10, "state": "open", "created_at": "2016-07-07T11:39:41Z", "updated_at": "2016-11-22T13:34:58Z", "due_on": null, "closed_at": null}, "comments": 0, "created_at": "2016-02-09T09:10:52Z", "updated_at": "2016-11-21T11:06:17Z", "closed_at": "2016-11-21T11:06:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "As requested in https://stackoverflow.com/questions/21181628/python-scrapy-get-href-using-css-selector#comment46652785_21182445\n\n> Where can I see all Scrapy's CSS extensions? Can't find it in the docs. \u2013 Javier Ayres Mar 23 '15\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/23", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/23/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/23/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/23/events", "html_url": "https://github.com/scrapy/parsel/issues/23", "id": 114836575, "node_id": "MDU6SXNzdWUxMTQ4MzY1NzU=", "number": 23, "title": "removing text when `<` is inside", "user": {"login": "eLRuLL", "id": 1459486, "node_id": "MDQ6VXNlcjE0NTk0ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1459486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eLRuLL", "html_url": "https://github.com/eLRuLL", "followers_url": "https://api.github.com/users/eLRuLL/followers", "following_url": "https://api.github.com/users/eLRuLL/following{/other_user}", "gists_url": "https://api.github.com/users/eLRuLL/gists{/gist_id}", "starred_url": "https://api.github.com/users/eLRuLL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eLRuLL/subscriptions", "organizations_url": "https://api.github.com/users/eLRuLL/orgs", "repos_url": "https://api.github.com/users/eLRuLL/repos", "events_url": "https://api.github.com/users/eLRuLL/events{/privacy}", "received_events_url": "https://api.github.com/users/eLRuLL/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-11-03T15:05:28Z", "updated_at": "2016-05-02T12:38:07Z", "closed_at": "2016-01-27T17:08:48Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "```\n>> s = Selector(text=u'<html><body>Color: White, Size:Free Size, With the body: Braided, Buckle: Automatic Deduction, With the body width: section (<2cm), Belt Length: 93cm</body></html>')\n\n>> s.extract()\nu'<html><body>Color: White, Size:Free Size, With the body: Braided, Buckle: Automatic Deduction, With the body width: section (</body></html>'\n```\n\nthe text after `<` is removed\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/18", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/18/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/18/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/18/events", "html_url": "https://github.com/scrapy/parsel/issues/18", "id": 102614781, "node_id": "MDU6SXNzdWUxMDI2MTQ3ODE=", "number": 18, "title": "v1.0 can't be pre-alpha", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-08-23T12:39:24Z", "updated_at": "2015-08-24T20:20:38Z", "closed_at": "2015-08-24T20:20:38Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I think we should update classifiers in https://github.com/scrapy/parsel/blob/master/setup.py\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/16", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/16/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/16/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/16/events", "html_url": "https://github.com/scrapy/parsel/issues/16", "id": 101011730, "node_id": "MDU6SXNzdWUxMDEwMTE3MzA=", "number": 16, "title": "Move API docs to autodocs/docstrings", "user": {"login": "eliasdorneles", "id": 37565, "node_id": "MDQ6VXNlcjM3NTY1", "avatar_url": "https://avatars0.githubusercontent.com/u/37565?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eliasdorneles", "html_url": "https://github.com/eliasdorneles", "followers_url": "https://api.github.com/users/eliasdorneles/followers", "following_url": "https://api.github.com/users/eliasdorneles/following{/other_user}", "gists_url": "https://api.github.com/users/eliasdorneles/gists{/gist_id}", "starred_url": "https://api.github.com/users/eliasdorneles/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eliasdorneles/subscriptions", "organizations_url": "https://api.github.com/users/eliasdorneles/orgs", "repos_url": "https://api.github.com/users/eliasdorneles/repos", "events_url": "https://api.github.com/users/eliasdorneles/events{/privacy}", "received_events_url": "https://api.github.com/users/eliasdorneles/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2015-08-14T13:35:45Z", "updated_at": "2015-08-21T18:55:43Z", "closed_at": "2015-08-21T18:55:43Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently the API reference is listed manually in `usage.rst`, this makes it too easy to have it out of sync with the code (it is out of sync as of this moment, see: http://parsel.readthedocs.org/en/latest/usage.html#parsel.selector.SelectorList.__nonzero__).\n\nLet's move it to docstrings and use autodocs.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/13", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/13/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/13/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/13/events", "html_url": "https://github.com/scrapy/parsel/issues/13", "id": 100686360, "node_id": "MDU6SXNzdWUxMDA2ODYzNjA=", "number": 13, "title": "custom xpath support", "user": {"login": "eLRuLL", "id": 1459486, "node_id": "MDQ6VXNlcjE0NTk0ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1459486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eLRuLL", "html_url": "https://github.com/eLRuLL", "followers_url": "https://api.github.com/users/eLRuLL/followers", "following_url": "https://api.github.com/users/eLRuLL/following{/other_user}", "gists_url": "https://api.github.com/users/eLRuLL/gists{/gist_id}", "starred_url": "https://api.github.com/users/eLRuLL/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eLRuLL/subscriptions", "organizations_url": "https://api.github.com/users/eLRuLL/orgs", "repos_url": "https://api.github.com/users/eLRuLL/repos", "events_url": "https://api.github.com/users/eLRuLL/events{/privacy}", "received_events_url": "https://api.github.com/users/eLRuLL/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2015-08-13T04:16:08Z", "updated_at": "2018-06-29T17:54:16Z", "closed_at": "2018-06-29T17:54:16Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "custom xpath functions could be added here? like: \n\n``` python\n# Original Source: https://gist.github.com/shirk3y/458224083ce5464627bc\nfrom lxml import etree\n\nCLASS_EXPR = \"contains(concat(' ', normalize-space(@class), ' '), ' {} ')\"\n\ndef has_class(context, *classes):\n    \"\"\"\n    This lxml extension allows to select by CSS class more easily\n    >>> ns = etree.FunctionNamespace(None)\n    >>> ns['has-class'] = has_class\n    >>> root = etree.XML('''\n    ... <a>\n    ...     <b class=\"one first text\">I</b>\n    ...     <b class=\"two text\">LOVE</b>\n    ...     <b class=\"three text\">CSS</b>\n    ... </a>\n    ... ''')\n    >>> len(root.xpath('//b[has-class(\"text\")]'))\n    3\n    >>> len(root.xpath('//b[has-class(\"one\")]'))\n    1\n    >>> len(root.xpath('//b[has-class(\"text\", \"first\")]'))\n    1\n    >>> len(root.xpath('//b[not(has-class(\"first\"))]'))\n    2\n    >>> len(root.xpath('//b[has-class(\"not-exists\")]'))\n    0\n    \"\"\"\n\n    expressions = ' and '.join([CLASS_EXPR.format(c) for c in classes])\n    xpath = 'self::*[@class and {}]'.format(expressions)\n    return bool(context.context_node.xpath(xpath))\n```\n\nI think it is a common practice to create custom xpaths on different projects.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/9", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/9/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/9/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/9/events", "html_url": "https://github.com/scrapy/parsel/issues/9", "id": 99049928, "node_id": "MDU6SXNzdWU5OTA0OTkyOA==", "number": 9, "title": "project description", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2015-08-04T20:02:15Z", "updated_at": "2015-08-04T20:36:28Z", "closed_at": "2015-08-04T20:36:28Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently project description on github is the following:\n\n> Parsel lets you extract text from XML/HTML documents using XPath or CSS selectors\n\nI think it is confusing - Parsel can be used not only to extract text, it can also extract parts of XML/HTML documents with markup, or attributes of elements. \n\nTechniclly any part of HTML is text (including markup and tags), but I think it is confusing to use \"text\" in this context - usually \"extract text from HTML\" means \"remove tags\".\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/7", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/7/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/7/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/7/events", "html_url": "https://github.com/scrapy/parsel/issues/7", "id": 98377824, "node_id": "MDU6SXNzdWU5ODM3NzgyNA==", "number": 7, "title": "HISTORY.rst is incorrect", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2015-07-31T12:03:54Z", "updated_at": "2015-07-31T19:12:24Z", "closed_at": "2015-07-31T19:12:24Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The data on pypi looks fine (https://pypi.python.org/pypi/parsel/0.9.0), but on github HISTORY.rst contains only information about non-existent 1.0.0 release.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/6", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/6/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/6/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/6/events", "html_url": "https://github.com/scrapy/parsel/issues/6", "id": 98374203, "node_id": "MDU6SXNzdWU5ODM3NDIwMw==", "number": 6, "title": "Run doctests in tox", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-07-31T11:42:47Z", "updated_at": "2015-07-31T19:20:38Z", "closed_at": "2015-07-31T19:20:38Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "After a [switch](https://github.com/scrapy/parsel/commit/80deeef38062fc1e2106da7042d11afee694f439) from nosetests to pytest doc we stopped running doctests. I think they should be re-enabled. At least parsel.utils rely on doctests.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/5", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/5/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/5/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/5/events", "html_url": "https://github.com/scrapy/parsel/issues/5", "id": 98373830, "node_id": "MDU6SXNzdWU5ODM3MzgzMA==", "number": 5, "title": "Documentation", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-07-31T11:40:09Z", "updated_at": "2015-08-14T10:06:17Z", "closed_at": "2015-08-14T10:06:17Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Documentation in docs/ folder is for scrapy selectors, not for parsel. We should update it and setup ReadTheDocs integration.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/3", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/3/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/3/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/3/events", "html_url": "https://github.com/scrapy/parsel/issues/3", "id": 71826517, "node_id": "MDU6SXNzdWU3MTgyNjUxNw==", "number": 3, "title": "remove Scrapy dependency", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-04-29T09:29:27Z", "updated_at": "2015-07-31T10:03:45Z", "closed_at": "2015-07-31T10:03:45Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Selectors shouldn't import from Scrapy, otherwise splitting them to a separate library doesn't provide benefits.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/2", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/2/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/2/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/2/events", "html_url": "https://github.com/scrapy/parsel/issues/2", "id": 71478805, "node_id": "MDU6SXNzdWU3MTQ3ODgwNQ==", "number": 2, "title": "Define module name", "user": {"login": "pablohoffman", "id": 185212, "node_id": "MDQ6VXNlcjE4NTIxMg==", "avatar_url": "https://avatars1.githubusercontent.com/u/185212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pablohoffman", "html_url": "https://github.com/pablohoffman", "followers_url": "https://api.github.com/users/pablohoffman/followers", "following_url": "https://api.github.com/users/pablohoffman/following{/other_user}", "gists_url": "https://api.github.com/users/pablohoffman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pablohoffman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pablohoffman/subscriptions", "organizations_url": "https://api.github.com/users/pablohoffman/orgs", "repos_url": "https://api.github.com/users/pablohoffman/repos", "events_url": "https://api.github.com/users/pablohoffman/events{/privacy}", "received_events_url": "https://api.github.com/users/pablohoffman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2015-04-28T05:05:37Z", "updated_at": "2015-07-30T22:07:15Z", "closed_at": "2015-07-30T22:07:15Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Is there a module name suggested for this new baby?. Feel free to dump ideas :)\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/parsel/issues/1", "repository_url": "https://api.github.com/repos/scrapy/parsel", "labels_url": "https://api.github.com/repos/scrapy/parsel/issues/1/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/parsel/issues/1/comments", "events_url": "https://api.github.com/repos/scrapy/parsel/issues/1/events", "html_url": "https://github.com/scrapy/parsel/issues/1", "id": 71470920, "node_id": "MDU6SXNzdWU3MTQ3MDkyMA==", "number": 1, "title": "Extract history from Scrapy repository", "user": {"login": "dangra", "id": 37369, "node_id": "MDQ6VXNlcjM3MzY5", "avatar_url": "https://avatars3.githubusercontent.com/u/37369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dangra", "html_url": "https://github.com/dangra", "followers_url": "https://api.github.com/users/dangra/followers", "following_url": "https://api.github.com/users/dangra/following{/other_user}", "gists_url": "https://api.github.com/users/dangra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dangra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dangra/subscriptions", "organizations_url": "https://api.github.com/users/dangra/orgs", "repos_url": "https://api.github.com/users/dangra/repos", "events_url": "https://api.github.com/users/dangra/events{/privacy}", "received_events_url": "https://api.github.com/users/dangra/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2015-04-28T03:55:19Z", "updated_at": "2015-05-11T21:52:35Z", "closed_at": "2015-05-11T21:52:35Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Per https://github.com/scrapy/scrapy/pull/1007#issuecomment-95977344 we want to retain commit messages, dates and authors of selectors history as developed in Scrapy repo\n", "performed_via_github_app": null, "score": 1.0}]}