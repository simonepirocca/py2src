{"total_count": 112, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/intake/filesystem_spec/issues/375", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/375/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/375/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/375/events", "html_url": "https://github.com/intake/filesystem_spec/issues/375", "id": 679230291, "node_id": "MDU6SXNzdWU2NzkyMzAyOTE=", "number": 375, "title": "Change in http implementation of isdir() ?", "user": {"login": "joshmoore", "id": 88113, "node_id": "MDQ6VXNlcjg4MTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/88113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joshmoore", "html_url": "https://github.com/joshmoore", "followers_url": "https://api.github.com/users/joshmoore/followers", "following_url": "https://api.github.com/users/joshmoore/following{/other_user}", "gists_url": "https://api.github.com/users/joshmoore/gists{/gist_id}", "starred_url": "https://api.github.com/users/joshmoore/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joshmoore/subscriptions", "organizations_url": "https://api.github.com/users/joshmoore/orgs", "repos_url": "https://api.github.com/users/joshmoore/repos", "events_url": "https://api.github.com/users/joshmoore/events{/privacy}", "received_events_url": "https://api.github.com/users/joshmoore/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-14T15:21:50Z", "updated_at": "2020-08-17T16:09:12Z", "closed_at": "2020-08-17T16:09:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "The python Zarr client was previously working together with our HTTP-based implementation. (https://github.com/ome/omero-ms-zarr), but a recent change seems to have changed the expectations of a directory listing.\r\n\r\n---- \r\n\r\nTest environment:\r\n\r\n```\r\nconda create -n fsspec -c conda-forge zarr fsspec dask s3fs aiohttp requests\r\n\r\ndask-2.22.0          | 4 KB      | ############################################################################################ | 100%\r\nyarl-1.3.0           | 126 KB    | ############################################################################################ | 100%\r\nmultidict-4.7.5      | 60 KB     | ############################################################################################ | 100%\r\nattrs-19.3.0         | 35 KB     | ############################################################################################ | 100%\r\nidna-2.10            | 52 KB     | ############################################################################################ | 100%\r\nmarkupsafe-1.1.1     | 25 KB     | ############################################################################################ | 100%\r\npyyaml-5.3.1         | 176 KB    | ############################################################################################ | 100%\r\ndask-core-2.22.0     | 624 KB    | ############################################################################################ | 100%\r\ndistributed-2.22.0   | 1.0 MB    | ############################################################################################ | 100%\r\nbotocore-1.17.42     | 4.0 MB    | ############################################################################################ | 100%\r\npandas-1.1.0         | 10.2 MB   | ############################################################################################ | 100%\r\nsqlite-3.32.3        | 1.7 MB    | ############################################################################################ | 100%\r\nsetuptools-49.6.0    | 955 KB    | ############################################################################################ | 100%\r\nurllib3-1.25.10      | 92 KB     | ############################################################################################ | 100%\r\ntk-8.6.10            | 3.3 MB    | ############################################################################################ | 100%\r\nasync-timeout-3.0.1  | 11 KB     | ############################################################################################ | 100%\r\ncytoolz-0.10.1       | 365 KB    | ############################################################################################ | 100%\r\npsutil-5.7.2         | 345 KB    | ############################################################################################ | 100%\r\ncffi-1.14.1          | 218 KB    | ############################################################################################ | 100%\r\ntornado-6.0.4        | 642 KB    | ############################################################################################ | 100%\r\naiohttp-3.6.2        | 593 KB    | ############################################################################################ | 100%\r\ndocutils-0.15.2      | 737 KB    | ############################################################################################ | 100%\r\nbokeh-2.1.1          | 7.0 MB    | ############################################################################################ | 100%\r\nboto3-1.14.42        | 69 KB     | ############################################################################################ | 100%\r\ns3transfer-0.3.3     | 91 KB     | ############################################################################################ | 100%\r\ncloudpickle-1.5.0    | 22 KB     | ############################################################################################ | 100%\r\nlibpng-1.6.37        | 319 KB    | ############################################################################################ | 100%\r\nfsspec-0.8.0         | 61 KB     | ############################################################################################ | 100%\r\npycparser-2.20       | 94 KB     | ############################################################################################ | 100%\r\ncryptography-3.0     | 619 KB    | ############################################################################################ | 100%\r\nsortedcontainers-2.2 | 25 KB     | ############################################################################################ | 100%\r\n```\r\n\r\nwith @martindurant `fsspec` branch of zarr-python installed on top.  \r\n\r\nHTTP output:\r\n\r\n```\r\n(fsspec) ~ $curl -q http://localhost:8080/image/1.zarr/ | xmllint --format -\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100   250  100   250    0     0   2475      0 --:--:-- --:--:-- --:--:--  2500\r\n<?xml version=\"1.0\"?>\r\n<html>\r\n  <head>\r\n    <title>Image #1</title>\r\n  </head>\r\n  <body>\r\n    <h1>Directory listing for Image #1</h1>\r\n    <ul>\r\n      <li>\r\n        <a href=\".zattrs\">.zattrs</a>\r\n      </li>\r\n      <li>\r\n        <a href=\".zgroup\">.zgroup</a>\r\n      </li>\r\n      <li>\r\n        <a href=\"masks/\">masks/</a>\r\n      </li>\r\n      <li>\r\n        <a href=\"0/\">0/</a>\r\n      </li>\r\n    </ul>\r\n  </body>\r\n</html>\r\n```\r\n\r\nPython test:\r\n\r\n```\r\nimport zarr\r\nzarr.group(store=zarr.storage.FSStore(\"http://localhost:8080/image/1.zarr/\"))\r\n```\r\n\r\nPython output:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"./martin.py\", line 17, in <module>\r\n    print(now(), t(x)[\"0\"][0][0][0][0][0])\r\n  File \"./martin.py\", line 12, in t\r\n    store = zarr.storage.FSStore(x, **options)\r\n  File \"/Users/jamoore/opt/zarr/zarr/storage.py\", line 966, in __init__\r\n    if self.fs.exists(url) and not self.fs.isdir(url):\r\n  File \"/Users/jamoore/opt/zarr/zarr/errors.py\", line 38, in err_fspath_exists_notdir\r\n    raise ValueError('path exists but is not a directory: %r' % fspath)\r\nValueError: path exists but is not a directory: 'http://localhost:8080/image/1.zarr/'\r\n```\r\n\r\nsee: https://github.com/zarr-developers/zarr-python/pull/546#issuecomment-674112250 \r\n\r\ncc: @mtbc", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/373", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/373/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/373/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/373/events", "html_url": "https://github.com/intake/filesystem_spec/issues/373", "id": 675024043, "node_id": "MDU6SXNzdWU2NzUwMjQwNDM=", "number": 373, "title": "use of 'az' as a shorter version of 'abfs`", "user": {"login": "raybellwaves", "id": 17162724, "node_id": "MDQ6VXNlcjE3MTYyNzI0", "avatar_url": "https://avatars0.githubusercontent.com/u/17162724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raybellwaves", "html_url": "https://github.com/raybellwaves", "followers_url": "https://api.github.com/users/raybellwaves/followers", "following_url": "https://api.github.com/users/raybellwaves/following{/other_user}", "gists_url": "https://api.github.com/users/raybellwaves/gists{/gist_id}", "starred_url": "https://api.github.com/users/raybellwaves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raybellwaves/subscriptions", "organizations_url": "https://api.github.com/users/raybellwaves/orgs", "repos_url": "https://api.github.com/users/raybellwaves/repos", "events_url": "https://api.github.com/users/raybellwaves/events{/privacy}", "received_events_url": "https://api.github.com/users/raybellwaves/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-07T13:40:51Z", "updated_at": "2020-08-07T14:43:52Z", "closed_at": "2020-08-07T14:43:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is more of a discussion than a features request.\r\n\r\nLooking at `known_implementations` there are `gcs` and `gs` which both point to `gcsfs.GCSFileSystem`. Could `az` be created as a shorter version of `abfs`?\r\n\r\n- `az` is common with Azure CLI syntax e.g. https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10#run-azcopy.\r\n- As someone who is very lazy I prefer two key strokes instead of four.\r\n\r\n**Caveats**\r\n\r\nUnlike `gs` and `s3`, Azure has two classes (`adlfs.AzureDatalakeFileSystem` and `adlfs.AzureBlobFileSystem`). I imagine you can't use `az` for both classes.\r\n\r\n**Proposed solution**\r\n\r\nUse `az` as a shortcut for `'abfs': {'class': 'adlfs.AzureBlobFileSystem'}`. Given this is for the latest version of storage (Azure Datalake Gen2 and Azure Blob Storage). In addition my 50 % reduction in key strokes motivation doesn't apply to `adl` (Azure Datalake Gen1).\r\n\r\nIf you prefer me to open at https://github.com/dask/adlfs I will do so.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/368", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/368/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/368/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/368/events", "html_url": "https://github.com/intake/filesystem_spec/issues/368", "id": 672533781, "node_id": "MDU6SXNzdWU2NzI1MzM3ODE=", "number": 368, "title": "Version 0.8.0 marked as compatible with Python 3.5 but uses f-strings", "user": {"login": "dlindelof", "id": 245328, "node_id": "MDQ6VXNlcjI0NTMyOA==", "avatar_url": "https://avatars1.githubusercontent.com/u/245328?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dlindelof", "html_url": "https://github.com/dlindelof", "followers_url": "https://api.github.com/users/dlindelof/followers", "following_url": "https://api.github.com/users/dlindelof/following{/other_user}", "gists_url": "https://api.github.com/users/dlindelof/gists{/gist_id}", "starred_url": "https://api.github.com/users/dlindelof/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dlindelof/subscriptions", "organizations_url": "https://api.github.com/users/dlindelof/orgs", "repos_url": "https://api.github.com/users/dlindelof/repos", "events_url": "https://api.github.com/users/dlindelof/events{/privacy}", "received_events_url": "https://api.github.com/users/dlindelof/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-08-04T06:14:33Z", "updated_at": "2020-08-07T12:58:42Z", "closed_at": "2020-08-07T12:58:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Version 0.8.0 is marked on PyPI as requiring Python >= 3.5, but there's an f-string in core.py. Python 3.6 is required for f-strings.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/367", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/367/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/367/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/367/events", "html_url": "https://github.com/intake/filesystem_spec/issues/367", "id": 672053856, "node_id": "MDU6SXNzdWU2NzIwNTM4NTY=", "number": 367, "title": "In-memory filesystem \"mv\" fails with KeyError for files when recursive=True", "user": {"login": "jorisvandenbossche", "id": 1020496, "node_id": "MDQ6VXNlcjEwMjA0OTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorisvandenbossche", "html_url": "https://github.com/jorisvandenbossche", "followers_url": "https://api.github.com/users/jorisvandenbossche/followers", "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}", "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions", "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs", "repos_url": "https://api.github.com/users/jorisvandenbossche/repos", "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}", "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-03T12:51:09Z", "updated_at": "2020-08-04T15:11:46Z", "closed_at": "2020-08-04T15:11:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "From https://issues.apache.org/jira/browse/ARROW-9621\r\n\r\n```python\r\nimport fsspec\r\nmemfs = fsspec.filesystem(\"memory\")\r\n\r\n# works\r\nmemfs.touch(\"source.txt\")  \r\nmemfs.mv(\"source.txt\", \"target.txt\")\r\n\r\n# fails \r\nmemfs.touch(\"source2.txt\")  \r\nmemfs.mv(\"source2.txt\", \"target2.txt\", recursive=True)\r\n```\r\n\r\ngives\r\n\r\n```\r\n---> 10 memfs.mv(\"source2.txt\", \"target2.txt\", recursive=True)\r\n\r\n~/scipy/repos/filesystem_spec/fsspec/spec.py in mv(self, path1, path2, recursive, maxdepth, **kwargs)\r\n    742     def mv(self, path1, path2, recursive=False, maxdepth=None, **kwargs):\r\n    743         \"\"\" Move file(s) from one location to another \"\"\"\r\n--> 744         self.copy(path1, path2, recursive=recursive, maxdepth=maxdepth)\r\n    745         self.rm(path1, recursive=recursive)\r\n    746 \r\n\r\n~/scipy/repos/filesystem_spec/fsspec/spec.py in copy(self, path1, path2, recursive, **kwargs)\r\n    717         path2 = other_paths(paths, path2)\r\n    718         for p1, p2 in zip(paths, path2):\r\n--> 719             self.cp_file(p1, p2, **kwargs)\r\n    720 \r\n    721     def expand_path(self, path, recursive=False, maxdepth=None):\r\n\r\n~/scipy/repos/filesystem_spec/fsspec/implementations/memory.py in cp_file(self, path1, path2, **kwargs)\r\n    132     def cp_file(self, path1, path2, **kwargs):\r\n    133         if self.isfile(path1):\r\n--> 134             self.store[path2] = MemoryFile(self, path2, self.store[path1].getbuffer())\r\n    135         elif self.isdir(path1):\r\n    136             if path2 not in self.pseudo_dirs:\r\n\r\nKeyError: 'source2.txt/'\r\n```\r\n\r\nThis worked before, and started failing with fsspec 0.8.0", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/361", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/361/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/361/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/361/events", "html_url": "https://github.com/intake/filesystem_spec/issues/361", "id": 665662051, "node_id": "MDU6SXNzdWU2NjU2NjIwNTE=", "number": 361, "title": "bug: open_local second time after cache dir got deleted fails", "user": {"login": "aaronspring", "id": 12237157, "node_id": "MDQ6VXNlcjEyMjM3MTU3", "avatar_url": "https://avatars0.githubusercontent.com/u/12237157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaronspring", "html_url": "https://github.com/aaronspring", "followers_url": "https://api.github.com/users/aaronspring/followers", "following_url": "https://api.github.com/users/aaronspring/following{/other_user}", "gists_url": "https://api.github.com/users/aaronspring/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaronspring/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaronspring/subscriptions", "organizations_url": "https://api.github.com/users/aaronspring/orgs", "repos_url": "https://api.github.com/users/aaronspring/repos", "events_url": "https://api.github.com/users/aaronspring/events{/privacy}", "received_events_url": "https://api.github.com/users/aaronspring/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-25T21:14:09Z", "updated_at": "2020-07-28T16:06:03Z", "closed_at": "2020-07-27T19:32:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "```python\r\nimport fsspec as fs\r\nimport os\r\nimport shutil\r\nurl = 'http://maps.tnc.org/files/shp/MEOW-TNC.zip'\r\nlurl = fs.open_local(f'simplecache::{url}', simplecache={'same_names':True, 'cache_storage': 'cache'})\r\nassert os.path.exists(lurl)\r\nlurl\r\n['cache/MEOW-TNC.zip']\r\n\r\n# remove cache dir\r\nshutil.rmtree('cache')\r\nassert not os.path.exists(lurl)\r\n\r\n# access second time\r\n# except to reload\r\nlurl = fs.open_local(f'simplecache::{url}', simplecache={'same_names':True, 'cache_storage': 'cache'})\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/Users/aaron.spring/anaconda3/envs/xr/lib/python3.7/site-packages/fsspec/core.py\", line 420, in open_local\r\n    paths = [f.open().name for f in of]\r\n  File \"/Users/aaron.spring/anaconda3/envs/xr/lib/python3.7/site-packages/fsspec/core.py\", line 420, in <listcomp>\r\n    paths = [f.open().name for f in of]\r\n  File \"/Users/aaron.spring/anaconda3/envs/xr/lib/python3.7/site-packages/fsspec/core.py\", line 133, in open\r\n    out = self.__enter__()\r\n  File \"/Users/aaron.spring/anaconda3/envs/xr/lib/python3.7/site-packages/fsspec/core.py\", line 101, in __enter__\r\n    f = self.fs.open(self.path, mode=mode)\r\n  File \"/Users/aaron.spring/anaconda3/envs/xr/lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 363, in <lambda>\r\n    return lambda *args, **kw: getattr(type(self), item)(self, *args, **kw)\r\n  File \"/Users/aaron.spring/anaconda3/envs/xr/lib/python3.7/site-packages/fsspec/spec.py\", line 844, in open\r\n    **kwargs\r\n  File \"/Users/aaron.spring/anaconda3/envs/xr/lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 363, in <lambda>\r\n    return lambda *args, **kw: getattr(type(self), item)(self, *args, **kw)\r\n  File \"/Users/aaron.spring/anaconda3/envs/xr/lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 534, in _open\r\n    with self.fs._open(path, **kwargs) as f, open(fn, \"wb\") as f2:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'cache/MEOW-TNC.zip'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/360", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/360/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/360/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/360/events", "html_url": "https://github.com/intake/filesystem_spec/issues/360", "id": 665655463, "node_id": "MDU6SXNzdWU2NjU2NTU0NjM=", "number": 360, "title": "ENH: can given URL/filesystem can return a local path", "user": {"login": "aaronspring", "id": 12237157, "node_id": "MDQ6VXNlcjEyMjM3MTU3", "avatar_url": "https://avatars0.githubusercontent.com/u/12237157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaronspring", "html_url": "https://github.com/aaronspring", "followers_url": "https://api.github.com/users/aaronspring/followers", "following_url": "https://api.github.com/users/aaronspring/following{/other_user}", "gists_url": "https://api.github.com/users/aaronspring/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaronspring/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaronspring/subscriptions", "organizations_url": "https://api.github.com/users/aaronspring/orgs", "repos_url": "https://api.github.com/users/aaronspring/repos", "events_url": "https://api.github.com/users/aaronspring/events{/privacy}", "received_events_url": "https://api.github.com/users/aaronspring/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-25T20:26:36Z", "updated_at": "2020-07-27T19:32:48Z", "closed_at": "2020-07-27T19:32:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "bool whether `\"*cache://\"` in urlpath \r\n\r\ncame up in https://github.com/intake/intake_geopandas/pull/16 https://github.com/intake/intake_geopandas/pull/17", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/359", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/359/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/359/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/359/events", "html_url": "https://github.com/intake/filesystem_spec/issues/359", "id": 664578805, "node_id": "MDU6SXNzdWU2NjQ1Nzg4MDU=", "number": 359, "title": "Release request", "user": {"login": "sodre", "id": 1043285, "node_id": "MDQ6VXNlcjEwNDMyODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1043285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sodre", "html_url": "https://github.com/sodre", "followers_url": "https://api.github.com/users/sodre/followers", "following_url": "https://api.github.com/users/sodre/following{/other_user}", "gists_url": "https://api.github.com/users/sodre/gists{/gist_id}", "starred_url": "https://api.github.com/users/sodre/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sodre/subscriptions", "organizations_url": "https://api.github.com/users/sodre/orgs", "repos_url": "https://api.github.com/users/sodre/repos", "events_url": "https://api.github.com/users/sodre/events{/privacy}", "received_events_url": "https://api.github.com/users/sodre/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-23T15:36:26Z", "updated_at": "2020-07-31T17:52:45Z", "closed_at": "2020-07-23T18:12:30Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "@martindurant, are we close to a new release of fssspec? \r\n\r\nIn particular I am looking for the fixes to #329, and #332, and #334 to be available in conda-forge and PyPi.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/357", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/357/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/357/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/357/events", "html_url": "https://github.com/intake/filesystem_spec/issues/357", "id": 663044406, "node_id": "MDU6SXNzdWU2NjMwNDQ0MDY=", "number": 357, "title": "ENH: Combined context manager for open_files", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-21T14:08:02Z", "updated_at": "2020-07-31T17:51:53Z", "closed_at": "2020-07-31T17:51:53Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The return value of open_files could be a special instance, which can act as a context manager: when entered, all the files are opened, and then closed on exit. Iteration and getitem should still work as expected and give the OpenFile objects.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/355", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/355/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/355/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/355/events", "html_url": "https://github.com/intake/filesystem_spec/issues/355", "id": 661880389, "node_id": "MDU6SXNzdWU2NjE4ODAzODk=", "number": 355, "title": "typo `neet` may be `need` ?", "user": {"login": "gsy0911", "id": 26303754, "node_id": "MDQ6VXNlcjI2MzAzNzU0", "avatar_url": "https://avatars1.githubusercontent.com/u/26303754?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gsy0911", "html_url": "https://github.com/gsy0911", "followers_url": "https://api.github.com/users/gsy0911/followers", "following_url": "https://api.github.com/users/gsy0911/following{/other_user}", "gists_url": "https://api.github.com/users/gsy0911/gists{/gist_id}", "starred_url": "https://api.github.com/users/gsy0911/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gsy0911/subscriptions", "organizations_url": "https://api.github.com/users/gsy0911/orgs", "repos_url": "https://api.github.com/users/gsy0911/repos", "events_url": "https://api.github.com/users/gsy0911/events{/privacy}", "received_events_url": "https://api.github.com/users/gsy0911/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-20T14:20:06Z", "updated_at": "2020-07-20T22:48:57Z", "closed_at": "2020-07-20T22:48:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "In `spec.py` Line 1278, there would be typo `neet`.\r\nIt may be `need` ?\r\n\r\n```\r\n    def _upload_chunk(self, final=False):\r\n        \"\"\" Write one part of a multi-block file upload\r\n        Parameters\r\n        ==========\r\n        final: bool\r\n            This is the last block, so should complete file, if\r\n            self.autocommit is True.\r\n        \"\"\"\r\n\r\n        # may not yet have been initialized, may neet to call _initialize_upload  <<< Line 1278 typo ?\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/353", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/353/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/353/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/353/events", "html_url": "https://github.com/intake/filesystem_spec/issues/353", "id": 659302971, "node_id": "MDU6SXNzdWU2NTkzMDI5NzE=", "number": 353, "title": "lzma.LZMAFile AttributeError in Python without LZMA", "user": {"login": "dfigus", "id": 10271668, "node_id": "MDQ6VXNlcjEwMjcxNjY4", "avatar_url": "https://avatars3.githubusercontent.com/u/10271668?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dfigus", "html_url": "https://github.com/dfigus", "followers_url": "https://api.github.com/users/dfigus/followers", "following_url": "https://api.github.com/users/dfigus/following{/other_user}", "gists_url": "https://api.github.com/users/dfigus/gists{/gist_id}", "starred_url": "https://api.github.com/users/dfigus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dfigus/subscriptions", "organizations_url": "https://api.github.com/users/dfigus/orgs", "repos_url": "https://api.github.com/users/dfigus/repos", "events_url": "https://api.github.com/users/dfigus/events{/privacy}", "received_events_url": "https://api.github.com/users/dfigus/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-17T14:29:39Z", "updated_at": "2020-07-20T15:36:43Z", "closed_at": "2020-07-20T15:36:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I sometimes get a `module 'lzma' has no attribute 'LZMAFile' ` error in a threaded environment (which I don't have any control over, unfortunately \ud83d\ude1f - it's an company internal \"cloud\" engine). It's not reproducible and I was unable so far to create a local example for this. \r\n\r\nThe stack trace is:\r\n```\r\n  File \"/root/.local/lib/python3.6/site-packages/adlfs/__init__.py\", line 1, in <module>\r\n    from .core import AzureDatalakeFileSystem\r\n  File \"/root/.local/lib/python3.6/site-packages/adlfs/core.py\", line 12, in <module>\r\n    from fsspec import AbstractFileSystem\r\n  File \"/root/.local/lib/python3.6/site-packages/fsspec/__init__.py\", line 5, in <module>\r\n    from .mapping import FSMap, get_mapper\r\n  File \"/root/.local/lib/python3.6/site-packages/fsspec/mapping.py\", line 3, in <module>\r\n    from .core import split_protocol\r\n  File \"/root/.local/lib/python3.6/site-packages/fsspec/core.py\", line 6, in <module>\r\n    from .compression import compr\r\n  File \"/root/.local/lib/python3.6/site-packages/fsspec/compression.py\", line 77, in <module>\r\n    register_compression(\"lzma\", lzma.LZMAFile, \"xz\")\r\nAttributeError: module 'lzma' has no attribute 'LZMAFile'\r\n```\r\n\r\nAfter digging some time I found [Python issue 39430: tarfile.open(mode=\"r\") race condition when importing lzma](https://bugs.python.org/issue39430) which also suffered from the same AttributeError. It looks like there is a race condition when using `import lzma` compared to `from lzma import xyz` in a threaded environment.\r\n\r\nWould it be ok to change the lzma import in [fsspec/compression.py](https://github.com/intake/filesystem_spec/blob/master/fsspec/compression.py#L76-L79)? What do you think? I did a local modification of those lines and so far the AttributeError does not longer occur.\r\n\r\nHappy to get your feedback on this and opening a PR if we agree on this.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/350", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/350/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/350/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/350/events", "html_url": "https://github.com/intake/filesystem_spec/issues/350", "id": 654974452, "node_id": "MDU6SXNzdWU2NTQ5NzQ0NTI=", "number": 350, "title": "Iterating over local files", "user": {"login": "ifiddes", "id": 7818077, "node_id": "MDQ6VXNlcjc4MTgwNzc=", "avatar_url": "https://avatars2.githubusercontent.com/u/7818077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ifiddes", "html_url": "https://github.com/ifiddes", "followers_url": "https://api.github.com/users/ifiddes/followers", "following_url": "https://api.github.com/users/ifiddes/following{/other_user}", "gists_url": "https://api.github.com/users/ifiddes/gists{/gist_id}", "starred_url": "https://api.github.com/users/ifiddes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ifiddes/subscriptions", "organizations_url": "https://api.github.com/users/ifiddes/orgs", "repos_url": "https://api.github.com/users/ifiddes/repos", "events_url": "https://api.github.com/users/ifiddes/events{/privacy}", "received_events_url": "https://api.github.com/users/ifiddes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-10T18:54:10Z", "updated_at": "2020-07-21T17:26:19Z", "closed_at": "2020-07-21T17:26:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was expecting to be able to do this regardless of the file system being used:\r\n\r\n```\r\nwith fsspec.open(file) as fh:\r\n    for line in fh:\r\n        print(line)\r\n```\r\n\r\nThis works fine for S3FS, but for a local file, the returned `LocalFileOpener` object lacks the classic methods associated with an open file handle like `seek`, or a `__iter__`. However, the `fh.f`member, a `io.BufferedReader`, has the necessary functionality.\r\n\r\nThis makes writing an API that is meant to seamlessly treat local files and remote files the same way require a wrapper in front of `open`. Is there a reason for this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/349", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/349/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/349/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/349/events", "html_url": "https://github.com/intake/filesystem_spec/issues/349", "id": 653717394, "node_id": "MDU6SXNzdWU2NTM3MTczOTQ=", "number": 349, "title": "MemoryFileSystem fails to rewind", "user": {"login": "joachimvalente", "id": 1289004, "node_id": "MDQ6VXNlcjEyODkwMDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1289004?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joachimvalente", "html_url": "https://github.com/joachimvalente", "followers_url": "https://api.github.com/users/joachimvalente/followers", "following_url": "https://api.github.com/users/joachimvalente/following{/other_user}", "gists_url": "https://api.github.com/users/joachimvalente/gists{/gist_id}", "starred_url": "https://api.github.com/users/joachimvalente/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joachimvalente/subscriptions", "organizations_url": "https://api.github.com/users/joachimvalente/orgs", "repos_url": "https://api.github.com/users/joachimvalente/repos", "events_url": "https://api.github.com/users/joachimvalente/events{/privacy}", "received_events_url": "https://api.github.com/users/joachimvalente/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-07-09T02:39:50Z", "updated_at": "2020-07-31T17:52:06Z", "closed_at": "2020-07-31T17:52:06Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "# Steps to reproduce\r\n\r\n```py\r\n>>> import fsspec\r\n>>> fsspec.__version__\r\n0.7.4\r\n>>> fs = fsspec.filesystem(\"memory\")\r\n>>> with fs.open(\"foo\", \"w\") as f:\r\n...   f.write(\"bar\")\r\n>>> with fs.open(\"foo\") as f:\r\n...   print(f.read())\r\nb''\r\n>>> with fs.open(\"foo\") as f:\r\n...   f.seek(0) # we shouldn't need this!\r\n...   print(f.read())\r\nb'bar'\r\n```\r\n\r\n# Root cause\r\n\r\nThis is due to this line:\r\n\r\nhttps://github.com/intake/filesystem_spec/blob/0e201d4321ae27bc1ac37d4b28057d085de393f1/fsspec/implementations/memory.py#L179-L180\r\n\r\n# Partial fix\r\n\r\nIt works if we comment out that line, or if we do `.seek(0)` instead of `.seek(0, 2)`. I'm guessing we want something like this:\r\n\r\nhttps://github.com/intake/filesystem_spec/blob/0e201d4321ae27bc1ac37d4b28057d085de393f1/fsspec/implementations/memory.py#L117-L120\r\n\r\n... except that we don't have access to `mode` in `__exit__`, so we'd have to save it in `_open`?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/346", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/346/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/346/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/346/events", "html_url": "https://github.com/intake/filesystem_spec/issues/346", "id": 652384865, "node_id": "MDU6SXNzdWU2NTIzODQ4NjU=", "number": 346, "title": "BUG: LocalFileSystem.move broken for directories", "user": {"login": "jorisvandenbossche", "id": 1020496, "node_id": "MDQ6VXNlcjEwMjA0OTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorisvandenbossche", "html_url": "https://github.com/jorisvandenbossche", "followers_url": "https://api.github.com/users/jorisvandenbossche/followers", "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}", "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions", "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs", "repos_url": "https://api.github.com/users/jorisvandenbossche/repos", "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}", "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-07T14:46:30Z", "updated_at": "2020-07-07T15:34:22Z", "closed_at": "2020-07-07T15:34:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "The last merged PR (https://github.com/intake/filesystem_spec/pull/345) seems to have broken local filesystem `move`. At least for moving an empty directory, the new directory is not created:\r\n\r\n```\r\nIn [22]: localfs = fsspec.filesystem(\"file\")                                                                                                                                                                       \r\n\r\nIn [23]: localfs.isdir(\"src\")                                                                                                                                                                                      \r\nOut[23]: False\r\n\r\nIn [24]: localfs.mkdir(\"src\")                                                                                                                                                                                      \r\n\r\nIn [25]: localfs.isdir(\"src\")                                                                                                                                                                                      \r\nOut[25]: True\r\n\r\nIn [26]: localfs.move(\"src\", \"dest\", recursive=True)                                                                                                                                                               \r\n\r\nIn [27]: localfs.isdir(\"src\")                                                                                                                                                                                      \r\nOut[27]: False\r\n\r\nIn [28]: localfs.isdir(\"dest\")                                                                                                                                                                                     \r\nOut[28]: False\r\n\r\nIn [29]: localfs.info(\"dest\")                                                                                                                                                                                      \r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n<ipython-input-29-6c85f2047d6b> in <module>\r\n----> 1 localfs.info(\"dest\")\r\n\r\n~/scipy/repos/filesystem_spec/fsspec/implementations/local.py in info(self, path, **kwargs)\r\n     57     def info(self, path, **kwargs):\r\n     58         path = self._strip_protocol(path)\r\n---> 59         out = os.stat(path, follow_symlinks=False)\r\n     60         dest = False\r\n     61         if os.path.islink(path):\r\n\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/joris/scipy/dest'\r\n```\r\n\r\nThis was working before that PR.\r\n\r\nAnd also an actual directory with a file seems to error right now", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/337", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/337/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/337/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/337/events", "html_url": "https://github.com/intake/filesystem_spec/issues/337", "id": 646802259, "node_id": "MDU6SXNzdWU2NDY4MDIyNTk=", "number": 337, "title": "Update HDFSFile to inherit from AbstractBufferedFileSystem", "user": {"login": "ayushdg", "id": 19949207, "node_id": "MDQ6VXNlcjE5OTQ5MjA3", "avatar_url": "https://avatars2.githubusercontent.com/u/19949207?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ayushdg", "html_url": "https://github.com/ayushdg", "followers_url": "https://api.github.com/users/ayushdg/followers", "following_url": "https://api.github.com/users/ayushdg/following{/other_user}", "gists_url": "https://api.github.com/users/ayushdg/gists{/gist_id}", "starred_url": "https://api.github.com/users/ayushdg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ayushdg/subscriptions", "organizations_url": "https://api.github.com/users/ayushdg/orgs", "repos_url": "https://api.github.com/users/ayushdg/repos", "events_url": "https://api.github.com/users/ayushdg/events{/privacy}", "received_events_url": "https://api.github.com/users/ayushdg/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-28T00:48:49Z", "updated_at": "2020-07-02T17:45:02Z", "closed_at": "2020-07-02T17:45:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "Currently most Filesystem implementations in `fsspec` on opening a file (`fs.open(...).open()`) return an object that is an instance of `io.IOBase`. While [HDFSFile](https://github.com/intake/filesystem_spec/blob/master/fsspec/implementations/hdfs.py#L177) is a wrapper around Arrow's HdfsFile (which is an instance of `io.IOBase`), and exposes all it's attributes via `__getattr___` the class itself is not an an instance of `IOBase`.\r\n\r\nNote: I'm guessing this feature was intended for the future based on the comment [here](https://github.com/intake/filesystem_spec/blob/master/fsspec/implementations/hdfs.py#L194).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/334", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/334/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/334/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/334/events", "html_url": "https://github.com/intake/filesystem_spec/issues/334", "id": 644813474, "node_id": "MDU6SXNzdWU2NDQ4MTM0NzQ=", "number": 334, "title": "URL Unpacking does not work as expected when chaining 3(+) FileSystems", "user": {"login": "sodre", "id": 1043285, "node_id": "MDQ6VXNlcjEwNDMyODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1043285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sodre", "html_url": "https://github.com/sodre", "followers_url": "https://api.github.com/users/sodre/followers", "following_url": "https://api.github.com/users/sodre/following{/other_user}", "gists_url": "https://api.github.com/users/sodre/gists{/gist_id}", "starred_url": "https://api.github.com/users/sodre/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sodre/subscriptions", "organizations_url": "https://api.github.com/users/sodre/orgs", "repos_url": "https://api.github.com/users/sodre/repos", "events_url": "https://api.github.com/users/sodre/events{/privacy}", "received_events_url": "https://api.github.com/users/sodre/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-24T18:10:36Z", "updated_at": "2020-07-31T17:52:31Z", "closed_at": "2020-07-31T17:52:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently URL unpacking expects the following syntax if we want to open a zip file stored in S3 with a blockcache in the middle. The use case in question is a 19GB file for the Coco dataset.\r\n\r\nThis is the syntax that works:\r\n\r\n> of = fsspec.open_files(\"zip://**.jpg::blockcache://fast-ai-coco/unlabeled2017.zip::s3://\", s3={\"anon\":True}) \r\n\r\nShouldn't this be:\r\n\r\n> of = fsspec.open_files(\"zip://**.jpg::blockcache::s3://fast-ai-coco/unlabeled2017.zip\", s3={\"anon\":True})\r\n\r\n_Originally posted by @martindurant in https://github.com/intake/filesystem_spec/pull/332#issuecomment-648167709_", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/329", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/329/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/329/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/329/events", "html_url": "https://github.com/intake/filesystem_spec/issues/329", "id": 642636462, "node_id": "MDU6SXNzdWU2NDI2MzY0NjI=", "number": 329, "title": "Can't cache a github:// url", "user": {"login": "sodre", "id": 1043285, "node_id": "MDQ6VXNlcjEwNDMyODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1043285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sodre", "html_url": "https://github.com/sodre", "followers_url": "https://api.github.com/users/sodre/followers", "following_url": "https://api.github.com/users/sodre/following{/other_user}", "gists_url": "https://api.github.com/users/sodre/gists{/gist_id}", "starred_url": "https://api.github.com/users/sodre/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sodre/subscriptions", "organizations_url": "https://api.github.com/users/sodre/orgs", "repos_url": "https://api.github.com/users/sodre/repos", "events_url": "https://api.github.com/users/sodre/events{/privacy}", "received_events_url": "https://api.github.com/users/sodre/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-21T20:36:33Z", "updated_at": "2020-06-22T15:01:41Z", "closed_at": "2020-06-22T15:01:41Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "As a user of intake, I would like to cache files stored in github. Unfortunately, this does not work broken with fsspec 0.7.4 from conda-forge. Here is the exception that is being raised:\r\n\r\n```python-traceback\r\nPython 3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) \r\n[GCC 7.5.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import fsspec\r\n>>> github_url=\"github://intake:filesystem_spec@master/README.md\"\r\n>>> fsspec.open(github_url)\r\n<OpenFile 'README.md'>\r\n>>> fsspec.open(f\"simplecache::{github_url}\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/pcarlos/.conda/envs/dev/lib/python3.8/site-packages/fsspec/core.py\", line 370, in open\r\n    return open_files(\r\n  File \"/home/pcarlos/.conda/envs/dev/lib/python3.8/site-packages/fsspec/core.py\", line 242, in open_files\r\n    fs, fs_token, paths = get_fs_token_paths(\r\n  File \"/home/pcarlos/.conda/envs/dev/lib/python3.8/site-packages/fsspec/core.py\", line 523, in get_fs_token_paths\r\n    fs = cls(**options)\r\n  File \"/home/pcarlos/.conda/envs/dev/lib/python3.8/site-packages/fsspec/spec.py\", line 54, in __call__\r\n    obj = super().__call__(*args, **kwargs)\r\n  File \"/home/pcarlos/.conda/envs/dev/lib/python3.8/site-packages/fsspec/implementations/cached.py\", line 444, in __init__\r\n    super().__init__(**kw)\r\n  File \"/home/pcarlos/.conda/envs/dev/lib/python3.8/site-packages/fsspec/implementations/cached.py\", line 113, in __init__\r\n    self.fs = fs if fs is not None else filesystem(target_protocol, **self.kwargs)\r\n  File \"/home/pcarlos/.conda/envs/dev/lib/python3.8/site-packages/fsspec/registry.py\", line 215, in filesystem\r\n    return cls(**storage_options)\r\n  File \"/home/pcarlos/.conda/envs/dev/lib/python3.8/site-packages/fsspec/spec.py\", line 54, in __call__\r\n    obj = super().__call__(*args, **kwargs)\r\nTypeError: __init__() missing 2 required positional arguments: 'org' and 'repo'\r\n>>> \r\n```\r\n\r\n:scroll: The actual catalog uses a stable `SHA` instead of `master`, and it needs to reference files in different github organizations and repositories within the same intake data source.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/326", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/326/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/326/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/326/events", "html_url": "https://github.com/intake/filesystem_spec/issues/326", "id": 641220456, "node_id": "MDU6SXNzdWU2NDEyMjA0NTY=", "number": 326, "title": "local filesystem isn't consistent", "user": {"login": "pvanderlinden", "id": 391586, "node_id": "MDQ6VXNlcjM5MTU4Ng==", "avatar_url": "https://avatars3.githubusercontent.com/u/391586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pvanderlinden", "html_url": "https://github.com/pvanderlinden", "followers_url": "https://api.github.com/users/pvanderlinden/followers", "following_url": "https://api.github.com/users/pvanderlinden/following{/other_user}", "gists_url": "https://api.github.com/users/pvanderlinden/gists{/gist_id}", "starred_url": "https://api.github.com/users/pvanderlinden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pvanderlinden/subscriptions", "organizations_url": "https://api.github.com/users/pvanderlinden/orgs", "repos_url": "https://api.github.com/users/pvanderlinden/repos", "events_url": "https://api.github.com/users/pvanderlinden/events{/privacy}", "received_events_url": "https://api.github.com/users/pvanderlinden/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-06-18T13:44:57Z", "updated_at": "2020-06-18T14:23:54Z", "closed_at": "2020-06-18T14:23:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "- If you set `auto_mkdir` to True for a local filesystem, it won't actually listen to this, for example when copying files, it just invokes `shutil.copyfile`\r\n- if you pass an uri with the scheme included in it to certain functions, the local filesystem will give an error.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/322", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/322/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/322/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/322/events", "html_url": "https://github.com/intake/filesystem_spec/issues/322", "id": 640477378, "node_id": "MDU6SXNzdWU2NDA0NzczNzg=", "number": 322, "title": "OSError: [Errno 18] Invalid cross-device link error on readthedocs", "user": {"login": "gmaze", "id": 1956032, "node_id": "MDQ6VXNlcjE5NTYwMzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/1956032?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gmaze", "html_url": "https://github.com/gmaze", "followers_url": "https://api.github.com/users/gmaze/followers", "following_url": "https://api.github.com/users/gmaze/following{/other_user}", "gists_url": "https://api.github.com/users/gmaze/gists{/gist_id}", "starred_url": "https://api.github.com/users/gmaze/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gmaze/subscriptions", "organizations_url": "https://api.github.com/users/gmaze/orgs", "repos_url": "https://api.github.com/users/gmaze/repos", "events_url": "https://api.github.com/users/gmaze/events{/privacy}", "received_events_url": "https://api.github.com/users/gmaze/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-06-17T14:13:38Z", "updated_at": "2020-06-17T15:12:47Z", "closed_at": "2020-06-17T15:12:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi folks,\r\nI develop a python library to work with ocean data collected using a specific type of instruments (Argo floats): https://github.com/euroargodev/argopy\r\nData can be fetched from local files or from an erddap server online.\r\n\r\nI recently tried to use fsspec to implement file/resource management and ease handling of cached data.\r\nI ended up wrapping ``file``, ``memory`` and ``http`` fsspec file systems into [classes](https://github.com/euroargodev/argopy/blob/master/argopy/stores/fsspec_wrappers.py) that managed custom methods like open_dataset or open_dataframe.\r\n\r\nI worked nicely up to the point where the new master branch was pushed to readthedocs, which failed because of a:\r\n```bash\r\nOSError: [Errno 18] Invalid cross-device link: '/tmp/tmp1twhthrp' -> 'mycache_folder/cache'\r\n```\r\n\r\nThe error is raised when readthedocs executes [a notebook where I demonstrate the use of the caching system of **argopy**](https://github.com/euroargodev/argopy/blob/master/docs/performances.ipynb).\r\nThe error is raised by the sspec/implementations/cached.py ``save_cache(self)`` method in the line where the new cache replace the old one: ``os.replace(fn2, fn)``.\r\n\r\nThis is apparently raised because ``os`` expect files to be from the same file system.\r\n\r\nIs this only related to readthedocs ? and if you have any ideas about how to fix this, that would be great ! One possibility is by using ``shutil.move`` instead of ``os.rename``.\r\n\r\n[The RTD log build with the error can be seen here](https://readthedocs.org/projects/argopy/builds/11273728/).\r\nThe interesting peace is here (sorry for the RTD character mess):\r\n```bash\r\n\u001b[0;32m~/checkouts/readthedocs.org/user_builds/argopy/envs/latest/lib/python3.6/site-packages/fsspec/implementations/cached.py\u001b[0m in \u001b[0;36msave_cache\u001b[0;34m(self)\u001b[0m\r\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n\u001b[1;32m    158\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\r\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n\r\n\u001b[0;31mOSError\u001b[0m: [Errno 18] Invalid cross-device link: '/tmp/tmp3wnrdtiz' -> 'mycache_folder/cache'\r\nOSError: [Errno 18] Invalid cross-device link: '/tmp/tmp3wnrdtiz' -> 'mycache_folder/cache'\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/318", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/318/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/318/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/318/events", "html_url": "https://github.com/intake/filesystem_spec/issues/318", "id": 638563760, "node_id": "MDU6SXNzdWU2Mzg1NjM3NjA=", "number": 318, "title": "Pickling OpenFile object ignores newline attribute", "user": {"login": "mgsdk", "id": 856309, "node_id": "MDQ6VXNlcjg1NjMwOQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/856309?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mgsdk", "html_url": "https://github.com/mgsdk", "followers_url": "https://api.github.com/users/mgsdk/followers", "following_url": "https://api.github.com/users/mgsdk/following{/other_user}", "gists_url": "https://api.github.com/users/mgsdk/gists{/gist_id}", "starred_url": "https://api.github.com/users/mgsdk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mgsdk/subscriptions", "organizations_url": "https://api.github.com/users/mgsdk/orgs", "repos_url": "https://api.github.com/users/mgsdk/repos", "events_url": "https://api.github.com/users/mgsdk/events{/privacy}", "received_events_url": "https://api.github.com/users/mgsdk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-15T05:48:13Z", "updated_at": "2020-06-15T13:35:59Z", "closed_at": "2020-06-15T13:35:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "When pickling `OpenFile` objects, the `newline` attribute is not persisted. This causes issues on Windows, where a value of `None` inserts an additional `\\r` when using the file with a stream already containing correct line termination.\r\n\r\n```python\r\nimport fsspec\r\nimport pickle\r\n\r\n\r\ndef main():\r\n    test = fsspec.open(__file__, newline=b\"\")\r\n    \r\n    pickled = pickle.dumps(test)\r\n    restored = pickle.loads(pickled)\r\n    \r\n    assert test.newline == restored.newline\r\n    return\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nIs there an underlying reason as to why this is not pickled, or was it simply missed during the addition of the `newline` attribute?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/317", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/317/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/317/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/317/events", "html_url": "https://github.com/intake/filesystem_spec/issues/317", "id": 637883352, "node_id": "MDU6SXNzdWU2Mzc4ODMzNTI=", "number": 317, "title": "Intermittent ValueError: Name (`protocol`) already in the registry and clobber is False", "user": {"login": "andersy005", "id": 13301940, "node_id": "MDQ6VXNlcjEzMzAxOTQw", "avatar_url": "https://avatars2.githubusercontent.com/u/13301940?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andersy005", "html_url": "https://github.com/andersy005", "followers_url": "https://api.github.com/users/andersy005/followers", "following_url": "https://api.github.com/users/andersy005/following{/other_user}", "gists_url": "https://api.github.com/users/andersy005/gists{/gist_id}", "starred_url": "https://api.github.com/users/andersy005/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andersy005/subscriptions", "organizations_url": "https://api.github.com/users/andersy005/orgs", "repos_url": "https://api.github.com/users/andersy005/repos", "events_url": "https://api.github.com/users/andersy005/events{/privacy}", "received_events_url": "https://api.github.com/users/andersy005/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-12T16:48:28Z", "updated_at": "2020-06-29T14:39:04Z", "closed_at": "2020-06-29T13:19:26Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I recently started getting the following error when using `fsspec.get_mapper()` in the latest version of fsspec (fsspec=0.7.4):\r\n\r\n```python\r\nValueError: Name (gs) already in the registry and clobber is False\r\n```\r\n\r\nI noticed this issue with both gcsfs and s3fs. I tried passing `storage_options={'clobber': True}`, but the error doesn't go away. The error does go away if I re-run the notebook cell in question. What's the proper way for dealing with this issue? Am I missing something?\r\n\r\nI can confirm that the error doesn't occur when using fsspec=0.7.3. \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/316", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/316/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/316/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/316/events", "html_url": "https://github.com/intake/filesystem_spec/issues/316", "id": 636816833, "node_id": "MDU6SXNzdWU2MzY4MTY4MzM=", "number": 316, "title": "In-memory filesystem \"mv\" fails with KeyError on src directory", "user": {"login": "jorisvandenbossche", "id": 1020496, "node_id": "MDQ6VXNlcjEwMjA0OTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorisvandenbossche", "html_url": "https://github.com/jorisvandenbossche", "followers_url": "https://api.github.com/users/jorisvandenbossche/followers", "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}", "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions", "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs", "repos_url": "https://api.github.com/users/jorisvandenbossche/repos", "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}", "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-11T08:15:37Z", "updated_at": "2020-07-07T17:10:01Z", "closed_at": "2020-07-02T15:03:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "It's not fully clear if this is supposed to work. The spec docs mention \"move file\" https://filesystem-spec.readthedocs.io/en/latest/api.html#fsspec.spec.AbstractFileSystem.mv, but in general (eg `mv` bash command) `mv` also works for directories, and also the fsspec LocalFileSystem moves directories. \r\n\r\nOr, if not `mv`, what's the method in the spec to copy directories? (I think `copy` is meant to be limited to files?)\r\n\r\n```\r\nIn [1]: import fsspec                                                                                                                                                                                              \r\n\r\nIn [2]: memfs = fsspec.filesystem(\"memory\")                                                                                                                                                                        \r\n\r\nIn [3]: memfs.mkdir(\"src\")                                                                                                                                                                                         \r\n\r\nIn [4]: memfs.touch(\"src/file.txt\")                                                                                                                                                                                \r\n\r\nIn [5]: memfs.mv(\"src\", \"dest\")                                                                                                                                                                                    \r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-5-2fbbb45834de> in <module>\r\n----> 1 memfs.mv(\"src\", \"dest\")\r\n\r\n~/scipy/repos/filesystem_spec/fsspec/spec.py in mv(self, path1, path2, **kwargs)\r\n    668     def mv(self, path1, path2, **kwargs):\r\n    669         \"\"\" Move file from one location to another \"\"\"\r\n--> 670         self.copy(path1, path2, **kwargs)\r\n    671         self.rm(path1, recursive=False)\r\n    672 \r\n\r\n~/scipy/repos/filesystem_spec/fsspec/implementations/memory.py in copy(self, path1, path2, **kwargs)\r\n    129 \r\n    130     def copy(self, path1, path2, **kwargs):\r\n--> 131         self.store[path2] = MemoryFile(self, path2, self.store[path1].getbuffer())\r\n    132 \r\n    133     def cat(self, path):\r\n\r\nKeyError: 'src'\r\n\r\nIn [6]: memfs.info(\"src\")                                                                                                                                                                                          \r\nOut[6]: {'name': 'src/', 'size': 0, 'type': 'directory'}\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/314", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/314/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/314/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/314/events", "html_url": "https://github.com/intake/filesystem_spec/issues/314", "id": 636117276, "node_id": "MDU6SXNzdWU2MzYxMTcyNzY=", "number": 314, "title": "In-memory filesystem rmdir raises FileNotFoundError if directory has nested directories", "user": {"login": "jorisvandenbossche", "id": 1020496, "node_id": "MDQ6VXNlcjEwMjA0OTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorisvandenbossche", "html_url": "https://github.com/jorisvandenbossche", "followers_url": "https://api.github.com/users/jorisvandenbossche/followers", "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}", "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions", "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs", "repos_url": "https://api.github.com/users/jorisvandenbossche/repos", "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}", "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-10T10:05:24Z", "updated_at": "2020-06-10T15:58:52Z", "closed_at": "2020-06-10T15:58:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "`memfs.rmdir(\"directory\")` fails while `memfs.info(\"directory\")` confirms it is a directory:\r\n\r\n\r\n```\r\nIn [1]: import fsspec\r\n\r\nIn [2]: memfs = fsspec.filesystem(\"memory\")                                                                                                                                                                        \r\n\r\nIn [3]: memfs.mkdir(\"directory/nested\")                                                                                                                                                                            \r\n\r\nIn [4]: memfs.info(\"directory\")                                                                                                                                                                                    \r\nOut[4]: {'name': 'directory', 'size': 0, 'type': 'directory'}\r\n\r\nIn [5]: memfs.rmdir(\"directory\")                                                                                                                                                                                   \r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n<ipython-input-5-891b93ee53ba> in <module>\r\n----> 1 memfs.rmdir(\"directory\")\r\n\r\n~/miniconda3/envs/arrow-dev/lib/python3.7/site-packages/fsspec/implementations/memory.py in rmdir(self, path)\r\n     94                 raise OSError(\"Directory %s not empty\" % path)\r\n     95         else:\r\n---> 96             raise FileNotFoundError(path)\r\n     97 \r\n     98     def exists(self, path):\r\n\r\nFileNotFoundError: directory\r\n\r\nIn [6]: memfs.rm(\"directory\", recursive=True)                                                                                                                                                                      \r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n<ipython-input-6-029624932829> in <module>\r\n----> 1 memfs.rm(\"directory\", recursive=True)\r\n\r\n~/miniconda3/envs/arrow-dev/lib/python3.7/site-packages/fsspec/spec.py in rm(self, path, recursive, maxdepth)\r\n    700                         fn = \"/\".join([pa_, name]) if pa_ else name\r\n    701                         self.rm(fn)\r\n--> 702                     self.rmdir(pa_)\r\n    703             else:\r\n    704                 self._rm(p)\r\n\r\n~/miniconda3/envs/arrow-dev/lib/python3.7/site-packages/fsspec/implementations/memory.py in rmdir(self, path)\r\n     94                 raise OSError(\"Directory %s not empty\" % path)\r\n     95         else:\r\n---> 96             raise FileNotFoundError(path)\r\n     97 \r\n     98     def exists(self, path):\r\n\r\nFileNotFoundError: directory\r\n```\r\n\r\nUsing fsspec 0.7.4 (current latest version)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/313", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/313/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/313/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/313/events", "html_url": "https://github.com/intake/filesystem_spec/issues/313", "id": 636115087, "node_id": "MDU6SXNzdWU2MzYxMTUwODc=", "number": 313, "title": "In-memory filesystem mkdir unexpected argument \"create_parents\"", "user": {"login": "jorisvandenbossche", "id": 1020496, "node_id": "MDQ6VXNlcjEwMjA0OTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1020496?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jorisvandenbossche", "html_url": "https://github.com/jorisvandenbossche", "followers_url": "https://api.github.com/users/jorisvandenbossche/followers", "following_url": "https://api.github.com/users/jorisvandenbossche/following{/other_user}", "gists_url": "https://api.github.com/users/jorisvandenbossche/gists{/gist_id}", "starred_url": "https://api.github.com/users/jorisvandenbossche/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jorisvandenbossche/subscriptions", "organizations_url": "https://api.github.com/users/jorisvandenbossche/orgs", "repos_url": "https://api.github.com/users/jorisvandenbossche/repos", "events_url": "https://api.github.com/users/jorisvandenbossche/events{/privacy}", "received_events_url": "https://api.github.com/users/jorisvandenbossche/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-10T10:02:06Z", "updated_at": "2020-06-10T15:58:52Z", "closed_at": "2020-06-10T15:58:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Ran into this error, where it seems the alias expects `mkdir` to have a `create_parents` keyword (which is indeed expected according to the base class spec):\r\n\r\n```\r\nIn [1]: import fsspec                                                                                                                                                                                              \r\n\r\nIn [2]: memfs = fsspec.filesystem(\"memory\")                                                                                                                                                                        \r\n\r\nIn [3]: memfs.makedir(\"directory\")                                                                                                                                                                                 \r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-4c50bc902c83> in <module>\r\n----> 1 memfs.makedir(\"directory\")\r\n\r\n~/miniconda3/envs/arrow-dev/lib/python3.7/site-packages/fsspec/spec.py in makedir(self, path, create_parents, **kwargs)\r\n    935     def makedir(self, path, create_parents=True, **kwargs):\r\n    936         \"\"\"Alias of :ref:`FilesystemSpec.mkdir`.\"\"\"\r\n--> 937         return self.mkdir(path, create_parents=create_parents, **kwargs)\r\n    938 \r\n    939     def mkdirs(self, path, exist_ok=False):\r\n\r\nTypeError: mkdir() got an unexpected keyword argument 'create_parents'\r\n```\r\n\r\nUsing fsspec 0.7.4 (current latest version)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/311", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/311/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/311/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/311/events", "html_url": "https://github.com/intake/filesystem_spec/issues/311", "id": 635728646, "node_id": "MDU6SXNzdWU2MzU3Mjg2NDY=", "number": 311, "title": "open_local always fails on first call but loads on following calls", "user": {"login": "eric-czech", "id": 6130352, "node_id": "MDQ6VXNlcjYxMzAzNTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6130352?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eric-czech", "html_url": "https://github.com/eric-czech", "followers_url": "https://api.github.com/users/eric-czech/followers", "following_url": "https://api.github.com/users/eric-czech/following{/other_user}", "gists_url": "https://api.github.com/users/eric-czech/gists{/gist_id}", "starred_url": "https://api.github.com/users/eric-czech/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eric-czech/subscriptions", "organizations_url": "https://api.github.com/users/eric-czech/orgs", "repos_url": "https://api.github.com/users/eric-czech/repos", "events_url": "https://api.github.com/users/eric-czech/events{/privacy}", "received_events_url": "https://api.github.com/users/eric-czech/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-09T20:18:04Z", "updated_at": "2020-06-10T15:05:10Z", "closed_at": "2020-06-10T15:05:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am seeing this same behavior with a variety of public GCS files (of varying sizes) where the first call to `open_local` fails 100% of the time and subsequent calls *almost* always succeed.  Sometimes they fail as well, but either way I have yet to see one case where changing `cache_storage` in this example doesn't then cause an error on the following run of the same code:\r\n\r\n```python\r\nimport fsspec\r\nfsspec.open_local(\r\n  'simplecache::gs://public-data-source/README.md', \r\n  simplecache={'cache_storage': '/tmp/cache'}, \r\n  gcs={'anon': True}\r\n)\r\n_call non-retriable exception: \r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/gcsfs/core.py\", line 487, in _call\r\n    validate_response(r, path)\r\n  File \"/opt/conda/lib/python3.7/site-packages/gcsfs/core.py\", line 132, in validate_response\r\n    raise HttpError({\"code\": r.status_code})\r\ngcsfs.utils.HttpError\r\n```\r\n<details>\r\n<summary>Full Trace</summary>\r\n_call non-retriable exception: \r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.7/site-packages/gcsfs/core.py\", line 487, in _call\r\n    validate_response(r, path)\r\n  File \"/opt/conda/lib/python3.7/site-packages/gcsfs/core.py\", line 132, in validate_response\r\n    raise HttpError({\"code\": r.status_code})\r\ngcsfs.utils.HttpError\r\n---------------------------------------------------------------------------\r\nHttpError                                 Traceback (most recent call last)\r\n<ipython-input-67-6101ab786208> in <module>\r\n      1 #%%debug\r\n      2 url = 'simplecache::gs://public-data-source/README.md'\r\n----> 3 fsspec.open_local(url, simplecache={'cache_storage': '/tmp/cache7'}, gcs={'anon': True})\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/core.py in open_local(url, mode, **storage_options)\r\n    397         raise ValueError(\"Can only ensure local files when reading\")\r\n    398     of = open_files(url, mode=mode, **storage_options)\r\n--> 399     paths = [f.open().name for f in of]\r\n    400     if isinstance(url, str) and \"*\" not in url:\r\n    401         return paths[0]\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/core.py in <listcomp>(.0)\r\n    397         raise ValueError(\"Can only ensure local files when reading\")\r\n    398     of = open_files(url, mode=mode, **storage_options)\r\n--> 399     paths = [f.open().name for f in of]\r\n    400     if isinstance(url, str) and \"*\" not in url:\r\n    401         return paths[0]\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/core.py in open(self)\r\n    130         been deleted; but a with-context is better style.\r\n    131         \"\"\"\r\n--> 132         out = self.__enter__()\r\n    133         closer = out.close\r\n    134         fobjects = self.fobjects.copy()[:-1]\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/core.py in __enter__(self)\r\n     98         mode = self.mode.replace(\"t\", \"\").replace(\"b\", \"\") + \"b\"\r\n     99 \r\n--> 100         f = self.fs.open(self.path, mode=mode)\r\n    101 \r\n    102         self.fobjects = [f]\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/implementations/cached.py in <lambda>(*args, **kw)\r\n    314             # all the methods defined in this class. Note `open` here, since\r\n    315             # it calls `_open`, but is actually in superclass\r\n--> 316             return lambda *args, **kw: getattr(type(self), item)(self, *args, **kw)\r\n    317         if item in [\"__reduce_ex__\"]:\r\n    318             raise AttributeError\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/spec.py in open(self, path, mode, block_size, cache_options, **kwargs)\r\n    773                 autocommit=ac,\r\n    774                 cache_options=cache_options,\r\n--> 775                 **kwargs\r\n    776             )\r\n    777             if not ac:\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/implementations/cached.py in <lambda>(*args, **kw)\r\n    314             # all the methods defined in this class. Note `open` here, since\r\n    315             # it calls `_open`, but is actually in superclass\r\n--> 316             return lambda *args, **kw: getattr(type(self), item)(self, *args, **kw)\r\n    317         if item in [\"__reduce_ex__\"]:\r\n    318             raise AttributeError\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/implementations/cached.py in _open(self, path, mode, **kwargs)\r\n    495                 data = True\r\n    496                 while data:\r\n--> 497                     data = f.read(f.blocksize)\r\n    498                     f2.write(data)\r\n    499             else:\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/spec.py in read(self, length)\r\n   1237             # don't even bother calling fetch\r\n   1238             return b\"\"\r\n-> 1239         out = self.cache._fetch(self.loc, self.loc + length)\r\n   1240         self.loc += len(out)\r\n   1241         return out\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/caching.py in _fetch(self, start, end)\r\n     30 \r\n     31     def _fetch(self, start, end):\r\n---> 32         return self.fetcher(start, end)\r\n     33 \r\n     34     def __getitem__(self, item: slice):\r\n\r\n/opt/conda/lib/python3.7/site-packages/gcsfs/core.py in _fetch_range(self, start, end)\r\n   1213             head = None\r\n   1214         try:\r\n-> 1215             r = self.gcsfs._call(\"GET\", self.details[\"mediaLink\"], headers=head)\r\n   1216             data = r.content\r\n   1217             return data\r\n\r\n/opt/conda/lib/python3.7/site-packages/gcsfs/core.py in _call(self, method, path, *args, **kwargs)\r\n    502                     continue\r\n    503                 logger.exception(\"_call non-retriable exception: %s\", e)\r\n--> 504                 raise e\r\n    505 \r\n    506         return r\r\n\r\n/opt/conda/lib/python3.7/site-packages/gcsfs/core.py in _call(self, method, path, *args, **kwargs)\r\n    485                     timeout=self.requests_timeout,\r\n    486                 )\r\n--> 487                 validate_response(r, path)\r\n    488                 break\r\n    489             except (HttpError, RequestException, GoogleAuthError) as e:\r\n\r\n/opt/conda/lib/python3.7/site-packages/gcsfs/core.py in validate_response(r, path)\r\n    130             raise HttpError(error)\r\n    131         elif r.status_code:\r\n--> 132             raise HttpError({\"code\": r.status_code})\r\n    133         else:\r\n    134             raise RuntimeError(m)\r\n\r\nHttpError: \r\n</details>\r\n\r\nThen on the next run:\r\n\r\n```python\r\nfsspec.open_local(\r\n  'simplecache::gs://public-data-source/README.md', \r\n  simplecache={'cache_storage': '/tmp/cache'}, \r\n  gcs={'anon': True}\r\n)\r\n> /tmp/cache7/e765909a3e2d87ed1557be40d63eb40b0070a7f234b4b9b626a965598c8ad286\r\n```\r\n\r\nWhen I switch to `filecache` (and change `cache_storage` to a different directory entirely), I see the same behavior except that it often fails on subsequent runs too if I wait ~10 seconds or so.\r\n\r\nAny idea what's going on here?\r\n\r\n----\r\n#### Environment\r\n\r\n```bash\r\n> conda list | grep 'fsspec\\|gcsfs'\r\nfsspec                    0.7.4                      py_0    conda-forge\r\ngcsfs                     0.6.2                      py_0    conda-forge\r\n> python --version\r\nPython 3.7.6\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/306", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/306/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/306/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/306/events", "html_url": "https://github.com/intake/filesystem_spec/issues/306", "id": 626523897, "node_id": "MDU6SXNzdWU2MjY1MjM4OTc=", "number": 306, "title": "samba backend", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-28T13:48:43Z", "updated_at": "2020-07-02T15:03:06Z", "closed_at": "2020-07-02T15:03:06Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://pysmb.readthedocs.io/en/latest/api/smb_SMBConnection.html appears to give a very thorough understandable interface to Samba for us to wrap, with random access. We can easily test these using one of the docker-based samba servers.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/303", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/303/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/303/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/303/events", "html_url": "https://github.com/intake/filesystem_spec/issues/303", "id": 624495649, "node_id": "MDU6SXNzdWU2MjQ0OTU2NDk=", "number": 303, "title": "open and filesystem.open don't match ", "user": {"login": "limx0", "id": 4816153, "node_id": "MDQ6VXNlcjQ4MTYxNTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/4816153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/limx0", "html_url": "https://github.com/limx0", "followers_url": "https://api.github.com/users/limx0/followers", "following_url": "https://api.github.com/users/limx0/following{/other_user}", "gists_url": "https://api.github.com/users/limx0/gists{/gist_id}", "starred_url": "https://api.github.com/users/limx0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/limx0/subscriptions", "organizations_url": "https://api.github.com/users/limx0/orgs", "repos_url": "https://api.github.com/users/limx0/repos", "events_url": "https://api.github.com/users/limx0/events{/privacy}", "received_events_url": "https://api.github.com/users/limx0/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-25T21:42:54Z", "updated_at": "2020-05-27T22:33:20Z", "closed_at": "2020-05-26T13:34:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi, \r\n\r\nI kept hitting a `TypeError: 'LocalFileOpener' object is not iterable` when trying to iterate over the lines in a file when I came across the fact that `open` and `filesystem.open` don't seem to match. \r\nSimple example:\r\n\r\n```python\r\n# Write some test data\r\nwith open('test.txt', 'wb') as f:\r\n    f.writelines([b'a\\n', b'b\\n', b'c\\n'])\r\n\r\n# Open with filesystem.open, works as expected\r\nof = fsspec.filesystem('file').open('file://test.txt')\r\nwith of as f:\r\n    for line in f:\r\n        print(line)\r\n\r\n# Open with `open`, throws a TypeError: 'LocalFileOpener' object is not iterable\r\nof = fsspec.open('file://test.txt')\r\nwith of as f:\r\n    for line in f:\r\n        print(line)\r\n```\r\n\r\nIs this expected? I've been iterating over lines with the memory and s3fs filesystems without issue\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/300", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/300/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/300/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/300/events", "html_url": "https://github.com/intake/filesystem_spec/issues/300", "id": 622056306, "node_id": "MDU6SXNzdWU2MjIwNTYzMDY=", "number": 300, "title": "LocalFileSystem recursion error on open file depickle", "user": {"login": "ahirner", "id": 6055037, "node_id": "MDQ6VXNlcjYwNTUwMzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/6055037?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahirner", "html_url": "https://github.com/ahirner", "followers_url": "https://api.github.com/users/ahirner/followers", "following_url": "https://api.github.com/users/ahirner/following{/other_user}", "gists_url": "https://api.github.com/users/ahirner/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahirner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahirner/subscriptions", "organizations_url": "https://api.github.com/users/ahirner/orgs", "repos_url": "https://api.github.com/users/ahirner/repos", "events_url": "https://api.github.com/users/ahirner/events{/privacy}", "received_events_url": "https://api.github.com/users/ahirner/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-20T20:15:52Z", "updated_at": "2020-05-21T13:11:24Z", "closed_at": "2020-05-21T13:11:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "`fsspec==0.7.4`\r\n`distributed==2.6.0`\r\n`cloudpickle==1.4.1`\r\n## Repro\r\n```python\r\nfrom dask.distributed import Client\r\nfrom fsspec.implementations.local import LocalFileSystem\r\n\r\ndef dump(f):\r\n   with f:\r\n       r = f.read()\r\n   print(r)\r\n   return r\r\n\r\ndef main():\r\n    with open(\"f.bin\", \"wb\") as f:\r\n        f.write(b\"1234\")\r\n\r\n    fs = LocalFileSystem(\"./\")\r\n    f = fs.open(\"f.bin\", \"rb\")\r\n\r\n    with Client() as c:\r\n        ff = c.map(dump, [f]*10)\r\n        rr = c.gather(ff)\r\n        c.close()\r\n\r\n    print(\"rr\", rr)\r\n\r\nif __name__==\"__main__\":\r\n    main()\r\n```\r\n## Error\r\n```\r\ndistributed.worker - WARNING - Could not deserialize task\r\nTraceback (most recent call last):\r\n  File \"~/miniconda3/lib/python3.6/site-packages/distributed/worker.py\", line 2340, in _maybe_deserialize_task\r\n    function, args, kwargs = _deserialize(*self.tasks[key])\r\n  File \"~/miniconda3/lib/python3.6/site-packages/distributed/worker.py\", line 3132, in _deserialize\r\n    args = pickle.loads(args)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/distributed/protocol/pickle.py\", line 59, in loads\r\n    return pickle.loads(x)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/fsspec/implementations/local.py\", line 214, in __setstate__\r\n    loc = self.state.pop(\"loc\")\r\n  File \"~/miniconda3/lib/python3.6/site-packages/fsspec/implementations/local.py\", line 246, in __getattr__\r\n    return getattr(self.f, item)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/fsspec/implementations/local.py\", line 246, in __getattr__\r\n    return getattr(self.f, item)\r\n  File \"~/miniconda3/lib/python3.6/site-packages/fsspec/implementations/local.py\", line 246, in __getattr__\r\n    return getattr(self.f, item)\r\n  [Previous line repeated 320 more times]\r\nRecursionError: maximum recursion depth exceeded~\r\n```\r\n## Expected\r\nHopefully this is case is not beyond the spec of fsspec. Since all pickle relevant methods are so well thought through I'd be happy if this works out.\r\nI think `self.f` should be set at depickling time and hence there should not be recursion... yet there is.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/293", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/293/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/293/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/293/events", "html_url": "https://github.com/intake/filesystem_spec/issues/293", "id": 614092333, "node_id": "MDU6SXNzdWU2MTQwOTIzMzM=", "number": 293, "title": "Provide an explicit way to register a protocol", "user": {"login": "tebeka", "id": 87697, "node_id": "MDQ6VXNlcjg3Njk3", "avatar_url": "https://avatars1.githubusercontent.com/u/87697?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tebeka", "html_url": "https://github.com/tebeka", "followers_url": "https://api.github.com/users/tebeka/followers", "following_url": "https://api.github.com/users/tebeka/following{/other_user}", "gists_url": "https://api.github.com/users/tebeka/gists{/gist_id}", "starred_url": "https://api.github.com/users/tebeka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tebeka/subscriptions", "organizations_url": "https://api.github.com/users/tebeka/orgs", "repos_url": "https://api.github.com/users/tebeka/repos", "events_url": "https://api.github.com/users/tebeka/events{/privacy}", "received_events_url": "https://api.github.com/users/tebeka/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2020-05-07T14:15:05Z", "updated_at": "2020-05-21T15:58:13Z", "closed_at": "2020-05-18T15:09:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm working on a [v3io driver](https://github.com/v3io/v3io-fs) for fsspec.\r\nI can't find a way to register the `v3io` protocol, currently I'm doing\r\n```python\r\nfrom fsspec.registry import known_implementations\r\n\r\nknown_implementations[V3ioFS.protocol] = {\r\n     'class': 'v3iofs.V3ioFS',\r\n}\r\n```\r\n\r\nWhich is  seems like working with internal implementaion detilas.\r\n\r\nI suggest adding `register_protocol(protocol: str, cls: type)` function that will allow implementations to register their protocol. I should probably raise an error if the protocol is already registered.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/286", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/286/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/286/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/286/events", "html_url": "https://github.com/intake/filesystem_spec/issues/286", "id": 606019293, "node_id": "MDU6SXNzdWU2MDYwMTkyOTM=", "number": 286, "title": "multiple zarr files + fsspec.get_mapper", "user": {"login": "Mikejmnez", "id": 8241481, "node_id": "MDQ6VXNlcjgyNDE0ODE=", "avatar_url": "https://avatars3.githubusercontent.com/u/8241481?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mikejmnez", "html_url": "https://github.com/Mikejmnez", "followers_url": "https://api.github.com/users/Mikejmnez/followers", "following_url": "https://api.github.com/users/Mikejmnez/following{/other_user}", "gists_url": "https://api.github.com/users/Mikejmnez/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mikejmnez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mikejmnez/subscriptions", "organizations_url": "https://api.github.com/users/Mikejmnez/orgs", "repos_url": "https://api.github.com/users/Mikejmnez/repos", "events_url": "https://api.github.com/users/Mikejmnez/events{/privacy}", "received_events_url": "https://api.github.com/users/Mikejmnez/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-24T03:51:13Z", "updated_at": "2020-07-02T15:03:06Z", "closed_at": "2020-07-02T15:03:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a sequence of zarr files distributed across different nodes that I want to read in parallel, while only providing a string (glob-like) path.\r\n\r\n**The behavior I want to emulate:**\r\nFor netcdf-files, we can do this using \r\n```\r\nurl = fsspec.open_local(paths)\r\n```\r\nwhere paths is given by\r\n```\r\npaths= '/directoryA/*/subdirectoryB/*.nc'\r\n```\r\nsuch that \r\n``\r\nlen(glob(paths)) = len(url)\r\n``\r\ne.g. 5 (5 nc-files distributed on different directories).  The ```url``` is then used as an argument for ```xarray.open_mfdataset```\r\n\r\n**The problem**\r\nzarr files open with a mapper (``url=fsspec.get_mapper(paths)`` with url as an argument to ```xarray.open_zarr```),  and a glob-like path does not work as nicely (compact) as it does with ```fsspec.open_local() ``` and nc-files. That is, given\r\n\r\n```\r\npaths= '/directoryA/*/subdirectoryB/*'\r\n```\r\n(where the zarr stores appear as directories) we get\r\n```\r\nlen(fsspec.get_mapper(paths))=0\r\n```\r\nIf you just try, the right hand side is zero, while the LHS > 0. \r\n\r\nA solution to the problem is to just pass the ```glob-like``` path directly to ```_open_zarr``` (with proper modifications to ```_open_zarr``` function much like ```xarray.open_mfdataset```). I am just wondering if  ```fsspec.get_mapper(paths)``` can take a glob-like path string and I just haven't figured out yet how...\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/285", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/285/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/285/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/285/events", "html_url": "https://github.com/intake/filesystem_spec/issues/285", "id": 605908262, "node_id": "MDU6SXNzdWU2MDU5MDgyNjI=", "number": 285, "title": "Cache chaining fails with recent s3fs", "user": {"login": "ian-r-rose", "id": 5728311, "node_id": "MDQ6VXNlcjU3MjgzMTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/5728311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ian-r-rose", "html_url": "https://github.com/ian-r-rose", "followers_url": "https://api.github.com/users/ian-r-rose/followers", "following_url": "https://api.github.com/users/ian-r-rose/following{/other_user}", "gists_url": "https://api.github.com/users/ian-r-rose/gists{/gist_id}", "starred_url": "https://api.github.com/users/ian-r-rose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ian-r-rose/subscriptions", "organizations_url": "https://api.github.com/users/ian-r-rose/orgs", "repos_url": "https://api.github.com/users/ian-r-rose/repos", "events_url": "https://api.github.com/users/ian-r-rose/events{/privacy}", "received_events_url": "https://api.github.com/users/ian-r-rose/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-23T22:13:56Z", "updated_at": "2020-04-24T17:59:36Z", "closed_at": "2020-04-24T17:59:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I ran into this problem with using the `WholeFileCacheFileSystem` chained with s3. The more recent versions s3fs have a list of protocols: `[\"s3\", \"s3a\"]`, but `fsspec` expects the protocol attribute to be a string.\r\n\r\nSo using `s3fs` 3.5, the following succeeds:\r\n```python\r\nimport fsspec\r\nfrom fsspec.implementations.cached import WholeFileCacheFileSystem\r\n\r\ntarget = fsspec.filesystem(\"s3\", anon=True)\r\nfs = WholeFileCacheFileSystem(fs=target)\r\nfs.open(\"s3://landsat-pds/scene_list.gz\")\r\n```\r\nBut using `s3fs` version 0.4.2 it produces the following error:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"test_s3_chain.py\", line 6, in <module>\r\n    fs.open(\"s3://landsat-pds/scene_list.gz\")\r\n  File \"/home/ian/miniconda3/lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 299, in <lambda>\r\n    return lambda *args, **kw: getattr(type(self), item)(self, *args, **kw)\r\n  File \"/home/ian/miniconda3/lib/python3.7/site-packages/fsspec/spec.py\", line 775, in open\r\n    **kwargs\r\n  File \"/home/ian/miniconda3/lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 299, in <lambda>\r\n    return lambda *args, **kw: getattr(type(self), item)(self, *args, **kw)\r\n  File \"/home/ian/miniconda3/lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 351, in _open\r\n    if not path.startswith(self.target_protocol):\r\nTypeError: startswith first arg must be str or a tuple of str, not list\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/283", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/283/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/283/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/283/events", "html_url": "https://github.com/intake/filesystem_spec/issues/283", "id": 604729162, "node_id": "MDU6SXNzdWU2MDQ3MjkxNjI=", "number": 283, "title": "LocalFileSystem.glob does not pass kwargs to super().glob", "user": {"login": "masda70", "id": 3266573, "node_id": "MDQ6VXNlcjMyNjY1NzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/3266573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/masda70", "html_url": "https://github.com/masda70", "followers_url": "https://api.github.com/users/masda70/followers", "following_url": "https://api.github.com/users/masda70/following{/other_user}", "gists_url": "https://api.github.com/users/masda70/gists{/gist_id}", "starred_url": "https://api.github.com/users/masda70/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/masda70/subscriptions", "organizations_url": "https://api.github.com/users/masda70/orgs", "repos_url": "https://api.github.com/users/masda70/repos", "events_url": "https://api.github.com/users/masda70/events{/privacy}", "received_events_url": "https://api.github.com/users/masda70/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-22T12:46:07Z", "updated_at": "2020-07-02T18:59:35Z", "closed_at": "2020-07-02T18:59:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I want to pass `detail=True` to `LocalFileSystem.glob`, but this is not currently possible. I think simply passing **kwargs to `super().glob` would suffice.\r\n\r\nhttps://github.com/intake/filesystem_spec/blob/4decaca5ef743e5065aa9350d79e78547999b9a2/fsspec/implementations/local.py#L52", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/280", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/280/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/280/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/280/events", "html_url": "https://github.com/intake/filesystem_spec/issues/280", "id": 602907598, "node_id": "MDU6SXNzdWU2MDI5MDc1OTg=", "number": 280, "title": "Feature request: Share point", "user": {"login": "raybellwaves", "id": 17162724, "node_id": "MDQ6VXNlcjE3MTYyNzI0", "avatar_url": "https://avatars0.githubusercontent.com/u/17162724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/raybellwaves", "html_url": "https://github.com/raybellwaves", "followers_url": "https://api.github.com/users/raybellwaves/followers", "following_url": "https://api.github.com/users/raybellwaves/following{/other_user}", "gists_url": "https://api.github.com/users/raybellwaves/gists{/gist_id}", "starred_url": "https://api.github.com/users/raybellwaves/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/raybellwaves/subscriptions", "organizations_url": "https://api.github.com/users/raybellwaves/orgs", "repos_url": "https://api.github.com/users/raybellwaves/repos", "events_url": "https://api.github.com/users/raybellwaves/events{/privacy}", "received_events_url": "https://api.github.com/users/raybellwaves/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-20T03:16:51Z", "updated_at": "2020-07-31T20:54:43Z", "closed_at": "2020-07-31T20:54:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "I believe there is a package for getting data in/out of share point https://github.com/ox-it/python-sharepoint could create a fsspec version of it", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/277", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/277/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/277/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/277/events", "html_url": "https://github.com/intake/filesystem_spec/issues/277", "id": 601648218, "node_id": "MDU6SXNzdWU2MDE2NDgyMTg=", "number": 277, "title": "numpy slice assignment failing on `readinto`", "user": {"login": "JacksonMaxfield", "id": 17132317, "node_id": "MDQ6VXNlcjE3MTMyMzE3", "avatar_url": "https://avatars2.githubusercontent.com/u/17132317?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JacksonMaxfield", "html_url": "https://github.com/JacksonMaxfield", "followers_url": "https://api.github.com/users/JacksonMaxfield/followers", "following_url": "https://api.github.com/users/JacksonMaxfield/following{/other_user}", "gists_url": "https://api.github.com/users/JacksonMaxfield/gists{/gist_id}", "starred_url": "https://api.github.com/users/JacksonMaxfield/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JacksonMaxfield/subscriptions", "organizations_url": "https://api.github.com/users/JacksonMaxfield/orgs", "repos_url": "https://api.github.com/users/JacksonMaxfield/repos", "events_url": "https://api.github.com/users/JacksonMaxfield/events{/privacy}", "received_events_url": "https://api.github.com/users/JacksonMaxfield/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-17T01:59:45Z", "updated_at": "2020-04-17T19:25:08Z", "closed_at": "2020-04-17T19:25:08Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`readinto` failing to perform slice assignment:\r\n\r\n```\r\n~/active/cell/filesystem_spec/fsspec/spec.py in readinto(self, b)\r\n   1249         # for i in range(len(data)):\r\n   1250         #     b[i] = data[i]\r\n-> 1251         b[: len(data)] = data\r\n   1252         return len(data)\r\n   1253 \r\n\r\nValueError: invalid literal for int() with base 10: ''\r\n```\r\n\r\n**`fsspec` version:** 0.7.2\r\n\r\n**Context:**\r\nI am one of the developers for [`aicsimageio`](https://github.com/AllenCellModeling/aicsimageio), relevant to this issue is the fact that we use delayed dask arrays to read microscopy images, but as a part of that we support very large files (usually this means >200GB). We natively support handing in `str` and `Path` to the `AICSImage` object as one would expect and I was in the process of extending support to reading from `S3File` or really, _any_ `fsspec` file like object.\r\n\r\nBear with me...\r\n**Commands for reproduction setup:**\r\n```bash\r\ngit clone git@github.com:AllenCellModeling/aicsimageio.git\r\ncd aicsimageio\r\ngit checkout feature/support-s3-file\r\npip install -e .\r\npython\r\n```\r\n\r\n(The above was done in a conda environment on python 3.7)\r\n\r\n**Commands to reproduce:**\r\n```python\r\nfrom aicsimageio import AICSImage\r\nfrom s3fs import S3File, S3FileSystem\r\nfs = S3FileSystem(anon=True)\r\nf = S3File(fs, \"allencell/aics/pipeline_integrated_single_cell/cell_images_3d/00001bb5_16872_35317_reg.tiff\")\r\nimg = AICSImage(f)\r\nprint(img.shape)\r\n```\r\n\r\n**Traceback:**\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/maxfield/active/cell/aicsimageio/aicsimageio/aics_image.py\", line 207, in shape\r\n    return self.size()\r\n  File \"/home/maxfield/active/cell/aicsimageio/aicsimageio/aics_image.py\", line 197, in size\r\n    return tuple([self.dask_data.shape[self.dims.index(dim)] for dim in dims])\r\n  File \"/home/maxfield/active/cell/aicsimageio/aicsimageio/aics_image.py\", line 197, in <listcomp>\r\n    return tuple([self.dask_data.shape[self.dims.index(dim)] for dim in dims])\r\n  File \"/home/maxfield/active/cell/aicsimageio/aicsimageio/aics_image.py\", line 152, in dask_data\r\n    reader_data = self.reader.dask_data\r\n  File \"/home/maxfield/active/cell/aicsimageio/aicsimageio/readers/tiff_reader.py\", line 176, in dask_data\r\n    self._dask_data = self._construct_dask_array(self._file, tiff)\r\n  File \"/home/maxfield/active/cell/aicsimageio/aicsimageio/readers/tiff_reader.py\", line 128, in _construct_dask_array\r\n    sample = scenes[0].pages[0].asarray()\r\n  File \"/home/maxfield/miniconda3/envs/aicsimageio-test/lib/python3.7/site-packages/tifffile/tifffile.py\", line 4587, in asarray\r\n    out=out\r\n  File \"/home/maxfield/miniconda3/envs/aicsimageio-test/lib/python3.7/site-packages/tifffile/tifffile.py\", line 6400, in read_array\r\n    n = fh.readinto(result)\r\n  File \"/home/maxfield/miniconda3/envs/aicsimageio-test/lib/python3.7/site-packages/fsspec/spec.py\", line 1241, in readinto\r\n    b[: len(data)] = data\r\nValueError: invalid literal for int() with base 10: ''\r\n```\r\n\r\n**Comments:**\r\nFrom some debugging, if we ignore all the `aicsimageio` reader code, the ultimate error that occurs occurs during the slice assignment in `readinto`. This same file, which can be downloaded [here](https://open.quiltdata.com/b/allencell/tree/aics/pipeline_integrated_single_cell/cell_images_3d/00001bb5_16872_35317_reg.tiff), (or with any other S3 downloader), can be read in to `AICSImage` just fine as a `str` or `Path` so it seems to be this slice assignment operation. I found what I would consider a really weird (and not optimal) but working solution of replacing the slice assignment with a simple loop and single item assignment: [link](https://github.com/intake/filesystem_spec/blob/master/fsspec/spec.py#L1243)\r\n```python\r\ndef readinto(self, b):\r\n    \"\"\"mirrors builtin file's readinto method\r\n\r\n    https://docs.python.org/3/library/io.html#io.RawIOBase.readinto\r\n    \"\"\"\r\n    data = self.read(len(b))\r\n    for i in range(len(data)):\r\n        b[i] = data[i]\r\n    # b[: len(data)] = data\r\n    return len(data)\r\n```\r\n\r\nWhich I will be opening a PR with for feedback on how to solve the issue in a more optimized fashion.\r\n\r\nUsing the loop above, the above image reading code now works:\r\n```python\r\nfrom aicsimageio import AICSImage\r\nfrom s3fs import S3File, S3FileSystem\r\nfs = S3FileSystem(anon=True)\r\nf = S3File(fs, \"allencell/aics/pipeline_integrated_single_cell/cell_images_3d/00001bb5_16872_35317_reg.tiff\")\r\nimg = AICSImage(f)\r\nprint(img.shape)\r\n```\r\n`(1, 1, 6, 64, 168, 104)`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/272", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/272/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/272/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/272/events", "html_url": "https://github.com/intake/filesystem_spec/issues/272", "id": 597425775, "node_id": "MDU6SXNzdWU1OTc0MjU3NzU=", "number": 272, "title": "setting up a 'filecache' file system to access data from DigitalOcean spaces", "user": {"login": "martibosch", "id": 5831581, "node_id": "MDQ6VXNlcjU4MzE1ODE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5831581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martibosch", "html_url": "https://github.com/martibosch", "followers_url": "https://api.github.com/users/martibosch/followers", "following_url": "https://api.github.com/users/martibosch/following{/other_user}", "gists_url": "https://api.github.com/users/martibosch/gists{/gist_id}", "starred_url": "https://api.github.com/users/martibosch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martibosch/subscriptions", "organizations_url": "https://api.github.com/users/martibosch/orgs", "repos_url": "https://api.github.com/users/martibosch/repos", "events_url": "https://api.github.com/users/martibosch/events{/privacy}", "received_events_url": "https://api.github.com/users/martibosch/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-09T17:04:41Z", "updated_at": "2020-04-10T07:42:07Z", "closed_at": "2020-04-10T07:42:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nI am trying to set up a file system that opens `nc` files with xarray from my DigitalOcean spaces bucket and caches them locally.\r\n\r\nIn order to make fsspec compatible with DigitalOcean, I do the following:\r\n\r\n```python\r\nfrom os import environ\r\n\r\nimport boto3\r\nimport fsspec\r\n\r\nsession = boto3.Session(\r\n    profile_name=environ.get('S3_PROFILE_NAME')\r\n)\r\n```\r\n\r\nso that when I set up a regular s3 file system, e.g.:\r\n\r\n```python\r\nfs = fsspec.filesystem(\r\n    's3',\r\n    session=session._session,\r\n    client_kwargs={'endpoint_url': environ.get('S3_ENDPOINT_URL')},\r\n    cache_storage='foo',\r\n)\r\nfs.ls('my-bucket-name')\r\n```\r\n\r\nI obtain something like:\r\n\r\n```\r\n['my-bucket-name/my-dir-1',\r\n 'my-bucket-name/my-dir-2',\r\n 'my-bucket-name/my-dir-3',\r\n 'my-bucket-name/my-dir-4',\r\n 'my-bucket-name/my-dir-5',\r\n 'my-bucket-name/my-dir-6',\r\n 'my-bucket-name/my-dir-7',\r\n 'my-bucket-name/my-dir-8',\r\n 'my-bucket-name/my-dir-9',\r\n 'my-bucket-name/my-dir-10',\r\n 'my-bucket-name/my-dir-11',\r\n 'my-bucket-name/my-dir-12',\r\n 'my-bucket-name/my-dir-13']\r\n```\r\n\r\nand I can use `fs.open` and successfully open the remote files. Nevertheless, if I try to set up a local cache for my remote s3 as in:\r\n\r\n```python\r\nfs = fsspec.filesystem(\r\n    'filecache',\r\n    target_protocol='s3',\r\n    session=session._session,\r\n    client_kwargs={'endpoint_url': environ.get('S3_ENDPOINT_URL')},\r\n    cache_storage='foo',\r\n)\r\nfs.ls('my-bucket-name')\r\n```\r\n\r\nI then obtain something like:\r\n\r\n```\r\n['my-bucket-name/26',\r\n 'my-bucket-name/29',\r\n 'my-bucket-name/37',\r\n 'my-bucket-name/4a',\r\n 'my-bucket-name/5a',\r\n 'my-bucket-name/61',\r\n 'my-bucket-name/6e',\r\n 'my-bucket-name/72',\r\n 'my-bucket-name/ad',\r\n 'my-bucket-name/b0',\r\n 'my-bucket-name/b3',\r\n 'my-bucket-name/ca',\r\n 'my-bucket-name/e2',\r\n 'my-bucket-name/e4',\r\n 'my-bucket-name/f4',\r\n 'my-bucket-name/f8']\r\n```\r\n\r\nand if I try to open a known path from my remote with `fs.open`, I get a `FileNotFoundError`.\r\n\r\nWhat am I doing wrong? I am sorry to bother you but I have not been able to find many documentation about this.\r\n\r\nThank you in advance,\r\nMart\u00ed", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/265", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/265/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/265/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/265/events", "html_url": "https://github.com/intake/filesystem_spec/issues/265", "id": 592984520, "node_id": "MDU6SXNzdWU1OTI5ODQ1MjA=", "number": 265, "title": "Created / modified timestamps?", "user": {"login": "limx0", "id": 4816153, "node_id": "MDQ6VXNlcjQ4MTYxNTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/4816153?v=4", "gravatar_id": "", "url": "https://api.github.com/users/limx0", "html_url": "https://github.com/limx0", "followers_url": "https://api.github.com/users/limx0/followers", "following_url": "https://api.github.com/users/limx0/following{/other_user}", "gists_url": "https://api.github.com/users/limx0/gists{/gist_id}", "starred_url": "https://api.github.com/users/limx0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/limx0/subscriptions", "organizations_url": "https://api.github.com/users/limx0/orgs", "repos_url": "https://api.github.com/users/limx0/repos", "events_url": "https://api.github.com/users/limx0/events{/privacy}", "received_events_url": "https://api.github.com/users/limx0/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-04-02T23:46:09Z", "updated_at": "2020-04-11T01:31:45Z", "closed_at": "2020-04-11T01:31:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Is there a plan to add/support created/modified timestamps within fsspec? Are there any (known) reasons this could not be implemented?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/255", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/255/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/255/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/255/events", "html_url": "https://github.com/intake/filesystem_spec/issues/255", "id": 587140533, "node_id": "MDU6SXNzdWU1ODcxNDA1MzM=", "number": 255, "title": "Potential bad interaction with zarr and missing chunks", "user": {"login": "alimanfoo", "id": 703554, "node_id": "MDQ6VXNlcjcwMzU1NA==", "avatar_url": "https://avatars1.githubusercontent.com/u/703554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alimanfoo", "html_url": "https://github.com/alimanfoo", "followers_url": "https://api.github.com/users/alimanfoo/followers", "following_url": "https://api.github.com/users/alimanfoo/following{/other_user}", "gists_url": "https://api.github.com/users/alimanfoo/gists{/gist_id}", "starred_url": "https://api.github.com/users/alimanfoo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alimanfoo/subscriptions", "organizations_url": "https://api.github.com/users/alimanfoo/orgs", "repos_url": "https://api.github.com/users/alimanfoo/repos", "events_url": "https://api.github.com/users/alimanfoo/events{/privacy}", "received_events_url": "https://api.github.com/users/alimanfoo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-24T17:24:16Z", "updated_at": "2020-03-27T16:07:30Z", "closed_at": "2020-03-27T16:07:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "We've encountered a situation using zarr on GCS via gcsfs where an attempt to retrieve a chunk object fails for some transient reason, but the fsspec gcsfs mapping raises a KeyError, which zarr interprets as meaning the object doesn't exist. Zarr's default behaviour in that case is to fill the chunk entirely with the fill value set for the array.\r\n\r\nWhat this means is that any transient errors in GCS can result in chunks of an array being returned as filled with the fill value, rather than the actual data, without any error being raised. This is obviously a serious issue.\r\n\r\nCurrently the fsspec `FSMap` class catches any exception within `__getitem__` and reraises as a KeyError: \r\n\r\nhttps://github.com/intake/filesystem_spec/blob/cc7cbc0cc58c96c427708c1e9a98b0d6c99bd1f0/fsspec/mapping.py#L77\r\n\r\nI think this should be modified in some way, such that `FSMap` is able to distinguish between a genuine \"this file/object does not exist\" error and any other kind of error. In the case where a \"this file/object does not exist\" error is encountered, it should be safe to reraise that from `__getitem__` as a `KeyError`, but any other type of error I suggest would be safer to raise either by propagating the underlying error as-is, or by reraising as a `RuntimeError`. This would mean that any transient errors would get propagated all the way up through zarr, preventing any silent replacement of data with fill values.\r\n\r\nFor the time being we have worked around this with a wrapper class that transforms all `KeyError` into `RuntimeError` as [described here](https://nbviewer.jupyter.org/gist/alimanfoo/66d7760440eba981214d483f6d917c79). Note that this only works for the case where we know ahead of time that all chunks of an array should exist, and therefore we never expect to experience a `KeyError` for any reason.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/253", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/253/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/253/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/253/events", "html_url": "https://github.com/intake/filesystem_spec/issues/253", "id": 585656901, "node_id": "MDU6SXNzdWU1ODU2NTY5MDE=", "number": 253, "title": "test_strip_protocol_expanduser assumes home paths", "user": {"login": "QuLogic", "id": 302469, "node_id": "MDQ6VXNlcjMwMjQ2OQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/302469?v=4", "gravatar_id": "", "url": "https://api.github.com/users/QuLogic", "html_url": "https://github.com/QuLogic", "followers_url": "https://api.github.com/users/QuLogic/followers", "following_url": "https://api.github.com/users/QuLogic/following{/other_user}", "gists_url": "https://api.github.com/users/QuLogic/gists{/gist_id}", "starred_url": "https://api.github.com/users/QuLogic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/QuLogic/subscriptions", "organizations_url": "https://api.github.com/users/QuLogic/orgs", "repos_url": "https://api.github.com/users/QuLogic/repos", "events_url": "https://api.github.com/users/QuLogic/events{/privacy}", "received_events_url": "https://api.github.com/users/QuLogic/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-03-22T06:42:45Z", "updated_at": "2020-07-28T15:56:40Z", "closed_at": "2020-07-28T15:56:40Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`test_strip_protocol_expanduser` assumes that `$USER` is part of the path of `$HOME`, but there's no requirement for that to be so.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/249", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/249/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/249/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/249/events", "html_url": "https://github.com/intake/filesystem_spec/issues/249", "id": 583733560, "node_id": "MDU6SXNzdWU1ODM3MzM1NjA=", "number": 249, "title": "CachingFileSystem not thread-safe", "user": {"login": "SeguinBe", "id": 7132817, "node_id": "MDQ6VXNlcjcxMzI4MTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/7132817?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SeguinBe", "html_url": "https://github.com/SeguinBe", "followers_url": "https://api.github.com/users/SeguinBe/followers", "following_url": "https://api.github.com/users/SeguinBe/following{/other_user}", "gists_url": "https://api.github.com/users/SeguinBe/gists{/gist_id}", "starred_url": "https://api.github.com/users/SeguinBe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SeguinBe/subscriptions", "organizations_url": "https://api.github.com/users/SeguinBe/orgs", "repos_url": "https://api.github.com/users/SeguinBe/repos", "events_url": "https://api.github.com/users/SeguinBe/events{/privacy}", "received_events_url": "https://api.github.com/users/SeguinBe/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2020-03-18T13:36:40Z", "updated_at": "2020-03-19T12:40:20Z", "closed_at": "2020-03-19T12:40:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nWonderful library that I start to use extensively!\r\n\r\nMaybe it would be good to specify in the documentation that `CachingFileSystem` is not suited to a concurrent use? It seems to be using temporary file moving which are not atomic operations and fail in a conccurent setting.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/242", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/242/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/242/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/242/events", "html_url": "https://github.com/intake/filesystem_spec/issues/242", "id": 573916009, "node_id": "MDU6SXNzdWU1NzM5MTYwMDk=", "number": 242, "title": "Issue with sftp protocol", "user": {"login": "MarineChap", "id": 34722888, "node_id": "MDQ6VXNlcjM0NzIyODg4", "avatar_url": "https://avatars3.githubusercontent.com/u/34722888?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarineChap", "html_url": "https://github.com/MarineChap", "followers_url": "https://api.github.com/users/MarineChap/followers", "following_url": "https://api.github.com/users/MarineChap/following{/other_user}", "gists_url": "https://api.github.com/users/MarineChap/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarineChap/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarineChap/subscriptions", "organizations_url": "https://api.github.com/users/MarineChap/orgs", "repos_url": "https://api.github.com/users/MarineChap/repos", "events_url": "https://api.github.com/users/MarineChap/events{/privacy}", "received_events_url": "https://api.github.com/users/MarineChap/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-03-02T11:38:43Z", "updated_at": "2020-03-05T15:02:04Z", "closed_at": "2020-03-05T14:56:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello ! \r\nI am trying to use intake with the sftp implementation. \r\n\r\nThe _get_kwargs_from_urls is not correctly selecting the path (by keeping \"/\" in front of the path) making paramiko failed for not finding the file. \r\n\r\nThe bug happen when the urlpath look like this : `ssh://host/path `\r\nthe final path is `/path` instead of `path`. \r\n\r\nIt makes it impossible to use intake catalog with this implementation. \r\n\r\nAlso, the host is mandatory in the urlpath. Is that something wanted ? Why it cannot just be added to to ssh_options ? \r\nDo you think I am correctly setting the path or there is another way that avoid the problem ?\r\n\r\nThank you", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/240", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/240/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/240/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/240/events", "html_url": "https://github.com/intake/filesystem_spec/issues/240", "id": 570754650, "node_id": "MDU6SXNzdWU1NzA3NTQ2NTA=", "number": 240, "title": "Reuse connectionpool in HTTPFileSystem?", "user": {"login": "rabernat", "id": 1197350, "node_id": "MDQ6VXNlcjExOTczNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1197350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rabernat", "html_url": "https://github.com/rabernat", "followers_url": "https://api.github.com/users/rabernat/followers", "following_url": "https://api.github.com/users/rabernat/following{/other_user}", "gists_url": "https://api.github.com/users/rabernat/gists{/gist_id}", "starred_url": "https://api.github.com/users/rabernat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rabernat/subscriptions", "organizations_url": "https://api.github.com/users/rabernat/orgs", "repos_url": "https://api.github.com/users/rabernat/repos", "events_url": "https://api.github.com/users/rabernat/events{/privacy}", "received_events_url": "https://api.github.com/users/rabernat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-25T18:36:41Z", "updated_at": "2020-02-25T19:17:35Z", "closed_at": "2020-02-25T19:17:35Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "This issue originally came up in https://github.com/zarr-developers/zarr-python/issues/536.\r\n\r\n\r\nHTTPFilesystem is slow to fetch many files, because it does not reuse a connectionpool. Example:\r\n\r\n```python\r\nfrom fsspec.implementations.http import HTTPFileSystem\r\nfs = HTTPFileSystem()\r\n\r\nurl_base = 'https://mur-sst.s3.us-west-2.amazonaws.com/zarr/time'\r\ndef get_chunk_fsspec(n):\r\n    return fs.cat(url_base + f'/{n}')\r\n\r\n%prun all_data = [get_chunk_fsspec(i) for i in range(20)]\r\n```\r\nAs you can see, `SSL_do_handshake` is called 20 times and takes most of the time.\r\n\r\n```\r\n         205967 function calls (205947 primitive calls) in 7.177 seconds\r\n\r\n   Ordered by: internal time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n       20    2.726    0.136    2.730    0.137 {built-in method _openssl.SSL_do_handshake}\r\n       20    1.871    0.094    1.871    0.094 {method 'connect' of '_socket.socket' objects}\r\n       40    1.853    0.046    1.853    0.046 {built-in method _openssl.SSL_read}\r\n       20    0.270    0.014    0.270    0.014 {built-in method _openssl.SSL_CTX_load_verify_locations}\r\n...\r\n```\r\n\r\nIf we do basically the same thing with requests\r\n```python\r\nimport requests\r\n\r\ns = requests.Session()\r\ndef get_chunk_http(n):\r\n    r = s.get(url_base + f'/{n}')\r\n    r.raise_for_status()\r\n    return r.content\r\n\r\n%prun all_data = [get_chunk_http(i) for i in range(20)] \r\n```\r\n\r\nIn this case, because we reused the session, it goes much faster:\r\n```\r\n \r\n         91599 function calls (91579 primitive calls) in 2.114 seconds\r\n\r\n   Ordered by: internal time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n       40    1.699    0.042    1.699    0.042 {built-in method _openssl.SSL_read}\r\n        1    0.142    0.142    0.142    0.142 {built-in method _openssl.SSL_do_handshake}\r\n        1    0.069    0.069    0.069    0.069 {method 'connect' of '_socket.socket' objects}\r\n       20    0.025    0.001    0.025    0.001 {built-in method _socket.gethostbyname}\r\n        1    0.016    0.016    0.016    0.016 {built-in method _openssl.SSL_CTX_load_verify_locations}\r\n       20    0.007    0.000    0.007    0.000 {built-in method _scproxy._get_proxy_settings}\r\n...\r\n```\r\n\r\nCould `HTTPFileSystem` be configured to reuse a session in a similar way?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/237", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/237/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/237/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/237/events", "html_url": "https://github.com/intake/filesystem_spec/issues/237", "id": 561281691, "node_id": "MDU6SXNzdWU1NjEyODE2OTE=", "number": 237, "title": "get_fs_token_paths not in API docs", "user": {"login": "oliverwm1", "id": 23640870, "node_id": "MDQ6VXNlcjIzNjQwODcw", "avatar_url": "https://avatars2.githubusercontent.com/u/23640870?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oliverwm1", "html_url": "https://github.com/oliverwm1", "followers_url": "https://api.github.com/users/oliverwm1/followers", "following_url": "https://api.github.com/users/oliverwm1/following{/other_user}", "gists_url": "https://api.github.com/users/oliverwm1/gists{/gist_id}", "starred_url": "https://api.github.com/users/oliverwm1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oliverwm1/subscriptions", "organizations_url": "https://api.github.com/users/oliverwm1/orgs", "repos_url": "https://api.github.com/users/oliverwm1/repos", "events_url": "https://api.github.com/users/oliverwm1/events{/privacy}", "received_events_url": "https://api.github.com/users/oliverwm1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-06T21:31:19Z", "updated_at": "2020-02-25T19:27:41Z", "closed_at": "2020-02-25T19:27:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is the function `get_fs_token_paths` intended for public use? This is a very useful feature that I have found myself reimplementing in order to use filesystem object functions (e.g. `ls`, `exists`) without knowing a priori what filesystem a urlpath corresponds to.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/232", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/232/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/232/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/232/events", "html_url": "https://github.com/intake/filesystem_spec/issues/232", "id": 552364895, "node_id": "MDU6SXNzdWU1NTIzNjQ4OTU=", "number": 232, "title": "DeprecationWarning over invalid escape sequence", "user": {"login": "tirkarthi", "id": 3972343, "node_id": "MDQ6VXNlcjM5NzIzNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3972343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tirkarthi", "html_url": "https://github.com/tirkarthi", "followers_url": "https://api.github.com/users/tirkarthi/followers", "following_url": "https://api.github.com/users/tirkarthi/following{/other_user}", "gists_url": "https://api.github.com/users/tirkarthi/gists{/gist_id}", "starred_url": "https://api.github.com/users/tirkarthi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tirkarthi/subscriptions", "organizations_url": "https://api.github.com/users/tirkarthi/orgs", "repos_url": "https://api.github.com/users/tirkarthi/repos", "events_url": "https://api.github.com/users/tirkarthi/events{/privacy}", "received_events_url": "https://api.github.com/users/tirkarthi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-01-20T15:21:20Z", "updated_at": "2020-02-27T21:10:25Z", "closed_at": "2020-02-27T21:10:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Deprecation warning is thrown over invalid escape sequences. It might be a good idea to use escape them or use raw strings.\r\n\r\n```\r\n./filesystem_spec/versioneer.py:432: DeprecationWarning: invalid escape sequence \\s\r\n  ] = '''\r\n```\r\n\r\nhttps://github.com/intake/filesystem_spec/blob/c325a40e5c3bb73100c0f922bccf2e0d4e8bca3a/versioneer.py#L432", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/229", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/229/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/229/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/229/events", "html_url": "https://github.com/intake/filesystem_spec/issues/229", "id": 552034680, "node_id": "MDU6SXNzdWU1NTIwMzQ2ODA=", "number": 229, "title": "PermissionError on Windows when using LocalFileSystem.transaction", "user": {"login": "dhirschfeld", "id": 881019, "node_id": "MDQ6VXNlcjg4MTAxOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/881019?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhirschfeld", "html_url": "https://github.com/dhirschfeld", "followers_url": "https://api.github.com/users/dhirschfeld/followers", "following_url": "https://api.github.com/users/dhirschfeld/following{/other_user}", "gists_url": "https://api.github.com/users/dhirschfeld/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhirschfeld/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhirschfeld/subscriptions", "organizations_url": "https://api.github.com/users/dhirschfeld/orgs", "repos_url": "https://api.github.com/users/dhirschfeld/repos", "events_url": "https://api.github.com/users/dhirschfeld/events{/privacy}", "received_events_url": "https://api.github.com/users/dhirschfeld/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-01-20T02:35:27Z", "updated_at": "2020-02-11T19:07:07Z", "closed_at": "2020-02-11T17:23:02Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```python\r\nfrom fsspec.implementations.local import LocalFileSystem\r\n\r\n\r\nfs = LocalFileSystem()\r\n\r\nwith fs.open('data.txt', 'w') as f:\r\n    f.write('ABC')\r\n\r\nwith fs.transaction:\r\n    with fs.open('data.txt', 'w') as f:\r\n        f.write('DEF')\r\n```\r\n```python-traceback\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-9-afc4aa1abe2e>\", line 3, in <module>\r\n    f.write('DEF')\r\n\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\site-packages\\fsspec\\transaction.py\", line 24, in __exit__\r\n    self.complete(commit=exc_type is None)\r\n\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\site-packages\\fsspec\\transaction.py\", line 36, in complete\r\n    f.commit()\r\n\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\site-packages\\fsspec\\implementations\\local.py\", line 219, in commit\r\n    os.rename(self.temp, self.path)\r\n\r\nPermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\dhirschf\\\\AppData\\\\Local\\\\Temp\\\\2\\\\tmpa03bxzd_' -> 'C:/Users/dhirschf/code/sandbox/data.txt'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/227", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/227/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/227/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/227/events", "html_url": "https://github.com/intake/filesystem_spec/issues/227", "id": 549004598, "node_id": "MDU6SXNzdWU1NDkwMDQ1OTg=", "number": 227, "title": "use pooch for file caching", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-01-13T15:28:17Z", "updated_at": "2020-07-02T15:03:30Z", "closed_at": "2020-07-02T15:03:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Ref: https://github.com/fatiando/pooch/pull/134\r\n\r\n[Pooch](https://www.fatiando.org/pooch/latest/) is a package explicitly for the downloading of data filed from HTTP and FTP. It has a file-based registry pointing to URLs and contains optional extra information and checksums. Writing an implementation for fsspec would be trivial, such that the following would be possible:\r\n\r\n    of = fsspec.open('pooch://afile.csv', registry='myfile')\r\n\r\nand thus include pooch downloading in dask or intake. \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/226", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/226/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/226/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/226/events", "html_url": "https://github.com/intake/filesystem_spec/issues/226", "id": 546325270, "node_id": "MDU6SXNzdWU1NDYzMjUyNzA=", "number": 226, "title": "Release of dropbox implementation", "user": {"login": "MarineChap", "id": 34722888, "node_id": "MDQ6VXNlcjM0NzIyODg4", "avatar_url": "https://avatars3.githubusercontent.com/u/34722888?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarineChap", "html_url": "https://github.com/MarineChap", "followers_url": "https://api.github.com/users/MarineChap/followers", "following_url": "https://api.github.com/users/MarineChap/following{/other_user}", "gists_url": "https://api.github.com/users/MarineChap/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarineChap/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarineChap/subscriptions", "organizations_url": "https://api.github.com/users/MarineChap/orgs", "repos_url": "https://api.github.com/users/MarineChap/repos", "events_url": "https://api.github.com/users/MarineChap/events{/privacy}", "received_events_url": "https://api.github.com/users/MarineChap/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-07T14:48:56Z", "updated_at": "2020-03-02T15:32:40Z", "closed_at": "2020-03-02T15:32:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "The dropbox implementation have been release in pypi under the module dropboxdrivefs. \r\nThe code is available in my repository [intake_dropbox]( https://github.com/MarineChap/intake_dropbox )\r\n\r\nIt is ready to be used in fsspec with the protocole '\"dropbox\"\r\n\r\nDon't hesitate to give me feedback, comments, questions\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/225", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/225/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/225/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/225/events", "html_url": "https://github.com/intake/filesystem_spec/issues/225", "id": 545490035, "node_id": "MDU6SXNzdWU1NDU0OTAwMzU=", "number": 225, "title": "FTPFileSystem.open raises exception", "user": {"login": "dhirschfeld", "id": 881019, "node_id": "MDQ6VXNlcjg4MTAxOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/881019?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dhirschfeld", "html_url": "https://github.com/dhirschfeld", "followers_url": "https://api.github.com/users/dhirschfeld/followers", "following_url": "https://api.github.com/users/dhirschfeld/following{/other_user}", "gists_url": "https://api.github.com/users/dhirschfeld/gists{/gist_id}", "starred_url": "https://api.github.com/users/dhirschfeld/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dhirschfeld/subscriptions", "organizations_url": "https://api.github.com/users/dhirschfeld/orgs", "repos_url": "https://api.github.com/users/dhirschfeld/repos", "events_url": "https://api.github.com/users/dhirschfeld/events{/privacy}", "received_events_url": "https://api.github.com/users/dhirschfeld/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-01-06T00:37:05Z", "updated_at": "2020-01-23T23:21:32Z", "closed_at": "2020-01-23T23:21:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "With the FTP I'm using, trying to open a file raises `ftplib.error_temp: 426 Nothing to abort`\r\n```python\r\nimport fsspec\r\n\r\n\r\nfs = fsspec.filesystem('ftp', **kwargs)\r\nfiles = fs.ls('/')\r\nfilename = files[0]['name']\r\nwith fs.open(filename, 'rb') as f:\r\n    content = f.read()\r\n```\r\n```python-traceback\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\site-packages\\fsspec\\implementations\\ftp.py\", line 242, in _fetch_range\r\n    callback=callback,\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\ftplib.py\", line 447, in retrbinary\r\n    callback(data)\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\site-packages\\fsspec\\implementations\\ftp.py\", line 235, in callback\r\n    raise TransferDone\r\nfsspec.implementations.ftp.TransferDone\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/dhirschf/.PyCharm2019.3/config/scratches/scratch_5.py\", line 12, in <module>\r\n    content = f.read()\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\site-packages\\fsspec\\spec.py\", line 1130, in read\r\n    out = self.cache._fetch(self.loc, self.loc + length)\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\site-packages\\fsspec\\caching.py\", line 156, in _fetch\r\n    self.cache = self.fetcher(start, end)  # new block replaces old\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\site-packages\\fsspec\\implementations\\ftp.py\", line 247, in _fetch_range\r\n    self.fs.ftp.voidresp()\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\ftplib.py\", line 251, in voidresp\r\n    resp = self.getresp()\r\n  File \"C:\\Users\\dhirschf\\envs\\dev\\lib\\ftplib.py\", line 244, in getresp\r\n    raise error_temp(resp)\r\nftplib.error_temp: 426 Nothing to abort.\r\n```\r\nhttps://github.com/intake/filesystem_spec/blob/b7b60092898b90b56124a9b3d983a21055c0b4b3/fsspec/implementations/ftp.py#L237-L250\r\n\r\n...so it's actually the call to `voidresp` which fails (after the abort call appears to work correctly - returning a 226).\r\n\r\n[**`ftplib.py`**](https://github.com/python/cpython/blob/efa3b51fd060352cc6220b27a1026e4d4d5401bd/Lib/ftplib.py#L246)\r\n![image](https://user-images.githubusercontent.com/881019/71788588-79221000-306f-11ea-87fe-92e5951cca96.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/220", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/220/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/220/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/220/events", "html_url": "https://github.com/intake/filesystem_spec/issues/220", "id": 538146712, "node_id": "MDU6SXNzdWU1MzgxNDY3MTI=", "number": 220, "title": "Question about next release", "user": {"login": "hayesgb", "id": 12595382, "node_id": "MDQ6VXNlcjEyNTk1Mzgy", "avatar_url": "https://avatars1.githubusercontent.com/u/12595382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hayesgb", "html_url": "https://github.com/hayesgb", "followers_url": "https://api.github.com/users/hayesgb/followers", "following_url": "https://api.github.com/users/hayesgb/following{/other_user}", "gists_url": "https://api.github.com/users/hayesgb/gists{/gist_id}", "starred_url": "https://api.github.com/users/hayesgb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hayesgb/subscriptions", "organizations_url": "https://api.github.com/users/hayesgb/orgs", "repos_url": "https://api.github.com/users/hayesgb/repos", "events_url": "https://api.github.com/users/hayesgb/events{/privacy}", "received_events_url": "https://api.github.com/users/hayesgb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-12-16T02:06:21Z", "updated_at": "2019-12-16T20:29:29Z", "closed_at": "2019-12-16T20:26:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Wondering if you know when the next release may come out?  The `adl://` and `abfs://` protocols from [adlfs](https://github.com/dask/adlfs) are currently available in the registry of fsspec's master branch.  Wondering when I can plan to remove conditional declarations for the fsspec registry?\r\n\r\nSharing the discussion from [here](https://github.com/dask/adlfs/issues/22).\r\n\r\nThanks,\r\nGreg", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/217", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/217/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/217/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/217/events", "html_url": "https://github.com/intake/filesystem_spec/issues/217", "id": 534478054, "node_id": "MDU6SXNzdWU1MzQ0NzgwNTQ=", "number": 217, "title": "Implement github handler", "user": {"login": "c0ffymachyne", "id": 1432920, "node_id": "MDQ6VXNlcjE0MzI5MjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1432920?v=4", "gravatar_id": "", "url": "https://api.github.com/users/c0ffymachyne", "html_url": "https://github.com/c0ffymachyne", "followers_url": "https://api.github.com/users/c0ffymachyne/followers", "following_url": "https://api.github.com/users/c0ffymachyne/following{/other_user}", "gists_url": "https://api.github.com/users/c0ffymachyne/gists{/gist_id}", "starred_url": "https://api.github.com/users/c0ffymachyne/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/c0ffymachyne/subscriptions", "organizations_url": "https://api.github.com/users/c0ffymachyne/orgs", "repos_url": "https://api.github.com/users/c0ffymachyne/repos", "events_url": "https://api.github.com/users/c0ffymachyne/events{/privacy}", "received_events_url": "https://api.github.com/users/c0ffymachyne/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-08T01:38:44Z", "updated_at": "2020-01-13T15:18:37Z", "closed_at": "2020-01-13T15:18:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Self-explanatory enough. Basic handling could be implemented like checkout and push, branches as file names.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/215", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/215/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/215/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/215/events", "html_url": "https://github.com/intake/filesystem_spec/issues/215", "id": 532262738, "node_id": "MDU6SXNzdWU1MzIyNjI3Mzg=", "number": 215, "title": "Standardize dircache timeout", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-03T21:00:37Z", "updated_at": "2020-03-25T18:08:54Z", "closed_at": "2020-03-25T18:08:54Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Currently gcsfs implements a `cache_timeout` and s3fs might want one too (https://github.com/dask/s3fs/issues/271, https://github.com/dask/s3fs/issues/253). So maybe we should just add it to AbstractFileSystem.\r\n\r\n**Proposal**\r\n\r\nAdds a `cache_timeout` to  `AbstractFileSystem.__init__`. Taken from the gcsfs docs\r\n\r\n```\r\n    cache_timeout: float, optional\r\n        Cache expiration time in seconds for object metadata cache.\r\n        Set cache_timeout <= 0 for no caching, None for no cache expiration.\r\n```\r\n\r\nAs for the default, I think `None` makes the most sense for now since that's what gcsfs does. We can explore deprecating `None` in favor of something else (I think `0` for no caching) down the road.\r\n\r\nOne question: is this timeout per-key, per-directory, or global to the filesystem instance? In the gcsfs docs, we state\r\n\r\n```\r\nGCSFileSystem maintains a per-implied-directory cache of object listings and\r\n    fulfills all object information and listing requests from cache. \r\n```\r\n\r\nBut from what I can tell, the cache is actually **per object**, not per-directory.\r\n\r\n```python\r\n    @_tracemethod\r\n    def _list_objects(self, path):\r\n        ...\r\n        listing = self._do_list_objects(path)\r\n        retrieved_time = time.time()\r\n\r\n        self._listing_cache[path] = (retrieved_time, listing)\r\n        return listing\r\n```\r\n\r\nand\r\n\r\n```python\r\n    @_tracemethod\r\n    def _maybe_get_cached_listing(self, path):\r\n        ...\r\n        if path in self._listing_cache:\r\n            retrieved_time, listing = self._listing_cache[path]\r\n            cache_age = time.time() - retrieved_time\r\n            if self.cache_timeout is not None and cache_age > self.cache_timeout:\r\n                logger.debug(\r\n                    \"expired cache path: %s retrieved_time: %.3f cache_age: \"\r\n                    \"%.3f cache_timeout: %.3f\",\r\n                    path,\r\n                    retrieved_time,\r\n                    cache_age,\r\n                    self.cache_timeout,\r\n                )\r\n                del self._listing_cache[path]\r\n                return None\r\n\r\n            return listing\r\n\r\n        return None\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/214", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/214/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/214/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/214/events", "html_url": "https://github.com/intake/filesystem_spec/issues/214", "id": 529754472, "node_id": "MDU6SXNzdWU1Mjk3NTQ0NzI=", "number": 214, "title": "Shouldn't 'walk' return 'info' instead of just name?", "user": {"login": "ivannp", "id": 1331156, "node_id": "MDQ6VXNlcjEzMzExNTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1331156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ivannp", "html_url": "https://github.com/ivannp", "followers_url": "https://api.github.com/users/ivannp/followers", "following_url": "https://api.github.com/users/ivannp/following{/other_user}", "gists_url": "https://api.github.com/users/ivannp/gists{/gist_id}", "starred_url": "https://api.github.com/users/ivannp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ivannp/subscriptions", "organizations_url": "https://api.github.com/users/ivannp/orgs", "repos_url": "https://api.github.com/users/ivannp/repos", "events_url": "https://api.github.com/users/ivannp/events{/privacy}", "received_events_url": "https://api.github.com/users/ivannp/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-11-28T08:09:12Z", "updated_at": "2020-01-30T14:56:32Z", "closed_at": "2020-01-30T14:56:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Have been working on a tiny wrapper (mostly put/get functionality, no need of _open) around [Google Drive](https://developers.google.com/drive/api/v3/about-sdk) - _gdrivefs_.\r\n\r\nOne thing I noticed is that _walk_ doesn't return the object infos. Is there a reason for this?\r\n\r\nIn my case this will double the necessary remote calls to retrieve the file info. Hence, I don't want to use the provided _walk_, so if it's not going to change (to provide a fourth array with the infos) - I will overwrite it in _gdrivefs_.\r\n\r\nIf you are wondering in what context I need this - I am porting [a cloud storage sync application](https://github.com/ivannp/cync) from C# to Python. In the process, I came across fsspec and decided it to use it - very nice and has similar functionality to the fs abstraction I have in my project.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/212", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/212/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/212/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/212/events", "html_url": "https://github.com/intake/filesystem_spec/issues/212", "id": 529452467, "node_id": "MDU6SXNzdWU1Mjk0NTI0Njc=", "number": 212, "title": "Deprecate auto_mkdir=True for LocalFileSystem", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-27T16:26:03Z", "updated_at": "2019-12-20T21:22:32Z", "closed_at": "2019-12-20T21:22:32Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "xref https://github.com/intake/filesystem_spec/pull/211 and https://github.com/dask/dask/issues/5526.\r\n\r\nThis is a bit of a strange API, that's no longer needed after #211. I'd like to change the default from True to `None`. Users will need to specify `auto_mkdir=True` to retain the old behavior, or `=False` to opt into the new behavior now.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/210", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/210/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/210/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/210/events", "html_url": "https://github.com/intake/filesystem_spec/issues/210", "id": 529306950, "node_id": "MDU6SXNzdWU1MjkzMDY5NTA=", "number": 210, "title": "Issue with integration with pyarrow", "user": {"login": "srizvan", "id": 3490922, "node_id": "MDQ6VXNlcjM0OTA5MjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/3490922?v=4", "gravatar_id": "", "url": "https://api.github.com/users/srizvan", "html_url": "https://github.com/srizvan", "followers_url": "https://api.github.com/users/srizvan/followers", "following_url": "https://api.github.com/users/srizvan/following{/other_user}", "gists_url": "https://api.github.com/users/srizvan/gists{/gist_id}", "starred_url": "https://api.github.com/users/srizvan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/srizvan/subscriptions", "organizations_url": "https://api.github.com/users/srizvan/orgs", "repos_url": "https://api.github.com/users/srizvan/repos", "events_url": "https://api.github.com/users/srizvan/events{/privacy}", "received_events_url": "https://api.github.com/users/srizvan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-11-27T12:09:14Z", "updated_at": "2019-11-27T19:14:36Z", "closed_at": "2019-11-27T19:14:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "Env:\r\nPython 3.7.4\r\nfsspec==0.6.0\r\npyarrow==0.15.1\r\ndask==2.8.1\r\n\r\nWhen I'm trying to read data frame from HDFS, the next issue appears:\r\n```\r\ndf = dd.read_csv('hdfs://hostname:9820/data/ds_*.csv')\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-6-368b0d249316> in <module>\r\n----> 1 df = dd.read_csv('hdfs://hostname:9820/data/ds_*.csv')\r\n\r\n~/miniconda3/lib/python3.7/site-packages/dask/dataframe/io/csv.py in read(urlpath, blocksize, collection, lineterminator, compression, sample, enforce, assume_missing, storage_options, include_path_column, **kwargs)\r\n    576             storage_options=storage_options,\r\n    577             include_path_column=include_path_column,\r\n--> 578             **kwargs\r\n    579         )\r\n    580 \r\n\r\n~/miniconda3/lib/python3.7/site-packages/dask/dataframe/io/csv.py in read_pandas(reader, urlpath, blocksize, collection, lineterminator, compression, sample, enforce, assume_missing, storage_options, include_path_column, **kwargs)\r\n    403         compression=compression,\r\n    404         include_path=include_path_column,\r\n--> 405         **(storage_options or {})\r\n    406     )\r\n    407 \r\n\r\n~/miniconda3/lib/python3.7/site-packages/dask/bytes/core.py in read_bytes(urlpath, delimiter, not_zero, blocksize, sample, compression, include_path, **kwargs)\r\n    156         if isinstance(sample, str):\r\n    157             sample = parse_bytes(sample)\r\n--> 158         with OpenFile(fs, paths[0], compression=compression) as f:\r\n    159             # read block without seek (because we start at zero)\r\n    160             if delimiter is None:\r\n\r\n~/miniconda3/lib/python3.7/site-packages/fsspec/core.py in __enter__(self)\r\n     96         mode = self.mode.replace(\"t\", \"\").replace(\"b\", \"\") + \"b\"\r\n     97 \r\n---> 98         f = self.fs.open(self.path, mode=mode)\r\n     99 \r\n    100         self.fobjects = [f]\r\n\r\n~/miniconda3/lib/python3.7/site-packages/fsspec/implementations/hdfs.py in <lambda>(*args, **kw)\r\n    116             # all the methods defined in this class. Note `open` here, since\r\n    117             # it calls `_open`, but is actually in superclass\r\n--> 118             return lambda *args, **kw: getattr(PyArrowHDFS, item)(self, *args, **kw)\r\n    119         if item == \"__class__\":\r\n    120             return PyArrowHDFS\r\n\r\n~/miniconda3/lib/python3.7/site-packages/fsspec/spec.py in open(self, path, mode, block_size, cache_options, **kwargs)\r\n    723                 autocommit=ac,\r\n    724                 cache_options=cache_options,\r\n--> 725                 **kwargs\r\n    726             )\r\n    727             if not ac:\r\n\r\n~/miniconda3/lib/python3.7/site-packages/fsspec/implementations/hdfs.py in <lambda>(*args, **kw)\r\n    116             # all the methods defined in this class. Note `open` here, since\r\n    117             # it calls `_open`, but is actually in superclass\r\n--> 118             return lambda *args, **kw: getattr(PyArrowHDFS, item)(self, *args, **kw)\r\n    119         if item == \"__class__\":\r\n    120             return PyArrowHDFS\r\n\r\n~/miniconda3/lib/python3.7/site-packages/fsspec/implementations/hdfs.py in _open(self, path, mode, block_size, autocommit, **kwargs)\r\n     72         if not autocommit:\r\n     73             raise NotImplementedError\r\n---> 74         return HDFSFile(self, path, mode, block_size, **kwargs)\r\n     75 \r\n     76     def __reduce_ex__(self, protocol):\r\n\r\n~/miniconda3/lib/python3.7/site-packages/fsspec/implementations/hdfs.py in __init__(self, fs, path, mode, block_size, **kwargs)\r\n    171         self.mode = mode\r\n    172         self.block_size = block_size\r\n--> 173         self.fh = fs.pahdfs.open(path, mode, block_size, **kwargs)\r\n    174         if self.fh.readable():\r\n    175             self.seek_size = self.size()\r\n\r\n~/miniconda3/lib/python3.7/site-packages/pyarrow/io-hdfs.pxi in pyarrow.lib.HadoopFileSystem.open()\r\n\r\nTypeError: open() got an unexpected keyword argument 'cache_options'\r\n```\r\n\r\nAs a workaround, I just comment out line 724 in the ~/miniconda3/lib/python3.7/site-packages/fsspec/spec.py file (`cache_options=cache_options,`).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/205", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/205/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/205/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/205/events", "html_url": "https://github.com/intake/filesystem_spec/issues/205", "id": 523498520, "node_id": "MDU6SXNzdWU1MjM0OTg1MjA=", "number": 205, "title": "issue with cache_options in 0.6.0 using intake.upload with azure datalake", "user": {"login": "JoranDox", "id": 7152733, "node_id": "MDQ6VXNlcjcxNTI3MzM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7152733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JoranDox", "html_url": "https://github.com/JoranDox", "followers_url": "https://api.github.com/users/JoranDox/followers", "following_url": "https://api.github.com/users/JoranDox/following{/other_user}", "gists_url": "https://api.github.com/users/JoranDox/gists{/gist_id}", "starred_url": "https://api.github.com/users/JoranDox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JoranDox/subscriptions", "organizations_url": "https://api.github.com/users/JoranDox/orgs", "repos_url": "https://api.github.com/users/JoranDox/repos", "events_url": "https://api.github.com/users/JoranDox/events{/privacy}", "received_events_url": "https://api.github.com/users/JoranDox/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-15T14:24:20Z", "updated_at": "2019-11-19T16:18:16Z", "closed_at": "2019-11-19T16:18:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nTraceback (most recent call last):\r\n  File \"/home/vsts/work/1/s/machine_readable_spec/transformations/push_to_datalake.py\", line 38, in <module>\r\n    entry = intake.upload([infile_read], outloc_latest, storage_options=global_storage_options)\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/intake/container/__init__.py\", line 54, in upload\r\n    s = cls._data_to_source(data, path, **kwargs)\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/intake/container/semistructured.py\", line 95, in _data_to_source\r\n    dask.compute(out)\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/dask/base.py\", line 436, in compute\r\n    results = schedule(dsk, keys, **kwargs)\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/dask/threaded.py\", line 81, in get\r\n    **kwargs\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/dask/local.py\", line 486, in get_async\r\n    raise_exception(exc, tb)\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/dask/local.py\", line 316, in reraise\r\n    raise exc\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/dask/local.py\", line 222, in execute_task\r\n    result = _execute_task(task, data)\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/dask/core.py\", line 119, in _execute_task\r\n    return func(*args2)\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/intake/container/semistructured.py\", line 101, in write_file\r\n    with fo as f:\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/fsspec/core.py\", line 98, in __enter__\r\n    f = self.fs.open(self.path, mode=mode)\r\n  File \"/opt/hostedtoolcache/Python/3.7.5/x64/lib/python3.7/site-packages/fsspec/spec.py\", line 725, in open\r\n    **kwargs\r\nTypeError: _open() got an unexpected keyword argument 'cache_options'\r\n##[error]/opt/hostedtoolcache/Python/3.7.5/x64/bin/python failed with return code: 1\r\n\r\n```\r\npip freeze:\r\n\r\nadal==1.2.2\r\nadlfs==0.1.0\r\nappdirs==1.4.3\r\nattrs==19.3.0\r\nazure-common==1.1.23\r\nazure-datalake-store==0.0.48\r\nazure-storage-blob==2.1.0\r\nazure-storage-common==2.1.0\r\nboltons==19.3.0\r\ncertifi==2019.9.11\r\ncffi==1.13.2\r\nchardet==3.0.4\r\ncloudpickle==1.2.2\r\ncryptography==2.8\r\ndask==2.7.0\r\nentrypoints==0.3\r\nfsspec==0.6.0\r\nidna==2.8\r\nimportlib-metadata==0.23\r\nintake==0.5.3+36.gba252a0\r\nJinja2==2.10.3\r\njsonschema==3.1.1\r\nlocket==0.2.0\r\nMarkupSafe==1.1.1\r\nmore-itertools==7.2.0\r\nmsgpack==0.6.2\r\nnumpy==1.17.4\r\npandas==0.25.3\r\npartd==1.0.0\r\npyarrow==0.15.1\r\npycparser==2.19\r\nPyJWT==1.7.1\r\npyrsistent==0.15.5\r\npython-dateutil==2.8.1\r\npytz==2019.3\r\nPyYAML==5.1.2\r\nrequests==2.22.0\r\nsix==1.13.0\r\ntoolz==0.10.0\r\nurllib3==1.25.7\r\nzipp==0.6.0\r\n\r\nI'm not sure what other things I can add as extra info, if there is anything, please let me know\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/200", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/200/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/200/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/200/events", "html_url": "https://github.com/intake/filesystem_spec/issues/200", "id": 522872104, "node_id": "MDU6SXNzdWU1MjI4NzIxMDQ=", "number": 200, "title": "access to dropbox?", "user": {"login": "fkloosterman", "id": 4592857, "node_id": "MDQ6VXNlcjQ1OTI4NTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/4592857?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fkloosterman", "html_url": "https://github.com/fkloosterman", "followers_url": "https://api.github.com/users/fkloosterman/followers", "following_url": "https://api.github.com/users/fkloosterman/following{/other_user}", "gists_url": "https://api.github.com/users/fkloosterman/gists{/gist_id}", "starred_url": "https://api.github.com/users/fkloosterman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fkloosterman/subscriptions", "organizations_url": "https://api.github.com/users/fkloosterman/orgs", "repos_url": "https://api.github.com/users/fkloosterman/repos", "events_url": "https://api.github.com/users/fkloosterman/events{/privacy}", "received_events_url": "https://api.github.com/users/fkloosterman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-11-14T13:50:07Z", "updated_at": "2020-01-07T14:55:13Z", "closed_at": "2020-01-07T14:55:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was wondering if there is already a filesystem implementation that provides access to dropbox (I suppose using the dropbox API)? If not, what alternatives for dropbox access with fsspec exist?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/199", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/199/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/199/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/199/events", "html_url": "https://github.com/intake/filesystem_spec/issues/199", "id": 522815464, "node_id": "MDU6SXNzdWU1MjI4MTU0NjQ=", "number": 199, "title": "alternative serializations (json?)", "user": {"login": "lukasheinrich", "id": 2318083, "node_id": "MDQ6VXNlcjIzMTgwODM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2318083?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukasheinrich", "html_url": "https://github.com/lukasheinrich", "followers_url": "https://api.github.com/users/lukasheinrich/followers", "following_url": "https://api.github.com/users/lukasheinrich/following{/other_user}", "gists_url": "https://api.github.com/users/lukasheinrich/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukasheinrich/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukasheinrich/subscriptions", "organizations_url": "https://api.github.com/users/lukasheinrich/orgs", "repos_url": "https://api.github.com/users/lukasheinrich/repos", "events_url": "https://api.github.com/users/lukasheinrich/events{/privacy}", "received_events_url": "https://api.github.com/users/lukasheinrich/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-11-14T12:05:30Z", "updated_at": "2020-03-17T17:37:26Z", "closed_at": "2020-03-17T17:37:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm interested in a layer that allows to consistently pass file-like obects between e.g. languages, and was wondering whether fsspec would be the right tool as serializability of file-like entities seems to be a priority. Would alternative serializations to pickle/cloudpickle be in-scope?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/198", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/198/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/198/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/198/events", "html_url": "https://github.com/intake/filesystem_spec/issues/198", "id": 522566467, "node_id": "MDU6SXNzdWU1MjI1NjY0Njc=", "number": 198, "title": "PyArrowHDFS doesn't support cache_options", "user": {"login": "jrbourbeau", "id": 11656932, "node_id": "MDQ6VXNlcjExNjU2OTMy", "avatar_url": "https://avatars1.githubusercontent.com/u/11656932?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrbourbeau", "html_url": "https://github.com/jrbourbeau", "followers_url": "https://api.github.com/users/jrbourbeau/followers", "following_url": "https://api.github.com/users/jrbourbeau/following{/other_user}", "gists_url": "https://api.github.com/users/jrbourbeau/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrbourbeau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrbourbeau/subscriptions", "organizations_url": "https://api.github.com/users/jrbourbeau/orgs", "repos_url": "https://api.github.com/users/jrbourbeau/repos", "events_url": "https://api.github.com/users/jrbourbeau/events{/privacy}", "received_events_url": "https://api.github.com/users/jrbourbeau/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-14T01:21:28Z", "updated_at": "2019-11-14T17:25:22Z", "closed_at": "2019-11-14T17:24:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "We're seeing failures over on Dask's CI HDFS tests (see https://travis-ci.org/dask/dask/jobs/611548312) where we're getting the following error: `TypeError: open() got an unexpected keyword argument 'cache_options'`\r\n\r\n<details>\r\n<summary>Full traceback:</summary>\r\n\r\n```python\r\n_____________________________ test_read_bytes_URL ______________________________\r\n\r\nhdfs = <pyarrow.hdfs.HadoopFileSystem object at 0x7f22a618b8c8>\r\n\r\n    def test_read_bytes_URL(hdfs):\r\n\r\n        nfiles = 10\r\n\r\n        data = b\"a\" * int(1e3)\r\n\r\n    \r\n\r\n        for fn in [\"%s/file.%d\" % (basedir, i) for i in range(nfiles)]:\r\n\r\n            with hdfs.open(fn, \"wb\", replication=1) as f:\r\n\r\n                f.write(data)\r\n\r\n    \r\n\r\n        path = \"hdfs://localhost:8020%s/file.*\" % basedir\r\n\r\n>       sample, values = read_bytes(path)\r\n\r\ndask/bytes/tests/test_hdfs.py:73: \r\n\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\ndask/bytes/core.py:158: in read_bytes\r\n\r\n    with OpenFile(fs, paths[0], compression=compression) as f:\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/core.py:98: in __enter__\r\n\r\n    f = self.fs.open(self.path, mode=mode)\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/implementations/hdfs.py:118: in <lambda>\r\n\r\n    return lambda *args, **kw: getattr(PyArrowHDFS, item)(self, *args, **kw)\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/spec.py:725: in open\r\n\r\n    **kwargs\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/implementations/hdfs.py:118: in <lambda>\r\n\r\n    return lambda *args, **kw: getattr(PyArrowHDFS, item)(self, *args, **kw)\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/implementations/hdfs.py:74: in _open\r\n\r\n    return HDFSFile(self, path, mode, block_size, **kwargs)\r\n\r\n/opt/conda/lib/python3.7/site-packages/fsspec/implementations/hdfs.py:173: in __init__\r\n\r\n    self.fh = fs.pahdfs.open(path, mode, block_size, **kwargs)\r\n\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n>   ???\r\n\r\nE   TypeError: open() got an unexpected keyword argument 'cache_options'\r\n\r\npyarrow/io-hdfs.pxi:383: TypeError\r\n```\r\n\r\n</details>\r\n\r\nI think the issue is `fsspec` is passing a `cache_options` parameter down to PyArrow's HdfsFile here:\r\n\r\nhttps://github.com/intake/filesystem_spec/blob/8b59dc8c2c035db5793102b9513c46e6a1bd4fb0/fsspec/implementations/hdfs.py#L173\r\n\r\nwhich isn't supported (feel free to correct me if I'm wrong here).\r\n\r\nDoes `pop`ing off the `cache_options` keyword argument and raising if it's not `None` seem like a reasonable fix?\r\n\r\n```diff\r\ndiff --git a/fsspec/implementations/hdfs.py b/fsspec/implementations/hdfs.py\r\nindex 06ec205..18602a0 100644\r\n--- a/fsspec/implementations/hdfs.py\r\n+++ b/fsspec/implementations/hdfs.py\r\n@@ -170,6 +170,10 @@ class HDFSFile(object):\r\n         self.path = path\r\n         self.mode = mode\r\n         self.block_size = block_size\r\n+        if kwargs.get(\"cache_options\") is None:\r\n+            kwargs.pop(\"cache_options\")\r\n+        else:\r\n+            raise NotImplementedError(\"cache_options is not implemented for HDFSFile\")\r\n         self.fh = fs.pahdfs.open(path, mode, block_size, **kwargs)\r\n         if self.fh.readable():\r\n             self.seek_size = self.size()\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/197", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/197/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/197/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/197/events", "html_url": "https://github.com/intake/filesystem_spec/issues/197", "id": 522518907, "node_id": "MDU6SXNzdWU1MjI1MTg5MDc=", "number": 197, "title": "FTP file open is broken", "user": {"login": "ahcub", "id": 4904947, "node_id": "MDQ6VXNlcjQ5MDQ5NDc=", "avatar_url": "https://avatars0.githubusercontent.com/u/4904947?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahcub", "html_url": "https://github.com/ahcub", "followers_url": "https://api.github.com/users/ahcub/followers", "following_url": "https://api.github.com/users/ahcub/following{/other_user}", "gists_url": "https://api.github.com/users/ahcub/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahcub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahcub/subscriptions", "organizations_url": "https://api.github.com/users/ahcub/orgs", "repos_url": "https://api.github.com/users/ahcub/repos", "events_url": "https://api.github.com/users/ahcub/events{/privacy}", "received_events_url": "https://api.github.com/users/ahcub/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-11-13T22:51:12Z", "updated_at": "2020-02-27T21:51:38Z", "closed_at": "2020-02-27T21:51:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "a simple try to open a file using ftp like the following\r\n\r\n```\r\nimport fsspec\r\nfs = fsspec.filesystem('ftp', host='hostname', port=21, username='test', password='test')\r\nprint(fs.open('/root/test.csv'))\r\n\r\n```\r\nresults into an error like this\r\n\r\n```Traceback (most recent call last):\r\n  File \"C:/Users/trader/.PyCharm2019.2/config/scratches/scratch_1.py\", line 5, in <module>\r\n    print(fs.open('///sim/test.csv'))\r\n  File \"C:\\Users\\trader\\Miniconda3\\envs\\p3\\lib\\site-packages\\fsspec\\spec.py\", line 708, in open\r\n    path, mode=mode, block_size=block_size, autocommit=ac, **kwargs\r\n  File \"C:\\Users\\trader\\Miniconda3\\envs\\p3\\lib\\site-packages\\fsspec\\implementations\\ftp.py\", line 133, in _open\r\n    autocommit=autocommit,\r\n  File \"C:\\Users\\trader\\Miniconda3\\envs\\p3\\lib\\site-packages\\fsspec\\implementations\\ftp.py\", line 170, in __init__\r\n    super().__init__(fs, path, **kwargs)\r\n  File \"C:\\Users\\trader\\Miniconda3\\envs\\p3\\lib\\site-packages\\fsspec\\spec.py\", line 875, in __init__\r\n    self.details = fs.info(path)\r\n  File \"C:\\Users\\trader\\Miniconda3\\envs\\p3\\lib\\site-packages\\fsspec\\implementations\\ftp.py\", line 122, in info\r\n    return [f for f in files if f[\"name\"] == path][0]\r\nIndexError: list index out of range\r\n```\r\n\r\nbecause the `self._parent('/root/test.csv')` returns `'//root'` instead of `'/root'`\r\nand then `self.ls('//root', True)` returns the list of `'/'` directory instead of `'/root'`\r\n\r\nthat affects dask as it fails with the same error when trying to open files via ftp\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/190", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/190/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/190/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/190/events", "html_url": "https://github.com/intake/filesystem_spec/issues/190", "id": 521672436, "node_id": "MDU6SXNzdWU1MjE2NzI0MzY=", "number": 190, "title": "Release: 0.6.0", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-11-12T16:52:51Z", "updated_at": "2019-11-13T18:27:22Z", "closed_at": "2019-11-13T18:27:22Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Planning to use 0.6.0 as the next version number. Hoping to do this by the end of the week. I believe the biggest fixed issue is the change to the filesystem init, which *should* eliminate all the permission errors we were seeing (if they weren't already fixed).\r\n\r\nAnything else we should consider?\r\n\r\nThis should be backwards compatible, but I'll also do releases of s3fs and gcsfs at the same time.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/186", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/186/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/186/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/186/events", "html_url": "https://github.com/intake/filesystem_spec/issues/186", "id": 521621449, "node_id": "MDU6SXNzdWU1MjE2MjE0NDk=", "number": 186, "title": "FSMap.keys() shouldn't be a generator", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-12T15:29:22Z", "updated_at": "2019-11-12T16:48:00Z", "closed_at": "2019-11-12T16:48:00Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "The view of the keys from a mapping shouldn't be a generator, which is consumed.\r\n\r\n```python\r\nIn [16]: d = {\"a\": 1, \"b\": 2}\r\n\r\nIn [17]: keys = d.keys()\r\n\r\nIn [18]: list(keys)\r\nOut[18]: ['a', 'b']\r\n\r\nIn [19]: list(keys)\r\nOut[19]: ['a', 'b']\r\n```\r\n\r\n```python\r\nIn [20]: fs = LocalFileSystem()\r\n\r\nIn [21]: mapper = fs.get_mapper('/')\r\n\r\nIn [24]: keys = mapper.keys()\r\n\r\nIn [25]: len(list(keys))\r\nOut[25]: 859\r\n\r\nIn [26]: len(list(keys))\r\nOut[26]: 0\r\n```\r\n\r\nIt should also support things like `len`, etc.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/169", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/169/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/169/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/169/events", "html_url": "https://github.com/intake/filesystem_spec/issues/169", "id": 515843865, "node_id": "MDU6SXNzdWU1MTU4NDM4NjU=", "number": 169, "title": "`glob` does not support range", "user": {"login": "jonathan-hourany", "id": 45407670, "node_id": "MDQ6VXNlcjQ1NDA3Njcw", "avatar_url": "https://avatars0.githubusercontent.com/u/45407670?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonathan-hourany", "html_url": "https://github.com/jonathan-hourany", "followers_url": "https://api.github.com/users/jonathan-hourany/followers", "following_url": "https://api.github.com/users/jonathan-hourany/following{/other_user}", "gists_url": "https://api.github.com/users/jonathan-hourany/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonathan-hourany/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonathan-hourany/subscriptions", "organizations_url": "https://api.github.com/users/jonathan-hourany/orgs", "repos_url": "https://api.github.com/users/jonathan-hourany/repos", "events_url": "https://api.github.com/users/jonathan-hourany/events{/privacy}", "received_events_url": "https://api.github.com/users/jonathan-hourany/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-01T00:40:39Z", "updated_at": "2019-11-04T20:25:22Z", "closed_at": "2019-11-04T20:25:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Although stated in the docstring that ranges (e.g. `s3://test/date=2019-10-0[1-5]`) are supported it turns out they are not. Using the `s3fs.S3FileSystem` library, which relies on this implementation of `glob`, returns an empty list when supplying a path with a range in it.\r\n\r\nThis is because the opening brace (i.e. `[`) is not detected in glob's if-check\r\nhttps://github.com/intake/filesystem_spec/blob/56fd518316a5ec05357d6e62c9a41a1b981802ee/fsspec/spec.py#L445\r\nBy adding `\"[\" not in path` or using the `glob.has_magic` function in the if-check this bug is solved", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/166", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/166/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/166/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/166/events", "html_url": "https://github.com/intake/filesystem_spec/issues/166", "id": 515200446, "node_id": "MDU6SXNzdWU1MTUyMDA0NDY=", "number": 166, "title": "AbstractFileSystem walk method calls ls with 3 parameters, but only 2 expected", "user": {"login": "jonathan-hourany", "id": 45407670, "node_id": "MDQ6VXNlcjQ1NDA3Njcw", "avatar_url": "https://avatars0.githubusercontent.com/u/45407670?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonathan-hourany", "html_url": "https://github.com/jonathan-hourany", "followers_url": "https://api.github.com/users/jonathan-hourany/followers", "following_url": "https://api.github.com/users/jonathan-hourany/following{/other_user}", "gists_url": "https://api.github.com/users/jonathan-hourany/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonathan-hourany/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonathan-hourany/subscriptions", "organizations_url": "https://api.github.com/users/jonathan-hourany/orgs", "repos_url": "https://api.github.com/users/jonathan-hourany/repos", "events_url": "https://api.github.com/users/jonathan-hourany/events{/privacy}", "received_events_url": "https://api.github.com/users/jonathan-hourany/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-31T06:34:44Z", "updated_at": "2019-10-31T21:50:17Z", "closed_at": "2019-10-31T21:50:17Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Although `ls` is expected to be overwritten by child classes, it's still worth noting that the `walk` method passes 3 arguments (2 positional and `**kwargs`) \r\n\r\nhttps://github.com/intake/filesystem_spec/blob/d774f0ef92b5f7bd28ec0b1b4e4fdb62ee8bea60/fsspec/spec.py#L344\r\n\r\nWhile `ls` only accepts 1 position and `**kwargs`\r\nhttps://github.com/intake/filesystem_spec/blob/d774f0ef92b5f7bd28ec0b1b4e4fdb62ee8bea60/fsspec/spec.py#L264\r\n\r\nThis causes `TypeError` to be raised instead of the expected `NotImplementedError`. Looking at the docstring for `ls`, it looks like walk should be called with `detail=True` or `ls` changed to have \"detail\" explicitly declared in the function signature (or both).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/164", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/164/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/164/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/164/events", "html_url": "https://github.com/intake/filesystem_spec/issues/164", "id": 514211549, "node_id": "MDU6SXNzdWU1MTQyMTE1NDk=", "number": 164, "title": "infer_storage_options fails with on file paths with two leading slashes", "user": {"login": "samkaufman", "id": 117156, "node_id": "MDQ6VXNlcjExNzE1Ng==", "avatar_url": "https://avatars0.githubusercontent.com/u/117156?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samkaufman", "html_url": "https://github.com/samkaufman", "followers_url": "https://api.github.com/users/samkaufman/followers", "following_url": "https://api.github.com/users/samkaufman/following{/other_user}", "gists_url": "https://api.github.com/users/samkaufman/gists{/gist_id}", "starred_url": "https://api.github.com/users/samkaufman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samkaufman/subscriptions", "organizations_url": "https://api.github.com/users/samkaufman/orgs", "repos_url": "https://api.github.com/users/samkaufman/repos", "events_url": "https://api.github.com/users/samkaufman/events{/privacy}", "received_events_url": "https://api.github.com/users/samkaufman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-29T20:44:12Z", "updated_at": "2020-03-02T15:30:57Z", "closed_at": "2020-03-02T15:30:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Calling `infer_storage_options(\"//tmp/f\u201d)` returns:\r\n\r\n```python\r\n{'protocol': 'file', 'path': '/f', 'host': 'tmp\u2019}\r\n```\r\n\r\nbut I expected it to return:\r\n\r\n```python\r\n{'protocol': 'file', 'path': '//tmp/f\u2019}\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/160", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/160/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/160/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/160/events", "html_url": "https://github.com/intake/filesystem_spec/issues/160", "id": 508827545, "node_id": "MDU6SXNzdWU1MDg4Mjc1NDU=", "number": 160, "title": "ValueError: Got more bytes so far than requested", "user": {"login": "weiji14", "id": 23487320, "node_id": "MDQ6VXNlcjIzNDg3MzIw", "avatar_url": "https://avatars3.githubusercontent.com/u/23487320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiji14", "html_url": "https://github.com/weiji14", "followers_url": "https://api.github.com/users/weiji14/followers", "following_url": "https://api.github.com/users/weiji14/following{/other_user}", "gists_url": "https://api.github.com/users/weiji14/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiji14/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiji14/subscriptions", "organizations_url": "https://api.github.com/users/weiji14/orgs", "repos_url": "https://api.github.com/users/weiji14/repos", "events_url": "https://api.github.com/users/weiji14/events{/privacy}", "received_events_url": "https://api.github.com/users/weiji14/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-10-18T03:07:52Z", "updated_at": "2019-10-18T23:22:59Z", "closed_at": "2019-10-18T17:06:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "There seems to be an issue with using `fsspec` to fetch large-ish files over http:\r\n\r\n```python\r\nimport fsspec\r\nimport xarray as xr\r\nwith fsspec.open(\"http://test.opendap.org/opendap/data/nc/coads_climatology2.nc\") as f:\r\n    ds = xr.open_dataset(f)\r\n```\r\n\r\nFull error message:\r\n\r\n<details>\r\n\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-5-4b2387e53223> in <module>\r\n      2 import xarray as xr\r\n      3 with fsspec.open(\"http://test.opendap.org/opendap/data/nc/coads_climatology2.nc\") as f:\r\n----> 4     ds = xr.open_dataset(f)\r\n\r\n~/.local/share/virtualenvs/condaenv-AbcDeF1z/lib/python3.7/site-packages/xarray/backends/api.py in open_dataset(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs, use_cftime)\r\n    524                 \"with engine='scipy' or 'h5netcdf'\"\r\n    525             )\r\n--> 526         engine = _get_engine_from_magic_number(filename_or_obj)\r\n    527         if engine == \"scipy\":\r\n    528             store = backends.ScipyDataStore(filename_or_obj, **backend_kwargs)\r\n\r\n~/.local/share/virtualenvs/condaenv-AbcDeF1z/lib/python3.7/site-packages/xarray/backends/api.py in _get_engine_from_magic_number(filename_or_obj)\r\n    118                 \"manager\"\r\n    119             )\r\n--> 120         magic_number = filename_or_obj.read(8)\r\n    121         filename_or_obj.seek(0)\r\n    122 \r\n\r\n~/.local/share/virtualenvs/condaenv-AbcDeF1z/src/fsspec/fsspec/implementations/http.py in read(self, length)\r\n    257         else:\r\n    258             length = min(self.size - self.loc, length)\r\n--> 259         return super().read(length)\r\n    260 \r\n    261     def _fetch_all(self):\r\n\r\n~/.local/share/virtualenvs/condaenv-AbcDeF1z/src/fsspec/fsspec/spec.py in read(self, length)\r\n   1045             # don't even bother calling fetch\r\n   1046             return b\"\"\r\n-> 1047         out = self.cache._fetch(self.loc, self.loc + length)\r\n   1048         self.loc += len(out)\r\n   1049         return out\r\n\r\n~/.local/share/virtualenvs/condaenv-AbcDeF1z/src/fsspec/fsspec/core.py in _fetch(self, start, end)\r\n    596         ):\r\n    597             # First read, or extending both before and after\r\n--> 598             self.cache = self.fetcher(start, bend)\r\n    599             self.start = start\r\n    600         elif start < self.start:\r\n\r\n~/.local/share/virtualenvs/condaenv-AbcDeF1z/src/fsspec/fsspec/implementations/http.py in _fetch_range(self, start, end)\r\n    311                         raise ValueError(\r\n    312                             \"Got more bytes so far (>%i) than requested (%i)\"\r\n--> 313                             % (cl, end - start)\r\n    314                         )\r\n    315                 else:\r\n\r\nValueError: Got more bytes so far (>5242929) than requested (5242888)\r\n```\r\n\r\n</details>\r\n\r\nThe example test NetCDF file above is actually just 5.2MB in size. However, trying it on a smaller file of just 3.0MB works:\r\n\r\n```python\r\nimport fsspec\r\nimport xarray as xr\r\nwith fsspec.open(\"http://test.opendap.org/opendap/data/nc/coads_climatology.nc\") as f:\r\n    ds = xr.open_dataset(f, decode_times=False)\r\n    print(ds)\r\n```\r\n\r\n```python-traceback\r\n<xarray.Dataset>\r\nDimensions:  (COADSX: 180, COADSY: 90, TIME: 12)\r\nCoordinates:\r\n  * COADSX   (COADSX) float64 21.0 23.0 25.0 27.0 ... 373.0 375.0 377.0 379.0\r\n  * COADSY   (COADSY) float64 -89.0 -87.0 -85.0 -83.0 ... 83.0 85.0 87.0 89.0\r\n  * TIME     (TIME) float64 366.0 1.096e+03 1.827e+03 ... 7.671e+03 8.401e+03\r\nData variables:\r\n    SST      (TIME, COADSY, COADSX) float32 ...\r\n    AIRT     (TIME, COADSY, COADSX) float32 ...\r\n    UWND     (TIME, COADSY, COADSX) float32 ...\r\n    VWND     (TIME, COADSY, COADSX) float32 ...\r\nAttributes:\r\n    history:  FERRET V4.30 (debug/no GUI) 15-Aug-96\r\n```\r\n\r\nThis was tested using the latest `fsspec` from master (commit e69b679a94d4342d0ebbe8ba21314ceec0c62a8a) and `xarray==0.14.0`. Carried forward from https://github.com/intake/intake-xarray/issues/56.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/157", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/157/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/157/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/157/events", "html_url": "https://github.com/intake/filesystem_spec/issues/157", "id": 506099849, "node_id": "MDU6SXNzdWU1MDYwOTk4NDk=", "number": 157, "title": "fsspec and dask.delayed", "user": {"login": "matt-long", "id": 9341267, "node_id": "MDQ6VXNlcjkzNDEyNjc=", "avatar_url": "https://avatars3.githubusercontent.com/u/9341267?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matt-long", "html_url": "https://github.com/matt-long", "followers_url": "https://api.github.com/users/matt-long/followers", "following_url": "https://api.github.com/users/matt-long/following{/other_user}", "gists_url": "https://api.github.com/users/matt-long/gists{/gist_id}", "starred_url": "https://api.github.com/users/matt-long/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matt-long/subscriptions", "organizations_url": "https://api.github.com/users/matt-long/orgs", "repos_url": "https://api.github.com/users/matt-long/repos", "events_url": "https://api.github.com/users/matt-long/events{/privacy}", "received_events_url": "https://api.github.com/users/matt-long/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-10-11T23:52:32Z", "updated_at": "2020-03-02T16:00:13Z", "closed_at": "2020-03-02T16:00:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "We are running into an issue that's difficult to characterize precisely and debug, in part because it is intermittent.\r\n\r\nThis relates to use of `fsspec` in intake-esm. We are reading several zarr stores inside a dask.delayed function. We discovered the `fsspec.get_mapper` is not thread-safe, which is perhaps expected after reading the documentation. \r\n\r\nWe changed the code to pre-generate a dictionary of mapping like this\r\n```python\r\nmapper_dict = {\r\n            path: fsspec.get_mapper(path) for path in self.df[path_column_name]\r\n        }  #\r\n```\r\nwhere `self.df[path_column_name]` contains a strings like 'gs://cmip6/AerChemMIP/BCC/BCC-ESM1/ssp370/r1i1p1f1/Amon/pr/gn/'.\r\n\r\nWe subsequently use `mapper_dict[path]` in the call to `xarray.open_zarr`, which is inside a `dask.delayed` function.\r\n\r\nThis works most of the time, but we get intermittent failures that seem like perhaps the mapping has been disrupted. The failure rate is order 20%. This is the error message.\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<timed exec> in <module>\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/core.py in to_dataset_dict(self, zarr_kwargs, cdf_kwargs)\r\n    167         self.zarr_kwargs = zarr_kwargs\r\n    168         self.cdf_kwargs = cdf_kwargs\r\n--> 169         return self.to_dask()\r\n    170 \r\n    171     def _get_schema(self):\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_xarray/base.py in to_dask(self)\r\n     67     def to_dask(self):\r\n     68         \"\"\"Return xarray object where variables are dask arrays\"\"\"\r\n---> 69         return self.read_chunked()\r\n     70 \r\n     71     def close(self):\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_xarray/base.py in read_chunked(self)\r\n     42     def read_chunked(self):\r\n     43         \"\"\"Return xarray object (which will have chunks)\"\"\"\r\n---> 44         self._load_metadata()\r\n     45         return self._ds\r\n     46 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake/source/base.py in _load_metadata(self)\r\n    115         \"\"\"load metadata only if needed\"\"\"\r\n    116         if self._schema is None:\r\n--> 117             self._schema = self._get_schema()\r\n    118             self.datashape = self._schema.datashape\r\n    119             self.dtype = self._schema.dtype\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/core.py in _get_schema(self)\r\n    172         from intake.source.base import Schema\r\n    173 \r\n--> 174         self._open_dataset()\r\n    175         self._schema = Schema(\r\n    176             datashape=None, dtype=None, shape=None, npartitions=None, extra_metadata={}\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/core.py in _open_dataset(self)\r\n    233         ]\r\n    234 \r\n--> 235         dsets = dask.compute(*dsets)\r\n    236         del mapper_dict\r\n    237 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/dask/base.py in compute(*args, **kwargs)\r\n    444     keys = [x.__dask_keys__() for x in collections]\r\n    445     postcomputes = [x.__dask_postcompute__() for x in collections]\r\n--> 446     results = schedule(dsk, keys, **kwargs)\r\n    447     return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])\r\n    448 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/distributed/client.py in get(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\r\n   2509                     should_rejoin = False\r\n   2510             try:\r\n-> 2511                 results = self.gather(packed, asynchronous=asynchronous, direct=direct)\r\n   2512             finally:\r\n   2513                 for f in futures.values():\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/distributed/client.py in gather(self, futures, errors, direct, asynchronous)\r\n   1809                 direct=direct,\r\n   1810                 local_worker=local_worker,\r\n-> 1811                 asynchronous=asynchronous,\r\n   1812             )\r\n   1813 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/distributed/client.py in sync(self, func, asynchronous, callback_timeout, *args, **kwargs)\r\n    750         else:\r\n    751             return sync(\r\n--> 752                 self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\r\n    753             )\r\n    754 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/distributed/utils.py in sync(loop, func, callback_timeout, *args, **kwargs)\r\n    325             e.wait(10)\r\n    326     if error[0]:\r\n--> 327         six.reraise(*error[0])\r\n    328     else:\r\n    329         return result[0]\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/six.py in reraise(tp, value, tb)\r\n    691             if value.__traceback__ is not tb:\r\n    692                 raise value.with_traceback(tb)\r\n--> 693             raise value\r\n    694         finally:\r\n    695             value = None\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/distributed/utils.py in f()\r\n    310             if callback_timeout is not None:\r\n    311                 future = gen.with_timeout(timedelta(seconds=callback_timeout), future)\r\n--> 312             result[0] = yield future\r\n    313         except Exception as exc:\r\n    314             error[0] = sys.exc_info()\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/tornado/gen.py in run(self)\r\n    733 \r\n    734                     try:\r\n--> 735                         value = future.result()\r\n    736                     except Exception:\r\n    737                         exc_info = sys.exc_info()\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/distributed/client.py in _gather(self, futures, errors, direct, local_worker)\r\n   1665                             exc = CancelledError(key)\r\n   1666                         else:\r\n-> 1667                             six.reraise(type(exception), exception, traceback)\r\n   1668                         raise exc\r\n   1669                     if errors == \"skip\":\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/six.py in reraise(tp, value, tb)\r\n    690                 value = tp()\r\n    691             if value.__traceback__ is not tb:\r\n--> 692                 raise value.with_traceback(tb)\r\n    693             raise value\r\n    694         finally:\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/core.py in _load_group_dataset()\r\n    268 \r\n    269     ds = aggregate(\r\n--> 270         aggregation_dict, agg_columns, n_agg, nd, lookup, mapper_dict, zarr_kwargs, cdf_kwargs\r\n    271     )\r\n    272     group_id = '.'.join(key)\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/merge_util.py in aggregate()\r\n     94             return ds\r\n     95 \r\n---> 96     return apply_aggregation(v)\r\n     97 \r\n     98 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/merge_util.py in apply_aggregation()\r\n     76             dsets = [\r\n     77                 apply_aggregation(value, agg_column, key=key, level=level + 1)\r\n---> 78                 for key, value in v.items()\r\n     79             ]\r\n     80             keys = list(v.keys())\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/merge_util.py in <listcomp>()\r\n     76             dsets = [\r\n     77                 apply_aggregation(value, agg_column, key=key, level=level + 1)\r\n---> 78                 for key, value in v.items()\r\n     79             ]\r\n     80             keys = list(v.keys())\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/merge_util.py in apply_aggregation()\r\n     76             dsets = [\r\n     77                 apply_aggregation(value, agg_column, key=key, level=level + 1)\r\n---> 78                 for key, value in v.items()\r\n     79             ]\r\n     80             keys = list(v.keys())\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/merge_util.py in <listcomp>()\r\n     76             dsets = [\r\n     77                 apply_aggregation(value, agg_column, key=key, level=level + 1)\r\n---> 78                 for key, value in v.items()\r\n     79             ]\r\n     80             keys = list(v.keys())\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/merge_util.py in apply_aggregation()\r\n     60                 data_format=data_format,\r\n     61                 zarr_kwargs=zarr_kwargs,\r\n---> 62                 cdf_kwargs=cdf_kwargs,\r\n     63             )\r\n     64 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/intake_esm/merge_util.py in open_dataset()\r\n    100 \r\n    101     if data_format == 'zarr':\r\n--> 102         ds = xr.open_zarr(path, **zarr_kwargs)\r\n    103         return _set_coords(ds, varname)\r\n    104 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/xarray/backends/zarr.py in open_zarr()\r\n    617         synchronizer=synchronizer,\r\n    618         group=group,\r\n--> 619         consolidated=consolidated,\r\n    620     )\r\n    621     ds = maybe_decode_store(zarr_store)\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/xarray/backends/zarr.py in open_group()\r\n    277         if consolidated:\r\n    278             # TODO: an option to pass the metadata_key keyword\r\n--> 279             zarr_group = zarr.open_consolidated(store, **open_kwargs)\r\n    280         else:\r\n    281             zarr_group = zarr.open_group(store, **open_kwargs)\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/zarr/convenience.py in open_consolidated()\r\n   1180 \r\n   1181     # setup metadata sotre\r\n-> 1182     meta_store = ConsolidatedMetadataStore(store, metadata_key=metadata_key)\r\n   1183 \r\n   1184     # pass through\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/zarr/storage.py in __init__()\r\n   2455             d = store[metadata_key].decode()  # pragma: no cover\r\n   2456         else:  # pragma: no cover\r\n-> 2457             d = store[metadata_key]\r\n   2458         meta = json_loads(d)\r\n   2459 \r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/fsspec/mapping.py in __getitem__()\r\n     78             if default is not None:\r\n     79                 return default\r\n---> 80             raise KeyError(key)\r\n     81         return result\r\n     82 \r\n\r\nKeyError: 'cmip6/CMIP/CCCma/CanESM5/historical/r10i1p2f1/Amon/pr/gn/.zmetadata'****\r\n```\r\nRunning without the distributed scheduler seems to avoid the problem.\r\n\r\ncc @rabernat ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/151", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/151/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/151/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/151/events", "html_url": "https://github.com/intake/filesystem_spec/issues/151", "id": 503136343, "node_id": "MDU6SXNzdWU1MDMxMzYzNDM=", "number": 151, "title": "Fuse is no longer optional in tests", "user": {"login": "QuLogic", "id": 302469, "node_id": "MDQ6VXNlcjMwMjQ2OQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/302469?v=4", "gravatar_id": "", "url": "https://api.github.com/users/QuLogic", "html_url": "https://github.com/QuLogic", "followers_url": "https://api.github.com/users/QuLogic/followers", "following_url": "https://api.github.com/users/QuLogic/following{/other_user}", "gists_url": "https://api.github.com/users/QuLogic/gists{/gist_id}", "starred_url": "https://api.github.com/users/QuLogic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/QuLogic/subscriptions", "organizations_url": "https://api.github.com/users/QuLogic/orgs", "repos_url": "https://api.github.com/users/QuLogic/repos", "events_url": "https://api.github.com/users/QuLogic/events{/privacy}", "received_events_url": "https://api.github.com/users/QuLogic/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-06T17:57:30Z", "updated_at": "2019-10-17T13:23:32Z", "closed_at": "2019-10-17T13:23:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The import of `fsspec.fuse` and the `importorskip` are in reverse, so it fails to import `fuse` before it can realize the file should be skipped. This worked correctly in 0.5.1.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/148", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/148/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/148/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/148/events", "html_url": "https://github.com/intake/filesystem_spec/issues/148", "id": 497322992, "node_id": "MDU6SXNzdWU0OTczMjI5OTI=", "number": 148, "title": "test_memory.py::test_ls failure on py35.", "user": {"login": "asford", "id": 282792, "node_id": "MDQ6VXNlcjI4Mjc5Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/282792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asford", "html_url": "https://github.com/asford", "followers_url": "https://api.github.com/users/asford/followers", "following_url": "https://api.github.com/users/asford/following{/other_user}", "gists_url": "https://api.github.com/users/asford/gists{/gist_id}", "starred_url": "https://api.github.com/users/asford/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asford/subscriptions", "organizations_url": "https://api.github.com/users/asford/orgs", "repos_url": "https://api.github.com/users/asford/repos", "events_url": "https://api.github.com/users/asford/events{/privacy}", "received_events_url": "https://api.github.com/users/asford/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-23T20:53:49Z", "updated_at": "2020-02-27T21:14:25Z", "closed_at": "2020-02-27T21:14:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "fsspec/implementations/tests/test_memory.py::test_ls fails on python 3.5.\r\n\r\n[Travis log](https://travis-ci.org/intake/filesystem_spec/jobs/587239702#L757-L773):\r\n```\r\n___________________________________ test_ls ____________________________________\r\nm = <fsspec.implementations.memory.MemoryFileSystem object at 0x7fcdad8746d8>\r\n    def test_ls(m):\r\n        m.touch(\"/dir/afile\")\r\n        m.touch(\"/dir/dir1/bfile\")\r\n        m.touch(\"/dir/dir1/cfile\")\r\n    \r\n        assert m.ls(\"/\", False) == [\"/dir/\"]\r\n        assert m.ls(\"/dir\", False) == [\"/dir/afile\", \"/dir/dir1/\"]\r\n>       assert m.ls(\"/dir\", True)[0][\"type\"] == \"file\"\r\nE       AssertionError: assert 'directory' == 'file'\r\nE         - directory\r\nE         + file\r\nfsspec/implementations/tests/test_memory.py:29: AssertionError\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/147", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/147/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/147/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/147/events", "html_url": "https://github.com/intake/filesystem_spec/issues/147", "id": 497320631, "node_id": "MDU6SXNzdWU0OTczMjA2MzE=", "number": 147, "title": "test_file.py::test_pickle failure on py35.", "user": {"login": "asford", "id": 282792, "node_id": "MDQ6VXNlcjI4Mjc5Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/282792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asford", "html_url": "https://github.com/asford", "followers_url": "https://api.github.com/users/asford/followers", "following_url": "https://api.github.com/users/asford/following{/other_user}", "gists_url": "https://api.github.com/users/asford/gists{/gist_id}", "starred_url": "https://api.github.com/users/asford/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asford/subscriptions", "organizations_url": "https://api.github.com/users/asford/orgs", "repos_url": "https://api.github.com/users/asford/repos", "events_url": "https://api.github.com/users/asford/events{/privacy}", "received_events_url": "https://api.github.com/users/asford/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-23T20:48:36Z", "updated_at": "2020-02-27T21:14:25Z", "closed_at": "2020-02-27T21:14:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`fsspec/tests/test_file.py::test_pickle` fails an equality assertion run under python 3.5.\r\n\r\n[Travis log](https://travis-ci.org/intake/filesystem_spec/jobs/587239702#L774-L790):\r\n\r\n```\r\n_________________________________ test_pickle __________________________________\r\nftp_writable = ('localhost', 2121, 'user', 'pass')\r\n    def test_pickle(ftp_writable):\r\n        host, port, user, pw = ftp_writable\r\n        ftp = FTPFileSystem(host=host, port=port, username=user, password=pw)\r\n    \r\n        f = ftp.open(\"/out\", \"rb\")\r\n    \r\n        f2 = pickle.loads(pickle.dumps(f))\r\n>       assert f == f2\r\nE       assert <File-like ob...eSystem, /out> == <File-like obj...eSystem, /out>\r\nE         Full diff:\r\nE         <File-like object FTPFileSystem, /out>\r\nfsspec/tests/test_file.py:16: AssertionError\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/144", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/144/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/144/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/144/events", "html_url": "https://github.com/intake/filesystem_spec/issues/144", "id": 496437857, "node_id": "MDU6SXNzdWU0OTY0Mzc4NTc=", "number": 144, "title": "protocol stripping problem", "user": {"login": "rabernat", "id": 1197350, "node_id": "MDQ6VXNlcjExOTczNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1197350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rabernat", "html_url": "https://github.com/rabernat", "followers_url": "https://api.github.com/users/rabernat/followers", "following_url": "https://api.github.com/users/rabernat/following{/other_user}", "gists_url": "https://api.github.com/users/rabernat/gists{/gist_id}", "starred_url": "https://api.github.com/users/rabernat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rabernat/subscriptions", "organizations_url": "https://api.github.com/users/rabernat/orgs", "repos_url": "https://api.github.com/users/rabernat/repos", "events_url": "https://api.github.com/users/rabernat/events{/privacy}", "received_events_url": "https://api.github.com/users/rabernat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-20T16:13:33Z", "updated_at": "2019-09-20T17:20:33Z", "closed_at": "2019-09-20T17:20:33Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": " I am trying to read a zarr store over plain http\r\n\r\nThis file exists:\r\n```\r\ncurl http://s3.wasabisys.com/era5-single-reanalysis/.zmetadata\r\n```\r\n\r\nHowever, I can't access it from an HTTP filesystem\r\n```python\r\nimport fsspec\r\nhttp_url = 'http://s3.wasabisys.com/era5-single-reanalysis'\r\nmapper = fsspec.get_mapper(http_url)\r\nmapper['.zmetadata']\r\n```\r\n\r\n```\r\nMissingSchema: Invalid URL 's3.wasabisys.com/era5-single-reanalysis/.zmetadata': No schema supplied. Perhaps you meant http://s3.wasabisys.com/era5-single-reanalysis/.zmetadata?\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-16-690c397eba4f> in <module>\r\n      2 http_url = 'http://s3.wasabisys.com/era5-single-reanalysis'\r\n      3 mapper = fsspec.get_mapper(http_url)\r\n----> 4 mapper['.zmetadata']\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/fsspec/mapping.py in __getitem__(self, key, default)\r\n     76             if default is not None:\r\n     77                 return default\r\n---> 78             raise KeyError(key)\r\n     79         return result\r\n     80 \r\n\r\nKeyError: 's3.wasabisys.com/era5-single-reanalysis/.zmetadata'\r\n```\r\n\r\nAccording to @martindurant on gitter\r\n\r\n> fs.get_mapper() works as expected, but get_mapper does not, it strips the protocol instead of deferring to the class implementation of what to do with the protocol - this is only an issue for HTTP, I think.\r\n\r\n```\r\n--- a/fsspec/mapping.py\r\n+++ b/fsspec/mapping.py\r\n@@ -157,4 +157,4 @@ def get_mapper(url, check=False, create=False, **kwargs):\r\n     cls = get_filesystem_class(protocol)\r\n     fs = cls(**kwargs)\r\n     # Removing protocol here - could defer to each open() on the backend\r\n-    return FSMap(path, fs, check, create)\r\n+    return FSMap(url, fs, check, create)\r\n```\r\n\r\nThis feels like the sort of thing that should be covered by the test suite.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/135", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/135/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/135/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/135/events", "html_url": "https://github.com/intake/filesystem_spec/issues/135", "id": 493296861, "node_id": "MDU6SXNzdWU0OTMyOTY4NjE=", "number": 135, "title": "issue with ftp traversal, KeyError \"name\"", "user": {"login": "hardingnj", "id": 4437708, "node_id": "MDQ6VXNlcjQ0Mzc3MDg=", "avatar_url": "https://avatars0.githubusercontent.com/u/4437708?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hardingnj", "html_url": "https://github.com/hardingnj", "followers_url": "https://api.github.com/users/hardingnj/followers", "following_url": "https://api.github.com/users/hardingnj/following{/other_user}", "gists_url": "https://api.github.com/users/hardingnj/gists{/gist_id}", "starred_url": "https://api.github.com/users/hardingnj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hardingnj/subscriptions", "organizations_url": "https://api.github.com/users/hardingnj/orgs", "repos_url": "https://api.github.com/users/hardingnj/repos", "events_url": "https://api.github.com/users/hardingnj/events{/privacy}", "received_events_url": "https://api.github.com/users/hardingnj/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-09-13T12:24:13Z", "updated_at": "2020-03-02T15:29:51Z", "closed_at": "2020-03-02T15:29:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "I think this is a bug (version `0.4.4`), caused by some entries (`cdir` and `pdir`) on FTP not having the `name` attribute. Very happy to submit a PR if so, should be a straightforward fix.\r\n\r\n```\r\nimport fsspec\r\nhost = fsspec.filesystem('ftp', host='ngs.sanger.ac.uk') \r\nhost.ls(\".\")\r\n```\r\ngives:\r\n```\r\n[{'modify': '20180615104058',\r\n  'perm': 'fle',\r\n  'type': 'cdir',\r\n  'unique': 'FC02U80',\r\n  'unix.group': '0',\r\n  'unix.mode': '0755',\r\n  'unix.owner': '0'},\r\n {'modify': '20180615104058',\r\n  'perm': 'fle',\r\n  'type': 'pdir',\r\n  'unique': 'FC02U80',\r\n  'unix.group': '0',\r\n  'unix.mode': '0755',\r\n  'unix.owner': '0'},\r\n {'modify': '20190513162006',\r\n  'perm': 'fle',\r\n  'type': 'dir',\r\n  'unique': 'FC02U83',\r\n  'unix.group': '0',\r\n  'unix.mode': '0755',\r\n  'unix.owner': '0',\r\n  'name': '/./production',\r\n  'size': 0},\r\n {'modify': '20180615104110',\r\n  'perm': 'fle',\r\n  'type': 'dir',\r\n  'unique': 'FC02U80000080',\r\n  'unix.group': '0',\r\n  'unix.mode': '0755',\r\n  'unix.owner': '0',\r\n  'name': '/./scratch',\r\n  'size': 0},\r\n {'modify': '20180119093730',\r\n  'perm': 'adfr',\r\n  'size': 1099,\r\n  'type': 'file',\r\n  'unique': 'FC02U3937',\r\n  'unix.group': '0',\r\n  'unix.mode': '0644',\r\n  'unix.owner': '0',\r\n  'name': '/./README'}]\r\n```\r\n\r\nbut\r\n```\r\nhost.open(\"README\")\r\n```\r\ngives:\r\n```\r\n...\r\n\r\n~/git/vector-ops/binder/deps/conda/envs/vector-ops-c668a73/lib/python3.6/site-packages/fsspec/implementations/ftp.py in <listcomp>(.0)\r\n    108         path = self._strip_protocol(path)\r\n    109         files = self.ls(self._parent(path), True)\r\n--> 110         return [f for f in files if f['name'] == path][0]\r\n    111 \r\n    112     def _open(self, path, mode='rb', block_size=None, autocommit=True,\r\n\r\nKeyError: 'name'\r\n```\r\nI guess because when traversing `pdir` or `cdir`, it fails to find the attribute. Perhaps because line  `109` is not functioning as intended in allowing dirs as well?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/131", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/131/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/131/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/131/events", "html_url": "https://github.com/intake/filesystem_spec/issues/131", "id": 492333846, "node_id": "MDU6SXNzdWU0OTIzMzM4NDY=", "number": 131, "title": "Black-ening?", "user": {"login": "asford", "id": 282792, "node_id": "MDQ6VXNlcjI4Mjc5Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/282792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asford", "html_url": "https://github.com/asford", "followers_url": "https://api.github.com/users/asford/followers", "following_url": "https://api.github.com/users/asford/following{/other_user}", "gists_url": "https://api.github.com/users/asford/gists{/gist_id}", "starred_url": "https://api.github.com/users/asford/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asford/subscriptions", "organizations_url": "https://api.github.com/users/asford/orgs", "repos_url": "https://api.github.com/users/asford/repos", "events_url": "https://api.github.com/users/asford/events{/privacy}", "received_events_url": "https://api.github.com/users/asford/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-09-11T16:11:16Z", "updated_at": "2019-09-19T18:32:31Z", "closed_at": "2019-09-19T18:32:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "@martindurant Would you consider adopting [black](https://black.readthedocs.io/en/stable/index.html) as the code format for this repo? I've just noticed in my two recent PRs that the \"diff radius\" was a bit larger than I'd intended due to accidental code formatting in my editor. Having a pre-established code format may be useful if more folks begin joining this project.\r\n\r\nI would be happy to open a PR for this. It would include:\r\n\r\n- Setup up a pre-commit config for code formatting.\r\n- Add a code formatting check to your existing CI.\r\n- Blacken the code base.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/129", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/129/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/129/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/129/events", "html_url": "https://github.com/intake/filesystem_spec/issues/129", "id": 491365529, "node_id": "MDU6SXNzdWU0OTEzNjU1Mjk=", "number": 129, "title": "`infer_compression` does not support zstd/lz4 compression.", "user": {"login": "asford", "id": 282792, "node_id": "MDQ6VXNlcjI4Mjc5Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/282792?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asford", "html_url": "https://github.com/asford", "followers_url": "https://api.github.com/users/asford/followers", "following_url": "https://api.github.com/users/asford/following{/other_user}", "gists_url": "https://api.github.com/users/asford/gists{/gist_id}", "starred_url": "https://api.github.com/users/asford/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asford/subscriptions", "organizations_url": "https://api.github.com/users/asford/orgs", "repos_url": "https://api.github.com/users/asford/repos", "events_url": "https://api.github.com/users/asford/events{/privacy}", "received_events_url": "https://api.github.com/users/asford/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-09T22:57:22Z", "updated_at": "2019-09-11T15:50:04Z", "closed_at": "2019-09-11T15:50:04Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The `fsspec.core.open` interface provides a `compression=\"infer\"` option, which infers a file's compression via file extension. I would expect that this interface support all compression types, including the built-in lz4 and zstd compression tools, but it does not currently recognize the `lz4` and `zstd` compression types. Ideally, any dynamically registered compression method should support a set of file extensions for compatibility with `infer_compression`.\r\n\r\nThe current implementation is a *bit* tricky to fix, as a simple check against `fsspec.compression.compr` introduces an import cycle between `utils` and `compression`. As `utils.infer_compression` is used by dask, we can assume that this function must remain in it's current namespace.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/123", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/123/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/123/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/123/events", "html_url": "https://github.com/intake/filesystem_spec/issues/123", "id": 487454768, "node_id": "MDU6SXNzdWU0ODc0NTQ3Njg=", "number": 123, "title": "regressions with llcreader", "user": {"login": "rabernat", "id": 1197350, "node_id": "MDQ6VXNlcjExOTczNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1197350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rabernat", "html_url": "https://github.com/rabernat", "followers_url": "https://api.github.com/users/rabernat/followers", "following_url": "https://api.github.com/users/rabernat/following{/other_user}", "gists_url": "https://api.github.com/users/rabernat/gists{/gist_id}", "starred_url": "https://api.github.com/users/rabernat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rabernat/subscriptions", "organizations_url": "https://api.github.com/users/rabernat/orgs", "repos_url": "https://api.github.com/users/rabernat/repos", "events_url": "https://api.github.com/users/rabernat/events{/privacy}", "received_events_url": "https://api.github.com/users/rabernat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-08-30T12:22:16Z", "updated_at": "2019-09-05T15:03:20Z", "closed_at": "2019-09-05T15:03:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I am getting some regressions with the latest release of fsspec on my xmitgcm package.\r\nhttps://travis-ci.org/xgcm/xmitgcm/jobs/572386378\r\n\r\n\r\nI haven't had time to look into this is too much depth, but the errors look like\r\n\r\n```\r\nE           KeyError: 'https://storage.googleapis.com/pangeo-ecco/llc/masks/llc_2160_masks.zarr/.zmetadata'\r\n...\r\nE           TypeError: request() got an unexpected keyword argument 'size_policy'\r\n```\r\n\r\nI thought I would report this here while I dig further.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/110", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/110/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/110/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/110/events", "html_url": "https://github.com/intake/filesystem_spec/issues/110", "id": 482811610, "node_id": "MDU6SXNzdWU0ODI4MTE2MTA=", "number": 110, "title": "BytesCache bug leading to duplicate file reads for small files on remote storage", "user": {"login": "hayesgb", "id": 12595382, "node_id": "MDQ6VXNlcjEyNTk1Mzgy", "avatar_url": "https://avatars1.githubusercontent.com/u/12595382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hayesgb", "html_url": "https://github.com/hayesgb", "followers_url": "https://api.github.com/users/hayesgb/followers", "following_url": "https://api.github.com/users/hayesgb/following{/other_user}", "gists_url": "https://api.github.com/users/hayesgb/gists{/gist_id}", "starred_url": "https://api.github.com/users/hayesgb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hayesgb/subscriptions", "organizations_url": "https://api.github.com/users/hayesgb/orgs", "repos_url": "https://api.github.com/users/hayesgb/repos", "events_url": "https://api.github.com/users/hayesgb/events{/privacy}", "received_events_url": "https://api.github.com/users/hayesgb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2019-08-20T11:46:50Z", "updated_at": "2019-08-29T09:08:09Z", "closed_at": "2019-08-27T18:51:31Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm working on an Azure Datalake Gen2 package using fsspec and encountered strange behavior with BytesCacheing, where the file being read from the datalake and calling compute() on the cached dataframe appears as an exact duplicate of rows of the same dataframe.\r\n\r\nIt appears to be caused by the _fetch method in BytesCache when reading a file into Dask.  During what should be the first read when calling \"dd.read_csv()\", the value of start (when none) is passed as zero, but when calling the .compute() method on the dataframe, the file gets read again, leading to the duplication of rows.  Explicitly setting start, end= 0,0 like: \r\n\r\n```\r\ndef _fetch(self, start, end):\r\n        # TODO: only set start/end after fetch, in case it fails?\r\n        # is this where retry logic might go?\r\n        if self.start is None and self.end is None:\r\n            # First read\r\n            start, end = 0, 0\r\n            self.cache = self.fetcher(start, end + self.blocksize)\r\n            self.start = start\r\n```\r\n\r\nappears to fix it for me.  Have you observed any issues with BytesCacheing elsewhere?   ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/104", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/104/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/104/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/104/events", "html_url": "https://github.com/intake/filesystem_spec/issues/104", "id": 480308045, "node_id": "MDU6SXNzdWU0ODAzMDgwNDU=", "number": 104, "title": "AbstractBufferedFile.__fspath__ breaks dask's PyArrow.orc test", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-08-13T18:41:59Z", "updated_at": "2019-08-13T20:32:26Z", "closed_at": "2019-08-13T20:32:26Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "With fsspec master, the following dask test fails\r\n\r\n```\r\n$ pytest dask/dataframe/io/tests/test_orc.py::test_orc_with_backend \r\n```\r\n\r\nThe pyarrow error message isn't really helpful. I've traced it down to AbstractBufferedFile.__fspath__. Removing that, the test passes.\r\n\r\n```diff\r\ndiff --git a/fsspec/spec.py b/fsspec/spec.py\r\nindex 0b66f99..6567ad9 100644\r\n--- a/fsspec/spec.py\r\n+++ b/fsspec/spec.py\r\n@@ -1162,10 +1162,6 @@ class AbstractBufferedFile(io.IOBase):\r\n \r\n     def __str__(self):\r\n         return \"<File-like object %s, %s>\" % (type(self.fs).__name__, self.path)\r\n-\r\n-    def __fspath__(self):\r\n-        return self.fs.protocol + \"://\" + self.path\r\n-\r\n     __repr__ = __str__\r\n \r\n     def __enter__(self):\r\n```\r\n\r\nDoes fspath make sense on this object? Is it actually present on the filesystem, or just in memory?\r\n\r\n\r\nxref https://github.com/dask/dask/pull/5267", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/102", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/102/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/102/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/102/events", "html_url": "https://github.com/intake/filesystem_spec/issues/102", "id": 478737896, "node_id": "MDU6SXNzdWU0Nzg3Mzc4OTY=", "number": 102, "title": "A simpler caching file-system", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-08-09T00:05:02Z", "updated_at": "2019-10-03T19:13:30Z", "closed_at": "2019-10-03T19:13:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The caching file-system downloads from other file systems to a local store, and uses MMap to only fetch the chunks that are accessed, to a sparse file. An alternative mode of the same class would simply download whole files on first access, potentially with on-the-fly decompression, and then provide the local copy. This could then replace most/all of the functionality in Intake's cache layer (although who takes responsibility for metadata for checkpointing remains to be decided).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/96", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/96/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/96/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/96/events", "html_url": "https://github.com/intake/filesystem_spec/issues/96", "id": 477486065, "node_id": "MDU6SXNzdWU0Nzc0ODYwNjU=", "number": 96, "title": "Issue with Dask read_csv from S3", "user": {"login": "leiwenxi", "id": 53831840, "node_id": "MDQ6VXNlcjUzODMxODQw", "avatar_url": "https://avatars3.githubusercontent.com/u/53831840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leiwenxi", "html_url": "https://github.com/leiwenxi", "followers_url": "https://api.github.com/users/leiwenxi/followers", "following_url": "https://api.github.com/users/leiwenxi/following{/other_user}", "gists_url": "https://api.github.com/users/leiwenxi/gists{/gist_id}", "starred_url": "https://api.github.com/users/leiwenxi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leiwenxi/subscriptions", "organizations_url": "https://api.github.com/users/leiwenxi/orgs", "repos_url": "https://api.github.com/users/leiwenxi/repos", "events_url": "https://api.github.com/users/leiwenxi/events{/privacy}", "received_events_url": "https://api.github.com/users/leiwenxi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-08-06T16:45:05Z", "updated_at": "2019-08-06T17:58:26Z", "closed_at": "2019-08-06T17:58:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "when doing \r\n\r\n```\r\nimport pandas as pd\r\nimport s3fs\r\nimport dask.dataframe as dd\r\n\r\nddf=dd.read_csv(\"s3://bucket/data/path.csv\")\r\n```\r\n\r\ngetting the following error\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-34-64a49ed7781b> in <module>\r\n----> 1 df = dd.read_csv(\"s3://amra-s3-0066-00-external/promotion-data/transactions/Kay_trans_data_201806_202005.csv\", storage_options={'token': fs})\r\n\r\n/opt/anaconda/envs/promo/lib/python3.7/site-packages/dask/dataframe/io/csv.py in read(urlpath, blocksize, collection, lineterminator, compression, sample, enforce, assume_missing, storage_options, include_path_column, **kwargs)\r\n    580             storage_options=storage_options,\r\n    581             include_path_column=include_path_column,\r\n--> 582             **kwargs\r\n    583         )\r\n    584 \r\n\r\n/opt/anaconda/envs/promo/lib/python3.7/site-packages/dask/dataframe/io/csv.py in read_pandas(reader, urlpath, blocksize, collection, lineterminator, compression, sample, enforce, assume_missing, storage_options, include_path_column, **kwargs)\r\n    407         compression=compression,\r\n    408         include_path=include_path_column,\r\n--> 409         **(storage_options or {})\r\n    410     )\r\n    411 \r\n\r\n/opt/anaconda/envs/promo/lib/python3.7/site-packages/dask/bytes/core.py in read_bytes(urlpath, delimiter, not_zero, blocksize, sample, compression, include_path, **kwargs)\r\n     93 \r\n     94     \"\"\"\r\n---> 95     fs, fs_token, paths = get_fs_token_paths(urlpath, mode=\"rb\", storage_options=kwargs)\r\n     96 \r\n     97     if len(paths) == 0:\r\n\r\n/opt/anaconda/envs/promo/lib/python3.7/site-packages/fsspec/core.py in get_fs_token_paths(urlpath, mode, num, name_function, storage_options, protocol)\r\n    313         cls = get_filesystem_class(protocol)\r\n    314 \r\n--> 315         options = cls._get_kwargs_from_urls(urlpath)\r\n    316         path = cls._strip_protocol(urlpath)\r\n    317         update_storage_options(options, storage_options)\r\n\r\nAttributeError: type object 'S3FileSystem' has no attribute '_get_kwargs_from_urls'\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/92", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/92/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/92/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/92/events", "html_url": "https://github.com/intake/filesystem_spec/issues/92", "id": 476971568, "node_id": "MDU6SXNzdWU0NzY5NzE1Njg=", "number": 92, "title": "known_implementations showing gcsfs with err even when gcsfs installed", "user": {"login": "andyshinn", "id": 315485, "node_id": "MDQ6VXNlcjMxNTQ4NQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/315485?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andyshinn", "html_url": "https://github.com/andyshinn", "followers_url": "https://api.github.com/users/andyshinn/followers", "following_url": "https://api.github.com/users/andyshinn/following{/other_user}", "gists_url": "https://api.github.com/users/andyshinn/gists{/gist_id}", "starred_url": "https://api.github.com/users/andyshinn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andyshinn/subscriptions", "organizations_url": "https://api.github.com/users/andyshinn/orgs", "repos_url": "https://api.github.com/users/andyshinn/repos", "events_url": "https://api.github.com/users/andyshinn/events{/privacy}", "received_events_url": "https://api.github.com/users/andyshinn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-05T17:21:13Z", "updated_at": "2019-08-05T17:56:16Z", "closed_at": "2019-08-05T17:32:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to debug gcsfs not working in Dask and tracing back to fsspec via `known_implementations`. It says there is an error and requires `gcsfs` to be installed (which it is):\r\n\r\n```\r\n>>> import gcsfs\r\n>>> from fsspec.registry import known_implementations\r\n>>> known_implementations\r\n{'file': {'class': 'fsspec.implementations.local.LocalFileSystem'}, 'memory': {'class': 'fsspec.implementations.memory.MemoryFileSystem'}, 'http': {'class': 'fsspec.implementations.http.HTTPFileSystem', 'err': 'HTTPFileSystem requires \"requests\" to be installed'}, 'https': {'class': 'fsspec.implementations.http.HTTPFileSystem', 'err': 'HTTPFileSystem requires \"requests\" to be installed'}, 'zip': {'class': 'fsspec.implementations.zip.ZipFileSystem'}, 'gcs': {'class': 'gcsfs.GCSFileSystem', 'err': 'Please install gcsfs to access Google Storage'}, 'gs': {'class': 'gcsfs.GCSFileSystem', 'err': 'Please install gcsfs to access Google Storage'}, 'sftp': {'class': 'fsspec.implementations.sftp.SFTPFileSystem', 'err': 'SFTPFileSystem requires \"paramiko\" to be installed'}, 'ssh': {'class': 'fsspec.implementations.sftp.SFTPFileSystem', 'err': 'SFTPFileSystem requires \"paramiko\" to be installed'}, 'ftp': {'class': 'fsspec.implementations.ftp.FTPFileSystem'}, 'hdfs': {'class': 'fsspec.implementations.hdfs.PyArrowHDFS', 'err': 'pyarrow and local java libraries required for HDFS'}, 'webhdfs': {'class': 'fsspec.implementations.webhdfs.WebHDFS', 'err': 'webHDFS access requires \"requests\" to be installed'}, 's3': {'class': 's3fs.S3FileSystem', 'err': 'Install s3fs to access S3'}, 'cached': {'class': 'fsspec.implementations.cached.CachingFileSystem'}, 'dask': {'class': 'fsspec.implementations.dask.DaskWorkerFileSystem', 'err': 'Install dask distributed to access worker file system'}}\r\n>>> \r\n```\r\n\r\nThis is fsspec 0.4.1 and gcsfs 0.3.0. Should `known_implementations` be listing it without an `err` key if it is working correctly? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/90", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/90/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/90/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/90/events", "html_url": "https://github.com/intake/filesystem_spec/issues/90", "id": 476700695, "node_id": "MDU6SXNzdWU0NzY3MDA2OTU=", "number": 90, "title": "error when reading empty file using CachingFileSystem", "user": {"login": "ophiry", "id": 5228696, "node_id": "MDQ6VXNlcjUyMjg2OTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/5228696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ophiry", "html_url": "https://github.com/ophiry", "followers_url": "https://api.github.com/users/ophiry/followers", "following_url": "https://api.github.com/users/ophiry/following{/other_user}", "gists_url": "https://api.github.com/users/ophiry/gists{/gist_id}", "starred_url": "https://api.github.com/users/ophiry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ophiry/subscriptions", "organizations_url": "https://api.github.com/users/ophiry/orgs", "repos_url": "https://api.github.com/users/ophiry/repos", "events_url": "https://api.github.com/users/ophiry/events{/privacy}", "received_events_url": "https://api.github.com/users/ophiry/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-05T07:31:45Z", "updated_at": "2019-08-13T19:58:21Z", "closed_at": "2019-08-13T19:58:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "example:\r\n```\r\nfrom fsspec.implementations.cached import CachingFileSystem\r\nfs = CachingFileSystem(target_protocol='s3')\r\nfs.open('s3://bucket/empty')\r\n\r\n```\r\n```\r\n{'fn': '01c8b40c487e3c79a7549715f6fff04a15e6b0017bcb83cb98d9278b0b4ed4ec', 'blocks': set()}\r\nTraceback (most recent call last):\r\n  File \"/fsspec_test.py\", line 3, in <module>\r\n    fs.open('s3://bucket/empty')\r\n  File \"/usr/local/miniconda3/envs//lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 157, in <lambda>\r\n    self, *args, **kw\r\n  File \"/usr/local/miniconda3/envs//lib/python3.7/site-packages/fsspec/spec.py\", line 669, in open\r\n    autocommit=ac, **kwargs)\r\n  File \"/usr/local/miniconda3/envs//lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 157, in <lambda>\r\n    self, *args, **kw\r\n  File \"/usr/local/miniconda3/envs//lib/python3.7/site-packages/fsspec/implementations/cached.py\", line 132, in _open\r\n    fn, blocks)\r\n  File \"/usr/local/miniconda3/envs//lib/python3.7/site-packages/fsspec/core.py\", line 397, in __init__\r\n    self.cache = self._makefile()\r\n  File \"/usr/local/miniconda3/envs//lib/python3.7/site-packages/fsspec/core.py\", line 409, in _makefile\r\n    fd.seek(self.size - 1)\r\nOSError: [Errno 22] Invalid argument\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/89", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/89/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/89/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/89/events", "html_url": "https://github.com/intake/filesystem_spec/issues/89", "id": 476465018, "node_id": "MDU6SXNzdWU0NzY0NjUwMTg=", "number": 89, "title": "glob doesn't pass extra parameters to ls", "user": {"login": "ophiry", "id": 5228696, "node_id": "MDQ6VXNlcjUyMjg2OTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/5228696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ophiry", "html_url": "https://github.com/ophiry", "followers_url": "https://api.github.com/users/ophiry/followers", "following_url": "https://api.github.com/users/ophiry/following{/other_user}", "gists_url": "https://api.github.com/users/ophiry/gists{/gist_id}", "starred_url": "https://api.github.com/users/ophiry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ophiry/subscriptions", "organizations_url": "https://api.github.com/users/ophiry/orgs", "repos_url": "https://api.github.com/users/ophiry/repos", "events_url": "https://api.github.com/users/ophiry/events{/privacy}", "received_events_url": "https://api.github.com/users/ophiry/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-08-03T16:02:07Z", "updated_at": "2019-08-09T19:39:03Z", "closed_at": "2019-08-09T19:39:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "according to this: https://github.com/intake/filesystem_spec/blob/master/fsspec/spec.py#L420 glob should pass extra kwargs to the ls function.\r\n\r\nI tried using the details=True flag, but got an exception\r\n\r\n```\r\nimport fsspec\r\nfs = fsspec.get_filesystem_class('s3')()\r\nfs.glob('s3://bucket/*', detail=True)\r\n\r\n```\r\n```\r\n  File \"fsspec_test.py\", line 3, in <module>\r\n    fs.glob('s3://bucket/*', detail=True)\r\n  File \"./lib/python3.7/site-packages/fsspec/spec.py\", line 444, in glob\r\n    allpaths = self.find(root, maxdepth=depth, **kwargs)\r\n  File \"./lib/python3.7/site-packages/fsspec/spec.py\", line 373, in find\r\n    for path, _, files in self.walk(path, maxdepth, **kwargs):\r\nTypeError: walk() got an unexpected keyword argument 'detail'\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/88", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/88/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/88/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/88/events", "html_url": "https://github.com/intake/filesystem_spec/issues/88", "id": 476431752, "node_id": "MDU6SXNzdWU0NzY0MzE3NTI=", "number": 88, "title": "How to use fsspec with persistent local cache in a predefined directory", "user": {"login": "ophiry", "id": 5228696, "node_id": "MDQ6VXNlcjUyMjg2OTY=", "avatar_url": "https://avatars1.githubusercontent.com/u/5228696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ophiry", "html_url": "https://github.com/ophiry", "followers_url": "https://api.github.com/users/ophiry/followers", "following_url": "https://api.github.com/users/ophiry/following{/other_user}", "gists_url": "https://api.github.com/users/ophiry/gists{/gist_id}", "starred_url": "https://api.github.com/users/ophiry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ophiry/subscriptions", "organizations_url": "https://api.github.com/users/ophiry/orgs", "repos_url": "https://api.github.com/users/ophiry/repos", "events_url": "https://api.github.com/users/ophiry/events{/privacy}", "received_events_url": "https://api.github.com/users/ophiry/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-03T08:59:52Z", "updated_at": "2019-10-03T19:13:30Z", "closed_at": "2019-10-03T19:13:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm looking for more details about using local cache with fsspec\r\nspecifically:\r\n1. how to specify if using cache\r\n2. how to specify if the cache should be cleaned on process exit\r\n3. how to control the location of the cache\r\n4. if a file is in the cache, I assume the version of the file is checked to verify the cache is up to date - is it possible o disable this? (for cases I trust the remote files don't change)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/85", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/85/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/85/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/85/events", "html_url": "https://github.com/intake/filesystem_spec/issues/85", "id": 476267449, "node_id": "MDU6SXNzdWU0NzYyNjc0NDk=", "number": 85, "title": "put and get with file fs should support recursive=True", "user": {"login": "kalefranz", "id": 1418419, "node_id": "MDQ6VXNlcjE0MTg0MTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1418419?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kalefranz", "html_url": "https://github.com/kalefranz", "followers_url": "https://api.github.com/users/kalefranz/followers", "following_url": "https://api.github.com/users/kalefranz/following{/other_user}", "gists_url": "https://api.github.com/users/kalefranz/gists{/gist_id}", "starred_url": "https://api.github.com/users/kalefranz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kalefranz/subscriptions", "organizations_url": "https://api.github.com/users/kalefranz/orgs", "repos_url": "https://api.github.com/users/kalefranz/repos", "events_url": "https://api.github.com/users/kalefranz/events{/privacy}", "received_events_url": "https://api.github.com/users/kalefranz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-08-02T16:44:14Z", "updated_at": "2019-08-02T17:39:58Z", "closed_at": "2019-08-02T17:39:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently just  implemented with `shutil.copyfile()`, i.e.\r\n\r\n```\r\n    def copy(self, path1, path2, **kwargs):\r\n        \"\"\" Copy within two locations in the filesystem\"\"\"\r\n        shutil.copyfile(path1, path2)\r\n\r\n    get = copy\r\n    put = copy\r\n```\r\n\r\nwhich only works for single files.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/83", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/83/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/83/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/83/events", "html_url": "https://github.com/intake/filesystem_spec/issues/83", "id": 476263561, "node_id": "MDU6SXNzdWU0NzYyNjM1NjE=", "number": 83, "title": "using rm with recursive=True on a file should succeed", "user": {"login": "kalefranz", "id": 1418419, "node_id": "MDQ6VXNlcjE0MTg0MTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1418419?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kalefranz", "html_url": "https://github.com/kalefranz", "followers_url": "https://api.github.com/users/kalefranz/followers", "following_url": "https://api.github.com/users/kalefranz/following{/other_user}", "gists_url": "https://api.github.com/users/kalefranz/gists{/gist_id}", "starred_url": "https://api.github.com/users/kalefranz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kalefranz/subscriptions", "organizations_url": "https://api.github.com/users/kalefranz/orgs", "repos_url": "https://api.github.com/users/kalefranz/repos", "events_url": "https://api.github.com/users/kalefranz/events{/privacy}", "received_events_url": "https://api.github.com/users/kalefranz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-08-02T16:33:14Z", "updated_at": "2019-08-02T17:39:32Z", "closed_at": "2019-08-02T17:39:32Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "```\r\n>>> import os, fsspec\r\n>>> fsspec.__version__\r\n'0.3.6'\r\n>>> fs = fsspec.filesystem(\"file\")\r\n>>> fs.touch(f\"{os.getcwd()}/testfile\")\r\n>>> fs.rm(f\"{os.getcwd()}/testfile\", recursive=True)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/kfranz/ae/repo/env/lib/python3.7/site-packages/fsspec/implementations/local.py\", line 90, in rm\r\n    shutil.rmtree(path)\r\n  File \"/Users/kfranz/ae/repo/env/lib/python3.7/shutil.py\", line 491, in rmtree\r\n    _rmtree_safe_fd(fd, path, onerror)\r\n  File \"/Users/kfranz/ae/repo/env/lib/python3.7/shutil.py\", line 410, in _rmtree_safe_fd\r\n    onerror(os.scandir, path, sys.exc_info())\r\n  File \"/Users/kfranz/ae/repo/env/lib/python3.7/shutil.py\", line 406, in _rmtree_safe_fd\r\n    with os.scandir(topfd) as scandir_it:\r\nNotADirectoryError: [Errno 20] Not a directory: '/Users/kfranz/ae/repo/testfile'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/81", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/81/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/81/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/81/events", "html_url": "https://github.com/intake/filesystem_spec/issues/81", "id": 474598106, "node_id": "MDU6SXNzdWU0NzQ1OTgxMDY=", "number": 81, "title": "tag 0.3.6", "user": {"login": "pgajdos", "id": 4067843, "node_id": "MDQ6VXNlcjQwNjc4NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4067843?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pgajdos", "html_url": "https://github.com/pgajdos", "followers_url": "https://api.github.com/users/pgajdos/followers", "following_url": "https://api.github.com/users/pgajdos/following{/other_user}", "gists_url": "https://api.github.com/users/pgajdos/gists{/gist_id}", "starred_url": "https://api.github.com/users/pgajdos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pgajdos/subscriptions", "organizations_url": "https://api.github.com/users/pgajdos/orgs", "repos_url": "https://api.github.com/users/pgajdos/repos", "events_url": "https://api.github.com/users/pgajdos/events{/privacy}", "received_events_url": "https://api.github.com/users/pgajdos/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-30T13:51:36Z", "updated_at": "2019-07-30T13:53:33Z", "closed_at": "2019-07-30T13:53:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "Could you please tag 0.3.6 in git repo?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/75", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/75/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/75/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/75/events", "html_url": "https://github.com/intake/filesystem_spec/issues/75", "id": 472344202, "node_id": "MDU6SXNzdWU0NzIzNDQyMDI=", "number": 75, "title": "readd tests", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-24T15:19:09Z", "updated_at": "2019-08-02T17:44:52Z", "closed_at": "2019-08-02T17:44:52Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently, fuse, dask and hdfs are not being tested on Travis, although tests exist, leading to apparently low code coverage. \r\nEach of these has had working fixtures in the past, and it would be reasonable to make the effort to add them again. HDFS may not be tractable, since it must be run on an edge node - we can indeed run it (dask [nightlies](https://travis-ci.org/dask/dask/builds/562743503) is doing this), but the coverage will not show up.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/69", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/69/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/69/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/69/events", "html_url": "https://github.com/intake/filesystem_spec/issues/69", "id": 469307914, "node_id": "MDU6SXNzdWU0NjkzMDc5MTQ=", "number": 69, "title": "Add snappy and zstd compressions", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-17T16:03:45Z", "updated_at": "2019-07-18T16:07:58Z", "closed_at": "2019-07-18T16:07:58Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "xref https://github.com/dask/dask/issues/5039#", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/58", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/58/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/58/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/58/events", "html_url": "https://github.com/intake/filesystem_spec/issues/58", "id": 461784022, "node_id": "MDU6SXNzdWU0NjE3ODQwMjI=", "number": 58, "title": "Glob search breaks when '?' occurs before '*'", "user": {"login": "maciejb", "id": 2573696, "node_id": "MDQ6VXNlcjI1NzM2OTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/2573696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maciejb", "html_url": "https://github.com/maciejb", "followers_url": "https://api.github.com/users/maciejb/followers", "following_url": "https://api.github.com/users/maciejb/following{/other_user}", "gists_url": "https://api.github.com/users/maciejb/gists{/gist_id}", "starred_url": "https://api.github.com/users/maciejb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maciejb/subscriptions", "organizations_url": "https://api.github.com/users/maciejb/orgs", "repos_url": "https://api.github.com/users/maciejb/repos", "events_url": "https://api.github.com/users/maciejb/events{/privacy}", "received_events_url": "https://api.github.com/users/maciejb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-27T22:59:18Z", "updated_at": "2019-06-30T13:42:22Z", "closed_at": "2019-06-30T13:42:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "I originally filed this under s3fs ([here](https://github.com/dask/s3fs/issues/189)), but adding it here as related:\r\n\r\nConsider for example:\r\n`fs.glob('mybucket/*/????/*.zip')`\r\nreturns\r\n`['mybucket/folder/2018/file.zip', 'mybucket/folder/2019/file.zip']`\r\nwhereas\r\n`fs.glob('mybucket/folder/????/*.zip')`\r\nreturns\r\n`[]`\r\n\r\nIf the * is after the ?, the ? ends up in the path that gets walked, and so it doesn't find the path. Instead of searching the * only, this bit should consider other characters:\r\nhttps://github.com/intake/filesystem_spec/blob/c0c4f2bfa69127f5d6daf81b98b8584669041468/fsspec/spec.py#L417\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/56", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/56/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/56/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/56/events", "html_url": "https://github.com/intake/filesystem_spec/issues/56", "id": 461716828, "node_id": "MDU6SXNzdWU0NjE3MTY4Mjg=", "number": 56, "title": "Stripping of prefix for FSMap", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-27T19:48:38Z", "updated_at": "2019-06-27T20:49:05Z", "closed_at": "2019-06-27T20:49:05Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "`FSMap.__init__` should probably strip the protocol / prefix of the `root` so that `S3Map('s3://mybucket/file')` is treated the same as `S3Map('mybucket/file')`.\r\n\r\n```python\r\nIn [15]: s3 = s3fs.S3FileSystem()\r\n\r\nIn [16]: map1 = s3fs.S3Map('s3://a/b', s3)\r\n\r\nIn [17]: map2 = s3fs.S3Map('a/b', s3)\r\n\r\nIn [18]: assert map1.root == map2.root\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-18-f02e96dd7165> in <module>\r\n----> 1 assert map1.root == map2.root\r\n\r\nAssertionError:\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/55", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/55/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/55/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/55/events", "html_url": "https://github.com/intake/filesystem_spec/issues/55", "id": 459985534, "node_id": "MDU6SXNzdWU0NTk5ODU1MzQ=", "number": 55, "title": "accept Path objects", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-24T16:28:16Z", "updated_at": "2019-07-16T13:44:52Z", "closed_at": "2019-07-16T13:44:52Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Reuse https://github.com/dask/dask/pull/3335/files#diff-a8ff31fbc7d5c0e42fc6bafd7f7b9197R271 in functions that take paths to also allow Path-like objects and fspath protocol things. This would be in functions like open_files.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/52", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/52/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/52/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/52/events", "html_url": "https://github.com/intake/filesystem_spec/issues/52", "id": 457710029, "node_id": "MDU6SXNzdWU0NTc3MTAwMjk=", "number": 52, "title": "size_policy is broken", "user": {"login": "rabernat", "id": 1197350, "node_id": "MDQ6VXNlcjExOTczNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1197350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rabernat", "html_url": "https://github.com/rabernat", "followers_url": "https://api.github.com/users/rabernat/followers", "following_url": "https://api.github.com/users/rabernat/following{/other_user}", "gists_url": "https://api.github.com/users/rabernat/gists{/gist_id}", "starred_url": "https://api.github.com/users/rabernat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rabernat/subscriptions", "organizations_url": "https://api.github.com/users/rabernat/orgs", "repos_url": "https://api.github.com/users/rabernat/repos", "events_url": "https://api.github.com/users/rabernat/events{/privacy}", "received_events_url": "https://api.github.com/users/rabernat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-06-18T21:43:06Z", "updated_at": "2019-06-19T13:59:37Z", "closed_at": "2019-06-18T22:18:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "In #46, @martindurant added a `size_policy` keyword to HTTPFileSystem.\r\n\r\nIn fsspec 0.2.1, it appears to be broken.\r\n```python\r\nfrom fsspec.implementations.http import HTTPFileSystem\r\nfs = HTTPFileSystem()\r\npath = 'https://data.nas.nasa.gov/ecco/download_data.php?file=/eccodata/llc_2160/compressed/0000092160/Theta.0000092160.data.shrunk'\r\nf = fs.open(path, size_policy='get')\r\n```\r\nraises\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-15-857d04d27e7c> in <module>()\r\n      2 fs = HTTPFileSystem()\r\n      3 path = 'https://data.nas.nasa.gov/ecco/download_data.php?file=/eccodata/llc_2160/compressed/0000092160/Theta.0000092160.data.shrunk'\r\n----> 4 f = fs.open(path, size_policy='get')\r\n\r\n~/miniconda3/envs/geo_scipy/lib/python3.6/site-packages/fsspec/spec.py in open(self, path, mode, block_size, **kwargs)\r\n    615             ac = kwargs.pop('autocommit', not self._intrans)\r\n    616             f = self._open(path, mode=mode, block_size=block_size,\r\n--> 617                            autocommit=ac, **kwargs)\r\n    618             if not ac:\r\n    619                 self.transaction.files.append(f)\r\n\r\n~/miniconda3/envs/geo_scipy/lib/python3.6/site-packages/fsspec/implementations/http.py in _open(self, url, mode, block_size, **kwargs)\r\n    131         if block_size:\r\n    132             return HTTPFile(self, url, self.session, block_size,\r\n--> 133                             size_policy=self.size_policy, **kw)\r\n    134         else:\r\n    135             kw['stream'] = True\r\n\r\nTypeError: type object got multiple values for keyword argument 'size_policy'\r\n``` ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/49", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/49/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/49/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/49/events", "html_url": "https://github.com/intake/filesystem_spec/issues/49", "id": 457061197, "node_id": "MDU6SXNzdWU0NTcwNjExOTc=", "number": 49, "title": "next release?", "user": {"login": "rabernat", "id": 1197350, "node_id": "MDQ6VXNlcjExOTczNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1197350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rabernat", "html_url": "https://github.com/rabernat", "followers_url": "https://api.github.com/users/rabernat/followers", "following_url": "https://api.github.com/users/rabernat/following{/other_user}", "gists_url": "https://api.github.com/users/rabernat/gists{/gist_id}", "starred_url": "https://api.github.com/users/rabernat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rabernat/subscriptions", "organizations_url": "https://api.github.com/users/rabernat/orgs", "repos_url": "https://api.github.com/users/rabernat/repos", "events_url": "https://api.github.com/users/rabernat/events{/privacy}", "received_events_url": "https://api.github.com/users/rabernat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-17T17:38:21Z", "updated_at": "2019-06-18T16:01:14Z", "closed_at": "2019-06-18T16:01:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "There has been a bit of development since the 0.2.0 release. I'm wondering when the next release is planned. I am about to release a version of xmitgcm that needs the feature added in #46, so I need to decide what to do about the dependency. I would love to just be able to depend on 0.2.1, rather than github master. But I don't want to rush a release unnecessarily.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/48", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/48/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/48/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/48/events", "html_url": "https://github.com/intake/filesystem_spec/issues/48", "id": 452606875, "node_id": "MDU6SXNzdWU0NTI2MDY4NzU=", "number": 48, "title": "local cache file-system", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-05T16:45:45Z", "updated_at": "2019-07-16T13:44:52Z", "closed_at": "2019-07-16T13:44:52Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "We could create a file-system type, which makes local copies of any file which is opened for reading on a given other file-system: download-on-first-access. That would allow for local, and therefore fast, access to some parts of a much bigger data-set. This is probably not much work, but we would need to decide how and where to to store the files.\r\n\r\nThe [MMap](https://github.com/martindurant/filesystem_spec/blob/master/fsspec/core.py#L361) file-cache also demonstrates only downloading those blocks of a file which are accessed into a sparse file. That could also be implemented for absolute minimal storage.\r\n\r\n@rabernat , this is the kind of thing you had in mind, and it is an interesting idea, and probably not hard to implement.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/47", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/47/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/47/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/47/events", "html_url": "https://github.com/intake/filesystem_spec/issues/47", "id": 451686361, "node_id": "MDU6SXNzdWU0NTE2ODYzNjE=", "number": 47, "title": "Handling incorrect content-length headers", "user": {"login": "TomAugspurger", "id": 1312546, "node_id": "MDQ6VXNlcjEzMTI1NDY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1312546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TomAugspurger", "html_url": "https://github.com/TomAugspurger", "followers_url": "https://api.github.com/users/TomAugspurger/followers", "following_url": "https://api.github.com/users/TomAugspurger/following{/other_user}", "gists_url": "https://api.github.com/users/TomAugspurger/gists{/gist_id}", "starred_url": "https://api.github.com/users/TomAugspurger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TomAugspurger/subscriptions", "organizations_url": "https://api.github.com/users/TomAugspurger/orgs", "repos_url": "https://api.github.com/users/TomAugspurger/repos", "events_url": "https://api.github.com/users/TomAugspurger/events{/privacy}", "received_events_url": "https://api.github.com/users/TomAugspurger/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-03T20:57:44Z", "updated_at": "2019-08-09T19:40:25Z", "closed_at": "2019-08-09T19:40:25Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "From https://github.com/intake/intake/issues/367\r\n\r\n```python\r\n\r\n>>> x = len(dd.read_csv(\"https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv\").compute())\r\n>>> y = pd.read_csv(\"https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv\")\r\n>>> len(x), len(y)\r\n(519, 1458)\r\n```\r\n\r\n@martindurant thinks this may be because Github's HTTP server isn't respecting the `'identity'` request header, and is sending back the compressed content length instead.\r\n\r\nHow should we handle this situation?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/45", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/45/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/45/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/45/events", "html_url": "https://github.com/intake/filesystem_spec/issues/45", "id": 450316302, "node_id": "MDU6SXNzdWU0NTAzMTYzMDI=", "number": 45, "title": "HTTPFileSystem hanging on open", "user": {"login": "rabernat", "id": 1197350, "node_id": "MDQ6VXNlcjExOTczNTA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1197350?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rabernat", "html_url": "https://github.com/rabernat", "followers_url": "https://api.github.com/users/rabernat/followers", "following_url": "https://api.github.com/users/rabernat/following{/other_user}", "gists_url": "https://api.github.com/users/rabernat/gists{/gist_id}", "starred_url": "https://api.github.com/users/rabernat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rabernat/subscriptions", "organizations_url": "https://api.github.com/users/rabernat/orgs", "repos_url": "https://api.github.com/users/rabernat/repos", "events_url": "https://api.github.com/users/rabernat/events{/privacy}", "received_events_url": "https://api.github.com/users/rabernat/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2019-05-30T13:46:32Z", "updated_at": "2019-05-30T18:10:12Z", "closed_at": "2019-05-30T18:10:12Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I am trying to use fsspec.implementations.http.HTTPFileSystem to read a byte range from a remote url. Here's what I'm doing\r\n\r\n```python\r\nfrom fsspec.implementations.http import HTTPFileSystem\r\npath = 'https://data.nas.nasa.gov/ecco/download_data.php?file=/eccodata/llc_4320/compressed/0000010368/Theta.0000010368.data.shrunk'\r\nfs = HTTPFileSystem()\r\nf_obj = fs.open(path)\r\n# ... later would come the reading commands\r\n```\r\nThis hangs forever. I have turned on urllib3 debugging to see what's happening. I get the following log output\r\n```\r\nDEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): data.nas.nasa.gov:443\r\n```\r\nIf I interrupt the running command, I get this stack trace\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/urllib3/connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\r\n    376             try:  # Python 2.7, use buffering of HTTP responses\r\n--> 377                 httplib_response = conn.getresponse(buffering=True)\r\n    378             except TypeError:  # Python 3\r\n\r\nTypeError: getresponse() got an unexpected keyword argument 'buffering'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nKeyboardInterrupt                         Traceback (most recent call last)\r\n<ipython-input-27-556e6da93e62> in <module>\r\n----> 1 f_obj = fs.open(path)\r\n      2 f_obj\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/fsspec/spec.py in open(self, path, mode, block_size, **kwargs)\r\n    562             ac = kwargs.pop('autocommit', not self._intrans)\r\n    563             f = self._open(path, mode=mode, block_size=block_size,\r\n--> 564                            autocommit=ac, **kwargs)\r\n    565             if not ac:\r\n    566                 self.transaction.files.append(f)\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/fsspec/implementations/http.py in _open(self, url, mode, block_size, **kwargs)\r\n    117         kw.pop('autocommit', None)\r\n    118         if block_size:\r\n--> 119             return HTTPFile(url, self.session, block_size, **kw)\r\n    120         else:\r\n    121             kw['stream'] = True\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/fsspec/implementations/http.py in __init__(self, url, session, block_size, **kwargs)\r\n    165         try:\r\n    166             self.size = file_size(url, self.session, allow_redirects=True,\r\n--> 167                                   **self.kwargs)\r\n    168         except (ValueError, requests.HTTPError):\r\n    169             # No size information - only allow read() and no seek()\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/fsspec/implementations/http.py in file_size(url, session, **kwargs)\r\n    370     head = kwargs.get('headers', {})\r\n    371     head['Accept-Encoding'] = 'identity'\r\n--> 372     r = session.head(url, allow_redirects=ar, **kwargs)\r\n    373     r.raise_for_status()\r\n    374     if 'Content-Length' in r.headers:\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/requests/sessions.py in head(self, url, **kwargs)\r\n    566 \r\n    567         kwargs.setdefault('allow_redirects', False)\r\n--> 568         return self.request('HEAD', url, **kwargs)\r\n    569 \r\n    570     def post(self, url, data=None, json=None, **kwargs):\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/requests/sessions.py in request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\r\n    531         }\r\n    532         send_kwargs.update(settings)\r\n--> 533         resp = self.send(prep, **send_kwargs)\r\n    534 \r\n    535         return resp\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/requests/sessions.py in send(self, request, **kwargs)\r\n    644 \r\n    645         # Send the request\r\n--> 646         r = adapter.send(request, **kwargs)\r\n    647 \r\n    648         # Total elapsed time of the request (approximately)\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\r\n    447                     decode_content=False,\r\n    448                     retries=self.max_retries,\r\n--> 449                     timeout=timeout\r\n    450                 )\r\n    451 \r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/urllib3/connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\r\n    598                                                   timeout=timeout_obj,\r\n    599                                                   body=body, headers=headers,\r\n--> 600                                                   chunked=chunked)\r\n    601 \r\n    602             # If we're going to release the connection in ``finally:``, then\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/urllib3/connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\r\n    378             except TypeError:  # Python 3\r\n    379                 try:\r\n--> 380                     httplib_response = conn.getresponse()\r\n    381                 except Exception as e:\r\n    382                     # Remove the TypeError from the exception chain in Python 3;\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/http/client.py in getresponse(self)\r\n   1329         try:\r\n   1330             try:\r\n-> 1331                 response.begin()\r\n   1332             except ConnectionError:\r\n   1333                 self.close()\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/http/client.py in begin(self)\r\n    295         # read until we get a non-100 response\r\n    296         while True:\r\n--> 297             version, status, reason = self._read_status()\r\n    298             if status != CONTINUE:\r\n    299                 break\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/http/client.py in _read_status(self)\r\n    256 \r\n    257     def _read_status(self):\r\n--> 258         line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\r\n    259         if len(line) > _MAXLINE:\r\n    260             raise LineTooLong(\"status line\")\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/socket.py in readinto(self, b)\r\n    584         while True:\r\n    585             try:\r\n--> 586                 return self._sock.recv_into(b)\r\n    587             except timeout:\r\n    588                 self._timeout_occurred = True\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py in recv_into(self, *args, **kwargs)\r\n    295     def recv_into(self, *args, **kwargs):\r\n    296         try:\r\n--> 297             return self.connection.recv_into(*args, **kwargs)\r\n    298         except OpenSSL.SSL.SysCallError as e:\r\n    299             if self.suppress_ragged_eofs and e.args == (-1, 'Unexpected EOF'):\r\n\r\n~/anaconda/envs/pangeo/lib/python3.6/site-packages/OpenSSL/SSL.py in recv_into(self, buffer, nbytes, flags)\r\n   1819             result = _lib.SSL_peek(self._ssl, buf, nbytes)\r\n   1820         else:\r\n-> 1821             result = _lib.SSL_read(self._ssl, buf, nbytes)\r\n   1822         self._raise_ssl_error(self._ssl, result)\r\n   1823 \r\n\r\nKeyboardInterrupt: \r\n```\r\n\r\nEverything works fine if I use requests.\r\n```python\r\nimport requests\r\nr = requests.get(path, headers={\"Range\": \"bytes=0-100\"})\r\n```\r\n\r\n```\r\nDEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): data.nas.nasa.gov:443\r\nDEBUG:urllib3.connectionpool:https://data.nas.nasa.gov:443 \"GET /ecco/download_data.php?file=/eccodata/llc_4320/compressed/0000010368/Theta.0000010368.data.shrunk HTTP/1.1\" 206 101\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/44", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/44/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/44/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/44/events", "html_url": "https://github.com/intake/filesystem_spec/issues/44", "id": 436927831, "node_id": "MDU6SXNzdWU0MzY5Mjc4MzE=", "number": 44, "title": "HTTPfile object has no attribute kwargs", "user": {"login": "youngsaj", "id": 36857535, "node_id": "MDQ6VXNlcjM2ODU3NTM1", "avatar_url": "https://avatars0.githubusercontent.com/u/36857535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/youngsaj", "html_url": "https://github.com/youngsaj", "followers_url": "https://api.github.com/users/youngsaj/followers", "following_url": "https://api.github.com/users/youngsaj/following{/other_user}", "gists_url": "https://api.github.com/users/youngsaj/gists{/gist_id}", "starred_url": "https://api.github.com/users/youngsaj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/youngsaj/subscriptions", "organizations_url": "https://api.github.com/users/youngsaj/orgs", "repos_url": "https://api.github.com/users/youngsaj/repos", "events_url": "https://api.github.com/users/youngsaj/events{/privacy}", "received_events_url": "https://api.github.com/users/youngsaj/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-24T22:06:29Z", "updated_at": "2019-04-25T16:14:27Z", "closed_at": "2019-04-25T16:14:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "urlsmall = 'https://six-library.s3.amazonaws.com/sicd_example_RMA_RGZERO_RE32F_IM32F_cropped_multiple_image_segments.nitf'\r\n#test = cf_sicd.Reader(urlsmall)\r\ntest = fsspec.open(urlsmall)\r\n\r\ntest.fs.exists(test.path)\r\n\r\nTrue\r\n\r\nwith test as fid:\r\n    fid.read(9)\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-9-869a2fab67bb> in <module>\r\n----> 1 with test as fid:\r\n      2     fid.read(9)\r\n\r\nC:\\Apps\\Anaconda3\\envs\\pyviz_dev\\lib\\site-packages\\fsspec-0.2.0+28.g9b388d4-py3.7.egg\\fsspec\\core.py in __enter__(self)\r\n     57         mode = self.mode.replace('t', '').replace('b', '') + 'b'\r\n     58 \r\n---> 59         f = self.fs.open(self.path, mode=mode)\r\n     60 \r\n     61         fobjects = [f]\r\n\r\nC:\\Apps\\Anaconda3\\envs\\pyviz_dev\\lib\\site-packages\\fsspec-0.2.0+28.g9b388d4-py3.7.egg\\fsspec\\spec.py in open(self, path, mode, block_size, **kwargs)\r\n    584             ac = kwargs.pop('autocommit', not self._intrans)\r\n    585             f = self._open(path, mode=mode, block_size=block_size,\r\n--> 586                            autocommit=ac, **kwargs)\r\n    587             if not ac:\r\n    588                 self.transaction.files.append(f)\r\n\r\nC:\\Apps\\Anaconda3\\envs\\pyviz_dev\\lib\\site-packages\\fsspec-0.2.0+28.g9b388d4-py3.7.egg\\fsspec\\implementations\\http.py in _open(self, url, mode, block_size, **kwargs)\r\n    128         kw.pop('autocommit', None)\r\n    129         if block_size:\r\n--> 130             return HTTPFile(self, url, self.session, block_size, **kw)\r\n    131         else:\r\n    132             kw['stream'] = True\r\n\r\nC:\\Apps\\Anaconda3\\envs\\pyviz_dev\\lib\\site-packages\\fsspec-0.2.0+28.g9b388d4-py3.7.egg\\fsspec\\implementations\\http.py in __init__(self, fs, url, session, block_size, mode, **kwargs)\r\n    175         try:\r\n    176             size = file_size(url, self.session, allow_redirects=True,\r\n--> 177                              **self.kwargs)\r\n    178         except (ValueError, requests.HTTPError):\r\n    179             # No size information - only allow read() and no seek()\r\n\r\nAttributeError: 'HTTPFile' object has no attribute 'kwargs'", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/42", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/42/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/42/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/42/events", "html_url": "https://github.com/intake/filesystem_spec/issues/42", "id": 436849113, "node_id": "MDU6SXNzdWU0MzY4NDkxMTM=", "number": 42, "title": "Best way to determine file or url exists?", "user": {"login": "youngsaj", "id": 36857535, "node_id": "MDQ6VXNlcjM2ODU3NTM1", "avatar_url": "https://avatars0.githubusercontent.com/u/36857535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/youngsaj", "html_url": "https://github.com/youngsaj", "followers_url": "https://api.github.com/users/youngsaj/followers", "following_url": "https://api.github.com/users/youngsaj/following{/other_user}", "gists_url": "https://api.github.com/users/youngsaj/gists{/gist_id}", "starred_url": "https://api.github.com/users/youngsaj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/youngsaj/subscriptions", "organizations_url": "https://api.github.com/users/youngsaj/orgs", "repos_url": "https://api.github.com/users/youngsaj/repos", "events_url": "https://api.github.com/users/youngsaj/events{/privacy}", "received_events_url": "https://api.github.com/users/youngsaj/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-04-24T18:40:15Z", "updated_at": "2019-04-24T20:28:44Z", "closed_at": "2019-04-24T20:27:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "with of as f:\r\n      f.exists(path)\r\n\r\nThat's fine for local files.  However, I ultimately want to use this in underlying code that intake will use, and path being https, s3 or c:\\ can all be valid possibilities.\r\nHTTPfile doesn't have an exists(), what is the recommended way to do this?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/39", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/39/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/39/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/39/events", "html_url": "https://github.com/intake/filesystem_spec/issues/39", "id": 435868663, "node_id": "MDU6SXNzdWU0MzU4Njg2NjM=", "number": 39, "title": "numpy.fromfile from https", "user": {"login": "youngsaj", "id": 36857535, "node_id": "MDQ6VXNlcjM2ODU3NTM1", "avatar_url": "https://avatars0.githubusercontent.com/u/36857535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/youngsaj", "html_url": "https://github.com/youngsaj", "followers_url": "https://api.github.com/users/youngsaj/followers", "following_url": "https://api.github.com/users/youngsaj/following{/other_user}", "gists_url": "https://api.github.com/users/youngsaj/gists{/gist_id}", "starred_url": "https://api.github.com/users/youngsaj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/youngsaj/subscriptions", "organizations_url": "https://api.github.com/users/youngsaj/orgs", "repos_url": "https://api.github.com/users/youngsaj/repos", "events_url": "https://api.github.com/users/youngsaj/events{/privacy}", "received_events_url": "https://api.github.com/users/youngsaj/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 20, "created_at": "2019-04-22T20:02:07Z", "updated_at": "2019-04-24T14:37:42Z", "closed_at": "2019-04-24T14:37:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Question:\r\nI have a final hurdle in getting https files read, metadata gets read correctly, just np.fromfile doesn't like the fid.\r\nIt's not clear to me if readbytes is a close replacement.\r\nSince we end up looping, using np.fromfile and fid.seek\r\nI suspect there's a cleaner way now using fsspec to subsample (seek to where we need).\r\nWhat's the best np.fromfile replacement to use fsspec?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/37", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/37/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/37/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/37/events", "html_url": "https://github.com/intake/filesystem_spec/issues/37", "id": 423397282, "node_id": "MDU6SXNzdWU0MjMzOTcyODI=", "number": 37, "title": "Implement `__fspath__`", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-20T18:02:46Z", "updated_at": "2019-05-30T13:48:36Z", "closed_at": "2019-05-30T13:48:36Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "[PEP-519](https://www.python.org/dev/peps/pep-0519/) added paths-like support to arbitrary file-like things. We should support that and return full URLs, including protocols.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/36", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/36/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/36/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/36/events", "html_url": "https://github.com/intake/filesystem_spec/issues/36", "id": 420110426, "node_id": "MDU6SXNzdWU0MjAxMTA0MjY=", "number": 36, "title": "add recursive glob", "user": {"login": "martindurant", "id": 6042212, "node_id": "MDQ6VXNlcjYwNDIyMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6042212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martindurant", "html_url": "https://github.com/martindurant", "followers_url": "https://api.github.com/users/martindurant/followers", "following_url": "https://api.github.com/users/martindurant/following{/other_user}", "gists_url": "https://api.github.com/users/martindurant/gists{/gist_id}", "starred_url": "https://api.github.com/users/martindurant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martindurant/subscriptions", "organizations_url": "https://api.github.com/users/martindurant/orgs", "repos_url": "https://api.github.com/users/martindurant/repos", "events_url": "https://api.github.com/users/martindurant/events{/privacy}", "received_events_url": "https://api.github.com/users/martindurant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-12T17:20:11Z", "updated_at": "2019-07-16T13:45:05Z", "closed_at": "2019-07-16T13:45:05Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "As discussed in\r\n\r\nhttps://github.com/dask/dask/pull/4186\r\n\r\nAll file-systems should support full glob.\r\n\r\nAlso, `recursive` should be allowd in various methods (see https://github.com/dask/gcsfs/pull/139 ). This is somewhat similar to #17", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/35", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/35/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/35/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/35/events", "html_url": "https://github.com/intake/filesystem_spec/issues/35", "id": 418362684, "node_id": "MDU6SXNzdWU0MTgzNjI2ODQ=", "number": 35, "title": "Support encoding for LocalFileOpener ", "user": {"login": "gsakkis", "id": 291289, "node_id": "MDQ6VXNlcjI5MTI4OQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/291289?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gsakkis", "html_url": "https://github.com/gsakkis", "followers_url": "https://api.github.com/users/gsakkis/followers", "following_url": "https://api.github.com/users/gsakkis/following{/other_user}", "gists_url": "https://api.github.com/users/gsakkis/gists{/gist_id}", "starred_url": "https://api.github.com/users/gsakkis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gsakkis/subscriptions", "organizations_url": "https://api.github.com/users/gsakkis/orgs", "repos_url": "https://api.github.com/users/gsakkis/repos", "events_url": "https://api.github.com/users/gsakkis/events{/privacy}", "received_events_url": "https://api.github.com/users/gsakkis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-07T15:14:34Z", "updated_at": "2019-05-30T13:49:25Z", "closed_at": "2019-05-30T13:49:25Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Currently local file `open()` supports only `mode`. It would be useful to add at least `encoding` (since it's implemented e.g. for `S3FileSystem`) if not all builtin `open` parameters (`buffering`, `errors`, etc).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/intake/filesystem_spec/issues/32", "repository_url": "https://api.github.com/repos/intake/filesystem_spec", "labels_url": "https://api.github.com/repos/intake/filesystem_spec/issues/32/labels{/name}", "comments_url": "https://api.github.com/repos/intake/filesystem_spec/issues/32/comments", "events_url": "https://api.github.com/repos/intake/filesystem_spec/issues/32/events", "html_url": "https://github.com/intake/filesystem_spec/issues/32", "id": 414281545, "node_id": "MDU6SXNzdWU0MTQyODE1NDU=", "number": 32, "title": "Surprising behavior of open_files()", "user": {"login": "shoyer", "id": 1217238, "node_id": "MDQ6VXNlcjEyMTcyMzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoyer", "html_url": "https://github.com/shoyer", "followers_url": "https://api.github.com/users/shoyer/followers", "following_url": "https://api.github.com/users/shoyer/following{/other_user}", "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions", "organizations_url": "https://api.github.com/users/shoyer/orgs", "repos_url": "https://api.github.com/users/shoyer/repos", "events_url": "https://api.github.com/users/shoyer/events{/privacy}", "received_events_url": "https://api.github.com/users/shoyer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2019-02-25T20:01:58Z", "updated_at": "2019-02-26T20:24:03Z", "closed_at": "2019-02-26T20:24:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "h5py now supports file-like objects. This works with the built-in `open()`, but I get an error when I try this with `fsspec`:\r\n```python\r\nimport h5py\r\nimport fsspec\r\n\r\nwith fsspec.open_files('test.h5', 'wb')[0] as f:\r\n  with h5py.File(f, 'w') as h5file:\r\n    h5file.attrs['foo'] = 'bar'\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nNotADirectoryError                        Traceback (most recent call last)\r\n<ipython-input-15-bc0b4a6a665e> in <module>()\r\n      2 import fsspec\r\n      3 \r\n----> 4 with fsspec.open_files('test.h5', 'wb')[0] as f:\r\n      5   with h5py.File(f, 'w') as h5file:\r\n      6     h5file.attrs['foo'] = 'bar'\r\n\r\n/usr/local/lib/python3.6/dist-packages/fsspec/core.py in __enter__(self)\r\n     57         mode = self.mode.replace('t', '').replace('b', '') + 'b'\r\n     58 \r\n---> 59         f = self.fs.open(self.path, mode=mode)\r\n     60 \r\n     61         fobjects = [f]\r\n\r\n/usr/local/lib/python3.6/dist-packages/fsspec/spec.py in open(self, path, mode, block_size, **kwargs)\r\n    562             ac = kwargs.pop('autocommit', not self._intrans)\r\n    563             f = self._open(path, mode=mode, block_size=block_size,\r\n--> 564                            autocommit=ac, **kwargs)\r\n    565             if not ac:\r\n    566                 self.transaction.files.append(f)\r\n\r\n/usr/local/lib/python3.6/dist-packages/fsspec/implementations/local.py in _open(self, path, mode, block_size, **kwargs)\r\n     70 \r\n     71     def _open(self, path, mode='rb', block_size=None, **kwargs):\r\n---> 72         return LocalFileOpener(path, mode, **kwargs)\r\n     73 \r\n     74     def touch(self, path, **kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/fsspec/implementations/local.py in __init__(self, path, mode, autocommit)\r\n     85         self.autocommit = autocommit\r\n     86         if autocommit or 'w' not in mode:\r\n---> 87             self.f = open(path, mode=mode)\r\n     88         else:\r\n     89             # TODO: check if path is writable?\r\n\r\nNotADirectoryError: [Errno 20] Not a directory: 'test.h5/0.part'\r\n```\r\n\r\nWorking example with `open()`:\r\n```python\r\nwith open('test.h5', 'wb') as f:\r\n  with h5py.File(f, 'w') as h5file:\r\n    h5file.attrs['foo'] = 'bar'\r\n```", "performed_via_github_app": null, "score": 1.0}]}