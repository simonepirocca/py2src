{"total_count": 247, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/spotify/annoy/issues/499", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/499/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/499/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/499/events", "html_url": "https://github.com/spotify/annoy/issues/499", "id": 675595876, "node_id": "MDU6SXNzdWU2NzU1OTU4NzY=", "number": 499, "title": "Parallel query", "user": {"login": "pvnieo", "id": 22404728, "node_id": "MDQ6VXNlcjIyNDA0NzI4", "avatar_url": "https://avatars2.githubusercontent.com/u/22404728?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pvnieo", "html_url": "https://github.com/pvnieo", "followers_url": "https://api.github.com/users/pvnieo/followers", "following_url": "https://api.github.com/users/pvnieo/following{/other_user}", "gists_url": "https://api.github.com/users/pvnieo/gists{/gist_id}", "starred_url": "https://api.github.com/users/pvnieo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pvnieo/subscriptions", "organizations_url": "https://api.github.com/users/pvnieo/orgs", "repos_url": "https://api.github.com/users/pvnieo/repos", "events_url": "https://api.github.com/users/pvnieo/events{/privacy}", "received_events_url": "https://api.github.com/users/pvnieo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-08T22:09:42Z", "updated_at": "2020-08-09T17:43:29Z", "closed_at": "2020-08-09T17:43:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nThank you for the great library.\r\n\r\nWhile using Annoy, I noticed that because the querying is done by element, If I want to query a lot of element, the only solution is to do it in a linear way, and use only 1 core, which is a time consuming.\r\n\r\nIs there a way to query multiple elements in parallel? I tried using `multiprocessing` and `joblib`, but I failed because it's unpickable.\r\n\r\nThank you in advance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/491", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/491/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/491/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/491/events", "html_url": "https://github.com/spotify/annoy/issues/491", "id": 657292468, "node_id": "MDU6SXNzdWU2NTcyOTI0Njg=", "number": 491, "title": "Will this library work in my use-case?", "user": {"login": "techytushar", "id": 26834658, "node_id": "MDQ6VXNlcjI2ODM0NjU4", "avatar_url": "https://avatars3.githubusercontent.com/u/26834658?v=4", "gravatar_id": "", "url": "https://api.github.com/users/techytushar", "html_url": "https://github.com/techytushar", "followers_url": "https://api.github.com/users/techytushar/followers", "following_url": "https://api.github.com/users/techytushar/following{/other_user}", "gists_url": "https://api.github.com/users/techytushar/gists{/gist_id}", "starred_url": "https://api.github.com/users/techytushar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/techytushar/subscriptions", "organizations_url": "https://api.github.com/users/techytushar/orgs", "repos_url": "https://api.github.com/users/techytushar/repos", "events_url": "https://api.github.com/users/techytushar/events{/privacy}", "received_events_url": "https://api.github.com/users/techytushar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-15T11:55:59Z", "updated_at": "2020-07-27T13:13:51Z", "closed_at": "2020-07-27T13:13:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a search problem in which I have 10 Million vectors of size 10,000. \r\n\r\n1.  For every search query I have to find the top 5 similar vectors.\r\n2.  I'll have to periodically (15 days) update the index to add new vectors.\r\n3.  There might be multiple requests (40-50) at the same time.\r\n\r\nWill this library be able to help in this case? If yes, what will be the server requirements in terms of memory and compute that I'll need for efficient working of this tool.\r\n\r\nAny help or suggestions would be highly appreciated.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/489", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/489/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/489/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/489/events", "html_url": "https://github.com/spotify/annoy/issues/489", "id": 650987200, "node_id": "MDU6SXNzdWU2NTA5ODcyMDA=", "number": 489, "title": "question: pushing two children nodes to priority_queue ", "user": {"login": "ncjin", "id": 26405138, "node_id": "MDQ6VXNlcjI2NDA1MTM4", "avatar_url": "https://avatars1.githubusercontent.com/u/26405138?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ncjin", "html_url": "https://github.com/ncjin", "followers_url": "https://api.github.com/users/ncjin/followers", "following_url": "https://api.github.com/users/ncjin/following{/other_user}", "gists_url": "https://api.github.com/users/ncjin/gists{/gist_id}", "starred_url": "https://api.github.com/users/ncjin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ncjin/subscriptions", "organizations_url": "https://api.github.com/users/ncjin/orgs", "repos_url": "https://api.github.com/users/ncjin/repos", "events_url": "https://api.github.com/users/ncjin/events{/privacy}", "received_events_url": "https://api.github.com/users/ncjin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-05T02:22:27Z", "updated_at": "2020-07-05T11:32:26Z", "closed_at": "2020-07-05T11:32:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/spotify/annoy/blob/7f2562add33eeb217dcdc755520c201aefc1b021/src/annoylib.h#L1280\r\nI cant understand that you push two children node to priority_queue q, rather than the closet one. Pushing two children will traverse the trees, compute all nodes distance, and cost more time.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/488", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/488/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/488/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/488/events", "html_url": "https://github.com/spotify/annoy/issues/488", "id": 649880387, "node_id": "MDU6SXNzdWU2NDk4ODAzODc=", "number": 488, "title": "Annoy index with cosine similarity", "user": {"login": "deepettas", "id": 20043465, "node_id": "MDQ6VXNlcjIwMDQzNDY1", "avatar_url": "https://avatars2.githubusercontent.com/u/20043465?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deepettas", "html_url": "https://github.com/deepettas", "followers_url": "https://api.github.com/users/deepettas/followers", "following_url": "https://api.github.com/users/deepettas/following{/other_user}", "gists_url": "https://api.github.com/users/deepettas/gists{/gist_id}", "starred_url": "https://api.github.com/users/deepettas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deepettas/subscriptions", "organizations_url": "https://api.github.com/users/deepettas/orgs", "repos_url": "https://api.github.com/users/deepettas/repos", "events_url": "https://api.github.com/users/deepettas/events{/privacy}", "received_events_url": "https://api.github.com/users/deepettas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-02T12:09:12Z", "updated_at": "2020-07-02T13:23:43Z", "closed_at": "2020-07-02T13:23:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to create an AnnoyIndex with the 'cosine' metric, but I am unable to do so.\r\nThe 'cosine' argument for metric produces a \"invalid metric\" error. \r\n\r\nAny clues?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/487", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/487/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/487/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/487/events", "html_url": "https://github.com/spotify/annoy/issues/487", "id": 645473184, "node_id": "MDU6SXNzdWU2NDU0NzMxODQ=", "number": 487, "title": "ftruncate does not work on Windows for large datasets", "user": {"login": "vbod", "id": 5793742, "node_id": "MDQ6VXNlcjU3OTM3NDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5793742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vbod", "html_url": "https://github.com/vbod", "followers_url": "https://api.github.com/users/vbod/followers", "following_url": "https://api.github.com/users/vbod/following{/other_user}", "gists_url": "https://api.github.com/users/vbod/gists{/gist_id}", "starred_url": "https://api.github.com/users/vbod/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vbod/subscriptions", "organizations_url": "https://api.github.com/users/vbod/orgs", "repos_url": "https://api.github.com/users/vbod/repos", "events_url": "https://api.github.com/users/vbod/events{/privacy}", "received_events_url": "https://api.github.com/users/vbod/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-25T11:06:42Z", "updated_at": "2020-07-27T12:57:52Z", "closed_at": "2020-07-27T12:57:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "The Windows API that is used for `ftruncate` does not work for large file truncate, which makes `save()` and `on_disk_build()` fail with truncation error. \r\n\r\nI just drop here a quick script that works on 64-bits Windows (but might fail on 32-bits):\r\n```C++\r\ninline int ftruncate(int fd, int64_t l_size)\r\n{\r\n\tif (fd < 0)\r\n\t{\r\n\t\terrno = EBADF;\r\n\t\tfprintf(stderr, \"%s\\n\", \"fd arg was negative\");\r\n\t\treturn -1;\r\n\t}\r\n\r\n\tHANDLE h = (HANDLE)_get_osfhandle(fd);\r\n\r\n\tLARGE_INTEGER li_0;\r\n\tli_0.QuadPart = (int64_t)0;\r\n\tBOOL cur = SetFilePointerEx(h, li_0, NULL, FILE_CURRENT);\r\n\tif (!cur)\r\n\t{\r\n\t\tfprintf(stderr, \"[SetFilePointerEx] Error getting current position in file.\\n\");\r\n\t\treturn -1;\r\n\t}\r\n\r\n\tLARGE_INTEGER li_size;\r\n\tli_size.QuadPart = l_size;\r\n\tBOOL cur2 = SetFilePointerEx(h, li_size, NULL, FILE_BEGIN);\r\n\tif (cur2 == 0)\r\n\t{\r\n\t\tint error = GetLastError();\r\n\t        fprintf(stderr, \"[SetFilePointerEx] GetLastError is: %d\\n\", error);\r\n\t\tswitch (error)\r\n\t\t{\r\n\t\tcase ERROR_INVALID_HANDLE:\r\n\t\t\terrno = EBADF;\r\n\t\t\tbreak;\r\n\t\tdefault:\r\n\t\t\terrno = EIO;\r\n\t\t\tbreak;\r\n\t\t}\r\n\t\treturn -1;\r\n\t}\r\n\r\n\tif (!SetEndOfFile(h))\r\n\t{\r\n\t\tint error = GetLastError();\r\n\t\tfprintf(stderr, \"[SetEndOfFile] GetLastError is: %d\\n\", error );\r\n\t\tswitch (error)\r\n\t\t{\r\n\t\tcase ERROR_INVALID_HANDLE:\r\n\t\t\terrno = EBADF;\r\n\t\t\tbreak;\r\n\t\tdefault:\r\n\t\t\terrno = EIO;\r\n\t\t\tbreak;\r\n\t\t}\r\n\t\treturn -1;\r\n\t}\r\n\r\n\treturn 0;\r\n}\r\n```\r\n\r\nThe main difference (except for a more thorough logging) is to use `SetFilePointerEx` instead of `SetFilePointer` and feed it with `int64_t` instead of previous signature. Of course all of the calls to `ftruncate` in `annoylib.h` should accordingly call it with `int64_t` instead of `S` type (that is `int32_t` when using the Python binder). \r\n\r\nNote that `on_disk_build()` will still fail with an errno ERROR_USER_MAPPED_FILE (1224) during `build()` (roughly line 967 of `annoylib.h`) just because it's not allowed to truncate a file that is memory-mapped on Windows. I did not bother fix it though (cause I did not use it) but there's some more work needed in here. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/486", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/486/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/486/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/486/events", "html_url": "https://github.com/spotify/annoy/issues/486", "id": 643332914, "node_id": "MDU6SXNzdWU2NDMzMzI5MTQ=", "number": 486, "title": "Annoy model optimization - best practices", "user": {"login": "tylerhutcherson", "id": 20304844, "node_id": "MDQ6VXNlcjIwMzA0ODQ0", "avatar_url": "https://avatars3.githubusercontent.com/u/20304844?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tylerhutcherson", "html_url": "https://github.com/tylerhutcherson", "followers_url": "https://api.github.com/users/tylerhutcherson/followers", "following_url": "https://api.github.com/users/tylerhutcherson/following{/other_user}", "gists_url": "https://api.github.com/users/tylerhutcherson/gists{/gist_id}", "starred_url": "https://api.github.com/users/tylerhutcherson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tylerhutcherson/subscriptions", "organizations_url": "https://api.github.com/users/tylerhutcherson/orgs", "repos_url": "https://api.github.com/users/tylerhutcherson/repos", "events_url": "https://api.github.com/users/tylerhutcherson/events{/privacy}", "received_events_url": "https://api.github.com/users/tylerhutcherson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-22T20:14:44Z", "updated_at": "2020-06-23T15:29:27Z", "closed_at": "2020-06-23T15:29:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thanks for an incredible piece of software!\r\n\r\n**Context**\r\nI currently leverage Annoy as the primary workhorse for a product image search engine application. I have ~10k items/vectors of 2048 features. The exact number of items and feature values are updated & re-built each day as the underlying data source changes.\r\n\r\nBecause my application is serving \"real-time\" results to users, the task is to return nearest neighbors to the query vector as fast as possible (less than 100ms). Pretty straightforward.\r\n\r\n**Challenge**\r\nRuntime memory + index build time are not concerns for my particular situation. Setting `n_trees` to something large (between 100-1000) and then tweaking `search_k` from there works reasonably well. However, if I just set the params once and forget them, my searches perform differently day-to-day, depending on the structure of the vector space, i.e. the spatial layout of the feature vectors:\r\n\r\n_For example, for constant params, some searches can take up to ~800ms or yield less than ideal results (depending on if `search_k` is too high or too low)._\r\n\r\nI'm curious if others have employed strategies to automatically tune the params based on some pre-defined criteria? Thanks!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/484", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/484/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/484/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/484/events", "html_url": "https://github.com/spotify/annoy/issues/484", "id": 636669260, "node_id": "MDU6SXNzdWU2MzY2NjkyNjA=", "number": 484, "title": "How can we save multiple annoy.Annoy object in one file?", "user": {"login": "lxgend", "id": 17113699, "node_id": "MDQ6VXNlcjE3MTEzNjk5", "avatar_url": "https://avatars1.githubusercontent.com/u/17113699?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lxgend", "html_url": "https://github.com/lxgend", "followers_url": "https://api.github.com/users/lxgend/followers", "following_url": "https://api.github.com/users/lxgend/following{/other_user}", "gists_url": "https://api.github.com/users/lxgend/gists{/gist_id}", "starred_url": "https://api.github.com/users/lxgend/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lxgend/subscriptions", "organizations_url": "https://api.github.com/users/lxgend/orgs", "repos_url": "https://api.github.com/users/lxgend/repos", "events_url": "https://api.github.com/users/lxgend/events{/privacy}", "received_events_url": "https://api.github.com/users/lxgend/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-11T02:28:08Z", "updated_at": "2020-06-11T18:29:01Z", "closed_at": "2020-06-11T18:29:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nIs there a way to save multiple annoy.Annoy objects in one file?\r\nthen we can select certain Annoyindex by keys.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/483", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/483/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/483/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/483/events", "html_url": "https://github.com/spotify/annoy/issues/483", "id": 626102264, "node_id": "MDU6SXNzdWU2MjYxMDIyNjQ=", "number": 483, "title": "Potential speedups for binary vectors?", "user": {"login": "ricardocarvalhods", "id": 7207015, "node_id": "MDQ6VXNlcjcyMDcwMTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/7207015?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ricardocarvalhods", "html_url": "https://github.com/ricardocarvalhods", "followers_url": "https://api.github.com/users/ricardocarvalhods/followers", "following_url": "https://api.github.com/users/ricardocarvalhods/following{/other_user}", "gists_url": "https://api.github.com/users/ricardocarvalhods/gists{/gist_id}", "starred_url": "https://api.github.com/users/ricardocarvalhods/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ricardocarvalhods/subscriptions", "organizations_url": "https://api.github.com/users/ricardocarvalhods/orgs", "repos_url": "https://api.github.com/users/ricardocarvalhods/repos", "events_url": "https://api.github.com/users/ricardocarvalhods/events{/privacy}", "received_events_url": "https://api.github.com/users/ricardocarvalhods/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-27T23:23:47Z", "updated_at": "2020-05-28T21:41:45Z", "closed_at": "2020-05-28T21:41:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nAre there any potential speedups we can use in the case of binary vectors for nearest neighbours search using e.g. angular metric?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/482", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/482/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/482/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/482/events", "html_url": "https://github.com/spotify/annoy/issues/482", "id": 622612746, "node_id": "MDU6SXNzdWU2MjI2MTI3NDY=", "number": 482, "title": "Slowdown with two indices (using tmpfs)", "user": {"login": "eddie-scio", "id": 52253266, "node_id": "MDQ6VXNlcjUyMjUzMjY2", "avatar_url": "https://avatars0.githubusercontent.com/u/52253266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddie-scio", "html_url": "https://github.com/eddie-scio", "followers_url": "https://api.github.com/users/eddie-scio/followers", "following_url": "https://api.github.com/users/eddie-scio/following{/other_user}", "gists_url": "https://api.github.com/users/eddie-scio/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddie-scio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddie-scio/subscriptions", "organizations_url": "https://api.github.com/users/eddie-scio/orgs", "repos_url": "https://api.github.com/users/eddie-scio/repos", "events_url": "https://api.github.com/users/eddie-scio/events{/privacy}", "received_events_url": "https://api.github.com/users/eddie-scio/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-21T16:12:40Z", "updated_at": "2020-05-22T22:16:20Z", "closed_at": "2020-05-22T17:15:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've been mounting a tmpfs in a Google App Engine Flex instance (after looking through a couple of issues in this repo that suggested this) to ensure everything is fully mmapped.\r\n\r\nRecently, I made a change where my server is loading two Annoy indices -- I've tried both allocating two tmpfs and one larger tmpfs, the total volume of which is much larger than it needs to be to load both indices into memory.\r\n\r\nHowever, simply keeping index 2 loaded has a ~2x slowdown at 50% on `.retrieve()` calls to index 1 (whether they're loaded from the same tmpfs or two separate ones).  Is is possible there are some library-level locks or logic that prevent multiple indices from being fully mmapped on the same machine?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/481", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/481/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/481/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/481/events", "html_url": "https://github.com/spotify/annoy/issues/481", "id": 622148229, "node_id": "MDU6SXNzdWU2MjIxNDgyMjk=", "number": 481, "title": "`search_k` vs. number of index items", "user": {"login": "eddie-scio", "id": 52253266, "node_id": "MDQ6VXNlcjUyMjUzMjY2", "avatar_url": "https://avatars0.githubusercontent.com/u/52253266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddie-scio", "html_url": "https://github.com/eddie-scio", "followers_url": "https://api.github.com/users/eddie-scio/followers", "following_url": "https://api.github.com/users/eddie-scio/following{/other_user}", "gists_url": "https://api.github.com/users/eddie-scio/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddie-scio/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddie-scio/subscriptions", "organizations_url": "https://api.github.com/users/eddie-scio/orgs", "repos_url": "https://api.github.com/users/eddie-scio/repos", "events_url": "https://api.github.com/users/eddie-scio/events{/privacy}", "received_events_url": "https://api.github.com/users/eddie-scio/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-05-20T23:34:18Z", "updated_at": "2020-06-10T02:59:23Z", "closed_at": "2020-05-22T17:16:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi all, thanks for building a great library!  I understand at a high level the trade-off between accuracy and latency when using `search_k` (for a fixed memory constraint via `num_trees`), but a few questions:\r\n\r\n1) If I set `search_k` to my index size, should I expect an exhaustive search?  I believe I've run into a case where I miss the true nearest neighbor when doing so.\r\n2) Relatedly, if I increase `search_k`, is it expected that latency should continue to degrade, even past the full index size?  Does `k` itself factor in here?  I am also seeing this, e.g. for 100-tree index of 100k items of 128d, setting `search_k` to 500k and 1m gives a 2x increase in latency).\r\n\r\nHow can I better understand the \"range\" of `search_k`?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/480", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/480/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/480/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/480/events", "html_url": "https://github.com/spotify/annoy/issues/480", "id": 611864075, "node_id": "MDU6SXNzdWU2MTE4NjQwNzU=", "number": 480, "title": "conda-forge Windows packages", "user": {"login": "pavlin-policar", "id": 5758119, "node_id": "MDQ6VXNlcjU3NTgxMTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/5758119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavlin-policar", "html_url": "https://github.com/pavlin-policar", "followers_url": "https://api.github.com/users/pavlin-policar/followers", "following_url": "https://api.github.com/users/pavlin-policar/following{/other_user}", "gists_url": "https://api.github.com/users/pavlin-policar/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavlin-policar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavlin-policar/subscriptions", "organizations_url": "https://api.github.com/users/pavlin-policar/orgs", "repos_url": "https://api.github.com/users/pavlin-policar/repos", "events_url": "https://api.github.com/users/pavlin-policar/events{/privacy}", "received_events_url": "https://api.github.com/users/pavlin-policar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-04T13:11:28Z", "updated_at": "2020-05-12T06:24:33Z", "closed_at": "2020-05-12T06:24:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I've just released a version of openTSNE (https://github.com/pavlin-policar/openTSNE), where I switched over to Annoy for nearest neighbor search. I am extremely happy with Annoy, however, I just noticed that Annoy does not provide Windows packages on conda-forge. This is very problematic, since I need my library to be totally cross-platform, and I am wondering why these packages are not included. Conda-forge takes care of the compilation process, and it shouldn't be too hard to adapt the C++ code to make it work on Windows as well.\r\n\r\nA similar C++ only t-SNE implementation (https://github.com/KlugerLab/FIt-SNE) uses Annoy, but I see that they have copied over the source code and modified it slightly.\r\n\r\nWhat are your thoughts on this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/479", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/479/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/479/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/479/events", "html_url": "https://github.com/spotify/annoy/issues/479", "id": 611733050, "node_id": "MDU6SXNzdWU2MTE3MzMwNTA=", "number": 479, "title": "finding neighbours takes forever!!", "user": {"login": "sumegha19", "id": 50694178, "node_id": "MDQ6VXNlcjUwNjk0MTc4", "avatar_url": "https://avatars3.githubusercontent.com/u/50694178?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sumegha19", "html_url": "https://github.com/sumegha19", "followers_url": "https://api.github.com/users/sumegha19/followers", "following_url": "https://api.github.com/users/sumegha19/following{/other_user}", "gists_url": "https://api.github.com/users/sumegha19/gists{/gist_id}", "starred_url": "https://api.github.com/users/sumegha19/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sumegha19/subscriptions", "organizations_url": "https://api.github.com/users/sumegha19/orgs", "repos_url": "https://api.github.com/users/sumegha19/repos", "events_url": "https://api.github.com/users/sumegha19/events{/privacy}", "received_events_url": "https://api.github.com/users/sumegha19/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-04T09:32:10Z", "updated_at": "2020-05-05T03:58:03Z", "closed_at": "2020-05-05T03:58:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nGreat work first of all!\r\nI am working with about 10 million,  100 dimensional, vectors with.\r\nI saw that as I increase the number of vectors to be loaded for some clustering that I need for a project I am doing it shows time complexity of the order 2^n\r\nSay for 100k vectors it took 91 seconds to find say 50 similar vectors(angular distance metric used)\r\nfor 200k it takes 183 seconds\r\nand for 300 k it takes 268 seconds.\r\nI build the trees for the respective data independently, for processing 10 million vectors it takes forever. \r\nCan you help me out where I might be getting this wrong.\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/476", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/476/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/476/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/476/events", "html_url": "https://github.com/spotify/annoy/issues/476", "id": 599650892, "node_id": "MDU6SXNzdWU1OTk2NTA4OTI=", "number": 476, "title": "Need guidance with best approach", "user": {"login": "rishabh00100", "id": 16775801, "node_id": "MDQ6VXNlcjE2Nzc1ODAx", "avatar_url": "https://avatars3.githubusercontent.com/u/16775801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rishabh00100", "html_url": "https://github.com/rishabh00100", "followers_url": "https://api.github.com/users/rishabh00100/followers", "following_url": "https://api.github.com/users/rishabh00100/following{/other_user}", "gists_url": "https://api.github.com/users/rishabh00100/gists{/gist_id}", "starred_url": "https://api.github.com/users/rishabh00100/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rishabh00100/subscriptions", "organizations_url": "https://api.github.com/users/rishabh00100/orgs", "repos_url": "https://api.github.com/users/rishabh00100/repos", "events_url": "https://api.github.com/users/rishabh00100/events{/privacy}", "received_events_url": "https://api.github.com/users/rishabh00100/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-14T15:15:09Z", "updated_at": "2020-04-14T19:37:43Z", "closed_at": "2020-04-14T17:18:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I want to create an index of n different identities, each identity having multiple vectors.\r\n\r\nFor example,\r\nLets say I have 3 identities having the following details:\r\n\r\n- Identity_1 has 20 vectors (lets call them vector_1, vector_2 ..... vector_20)\r\n- Identity_2 has 40 vectors (lets call them vector_21, vector_22 ..... vector_60)\r\n- Identity_3 has 15 vectors (lets call them vector_61, vector_62 ..... vector_75)\r\n\r\n**Question:**\r\nWhat should be the best approach in add_item? \r\n\r\nApproach 1:\r\nuse index_file.add_item(item_id, vector) with item_id in [1,2,3] and vector in [vector_1, vector_2 ....vector_75] \r\n\r\nApproach 2:\r\nuse index_file.add_item(item_id, vector) with item_id in [1,2,........74, 75] and vector in [vector_1, vector_2 ....vector_75] and then map the numbers 1 - 75 with my corresponding Identities separately\r\n\r\nTIA", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/475", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/475/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/475/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/475/events", "html_url": "https://github.com/spotify/annoy/issues/475", "id": 599639791, "node_id": "MDU6SXNzdWU1OTk2Mzk3OTE=", "number": 475, "title": "Hi,", "user": {"login": "rishabh00100", "id": 16775801, "node_id": "MDQ6VXNlcjE2Nzc1ODAx", "avatar_url": "https://avatars3.githubusercontent.com/u/16775801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rishabh00100", "html_url": "https://github.com/rishabh00100", "followers_url": "https://api.github.com/users/rishabh00100/followers", "following_url": "https://api.github.com/users/rishabh00100/following{/other_user}", "gists_url": "https://api.github.com/users/rishabh00100/gists{/gist_id}", "starred_url": "https://api.github.com/users/rishabh00100/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rishabh00100/subscriptions", "organizations_url": "https://api.github.com/users/rishabh00100/orgs", "repos_url": "https://api.github.com/users/rishabh00100/repos", "events_url": "https://api.github.com/users/rishabh00100/events{/privacy}", "received_events_url": "https://api.github.com/users/rishabh00100/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-04-14T14:59:59Z", "updated_at": "2020-04-14T16:31:00Z", "closed_at": "2020-04-14T16:31:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/474", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/474/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/474/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/474/events", "html_url": "https://github.com/spotify/annoy/issues/474", "id": 595176339, "node_id": "MDU6SXNzdWU1OTUxNzYzMzk=", "number": 474, "title": "scalability of annoy", "user": {"login": "jasica528", "id": 11925200, "node_id": "MDQ6VXNlcjExOTI1MjAw", "avatar_url": "https://avatars2.githubusercontent.com/u/11925200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasica528", "html_url": "https://github.com/jasica528", "followers_url": "https://api.github.com/users/jasica528/followers", "following_url": "https://api.github.com/users/jasica528/following{/other_user}", "gists_url": "https://api.github.com/users/jasica528/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasica528/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasica528/subscriptions", "organizations_url": "https://api.github.com/users/jasica528/orgs", "repos_url": "https://api.github.com/users/jasica528/repos", "events_url": "https://api.github.com/users/jasica528/events{/privacy}", "received_events_url": "https://api.github.com/users/jasica528/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-06T14:43:50Z", "updated_at": "2020-05-19T22:26:59Z", "closed_at": "2020-04-07T13:10:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "how about the memory, recall and search time changes when annoy scales from one million 128-dimensional features to one billion 128-dimensional features?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/471", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/471/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/471/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/471/events", "html_url": "https://github.com/spotify/annoy/issues/471", "id": 588210714, "node_id": "MDU6SXNzdWU1ODgyMTA3MTQ=", "number": 471, "title": "\"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\".            which method is more fast", "user": {"login": "hongshengxin", "id": 45747109, "node_id": "MDQ6VXNlcjQ1NzQ3MTA5", "avatar_url": "https://avatars0.githubusercontent.com/u/45747109?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hongshengxin", "html_url": "https://github.com/hongshengxin", "followers_url": "https://api.github.com/users/hongshengxin/followers", "following_url": "https://api.github.com/users/hongshengxin/following{/other_user}", "gists_url": "https://api.github.com/users/hongshengxin/gists{/gist_id}", "starred_url": "https://api.github.com/users/hongshengxin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hongshengxin/subscriptions", "organizations_url": "https://api.github.com/users/hongshengxin/orgs", "repos_url": "https://api.github.com/users/hongshengxin/repos", "events_url": "https://api.github.com/users/hongshengxin/events{/privacy}", "received_events_url": "https://api.github.com/users/hongshengxin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-26T07:26:47Z", "updated_at": "2020-03-26T13:24:06Z", "closed_at": "2020-03-26T13:24:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/469", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/469/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/469/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/469/events", "html_url": "https://github.com/spotify/annoy/issues/469", "id": 586436237, "node_id": "MDU6SXNzdWU1ODY0MzYyMzc=", "number": 469, "title": "Latest conda-forge build for Linux and Python 3.7 broken", "user": {"login": "buhrmann", "id": 190342, "node_id": "MDQ6VXNlcjE5MDM0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/190342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/buhrmann", "html_url": "https://github.com/buhrmann", "followers_url": "https://api.github.com/users/buhrmann/followers", "following_url": "https://api.github.com/users/buhrmann/following{/other_user}", "gists_url": "https://api.github.com/users/buhrmann/gists{/gist_id}", "starred_url": "https://api.github.com/users/buhrmann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/buhrmann/subscriptions", "organizations_url": "https://api.github.com/users/buhrmann/orgs", "repos_url": "https://api.github.com/users/buhrmann/repos", "events_url": "https://api.github.com/users/buhrmann/events{/privacy}", "received_events_url": "https://api.github.com/users/buhrmann/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-03-23T18:47:57Z", "updated_at": "2020-03-24T12:01:31Z", "closed_at": "2020-03-24T12:01:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Sorry for \"cross-posting\" this: https://github.com/conda-forge/python-annoy-feedstock/issues/32, but I'm not sure which is the best channel to raise this. In short, something must have gone wrong from build 1.16.3-py37he1b5a44_0 to 1.16.3-py37h3340039_1.  I imagine something in the configuration of the build, and resulting binary artifacts not being created correctly (since I don't think there were any code changes)?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/468", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/468/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/468/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/468/events", "html_url": "https://github.com/spotify/annoy/issues/468", "id": 586047802, "node_id": "MDU6SXNzdWU1ODYwNDc4MDI=", "number": 468, "title": "Hamming distance issue", "user": {"login": "dtanase", "id": 17724363, "node_id": "MDQ6VXNlcjE3NzI0MzYz", "avatar_url": "https://avatars1.githubusercontent.com/u/17724363?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dtanase", "html_url": "https://github.com/dtanase", "followers_url": "https://api.github.com/users/dtanase/followers", "following_url": "https://api.github.com/users/dtanase/following{/other_user}", "gists_url": "https://api.github.com/users/dtanase/gists{/gist_id}", "starred_url": "https://api.github.com/users/dtanase/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dtanase/subscriptions", "organizations_url": "https://api.github.com/users/dtanase/orgs", "repos_url": "https://api.github.com/users/dtanase/repos", "events_url": "https://api.github.com/users/dtanase/events{/privacy}", "received_events_url": "https://api.github.com/users/dtanase/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-23T09:10:30Z", "updated_at": "2020-03-23T15:03:35Z", "closed_at": "2020-03-23T13:27:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello \r\n\r\nI am encoding about 2M vectors (representing names of streets, as ASCII codes, e.g.: [63,71,179,102,32,222,127,111,...]) and I want to use to retrieve the street ID based on the free user input. Euclidean distance works just fine, but it has a problem: it is susceptible to input length: the user might write \"Somestr\" instead \"Somestreet\" which is still a valid input. Hamming distance seems much more robust to the variations in length, but there is either an implementation issue in Annoy or a misunderstanding on my side. Every time I am looking up similar vectors based on my input I get back a list of matches that 1) all have a vector of only 1.0 and 2) all have a 0.0 distance to my query vector:\r\n\r\n\r\nQuery vector: [119, 97, 108, 108, 105, 115, 101, 108, 108, 101, 110, 115, 116, 114, 97, 115, 115, 101, 32, 32, 32, 32, 32, 32, 32]\r\nThe best match: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\r\nDistance: 0.0\r\n\r\nI also tried to encode the data using continuous values ([0..1]) without any difference. I tried different tree sizes (up to 1000) with no change.\r\n\r\nAm I encoding wrongly my data (currently, it is the same routine as the query vector)? Is there any issue in Annoy's implementation of Hamming distance?\r\n\r\nI am using the release version: 1.16.3\r\n\r\nThank you\r\nDorian", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/465", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/465/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/465/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/465/events", "html_url": "https://github.com/spotify/annoy/issues/465", "id": 582571001, "node_id": "MDU6SXNzdWU1ODI1NzEwMDE=", "number": 465, "title": "Exposing _random in AnnoyIndex to python", "user": {"login": "jnboehm", "id": 12418563, "node_id": "MDQ6VXNlcjEyNDE4NTYz", "avatar_url": "https://avatars0.githubusercontent.com/u/12418563?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jnboehm", "html_url": "https://github.com/jnboehm", "followers_url": "https://api.github.com/users/jnboehm/followers", "following_url": "https://api.github.com/users/jnboehm/following{/other_user}", "gists_url": "https://api.github.com/users/jnboehm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jnboehm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jnboehm/subscriptions", "organizations_url": "https://api.github.com/users/jnboehm/orgs", "repos_url": "https://api.github.com/users/jnboehm/repos", "events_url": "https://api.github.com/users/jnboehm/events{/privacy}", "received_events_url": "https://api.github.com/users/jnboehm/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-16T20:10:58Z", "updated_at": "2020-03-17T14:16:00Z", "closed_at": "2020-03-17T14:15:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'd like to be able to have more control about the randomness when using annoy.  In essence I'd love to be able to pass a seed, or even better, an instance of numpy.random.RandomGenerator, although a seed will most likely suffice.\r\n\r\nI think editing [this line](https://github.com/spotify/annoy/blob/20047ca84b44f471c5739edd6ea7f22484e80fe1/src/annoylib.h#L846) and moving it to the public part would be the first step.\r\n\r\nWhat I'm still unclear on is how the C++ object would relate to the corresponding python object (I assume this is nontrivial). Furthermore, can the `Random` object even be initialized with an int?  In general how Python and C++ work together is still a bit of a mystery to me.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/464", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/464/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/464/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/464/events", "html_url": "https://github.com/spotify/annoy/issues/464", "id": 580073186, "node_id": "MDU6SXNzdWU1ODAwNzMxODY=", "number": 464, "title": "Same value returned for all distances", "user": {"login": "tykiww", "id": 36966666, "node_id": "MDQ6VXNlcjM2OTY2NjY2", "avatar_url": "https://avatars3.githubusercontent.com/u/36966666?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tykiww", "html_url": "https://github.com/tykiww", "followers_url": "https://api.github.com/users/tykiww/followers", "following_url": "https://api.github.com/users/tykiww/following{/other_user}", "gists_url": "https://api.github.com/users/tykiww/gists{/gist_id}", "starred_url": "https://api.github.com/users/tykiww/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tykiww/subscriptions", "organizations_url": "https://api.github.com/users/tykiww/orgs", "repos_url": "https://api.github.com/users/tykiww/repos", "events_url": "https://api.github.com/users/tykiww/events{/privacy}", "received_events_url": "https://api.github.com/users/tykiww/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-12T16:49:22Z", "updated_at": "2020-03-25T05:05:10Z", "closed_at": "2020-03-25T05:05:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Love the tech. Thank you for your work.\r\n\r\nI have been trying to use annoy to find the nearest neighbors of a 256x256x1 grayscale image with an appended vector of colors (length 12) and all the reported neighbors have come back with the same distance. It yields surprisingly great results, but the distances are disconcerting.\r\n\r\nIs that because my dimensions are too large? \r\n\r\nThe table below corresponds with:  ID, Neighbor (n), Distance (n), ... \r\n\r\n\r\n![neighbor_same](https://user-images.githubusercontent.com/36966666/76545464-6cdf7800-644f-11ea-8bea-021154d0c676.png)\r\n\r\n\r\n\r\nThank you for your help!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/459", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/459/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/459/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/459/events", "html_url": "https://github.com/spotify/annoy/issues/459", "id": 572335101, "node_id": "MDU6SXNzdWU1NzIzMzUxMDE=", "number": 459, "title": "Question about memory allocation and add_item", "user": {"login": "fralik", "id": 191278, "node_id": "MDQ6VXNlcjE5MTI3OA==", "avatar_url": "https://avatars0.githubusercontent.com/u/191278?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fralik", "html_url": "https://github.com/fralik", "followers_url": "https://api.github.com/users/fralik/followers", "following_url": "https://api.github.com/users/fralik/following{/other_user}", "gists_url": "https://api.github.com/users/fralik/gists{/gist_id}", "starred_url": "https://api.github.com/users/fralik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fralik/subscriptions", "organizations_url": "https://api.github.com/users/fralik/orgs", "repos_url": "https://api.github.com/users/fralik/repos", "events_url": "https://api.github.com/users/fralik/events{/privacy}", "received_events_url": "https://api.github.com/users/fralik/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-02-27T20:20:01Z", "updated_at": "2020-02-28T13:06:53Z", "closed_at": "2020-02-28T00:37:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "The documentation says that when one calls `a.add_item(i, v)`, then *it* will allocate memory for `max(i) + 1` items. My question is: when this allocation takes places? If I just read this explanation, then it seems to me that this code:\r\n```\r\na = AnnoyIndex(3, 'angular')\r\na.add_item(0, [1, 0, 0])\r\na.add_item(1, [0, 1, 0])\r\na.add_item(2, [0, 0, 1])\r\n```\r\nwill reallocate memory 3 times. First, it will allocate for 1 item, then it will reallocate for 2 items and then for 3. Is it so or do I miss smt?\r\n\r\nI tried to look for answer in issues, but have only found question regarding non sequential and non zero-based item ids.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/454", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/454/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/454/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/454/events", "html_url": "https://github.com/spotify/annoy/issues/454", "id": 564678248, "node_id": "MDU6SXNzdWU1NjQ2NzgyNDg=", "number": 454, "title": "Is there a possibility to add label/data to the items", "user": {"login": "n1ru4l", "id": 14338007, "node_id": "MDQ6VXNlcjE0MzM4MDA3", "avatar_url": "https://avatars2.githubusercontent.com/u/14338007?v=4", "gravatar_id": "", "url": "https://api.github.com/users/n1ru4l", "html_url": "https://github.com/n1ru4l", "followers_url": "https://api.github.com/users/n1ru4l/followers", "following_url": "https://api.github.com/users/n1ru4l/following{/other_user}", "gists_url": "https://api.github.com/users/n1ru4l/gists{/gist_id}", "starred_url": "https://api.github.com/users/n1ru4l/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/n1ru4l/subscriptions", "organizations_url": "https://api.github.com/users/n1ru4l/orgs", "repos_url": "https://api.github.com/users/n1ru4l/repos", "events_url": "https://api.github.com/users/n1ru4l/events{/privacy}", "received_events_url": "https://api.github.com/users/n1ru4l/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-13T13:21:02Z", "updated_at": "2020-02-13T13:57:29Z", "closed_at": "2020-02-13T13:57:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "For my use-case, I want to apply some post-filtering to the query result based on the input. Right now I would have to load the data from an external source such as Redis by using the returned indexes from the `get_nns_by_vector ` or `get_nns_by_item ` method.\r\n\r\nWould it be possible to specify some data that is stored along with the item which is added via the `add_item` method (e.g. as a third parameter)? It could then be returned as part of the result returned from `get_nns_by_vector` and `get_nns_by_item`, or at least be accessible via some other method that looks up the label/associated data via the index?\r\n\r\nWith that functionality, it would be possible to not require loading additional data source for retrieving the actual id of a result (or any other associated data).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/453", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/453/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/453/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/453/events", "html_url": "https://github.com/spotify/annoy/issues/453", "id": 564400893, "node_id": "MDU6SXNzdWU1NjQ0MDA4OTM=", "number": 453, "title": "documentation on selecting `n_trees`", "user": {"login": "redwrasse", "id": 6155946, "node_id": "MDQ6VXNlcjYxNTU5NDY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6155946?v=4", "gravatar_id": "", "url": "https://api.github.com/users/redwrasse", "html_url": "https://github.com/redwrasse", "followers_url": "https://api.github.com/users/redwrasse/followers", "following_url": "https://api.github.com/users/redwrasse/following{/other_user}", "gists_url": "https://api.github.com/users/redwrasse/gists{/gist_id}", "starred_url": "https://api.github.com/users/redwrasse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/redwrasse/subscriptions", "organizations_url": "https://api.github.com/users/redwrasse/orgs", "repos_url": "https://api.github.com/users/redwrasse/repos", "events_url": "https://api.github.com/users/redwrasse/events{/privacy}", "received_events_url": "https://api.github.com/users/redwrasse/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-13T02:35:38Z", "updated_at": "2020-02-13T03:11:53Z", "closed_at": "2020-02-13T03:11:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "the documentation/readme could potentially benefit (I can't find it anywhere) from a quantitative discussion for selecting the number of trees parameter, specifically its relation to precision and index size.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/452", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/452/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/452/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/452/events", "html_url": "https://github.com/spotify/annoy/issues/452", "id": 562492291, "node_id": "MDU6SXNzdWU1NjI0OTIyOTE=", "number": 452, "title": "Fixed-radius near neighbors", "user": {"login": "appanacca", "id": 8914853, "node_id": "MDQ6VXNlcjg5MTQ4NTM=", "avatar_url": "https://avatars1.githubusercontent.com/u/8914853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/appanacca", "html_url": "https://github.com/appanacca", "followers_url": "https://api.github.com/users/appanacca/followers", "following_url": "https://api.github.com/users/appanacca/following{/other_user}", "gists_url": "https://api.github.com/users/appanacca/gists{/gist_id}", "starred_url": "https://api.github.com/users/appanacca/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/appanacca/subscriptions", "organizations_url": "https://api.github.com/users/appanacca/orgs", "repos_url": "https://api.github.com/users/appanacca/repos", "events_url": "https://api.github.com/users/appanacca/events{/privacy}", "received_events_url": "https://api.github.com/users/appanacca/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-10T11:15:51Z", "updated_at": "2020-02-10T14:57:34Z", "closed_at": "2020-02-10T14:57:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nI have seen that in the interface of the AnnoyIndex is not possible to perform ball queries.\r\nIs it possible in theory to support it ? \r\nI had in mind something like \"get_nns_by_item\" with a radius parameters. \r\nIs it possible to do it in Annoy ? Any bibliography on the subject ? \r\n\r\nThank you  in advance !", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/451", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/451/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/451/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/451/events", "html_url": "https://github.com/spotify/annoy/issues/451", "id": 559059041, "node_id": "MDU6SXNzdWU1NTkwNTkwNDE=", "number": 451, "title": "Can on_disk_build mode save memory?", "user": {"login": "bit-pku-zdf", "id": 53204985, "node_id": "MDQ6VXNlcjUzMjA0OTg1", "avatar_url": "https://avatars0.githubusercontent.com/u/53204985?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bit-pku-zdf", "html_url": "https://github.com/bit-pku-zdf", "followers_url": "https://api.github.com/users/bit-pku-zdf/followers", "following_url": "https://api.github.com/users/bit-pku-zdf/following{/other_user}", "gists_url": "https://api.github.com/users/bit-pku-zdf/gists{/gist_id}", "starred_url": "https://api.github.com/users/bit-pku-zdf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bit-pku-zdf/subscriptions", "organizations_url": "https://api.github.com/users/bit-pku-zdf/orgs", "repos_url": "https://api.github.com/users/bit-pku-zdf/repos", "events_url": "https://api.github.com/users/bit-pku-zdf/events{/privacy}", "received_events_url": "https://api.github.com/users/bit-pku-zdf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-02-03T12:42:42Z", "updated_at": "2020-05-19T22:29:05Z", "closed_at": "2020-05-19T22:29:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "As the title, I want to know if the on disk build mode save memory?\r\nCode:\r\n\r\nt = AnnoyIndex(f, 'dot')  # Length of item vector that will be indexed\r\nt.on_disk_build('test.ann')\r\nt1 = time.time()\r\nprint(\"t1: %f\"%(t1))\r\nfor i in range(50000000):\r\n    #print(i)\r\n    #t_1 = time.time()\r\n    v = [random.gauss(0, 1) for z in range(f)]\r\n    #t_3 = time.time()\r\n    t.add_item(i, v)\r\n    #t_2 = time.time()\r\n    #print(t_2-t_1)\r\nt2 = time.time()\r\nprint(\"t2: %f\"%(t2))\r\nt.build(100) # 10 trees\r\n\r\nIf the number of vector is 50million, the dimension is 512, the space of disk is about 100G, how about the memory? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/450", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/450/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/450/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/450/events", "html_url": "https://github.com/spotify/annoy/issues/450", "id": 558761945, "node_id": "MDU6SXNzdWU1NTg3NjE5NDU=", "number": 450, "title": "What is the best way to scale the compute around annoy index", "user": {"login": "eyal13579", "id": 19887938, "node_id": "MDQ6VXNlcjE5ODg3OTM4", "avatar_url": "https://avatars3.githubusercontent.com/u/19887938?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eyal13579", "html_url": "https://github.com/eyal13579", "followers_url": "https://api.github.com/users/eyal13579/followers", "following_url": "https://api.github.com/users/eyal13579/following{/other_user}", "gists_url": "https://api.github.com/users/eyal13579/gists{/gist_id}", "starred_url": "https://api.github.com/users/eyal13579/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eyal13579/subscriptions", "organizations_url": "https://api.github.com/users/eyal13579/orgs", "repos_url": "https://api.github.com/users/eyal13579/repos", "events_url": "https://api.github.com/users/eyal13579/events{/privacy}", "received_events_url": "https://api.github.com/users/eyal13579/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-02-02T21:35:11Z", "updated_at": "2020-03-15T08:46:27Z", "closed_at": "2020-02-02T23:17:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Assume I have big annoy index that serves real time production system.\r\nAssume I need more than one machine/pod to handle the traffic.\r\nIn addition - from time to time throughout the day - index should be rebuilt.\r\n\r\nWhat's the practice to productize this?\r\n\r\n- Should we have some NAS (we've tried aws efs) - that all dockers are attached to? (performance is not well - but logic of replacement is pretty easy - hot swap)\r\n\r\n- Should we start syncing big files around the dockers (heavy logic, lots of edge cases)? and if so, any recommendation\r\n\r\n(just to make it a bit complicated - assume that each customer we serve has it's own index, so we need to have all dockers access to all indexes - to be able to reply to each query - load-search-unload..)\r\n\r\n\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/449", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/449/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/449/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/449/events", "html_url": "https://github.com/spotify/annoy/issues/449", "id": 558431528, "node_id": "MDU6SXNzdWU1NTg0MzE1Mjg=", "number": 449, "title": "Save annoy index in databricks/pyspark for later use?", "user": {"login": "robotheart", "id": 60528315, "node_id": "MDQ6VXNlcjYwNTI4MzE1", "avatar_url": "https://avatars3.githubusercontent.com/u/60528315?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robotheart", "html_url": "https://github.com/robotheart", "followers_url": "https://api.github.com/users/robotheart/followers", "following_url": "https://api.github.com/users/robotheart/following{/other_user}", "gists_url": "https://api.github.com/users/robotheart/gists{/gist_id}", "starred_url": "https://api.github.com/users/robotheart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robotheart/subscriptions", "organizations_url": "https://api.github.com/users/robotheart/orgs", "repos_url": "https://api.github.com/users/robotheart/repos", "events_url": "https://api.github.com/users/robotheart/events{/privacy}", "received_events_url": "https://api.github.com/users/robotheart/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-01-31T23:44:22Z", "updated_at": "2020-02-03T21:31:07Z", "closed_at": "2020-02-01T16:11:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there,\r\n\r\nFor a project I\u2019m using this library and was able to get a job running in Databricks that uses a lot of data to build the index (takes some time to run). For a follow up task I now need to use annoy in real time to predict on steaming data. Is there a best way to do this? I was hoping to just save the index I built previously and load it for the new job to predict. I see though the index can\u2019t be pickled and when I try to save it with the library method to an s3 bucket path it causes issues. It seems I can only save it as \u201cindex.ann\u201d for example, no path name. Is there a good workaround? Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/448", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/448/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/448/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/448/events", "html_url": "https://github.com/spotify/annoy/issues/448", "id": 551202570, "node_id": "MDU6SXNzdWU1NTEyMDI1NzA=", "number": 448, "title": "predict cost long time sometimes", "user": {"login": "zachwangb", "id": 20202539, "node_id": "MDQ6VXNlcjIwMjAyNTM5", "avatar_url": "https://avatars3.githubusercontent.com/u/20202539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zachwangb", "html_url": "https://github.com/zachwangb", "followers_url": "https://api.github.com/users/zachwangb/followers", "following_url": "https://api.github.com/users/zachwangb/following{/other_user}", "gists_url": "https://api.github.com/users/zachwangb/gists{/gist_id}", "starred_url": "https://api.github.com/users/zachwangb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zachwangb/subscriptions", "organizations_url": "https://api.github.com/users/zachwangb/orgs", "repos_url": "https://api.github.com/users/zachwangb/repos", "events_url": "https://api.github.com/users/zachwangb/events{/privacy}", "received_events_url": "https://api.github.com/users/zachwangb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-17T05:09:35Z", "updated_at": "2020-01-17T13:47:44Z", "closed_at": "2020-01-17T13:47:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "why some data due to long time cost,i have 10 trees,and about millions data with 200 dimension", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/446", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/446/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/446/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/446/events", "html_url": "https://github.com/spotify/annoy/issues/446", "id": 548214333, "node_id": "MDU6SXNzdWU1NDgyMTQzMzM=", "number": 446, "title": "Kernel dies when trying to add items", "user": {"login": "nishray12096", "id": 35083698, "node_id": "MDQ6VXNlcjM1MDgzNjk4", "avatar_url": "https://avatars2.githubusercontent.com/u/35083698?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nishray12096", "html_url": "https://github.com/nishray12096", "followers_url": "https://api.github.com/users/nishray12096/followers", "following_url": "https://api.github.com/users/nishray12096/following{/other_user}", "gists_url": "https://api.github.com/users/nishray12096/gists{/gist_id}", "starred_url": "https://api.github.com/users/nishray12096/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nishray12096/subscriptions", "organizations_url": "https://api.github.com/users/nishray12096/orgs", "repos_url": "https://api.github.com/users/nishray12096/repos", "events_url": "https://api.github.com/users/nishray12096/events{/privacy}", "received_events_url": "https://api.github.com/users/nishray12096/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-01-10T17:58:13Z", "updated_at": "2020-01-11T20:43:18Z", "closed_at": "2020-01-10T20:21:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\n\r\nI have ~30k documents transformed into LASER embeddings using the laserembeddings package (1024 dimensions). The documents are now in a pandas DF: indexed by some integer, with all columns being the LASER transformation dimensions.\r\n\r\nWhen I run this:\r\n`Laser_Index = AnnoyIndex(1024, 'angular')\r\nfor ind in EmbeddingsFrame.index:\r\n    Laser_Index.add_item(ind, EmbeddingsFrame.loc[ind].tolist())`\r\n\r\nThe python kernel dies. I've confirmed that ind is an integer and I've tried adding the embeddings as a list, array, and PD series. All yield the same results. I've run `pip install --upgrade annoy`, but the issue persists there as well. The toy example in the Readme works fine - so I figure this has something to do with data types, but am lost as to what I can do to resolve the issue. Thanks for any advice in advance :)\r\n\r\n-Nishant", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/445", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/445/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/445/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/445/events", "html_url": "https://github.com/spotify/annoy/issues/445", "id": 547822720, "node_id": "MDU6SXNzdWU1NDc4MjI3MjA=", "number": 445, "title": "Save vectors in remote HDFS", "user": {"login": "paulomann", "id": 7051554, "node_id": "MDQ6VXNlcjcwNTE1NTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/7051554?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulomann", "html_url": "https://github.com/paulomann", "followers_url": "https://api.github.com/users/paulomann/followers", "following_url": "https://api.github.com/users/paulomann/following{/other_user}", "gists_url": "https://api.github.com/users/paulomann/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulomann/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulomann/subscriptions", "organizations_url": "https://api.github.com/users/paulomann/orgs", "repos_url": "https://api.github.com/users/paulomann/repos", "events_url": "https://api.github.com/users/paulomann/events{/privacy}", "received_events_url": "https://api.github.com/users/paulomann/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-01-10T02:02:52Z", "updated_at": "2020-01-10T16:38:10Z", "closed_at": "2020-01-10T14:12:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Suppose I have two machines: **M1**, and **M2**, **M1** has the HDFS file system, while **M2** is where my Machine Learning inference code is running. What I need to do is to store vectors in the HDFS file system (in **M1**), and retrieve all similar vectors in **M2**. Since the number of vectors can rapidly increase, the **M2** will not have sufficient space, but the HDFS file system will have.\r\n\r\nTL;DR: Can I store Annoy vectors in a remote HDFS and read them in another machine?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/441", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/441/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/441/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/441/events", "html_url": "https://github.com/spotify/annoy/issues/441", "id": 537679019, "node_id": "MDU6SXNzdWU1Mzc2NzkwMTk=", "number": 441, "title": "Question regarding thread safety.", "user": {"login": "altmnt", "id": 32936967, "node_id": "MDQ6VXNlcjMyOTM2OTY3", "avatar_url": "https://avatars3.githubusercontent.com/u/32936967?v=4", "gravatar_id": "", "url": "https://api.github.com/users/altmnt", "html_url": "https://github.com/altmnt", "followers_url": "https://api.github.com/users/altmnt/followers", "following_url": "https://api.github.com/users/altmnt/following{/other_user}", "gists_url": "https://api.github.com/users/altmnt/gists{/gist_id}", "starred_url": "https://api.github.com/users/altmnt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/altmnt/subscriptions", "organizations_url": "https://api.github.com/users/altmnt/orgs", "repos_url": "https://api.github.com/users/altmnt/repos", "events_url": "https://api.github.com/users/altmnt/events{/privacy}", "received_events_url": "https://api.github.com/users/altmnt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-12-13T17:38:42Z", "updated_at": "2019-12-18T16:07:19Z", "closed_at": "2019-12-18T16:07:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am planning to create a webapp that is going to on_disk_build searches and adds vectors to the tree by web requests. Is this going to be an issue if several threads do that concurrently(several web requests)?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/440", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/440/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/440/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/440/events", "html_url": "https://github.com/spotify/annoy/issues/440", "id": 531557003, "node_id": "MDU6SXNzdWU1MzE1NTcwMDM=", "number": 440, "title": "GZip support for model files?", "user": {"login": "jpmatusik", "id": 29404365, "node_id": "MDQ6VXNlcjI5NDA0MzY1", "avatar_url": "https://avatars2.githubusercontent.com/u/29404365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpmatusik", "html_url": "https://github.com/jpmatusik", "followers_url": "https://api.github.com/users/jpmatusik/followers", "following_url": "https://api.github.com/users/jpmatusik/following{/other_user}", "gists_url": "https://api.github.com/users/jpmatusik/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpmatusik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpmatusik/subscriptions", "organizations_url": "https://api.github.com/users/jpmatusik/orgs", "repos_url": "https://api.github.com/users/jpmatusik/repos", "events_url": "https://api.github.com/users/jpmatusik/events{/privacy}", "received_events_url": "https://api.github.com/users/jpmatusik/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-02T21:41:30Z", "updated_at": "2019-12-03T19:07:43Z", "closed_at": "2019-12-03T19:07:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi quick question.\r\n\r\nI have a pretty big model file (about 1.6GB) and when I gzip it, it gets down to about 360MB. So some decent compression. But as far as I can tell, the load method does not support any compressed files.\r\n\r\nI was wondering if I'm wrong about that and if so, would a PR adding support for something like \r\nthe following be welcome?\r\n\r\n```\r\nu = AnnoyIndex(f, 'angular')\r\nu.load('model_file.knn.gz')\r\n```\r\n\r\nBasically just something to check to see if the file extension ends in 'gz' and handle it.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/438", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/438/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/438/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/438/events", "html_url": "https://github.com/spotify/annoy/issues/438", "id": 515117659, "node_id": "MDU6SXNzdWU1MTUxMTc2NTk=", "number": 438, "title": "Index size suddenly blows up after adding 500K items at 1024 dimension size.", "user": {"login": "jay-trivedi", "id": 25292338, "node_id": "MDQ6VXNlcjI1MjkyMzM4", "avatar_url": "https://avatars0.githubusercontent.com/u/25292338?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jay-trivedi", "html_url": "https://github.com/jay-trivedi", "followers_url": "https://api.github.com/users/jay-trivedi/followers", "following_url": "https://api.github.com/users/jay-trivedi/following{/other_user}", "gists_url": "https://api.github.com/users/jay-trivedi/gists{/gist_id}", "starred_url": "https://api.github.com/users/jay-trivedi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jay-trivedi/subscriptions", "organizations_url": "https://api.github.com/users/jay-trivedi/orgs", "repos_url": "https://api.github.com/users/jay-trivedi/repos", "events_url": "https://api.github.com/users/jay-trivedi/events{/privacy}", "received_events_url": "https://api.github.com/users/jay-trivedi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-10-31T02:44:10Z", "updated_at": "2020-06-04T16:31:47Z", "closed_at": "2019-11-05T01:32:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am using Annoy to index items with a dimension size of 1024. It works remarkably well during index building until about 500K items with index size reaching upto about 15GB in size. Easy to fit in RAM. However, as soon as I cross 500K items, the index size suddenly blows up and by the time I reach 520K items the index size goes beyond 60GB (= machine RAM) and my machine runs out of memory. I tried reducing the n_trees from 15 to 12 but that doesn't help. Here are some useful details.\r\n\r\nos - ubuntu 18.04, 60GB memory, 4 cores\r\npython version 3.6.9\r\nannoy version 1.16.0\r\ndimensions - 1024\r\nmetric - euclidian\r\n\r\nThanks for the help in advance!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/437", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/437/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/437/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/437/events", "html_url": "https://github.com/spotify/annoy/issues/437", "id": 512937613, "node_id": "MDU6SXNzdWU1MTI5Mzc2MTM=", "number": 437, "title": "When installing on windows 10 it throws this cl.exe error. What can I do? ", "user": {"login": "Tahsin-Mayeesha", "id": 17886829, "node_id": "MDQ6VXNlcjE3ODg2ODI5", "avatar_url": "https://avatars2.githubusercontent.com/u/17886829?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tahsin-Mayeesha", "html_url": "https://github.com/Tahsin-Mayeesha", "followers_url": "https://api.github.com/users/Tahsin-Mayeesha/followers", "following_url": "https://api.github.com/users/Tahsin-Mayeesha/following{/other_user}", "gists_url": "https://api.github.com/users/Tahsin-Mayeesha/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tahsin-Mayeesha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tahsin-Mayeesha/subscriptions", "organizations_url": "https://api.github.com/users/Tahsin-Mayeesha/orgs", "repos_url": "https://api.github.com/users/Tahsin-Mayeesha/repos", "events_url": "https://api.github.com/users/Tahsin-Mayeesha/events{/privacy}", "received_events_url": "https://api.github.com/users/Tahsin-Mayeesha/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-27T08:40:27Z", "updated_at": "2019-10-27T14:43:38Z", "closed_at": "2019-10-27T14:43:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "![Screenshot (1)](https://user-images.githubusercontent.com/17886829/67631982-92684c80-f8c7-11e9-8515-ebd04204f10d.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/432", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/432/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/432/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/432/events", "html_url": "https://github.com/spotify/annoy/issues/432", "id": 509706266, "node_id": "MDU6SXNzdWU1MDk3MDYyNjY=", "number": 432, "title": "Failing angular distance tests", "user": {"login": "karlhigley", "id": 885295, "node_id": "MDQ6VXNlcjg4NTI5NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/885295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karlhigley", "html_url": "https://github.com/karlhigley", "followers_url": "https://api.github.com/users/karlhigley/followers", "following_url": "https://api.github.com/users/karlhigley/following{/other_user}", "gists_url": "https://api.github.com/users/karlhigley/gists{/gist_id}", "starred_url": "https://api.github.com/users/karlhigley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karlhigley/subscriptions", "organizations_url": "https://api.github.com/users/karlhigley/orgs", "repos_url": "https://api.github.com/users/karlhigley/repos", "events_url": "https://api.github.com/users/karlhigley/events{/privacy}", "received_events_url": "https://api.github.com/users/karlhigley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-10-21T03:10:03Z", "updated_at": "2019-10-21T20:46:38Z", "closed_at": "2019-10-21T20:46:38Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When I clone master at v1.16.2 and run the tests, I get two failures with Python 2.7.16:\r\n\r\n```\r\n======================================================================\r\nFAIL: test_distance_consistency (angular_index_test.AngularIndexTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/Users/karl/Projects/ml/annoy/test/angular_index_test.py\", line 196, in test_distance_consistency\r\n    self.assertAlmostEqual(dist, numpy.dot(u_norm - v_norm, u_norm - v_norm) ** 0.5)\r\n  File \"/Users/karl/Projects/ml/annoy/test/common.py\", line 20, in assertAlmostEqual\r\n    super(TestCase, self).assertAlmostEqual(x, y, 3)\r\nAssertionError: 0.0005146485636942089 != 0.0 within 3 places\r\n\r\n======================================================================\r\nFAIL: test_single_vector (angular_index_test.AngularIndexTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/Users/karl/Projects/ml/annoy/test/angular_index_test.py\", line 226, in test_single_vector\r\n    self.assertEquals(a.get_nns_by_vector([1, 0, 0], 3, include_distances=True), ([0], [0.0]))\r\nAssertionError: Tuples differ: ([0], [0.0003452669770922512]) != ([0], [0.0])\r\n\r\nFirst differing element 1:\r\n[0.0003452669770922512]\r\n[0.0]\r\n\r\n- ([0], [0.0003452669770922512])\r\n+ ([0], [0.0])\r\n\r\n----------------------------------------------------------------------\r\nRan 99 tests in 175.784s\r\n\r\nFAILED (failures=2)\r\n```\r\n\r\nAny ideas why these tests would be failing? (With Python 3.7.4, only the second test fails.)\r\n\r\nThe Python 2 build logs look like this:\r\n\r\n```\r\n$ python setup.py nosetests\r\nrunning nosetests\r\nrunning egg_info\r\nwriting annoy.egg-info/PKG-INFO\r\nwriting top-level names to annoy.egg-info/top_level.txt\r\nwriting dependency_links to annoy.egg-info/dependency_links.txt\r\nreading manifest file 'annoy.egg-info/SOURCES.txt'\r\nreading manifest template 'MANIFEST.in'\r\nwriting manifest file 'annoy.egg-info/SOURCES.txt'\r\nbuilding 'annoy.annoylib' extension\r\ncreating build/temp.macosx-10.14-x86_64-2.7\r\ncreating build/temp.macosx-10.14-x86_64-2.7/src\r\nclang -fno-strict-aliasing -I/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/karl/.pyenv/versions/2.7.16/include/python2.7 -c src/annoymodule.cc -o build/temp.macosx-10.14-x86_64-2.7/src/annoymodule.o -march=native -O3 -ffast-math -fno-associative-math -std=c++11 -mmacosx-version-min=10.9\r\nIn file included from src/annoymodule.cc:15:\r\nsrc/annoylib.h:81:9: warning: Using 128-bit AVX instructions [-W#pragma-messages]\r\n#pragma message \"Using 128-bit AVX instructions\"\r\n        ^\r\nIn file included from src/annoymodule.cc:17:\r\nIn file included from /Users/karl/.pyenv/versions/2.7.16/include/python2.7/Python.h:88:\r\n/Users/karl/.pyenv/versions/2.7.16/include/python2.7/unicodeobject.h:534:5: warning: 'register'\r\n      storage class specifier is deprecated and incompatible with C++17 [-Wdeprecated-register]\r\n    register PyObject *obj,     /* Object */\r\n    ^~~~~~~~~\r\n/Users/karl/.pyenv/versions/2.7.16/include/python2.7/unicodeobject.h:553:5: warning: 'register'\r\n      storage class specifier is deprecated and incompatible with C++17 [-Wdeprecated-register]\r\n    register PyObject *obj      /* Object */\r\n    ^~~~~~~~~\r\n/Users/karl/.pyenv/versions/2.7.16/include/python2.7/unicodeobject.h:575:5: warning: 'register'\r\n      storage class specifier is deprecated and incompatible with C++17 [-Wdeprecated-register]\r\n    register const wchar_t *w,  /* wchar_t buffer */\r\n    ^~~~~~~~~\r\n/Users/karl/.pyenv/versions/2.7.16/include/python2.7/unicodeobject.h:593:5: warning: 'register'\r\n      storage class specifier is deprecated and incompatible with C++17 [-Wdeprecated-register]\r\n    register wchar_t *w,        /* wchar_t buffer */\r\n    ^~~~~~~~~\r\nIn file included from src/annoymodule.cc:17:\r\nIn file included from /Users/karl/.pyenv/versions/2.7.16/include/python2.7/Python.h:97:\r\n/Users/karl/.pyenv/versions/2.7.16/include/python2.7/stringobject.h:173:5: warning: 'register'\r\n      storage class specifier is deprecated and incompatible with C++17 [-Wdeprecated-register]\r\n    register PyObject *obj,     /* string or Unicode object */\r\n    ^~~~~~~~~\r\n/Users/karl/.pyenv/versions/2.7.16/include/python2.7/stringobject.h:174:5: warning: 'register'\r\n      storage class specifier is deprecated and incompatible with C++17 [-Wdeprecated-register]\r\n    register char **s,          /* pointer to buffer variable */\r\n    ^~~~~~~~~\r\n/Users/karl/.pyenv/versions/2.7.16/include/python2.7/stringobject.h:175:5: warning: 'register'\r\n      storage class specifier is deprecated and incompatible with C++17 [-Wdeprecated-register]\r\n    register Py_ssize_t *len    /* pointer to length variable or NULL\r\n    ^~~~~~~~~\r\n8 warnings generated.\r\ncreating build/lib.macosx-10.14-x86_64-2.7\r\ncreating build/lib.macosx-10.14-x86_64-2.7/annoy\r\nc++ -bundle -undefined dynamic_lookup -L/Users/karl/.homebrew/opt/readline/lib -L/Users/karl/.homebrew/opt/readline/lib -L/Users/karl/.homebrew/opt/openssl/lib -L/Users/karl/.pyenv/versions/2.7.16/lib build/temp.macosx-10.14-x86_64-2.7/src/annoymodule.o -o build/lib.macosx-10.14-x86_64-2.7/annoy/annoylib.so -stdlib=libc++ -mmacosx-version-min=10.9\r\ncopying build/lib.macosx-10.14-x86_64-2.7/annoy/annoylib.so -> annoy\r\n```\r\nThe only thing that stands out to me there is the warning about 128-bit AVX instructions, but not sure if that's related. \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/423", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/423/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/423/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/423/events", "html_url": "https://github.com/spotify/annoy/issues/423", "id": 498087439, "node_id": "MDU6SXNzdWU0OTgwODc0Mzk=", "number": 423, "title": "OSError: Index size is not a multiple of vector size", "user": {"login": "dtMndas", "id": 9609594, "node_id": "MDQ6VXNlcjk2MDk1OTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/9609594?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dtMndas", "html_url": "https://github.com/dtMndas", "followers_url": "https://api.github.com/users/dtMndas/followers", "following_url": "https://api.github.com/users/dtMndas/following{/other_user}", "gists_url": "https://api.github.com/users/dtMndas/gists{/gist_id}", "starred_url": "https://api.github.com/users/dtMndas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dtMndas/subscriptions", "organizations_url": "https://api.github.com/users/dtMndas/orgs", "repos_url": "https://api.github.com/users/dtMndas/repos", "events_url": "https://api.github.com/users/dtMndas/events{/privacy}", "received_events_url": "https://api.github.com/users/dtMndas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 28, "created_at": "2019-09-25T06:56:08Z", "updated_at": "2020-05-01T18:59:16Z", "closed_at": "2019-09-29T20:03:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "i  use  annoy to build ,which the number of words is 5844240 and the vector size is 200. it raise a error: \u3010OSError: Index size is not a multiple of vector size\u3011\u3002please help me ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/422", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/422/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/422/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/422/events", "html_url": "https://github.com/spotify/annoy/issues/422", "id": 498072746, "node_id": "MDU6SXNzdWU0OTgwNzI3NDY=", "number": 422, "title": "test_distance_consistency fails on 32bit", "user": {"login": "scarabeusiv", "id": 1055830, "node_id": "MDQ6VXNlcjEwNTU4MzA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1055830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scarabeusiv", "html_url": "https://github.com/scarabeusiv", "followers_url": "https://api.github.com/users/scarabeusiv/followers", "following_url": "https://api.github.com/users/scarabeusiv/following{/other_user}", "gists_url": "https://api.github.com/users/scarabeusiv/gists{/gist_id}", "starred_url": "https://api.github.com/users/scarabeusiv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scarabeusiv/subscriptions", "organizations_url": "https://api.github.com/users/scarabeusiv/orgs", "repos_url": "https://api.github.com/users/scarabeusiv/repos", "events_url": "https://api.github.com/users/scarabeusiv/events{/privacy}", "received_events_url": "https://api.github.com/users/scarabeusiv/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-25T06:20:04Z", "updated_at": "2019-09-26T02:34:29Z", "closed_at": "2019-09-26T02:34:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\n[  551s] ____________________ DotIndexTest.test_distance_consistency ____________________\r\n[  551s] \r\n[  551s] self = <dot_index_test.DotIndexTest testMethod=test_distance_consistency>\r\n[  551s] \r\n[  551s]     def test_distance_consistency(self):\r\n[  551s]         n, f = 1000, 3\r\n[  551s]         i = AnnoyIndex(f, 'dot')\r\n[  551s]         for j in range(n):\r\n[  551s]             i.add_item(j, numpy.random.normal(size=f))\r\n[  551s]         i.build(10)\r\n[  551s]         for a in random.sample(range(n), 100):\r\n[  551s]             indices, dists = i.get_nns_by_item(a, 100, include_distances=True)\r\n[  551s]             for b, dist in zip(indices, dists):\r\n[  551s]                 self.assertAlmostEqual(dist, numpy.dot(\r\n[  551s]                     i.get_item_vector(a),\r\n[  551s]                     i.get_item_vector(b)\r\n[  551s]                 ))\r\n[  551s] >               self.assertEqual(dist, i.get_distance(a, b))\r\n[  551s] E               AssertionError: 5.229551315307617 != 5.229551142363135\r\n[  551s] \r\n[  551s] dot_index_test.py:158: AssertionError\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/421", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/421/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/421/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/421/events", "html_url": "https://github.com/spotify/annoy/issues/421", "id": 497590366, "node_id": "MDU6SXNzdWU0OTc1OTAzNjY=", "number": 421, "title": "what method used to bulid the tree?", "user": {"login": "Cumberbatch08", "id": 30173360, "node_id": "MDQ6VXNlcjMwMTczMzYw", "avatar_url": "https://avatars0.githubusercontent.com/u/30173360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Cumberbatch08", "html_url": "https://github.com/Cumberbatch08", "followers_url": "https://api.github.com/users/Cumberbatch08/followers", "following_url": "https://api.github.com/users/Cumberbatch08/following{/other_user}", "gists_url": "https://api.github.com/users/Cumberbatch08/gists{/gist_id}", "starred_url": "https://api.github.com/users/Cumberbatch08/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Cumberbatch08/subscriptions", "organizations_url": "https://api.github.com/users/Cumberbatch08/orgs", "repos_url": "https://api.github.com/users/Cumberbatch08/repos", "events_url": "https://api.github.com/users/Cumberbatch08/events{/privacy}", "received_events_url": "https://api.github.com/users/Cumberbatch08/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-24T10:08:59Z", "updated_at": "2019-09-25T07:48:07Z", "closed_at": "2019-09-24T17:50:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "after add item, build the tree.\r\nI'm interested of the method used to build the tree. does it use the knn or the kmeans?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/420", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/420/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/420/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/420/events", "html_url": "https://github.com/spotify/annoy/issues/420", "id": 496914646, "node_id": "MDU6SXNzdWU0OTY5MTQ2NDY=", "number": 420, "title": "Segmentation fault with repeated builds", "user": {"login": "justinchiu", "id": 2389353, "node_id": "MDQ6VXNlcjIzODkzNTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/2389353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/justinchiu", "html_url": "https://github.com/justinchiu", "followers_url": "https://api.github.com/users/justinchiu/followers", "following_url": "https://api.github.com/users/justinchiu/following{/other_user}", "gists_url": "https://api.github.com/users/justinchiu/gists{/gist_id}", "starred_url": "https://api.github.com/users/justinchiu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/justinchiu/subscriptions", "organizations_url": "https://api.github.com/users/justinchiu/orgs", "repos_url": "https://api.github.com/users/justinchiu/repos", "events_url": "https://api.github.com/users/justinchiu/events{/privacy}", "received_events_url": "https://api.github.com/users/justinchiu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-09-23T06:24:33Z", "updated_at": "2019-09-29T20:33:44Z", "closed_at": "2019-09-29T20:33:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Repeated builds with the same argument leads to segmentations faults after saving then loading.\r\n\r\nRepro:\r\n```\r\nimport numpy as np\r\nfrom annoy import AnnoyIndex\r\n\r\nt = AnnoyIndex(250, \"dot\")\r\n\r\nfor i in range(1000):\r\n    t.add_item(i, np.absolute(np.random.rand(250)))\r\n\r\n# segfault\r\nt.build(16)\r\nt.build(16)\r\nt.build(16)\r\nt.save(\"test.ann\")\r\nprint(t.get_nns_by_item(0, 10))\r\n```\r\n\r\nThis may seem contrived, but calling build multiple times may be a bug that pops up when abstracting over AnnoyIndices and was pretty hard to find. A simple catch would be throwing an error if build has already been called, unless there are use-cases for calling build multiple times.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/417", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/417/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/417/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/417/events", "html_url": "https://github.com/spotify/annoy/issues/417", "id": 496175294, "node_id": "MDU6SXNzdWU0OTYxNzUyOTQ=", "number": 417, "title": "how to get the similarity score", "user": {"login": "Cumberbatch08", "id": 30173360, "node_id": "MDQ6VXNlcjMwMTczMzYw", "avatar_url": "https://avatars0.githubusercontent.com/u/30173360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Cumberbatch08", "html_url": "https://github.com/Cumberbatch08", "followers_url": "https://api.github.com/users/Cumberbatch08/followers", "following_url": "https://api.github.com/users/Cumberbatch08/following{/other_user}", "gists_url": "https://api.github.com/users/Cumberbatch08/gists{/gist_id}", "starred_url": "https://api.github.com/users/Cumberbatch08/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Cumberbatch08/subscriptions", "organizations_url": "https://api.github.com/users/Cumberbatch08/orgs", "repos_url": "https://api.github.com/users/Cumberbatch08/repos", "events_url": "https://api.github.com/users/Cumberbatch08/events{/privacy}", "received_events_url": "https://api.github.com/users/Cumberbatch08/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-20T06:40:18Z", "updated_at": "2019-09-24T09:39:57Z", "closed_at": "2019-09-20T16:11:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "after I build the tree model, and I use the method nearest(vec, n) to get the nearest item in the candidate corpus, but I want get the similarity score.\r\nbecase, some returned results are not very near. If I have the score of every returned result, I can filter the result.\r\nIs ther any method can do this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/416", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/416/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/416/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/416/events", "html_url": "https://github.com/spotify/annoy/issues/416", "id": 496143165, "node_id": "MDU6SXNzdWU0OTYxNDMxNjU=", "number": 416, "title": "search new item but not in build model", "user": {"login": "Cumberbatch08", "id": 30173360, "node_id": "MDQ6VXNlcjMwMTczMzYw", "avatar_url": "https://avatars0.githubusercontent.com/u/30173360?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Cumberbatch08", "html_url": "https://github.com/Cumberbatch08", "followers_url": "https://api.github.com/users/Cumberbatch08/followers", "following_url": "https://api.github.com/users/Cumberbatch08/following{/other_user}", "gists_url": "https://api.github.com/users/Cumberbatch08/gists{/gist_id}", "starred_url": "https://api.github.com/users/Cumberbatch08/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Cumberbatch08/subscriptions", "organizations_url": "https://api.github.com/users/Cumberbatch08/orgs", "repos_url": "https://api.github.com/users/Cumberbatch08/repos", "events_url": "https://api.github.com/users/Cumberbatch08/events{/privacy}", "received_events_url": "https://api.github.com/users/Cumberbatch08/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-09-20T04:48:15Z", "updated_at": "2019-09-20T04:48:33Z", "closed_at": "2019-09-20T04:48:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "If use model.neighbors(item, n), we can only search the item in the train corpus.\r\nbut I thinck we can use the other method **nearest_matching**.\r\nfirst, get the new item vec.\r\nsecond, model.nearest_matching(vec, n), we can get the nearest matching item in candidate corpus.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/415", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/415/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/415/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/415/events", "html_url": "https://github.com/spotify/annoy/issues/415", "id": 495952874, "node_id": "MDU6SXNzdWU0OTU5NTI4NzQ=", "number": 415, "title": "Is it possible to save result directly to S3?", "user": {"login": "rs-bingjie", "id": 48804949, "node_id": "MDQ6VXNlcjQ4ODA0OTQ5", "avatar_url": "https://avatars0.githubusercontent.com/u/48804949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rs-bingjie", "html_url": "https://github.com/rs-bingjie", "followers_url": "https://api.github.com/users/rs-bingjie/followers", "following_url": "https://api.github.com/users/rs-bingjie/following{/other_user}", "gists_url": "https://api.github.com/users/rs-bingjie/gists{/gist_id}", "starred_url": "https://api.github.com/users/rs-bingjie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rs-bingjie/subscriptions", "organizations_url": "https://api.github.com/users/rs-bingjie/orgs", "repos_url": "https://api.github.com/users/rs-bingjie/repos", "events_url": "https://api.github.com/users/rs-bingjie/events{/privacy}", "received_events_url": "https://api.github.com/users/rs-bingjie/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-19T18:14:15Z", "updated_at": "2019-09-19T22:06:30Z", "closed_at": "2019-09-19T22:06:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "I wonder whether there's a way to save ann object directly to S3, with help of boto3 or s3fs? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/413", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/413/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/413/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/413/events", "html_url": "https://github.com/spotify/annoy/issues/413", "id": 488241297, "node_id": "MDU6SXNzdWU0ODgyNDEyOTc=", "number": 413, "title": "Return vectors of closest matches", "user": {"login": "pietz", "id": 13137132, "node_id": "MDQ6VXNlcjEzMTM3MTMy", "avatar_url": "https://avatars2.githubusercontent.com/u/13137132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pietz", "html_url": "https://github.com/pietz", "followers_url": "https://api.github.com/users/pietz/followers", "following_url": "https://api.github.com/users/pietz/following{/other_user}", "gists_url": "https://api.github.com/users/pietz/gists{/gist_id}", "starred_url": "https://api.github.com/users/pietz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pietz/subscriptions", "organizations_url": "https://api.github.com/users/pietz/orgs", "repos_url": "https://api.github.com/users/pietz/repos", "events_url": "https://api.github.com/users/pietz/events{/privacy}", "received_events_url": "https://api.github.com/users/pietz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-02T15:27:02Z", "updated_at": "2020-01-11T20:32:17Z", "closed_at": "2020-01-11T20:32:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm not only interested in the IDs of the closest results and their distances to the query but also in the vectors of the closest results. While I could keep another data array as a lookup to the original points, I was wondering if annoy has something built in to help me out.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/412", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/412/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/412/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/412/events", "html_url": "https://github.com/spotify/annoy/issues/412", "id": 487922031, "node_id": "MDU6SXNzdWU0ODc5MjIwMzE=", "number": 412, "title": "Can't install annoy, Jupyter, Anaconda, Windows 10", "user": {"login": "Schrodinger-cat-kz", "id": 48585802, "node_id": "MDQ6VXNlcjQ4NTg1ODAy", "avatar_url": "https://avatars1.githubusercontent.com/u/48585802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Schrodinger-cat-kz", "html_url": "https://github.com/Schrodinger-cat-kz", "followers_url": "https://api.github.com/users/Schrodinger-cat-kz/followers", "following_url": "https://api.github.com/users/Schrodinger-cat-kz/following{/other_user}", "gists_url": "https://api.github.com/users/Schrodinger-cat-kz/gists{/gist_id}", "starred_url": "https://api.github.com/users/Schrodinger-cat-kz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Schrodinger-cat-kz/subscriptions", "organizations_url": "https://api.github.com/users/Schrodinger-cat-kz/orgs", "repos_url": "https://api.github.com/users/Schrodinger-cat-kz/repos", "events_url": "https://api.github.com/users/Schrodinger-cat-kz/events{/privacy}", "received_events_url": "https://api.github.com/users/Schrodinger-cat-kz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-09-01T19:24:47Z", "updated_at": "2020-07-27T13:13:24Z", "closed_at": "2020-07-27T13:13:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Would like to try this library for my ongoing project. Windows 10 installation for python instructions still do not exist on official web site. How to resolve this issue?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/411", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/411/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/411/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/411/events", "html_url": "https://github.com/spotify/annoy/issues/411", "id": 487844120, "node_id": "MDU6SXNzdWU0ODc4NDQxMjA=", "number": 411, "title": "Add more items to an index which is  loaded from disk", "user": {"login": "freakeinstein", "id": 19545678, "node_id": "MDQ6VXNlcjE5NTQ1Njc4", "avatar_url": "https://avatars1.githubusercontent.com/u/19545678?v=4", "gravatar_id": "", "url": "https://api.github.com/users/freakeinstein", "html_url": "https://github.com/freakeinstein", "followers_url": "https://api.github.com/users/freakeinstein/followers", "following_url": "https://api.github.com/users/freakeinstein/following{/other_user}", "gists_url": "https://api.github.com/users/freakeinstein/gists{/gist_id}", "starred_url": "https://api.github.com/users/freakeinstein/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/freakeinstein/subscriptions", "organizations_url": "https://api.github.com/users/freakeinstein/orgs", "repos_url": "https://api.github.com/users/freakeinstein/repos", "events_url": "https://api.github.com/users/freakeinstein/events{/privacy}", "received_events_url": "https://api.github.com/users/freakeinstein/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-09-01T05:31:38Z", "updated_at": "2019-09-01T15:54:48Z", "closed_at": "2019-09-01T12:59:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "Bindings: Python\r\nVersion: annoy==1.16.0\r\n\r\nHi, I'm using Annoy in a project, which supports data backup for failure recovery. I'm taking frequent backup of Annoy index to the disk. My requirement is to load Annoy index back, when the container restarts. I have used `load()` method to do that. The problem is, when I add more items to the loaded index with `add_item()` method, Annoy is giving an error saying `Exception: You can't add an item to a loaded index`.\r\n\r\nTo overcome this, I have tried `unbuild()` and `unload()` methods independently. What I observed in each scenario are:\r\nunbuild - it is prevented for loaded indexes\r\nunload - it just get's rid of current index along with its data and creates a fresh empty index - which I didn't wanted.\r\n\r\nI can't find a possible method to add new data to loaded index. Please help.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/409", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/409/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/409/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/409/events", "html_url": "https://github.com/spotify/annoy/issues/409", "id": 484933466, "node_id": "MDU6SXNzdWU0ODQ5MzM0NjY=", "number": 409, "title": "Can't compile annoy by docker?", "user": {"login": "WEN-MIN", "id": 20558149, "node_id": "MDQ6VXNlcjIwNTU4MTQ5", "avatar_url": "https://avatars2.githubusercontent.com/u/20558149?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WEN-MIN", "html_url": "https://github.com/WEN-MIN", "followers_url": "https://api.github.com/users/WEN-MIN/followers", "following_url": "https://api.github.com/users/WEN-MIN/following{/other_user}", "gists_url": "https://api.github.com/users/WEN-MIN/gists{/gist_id}", "starred_url": "https://api.github.com/users/WEN-MIN/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WEN-MIN/subscriptions", "organizations_url": "https://api.github.com/users/WEN-MIN/orgs", "repos_url": "https://api.github.com/users/WEN-MIN/repos", "events_url": "https://api.github.com/users/WEN-MIN/events{/privacy}", "received_events_url": "https://api.github.com/users/WEN-MIN/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-25T13:46:30Z", "updated_at": "2020-01-11T20:32:41Z", "closed_at": "2020-01-11T20:32:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, thanks for release this project, it did help me a lot. But i encountered some problems when i deploy with docker. it is run well in my Mac system but have no response in docker environment\u3002every-time i start this image it will break down and have no error info. do you have meet this problem?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/408", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/408/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/408/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/408/events", "html_url": "https://github.com/spotify/annoy/issues/408", "id": 483334840, "node_id": "MDU6SXNzdWU0ODMzMzQ4NDA=", "number": 408, "title": "Input as continuous data", "user": {"login": "a11apurva", "id": 17289080, "node_id": "MDQ6VXNlcjE3Mjg5MDgw", "avatar_url": "https://avatars3.githubusercontent.com/u/17289080?v=4", "gravatar_id": "", "url": "https://api.github.com/users/a11apurva", "html_url": "https://github.com/a11apurva", "followers_url": "https://api.github.com/users/a11apurva/followers", "following_url": "https://api.github.com/users/a11apurva/following{/other_user}", "gists_url": "https://api.github.com/users/a11apurva/gists{/gist_id}", "starred_url": "https://api.github.com/users/a11apurva/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/a11apurva/subscriptions", "organizations_url": "https://api.github.com/users/a11apurva/orgs", "repos_url": "https://api.github.com/users/a11apurva/repos", "events_url": "https://api.github.com/users/a11apurva/events{/privacy}", "received_events_url": "https://api.github.com/users/a11apurva/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-21T10:23:27Z", "updated_at": "2019-08-21T12:19:17Z", "closed_at": "2019-08-21T12:19:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I understand that the algorithm needs vectorized data as input. All the examples and tutorials are using word2vec/GLOVE embeddings. \r\n\r\nBut, my dataset has 30 continuous numerical/float variables (and 50K examples). Can Annoy handle it? Or is there any wrapper or function to convert in the required format?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/406", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/406/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/406/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/406/events", "html_url": "https://github.com/spotify/annoy/issues/406", "id": 481443434, "node_id": "MDU6SXNzdWU0ODE0NDM0MzQ=", "number": 406, "title": "In circleci, pip install fail v1.16.0", "user": {"login": "aie2", "id": 45744844, "node_id": "MDQ6VXNlcjQ1NzQ0ODQ0", "avatar_url": "https://avatars3.githubusercontent.com/u/45744844?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aie2", "html_url": "https://github.com/aie2", "followers_url": "https://api.github.com/users/aie2/followers", "following_url": "https://api.github.com/users/aie2/following{/other_user}", "gists_url": "https://api.github.com/users/aie2/gists{/gist_id}", "starred_url": "https://api.github.com/users/aie2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aie2/subscriptions", "organizations_url": "https://api.github.com/users/aie2/orgs", "repos_url": "https://api.github.com/users/aie2/repos", "events_url": "https://api.github.com/users/aie2/events{/privacy}", "received_events_url": "https://api.github.com/users/aie2/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-08-16T05:05:39Z", "updated_at": "2019-10-16T16:12:46Z", "closed_at": "2019-10-16T06:24:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "In circleci(image=circleci/python:3.6.4), When I try to pip install annoy 1.16.0, it fails. \r\n![\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2019-08-16 11 09 10](https://user-images.githubusercontent.com/45744844/63144562-78400180-c02e-11e9-9d7b-a416a9a8142b.png)\r\n\r\nBut, I try to pip install annoy 1.15.2, it successes.\r\nand I try to pip install annoy 1.16.0 by local circleci build, it succeses. (I wonder)\r\nI think that it's the same problem #402 ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/404", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/404/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/404/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/404/events", "html_url": "https://github.com/spotify/annoy/issues/404", "id": 479402691, "node_id": "MDU6SXNzdWU0Nzk0MDI2OTE=", "number": 404, "title": "On Disk Build Failing v1.16.0", "user": {"login": "barrycarey", "id": 3161456, "node_id": "MDQ6VXNlcjMxNjE0NTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/3161456?v=4", "gravatar_id": "", "url": "https://api.github.com/users/barrycarey", "html_url": "https://github.com/barrycarey", "followers_url": "https://api.github.com/users/barrycarey/followers", "following_url": "https://api.github.com/users/barrycarey/following{/other_user}", "gists_url": "https://api.github.com/users/barrycarey/gists{/gist_id}", "starred_url": "https://api.github.com/users/barrycarey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/barrycarey/subscriptions", "organizations_url": "https://api.github.com/users/barrycarey/orgs", "repos_url": "https://api.github.com/users/barrycarey/repos", "events_url": "https://api.github.com/users/barrycarey/events{/privacy}", "received_events_url": "https://api.github.com/users/barrycarey/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2019-08-11T19:31:40Z", "updated_at": "2020-07-27T17:17:31Z", "closed_at": "2020-07-27T13:12:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "The latest version fails to build the index on disk. \r\n\r\nBuilding the index results in \r\n\r\n`Error truncating file: Input/output error`\r\n\r\nSame code works on 1.15.2. \r\n\r\nPython 3.7 Windows 10", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/402", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/402/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/402/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/402/events", "html_url": "https://github.com/spotify/annoy/issues/402", "id": 471342422, "node_id": "MDU6SXNzdWU0NzEzNDI0MjI=", "number": 402, "title": "Can't build with gcc 5 where __AVX512F__ is defined", "user": {"login": "chyzzqo2", "id": 52714809, "node_id": "MDQ6VXNlcjUyNzE0ODA5", "avatar_url": "https://avatars3.githubusercontent.com/u/52714809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chyzzqo2", "html_url": "https://github.com/chyzzqo2", "followers_url": "https://api.github.com/users/chyzzqo2/followers", "following_url": "https://api.github.com/users/chyzzqo2/following{/other_user}", "gists_url": "https://api.github.com/users/chyzzqo2/gists{/gist_id}", "starred_url": "https://api.github.com/users/chyzzqo2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chyzzqo2/subscriptions", "organizations_url": "https://api.github.com/users/chyzzqo2/orgs", "repos_url": "https://api.github.com/users/chyzzqo2/repos", "events_url": "https://api.github.com/users/chyzzqo2/events{/privacy}", "received_events_url": "https://api.github.com/users/chyzzqo2/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-07-22T21:21:18Z", "updated_at": "2019-10-11T14:59:13Z", "closed_at": "2019-10-11T14:59:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Seems like the `_mm512_*` functions used in the `#ifdef USE_AVX512` block are only present when using gcc 7+. on 5 it fails with errors like \r\n\r\n``` src/annoylib.h: In function \u2018T {anonymous}::euclidean_distance(const T*, const T*, int) [with T = float]\u2019:\r\nsrc/annoylib.h:304:36: error: \u2018_mm512_reduce_add_ps\u2019 was not declared in this scope\r\nresult = _mm512_reduce_add_ps(d);```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/401", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/401/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/401/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/401/events", "html_url": "https://github.com/spotify/annoy/issues/401", "id": 467744552, "node_id": "MDU6SXNzdWU0Njc3NDQ1NTI=", "number": 401, "title": "1.16.0 release for Linux broken", "user": {"login": "ixxie", "id": 20320695, "node_id": "MDQ6VXNlcjIwMzIwNjk1", "avatar_url": "https://avatars0.githubusercontent.com/u/20320695?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ixxie", "html_url": "https://github.com/ixxie", "followers_url": "https://api.github.com/users/ixxie/followers", "following_url": "https://api.github.com/users/ixxie/following{/other_user}", "gists_url": "https://api.github.com/users/ixxie/gists{/gist_id}", "starred_url": "https://api.github.com/users/ixxie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ixxie/subscriptions", "organizations_url": "https://api.github.com/users/ixxie/orgs", "repos_url": "https://api.github.com/users/ixxie/repos", "events_url": "https://api.github.com/users/ixxie/events{/privacy}", "received_events_url": "https://api.github.com/users/ixxie/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-13T17:09:23Z", "updated_at": "2019-07-21T07:35:13Z", "closed_at": "2019-07-21T07:35:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "It seems the 1.16.0 release for Linux is broken; it seems a MacOSX build has been pushed instead of the Linux one.\r\n\r\nhttps://pypi.org/project/annoy/1.16.0/#files", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/398", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/398/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/398/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/398/events", "html_url": "https://github.com/spotify/annoy/issues/398", "id": 464896699, "node_id": "MDU6SXNzdWU0NjQ4OTY2OTk=", "number": 398, "title": "Adding items to existing index causes Segmentation Fault", "user": {"login": "Jotschi", "id": 326605, "node_id": "MDQ6VXNlcjMyNjYwNQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/326605?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jotschi", "html_url": "https://github.com/Jotschi", "followers_url": "https://api.github.com/users/Jotschi/followers", "following_url": "https://api.github.com/users/Jotschi/following{/other_user}", "gists_url": "https://api.github.com/users/Jotschi/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jotschi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jotschi/subscriptions", "organizations_url": "https://api.github.com/users/Jotschi/orgs", "repos_url": "https://api.github.com/users/Jotschi/repos", "events_url": "https://api.github.com/users/Jotschi/events{/privacy}", "received_events_url": "https://api.github.com/users/Jotschi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-07-06T22:52:57Z", "updated_at": "2019-11-11T12:57:16Z", "closed_at": "2019-11-11T12:57:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Example:\r\n```\r\n#!/usr/bin/env python3\r\n\r\nfrom annoy import AnnoyIndex\r\nimport random\r\nimport os  \r\n\r\nindexName = \"index.ann\"\r\nVECTOR_LENGTH = 32\r\n\r\ni = 1\r\nu = AnnoyIndex(VECTOR_LENGTH, metric='hamming')\r\n\r\nif os.path.exists(indexName):\r\n  print(\"Loading index \" + indexName)\r\n  u.load(indexName)  \r\n  i=i+1\r\n\r\nv = [random.gauss(0, 1) for z in range(VECTOR_LENGTH)]\r\nprint(\"Adding item \" + str(i))\r\nu.add_item(i, v)\r\n\r\n\r\nprint(\"Building tree\")\r\nu.build(10)\r\nprint(\"Saving index\")\r\nu.save(indexName)\r\n\r\nprint(u.get_nns_by_item(0, 1000))\r\n```\r\n\r\n`rm index.ann ; ./db.py ; echo -e  \"\\nSecond:\" ; ./db.py`\r\n\r\nCalling the program the first time works just fine. However when calling `u.add_item` on the loaded index a `Segmentation fault` is observed.\r\n\r\nOS: Debian Linux\r\nPython: 3.7.3-2\r\nAnnoy: 1.15.2\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/395", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/395/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/395/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/395/events", "html_url": "https://github.com/spotify/annoy/issues/395", "id": 459805157, "node_id": "MDU6SXNzdWU0NTk4MDUxNTc=", "number": 395, "title": "Can I get nearest vector for each class?", "user": {"login": "tienthegainz", "id": 34891363, "node_id": "MDQ6VXNlcjM0ODkxMzYz", "avatar_url": "https://avatars3.githubusercontent.com/u/34891363?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tienthegainz", "html_url": "https://github.com/tienthegainz", "followers_url": "https://api.github.com/users/tienthegainz/followers", "following_url": "https://api.github.com/users/tienthegainz/following{/other_user}", "gists_url": "https://api.github.com/users/tienthegainz/gists{/gist_id}", "starred_url": "https://api.github.com/users/tienthegainz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tienthegainz/subscriptions", "organizations_url": "https://api.github.com/users/tienthegainz/orgs", "repos_url": "https://api.github.com/users/tienthegainz/repos", "events_url": "https://api.github.com/users/tienthegainz/events{/privacy}", "received_events_url": "https://api.github.com/users/tienthegainz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-24T10:09:08Z", "updated_at": "2019-07-02T23:20:14Z", "closed_at": "2019-07-02T23:20:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "Using `a.get_nns_by_vector`, I can get nearest vector to my vector.\r\nBut I have, for example, 3 class: A, B, C and I want to return nearest vectors with my vector from each class to compare. Is there anyway to do that?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/394", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/394/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/394/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/394/events", "html_url": "https://github.com/spotify/annoy/issues/394", "id": 459685446, "node_id": "MDU6SXNzdWU0NTk2ODU0NDY=", "number": 394, "title": "Incorrect AnnIndex load/search nn triggers Segmentation Fault", "user": {"login": "midneet", "id": 11956251, "node_id": "MDQ6VXNlcjExOTU2MjUx", "avatar_url": "https://avatars3.githubusercontent.com/u/11956251?v=4", "gravatar_id": "", "url": "https://api.github.com/users/midneet", "html_url": "https://github.com/midneet", "followers_url": "https://api.github.com/users/midneet/followers", "following_url": "https://api.github.com/users/midneet/following{/other_user}", "gists_url": "https://api.github.com/users/midneet/gists{/gist_id}", "starred_url": "https://api.github.com/users/midneet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/midneet/subscriptions", "organizations_url": "https://api.github.com/users/midneet/orgs", "repos_url": "https://api.github.com/users/midneet/repos", "events_url": "https://api.github.com/users/midneet/events{/privacy}", "received_events_url": "https://api.github.com/users/midneet/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-06-24T04:46:15Z", "updated_at": "2019-07-07T12:11:13Z", "closed_at": "2019-07-07T12:11:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI'm not sure if this has been issued or not. I found the error message is kind of misleading when I load incorrect Ann index to do get_nns_by_vectors\r\nhere is what I was doing:\r\n\r\nt = AnnIndex(4096, metric='angular')\r\nt.load('A.ann') <-- This ann index is actually of dimension=768 when I build this index, but no error occurs\r\ntest = np.ones(4096)\r\nt.get_nns_by_vector(test, n=3) <-- this trigger Segmentation fault with no other error message\r\n_____________________\r\nHowever, when I tried more times with this code, it sometimes returns results of \"two\" nns, which is also not the number of nns I want.\r\n\r\nI figure out my problem myself when I notice I just load the wrong index, but I think the error message of Segmentation Fault didn't reveal the actual wrong place of codes. I'm wondering if you would mind correcting such error check? thank you", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/392", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/392/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/392/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/392/events", "html_url": "https://github.com/spotify/annoy/issues/392", "id": 451559888, "node_id": "MDU6SXNzdWU0NTE1NTk4ODg=", "number": 392, "title": "Is annoy an implementation of LSH Forest algorithm", "user": {"login": "jpainam", "id": 1701705, "node_id": "MDQ6VXNlcjE3MDE3MDU=", "avatar_url": "https://avatars2.githubusercontent.com/u/1701705?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpainam", "html_url": "https://github.com/jpainam", "followers_url": "https://api.github.com/users/jpainam/followers", "following_url": "https://api.github.com/users/jpainam/following{/other_user}", "gists_url": "https://api.github.com/users/jpainam/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpainam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpainam/subscriptions", "organizations_url": "https://api.github.com/users/jpainam/orgs", "repos_url": "https://api.github.com/users/jpainam/repos", "events_url": "https://api.github.com/users/jpainam/events{/privacy}", "received_events_url": "https://api.github.com/users/jpainam/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-03T15:51:31Z", "updated_at": "2019-06-03T16:56:42Z", "closed_at": "2019-06-03T16:56:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I have some difficulties understanding LSH Forest and I would like to know if this software Annoy gives an implementation of LSH Forest algorithm?\r\nThank you.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/391", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/391/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/391/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/391/events", "html_url": "https://github.com/spotify/annoy/issues/391", "id": 449529559, "node_id": "MDU6SXNzdWU0NDk1Mjk1NTk=", "number": 391, "title": "How to get nearest neighours according to distance threshold?", "user": {"login": "liwt31", "id": 22628546, "node_id": "MDQ6VXNlcjIyNjI4NTQ2", "avatar_url": "https://avatars3.githubusercontent.com/u/22628546?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liwt31", "html_url": "https://github.com/liwt31", "followers_url": "https://api.github.com/users/liwt31/followers", "following_url": "https://api.github.com/users/liwt31/following{/other_user}", "gists_url": "https://api.github.com/users/liwt31/gists{/gist_id}", "starred_url": "https://api.github.com/users/liwt31/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liwt31/subscriptions", "organizations_url": "https://api.github.com/users/liwt31/orgs", "repos_url": "https://api.github.com/users/liwt31/repos", "events_url": "https://api.github.com/users/liwt31/events{/privacy}", "received_events_url": "https://api.github.com/users/liwt31/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-29T00:09:09Z", "updated_at": "2019-05-29T00:38:59Z", "closed_at": "2019-05-29T00:38:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there any API like \r\n```\r\na.get_nns_by_item(i, threshold, search_k=-1, include_distances=False)\r\n```\r\nthat returns all neighours of `i` whose distances to `i` are smaller than `threshold`?\r\nIf not so, are there any suggestions on possible workarounds?\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/390", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/390/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/390/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/390/events", "html_url": "https://github.com/spotify/annoy/issues/390", "id": 449410089, "node_id": "MDU6SXNzdWU0NDk0MTAwODk=", "number": 390, "title": "a.get_nns_by_item() returning distance greater than 1", "user": {"login": "vrk7bp", "id": 3013317, "node_id": "MDQ6VXNlcjMwMTMzMTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/3013317?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vrk7bp", "html_url": "https://github.com/vrk7bp", "followers_url": "https://api.github.com/users/vrk7bp/followers", "following_url": "https://api.github.com/users/vrk7bp/following{/other_user}", "gists_url": "https://api.github.com/users/vrk7bp/gists{/gist_id}", "starred_url": "https://api.github.com/users/vrk7bp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vrk7bp/subscriptions", "organizations_url": "https://api.github.com/users/vrk7bp/orgs", "repos_url": "https://api.github.com/users/vrk7bp/repos", "events_url": "https://api.github.com/users/vrk7bp/events{/privacy}", "received_events_url": "https://api.github.com/users/vrk7bp/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-28T18:18:08Z", "updated_at": "2019-05-28T18:48:24Z", "closed_at": "2019-05-28T18:48:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I run a.get_nns_by_item(i, n, search_k=-1, include_distances=True) with cosine similarity, I'm getting distances that are larger than 1 (things like 1.11, 1.08). In general the results with the largest distance tend to be the most accurate results, but my understanding of cosine similarity is that the values should be between -1 and 1.\r\n\r\nIs this a downstream result of approximations being made? And if so, is it still fair to assume that the larger the distance the more accurate the results?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/389", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/389/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/389/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/389/events", "html_url": "https://github.com/spotify/annoy/issues/389", "id": 448277171, "node_id": "MDU6SXNzdWU0NDgyNzcxNzE=", "number": 389, "title": "Add items without copying", "user": {"login": "msmk0", "id": 6637284, "node_id": "MDQ6VXNlcjY2MzcyODQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/6637284?v=4", "gravatar_id": "", "url": "https://api.github.com/users/msmk0", "html_url": "https://github.com/msmk0", "followers_url": "https://api.github.com/users/msmk0/followers", "following_url": "https://api.github.com/users/msmk0/following{/other_user}", "gists_url": "https://api.github.com/users/msmk0/gists{/gist_id}", "starred_url": "https://api.github.com/users/msmk0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/msmk0/subscriptions", "organizations_url": "https://api.github.com/users/msmk0/orgs", "repos_url": "https://api.github.com/users/msmk0/repos", "events_url": "https://api.github.com/users/msmk0/events{/privacy}", "received_events_url": "https://api.github.com/users/msmk0/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-24T17:28:07Z", "updated_at": "2019-05-25T15:50:23Z", "closed_at": "2019-05-25T15:50:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is more of a question than an issue and relates to the C++ implementation.\r\n\r\nFrom my understanding of the code, item elements/weights are copied when using `.add_item(...)`. In our application we already have all items stored in memory. Would it be possible to avoid the copy and use the elements directly by reference/pointer? If so, where in the library would this change have to be implemented?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/388", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/388/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/388/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/388/events", "html_url": "https://github.com/spotify/annoy/issues/388", "id": 445545830, "node_id": "MDU6SXNzdWU0NDU1NDU4MzA=", "number": 388, "title": "Rewrite existing file issue", "user": {"login": "shmakovofficial", "id": 32734480, "node_id": "MDQ6VXNlcjMyNzM0NDgw", "avatar_url": "https://avatars1.githubusercontent.com/u/32734480?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shmakovofficial", "html_url": "https://github.com/shmakovofficial", "followers_url": "https://api.github.com/users/shmakovofficial/followers", "following_url": "https://api.github.com/users/shmakovofficial/following{/other_user}", "gists_url": "https://api.github.com/users/shmakovofficial/gists{/gist_id}", "starred_url": "https://api.github.com/users/shmakovofficial/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shmakovofficial/subscriptions", "organizations_url": "https://api.github.com/users/shmakovofficial/orgs", "repos_url": "https://api.github.com/users/shmakovofficial/repos", "events_url": "https://api.github.com/users/shmakovofficial/events{/privacy}", "received_events_url": "https://api.github.com/users/shmakovofficial/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 21, "created_at": "2019-05-17T17:34:37Z", "updated_at": "2019-12-27T14:21:33Z", "closed_at": "2019-12-18T13:41:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello! I'm using annoy 1.15.2 on python 3.7.3. Here is the issue:\r\n```\r\n>>>from annoy import AnnoyIndex\r\n>>>a=AnnoyIndex(1)\r\n>>>a.add_item(1,[1])\r\n>>>a.add_item(2,[2])\r\n>>>a.build(1)\r\nTrue\r\n>>>a.save(\"temp.ann\")\r\nTrue\r\n>>>b=AnnoyIndex(1)\r\n>>>b.add_item(3,[3])\r\n>>>b.add_item(4,[4])\r\n>>>b.build(1)\r\nTrue\r\n>>>b.save(\"temp.ann\")\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\nOSError: [Errno 22] Invalid argument\r\n```\r\nCould you tell why I get the error?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/385", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/385/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/385/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/385/events", "html_url": "https://github.com/spotify/annoy/issues/385", "id": 437853945, "node_id": "MDU6SXNzdWU0Mzc4NTM5NDU=", "number": 385, "title": "deploy", "user": {"login": "analyticsbot", "id": 7417790, "node_id": "MDQ6VXNlcjc0MTc3OTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/7417790?v=4", "gravatar_id": "", "url": "https://api.github.com/users/analyticsbot", "html_url": "https://github.com/analyticsbot", "followers_url": "https://api.github.com/users/analyticsbot/followers", "following_url": "https://api.github.com/users/analyticsbot/following{/other_user}", "gists_url": "https://api.github.com/users/analyticsbot/gists{/gist_id}", "starred_url": "https://api.github.com/users/analyticsbot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/analyticsbot/subscriptions", "organizations_url": "https://api.github.com/users/analyticsbot/orgs", "repos_url": "https://api.github.com/users/analyticsbot/repos", "events_url": "https://api.github.com/users/analyticsbot/events{/privacy}", "received_events_url": "https://api.github.com/users/analyticsbot/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-04-26T21:32:27Z", "updated_at": "2019-04-26T22:10:38Z", "closed_at": "2019-04-26T22:10:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/384", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/384/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/384/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/384/events", "html_url": "https://github.com/spotify/annoy/issues/384", "id": 432455869, "node_id": "MDU6SXNzdWU0MzI0NTU4Njk=", "number": 384, "title": "How can I reduced response time ", "user": {"login": "young2010", "id": 9781541, "node_id": "MDQ6VXNlcjk3ODE1NDE=", "avatar_url": "https://avatars0.githubusercontent.com/u/9781541?v=4", "gravatar_id": "", "url": "https://api.github.com/users/young2010", "html_url": "https://github.com/young2010", "followers_url": "https://api.github.com/users/young2010/followers", "following_url": "https://api.github.com/users/young2010/following{/other_user}", "gists_url": "https://api.github.com/users/young2010/gists{/gist_id}", "starred_url": "https://api.github.com/users/young2010/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/young2010/subscriptions", "organizations_url": "https://api.github.com/users/young2010/orgs", "repos_url": "https://api.github.com/users/young2010/repos", "events_url": "https://api.github.com/users/young2010/events{/privacy}", "received_events_url": "https://api.github.com/users/young2010/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-04-12T08:48:57Z", "updated_at": "2020-01-27T13:40:53Z", "closed_at": "2019-04-12T14:09:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi I have about 800million arrays , each of dimension 200, builds a forest of 200 tree, \r\nI load trees file in a lab which have 8CPUS and 60 memory,\r\nthen I search some arrays take about 5000+ millisecond first time(search_k = -1)\r\nHow can I reduced response time ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/382", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/382/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/382/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/382/events", "html_url": "https://github.com/spotify/annoy/issues/382", "id": 431766730, "node_id": "MDU6SXNzdWU0MzE3NjY3MzA=", "number": 382, "title": "search_k documentation is inconsistent", "user": {"login": "txntxn", "id": 8398528, "node_id": "MDQ6VXNlcjgzOTg1Mjg=", "avatar_url": "https://avatars2.githubusercontent.com/u/8398528?v=4", "gravatar_id": "", "url": "https://api.github.com/users/txntxn", "html_url": "https://github.com/txntxn", "followers_url": "https://api.github.com/users/txntxn/followers", "following_url": "https://api.github.com/users/txntxn/following{/other_user}", "gists_url": "https://api.github.com/users/txntxn/gists{/gist_id}", "starred_url": "https://api.github.com/users/txntxn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/txntxn/subscriptions", "organizations_url": "https://api.github.com/users/txntxn/orgs", "repos_url": "https://api.github.com/users/txntxn/repos", "events_url": "https://api.github.com/users/txntxn/events{/privacy}", "received_events_url": "https://api.github.com/users/txntxn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-10T23:36:06Z", "updated_at": "2020-08-05T16:33:54Z", "closed_at": "2020-08-05T16:33:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "The documentation for `search_k` is inconsistent.\r\n\r\nIn some places, it says: \"search_k nodes which defaults to n_trees * n if not provided\"\r\n\r\nIn other places, it says: \"If search_k is not provided, it will default to n * n_trees * D where n is the number of approximate nearest neighbors and D is a constant depending on the metric.\"\r\n\r\nWhich is it?\r\n\r\nAnd if it is `D`, could you enumerate the different `D` values for each metric? I searched the code for a few minutes but I was unable to determine what D is.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/379", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/379/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/379/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/379/events", "html_url": "https://github.com/spotify/annoy/issues/379", "id": 430524779, "node_id": "MDU6SXNzdWU0MzA1MjQ3Nzk=", "number": 379, "title": "save() ignores write failures, causing corrupt annoy trees", "user": {"login": "keithmcneill", "id": 1558085, "node_id": "MDQ6VXNlcjE1NTgwODU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1558085?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keithmcneill", "html_url": "https://github.com/keithmcneill", "followers_url": "https://api.github.com/users/keithmcneill/followers", "following_url": "https://api.github.com/users/keithmcneill/following{/other_user}", "gists_url": "https://api.github.com/users/keithmcneill/gists{/gist_id}", "starred_url": "https://api.github.com/users/keithmcneill/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keithmcneill/subscriptions", "organizations_url": "https://api.github.com/users/keithmcneill/orgs", "repos_url": "https://api.github.com/users/keithmcneill/repos", "events_url": "https://api.github.com/users/keithmcneill/events{/privacy}", "received_events_url": "https://api.github.com/users/keithmcneill/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-08T15:45:44Z", "updated_at": "2019-04-08T22:46:00Z", "closed_at": "2019-04-08T22:45:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "In particular if the disk is full, the annoy tree will be silently truncated.\r\n\r\nWorking on a fix on a fork.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/378", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/378/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/378/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/378/events", "html_url": "https://github.com/spotify/annoy/issues/378", "id": 430098505, "node_id": "MDU6SXNzdWU0MzAwOTg1MDU=", "number": 378, "title": "save/load problem: \"found 0 roots with degree -1\"", "user": {"login": "jlmelville", "id": 1936393, "node_id": "MDQ6VXNlcjE5MzYzOTM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1936393?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlmelville", "html_url": "https://github.com/jlmelville", "followers_url": "https://api.github.com/users/jlmelville/followers", "following_url": "https://api.github.com/users/jlmelville/following{/other_user}", "gists_url": "https://api.github.com/users/jlmelville/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlmelville/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlmelville/subscriptions", "organizations_url": "https://api.github.com/users/jlmelville/orgs", "repos_url": "https://api.github.com/users/jlmelville/repos", "events_url": "https://api.github.com/users/jlmelville/events{/privacy}", "received_events_url": "https://api.github.com/users/jlmelville/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-04-07T02:53:01Z", "updated_at": "2020-03-09T02:49:14Z", "closed_at": "2020-03-09T02:49:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "This seems related to #368 or #348 but I can't solve the problem by specifying the `metric` before loading. The problem is that after saving, I am unable to reload the index successfully. The load method notes `found 0 roots with degree -1`.\r\n\r\nUnfortunately, I have not been able to reproduce this with a small dataset. I am using the [small NORB dataset](https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/) which is very high dimensional (> 10,000 columns). I realize that this is a poor use case with Annoy, although Annoy is actually very accurate with the parameters I use (it's just very slow).  Assuming you can get hold of the small NORB dataset (see below), the error is triggered in quite a straightforward fashion, but only after building an index based on nearly 29,000 observations:\r\n\r\n```python\r\nfrom annoy import AnnoyIndex\r\n\r\nndim = 18432\r\nann = AnnoyIndex(ndim, metric=\"euclidean\")\r\nfor i in range(28852):\r\n    ann.add_item(i, norb_mat[i, :])\r\n\r\nann.verbose(True)\r\nann.build(50)\r\n\r\n# this works fine\r\nprint(ann.get_nns_by_item(0, 15, search_k=1500))\r\nann.save(\"norb29k.test\")\r\n\r\nann2 = AnnoyIndex(ndim, metric=\"euclidean\")\r\n# this doesn't find any data\r\nann2.load(\"norb29k.test\")\r\nprint(ann2.get_nns_by_item(0, 15, search_k=1500))\r\n```\r\n\r\nTo get hold of the NORB dataset, the easiest way in Python is to:\r\n\r\n* install numpy, matplotlib, scipy, tqdm\r\n* use the class defined in https://github.com/ndrplz/small_norb \r\n* download and unzip the six small NORB files into a single directory\r\n\r\nthen run:\r\n\r\n```python\r\nnorb = SmallNORBDataset(dataset_root=\"path/to/the/small/norb/directory\")\r\nnorb_all = norb.data['train'] + norb.data['test']\r\nnorb_mat = np.array([np.hstack((obs.image_lt.reshape((96 * 96, )), obs.image_rt.reshape((96 * 96, ))))  for obs in norb_all])\r\n```\r\n\r\nThe problem manifests after adding item 28852. Before that, this code saves and loads without problem. There doesn't seem to be anything special about that vector; if I skip it and use 28853 instead, the problem still manifests.\r\n\r\nThe problem also only manifests after setting `n_trees=50`; below that value, it works fine. But it's not a straightforward memory issue either, because I can store and use the index for the entire small NORB dataset (48,600 items) with `n_trees=50`, as long as I don't attempt to save it to disk and reload it. \r\n\r\nI am using Windows 10 with Python 3.7, but I originally saw the problem with RcppAnnoy, which binds with the C++ code directly, so it's not a Python problem. I apologize for not providing a more easily reproducible example.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/377", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/377/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/377/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/377/events", "html_url": "https://github.com/spotify/annoy/issues/377", "id": 427637348, "node_id": "MDU6SXNzdWU0Mjc2MzczNDg=", "number": 377, "title": "Annoy Index mapping", "user": {"login": "loretoparisi", "id": 163333, "node_id": "MDQ6VXNlcjE2MzMzMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/163333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/loretoparisi", "html_url": "https://github.com/loretoparisi", "followers_url": "https://api.github.com/users/loretoparisi/followers", "following_url": "https://api.github.com/users/loretoparisi/following{/other_user}", "gists_url": "https://api.github.com/users/loretoparisi/gists{/gist_id}", "starred_url": "https://api.github.com/users/loretoparisi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/loretoparisi/subscriptions", "organizations_url": "https://api.github.com/users/loretoparisi/orgs", "repos_url": "https://api.github.com/users/loretoparisi/repos", "events_url": "https://api.github.com/users/loretoparisi/events{/privacy}", "received_events_url": "https://api.github.com/users/loretoparisi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-04-01T10:51:13Z", "updated_at": "2019-04-01T14:38:00Z", "closed_at": "2019-04-01T13:53:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Which is the best practice to map the annoy sequential index to the item identifiers?\r\nAssumed that for a given dataset of items of fixed length, let's say 10K items I would have indexes ranging from 0 to 9,999, and I have update my index every day with new items.  Assumed I have a daily diff of 100 items, I will rebuild the new index with +100 keys every day, that means that at some point my `max(id)` will be filled out and then I would need to add 100 new keys at every update. This means that the index keys mapping (from item id to annoy integer id) must be dynamic and must be stored somewhere else than Annoy itself, causing a problem of synchronizing the mapping to the actual index keys (the ones got by the `status` api). So in this case, which is the best approach that honor the Annoy api?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/376", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/376/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/376/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/376/events", "html_url": "https://github.com/spotify/annoy/issues/376", "id": 427086809, "node_id": "MDU6SXNzdWU0MjcwODY4MDk=", "number": 376, "title": "First lookup for an ID is slow", "user": {"login": "scottbreyfogle", "id": 2302617, "node_id": "MDQ6VXNlcjIzMDI2MTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/2302617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scottbreyfogle", "html_url": "https://github.com/scottbreyfogle", "followers_url": "https://api.github.com/users/scottbreyfogle/followers", "following_url": "https://api.github.com/users/scottbreyfogle/following{/other_user}", "gists_url": "https://api.github.com/users/scottbreyfogle/gists{/gist_id}", "starred_url": "https://api.github.com/users/scottbreyfogle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scottbreyfogle/subscriptions", "organizations_url": "https://api.github.com/users/scottbreyfogle/orgs", "repos_url": "https://api.github.com/users/scottbreyfogle/repos", "events_url": "https://api.github.com/users/scottbreyfogle/events{/privacy}", "received_events_url": "https://api.github.com/users/scottbreyfogle/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 23, "created_at": "2019-03-29T17:03:19Z", "updated_at": "2020-03-12T21:16:59Z", "closed_at": "2019-04-03T19:51:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm seeing a problem when using the library where calling get_nns_by_vector is very slow on first execution for a given value (15s for an index with ~2m vectors of length 200), and then much faster in subsequent calls (subsecond). I've also seen similar behavior in get_item_vector, but I'm not sure if it's related. I've set prefault to true when loading the index from disk.\r\n\r\nThe strangest part is that it only occurs on some computers, and I'm not able to repro on my local machine to get details on what is going on. If I load the same index on my computer, the execution time is always subsecond. I'm continuing to look into this to see if I can find a reliable method of reproducing.\r\n\r\nHas anyone seen performance patterns like this? Do you have thoughts on what the problem may be? I'm not sure that it's Annoy specifically, but would be good to know if it is.\r\n\r\nMy current thoughts are that it has to do with the MMAPing and that the index is not all saved into RAM and the disk lookups are slow on some machines. I'm not very familiar with MMAPing and would appreciate outside thoughts on whether that's reasonable and/or how to verify if it's the problem.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/375", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/375/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/375/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/375/events", "html_url": "https://github.com/spotify/annoy/issues/375", "id": 427071222, "node_id": "MDU6SXNzdWU0MjcwNzEyMjI=", "number": 375, "title": "[Question] About Sparse Vectors", "user": {"login": "loretoparisi", "id": 163333, "node_id": "MDQ6VXNlcjE2MzMzMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/163333?v=4", "gravatar_id": "", "url": "https://api.github.com/users/loretoparisi", "html_url": "https://github.com/loretoparisi", "followers_url": "https://api.github.com/users/loretoparisi/followers", "following_url": "https://api.github.com/users/loretoparisi/following{/other_user}", "gists_url": "https://api.github.com/users/loretoparisi/gists{/gist_id}", "starred_url": "https://api.github.com/users/loretoparisi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/loretoparisi/subscriptions", "organizations_url": "https://api.github.com/users/loretoparisi/orgs", "repos_url": "https://api.github.com/users/loretoparisi/repos", "events_url": "https://api.github.com/users/loretoparisi/events{/privacy}", "received_events_url": "https://api.github.com/users/loretoparisi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-29T16:26:27Z", "updated_at": "2019-03-29T16:51:05Z", "closed_at": "2019-03-29T16:51:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "We have a sparse Index with ~1M columns tensor, and assumed we measure the `sparsity` like\r\n\r\n```python\r\nsparsity = 1.0 - ( count_nonzero(A) / float(A.size) )\r\n```\r\n\r\nin our data the sparsity it's about ~ .99, i.e its density is ~ .1.\r\nHow address data sparsity in Annoy? Shall we try a dimensionality reduction (SVD, PCA, etc.) before feeding annoy with sparse data?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/374", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/374/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/374/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/374/events", "html_url": "https://github.com/spotify/annoy/issues/374", "id": 425556344, "node_id": "MDU6SXNzdWU0MjU1NTYzNDQ=", "number": 374, "title": "Get all vectors at once", "user": {"login": "shoegazerstella", "id": 22822597, "node_id": "MDQ6VXNlcjIyODIyNTk3", "avatar_url": "https://avatars2.githubusercontent.com/u/22822597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoegazerstella", "html_url": "https://github.com/shoegazerstella", "followers_url": "https://api.github.com/users/shoegazerstella/followers", "following_url": "https://api.github.com/users/shoegazerstella/following{/other_user}", "gists_url": "https://api.github.com/users/shoegazerstella/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoegazerstella/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoegazerstella/subscriptions", "organizations_url": "https://api.github.com/users/shoegazerstella/orgs", "repos_url": "https://api.github.com/users/shoegazerstella/repos", "events_url": "https://api.github.com/users/shoegazerstella/events{/privacy}", "received_events_url": "https://api.github.com/users/shoegazerstella/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-26T17:36:04Z", "updated_at": "2019-03-28T13:47:28Z", "closed_at": "2019-03-28T13:47:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello and thanks a lot for making this tool public!\r\n\r\nIs there a fast way to get all vectors at once from an index?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/373", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/373/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/373/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/373/events", "html_url": "https://github.com/spotify/annoy/issues/373", "id": 422532996, "node_id": "MDU6SXNzdWU0MjI1MzI5OTY=", "number": 373, "title": "Can I get node information of the tree?", "user": {"login": "liqima", "id": 31846112, "node_id": "MDQ6VXNlcjMxODQ2MTEy", "avatar_url": "https://avatars2.githubusercontent.com/u/31846112?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liqima", "html_url": "https://github.com/liqima", "followers_url": "https://api.github.com/users/liqima/followers", "following_url": "https://api.github.com/users/liqima/following{/other_user}", "gists_url": "https://api.github.com/users/liqima/gists{/gist_id}", "starred_url": "https://api.github.com/users/liqima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liqima/subscriptions", "organizations_url": "https://api.github.com/users/liqima/orgs", "repos_url": "https://api.github.com/users/liqima/repos", "events_url": "https://api.github.com/users/liqima/events{/privacy}", "received_events_url": "https://api.github.com/users/liqima/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-19T03:57:05Z", "updated_at": "2019-03-19T13:31:27Z", "closed_at": "2019-03-19T13:31:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, very thanks for your share. But I have two confused questions:\r\nSuppose I add some items and build one tree,\r\n1.  Can I get node information of the tree? like node_list = [root, node1, node2 ...] with inorder or postorder, or node_list = [leafnode1, leafnode2, ...];\r\n2.  For a query vector, can I get the \"path\" when searching, like query_path = [root, node1, node19, node30, leafnode50].\r\n\r\nI do this because I want to build a code_book like [node1, node2, node3, ...], and encode my query vectors to {query1: node1, query2: node2 ...}\r\nThanks for your attention.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/372", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/372/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/372/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/372/events", "html_url": "https://github.com/spotify/annoy/issues/372", "id": 422236302, "node_id": "MDU6SXNzdWU0MjIyMzYzMDI=", "number": 372, "title": "centos 6 + python 2.7 can't use metric='dot'", "user": {"login": "YuxiangLu", "id": 20625936, "node_id": "MDQ6VXNlcjIwNjI1OTM2", "avatar_url": "https://avatars3.githubusercontent.com/u/20625936?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YuxiangLu", "html_url": "https://github.com/YuxiangLu", "followers_url": "https://api.github.com/users/YuxiangLu/followers", "following_url": "https://api.github.com/users/YuxiangLu/following{/other_user}", "gists_url": "https://api.github.com/users/YuxiangLu/gists{/gist_id}", "starred_url": "https://api.github.com/users/YuxiangLu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YuxiangLu/subscriptions", "organizations_url": "https://api.github.com/users/YuxiangLu/orgs", "repos_url": "https://api.github.com/users/YuxiangLu/repos", "events_url": "https://api.github.com/users/YuxiangLu/events{/privacy}", "received_events_url": "https://api.github.com/users/YuxiangLu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-18T14:05:10Z", "updated_at": "2019-03-20T04:04:45Z", "closed_at": "2019-03-20T04:04:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/371", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/371/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/371/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/371/events", "html_url": "https://github.com/spotify/annoy/issues/371", "id": 421454425, "node_id": "MDU6SXNzdWU0MjE0NTQ0MjU=", "number": 371, "title": "How to get the clustering center coordinates?", "user": {"login": "liqima", "id": 31846112, "node_id": "MDQ6VXNlcjMxODQ2MTEy", "avatar_url": "https://avatars2.githubusercontent.com/u/31846112?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liqima", "html_url": "https://github.com/liqima", "followers_url": "https://api.github.com/users/liqima/followers", "following_url": "https://api.github.com/users/liqima/following{/other_user}", "gists_url": "https://api.github.com/users/liqima/gists{/gist_id}", "starred_url": "https://api.github.com/users/liqima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liqima/subscriptions", "organizations_url": "https://api.github.com/users/liqima/orgs", "repos_url": "https://api.github.com/users/liqima/repos", "events_url": "https://api.github.com/users/liqima/events{/privacy}", "received_events_url": "https://api.github.com/users/liqima/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-15T10:37:58Z", "updated_at": "2019-03-15T13:03:05Z", "closed_at": "2019-03-15T13:03:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I'm a python user,  when I add_items to an AnnoyIndex() object, how can I get the clustering center coordinates?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/370", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/370/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/370/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/370/events", "html_url": "https://github.com/spotify/annoy/issues/370", "id": 419853754, "node_id": "MDU6SXNzdWU0MTk4NTM3NTQ=", "number": 370, "title": "How can i store meta data for Annoy Index?", "user": {"login": "arpsyapathy", "id": 29089769, "node_id": "MDQ6VXNlcjI5MDg5NzY5", "avatar_url": "https://avatars3.githubusercontent.com/u/29089769?v=4", "gravatar_id": "", "url": "https://api.github.com/users/arpsyapathy", "html_url": "https://github.com/arpsyapathy", "followers_url": "https://api.github.com/users/arpsyapathy/followers", "following_url": "https://api.github.com/users/arpsyapathy/following{/other_user}", "gists_url": "https://api.github.com/users/arpsyapathy/gists{/gist_id}", "starred_url": "https://api.github.com/users/arpsyapathy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/arpsyapathy/subscriptions", "organizations_url": "https://api.github.com/users/arpsyapathy/orgs", "repos_url": "https://api.github.com/users/arpsyapathy/repos", "events_url": "https://api.github.com/users/arpsyapathy/events{/privacy}", "received_events_url": "https://api.github.com/users/arpsyapathy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-12T08:17:26Z", "updated_at": "2019-03-12T18:58:14Z", "closed_at": "2019-03-12T18:58:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\n\r\nHow can i store meta data for Annoy Index?\r\n\r\nI store vectors in Annoy a.add_item(i, v)\r\nIs it possible store meta data for items?\r\nOr does it require a separate storage/database?\r\nThank you\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/369", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/369/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/369/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/369/events", "html_url": "https://github.com/spotify/annoy/issues/369", "id": 419150463, "node_id": "MDU6SXNzdWU0MTkxNTA0NjM=", "number": 369, "title": "Crash after saving index", "user": {"login": "Axel-CH", "id": 7593404, "node_id": "MDQ6VXNlcjc1OTM0MDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/7593404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Axel-CH", "html_url": "https://github.com/Axel-CH", "followers_url": "https://api.github.com/users/Axel-CH/followers", "following_url": "https://api.github.com/users/Axel-CH/following{/other_user}", "gists_url": "https://api.github.com/users/Axel-CH/gists{/gist_id}", "starred_url": "https://api.github.com/users/Axel-CH/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Axel-CH/subscriptions", "organizations_url": "https://api.github.com/users/Axel-CH/orgs", "repos_url": "https://api.github.com/users/Axel-CH/repos", "events_url": "https://api.github.com/users/Axel-CH/events{/privacy}", "received_events_url": "https://api.github.com/users/Axel-CH/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2019-03-10T05:58:18Z", "updated_at": "2019-03-10T17:38:27Z", "closed_at": "2019-03-10T17:29:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nFolowing the [coach issue](https://github.com/NervanaSystems/coach/issues/235)  and #367, I'm trying to save the annoy index in a file. The issue is that when I use the save function, I get this error:\r\n\r\n> You can't unbuild a loaded index\r\nSegmentation erro (core dumped)\r\n\r\n**Context:**\r\nI'm running a Deep reinforcement learning algorithme with the coach library. During the training I can enable automatic checkpoints saving every X seconds. This is where annoy is used. \r\nOne important thing here is that the **indexes in memory should be saved in files, and then stay in memory the be used in training**.\r\n\r\nThe index files will be restored after the training completion.\r\n\r\n\r\n\r\nI saw that the save method is doing multiple actions:\r\n\r\n- fwrite(_nodes, _s, _n_nodes, f);\r\n- unload();\r\n- return load(filename, prefault=false);\r\n\r\nI tried to comment \"unload\" and \"load\" the see if the issue persist, like that:\r\n\r\n      // unload();\r\n      // return load(filename, prefault=false);\r\n\r\n>       return true;\r\n\r\nBut the issue perssist, obviously it's more complicated than that.\r\n\r\nBellow the part of code triggering the error:\r\n```\r\n           for i in range(len(dicts)):\r\n                # save index for each action\r\n                p = Path(self.ap.task_parameters.checkpoint_save_dir) / \"indexes\"\r\n                p.mkdir(parents=True, exist_ok=True)\r\n                file_name = \"index_\" + str(i) + \".idx\"\r\n                indexPath = p / file_name\r\n                indexPathStr = str(indexPath.absolute())\r\n                dicts[i].index.save(indexPathStr) //Issue here\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/367", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/367/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/367/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/367/events", "html_url": "https://github.com/spotify/annoy/issues/367", "id": 415438452, "node_id": "MDU6SXNzdWU0MTU0Mzg0NTI=", "number": 367, "title": "Can't pickle annoy.Annoy objects", "user": {"login": "Axel-CH", "id": 7593404, "node_id": "MDQ6VXNlcjc1OTM0MDQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/7593404?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Axel-CH", "html_url": "https://github.com/Axel-CH", "followers_url": "https://api.github.com/users/Axel-CH/followers", "following_url": "https://api.github.com/users/Axel-CH/following{/other_user}", "gists_url": "https://api.github.com/users/Axel-CH/gists{/gist_id}", "starred_url": "https://api.github.com/users/Axel-CH/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Axel-CH/subscriptions", "organizations_url": "https://api.github.com/users/Axel-CH/orgs", "repos_url": "https://api.github.com/users/Axel-CH/repos", "events_url": "https://api.github.com/users/Axel-CH/events{/privacy}", "received_events_url": "https://api.github.com/users/Axel-CH/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2019-02-28T04:09:40Z", "updated_at": "2020-04-15T20:37:25Z", "closed_at": "2019-02-28T14:48:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nI have an Issue when I try to pickle an annoy object. Here Is the code generating the exception:\r\n`    def save_checkpoint(self, checkpoint_prefix):\r\n        super().save_checkpoint(checkpoint_prefix)\r\n        with open(os.path.join(self.ap.task_parameters.checkpoint_save_dir, str(checkpoint_prefix) + '.dnd'), 'wb') as f:\r\n            pickle.dump(self.networks['main'].online_network.output_heads[0].DND, f, pickle.HIGHEST_PROTOCOL)`\r\nThis code is comming from the [nec_agent](https://github.com/NervanaSystems/coach/blob/master/rl_coach/agents/nec_agent.py) of  Intel / NervanaSystems Coach Deep reinforcement learning librarie.\r\n\r\nI'm running that code on:\r\n\r\n- windows 10 64bits\r\n- Python 3.6.5\r\n- annoy 1.15.0\r\n\r\nThank for the help,\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/365", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/365/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/365/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/365/events", "html_url": "https://github.com/spotify/annoy/issues/365", "id": 413761884, "node_id": "MDU6SXNzdWU0MTM3NjE4ODQ=", "number": 365, "title": "annoy.build does not finish. Is there a limit to the items which can be added?", "user": {"login": "Paperone80", "id": 26833332, "node_id": "MDQ6VXNlcjI2ODMzMzMy", "avatar_url": "https://avatars1.githubusercontent.com/u/26833332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Paperone80", "html_url": "https://github.com/Paperone80", "followers_url": "https://api.github.com/users/Paperone80/followers", "following_url": "https://api.github.com/users/Paperone80/following{/other_user}", "gists_url": "https://api.github.com/users/Paperone80/gists{/gist_id}", "starred_url": "https://api.github.com/users/Paperone80/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Paperone80/subscriptions", "organizations_url": "https://api.github.com/users/Paperone80/orgs", "repos_url": "https://api.github.com/users/Paperone80/repos", "events_url": "https://api.github.com/users/Paperone80/events{/privacy}", "received_events_url": "https://api.github.com/users/Paperone80/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-02-24T00:29:58Z", "updated_at": "2019-02-24T19:29:58Z", "closed_at": "2019-02-24T19:29:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am on a MacBook Pro with 16GB memory. I successfully installed build annoy v1.15.0 using \r\n`sudo -H CC=/usr/local/bin//gcc-4.9 CPP=/usr/local/bin//cpp-4.9 CXX=/usr/local/bin//g++-4.9 pip install --upgrade annoy`\r\n\r\nI have ~120,000 items which have dims=np.array(49152,). However, to successfully annoy.build(n_trees) I can't add more than ~48,000 items. Any number above and annoy.build() never finishes (I waited 24h+) but I can see disk activity. I tried annoy.on_disk_build() and without, no success. I tried lowering n_trees to 10 but no success. \r\n\r\n48,000 items with n_trees=1500 takes about 1h 27min to successfully build. \r\n\r\nOne particularity I do though, is that I choose the number/sample of items randomly from a metadata file and are using the pandas.DataFrame.index integer as the annoy.add_item(int(idx). Not sure whether the numbers need to be a certain sequence or to start with but I understood from the documentation that it shouldn't matter as the annoy will allocate memory for max(i=idx)+1 anyway. \r\n\r\nThanks in advance for all the help.\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/364", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/364/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/364/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/364/events", "html_url": "https://github.com/spotify/annoy/issues/364", "id": 413273269, "node_id": "MDU6SXNzdWU0MTMyNzMyNjk=", "number": 364, "title": "result type []int in README_GO.rst", "user": {"login": "kyowill", "id": 8749196, "node_id": "MDQ6VXNlcjg3NDkxOTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/8749196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kyowill", "html_url": "https://github.com/kyowill", "followers_url": "https://api.github.com/users/kyowill/followers", "following_url": "https://api.github.com/users/kyowill/following{/other_user}", "gists_url": "https://api.github.com/users/kyowill/gists{/gist_id}", "starred_url": "https://api.github.com/users/kyowill/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kyowill/subscriptions", "organizations_url": "https://api.github.com/users/kyowill/orgs", "repos_url": "https://api.github.com/users/kyowill/repos", "events_url": "https://api.github.com/users/kyowill/events{/privacy}", "received_events_url": "https://api.github.com/users/kyowill/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-22T07:14:52Z", "updated_at": "2019-02-25T06:06:46Z", "closed_at": "2019-02-25T06:06:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "when use Annoy in my recommend service built in go version, the Annoy in go only supports '[]int', but '[]int64' is widely used in large candidate set.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/363", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/363/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/363/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/363/events", "html_url": "https://github.com/spotify/annoy/issues/363", "id": 413104419, "node_id": "MDU6SXNzdWU0MTMxMDQ0MTk=", "number": 363, "title": "Angular distance between orthogonal vectors", "user": {"login": "braingineer", "id": 1455742, "node_id": "MDQ6VXNlcjE0NTU3NDI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1455742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/braingineer", "html_url": "https://github.com/braingineer", "followers_url": "https://api.github.com/users/braingineer/followers", "following_url": "https://api.github.com/users/braingineer/following{/other_user}", "gists_url": "https://api.github.com/users/braingineer/gists{/gist_id}", "starred_url": "https://api.github.com/users/braingineer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/braingineer/subscriptions", "organizations_url": "https://api.github.com/users/braingineer/orgs", "repos_url": "https://api.github.com/users/braingineer/repos", "events_url": "https://api.github.com/users/braingineer/events{/privacy}", "received_events_url": "https://api.github.com/users/braingineer/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-02-21T20:14:50Z", "updated_at": "2019-02-24T21:46:37Z", "closed_at": "2019-02-24T19:47:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI've read through some of the issues (#162 and #149 and #193) to see if it's my misunderstanding but I'm still coming up short. \r\n\r\nPremises:\r\n- angular distance is computed as the euclidean distance of the 2 normalized vectors.   \r\n- this should be equal to 2(1-cos(theta)) where theta is the angle between the two vectors \r\n\r\nFor orthogonal vectors, theta should be 90 (pi/2), cos(theta) should be 0, the angular distance should be 2. Is this correct?  However, if you use the euclidean distance of the 2 vectors, you get the 1.41 answer shown below. \r\n\r\nTest script:\r\n```\r\nfrom annoy import AnnoyIndex\r\nimport numpy as np\r\n\r\nannoy_index = AnnoyIndex(f=2, metric=\"angular\")\r\n\r\nvec0 = np.array([0, 1])\r\nvec1 = np.array([1, 0])\r\nannoy_index.add_item(i=0, vector=vec0)\r\nannoy_index.add_item(i=1, vector=vec1)\r\n\r\nannoy_index.build(n_trees=-1)\r\n\r\nprint(annoy_index.get_distance(0, 1)) # prints 1.4142135381698608 , the sqrt(2)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/360", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/360/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/360/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/360/events", "html_url": "https://github.com/spotify/annoy/issues/360", "id": 411123577, "node_id": "MDU6SXNzdWU0MTExMjM1Nzc=", "number": 360, "title": "Jaccard distance?", "user": {"login": "gregfriedland", "id": 1192366, "node_id": "MDQ6VXNlcjExOTIzNjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1192366?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gregfriedland", "html_url": "https://github.com/gregfriedland", "followers_url": "https://api.github.com/users/gregfriedland/followers", "following_url": "https://api.github.com/users/gregfriedland/following{/other_user}", "gists_url": "https://api.github.com/users/gregfriedland/gists{/gist_id}", "starred_url": "https://api.github.com/users/gregfriedland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gregfriedland/subscriptions", "organizations_url": "https://api.github.com/users/gregfriedland/orgs", "repos_url": "https://api.github.com/users/gregfriedland/repos", "events_url": "https://api.github.com/users/gregfriedland/events{/privacy}", "received_events_url": "https://api.github.com/users/gregfriedland/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-16T22:50:23Z", "updated_at": "2019-02-24T19:49:18Z", "closed_at": "2019-02-24T19:49:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nCan someone advise what changes would be necessary to implement a Jaccard distance metric based on bit vectors? I saw that Hamming distance uses bit vectors so perhaps it's a relatively straightforward tweak from there... Any pointers would be appreciated.\r\n\r\nThanks!\r\nGreg", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/359", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/359/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/359/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/359/events", "html_url": "https://github.com/spotify/annoy/issues/359", "id": 410429845, "node_id": "MDU6SXNzdWU0MTA0Mjk4NDU=", "number": 359, "title": "Mahalanobis distance?", "user": {"login": "ConnorBarnhill", "id": 7959016, "node_id": "MDQ6VXNlcjc5NTkwMTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/7959016?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ConnorBarnhill", "html_url": "https://github.com/ConnorBarnhill", "followers_url": "https://api.github.com/users/ConnorBarnhill/followers", "following_url": "https://api.github.com/users/ConnorBarnhill/following{/other_user}", "gists_url": "https://api.github.com/users/ConnorBarnhill/gists{/gist_id}", "starred_url": "https://api.github.com/users/ConnorBarnhill/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ConnorBarnhill/subscriptions", "organizations_url": "https://api.github.com/users/ConnorBarnhill/orgs", "repos_url": "https://api.github.com/users/ConnorBarnhill/repos", "events_url": "https://api.github.com/users/ConnorBarnhill/events{/privacy}", "received_events_url": "https://api.github.com/users/ConnorBarnhill/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-02-14T18:19:56Z", "updated_at": "2019-02-19T21:38:43Z", "closed_at": "2019-02-19T21:38:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there a way to implement Mahalanobis distance?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/358", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/358/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/358/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/358/events", "html_url": "https://github.com/spotify/annoy/issues/358", "id": 409311648, "node_id": "MDU6SXNzdWU0MDkzMTE2NDg=", "number": 358, "title": "Windows 10 and Python 3.6- Not able to pip install annoy", "user": {"login": "abhi1489", "id": 44470885, "node_id": "MDQ6VXNlcjQ0NDcwODg1", "avatar_url": "https://avatars0.githubusercontent.com/u/44470885?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhi1489", "html_url": "https://github.com/abhi1489", "followers_url": "https://api.github.com/users/abhi1489/followers", "following_url": "https://api.github.com/users/abhi1489/following{/other_user}", "gists_url": "https://api.github.com/users/abhi1489/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhi1489/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhi1489/subscriptions", "organizations_url": "https://api.github.com/users/abhi1489/orgs", "repos_url": "https://api.github.com/users/abhi1489/repos", "events_url": "https://api.github.com/users/abhi1489/events{/privacy}", "received_events_url": "https://api.github.com/users/abhi1489/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-02-12T13:55:26Z", "updated_at": "2019-02-24T21:39:38Z", "closed_at": "2019-02-24T21:39:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am getting the following error while trying to pip install on my machine along with a host of warnings.\r\n\r\n c:\\users\\abhishek.aigali\\appdata\\local\\temp\\pip-install-6qce79eb\\annoy\\src\\annoylib.h(555): error C3861: '__popcnt64': identifier not found\r\n    c:\\users\\abhishek.aigali\\appdata\\local\\temp\\pip-install-6qce79eb\\annoy\\src\\annoylib.h(959): note: see reference to function template instantiation 'T Hamming::distance<S,T>(const Hamming::Node<S,T> *,const Hamming::Node<S,T> *,int)' being compiled\r\n            with\r\n            [\r\n                T=uint64_t,\r\n                S=int32_t\r\n            ]\r\n    c:\\users\\abhishek.aigali\\appdata\\local\\temp\\pip-install-6qce79eb\\annoy\\src\\annoylib.h(958): note: while compiling class template member function 'T AnnoyIndex<int32_t,T,Hamming,Kiss64Random>::get_distance(S,S) const'\r\n            with\r\n            [\r\n                T=uint64_t,\r\n                S=int32_t\r\n            ]\r\n    src/annoymodule.cc(74): note: see reference to function template instantiation 'T AnnoyIndex<int32_t,T,Hamming,Kiss64Random>::get_distance(S,S) const' being compiled\r\n            with\r\n            [\r\n                T=uint64_t,\r\n                S=int32_t\r\n            ]\r\n    error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2017\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.16.27023\\\\bin\\\\HostX86\\\\x86\\\\cl.exe' failed with exit status 2\r\n\r\nI have updated my visual studio 2017 build tools. The same command pip install annoy works when i run it through the Anaconda command prompt but when i copied the installed library, from\r\nC:\\Users\\abhishek.aigali\\AppData\\Local\\Continuum\\anaconda3\\Lib\\site-packages\r\n\r\nto:\r\nC:\\Users\\abhishek.aigali\\AppData\\Local\\Programs\\Python\\Python36-32\\Lib\\site-packages\r\n\r\nand did -- **import annoy** i got the following error:\r\nModuleNotFoundError: No module named 'annoy.annoylib'\r\n\r\nAny suggestions please?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/357", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/357/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/357/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/357/events", "html_url": "https://github.com/spotify/annoy/issues/357", "id": 407631432, "node_id": "MDU6SXNzdWU0MDc2MzE0MzI=", "number": 357, "title": "Can't use the dot metric", "user": {"login": "alejandrojcastaneira", "id": 42115387, "node_id": "MDQ6VXNlcjQyMTE1Mzg3", "avatar_url": "https://avatars3.githubusercontent.com/u/42115387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alejandrojcastaneira", "html_url": "https://github.com/alejandrojcastaneira", "followers_url": "https://api.github.com/users/alejandrojcastaneira/followers", "following_url": "https://api.github.com/users/alejandrojcastaneira/following{/other_user}", "gists_url": "https://api.github.com/users/alejandrojcastaneira/gists{/gist_id}", "starred_url": "https://api.github.com/users/alejandrojcastaneira/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alejandrojcastaneira/subscriptions", "organizations_url": "https://api.github.com/users/alejandrojcastaneira/orgs", "repos_url": "https://api.github.com/users/alejandrojcastaneira/repos", "events_url": "https://api.github.com/users/alejandrojcastaneira/events{/privacy}", "received_events_url": "https://api.github.com/users/alejandrojcastaneira/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-02-07T10:29:49Z", "updated_at": "2020-02-28T18:56:42Z", "closed_at": "2019-02-24T19:49:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "I tried to use the metric = \"dot\"  whit the latest version of annoy 1.15.0 and didn't work.\r\n\r\nI installed from pip and also from the git-hub repo.\r\n\r\nBest regards.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/356", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/356/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/356/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/356/events", "html_url": "https://github.com/spotify/annoy/issues/356", "id": 406121307, "node_id": "MDU6SXNzdWU0MDYxMjEzMDc=", "number": 356, "title": "Calculate percentage distance from vector search", "user": {"login": "OElesin", "id": 11349090, "node_id": "MDQ6VXNlcjExMzQ5MDkw", "avatar_url": "https://avatars3.githubusercontent.com/u/11349090?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OElesin", "html_url": "https://github.com/OElesin", "followers_url": "https://api.github.com/users/OElesin/followers", "following_url": "https://api.github.com/users/OElesin/following{/other_user}", "gists_url": "https://api.github.com/users/OElesin/gists{/gist_id}", "starred_url": "https://api.github.com/users/OElesin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OElesin/subscriptions", "organizations_url": "https://api.github.com/users/OElesin/orgs", "repos_url": "https://api.github.com/users/OElesin/repos", "events_url": "https://api.github.com/users/OElesin/events{/privacy}", "received_events_url": "https://api.github.com/users/OElesin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-02-03T19:26:54Z", "updated_at": "2019-02-05T23:30:37Z", "closed_at": "2019-02-05T23:30:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello team, great work.\r\n\r\nIs it possible to possible to calculate the percentage distance from vector search. I have built an index successfully and able to query with `get_nns_by_vector` with `include_distance=True`. \r\n\r\nI would like to convert the returned distance into percentages. Do you have any recommended ways of doing this?\r\n\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/355", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/355/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/355/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/355/events", "html_url": "https://github.com/spotify/annoy/issues/355", "id": 403630285, "node_id": "MDU6SXNzdWU0MDM2MzAyODU=", "number": 355, "title": "Same model is loaded with different programing language, but produced different results.  ", "user": {"login": "kyowill", "id": 8749196, "node_id": "MDQ6VXNlcjg3NDkxOTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/8749196?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kyowill", "html_url": "https://github.com/kyowill", "followers_url": "https://api.github.com/users/kyowill/followers", "following_url": "https://api.github.com/users/kyowill/following{/other_user}", "gists_url": "https://api.github.com/users/kyowill/gists{/gist_id}", "starred_url": "https://api.github.com/users/kyowill/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kyowill/subscriptions", "organizations_url": "https://api.github.com/users/kyowill/orgs", "repos_url": "https://api.github.com/users/kyowill/repos", "events_url": "https://api.github.com/users/kyowill/events{/privacy}", "received_events_url": "https://api.github.com/users/kyowill/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-28T02:42:48Z", "updated_at": "2019-01-28T15:36:48Z", "closed_at": "2019-01-28T08:44:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have built a tree with python.Then load same model file with Go.It produce different result", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/354", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/354/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/354/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/354/events", "html_url": "https://github.com/spotify/annoy/issues/354", "id": 403568717, "node_id": "MDU6SXNzdWU0MDM1Njg3MTc=", "number": 354, "title": "What does the search time depend on?", "user": {"login": "Karol-G", "id": 3471895, "node_id": "MDQ6VXNlcjM0NzE4OTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/3471895?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Karol-G", "html_url": "https://github.com/Karol-G", "followers_url": "https://api.github.com/users/Karol-G/followers", "following_url": "https://api.github.com/users/Karol-G/following{/other_user}", "gists_url": "https://api.github.com/users/Karol-G/gists{/gist_id}", "starred_url": "https://api.github.com/users/Karol-G/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Karol-G/subscriptions", "organizations_url": "https://api.github.com/users/Karol-G/orgs", "repos_url": "https://api.github.com/users/Karol-G/repos", "events_url": "https://api.github.com/users/Karol-G/events{/privacy}", "received_events_url": "https://api.github.com/users/Karol-G/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-01-27T16:27:35Z", "updated_at": "2019-06-16T08:03:55Z", "closed_at": "2019-01-28T03:47:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "I set the number of trees to one and search_k at a fixed value of 400. I then build multiple indexes with different amounts of items in the index. Meaning I build an index with 100k items, one with 400k items, ... and one with 1M items. When doing test searches the accuracy for all the indexes stayed good and the search time was constant. \r\n\r\nI do not have so much insight on how annoy works, but when choosing a fixed search_k value, does this mean that the search time will be constant no matter the size of the index? \r\nIf this is true, shouldn't the accuracy degrade when the index becomes to big? \r\n\r\nSo summarized:\r\nWhat is the relationship between search_k, index size, search time and accuracy?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/353", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/353/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/353/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/353/events", "html_url": "https://github.com/spotify/annoy/issues/353", "id": 403270391, "node_id": "MDU6SXNzdWU0MDMyNzAzOTE=", "number": 353, "title": "on_disk_build bug", "user": {"login": "Slikus", "id": 8903862, "node_id": "MDQ6VXNlcjg5MDM4NjI=", "avatar_url": "https://avatars1.githubusercontent.com/u/8903862?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Slikus", "html_url": "https://github.com/Slikus", "followers_url": "https://api.github.com/users/Slikus/followers", "following_url": "https://api.github.com/users/Slikus/following{/other_user}", "gists_url": "https://api.github.com/users/Slikus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Slikus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Slikus/subscriptions", "organizations_url": "https://api.github.com/users/Slikus/orgs", "repos_url": "https://api.github.com/users/Slikus/repos", "events_url": "https://api.github.com/users/Slikus/events{/privacy}", "received_events_url": "https://api.github.com/users/Slikus/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2019-01-25T18:11:17Z", "updated_at": "2020-07-28T03:37:08Z", "closed_at": "2020-07-27T13:12:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nfrom annoy import AnnoyIndex\r\n\r\na = AnnoyIndex(4)\r\n\r\na.add_item(0, [0, 0, 0, 0])\r\na.add_item(1, [0, 0, 6, 0])\r\na.add_item(2, [0, 5, 0, 0])\r\na.add_item(3, [0, 4, 0, 0])\r\na.add_item(4, [0, 0, 3, 0])\r\na.add_item(5, [2, 2, 0, 0])\r\na.add_item(6, [0, 0, 0, 0])\r\na.add_item(7, [0, 0, 0, 0])\r\n\r\na.build(-1)\r\na.save('C:/Users/home/Desktop/test1.tree')\r\na.unload()\r\n\r\n\r\nb = AnnoyIndex(4)\r\nb.on_disk_build('C:/Users/home/Desktop/test2.tree')\r\n\r\nb.add_item(0, [4, 0, 0, 0])\r\nb.add_item(1, [0, 4, 0, 0])\r\nb.add_item(2, [0, 3, 2, 0])\r\nb.add_item(3, [0, 0, 2, 0])\r\nb.add_item(4, [0, 0, 0, 0])\r\nb.add_item(5, [0, 4, 2, 0])\r\nb.add_item(6, [0, 0, 2, 0])\r\nb.add_item(7, [0, 0, 1, 0])\r\n\r\nb.build(-1)\r\nb.unload()\r\n\r\n\r\n\r\nc = AnnoyIndex(4)\r\nc.load('C:/Users/home/Desktop/test1.tree')\r\nprint('1 length:', c.get_n_items())\r\n\r\n\r\nd = AnnoyIndex(4)\r\nd.load('C:/Users/home/Desktop/test2.tree')\r\nprint('2 length:', d.get_n_items())\r\n\r\n```\r\n\r\noutput:\r\n1 length: 8\r\n2 length: 0\r\n\r\nso get_nns_by_vector and etc is not works too\r\n\r\n![image](https://user-images.githubusercontent.com/8903862/51776066-dd6eec80-2108-11e9-9b38-20ebe71b7987.png)\r\n\r\n\r\nupd:\r\nI deleted zeros at the end of the file (not on picture), and it worked. But there were only 3M lines in the file (50k 128D records), if the file is more than 100+ times longer I will not be able to do it. Need to fix it\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/352", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/352/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/352/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/352/events", "html_url": "https://github.com/spotify/annoy/issues/352", "id": 402267983, "node_id": "MDU6SXNzdWU0MDIyNjc5ODM=", "number": 352, "title": "UnicodeDecodeError: 'ascii' codec can't decode byte 0xc0 in position 9: ordinal not in range(128)", "user": {"login": "allieonpoppyfield", "id": 33809319, "node_id": "MDQ6VXNlcjMzODA5MzE5", "avatar_url": "https://avatars3.githubusercontent.com/u/33809319?v=4", "gravatar_id": "", "url": "https://api.github.com/users/allieonpoppyfield", "html_url": "https://github.com/allieonpoppyfield", "followers_url": "https://api.github.com/users/allieonpoppyfield/followers", "following_url": "https://api.github.com/users/allieonpoppyfield/following{/other_user}", "gists_url": "https://api.github.com/users/allieonpoppyfield/gists{/gist_id}", "starred_url": "https://api.github.com/users/allieonpoppyfield/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/allieonpoppyfield/subscriptions", "organizations_url": "https://api.github.com/users/allieonpoppyfield/orgs", "repos_url": "https://api.github.com/users/allieonpoppyfield/repos", "events_url": "https://api.github.com/users/allieonpoppyfield/events{/privacy}", "received_events_url": "https://api.github.com/users/allieonpoppyfield/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-23T14:34:48Z", "updated_at": "2019-03-06T14:16:31Z", "closed_at": "2019-01-23T15:19:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "I can not install annoy on python 2.7\r\n\r\nC:\\Python27\\Scripts\\pip.exe install annoy\r\n\r\nRunning setup.py install for annoy ... error\r\n    Complete output from command c:\\python27\\python.exe -u -c \"import setuptools, tokenize;__file__='c:\\\\users\\\\836d~1\\\\appdata\\\\local\\\\temp\\\\pip-install-dy79vf\\\\annoy\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record c:\\users\\836d~1\\appdata\\local\\temp\\pip-record-bm8azy\\install-record.txt --single-version-externally-managed --compile:\r\n    running install\r\n    running build\r\n    running build_py\r\n    creating build\r\n    creating build\\lib.win-amd64-2.7\r\n    creating build\\lib.win-amd64-2.7\\annoy\r\n    copying annoy\\__init__.py -> build\\lib.win-amd64-2.7\\annoy\r\n    running build_ext\r\n    building 'annoy.annoylib' extension\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"c:\\users\\836d~1\\appdata\\local\\temp\\pip-install-dy79vf\\annoy\\setup.py\", line 82, in <module>\r\n        setup_requires=['nose>=1.0']\r\n      File \"c:\\python27\\lib\\site-packages\\setuptools\\__init__.py\", line 129, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"c:\\python27\\lib\\distutils\\core.py\", line 151, in setup\r\n        dist.run_commands()\r\n      File \"c:\\python27\\lib\\distutils\\dist.py\", line 953, in run_commands\r\n        self.run_command(cmd)\r\n      File \"c:\\python27\\lib\\distutils\\dist.py\", line 972, in run_command\r\n        cmd_obj.run()\r\n      File \"c:\\python27\\lib\\site-packages\\setuptools\\command\\install.py\", line 61, in run\r\n        return orig.install.run(self)\r\n      File \"c:\\python27\\lib\\distutils\\command\\install.py\", line 563, in run\r\n        self.run_command('build')\r\n      File \"c:\\python27\\lib\\distutils\\cmd.py\", line 326, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"c:\\python27\\lib\\distutils\\dist.py\", line 972, in run_command\r\n        cmd_obj.run()\r\n      File \"c:\\python27\\lib\\distutils\\command\\build.py\", line 127, in run\r\n        self.run_command(cmd_name)\r\n      File \"c:\\python27\\lib\\distutils\\cmd.py\", line 326, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"c:\\python27\\lib\\distutils\\dist.py\", line 972, in run_command\r\n        cmd_obj.run()\r\n      File \"c:\\python27\\lib\\site-packages\\setuptools\\command\\build_ext.py\", line 78, in run\r\n        _build_ext.run(self)\r\n      File \"c:\\python27\\lib\\distutils\\command\\build_ext.py\", line 339, in run\r\n        self.build_extensions()\r\n      File \"c:\\python27\\lib\\distutils\\command\\build_ext.py\", line 448, in build_extensions\r\n        self.build_extension(ext)\r\n      File \"c:\\python27\\lib\\site-packages\\setuptools\\command\\build_ext.py\", line 199, in build_extension\r\n        _build_ext.build_extension(self, ext)\r\n      File \"c:\\python27\\lib\\distutils\\command\\build_ext.py\", line 498, in build_extension\r\n        depends=ext.depends)\r\n      File \"c:\\python27\\lib\\distutils\\msvc9compiler.py\", line 473, in compile\r\n        self.initialize()\r\n      File \"c:\\python27\\lib\\distutils\\msvc9compiler.py\", line 383, in initialize\r\n        vc_env = query_vcvarsall(VERSION, plat_spec)\r\n      File \"c:\\python27\\lib\\site-packages\\setuptools\\msvc.py\", line 148, in msvc9_query_vcvarsall\r\n        return EnvironmentInfo(arch, ver).return_env()\r\n      File \"c:\\python27\\lib\\site-packages\\setuptools\\msvc.py\", line 1257, in return_env\r\n        exists),\r\n      File \"c:\\python27\\lib\\site-packages\\setuptools\\msvc.py\", line 1280, in _build_paths\r\n        return os.pathsep.join(unique_paths)\r\n    UnicodeDecodeError: 'ascii' codec can't decode byte 0xc0 in position 9: ordinal not in range(128)\r\n\r\n    ----------------------------------------\r\nCommand \"c:\\python27\\python.exe -u -c \"import setuptools, tokenize;__file__='c:\\\\users\\\\836d~1\\\\appdata\\\\local\\\\temp\\\\pip-install-dy79vf\\\\annoy\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record c:\\users\\836d~1\\appdata\\local\\temp\\pip-record-bm8azy\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in c:\\users\\836d~1\\appdata\\local\\temp\\pip-install-dy79vf\\annoy\\\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/351", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/351/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/351/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/351/events", "html_url": "https://github.com/spotify/annoy/issues/351", "id": 402121549, "node_id": "MDU6SXNzdWU0MDIxMjE1NDk=", "number": 351, "title": "Why distance has the same type as vector elements in c++?", "user": {"login": "ibendrup", "id": 1009737, "node_id": "MDQ6VXNlcjEwMDk3Mzc=", "avatar_url": "https://avatars0.githubusercontent.com/u/1009737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibendrup", "html_url": "https://github.com/ibendrup", "followers_url": "https://api.github.com/users/ibendrup/followers", "following_url": "https://api.github.com/users/ibendrup/following{/other_user}", "gists_url": "https://api.github.com/users/ibendrup/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibendrup/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibendrup/subscriptions", "organizations_url": "https://api.github.com/users/ibendrup/orgs", "repos_url": "https://api.github.com/users/ibendrup/repos", "events_url": "https://api.github.com/users/ibendrup/events{/privacy}", "received_events_url": "https://api.github.com/users/ibendrup/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-01-23T08:23:53Z", "updated_at": "2019-02-07T09:08:20Z", "closed_at": "2019-02-07T09:08:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "To save memory it would be useful to store vector elements in such types like `uint16_t `or `uint8_t`. But using such types to store distance value leads to significant accuracy loss. I think it makes sence always use `float`  to store distance values.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/350", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/350/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/350/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/350/events", "html_url": "https://github.com/spotify/annoy/issues/350", "id": 402088317, "node_id": "MDU6SXNzdWU0MDIwODgzMTc=", "number": 350, "title": "Deploy annoy in web based system", "user": {"login": "gagan144", "id": 20434254, "node_id": "MDQ6VXNlcjIwNDM0MjU0", "avatar_url": "https://avatars0.githubusercontent.com/u/20434254?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gagan144", "html_url": "https://github.com/gagan144", "followers_url": "https://api.github.com/users/gagan144/followers", "following_url": "https://api.github.com/users/gagan144/following{/other_user}", "gists_url": "https://api.github.com/users/gagan144/gists{/gist_id}", "starred_url": "https://api.github.com/users/gagan144/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gagan144/subscriptions", "organizations_url": "https://api.github.com/users/gagan144/orgs", "repos_url": "https://api.github.com/users/gagan144/repos", "events_url": "https://api.github.com/users/gagan144/events{/privacy}", "received_events_url": "https://api.github.com/users/gagan144/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-01-23T06:19:55Z", "updated_at": "2019-04-27T09:07:42Z", "closed_at": "2019-01-23T15:19:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nWhat is the architectural design to deploy annoy in a web based system build in a framework like django, specially when data is rapidly changing (add/delete/update). Consider a scenario where the users are uploading images and some intermediate process converts those images into vectors which are then updated to annoy for query. The users can delete or modify images as well, so annoy must be updated accordingly in real-time. Also, how to handle situation when the server restarts, will annoy rebuild again? The data can be in millions!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/349", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/349/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/349/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/349/events", "html_url": "https://github.com/spotify/annoy/issues/349", "id": 401564696, "node_id": "MDU6SXNzdWU0MDE1NjQ2OTY=", "number": 349, "title": "pip install annoy not working on macOS mojave", "user": {"login": "thebarbershop", "id": 25029365, "node_id": "MDQ6VXNlcjI1MDI5MzY1", "avatar_url": "https://avatars0.githubusercontent.com/u/25029365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thebarbershop", "html_url": "https://github.com/thebarbershop", "followers_url": "https://api.github.com/users/thebarbershop/followers", "following_url": "https://api.github.com/users/thebarbershop/following{/other_user}", "gists_url": "https://api.github.com/users/thebarbershop/gists{/gist_id}", "starred_url": "https://api.github.com/users/thebarbershop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thebarbershop/subscriptions", "organizations_url": "https://api.github.com/users/thebarbershop/orgs", "repos_url": "https://api.github.com/users/thebarbershop/repos", "events_url": "https://api.github.com/users/thebarbershop/events{/privacy}", "received_events_url": "https://api.github.com/users/thebarbershop/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2019-01-22T01:40:58Z", "updated_at": "2019-05-01T16:36:52Z", "closed_at": "2019-02-22T15:23:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is where `pip install annoy` fails:\r\n\r\n```bash\r\n  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/taegyung/miniconda3/include -arch x86_64 -I/Users/taegyung/miniconda3/include -arch x86_64 -I/Users/taegyung/miniconda3/include/python3.6m -c src/annoymodule.cc -o build/temp.macosx-10.7-x86_64-3.6/src/annoymodule.o -O3 -ffast-math -fno-associative-math -march=native\r\n  warning: include path for stdlibc++ headers not found; pass '-std=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\r\n  In file included from src/annoymodule.cc:15:\r\n  src/annoylib.h:49:10: fatal error: 'vector' file not found\r\n  #include <vector>\r\n           ^~~~~~~~\r\n  1 warning and 1 error generated.\r\n  error: command 'gcc' failed with exit status 1\r\n```\r\n\r\nI tried some things I found from previous issues and some general solutions accros the web, including\r\n\r\n- sudo pip install annoy\r\n- Installing XCode 9.4 (I wasn't using any version of XCode previously)\r\n- xcode-select --install\r\n- brew remove gcc; brew install gcc\r\n\r\nI finally got it by running `conda install -c akode annoy`, but I'm not sure if this is the right way to do it (and don't know why this even works.)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/348", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/348/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/348/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/348/events", "html_url": "https://github.com/spotify/annoy/issues/348", "id": 394546825, "node_id": "MDU6SXNzdWUzOTQ1NDY4MjU=", "number": 348, "title": "Solved : Error \"IndexError: Item index larger than the largest item index \" or  null output ,when metric !='angular' ", "user": {"login": "moyunyoukuang", "id": 3771929, "node_id": "MDQ6VXNlcjM3NzE5Mjk=", "avatar_url": "https://avatars1.githubusercontent.com/u/3771929?v=4", "gravatar_id": "", "url": "https://api.github.com/users/moyunyoukuang", "html_url": "https://github.com/moyunyoukuang", "followers_url": "https://api.github.com/users/moyunyoukuang/followers", "following_url": "https://api.github.com/users/moyunyoukuang/following{/other_user}", "gists_url": "https://api.github.com/users/moyunyoukuang/gists{/gist_id}", "starred_url": "https://api.github.com/users/moyunyoukuang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/moyunyoukuang/subscriptions", "organizations_url": "https://api.github.com/users/moyunyoukuang/orgs", "repos_url": "https://api.github.com/users/moyunyoukuang/repos", "events_url": "https://api.github.com/users/moyunyoukuang/events{/privacy}", "received_events_url": "https://api.github.com/users/moyunyoukuang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-12-28T04:53:01Z", "updated_at": "2019-04-10T01:11:33Z", "closed_at": "2019-04-10T01:11:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\nSolved\uff1a\r\nerror  rised  \"IndexError: Item index larger than the largest item index\" when \r\n```\r\nt = AnnoyIndex(f,metric='euclidean')  \r\n\r\n## add 5000 data\r\n## build\r\n## save\r\n\r\nu = AnnoyIndex(f)\r\nu.load('./test.ann') \r\nprint(u.get_nns_by_item(0, 1000))\r\n```\r\n>>\"IndexError: Item index larger than the largest item index \" or null output\r\n\r\nuse this instead:\r\n```\r\nu = AnnoyIndex(f,metric='euclidean')\r\nu.load('./test.ann') \r\nprint(u.get_nns_by_item(0, 1000))\r\n```\r\n\r\nmetric='euclidean' is needed , the same with other metric\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/347", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/347/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/347/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/347/events", "html_url": "https://github.com/spotify/annoy/issues/347", "id": 394341779, "node_id": "MDU6SXNzdWUzOTQzNDE3Nzk=", "number": 347, "title": "Redis support", "user": {"login": "changzeng", "id": 11350222, "node_id": "MDQ6VXNlcjExMzUwMjIy", "avatar_url": "https://avatars1.githubusercontent.com/u/11350222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/changzeng", "html_url": "https://github.com/changzeng", "followers_url": "https://api.github.com/users/changzeng/followers", "following_url": "https://api.github.com/users/changzeng/following{/other_user}", "gists_url": "https://api.github.com/users/changzeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/changzeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/changzeng/subscriptions", "organizations_url": "https://api.github.com/users/changzeng/orgs", "repos_url": "https://api.github.com/users/changzeng/repos", "events_url": "https://api.github.com/users/changzeng/events{/privacy}", "received_events_url": "https://api.github.com/users/changzeng/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-27T09:23:14Z", "updated_at": "2018-12-28T03:01:49Z", "closed_at": "2018-12-27T14:54:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Does this package support redis storage?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/346", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/346/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/346/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/346/events", "html_url": "https://github.com/spotify/annoy/issues/346", "id": 392201963, "node_id": "MDU6SXNzdWUzOTIyMDE5NjM=", "number": 346, "title": "Information Retrieval Closest Senence", "user": {"login": "yondu22", "id": 5721671, "node_id": "MDQ6VXNlcjU3MjE2NzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/5721671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yondu22", "html_url": "https://github.com/yondu22", "followers_url": "https://api.github.com/users/yondu22/followers", "following_url": "https://api.github.com/users/yondu22/following{/other_user}", "gists_url": "https://api.github.com/users/yondu22/gists{/gist_id}", "starred_url": "https://api.github.com/users/yondu22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yondu22/subscriptions", "organizations_url": "https://api.github.com/users/yondu22/orgs", "repos_url": "https://api.github.com/users/yondu22/repos", "events_url": "https://api.github.com/users/yondu22/events{/privacy}", "received_events_url": "https://api.github.com/users/yondu22/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-18T15:15:31Z", "updated_at": "2019-04-27T09:08:59Z", "closed_at": "2018-12-18T15:18:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Came to this git from this post\r\nhttps://www.quora.com/How-can-I-use-sentence-similarity-in-information-retrieval-task\r\n\r\nBasically, if I have a list of 100,000 sentences, how would I find the closest sentence in that list to a given sentence", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/345", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/345/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/345/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/345/events", "html_url": "https://github.com/spotify/annoy/issues/345", "id": 391047788, "node_id": "MDU6SXNzdWUzOTEwNDc3ODg=", "number": 345, "title": "string search", "user": {"login": "yondu22", "id": 5721671, "node_id": "MDQ6VXNlcjU3MjE2NzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/5721671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yondu22", "html_url": "https://github.com/yondu22", "followers_url": "https://api.github.com/users/yondu22/followers", "following_url": "https://api.github.com/users/yondu22/following{/other_user}", "gists_url": "https://api.github.com/users/yondu22/gists{/gist_id}", "starred_url": "https://api.github.com/users/yondu22/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yondu22/subscriptions", "organizations_url": "https://api.github.com/users/yondu22/orgs", "repos_url": "https://api.github.com/users/yondu22/repos", "events_url": "https://api.github.com/users/yondu22/events{/privacy}", "received_events_url": "https://api.github.com/users/yondu22/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-12-14T10:14:39Z", "updated_at": "2018-12-14T10:15:10Z", "closed_at": "2018-12-14T10:15:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/344", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/344/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/344/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/344/events", "html_url": "https://github.com/spotify/annoy/issues/344", "id": 390089302, "node_id": "MDU6SXNzdWUzOTAwODkzMDI=", "number": 344, "title": "Can it support incremental building?", "user": {"login": "BinNong", "id": 20468555, "node_id": "MDQ6VXNlcjIwNDY4NTU1", "avatar_url": "https://avatars2.githubusercontent.com/u/20468555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BinNong", "html_url": "https://github.com/BinNong", "followers_url": "https://api.github.com/users/BinNong/followers", "following_url": "https://api.github.com/users/BinNong/following{/other_user}", "gists_url": "https://api.github.com/users/BinNong/gists{/gist_id}", "starred_url": "https://api.github.com/users/BinNong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BinNong/subscriptions", "organizations_url": "https://api.github.com/users/BinNong/orgs", "repos_url": "https://api.github.com/users/BinNong/repos", "events_url": "https://api.github.com/users/BinNong/events{/privacy}", "received_events_url": "https://api.github.com/users/BinNong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-12-12T06:56:20Z", "updated_at": "2018-12-12T13:25:10Z", "closed_at": "2018-12-12T13:25:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "when I load an existing index, can I add an new vector to the index rather re-train from scratch?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/338", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/338/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/338/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/338/events", "html_url": "https://github.com/spotify/annoy/issues/338", "id": 387419025, "node_id": "MDU6SXNzdWUzODc0MTkwMjU=", "number": 338, "title": "What is the default value of n_trees when using a.build(-1)?", "user": {"login": "ArielSSchwartz", "id": 3607224, "node_id": "MDQ6VXNlcjM2MDcyMjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/3607224?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ArielSSchwartz", "html_url": "https://github.com/ArielSSchwartz", "followers_url": "https://api.github.com/users/ArielSSchwartz/followers", "following_url": "https://api.github.com/users/ArielSSchwartz/following{/other_user}", "gists_url": "https://api.github.com/users/ArielSSchwartz/gists{/gist_id}", "starred_url": "https://api.github.com/users/ArielSSchwartz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ArielSSchwartz/subscriptions", "organizations_url": "https://api.github.com/users/ArielSSchwartz/orgs", "repos_url": "https://api.github.com/users/ArielSSchwartz/repos", "events_url": "https://api.github.com/users/ArielSSchwartz/events{/privacy}", "received_events_url": "https://api.github.com/users/ArielSSchwartz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-04T18:22:04Z", "updated_at": "2019-03-26T02:49:20Z", "closed_at": "2018-12-04T18:23:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "What is the default value of `n_trees` when using `a.build(-1)` as in [simple_test.py](https://github.com/spotify/annoy/blob/8729dccb7b4b4a9d3283531dbe5705eb98d52296/examples/simple_test.py)? Is there a way to get the number of trees of a loaded index? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/337", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/337/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/337/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/337/events", "html_url": "https://github.com/spotify/annoy/issues/337", "id": 386869691, "node_id": "MDU6SXNzdWUzODY4Njk2OTE=", "number": 337, "title": "How can I write data to an index in this format?", "user": {"login": "arpsyapathy", "id": 29089769, "node_id": "MDQ6VXNlcjI5MDg5NzY5", "avatar_url": "https://avatars3.githubusercontent.com/u/29089769?v=4", "gravatar_id": "", "url": "https://api.github.com/users/arpsyapathy", "html_url": "https://github.com/arpsyapathy", "followers_url": "https://api.github.com/users/arpsyapathy/followers", "following_url": "https://api.github.com/users/arpsyapathy/following{/other_user}", "gists_url": "https://api.github.com/users/arpsyapathy/gists{/gist_id}", "starred_url": "https://api.github.com/users/arpsyapathy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/arpsyapathy/subscriptions", "organizations_url": "https://api.github.com/users/arpsyapathy/orgs", "repos_url": "https://api.github.com/users/arpsyapathy/repos", "events_url": "https://api.github.com/users/arpsyapathy/events{/privacy}", "received_events_url": "https://api.github.com/users/arpsyapathy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-12-03T15:27:45Z", "updated_at": "2018-12-07T15:08:32Z", "closed_at": "2018-12-07T15:08:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\nI have several objects. For each there are properties \"name\",\"link\", \" encoding\"\r\nLike this:\r\nalex => (age = 20)\r\n             (link = http://alex.site)\r\n             (encoding = [1,3,4,5,6,7])\r\n\r\nHow can I write data to an index in this format?\r\nOr i can write this to Pickle and than load by annoy?\r\n\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/336", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/336/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/336/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/336/events", "html_url": "https://github.com/spotify/annoy/issues/336", "id": 386074256, "node_id": "MDU6SXNzdWUzODYwNzQyNTY=", "number": 336, "title": "Faster search face in base with more than 1 million images.", "user": {"login": "arpsyapathy", "id": 29089769, "node_id": "MDQ6VXNlcjI5MDg5NzY5", "avatar_url": "https://avatars3.githubusercontent.com/u/29089769?v=4", "gravatar_id": "", "url": "https://api.github.com/users/arpsyapathy", "html_url": "https://github.com/arpsyapathy", "followers_url": "https://api.github.com/users/arpsyapathy/followers", "following_url": "https://api.github.com/users/arpsyapathy/following{/other_user}", "gists_url": "https://api.github.com/users/arpsyapathy/gists{/gist_id}", "starred_url": "https://api.github.com/users/arpsyapathy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/arpsyapathy/subscriptions", "organizations_url": "https://api.github.com/users/arpsyapathy/orgs", "repos_url": "https://api.github.com/users/arpsyapathy/repos", "events_url": "https://api.github.com/users/arpsyapathy/events{/privacy}", "received_events_url": "https://api.github.com/users/arpsyapathy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-30T07:47:19Z", "updated_at": "2018-11-30T12:48:03Z", "closed_at": "2018-11-30T12:48:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\n\r\nI use for face recognition python library https://github.com/ageitgey/face_recognition\r\nI want to faster to find 1 face in more than 1 million faces.\r\n\r\nFace recognition give me a encodings (a list of 128 real-valued numbers) for each images.\r\n\r\nCan i faster find 1 face in more than 1M faces with Annoy? Find similar with distance?\r\nHow store 1M dataset (or encodings) for this?\r\n\r\nThank you\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/335", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/335/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/335/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/335/events", "html_url": "https://github.com/spotify/annoy/issues/335", "id": 385808472, "node_id": "MDU6SXNzdWUzODU4MDg0NzI=", "number": 335, "title": "Bus error in get_nns_by_vector", "user": {"login": "mxgr7", "id": 4935438, "node_id": "MDQ6VXNlcjQ5MzU0Mzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/4935438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mxgr7", "html_url": "https://github.com/mxgr7", "followers_url": "https://api.github.com/users/mxgr7/followers", "following_url": "https://api.github.com/users/mxgr7/following{/other_user}", "gists_url": "https://api.github.com/users/mxgr7/gists{/gist_id}", "starred_url": "https://api.github.com/users/mxgr7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mxgr7/subscriptions", "organizations_url": "https://api.github.com/users/mxgr7/orgs", "repos_url": "https://api.github.com/users/mxgr7/repos", "events_url": "https://api.github.com/users/mxgr7/events{/privacy}", "received_events_url": "https://api.github.com/users/mxgr7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2018-11-29T16:06:46Z", "updated_at": "2018-12-07T15:06:49Z", "closed_at": "2018-12-07T15:06:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "We are seeing bus errors in production from time to time when calling `get_nns_by_vector`. The process crashes with SIGBUS. We are stuck because we can't answer the following questions:\r\n\r\n1. We are not able to reproduce it in a development environment because we have no idea what could be causing it. Are there any obvious scenarios that would explain the SIGBUS?\r\n2. The core dumps from production don't help us either because we can't get gdb to use the correct symbols and show us function names etc. Is there a way to get that to work without running a debug version of Python in production?\r\n\r\nSome more context: \r\n* We are running two processes, both loading the same index files from disk into memory. \r\n* After the initial loading at startup, one of them becomes the \"query\" process which handles incoming requests by searching the loaded indices. \r\n* The other becomes the \"fetch\" process which monitors the file system for changes to index files and reloads any changed index. \r\n* Once the fetch process finishes reloading an index, the roles reverse and it becomes the \"query\" process while the other becomes the \"fetch\" process.\r\n* These two processes are started from a main process which runs Flask and which is in turn started by uwsgi inside a docker container. uwsgi is configured to use a single process and a single thread.\r\n\r\nAt this point we are running out of ideas and any pointers on what to look at would be greatly appreciated.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/334", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/334/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/334/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/334/events", "html_url": "https://github.com/spotify/annoy/issues/334", "id": 384978137, "node_id": "MDU6SXNzdWUzODQ5NzgxMzc=", "number": 334, "title": "Installing on macOS 10.14 with xcode 10", "user": {"login": "ThomasOerkild", "id": 16103356, "node_id": "MDQ6VXNlcjE2MTAzMzU2", "avatar_url": "https://avatars3.githubusercontent.com/u/16103356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ThomasOerkild", "html_url": "https://github.com/ThomasOerkild", "followers_url": "https://api.github.com/users/ThomasOerkild/followers", "following_url": "https://api.github.com/users/ThomasOerkild/following{/other_user}", "gists_url": "https://api.github.com/users/ThomasOerkild/gists{/gist_id}", "starred_url": "https://api.github.com/users/ThomasOerkild/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ThomasOerkild/subscriptions", "organizations_url": "https://api.github.com/users/ThomasOerkild/orgs", "repos_url": "https://api.github.com/users/ThomasOerkild/repos", "events_url": "https://api.github.com/users/ThomasOerkild/events{/privacy}", "received_events_url": "https://api.github.com/users/ThomasOerkild/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-11-27T20:44:45Z", "updated_at": "2018-12-07T18:11:50Z", "closed_at": "2018-12-07T16:25:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "When trying to install using pip on macOS i get the following error:\r\n```\r\nwarning: include path for stdlibc++ headers not found; pass '-std=libc++' on the command line to use the libc++ standard library instead\r\n      [-Wstdlibcxx-not-found]\r\nIn file included from src/annoymodule.cc:15:\r\nsrc/annoylib.h:20:10: fatal error: 'string' file not found\r\n#include <string>\r\n         ^~~~~~~~\r\n1 warning and 1 error generated.\r\nerror: command 'gcc' failed with exit status 1\r\n```\r\n\r\nIt seems that the `stdlibc++` headers have been [deprecated in xcode 10](https://stackoverflow.com/questions/51060596/ld-library-not-found-for-lstdc-6).\r\n\r\nAny ideas?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/spotify/annoy/issues/333", "repository_url": "https://api.github.com/repos/spotify/annoy", "labels_url": "https://api.github.com/repos/spotify/annoy/issues/333/labels{/name}", "comments_url": "https://api.github.com/repos/spotify/annoy/issues/333/comments", "events_url": "https://api.github.com/repos/spotify/annoy/issues/333/events", "html_url": "https://github.com/spotify/annoy/issues/333", "id": 379543836, "node_id": "MDU6SXNzdWUzNzk1NDM4MzY=", "number": 333, "title": "Feature Request: Index building directly from vector data serialized on disk.", "user": {"login": "windowpane", "id": 3112214, "node_id": "MDQ6VXNlcjMxMTIyMTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/3112214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/windowpane", "html_url": "https://github.com/windowpane", "followers_url": "https://api.github.com/users/windowpane/followers", "following_url": "https://api.github.com/users/windowpane/following{/other_user}", "gists_url": "https://api.github.com/users/windowpane/gists{/gist_id}", "starred_url": "https://api.github.com/users/windowpane/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/windowpane/subscriptions", "organizations_url": "https://api.github.com/users/windowpane/orgs", "repos_url": "https://api.github.com/users/windowpane/repos", "events_url": "https://api.github.com/users/windowpane/events{/privacy}", "received_events_url": "https://api.github.com/users/windowpane/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-11T17:27:59Z", "updated_at": "2018-11-11T18:16:06Z", "closed_at": "2018-11-11T18:16:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\n*Request:* Feature which enables building the tree from data stored temporally on disk, in order to support construction of massive data sets (+1B rows) that don't fit entirely into memory.\r\n\r\nRather than store all vectors in memory to build the index, build the index from serialized vectors on disk.\r\n\r\n*Known Drawbacks:* There would inevitable be some speed trade-off in construction time of the index, but for very large datasets there is no other way around it!\r\n\r\n*Reasoning*: I've looked everywhere, no other solutions seem to offer a scalable solution that can build the index from disk if you have limited RAM. All other solutions i've seen are in memory, and database solutions appear non-existent for higher dimension (+8D) knn search. \r\n\r\nAnnoy appears to be the project that would be most suitable for adding this feature, as it already has mem-mapping implemented.\r\n\r\n\r\nExample use case:\r\n```\r\n# Length of item vector 128dimension with fixed leaf size\r\n# and temporary file path specifying that data is written to disk before building\r\nf = 128\r\nt = AnnoyIndex(f, leaf_size = 1000, temp_file='raw_vectors.h5py)  \r\n\r\nfor i in xrange(int(1*1e9)):\r\n    v = [random.gauss(0, 1) for z in xrange(f)]\r\n    t.add_item(i, v)  # will be written to disk before index is built\r\n\r\nt.build_and_save(10, 'test.ann') # 10 trees built using the serialized data and written directly to disk.\r\n```\r\n\r\nsome perks:\r\n  - able to scale to  +billions of rows by enabling:\r\n    - massive single node storage using disk space\r\n    - replicated storage of the index on multiple data nodes\r\n   - cheapest way to scale (disk space is cheap compared to RAM)\r\n\r\nQuestions:\r\n  - At what point would it be useful to integrate the c++ code as a plug for a database system like solr, elasticsearch, mongo or cassandra?\r\n  - is it possible to represent the tree using dictionairy objects in python where the leaves are numpy/dask arrays in order to leverage the existing features of nosql document stores?", "performed_via_github_app": null, "score": 1.0}]}