{"total_count": 5, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/19", "repository_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling", "labels_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/19/labels{/name}", "comments_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/19/comments", "events_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/19/events", "html_url": "https://github.com/julioasotodv/spark-df-profiling/issues/19", "id": 387069330, "node_id": "MDU6SXNzdWUzODcwNjkzMzA=", "number": 19, "title": "Wrong Error being caught?", "user": {"login": "dNavalta", "id": 12104369, "node_id": "MDQ6VXNlcjEyMTA0MzY5", "avatar_url": "https://avatars3.githubusercontent.com/u/12104369?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dNavalta", "html_url": "https://github.com/dNavalta", "followers_url": "https://api.github.com/users/dNavalta/followers", "following_url": "https://api.github.com/users/dNavalta/following{/other_user}", "gists_url": "https://api.github.com/users/dNavalta/gists{/gist_id}", "starred_url": "https://api.github.com/users/dNavalta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dNavalta/subscriptions", "organizations_url": "https://api.github.com/users/dNavalta/orgs", "repos_url": "https://api.github.com/users/dNavalta/repos", "events_url": "https://api.github.com/users/dNavalta/events{/privacy}", "received_events_url": "https://api.github.com/users/dNavalta/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-12-04T00:44:27Z", "updated_at": "2018-12-12T00:13:30Z", "closed_at": "2018-12-12T00:13:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "With pandas 0.23.4 I'm getting the following Error:\r\n```\r\n File \"/Users/dnavalta/miniconda/envs/bnv/lib/python3.6/site-packages/spark_df_profiling/__init__.py\", line 19, in __init__\r\n    description_set = describe(df, bins=bins, corr_reject=corr_reject, **kwargs)\r\n  File \"/Users/dnavalta/miniconda/envs/bnv/lib/python3.6/site-packages/spark_df_profiling/base.py\", line 480, in describe\r\n    variable_stats = variable_stats.drop(\"value_counts\")\r\n  File \"/Users/dnavalta/miniconda/envs/bnv/lib/python3.6/site-packages/pandas/core/frame.py\", line 3697, in drop\r\n    errors=errors)\r\n  File \"/Users/dnavalta/miniconda/envs/bnv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3111, in drop\r\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\r\n  File \"/Users/dnavalta/miniconda/envs/bnv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3143, in _drop_axis\r\n    new_axis = axis.drop(labels, errors=errors)\r\n  File \"/Users/dnavalta/miniconda/envs/bnv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 4404, in drop\r\n    '{} not found in axis'.format(labels[mask]))\r\nKeyError: \"['value_counts'] not found in axis\"\r\n```\r\n\r\nNot really sure what 'value_counts' is for so I can't really predict where this issue is going to come up, but it's not every time. \r\nChanging line 514 (in MASTER) in `base.py` to read `except(KeyError, ValueError):` fixed the problem for me. I'm going to make a pull request for this.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/8", "repository_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling", "labels_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/8/labels{/name}", "comments_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/8/comments", "events_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/8/events", "html_url": "https://github.com/julioasotodv/spark-df-profiling/issues/8", "id": 240652193, "node_id": "MDU6SXNzdWUyNDA2NTIxOTM=", "number": 8, "title": "can i use the same library in scala", "user": {"login": "mahipalreddyv", "id": 29921650, "node_id": "MDQ6VXNlcjI5OTIxNjUw", "avatar_url": "https://avatars1.githubusercontent.com/u/29921650?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mahipalreddyv", "html_url": "https://github.com/mahipalreddyv", "followers_url": "https://api.github.com/users/mahipalreddyv/followers", "following_url": "https://api.github.com/users/mahipalreddyv/following{/other_user}", "gists_url": "https://api.github.com/users/mahipalreddyv/gists{/gist_id}", "starred_url": "https://api.github.com/users/mahipalreddyv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mahipalreddyv/subscriptions", "organizations_url": "https://api.github.com/users/mahipalreddyv/orgs", "repos_url": "https://api.github.com/users/mahipalreddyv/repos", "events_url": "https://api.github.com/users/mahipalreddyv/events{/privacy}", "received_events_url": "https://api.github.com/users/mahipalreddyv/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-07-05T13:33:48Z", "updated_at": "2017-07-07T11:51:15Z", "closed_at": "2017-07-07T11:51:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi \r\ni am trying to use this implement in the Scala note books and is it possible", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/6", "repository_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling", "labels_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/6/labels{/name}", "comments_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/6/comments", "events_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/6/events", "html_url": "https://github.com/julioasotodv/spark-df-profiling/issues/6", "id": 200424646, "node_id": "MDU6SXNzdWUyMDA0MjQ2NDY=", "number": 6, "title": "profile multiple files in parallel", "user": {"login": "mike-vogel", "id": 3799313, "node_id": "MDQ6VXNlcjM3OTkzMTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3799313?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mike-vogel", "html_url": "https://github.com/mike-vogel", "followers_url": "https://api.github.com/users/mike-vogel/followers", "following_url": "https://api.github.com/users/mike-vogel/following{/other_user}", "gists_url": "https://api.github.com/users/mike-vogel/gists{/gist_id}", "starred_url": "https://api.github.com/users/mike-vogel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mike-vogel/subscriptions", "organizations_url": "https://api.github.com/users/mike-vogel/orgs", "repos_url": "https://api.github.com/users/mike-vogel/repos", "events_url": "https://api.github.com/users/mike-vogel/events{/privacy}", "received_events_url": "https://api.github.com/users/mike-vogel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-01-12T17:06:33Z", "updated_at": "2017-01-15T22:41:01Z", "closed_at": "2017-01-15T22:41:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there a way to profile multiple files in parallel.  When I start a thread for each file using the same spark-context I get random failures from matplotlib apparently due to it not being thread safe.  ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/5", "repository_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling", "labels_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/5/labels{/name}", "comments_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/5/comments", "events_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/5/events", "html_url": "https://github.com/julioasotodv/spark-df-profiling/issues/5", "id": 174613789, "node_id": "MDU6SXNzdWUxNzQ2MTM3ODk=", "number": 5, "title": "Error - 'DataFrame' object has no attribute 'sort_values'", "user": {"login": "zakipatel", "id": 705670, "node_id": "MDQ6VXNlcjcwNTY3MA==", "avatar_url": "https://avatars0.githubusercontent.com/u/705670?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zakipatel", "html_url": "https://github.com/zakipatel", "followers_url": "https://api.github.com/users/zakipatel/followers", "following_url": "https://api.github.com/users/zakipatel/following{/other_user}", "gists_url": "https://api.github.com/users/zakipatel/gists{/gist_id}", "starred_url": "https://api.github.com/users/zakipatel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zakipatel/subscriptions", "organizations_url": "https://api.github.com/users/zakipatel/orgs", "repos_url": "https://api.github.com/users/zakipatel/repos", "events_url": "https://api.github.com/users/zakipatel/events{/privacy}", "received_events_url": "https://api.github.com/users/zakipatel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-09-01T20:07:57Z", "updated_at": "2017-07-07T09:33:10Z", "closed_at": "2017-07-07T09:33:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Running on Spark 2.0: \n\nWhen i run the following command on a data frame with one integer column, I get a a result. \n\nreport = spark_df_profiling.ProfileReport(df)\n\nHowever, if there are additional (non-integer) columns in the data frame, i get the error : - 'DataFrame' object has no attribute 'sort_values'\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/1", "repository_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling", "labels_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/1/labels{/name}", "comments_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/1/comments", "events_url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/issues/1/events", "html_url": "https://github.com/julioasotodv/spark-df-profiling/issues/1", "id": 169357240, "node_id": "MDU6SXNzdWUxNjkzNTcyNDA=", "number": 1, "title": "Distinct count in categorical columns with missings", "user": {"login": "julioasotodv", "id": 20630819, "node_id": "MDQ6VXNlcjIwNjMwODE5", "avatar_url": "https://avatars2.githubusercontent.com/u/20630819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/julioasotodv", "html_url": "https://github.com/julioasotodv", "followers_url": "https://api.github.com/users/julioasotodv/followers", "following_url": "https://api.github.com/users/julioasotodv/following{/other_user}", "gists_url": "https://api.github.com/users/julioasotodv/gists{/gist_id}", "starred_url": "https://api.github.com/users/julioasotodv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/julioasotodv/subscriptions", "organizations_url": "https://api.github.com/users/julioasotodv/orgs", "repos_url": "https://api.github.com/users/julioasotodv/repos", "events_url": "https://api.github.com/users/julioasotodv/events{/privacy}", "received_events_url": "https://api.github.com/users/julioasotodv/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 413966724, "node_id": "MDU6TGFiZWw0MTM5NjY3MjQ=", "url": "https://api.github.com/repos/julioasotodv/spark-df-profiling/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "julioasotodv", "id": 20630819, "node_id": "MDQ6VXNlcjIwNjMwODE5", "avatar_url": "https://avatars2.githubusercontent.com/u/20630819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/julioasotodv", "html_url": "https://github.com/julioasotodv", "followers_url": "https://api.github.com/users/julioasotodv/followers", "following_url": "https://api.github.com/users/julioasotodv/following{/other_user}", "gists_url": "https://api.github.com/users/julioasotodv/gists{/gist_id}", "starred_url": "https://api.github.com/users/julioasotodv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/julioasotodv/subscriptions", "organizations_url": "https://api.github.com/users/julioasotodv/orgs", "repos_url": "https://api.github.com/users/julioasotodv/repos", "events_url": "https://api.github.com/users/julioasotodv/events{/privacy}", "received_events_url": "https://api.github.com/users/julioasotodv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "julioasotodv", "id": 20630819, "node_id": "MDQ6VXNlcjIwNjMwODE5", "avatar_url": "https://avatars2.githubusercontent.com/u/20630819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/julioasotodv", "html_url": "https://github.com/julioasotodv", "followers_url": "https://api.github.com/users/julioasotodv/followers", "following_url": "https://api.github.com/users/julioasotodv/following{/other_user}", "gists_url": "https://api.github.com/users/julioasotodv/gists{/gist_id}", "starred_url": "https://api.github.com/users/julioasotodv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/julioasotodv/subscriptions", "organizations_url": "https://api.github.com/users/julioasotodv/orgs", "repos_url": "https://api.github.com/users/julioasotodv/repos", "events_url": "https://api.github.com/users/julioasotodv/events{/privacy}", "received_events_url": "https://api.github.com/users/julioasotodv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2016-08-04T11:57:36Z", "updated_at": "2016-08-21T20:12:42Z", "closed_at": "2016-08-21T20:12:42Z", "author_association": "OWNER", "active_lock_reason": null, "body": "Since the count distinct in Spark SQL omits missing values, we should add 1 to the distinct count in such cases\n", "performed_via_github_app": null, "score": 1.0}]}