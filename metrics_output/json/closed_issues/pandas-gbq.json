{"total_count": 138, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/320", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/320/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/320/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/320/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/320", "id": 631603179, "node_id": "MDU6SXNzdWU2MzE2MDMxNzk=", "number": 320, "title": "ENH: add possibility to pass labels", "user": {"login": "nicoa", "id": 2863863, "node_id": "MDQ6VXNlcjI4NjM4NjM=", "avatar_url": "https://avatars1.githubusercontent.com/u/2863863?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nicoa", "html_url": "https://github.com/nicoa", "followers_url": "https://api.github.com/users/nicoa/followers", "following_url": "https://api.github.com/users/nicoa/following{/other_user}", "gists_url": "https://api.github.com/users/nicoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/nicoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nicoa/subscriptions", "organizations_url": "https://api.github.com/users/nicoa/orgs", "repos_url": "https://api.github.com/users/nicoa/repos", "events_url": "https://api.github.com/users/nicoa/events{/privacy}", "received_events_url": "https://api.github.com/users/nicoa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-05T13:45:34Z", "updated_at": "2020-06-08T09:01:43Z", "closed_at": "2020-06-08T09:01:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "As far as I see pandas-gbq currently doesn't support passing [labels](https://cloud.google.com/bigquery/docs/adding-labels?hl=de#job-label). \r\n\r\nThe underlying google-cloud-bigquery package technically supports this both for queries as well as for tables from what I can see for example [here](https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.QueryJobConfig.html#google.cloud.bigquery.job.QueryJobConfig). \r\n\r\nWould this be an option for you to implement / support? Or is it already supported and I'm not finding it in the documentation?\r\n\r\nThanks for your support!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/315", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/315/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/315/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/315/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/315", "id": 577341803, "node_id": "MDU6SXNzdWU1NzczNDE4MDM=", "number": 315, "title": "Pandas should get the schema from bigquery if pushing to a table that already exists", "user": {"login": "ShantanuKumar", "id": 1596142, "node_id": "MDQ6VXNlcjE1OTYxNDI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1596142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ShantanuKumar", "html_url": "https://github.com/ShantanuKumar", "followers_url": "https://api.github.com/users/ShantanuKumar/followers", "following_url": "https://api.github.com/users/ShantanuKumar/following{/other_user}", "gists_url": "https://api.github.com/users/ShantanuKumar/gists{/gist_id}", "starred_url": "https://api.github.com/users/ShantanuKumar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ShantanuKumar/subscriptions", "organizations_url": "https://api.github.com/users/ShantanuKumar/orgs", "repos_url": "https://api.github.com/users/ShantanuKumar/repos", "events_url": "https://api.github.com/users/ShantanuKumar/events{/privacy}", "received_events_url": "https://api.github.com/users/ShantanuKumar/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-03-07T14:25:53Z", "updated_at": "2020-04-30T19:16:56Z", "closed_at": "2020-04-29T20:20:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Right now, when pushing new data to an **already existing table** using `to_gbq`, with option `if_exists=append`, but no explicit `table_schema`, pandas generates a default table schema, where the `mode`  of the column, which takes value either `REQUIRED` or `NULLABLE`, by default is always `NULLABLE`.  \r\n\r\nIt would make sense for pandas to fetch schema, and apply those for case where `if_exists=append` instead of passing a `NULLABLE` mode.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/307", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/307/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/307/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/307/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/307", "id": 550408395, "node_id": "MDU6SXNzdWU1NTA0MDgzOTU=", "number": 307, "title": "Escaped query params for `read_gbq`", "user": {"login": "acarl005", "id": 8334252, "node_id": "MDQ6VXNlcjgzMzQyNTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8334252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acarl005", "html_url": "https://github.com/acarl005", "followers_url": "https://api.github.com/users/acarl005/followers", "following_url": "https://api.github.com/users/acarl005/following{/other_user}", "gists_url": "https://api.github.com/users/acarl005/gists{/gist_id}", "starred_url": "https://api.github.com/users/acarl005/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acarl005/subscriptions", "organizations_url": "https://api.github.com/users/acarl005/orgs", "repos_url": "https://api.github.com/users/acarl005/repos", "events_url": "https://api.github.com/users/acarl005/events{/privacy}", "received_events_url": "https://api.github.com/users/acarl005/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980921, "node_id": "MDU6TGFiZWw1MzQ5ODA5MjE=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20question", "name": "type: question", "color": "c5def5", "default": false, "description": "Request for information or clarification. Not an issue."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-15T20:20:00Z", "updated_at": "2020-01-28T17:05:25Z", "closed_at": "2020-01-28T17:05:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there a way to use [parameterized queries](https://cloud.google.com/bigquery/docs/parameterized-queries) so that the parameters are scrubbed for potential malicious input?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/306", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/306/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/306/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/306/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/306", "id": 541691139, "node_id": "MDU6SXNzdWU1NDE2OTExMzk=", "number": 306, "title": "ENH: restrict to Python 3.5 and higher in setup.py", "user": {"login": "nicoa", "id": 2863863, "node_id": "MDQ6VXNlcjI4NjM4NjM=", "avatar_url": "https://avatars1.githubusercontent.com/u/2863863?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nicoa", "html_url": "https://github.com/nicoa", "followers_url": "https://api.github.com/users/nicoa/followers", "following_url": "https://api.github.com/users/nicoa/following{/other_user}", "gists_url": "https://api.github.com/users/nicoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/nicoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nicoa/subscriptions", "organizations_url": "https://api.github.com/users/nicoa/orgs", "repos_url": "https://api.github.com/users/nicoa/repos", "events_url": "https://api.github.com/users/nicoa/events{/privacy}", "received_events_url": "https://api.github.com/users/nicoa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}, {"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-12-23T10:32:15Z", "updated_at": "2020-02-24T14:11:52Z", "closed_at": "2020-02-24T14:11:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Some Foreword: please ask me for further information/MWE if necessary, I hope it will be understandable without for now:\r\n\r\nWe expercienced some error like the following:\r\n```\r\nMYENV/local/lib/python2.7/site-packages/pandas/io/common.pyc in writerows(self, rows)\r\n    549             data = self.encoder.encode(data)\r\n    550             # write to the target stream\r\n--> 551             self.stream.write(data)\r\n    552             # empty queue\r\n    553             self.queue.truncate(0)\r\n\r\nTypeError: unicode argument expected, got 'str'\r\n```\r\n\r\nThis seems to appear in version 0.13.0, pinning back to 0.12.0 seems to work.\r\n\r\nStill, referring to the changelog they are both not supported under python 2 (under which this occurred). Is it expected behaviour they get still installed? Is this a problem on pypi side or can it be fixed on the package site?\r\n\r\nThanks for your efforts!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/305", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/305/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/305/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/305/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/305", "id": 537867913, "node_id": "MDU6SXNzdWU1Mzc4Njc5MTM=", "number": 305, "title": "Big Query Storage API 400ing", "user": {"login": "megancooper", "id": 8683055, "node_id": "MDQ6VXNlcjg2ODMwNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/8683055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/megancooper", "html_url": "https://github.com/megancooper", "followers_url": "https://api.github.com/users/megancooper/followers", "following_url": "https://api.github.com/users/megancooper/following{/other_user}", "gists_url": "https://api.github.com/users/megancooper/gists{/gist_id}", "starred_url": "https://api.github.com/users/megancooper/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/megancooper/subscriptions", "organizations_url": "https://api.github.com/users/megancooper/orgs", "repos_url": "https://api.github.com/users/megancooper/repos", "events_url": "https://api.github.com/users/megancooper/events{/privacy}", "received_events_url": "https://api.github.com/users/megancooper/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980921, "node_id": "MDU6TGFiZWw1MzQ5ODA5MjE=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20question", "name": "type: question", "color": "c5def5", "default": false, "description": "Request for information or clarification. Not an issue."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-14T05:06:33Z", "updated_at": "2019-12-16T19:11:45Z", "closed_at": "2019-12-16T19:11:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am attempting to query BigQuery storage api from a spark script running on AWS EMR. For some all requests to BigQuery storage api are 400ing and are (redirecting?) to the BigQuery API. (See images below). Why is this happening?\r\n\r\nAll of my queries are `select count(*) from dataset.table ... ` queries that are quick and have minimal filters.\r\n```\r\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/hadoop/credentials.json'\r\npandas_gbq.context.use_bqstorage_api = True\r\ndf = pandas_gbq.read_gbq(query, \r\n        project_id=\"<project>\", \r\n        use_bqstorage_api=True)\r\ncount=  df['f0_'][0]\r\n```\r\n\r\n**BigQuery Storage API**\r\n\r\n![Screen Shot 2019-12-13 at 11 02 19 PM](https://user-images.githubusercontent.com/8683055/70843720-f786eb80-1dfc-11ea-9d98-ce930aea28fd.png)\r\n\r\n\r\n**BigQuery API**\r\n\r\n![Screen Shot 2019-12-13 at 11 06 14 PM](https://user-images.githubusercontent.com/8683055/70843741-3026c500-1dfd-11ea-878c-a9d495d0f6bc.png)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/304", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/304/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/304/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/304/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/304", "id": 537298155, "node_id": "MDU6SXNzdWU1MzcyOTgxNTU=", "number": 304, "title": "Import error with pandas_gbq", "user": {"login": "winsonhys", "id": 35393818, "node_id": "MDQ6VXNlcjM1MzkzODE4", "avatar_url": "https://avatars2.githubusercontent.com/u/35393818?v=4", "gravatar_id": "", "url": "https://api.github.com/users/winsonhys", "html_url": "https://github.com/winsonhys", "followers_url": "https://api.github.com/users/winsonhys/followers", "following_url": "https://api.github.com/users/winsonhys/following{/other_user}", "gists_url": "https://api.github.com/users/winsonhys/gists{/gist_id}", "starred_url": "https://api.github.com/users/winsonhys/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/winsonhys/subscriptions", "organizations_url": "https://api.github.com/users/winsonhys/orgs", "repos_url": "https://api.github.com/users/winsonhys/repos", "events_url": "https://api.github.com/users/winsonhys/events{/privacy}", "received_events_url": "https://api.github.com/users/winsonhys/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-12-13T01:21:10Z", "updated_at": "2020-04-10T09:09:39Z", "closed_at": "2019-12-23T14:22:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "There's a bug with the most recent google bigquery library. Hence, this error occurs in pandas-gbq\r\n\r\n`ImportError: pandas-gbq requires google-cloud-bigquery: cannot import name 'collections_abc'`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/301", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/301/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/301/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/301/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/301", "id": 536597376, "node_id": "MDU6SXNzdWU1MzY1OTczNzY=", "number": 301, "title": "CLN: Throw NotImplemented error when `private_key` is used", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535013928, "node_id": "MDU6TGFiZWw1MzUwMTM5Mjg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20cleanup", "name": "type: cleanup", "color": "c5def5", "default": false, "description": "An internal cleanup or hygiene concern."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-12-11T20:29:42Z", "updated_at": "2019-12-12T22:40:58Z", "closed_at": "2019-12-12T22:40:58Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "We've had a deprecation warning on `private_key` for quite some time now. We should go ahead and throw an error when it is supplied, in preparation for pandas 1.0.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/299", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/299/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/299/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/299/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/299", "id": 533545461, "node_id": "MDU6SXNzdWU1MzM1NDU0NjE=", "number": 299, "title": "AttributeError when use_bqstorage_api=True on empty df", "user": {"login": "Bizetremi", "id": 29840376, "node_id": "MDQ6VXNlcjI5ODQwMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/29840376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Bizetremi", "html_url": "https://github.com/Bizetremi", "followers_url": "https://api.github.com/users/Bizetremi/followers", "following_url": "https://api.github.com/users/Bizetremi/following{/other_user}", "gists_url": "https://api.github.com/users/Bizetremi/gists{/gist_id}", "starred_url": "https://api.github.com/users/Bizetremi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Bizetremi/subscriptions", "organizations_url": "https://api.github.com/users/Bizetremi/orgs", "repos_url": "https://api.github.com/users/Bizetremi/repos", "events_url": "https://api.github.com/users/Bizetremi/events{/privacy}", "received_events_url": "https://api.github.com/users/Bizetremi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1831643007, "node_id": "MDU6TGFiZWwxODMxNjQzMDA3", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/priority:%20p1", "name": "priority: p1", "color": "ffa03e", "default": false, "description": "Medium priority. Will be fixed prior to next release."}, {"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-12-05T19:22:45Z", "updated_at": "2020-02-13T16:57:36Z", "closed_at": "2020-02-13T16:57:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "The following error is thrown when using pandas_gbq.read_gbq with use_bqstorage_api=True when the query returns no data.\r\n\r\n\r\n  (use_bqstorage_api=True)\r\n  File '/env/local/lib/python3.7/site-packages/pandas_gbq/gbq.py', line 1034, in read_gbq\r\n    progress_bar_type=progress_bar_type,\r\n  File '/env/local/lib/python3.7/site-packages/pandas_gbq/gbq.py', line 532, in run_query\r\n    progress_bar_type=progress_bar_type,\r\n  File '/env/local/lib/python3.7/site-packages/pandas_gbq/gbq.py', line 576, in _download_results\r\n    df = _localize_df(schema_fields, df)\r\n  File '/env/local/lib/python3.7/site-packages/pandas_gbq/gbq.py', line 808, in _localize_df\r\n    if field['type'].upper() == 'TIMESTAMP' and df[column].dt.tz is None:\r\n  File '/env/local/lib/python3.7/site-packages/pandas/core/generic.py', line 5175, in __getattr__\r\n    return object.__getattribute__(self, name)\r\n  File '/env/local/lib/python3.7/site-packages/pandas/core/accessor.py', line 175, in __get__\r\n    accessor_obj = self._accessor(obj)\r\n  File '/env/local/lib/python3.7/site-packages/pandas/core/indexes/accessors.py', line 343, in __new__\r\n    raise AttributeError('Can only use .dt accessor with datetimelike ' 'values')\r\nAttributeError: Can only use .dt accessor with datetimelike values", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/296", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/296/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/296/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/296/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/296", "id": 528273694, "node_id": "MDU6SXNzdWU1MjgyNzM2OTQ=", "number": 296, "title": "BUG: tests fail due to missing progress_bar_type argument", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1697634762, "node_id": "MDU6TGFiZWwxNjk3NjM0NzYy", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/priority:%20p0", "name": "priority: p0", "color": "b60205", "default": false, "description": "P0 implies highest priority (e.g. blocking imminent release)."}, {"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-11-25T18:54:50Z", "updated_at": "2019-11-25T21:41:41Z", "closed_at": "2019-11-25T21:41:41Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Example test failure: https://circleci.com/gh/tswast/pandas-gbq/699?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n\r\n```\r\n____ TestReadGBQIntegration.test_should_properly_handle_null_timestamp[env] ____\r\n\r\nself = <tests.system.test_gbq.TestReadGBQIntegration object at 0x7f6326df4278>\r\nproject_id = '****************'\r\n\r\n    def test_should_properly_handle_null_timestamp(self, project_id):\r\n        query = \"SELECT TIMESTAMP(NULL) AS null_timestamp\"\r\n        df = gbq.read_gbq(\r\n            query,\r\n            project_id=project_id,\r\n            credentials=self.credentials,\r\n>           dialect=\"legacy\",\r\n        )\r\n\r\ntests/system/test_gbq.py:386: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\npandas_gbq/gbq.py:1034: in read_gbq\r\n    progress_bar_type=progress_bar_type,\r\npandas_gbq/gbq.py:532: in run_query\r\n    progress_bar_type=progress_bar_type,\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <pandas_gbq.gbq.GbqConnector object at 0x7f6326ddf2e8>\r\nquery_job = <google.cloud.bigquery.job.QueryJob object at 0x7f632259d630>\r\nmax_results = None, progress_bar_type = 'tqdm'\r\n\r\n    def _download_results(\r\n        self, query_job, max_results=None, progress_bar_type=None\r\n    ):\r\n        # No results are desired, so don't bother downloading anything.\r\n        if max_results == 0:\r\n            return None\r\n    \r\n        try:\r\n            bqstorage_client = None\r\n            if max_results is None:\r\n                # Only use the BigQuery Storage API if the full result set is requested.\r\n                bqstorage_client = _make_bqstorage_client(\r\n                    self.use_bqstorage_api, self.credentials\r\n                )\r\n    \r\n            query_job.result()\r\n            # Get the table schema, so that we can list rows.\r\n            destination = self.client.get_table(query_job.destination)\r\n            rows_iter = self.client.list_rows(\r\n                destination, max_results=max_results\r\n            )\r\n    \r\n            schema_fields = [field.to_api_repr() for field in rows_iter.schema]\r\n            nullsafe_dtypes = _bqschema_to_nullsafe_dtypes(schema_fields)\r\n            df = rows_iter.to_dataframe(\r\n                dtypes=nullsafe_dtypes,\r\n                bqstorage_client=bqstorage_client,\r\n>               progress_bar_type=progress_bar_type,\r\n            )\r\nE           TypeError: to_dataframe() got an unexpected keyword argument 'progress_bar_type'\r\n\r\npandas_gbq/gbq.py:562: TypeError\r\n```\r\n\r\nOlder versions of the `google-cloud-bigquery` client don't have a `progress_bar_type` argument.\r\n\r\n**Proposed solution:**\r\n\r\nDetect if the minimum version of `google-cloud-bigquery` is installed and only then populate the `progress_bar_type` argument.\r\n\r\n**Alternatives considered:**\r\n\r\n- Increment the minimum version of `google-cloud-bigquery`. As much as possible, we should allow any version of `google-cloud-bigquery`. The wider we can make the allowed package versions, the less likely it is that people will encounter version conflicts.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/294", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/294/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/294/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/294/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/294", "id": 520287695, "node_id": "MDU6SXNzdWU1MjAyODc2OTU=", "number": 294, "title": "BUG: potential resource leak when using BigQuery Storage API", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-08T23:51:18Z", "updated_at": "2019-11-25T22:10:40Z", "closed_at": "2019-11-25T22:10:40Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "It came to my attention in https://github.com/googleapis/google-cloud-python/issues/9457 that when a gRPC Google Cloud client object is destroyed, it doesn't clean up all the underlying resources from the gRPC transport layer.\r\n\r\nI'd like to address this at the Google Cloud client level by providing better support for short-lived gRPC clients, but in the meantime, we need to call `bqstorage_client.transport.close()` when we are done using a BigQuery Storage API client.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/290", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/290/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/290/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/290/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/290", "id": 500399082, "node_id": "MDU6SXNzdWU1MDAzOTkwODI=", "number": 290, "title": "Querying large amounts of data without creating a destination table", "user": {"login": "Mikerah", "id": 4249799, "node_id": "MDQ6VXNlcjQyNDk3OTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/4249799?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mikerah", "html_url": "https://github.com/Mikerah", "followers_url": "https://api.github.com/users/Mikerah/followers", "following_url": "https://api.github.com/users/Mikerah/following{/other_user}", "gists_url": "https://api.github.com/users/Mikerah/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mikerah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mikerah/subscriptions", "organizations_url": "https://api.github.com/users/Mikerah/orgs", "repos_url": "https://api.github.com/users/Mikerah/repos", "events_url": "https://api.github.com/users/Mikerah/events{/privacy}", "received_events_url": "https://api.github.com/users/Mikerah/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980921, "node_id": "MDU6TGFiZWw1MzQ5ODA5MjE=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20question", "name": "type: question", "color": "c5def5", "default": false, "description": "Request for information or clarification. Not an issue."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-09-30T16:56:42Z", "updated_at": "2019-10-09T16:54:54Z", "closed_at": "2019-10-08T23:38:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to load data from BigQuery into a data frame. This is a lot of data, initially requiring the use of `allowLargeResults`. However, every time I query, I use resources that I shouldn't have to be using. Is there a way to query large amount of data from BigQuery without having to create a destination table every time and just store the result in a data frame? \r\n\r\nI am using a jupyter notebook on an AWS instance, if this matters.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/289", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/289/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/289/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/289/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/289", "id": 492346317, "node_id": "MDU6SXNzdWU0OTIzNDYzMTc=", "number": 289, "title": "Is it possible to export data to BigQuery arrays with `to_gbq`?", "user": {"login": "mtchllbrrn", "id": 7254962, "node_id": "MDQ6VXNlcjcyNTQ5NjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/7254962?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mtchllbrrn", "html_url": "https://github.com/mtchllbrrn", "followers_url": "https://api.github.com/users/mtchllbrrn/followers", "following_url": "https://api.github.com/users/mtchllbrrn/following{/other_user}", "gists_url": "https://api.github.com/users/mtchllbrrn/gists{/gist_id}", "starred_url": "https://api.github.com/users/mtchllbrrn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mtchllbrrn/subscriptions", "organizations_url": "https://api.github.com/users/mtchllbrrn/orgs", "repos_url": "https://api.github.com/users/mtchllbrrn/repos", "events_url": "https://api.github.com/users/mtchllbrrn/events{/privacy}", "received_events_url": "https://api.github.com/users/mtchllbrrn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-09-11T16:37:45Z", "updated_at": "2019-09-11T17:13:43Z", "closed_at": "2019-09-11T17:13:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to export a DataFrame to BigQuery with `to_gbq`, and a few columns have array values.  Unfortunately, these get coerced into strings if I rely on the built-in schema inference.  If I manually specify `ARRAY` type in `table_schema` I get this error: \"Invalid value for type: ARRAY is not a valid value.\"\r\n\r\nI see that ARRAY is not listed as a valid type [here](https://pandas-gbq.readthedocs.io/en/latest/writing.html?highlight=schema#inferring-the-table-schema), but I'm having trouble finding any further documentation.  Is this not supported?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/281", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/281/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/281/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/281/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/281", "id": 469360578, "node_id": "MDU6SXNzdWU0NjkzNjA1Nzg=", "number": 281, "title": "ENH: Add user-agent string when constructing BigQuery and BigQuery Storage API clients.", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-17T17:53:22Z", "updated_at": "2019-07-29T16:39:21Z", "closed_at": "2019-07-29T16:39:21Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "It would help me prioritize work on pandas-gbq if Google could see how much BigQuery usage originates from pandas-gbq. Plus, it's actually required by the Google APIs terms of service that we accurately identify our \"application\" accurately in requests to Google APIs.\r\n\r\nTo do this, we need to populate the `user_agent` property of [`google.api_core.client_info.ClientInfo`](https://googleapis.github.io/google-cloud-python/latest/core/client_info.html#google.api_core.client_info.ClientInfo) or [`google.api_core.gapic_v1.client_info.ClientInfo`](https://googleapis.github.io/google-cloud-python/latest/core/client_info.html#google.api_core.gapic_v1.client_info.ClientInfo) when we construct a `bigquery.Client` or `bigquery_storage_v1beta1.Client`, respectively.\r\n\r\nI propose we use the pandas version information in this string, as pandas seems to be the \"application\", since this package exists to ith `pandas.read_gbq`.\r\n\r\n```\r\nbigquery.Client(\r\n    client_info=ClientInfo(\r\n        user_agent=\"pandas-{}\".format(get the pandas version)\r\n    )\r\n)\r\n```\r\n\r\nRelated: https://github.com/googleapis/google-cloud-python/issues/8696", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/280", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/280/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/280/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/280/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/280", "id": 457715196, "node_id": "MDU6SXNzdWU0NTc3MTUxOTY=", "number": 280, "title": "\"Field units already exist in schema\"", "user": {"login": "huntermaxfield", "id": 11686627, "node_id": "MDQ6VXNlcjExNjg2NjI3", "avatar_url": "https://avatars2.githubusercontent.com/u/11686627?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huntermaxfield", "html_url": "https://github.com/huntermaxfield", "followers_url": "https://api.github.com/users/huntermaxfield/followers", "following_url": "https://api.github.com/users/huntermaxfield/following{/other_user}", "gists_url": "https://api.github.com/users/huntermaxfield/gists{/gist_id}", "starred_url": "https://api.github.com/users/huntermaxfield/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huntermaxfield/subscriptions", "organizations_url": "https://api.github.com/users/huntermaxfield/orgs", "repos_url": "https://api.github.com/users/huntermaxfield/repos", "events_url": "https://api.github.com/users/huntermaxfield/events{/privacy}", "received_events_url": "https://api.github.com/users/huntermaxfield/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-18T21:58:30Z", "updated_at": "2019-06-26T20:09:28Z", "closed_at": "2019-06-26T20:09:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I posted this on SO yesterday, but haven't seen a response yet.  I haven't found any other question like it, so I thought i'd post it here as well.  Here is the link to my SO question:\r\n\r\nhttps://stackoverflow.com/questions/56639816/how-to-fix-field-units-already-exist-in-schema-for-pandas-gpq\r\n\r\nIn short, i'm trying to write to Bigquery and am getting an error \"400 POST: ......field units already exist in schema\".  ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/279", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/279/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/279/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/279/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/279", "id": 449715572, "node_id": "MDU6SXNzdWU0NDk3MTU1NzI=", "number": 279, "title": "Conda installation triggers R-packages uninstall", "user": {"login": "jesperdejby", "id": 29233323, "node_id": "MDQ6VXNlcjI5MjMzMzIz", "avatar_url": "https://avatars3.githubusercontent.com/u/29233323?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jesperdejby", "html_url": "https://github.com/jesperdejby", "followers_url": "https://api.github.com/users/jesperdejby/followers", "following_url": "https://api.github.com/users/jesperdejby/following{/other_user}", "gists_url": "https://api.github.com/users/jesperdejby/gists{/gist_id}", "starred_url": "https://api.github.com/users/jesperdejby/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jesperdejby/subscriptions", "organizations_url": "https://api.github.com/users/jesperdejby/orgs", "repos_url": "https://api.github.com/users/jesperdejby/repos", "events_url": "https://api.github.com/users/jesperdejby/events{/privacy}", "received_events_url": "https://api.github.com/users/jesperdejby/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-29T10:05:42Z", "updated_at": "2019-05-29T11:52:25Z", "closed_at": "2019-05-29T11:52:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm currently running a miniconda setup on Windows. Running `conda install pandas-gbq --channel conda-forge` will prompt an uninstall of R-packages. I installed the R packages with `conda install -c r r-essentials`. I was able to work around this issue by installing `pandas-gbq` first and then `r-essentials`. Printout:\r\n```\r\nThe following packages will be REMOVED:\r\n  mro-basics-3.5.1-0\r\n  r-abind-1.4_5-mro351_0\r\n  r-assertthat-0.2.0-mro351_0\r\n  r-backports-1.1.2-mro351_0\r\n  r-base64enc-0.1_3-mro351_0\r\n  r-bh-1.66.0_1-mro351hf348343_0\r\n  r-bindr-0.1.1-mro351_0\r\netc.\r\n``` ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/277", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/277/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/277/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/277/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/277", "id": 449437211, "node_id": "MDU6SXNzdWU0NDk0MzcyMTE=", "number": 277, "title": "to_gbq should not modify table_schema inplace", "user": {"login": "bsolomon1124", "id": 25164676, "node_id": "MDQ6VXNlcjI1MTY0Njc2", "avatar_url": "https://avatars1.githubusercontent.com/u/25164676?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bsolomon1124", "html_url": "https://github.com/bsolomon1124", "followers_url": "https://api.github.com/users/bsolomon1124/followers", "following_url": "https://api.github.com/users/bsolomon1124/following{/other_user}", "gists_url": "https://api.github.com/users/bsolomon1124/gists{/gist_id}", "starred_url": "https://api.github.com/users/bsolomon1124/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bsolomon1124/subscriptions", "organizations_url": "https://api.github.com/users/bsolomon1124/orgs", "repos_url": "https://api.github.com/users/bsolomon1124/repos", "events_url": "https://api.github.com/users/bsolomon1124/events{/privacy}", "received_events_url": "https://api.github.com/users/bsolomon1124/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-05-28T19:26:29Z", "updated_at": "2019-05-29T17:13:44Z", "closed_at": "2019-05-29T17:13:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Working on a PR...\r\n\r\n----\r\n\r\n### Problem Description\r\n\r\npandas-gbq version: 0.10.0\r\n\r\nGBQ table:\r\n\r\n![Screen Shot 2019-05-28 at 2 50 54 PM](https://user-images.githubusercontent.com/25164676/58505950-2fc62580-815c-11e9-9381-f53b36cdd674.png)\r\n\r\n\r\nReproducible example:\r\n\r\n```python\r\nfrom copy import deepcopy\r\nimport datetime\r\nimport pandas_gbq\r\nimport pandas as pd\r\nfrom google.oauth2.service_account import Credentials\r\n\r\ndf = pd.DataFrame(\r\n    {\r\n        \"field1\": [\"a\", \"b\"],\r\n        \"field2\": [1, 2],\r\n        \"field3\": [datetime.date(2019, 1, 1), datetime.date(2019, 5, 1)],\r\n    }\r\n)\r\n\r\noriginal_schema = [\r\n    {\r\n        \"name\": \"field1\",\r\n        \"type\": \"STRING\",\r\n        \"mode\": \"REQUIRED\",\r\n    },\r\n    {\r\n        \"name\": \"field2\",\r\n        \"type\": \"INTEGER\",\r\n    },\r\n    {\r\n        \"name\": \"field3\",\r\n        \"type\": \"DATE\",\r\n    },\r\n]\r\noriginal_schema_cp = deepcopy(original_schema)\r\n\r\npandas_gbq.to_gbq(\r\n    dataframe=df,\r\n    destination_table=\"XXXXX.schematest\",\r\n    project_id=\"XXXXX\",\r\n    credentials=Credentials.from_service_account_file(\"XXXXX.json\"),\r\n    if_exists=\"append\",\r\n    table_schema=original_schema,\r\n)\r\n```\r\n\r\nResults:\r\n\r\n```python\r\n>>> original_schema                                                                                                                                                                                                                                          \r\n[{'name': 'field1', 'type': 'STRING', 'mode': 'REQUIRED'},\r\n {'name': 'field2', 'type': 'INTEGER', 'mode': 'NULLABLE'},\r\n {'name': 'field3', 'type': 'DATE', 'mode': 'NULLABLE'}]\r\n>>> original_schema_cp == original_schema                                                                                                                                                                                                                    \r\nFalse\r\n```\r\n\r\nAhhhhh!  Nowhere is it noted in https://pandas-gbq.readthedocs.io/en/latest/api.html that, in some situations, the object passed to `table_schema` may be modified in place.  Most libraries go out of their way to avoid modifying mutable arguments; pandas-gbq should do the same.\r\n\r\n### Debugging\r\n\r\nA `pdb` session shows that `table_schema` is modified in [`connector.load_data()`](https://github.com/pydata/pandas-gbq/blob/59228d9c20cee12b24caa5cc41d3f2e6c0337932/pandas_gbq/gbq.py#L1153), which in turn calls [`load_chunks()`](https://github.com/bsolomon1124/pandas-gbq/blob/59228d9c20cee12b24caa5cc41d3f2e6c0337932/pandas_gbq/gbq.py#L530).  The specific place in `load_chunks()` where the inadvertant modification happens is here:\r\n\r\n```python\r\n# https://github.com/bsolomon1124/pandas-gbq/blob/59228d9c20cee12b24caa5cc41d3f2e6c0337932/pandas_gbq/load.py#L72\r\n    for field in schema[\"fields\"]:\r\n        if \"mode\" not in field:\r\n        field[\"mode\"] = \"NULLABLE\"\r\n```\r\n\r\nThis is because, I think, in `table_schema = schema.update_schema(default_schema, dict(fields=table_schema))`, the new `table_schema` now contains a reference to the `dict` elements of the original `table_schema` argument.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/276", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/276/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/276/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/276/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/276", "id": 446187901, "node_id": "MDU6SXNzdWU0NDYxODc5MDE=", "number": 276, "title": "google/cloud/bigquery/_http.py TypeError: __init__() takes 2 positional arguments but 3 were given", "user": {"login": "pabloazurduy", "id": 24685386, "node_id": "MDQ6VXNlcjI0Njg1Mzg2", "avatar_url": "https://avatars2.githubusercontent.com/u/24685386?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pabloazurduy", "html_url": "https://github.com/pabloazurduy", "followers_url": "https://api.github.com/users/pabloazurduy/followers", "following_url": "https://api.github.com/users/pabloazurduy/following{/other_user}", "gists_url": "https://api.github.com/users/pabloazurduy/gists{/gist_id}", "starred_url": "https://api.github.com/users/pabloazurduy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pabloazurduy/subscriptions", "organizations_url": "https://api.github.com/users/pabloazurduy/orgs", "repos_url": "https://api.github.com/users/pabloazurduy/repos", "events_url": "https://api.github.com/users/pabloazurduy/events{/privacy}", "received_events_url": "https://api.github.com/users/pabloazurduy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-20T15:44:46Z", "updated_at": "2019-05-23T00:42:30Z", "closed_at": "2019-05-20T15:46:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \r\nIm running into this error, any ideas of what the origin might be ?\r\n`python=3.5` \r\n```\r\nREQUIRED_PACKAGES = ['pandas==0.24.2',\r\n                     'pandas-gbq==0.10.0', \r\n                     'featuretools==0.7',\r\n                     'google-cloud-storage']\r\n \r\n```\r\n```\r\n File \"/root/.local/lib/python3.5/site-packages/aircraft_pfrs_pit/aircraft_pfrs_pit.py\", line 40, in create_table\r\n    aircraft_df = pd.read_gbq(sql, dialect='standard')\r\n  File \"/root/.local/lib/python3.5/site-packages/pandas/io/gbq.py\", line 149, in read_gbq\r\n    credentials=credentials, verbose=verbose, private_key=private_key)\r\n  File \"/root/.local/lib/python3.5/site-packages/pandas_gbq/gbq.py\", line 924, in read_gbq\r\n    use_bqstorage_api=use_bqstorage_api,\r\n  File \"/root/.local/lib/python3.5/site-packages/pandas_gbq/gbq.py\", line 362, in __init__\r\n    self.client = self.get_client()\r\n  File \"/root/.local/lib/python3.5/site-packages/pandas_gbq/gbq.py\", line 396, in get_client\r\n    project=self.project_id, credentials=self.credentials\r\n  File \"/root/.local/lib/python3.5/site-packages/google/cloud/bigquery/client.py\", line 161, in __init__\r\n    self._connection = Connection(self, client_info=client_info)\r\n  File \"/root/.local/lib/python3.5/site-packages/google/cloud/bigquery/_http.py\", line 33, in __init__\r\n    super(Connection, self).__init__(client, client_info)\r\nTypeError: __init__() takes 2 positional arguments but 3 were given\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/271", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/271/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/271/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/271/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/271", "id": 429543281, "node_id": "MDU6SXNzdWU0Mjk1NDMyODE=", "number": 271, "title": "google-big-query 1.11.1 appears to break things", "user": {"login": "jreback", "id": 953992, "node_id": "MDQ6VXNlcjk1Mzk5Mg==", "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jreback", "html_url": "https://github.com/jreback", "followers_url": "https://api.github.com/users/jreback/followers", "following_url": "https://api.github.com/users/jreback/following{/other_user}", "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}", "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jreback/subscriptions", "organizations_url": "https://api.github.com/users/jreback/orgs", "repos_url": "https://api.github.com/users/jreback/repos", "events_url": "https://api.github.com/users/jreback/events{/privacy}", "received_events_url": "https://api.github.com/users/jreback/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-04-05T01:05:37Z", "updated_at": "2019-04-05T17:31:45Z", "closed_at": "2019-04-05T17:31:45Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "https://travis-ci.org/pandas-dev/pandas/jobs/515983447 with 1.11.1 is breaking\r\nwhile 1.10.0 seems ok\r\n\r\nI see things like this when you have incompatible protobufs\r\n```\r\n==================================== ERRORS ====================================\r\n_________________ ERROR collecting pandas/tests/io/test_gbq.py _________________\r\npandas/tests/io/test_gbq.py:14: in <module>\r\n    bigquery = pytest.importorskip(\"google.cloud.bigquery\")\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/cloud/bigquery/__init__.py:35: in <module>\r\n    from google.cloud.bigquery.client import Client\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/cloud/bigquery/client.py:45: in <module>\r\n    from google.cloud.bigquery.dataset import Dataset\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/cloud/bigquery/dataset.py:24: in <module>\r\n    from google.cloud.bigquery.model import ModelReference\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/cloud/bigquery/model.py:27: in <module>\r\n    from google.cloud.bigquery_v2 import types\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/cloud/bigquery_v2/__init__.py:23: in <module>\r\n    from google.cloud.bigquery_v2 import types\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/cloud/bigquery_v2/types.py:22: in <module>\r\n    from google.cloud.bigquery_v2.proto import model_pb2\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/cloud/bigquery_v2/proto/model_pb2.py:17: in <module>\r\n    from google.cloud.bigquery_v2.proto import (\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/cloud/bigquery_v2/proto/model_reference_pb2.py:17: in <module>\r\n    from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/api/annotations_pb2.py:15: in <module>\r\n    from google.api import http_pb2 as google_dot_api_dot_http__pb2\r\n../../../miniconda3/envs/pandas-dev/lib/python3.6/site-packages/google/api/http_pb2.py:22: in <module>\r\n    serialized_pb=_b('\\n\\x15google/api/http.proto\\x12\\ngoogle.api\\\"T\\n\\x04Http\\x12#\\n\\x05rules\\x18\\x01 \\x03(\\x0b\\x32\\x14.google.api.HttpRule\\x12\\'\\n\\x1f\\x66ully_decode_reserved_expansion\\x18\\x02 \\x01(\\x08\\\"\\x81\\x02\\n\\x08HttpRule\\x12\\x10\\n\\x08selector\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x03get\\x18\\x02 \\x01(\\tH\\x00\\x12\\r\\n\\x03put\\x18\\x03 \\x01(\\tH\\x00\\x12\\x0e\\n\\x04post\\x18\\x04 \\x01(\\tH\\x00\\x12\\x10\\n\\x06\\x64\\x65lete\\x18\\x05 \\x01(\\H\\x00\\x12\\x0f\\n\\x05patch\\x18\\x06 \\x01(\\tH\\x00\\x12/\\n\\x06\\x63ustom\\x18\\x08 \\x01(\\x0b\\x32\\x1d.google.api.CustomHttpPatternH\\x00\\x12\\x0c\\n\\x04\\x62ody\\x18\\x07 \\x01(\\t\\x12\\x15\\n\\rresponse_body\\x18\\x0c \\x01(\\t\\x12\\x31\\n\\x13\\x61\\x64\\x64itional_bindings\\x18\\x0b \\x03(\\x0b\\x32\\x14.google.api.HttpRuleB\\t\\n\\x07pattern\\\"/\\n\\x11\\x43ustomHttpPattern\\x12\\x0c\\n\\x04kind\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04path\\x18\\x02 \\x01(\\tBj\\n\\x0e\\x63om.google.apiB\\tHttpProtoP\\x01ZAgoogle.golang.org/genproto/googleapis/api/annotations;annotations\\xf8\\x01\\x01\\xa2\\x02\\x04GAPIb\\x06proto3')\r\nE   TypeError: __new__() got an unexpected keyword argument 'serialized_options'\r\n===\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/268", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/268/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/268/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/268/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/268", "id": 428777199, "node_id": "MDU6SXNzdWU0Mjg3NzcxOTk=", "number": 268, "title": "CLN: Plan to drop Python 2 support", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-03T13:45:27Z", "updated_at": "2019-04-19T21:12:53Z", "closed_at": "2019-04-19T21:12:53Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "As discovered in https://github.com/pydata/pandas-gbq/pull/254 for #253, pandas 0.25.0 is starting to drop compatibility functions for Python 2 support.\r\n\r\nSince this package is pretty tightly coupled with upstream pandas, we'll need to follow-suit soon. Perhaps 0.10.0 is the last version that we officially support Python 2? I'd like to make sure we are able to run our test suite against 0.25.x, and supporting Python 2 is potentially a blocker.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/261", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/261/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/261/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/261/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/261", "id": 424424329, "node_id": "MDU6SXNzdWU0MjQ0MjQzMjk=", "number": 261, "title": "TST: dtype for BigQuery TIMESTAMP unexpectedly using datetime64[ns, UTC] dtype", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535065536, "node_id": "MDU6TGFiZWw1MzUwNjU1MzY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20process", "name": "type: process", "color": "c5def5", "default": false, "description": "A process-releated concern. May include testing, release, or the like."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2019-03-22T22:39:22Z", "updated_at": "2019-04-03T23:14:06Z", "closed_at": "2019-04-03T23:13:39Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "```\r\n$ pytest 'tests/system/test_gbq.py::TestReadGBQIntegration::test_return_correct_types[env-current_timestamp()-datetime64[ns]]'\r\n=============================== test session starts ===============================\r\nplatform darwin -- Python 3.6.4, pytest-4.2.0, py-1.8.0, pluggy-0.8.1\r\nrootdir: /Users/swast/src/pandas/pandas-gbq, inifile:\r\ncollected 1 item                                                                  \r\n\r\ntests/system/test_gbq.py F                                                  [100%]\r\n\r\n==================================== FAILURES =====================================\r\n_ TestReadGBQIntegration.test_return_correct_types[env-current_timestamp()-datetime64[ns]] _\r\n\r\nself = <tests.system.test_gbq.TestReadGBQIntegration object at 0x10c3277b8>\r\nproject_id = 'swast-scratch', expression = 'current_timestamp()'\r\ntype_ = 'datetime64[ns]'\r\n\r\n    @pytest.mark.parametrize(\r\n        \"expression, type_\",\r\n        [\r\n            (\"current_date()\", \"<M8[ns]\"),\r\n            (\"current_timestamp()\", \"datetime64[ns]\"),\r\n            (\"current_datetime()\", \"<M8[ns]\"),\r\n            (\"TRUE\", bool),\r\n            (\"FALSE\", bool),\r\n        ],\r\n    )\r\n    def test_return_correct_types(self, project_id, expression, type_):\r\n        \"\"\"\r\n        All type checks can be added to this function using additional\r\n        parameters, rather than creating additional functions.\r\n        We can consolidate the existing functions here in time\r\n    \r\n        TODO: time doesn't currently parse\r\n        (\"time(12,30,00)\", \"<M8[ns]\"),\r\n        \"\"\"\r\n        query = \"SELECT {} AS _\".format(expression)\r\n        df = gbq.read_gbq(\r\n            query,\r\n            project_id=project_id,\r\n            credentials=self.credentials,\r\n            dialect=\"standard\",\r\n        )\r\n>       assert df[\"_\"].dtype == type_\r\nE       AssertionError: assert datetime64[ns, UTC] == 'datetime64[ns]'\r\nE        +  where datetime64[ns, UTC] = 0   2019-03-22 22:35:32.398261+00:00\\nName: _, dtype: datetime64[ns, UTC].dtype\r\n\r\ntests/system/test_gbq.py:392: AssertionError\r\n============================ 1 failed in 2.68 seconds =============================\r\n```\r\n\r\nIt's odd that we explicitly specify the `datetime64[ns]` dtype, but it comes back as `datetime64[ns, UTC]` on the latest pandas version. I know `to_dataframe` from `google-cloud-bigquery` returns datetime objects with the UTC timezone, but I'd expect an explicit dtype of `datetime64[ns]` to take precedence.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/260", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/260/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/260/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/260/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/260", "id": 421943057, "node_id": "MDU6SXNzdWU0MjE5NDMwNTc=", "number": 260, "title": "Empty upload raises ZeroDivisionError at gbq.py\", line 524, in load_data", "user": {"login": "vackosar", "id": 11373934, "node_id": "MDQ6VXNlcjExMzczOTM0", "avatar_url": "https://avatars3.githubusercontent.com/u/11373934?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vackosar", "html_url": "https://github.com/vackosar", "followers_url": "https://api.github.com/users/vackosar/followers", "following_url": "https://api.github.com/users/vackosar/following{/other_user}", "gists_url": "https://api.github.com/users/vackosar/gists{/gist_id}", "starred_url": "https://api.github.com/users/vackosar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vackosar/subscriptions", "organizations_url": "https://api.github.com/users/vackosar/orgs", "repos_url": "https://api.github.com/users/vackosar/repos", "events_url": "https://api.github.com/users/vackosar/events{/privacy}", "received_events_url": "https://api.github.com/users/vackosar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-03-17T16:18:04Z", "updated_at": "2019-03-17T20:03:56Z", "closed_at": "2019-03-17T20:03:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "```pd.DataFrame(columns=['a', 'b']).to_gbq(...)```\r\ncreates table but raises ZeroDivisionError at gbq.py\", line 524, in load_data\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/253", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/253/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/253/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/253/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/253", "id": 413603373, "node_id": "MDU6SXNzdWU0MTM2MDMzNzM=", "number": 253, "title": "TST: Conda CI build not using latest wheels?", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535065536, "node_id": "MDU6TGFiZWw1MzUwNjU1MzY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20process", "name": "type: process", "color": "c5def5", "default": false, "description": "A process-releated concern. May include testing, release, or the like."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-02-22T22:25:27Z", "updated_at": "2019-05-10T17:15:40Z", "closed_at": "2019-05-10T17:15:40Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "See: https://github.com/pydata/pandas-gbq/pull/247#discussion_r259496042\r\n\r\nThe Conda build is likely using an old version of pandas, even though it's supposed to be using pre-release wheels.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/250", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/250/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/250/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/250/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/250", "id": 410221354, "node_id": "MDU6SXNzdWU0MTAyMjEzNTQ=", "number": 250, "title": "Implicit user authenication yields error, explicit authentication works", "user": {"login": "dkapitan", "id": 4090894, "node_id": "MDQ6VXNlcjQwOTA4OTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/4090894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dkapitan", "html_url": "https://github.com/dkapitan", "followers_url": "https://api.github.com/users/dkapitan/followers", "following_url": "https://api.github.com/users/dkapitan/following{/other_user}", "gists_url": "https://api.github.com/users/dkapitan/gists{/gist_id}", "starred_url": "https://api.github.com/users/dkapitan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dkapitan/subscriptions", "organizations_url": "https://api.github.com/users/dkapitan/orgs", "repos_url": "https://api.github.com/users/dkapitan/repos", "events_url": "https://api.github.com/users/dkapitan/events{/privacy}", "received_events_url": "https://api.github.com/users/dkapitan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-02-14T10:07:20Z", "updated_at": "2019-02-15T05:58:28Z", "closed_at": "2019-02-15T01:10:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Seen on:\r\n- Linux Debian\r\n- Python 3.5\r\n- pandas 0.23\r\n- pandas-gbq 0.9\r\n- pydata-google-auth 0.1\r\n\r\n\r\nImplicit user authentication yields `bad request: invalid grant error`:\r\n\r\n```\r\nimport pandas as pd\r\ndf = pd.read_gbq('select 1'', dialect='standard', project_id='some-project')\r\n```\r\n\r\nExplicit user authentication and assigning it to `context.credentials` works:\r\n\r\n```\r\nimport pydata_google_auth\r\nimport pandas as pd\r\nimport pandas_gbq\r\n\r\n# explicitly authenticate user via URL and assign to pandas_gbq context\r\ncredentials = pydata_google_auth.get_user_credentials(\r\n    ['https://www.googleapis.com/auth/cloud-platform'],\r\n)\r\npandas_gbq.context.credentials = credentials\r\n\r\n# now you can use pd.read_gbq\r\ndf = pd.read_gbq('select 1'', dialect='standard', project_id='some-project')\r\n```\r\n\r\nI first thought the error was due to different versions, but that doesn't seem the case. I have seen similar errors on different environments (OSX, python 3.7) and sometimes implicit works and sometimes it doesn't.\r\n\r\nFor now I can continue using `pandas-gbq` but would it be good to figure out what's causing this?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/249", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/249/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/249/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/249/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/249", "id": 408378656, "node_id": "MDU6SXNzdWU0MDgzNzg2NTY=", "number": 249, "title": "TST: Failing tests on CircleCI", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535065536, "node_id": "MDU6TGFiZWw1MzUwNjU1MzY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20process", "name": "type: process", "color": "c5def5", "default": false, "description": "A process-releated concern. May include testing, release, or the like."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2019-02-09T01:02:40Z", "updated_at": "2019-02-15T23:40:53Z", "closed_at": "2019-02-15T23:40:53Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "From https://circleci.com/workflow-run/8ac0fbac-33a2-4c35-8c83-3c500cba9277\r\n\r\n```\r\nBuilding wheels for collected packages: google-api-core, google-api-core, googleapis-common-protos\r\n  Building wheel for google-api-core (setup.py) ... -\b \bdone\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-smyvy_wq/wheels/d6/b1/39/13ee3b87c1f4ab8bfe66c783086bf81435f124faada93b5312\r\n  Building wheel for google-api-core (setup.py) ... -\b \berror\r\n  Complete output from command /usr/local/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-ypmp8ha1/google-api-core/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-yaiotew_ --python-tag cp36:\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/usr/local/lib/python3.6/tokenize.py\", line 452, in open\r\n      buffer = _builtin_open(filename, 'rb')\r\n  FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-install-ypmp8ha1/google-api-core/setup.py'\r\n  \r\n  ----------------------------------------\r\n  Failed building wheel for google-api-core\r\n  Running setup.py clean for google-api-core\r\n  Complete output from command /usr/local/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-ypmp8ha1/google-api-core/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" clean --all:\r\n  Traceback (most recent call last):\r\n    File \"<string>\", line 1, in <module>\r\n    File \"/usr/local/lib/python3.6/tokenize.py\", line 452, in open\r\n      buffer = _builtin_open(filename, 'rb')\r\n  FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-install-ypmp8ha1/google-api-core/setup.py'\r\n  \r\n  ----------------------------------------\r\n  Failed cleaning build dir for google-api-core\r\n  Building wheel for googleapis-common-protos (setup.py) ... -\b \bdone\r\n  Stored in directory: /root/.cache/pip/wheels/da/6b/81/8573adcbe2aa2ecba92c341dfe19c5b5a733f4514297ba52b4\r\nSuccessfully built google-api-core googleapis-common-protos\r\nFailed to build google-api-core\r\nInstalling collected packages: protobuf, googleapis-common-protos, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-api-core\r\nSuccessfully installed cachetools-3.1.0 google-api-core-1.7.0 google-auth-1.6.2 googleapis-common-protos-1.5.6 protobuf-3.6.1 pyasn1-0.4.5 pyasn1-modules-0.2.4 rsa-4.0\r\n+ pip install -e .\r\nObtaining file:///root/project\r\n  Installing build dependencies ... -\b \b\\\b \b|\b \b/\b \bdone\r\n  Getting requirements to build wheel ... -\b \berror\r\n  Complete output from command /usr/local/bin/python /usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/_in_process.py get_requires_for_build_wheel /tmp/tmp7zpu04nt:\r\n  Traceback (most recent call last):\r\n    File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/_in_process.py\", line 207, in <module>\r\n      main()\r\n    File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/_in_process.py\", line 197, in main\r\n      json_out['return_val'] = hook(**hook_input['kwargs'])\r\n    File \"/usr/local/lib/python3.6/site-packages/pip/_vendor/pep517/_in_process.py\", line 54, in get_requires_for_build_wheel\r\n      return hook(config_settings)\r\n    File \"/tmp/pip-build-env-wwt6nnnw/overlay/lib/python3.6/site-packages/setuptools/build_meta.py\", line 130, in get_requires_for_build_wheel\r\n      return self._get_build_requires(config_settings, requirements=['wheel'])\r\n    File \"/tmp/pip-build-env-wwt6nnnw/overlay/lib/python3.6/site-packages/setuptools/build_meta.py\", line 112, in _get_build_requires\r\n      self.run_setup()\r\n    File \"/tmp/pip-build-env-wwt6nnnw/overlay/lib/python3.6/site-packages/setuptools/build_meta.py\", line 126, in run_setup\r\n      exec(compile(code, __file__, 'exec'), locals())\r\n    File \"setup.py\", line 4, in <module>\r\n      import versioneer\r\n  ModuleNotFoundError: No module named 'versioneer'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/248", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/248/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/248/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/248/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/248", "id": 404751151, "node_id": "MDU6SXNzdWU0MDQ3NTExNTE=", "number": 248, "title": "Error if home directory isn't writable", "user": {"login": "PeterJCLaw", "id": 336212, "node_id": "MDQ6VXNlcjMzNjIxMg==", "avatar_url": "https://avatars2.githubusercontent.com/u/336212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PeterJCLaw", "html_url": "https://github.com/PeterJCLaw", "followers_url": "https://api.github.com/users/PeterJCLaw/followers", "following_url": "https://api.github.com/users/PeterJCLaw/following{/other_user}", "gists_url": "https://api.github.com/users/PeterJCLaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/PeterJCLaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PeterJCLaw/subscriptions", "organizations_url": "https://api.github.com/users/PeterJCLaw/orgs", "repos_url": "https://api.github.com/users/PeterJCLaw/repos", "events_url": "https://api.github.com/users/PeterJCLaw/events{/privacy}", "received_events_url": "https://api.github.com/users/PeterJCLaw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}, {"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-01-30T12:37:10Z", "updated_at": "2019-02-01T21:35:49Z", "closed_at": "2019-02-01T21:29:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've recently noticed that `pandas_gbq` requires that a user's home directory exist and be writeable in order to be used. This means that it cannot be used in restricted environments, where that may not be the case.\r\n\r\nI _think_ this is a result of the recent change (#241) to use https://github.com/pydata/pydata-google-auth for auth.\r\n\r\nI've raised the underlying issue as https://github.com/pydata/pydata-google-auth/issues/10, however from what I can tell `pydata_google_auth` is only actually used in the case where the user doesn't provide credentials as part of an operation.\r\nIn particular, I'm using a service account (where you're more likely to be in a restricted environment too), and always provide the credentials upfront anyway.\r\n\r\nIt would therefore be great if `pydata-google-auth` was a soft requirement rather than a hard one -- both removing it from the requirements of this library and from the checks in `_test_google_api_imports`, or making those checks aware of whether credentials have been explicitly provided.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/244", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/244/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/244/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/244/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/244", "id": 402726485, "node_id": "MDU6SXNzdWU0MDI3MjY0ODU=", "number": 244, "title": "BytesIO buffers remain open after being written", "user": {"login": "bsolomon1124", "id": 25164676, "node_id": "MDQ6VXNlcjI1MTY0Njc2", "avatar_url": "https://avatars1.githubusercontent.com/u/25164676?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bsolomon1124", "html_url": "https://github.com/bsolomon1124", "followers_url": "https://api.github.com/users/bsolomon1124/followers", "following_url": "https://api.github.com/users/bsolomon1124/following{/other_user}", "gists_url": "https://api.github.com/users/bsolomon1124/gists{/gist_id}", "starred_url": "https://api.github.com/users/bsolomon1124/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bsolomon1124/subscriptions", "organizations_url": "https://api.github.com/users/bsolomon1124/orgs", "repos_url": "https://api.github.com/users/bsolomon1124/repos", "events_url": "https://api.github.com/users/bsolomon1124/events{/privacy}", "received_events_url": "https://api.github.com/users/bsolomon1124/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-24T14:15:22Z", "updated_at": "2019-01-25T23:07:38Z", "closed_at": "2019-01-25T23:07:38Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "While they will eventually be destroyed and [closed](https://docs.python.org/3.7/tutorial/inputoutput.html#reading-and-writing-files) by the garbage collector, it is generally good practice to close file objects via either using them as a `with` context manager or explicitly calling `f.close()`.\r\n\r\nIn `pandas_gbq/load.py`, it looks like the `chunk_buffer`(s) remain open after being written to GBQ.  Is there a reason for them to be left open, or would it be sounder practice to call `.close()` on them in a `finally` block?\r\n\r\nHere is an example that seems to confirm.  (I suspected they might be closed by the underlying function call from google-cloud Python library itself, but that does not look to be true, unless I am missing something.)\r\n\r\nFirst I threw in a few print statements to `load.py`:\r\n\r\n```python\r\n    chunks = encode_chunks(dataframe, chunksize=chunksize)\r\n    for remaining_rows, chunk_buffer in chunks:\r\n        try:\r\n            yield remaining_rows\r\n            client.load_table_from_file(\r\n                chunk_buffer,\r\n                destination_table,\r\n                job_config=job_config,\r\n                location=location,\r\n            ).result()\r\n        finally:\r\n            print(\"Chunk buffer:\", chunk_buffer, id(chunk_buffer))\r\n            print(\"Closed:\", chunk_buffer.closed)\r\n            print()\r\n```\r\n\r\nThe result:\r\n\r\n```python\r\n>>> from google.oauth2.service_account import Credentials \r\n>>> import pandas.util.testing as tm\r\n>>> from pandas_gbq import to_gbq\r\n>>> \r\n>>> df = tm.makeDataFrame()\r\n>>> \r\n>>> to_gbq(\r\n...     dataframe=df,\r\n...     destination_table='aaa.bbb',\r\n...     project_id='xyz',\r\n...     if_exists='append',\r\n...     progress_bar=False,\r\n...     credentials=Credentials.from_service_account_file('xxx...a111.json')\r\n... )\r\nChunk buffer: <_io.BytesIO object at 0x110864f10> 4572204816\r\nClosed: False  # < -- Uh oh\r\n```\r\n\r\nThe relevant code is in [`load.py`](https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/load.py), where `encode_chunk()` returns an open `BytesIO` object that is funneled through a generator and then uploaded via `client.load_table_from_file()`.\r\n\r\nI would propose something like:\r\n\r\n```python\r\n    chunks = encode_chunks(dataframe, chunksize=chunksize)\r\n    for remaining_rows, chunk_buffer in chunks:\r\n        try:\r\n            yield remaining_rows\r\n            client.load_table_from_file(\r\n                chunk_buffer,\r\n                destination_table,\r\n                job_config=job_config,\r\n                location=location,\r\n            ).result()\r\n        finally:\r\n            chunk_buffer.close()\r\n```\r\n\r\n----\r\n\r\nMy info: Python 3.7.2, pandas_gbq 0.9.0", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/239", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/239/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/239/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/239/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/239", "id": 391889750, "node_id": "MDU6SXNzdWUzOTE4ODk3NTA=", "number": 239, "title": "Show imports in introductory and authentication examples", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535013870, "node_id": "MDU6TGFiZWw1MzUwMTM4NzA=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/docs", "name": "docs", "color": "1d76db", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-12-17T21:06:49Z", "updated_at": "2019-08-13T17:24:06Z", "closed_at": "2019-08-13T17:24:06Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "We should show the necessary imports in our how-to guides.\r\n\r\nhttps://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html needs to show `import pandas_gbq` and `from google.oauth2 import service_account`\r\n\r\nhttps://pandas-gbq.readthedocs.io/en/latest/intro.html should have a simple example for both `read_gbq` and `to_gbq`. We can show how to use from `pandas` or using `pandas_gbq` directly.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/238", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/238/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/238/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/238/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/238", "id": 391323579, "node_id": "MDU6SXNzdWUzOTEzMjM1Nzk=", "number": 238, "title": "Feature Request: Requesting support for streaming data to bigquery", "user": {"login": "rahul1990gupta", "id": 8749679, "node_id": "MDQ6VXNlcjg3NDk2Nzk=", "avatar_url": "https://avatars3.githubusercontent.com/u/8749679?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rahul1990gupta", "html_url": "https://github.com/rahul1990gupta", "followers_url": "https://api.github.com/users/rahul1990gupta/followers", "following_url": "https://api.github.com/users/rahul1990gupta/following{/other_user}", "gists_url": "https://api.github.com/users/rahul1990gupta/gists{/gist_id}", "starred_url": "https://api.github.com/users/rahul1990gupta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rahul1990gupta/subscriptions", "organizations_url": "https://api.github.com/users/rahul1990gupta/orgs", "repos_url": "https://api.github.com/users/rahul1990gupta/repos", "events_url": "https://api.github.com/users/rahul1990gupta/events{/privacy}", "received_events_url": "https://api.github.com/users/rahul1990gupta/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-12-15T00:35:24Z", "updated_at": "2019-03-23T19:02:47Z", "closed_at": "2019-01-04T21:39:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "to_gbq() method can only to be called at most 1000 times before it gets the `quota exceeded` error\r\nhttps://cloud.google.com/bigquery/quotas\r\n\r\nIt would be nice to have a support for stream data to big-query where writing to big-query table is implemented by client.insert_rows method as described below in the link.\r\n\r\nhttps://cloud.google.com/bigquery/streaming-data-into-bigquery#bigquery-stream-data-python\r\n\r\nSystem details:\r\nUbuntu 14.04\r\npandas                             0.22.0             \r\npandas-gbq                         0.7.0    \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/237", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/237/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/237/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/237/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/237", "id": 386477678, "node_id": "MDU6SXNzdWUzODY0Nzc2Nzg=", "number": 237, "title": "ZeroDivisionError on uploading empty dataframe", "user": {"login": "knowsuchagency", "id": 11974795, "node_id": "MDQ6VXNlcjExOTc0Nzk1", "avatar_url": "https://avatars0.githubusercontent.com/u/11974795?v=4", "gravatar_id": "", "url": "https://api.github.com/users/knowsuchagency", "html_url": "https://github.com/knowsuchagency", "followers_url": "https://api.github.com/users/knowsuchagency/followers", "following_url": "https://api.github.com/users/knowsuchagency/following{/other_user}", "gists_url": "https://api.github.com/users/knowsuchagency/gists{/gist_id}", "starred_url": "https://api.github.com/users/knowsuchagency/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/knowsuchagency/subscriptions", "organizations_url": "https://api.github.com/users/knowsuchagency/orgs", "repos_url": "https://api.github.com/users/knowsuchagency/repos", "events_url": "https://api.github.com/users/knowsuchagency/events{/privacy}", "received_events_url": "https://api.github.com/users/knowsuchagency/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}, {"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-12-01T17:21:40Z", "updated_at": "2019-03-15T22:39:48Z", "closed_at": "2019-03-15T22:39:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Attempting to upload an empty dataframe seems to raise to a `ZeroDivisionError` in version `0.8.0`\r\n\r\n```\r\n[2018-12-01 09:40:32,542] {base_task_runner.py:95} INFO - Subtask:   File \"/usr/local/lib/python2.7/site-packages/pandas_gbq/gbq.py\", line 509, in load_data\r\n[2018-12-01 09:40:32,542] {base_task_runner.py:95} INFO - Subtask:     ((total_rows - remaining_rows) * 100) / total_rows\r\n[2018-12-01 09:40:32,542] {base_task_runner.py:95} INFO - Subtask: ZeroDivisionError: integer division or modulo by zero\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/228", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/228/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/228/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/228/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/228", "id": 372038800, "node_id": "MDU6SXNzdWUzNzIwMzg4MDA=", "number": 228, "title": "TST: Migrate to CircleCI for builds", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535065536, "node_id": "MDU6TGFiZWw1MzUwNjU1MzY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20process", "name": "type: process", "color": "c5def5", "default": false, "description": "A process-releated concern. May include testing, release, or the like."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-10-19T16:59:22Z", "updated_at": "2018-11-09T18:06:55Z", "closed_at": "2018-11-09T18:06:55Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Everytime I use Travis, I have the frustration that I can't really define separate Docker images to use as the base for conda versus pip versus different versions of Python. This made changes like https://github.com/pydata/pandas-gbq/pull/222 a lot harder than they would have been if I could have had more control over the base image.\r\n\r\nI also suspect that Travis is maybe at fault for our Conda build failing https://github.com/pydata/pandas-gbq/issues/189. My only evidence for this is that I've tested on conda locally several times and am unable to reproduce the issue we see in the Travis build.\r\n\r\nThere are two interacting features of CircleCI that I think would be a big help:\r\n\r\n1. [Docker executor type](https://circleci.com/docs/2.0/executor-types/#using-docker)\r\n2. [Workflows](https://circleci.com/docs/2.0/workflows/), which provide the ability to run multiple \"jobs\" in parallel, where each job has its own executor definition.\r\n\r\nOne problem with this plan is that I don't have access to the GCP project that we use for Travis builds so that I can set up the secrets on CircleCI. Maybe @jreback could give me access to that?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/226", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/226/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/226/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/226/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/226", "id": 366893685, "node_id": "MDU6SXNzdWUzNjY4OTM2ODU=", "number": 226, "title": "Build on master branch is failing", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535013928, "node_id": "MDU6TGFiZWw1MzUwMTM5Mjg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20cleanup", "name": "type: cleanup", "color": "c5def5", "default": false, "description": "An internal cleanup or hygiene concern."}, {"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-10-04T17:29:53Z", "updated_at": "2018-10-12T18:14:19Z", "closed_at": "2018-10-12T18:14:19Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "https://travis-ci.org/pydata/pandas-gbq/jobs/437226967\r\n\r\n```\r\nE           google.auth.exceptions.TransportError: ('Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Enginemetadata service.\r\n```\r\n\r\nI believe this is due to https://github.com/GoogleCloudPlatform/google-auth-library-python/issues/287\r\n\r\nI think the workaround for us is to catch `RefreshError` whenever we call `google.auth.default()`: https://github.com/pydata/pandas-gbq/blob/942c8795e38b41e75d2ce6de22bc19e4c5b00814/pandas_gbq/auth.py#L115", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/223", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/223/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/223/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/223/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/223", "id": 364480116, "node_id": "MDU6SXNzdWUzNjQ0ODAxMTY=", "number": 223, "title": "Invalid_grant error: where does pandas read_gbq loads its credentials?", "user": {"login": "heoa", "id": 1807927, "node_id": "MDQ6VXNlcjE4MDc5Mjc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1807927?v=4", "gravatar_id": "", "url": "https://api.github.com/users/heoa", "html_url": "https://github.com/heoa", "followers_url": "https://api.github.com/users/heoa/followers", "following_url": "https://api.github.com/users/heoa/following{/other_user}", "gists_url": "https://api.github.com/users/heoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/heoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/heoa/subscriptions", "organizations_url": "https://api.github.com/users/heoa/orgs", "repos_url": "https://api.github.com/users/heoa/repos", "events_url": "https://api.github.com/users/heoa/events{/privacy}", "received_events_url": "https://api.github.com/users/heoa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-27T13:36:31Z", "updated_at": "2018-09-30T10:14:35Z", "closed_at": "2018-09-30T10:14:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am getting the error `invalid_grant: Bad Request', '{\\n  \"error\" : \"invalid_grant\",\\n  \"error_description\" : \"Bad Request` even with the simplest command\r\n\r\n```\r\nimport pandas as pd\r\npd.read_gbq(query='''select  1''', project_id=7777777)\r\n```\r\nI have tried removing pandas multiple times, re-authenticating multiple times with `gcloud auth login` -- but nothing seems to work. I am running Python inside Anaconda and I have tried all of the steps inside Anaconda and outside. \r\n\r\n**How can I resolve the invalid grant that looks like some credentials issue?**\r\n---\r\n\r\n**TRIAL 1: trying to clean up the environment and then reinstall everything needed to run BigQuery script with pandas read_gbq**\r\n\r\nI uninstall first all of the following to make clean environment:\r\n\r\n          pip list | grep pandas\r\n          pip list | grep google \r\n\r\nand then I try to install the latest\r\n\r\n          conda install pandas-gbq --channel conda-forge\r\n\r\nbut not working, apparently not removing some environment settings", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/221", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/221/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/221/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/221/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/221", "id": 362390933, "node_id": "MDU6SXNzdWUzNjIzOTA5MzM=", "number": 221, "title": "Context class (new in 0.7.0) is not thread-safe", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-09-20T22:28:45Z", "updated_at": "2018-09-21T00:40:19Z", "closed_at": "2018-09-20T23:52:33Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "It's possible that someone is calling `read_gbq` from multiple threads. With the current implementation of `Context`, such code may break because we do not protect the cached credentials / project properties with a mutex.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/220", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/220/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/220/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/220/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/220", "id": 362257020, "node_id": "MDU6SXNzdWUzNjIyNTcwMjA=", "number": 220, "title": "`to_gbq` incorrectly converts unsigned integers to strings", "user": {"login": "jamesthimont", "id": 1469790, "node_id": "MDQ6VXNlcjE0Njk3OTA=", "avatar_url": "https://avatars2.githubusercontent.com/u/1469790?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jamesthimont", "html_url": "https://github.com/jamesthimont", "followers_url": "https://api.github.com/users/jamesthimont/followers", "following_url": "https://api.github.com/users/jamesthimont/following{/other_user}", "gists_url": "https://api.github.com/users/jamesthimont/gists{/gist_id}", "starred_url": "https://api.github.com/users/jamesthimont/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jamesthimont/subscriptions", "organizations_url": "https://api.github.com/users/jamesthimont/orgs", "repos_url": "https://api.github.com/users/jamesthimont/repos", "events_url": "https://api.github.com/users/jamesthimont/events{/privacy}", "received_events_url": "https://api.github.com/users/jamesthimont/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-09-20T16:02:44Z", "updated_at": "2018-10-13T02:35:22Z", "closed_at": "2018-10-13T02:35:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "in `schema.py` the field mapping is missing the _u_ datatype\r\n\r\n```\r\ntype_mapping = {\r\n        \"i\": \"INTEGER\",\r\n        \"b\": \"BOOLEAN\",\r\n        \"f\": \"FLOAT\",\r\n        \"O\": \"STRING\",\r\n        \"S\": \"STRING\",\r\n        \"U\": \"STRING\",\r\n        \"M\": \"TIMESTAMP\",\r\n    }\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/218", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/218/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/218/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/218/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/218", "id": 361003351, "node_id": "MDU6SXNzdWUzNjEwMDMzNTE=", "number": 218, "title": "Allow partial schemas in to_gbq() table_schema", "user": {"login": "melissachang", "id": 10929390, "node_id": "MDQ6VXNlcjEwOTI5Mzkw", "avatar_url": "https://avatars1.githubusercontent.com/u/10929390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/melissachang", "html_url": "https://github.com/melissachang", "followers_url": "https://api.github.com/users/melissachang/followers", "following_url": "https://api.github.com/users/melissachang/following{/other_user}", "gists_url": "https://api.github.com/users/melissachang/gists{/gist_id}", "starred_url": "https://api.github.com/users/melissachang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/melissachang/subscriptions", "organizations_url": "https://api.github.com/users/melissachang/orgs", "repos_url": "https://api.github.com/users/melissachang/repos", "events_url": "https://api.github.com/users/melissachang/events{/privacy}", "received_events_url": "https://api.github.com/users/melissachang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}, {"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-09-17T19:10:36Z", "updated_at": "2019-05-24T17:47:55Z", "closed_at": "2019-05-24T17:47:55Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I am using pandas with BigQuery tables. Because pandas doesn't support boolean missing values, BigQuery BOOLEAN columns become dataframe object columns. I have to use to_gbq() table_schema to convert force those columns back to BOOLEAN.\r\n\r\nMy dataframe has 62 columns. table_schema has to include every column. It would be nice if I could only pass in the boolean columns in table_schema; for the other columns, to_gbq should default to dataframe column type.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/215", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/215/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/215/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/215/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/215", "id": 360139184, "node_id": "MDU6SXNzdWUzNjAxMzkxODQ=", "number": 215, "title": "Master failing", "user": {"login": "max-sixty", "id": 5635139, "node_id": "MDQ6VXNlcjU2MzUxMzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/max-sixty", "html_url": "https://github.com/max-sixty", "followers_url": "https://api.github.com/users/max-sixty/followers", "following_url": "https://api.github.com/users/max-sixty/following{/other_user}", "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}", "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions", "organizations_url": "https://api.github.com/users/max-sixty/orgs", "repos_url": "https://api.github.com/users/max-sixty/repos", "events_url": "https://api.github.com/users/max-sixty/events{/privacy}", "received_events_url": "https://api.github.com/users/max-sixty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-09-14T02:59:35Z", "updated_at": "2018-09-14T22:09:12Z", "closed_at": "2018-09-14T22:09:12Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "@tswast, do you recognize whether this an issue of the creds on the pandas-gbq travis being expired?\r\n\r\nhttps://travis-ci.org/pydata/pandas-gbq/jobs/428221719\r\n\r\nRunning with my creds works great: https://travis-ci.org/max-sixty/pandas-gbq", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/213", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/213/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/213/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/213/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/213", "id": 358596467, "node_id": "MDU6SXNzdWUzNTg1OTY0Njc=", "number": 213, "title": "`to_gbq` doesn't respect location argument when it also creates dataset", "user": {"login": "robertlacok", "id": 3392654, "node_id": "MDQ6VXNlcjMzOTI2NTQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/3392654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/robertlacok", "html_url": "https://github.com/robertlacok", "followers_url": "https://api.github.com/users/robertlacok/followers", "following_url": "https://api.github.com/users/robertlacok/following{/other_user}", "gists_url": "https://api.github.com/users/robertlacok/gists{/gist_id}", "starred_url": "https://api.github.com/users/robertlacok/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/robertlacok/subscriptions", "organizations_url": "https://api.github.com/users/robertlacok/orgs", "repos_url": "https://api.github.com/users/robertlacok/repos", "events_url": "https://api.github.com/users/robertlacok/events{/privacy}", "received_events_url": "https://api.github.com/users/robertlacok/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-09-10T12:15:40Z", "updated_at": "2018-10-05T07:51:49Z", "closed_at": "2018-10-05T07:51:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When trying to use the `to_gbq` method to both create dataset and the table, the method fails when setting the location other than `US`. \r\n\r\nThe reason is that the location is not respected when creating dataset, so it defaults to `US`. However, trying to launch a LoadJob with `location='EU'` when the dataset is in the `US` leads to failure.\r\n\r\nSteps to reproduce: \r\n```\r\nto_gbq(df, 'my_dataset.my_table', google_cloud_project, location='EU')\r\n```\r\nwhere `my_dataset` doesn't exist. \r\n\r\n\r\nI can try fixing it by passing the `location` argument down to constructors of `_Table` and `_Dataset`, and then [here](https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/gbq.py#L1133) in the `create` method of `_Dataset` doing something like:\r\n```\r\nif self.location is not None:\r\n    dataset.location = self.location\r\n```\r\n\r\nIf you OK it I will test and submit a PR. Is there a better way? \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/211", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/211/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/211/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/211/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/211", "id": 357421465, "node_id": "MDU6SXNzdWUzNTc0MjE0NjU=", "number": 211, "title": "TST: update to latest version of Nox", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-09-05T22:04:55Z", "updated_at": "2018-09-21T19:23:49Z", "closed_at": "2018-09-21T19:23:49Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "https://github.com/theacodes/nox/releases/tag/2018.8.23\r\n\r\nThe biggest change relevant to us is that nox changed how to specify Python versions for sessions.\r\n\r\n> Please consult the documentation on how to use @nox.session(python=[...]) to configure virtualenvs for sessions.\r\n\r\nRelevant docs: https://nox.readthedocs.io/en/stable/config.html#virtualenv-config\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/205", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/205/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/205/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/205/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/205", "id": 355225446, "node_id": "MDU6SXNzdWUzNTUyMjU0NDY=", "number": 205, "title": "MemoryError while reading nearly 1.8M rows of data from Bigquery table", "user": {"login": "HarshCHhz", "id": 33054269, "node_id": "MDQ6VXNlcjMzMDU0MjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/33054269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HarshCHhz", "html_url": "https://github.com/HarshCHhz", "followers_url": "https://api.github.com/users/HarshCHhz/followers", "following_url": "https://api.github.com/users/HarshCHhz/following{/other_user}", "gists_url": "https://api.github.com/users/HarshCHhz/gists{/gist_id}", "starred_url": "https://api.github.com/users/HarshCHhz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HarshCHhz/subscriptions", "organizations_url": "https://api.github.com/users/HarshCHhz/orgs", "repos_url": "https://api.github.com/users/HarshCHhz/repos", "events_url": "https://api.github.com/users/HarshCHhz/events{/privacy}", "received_events_url": "https://api.github.com/users/HarshCHhz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-08-29T15:52:40Z", "updated_at": "2018-08-30T00:57:10Z", "closed_at": "2018-08-29T16:33:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, while trying to fetch the data of 1.8 M rows from Bigquery to local machine, we are getting Memory Error.\r\n\r\nImport pandas_gbq as pgbq\r\ndf= pgbq.read_gbq(sql, dialect)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/203", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/203/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/203/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/203/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/203", "id": 354886367, "node_id": "MDU6SXNzdWUzNTQ4ODYzNjc=", "number": 203, "title": "pandas requires google-cloud-python for Google BigQuery support:", "user": {"login": "netskink", "id": 4422172, "node_id": "MDQ6VXNlcjQ0MjIxNzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/4422172?v=4", "gravatar_id": "", "url": "https://api.github.com/users/netskink", "html_url": "https://github.com/netskink", "followers_url": "https://api.github.com/users/netskink/followers", "following_url": "https://api.github.com/users/netskink/following{/other_user}", "gists_url": "https://api.github.com/users/netskink/gists{/gist_id}", "starred_url": "https://api.github.com/users/netskink/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/netskink/subscriptions", "organizations_url": "https://api.github.com/users/netskink/orgs", "repos_url": "https://api.github.com/users/netskink/repos", "events_url": "https://api.github.com/users/netskink/events{/privacy}", "received_events_url": "https://api.github.com/users/netskink/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2018-08-28T20:14:37Z", "updated_at": "2018-10-04T10:05:53Z", "closed_at": "2018-08-28T21:32:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I used to do this in a datalab notebook\r\n\r\n`df = gbq.read_gbq('SELECT * FROM gsd_sample.blackman75', PROJECT)`\r\n\r\nNow, it says \r\n`ImportError: pandas requires google-cloud-python for Google BigQuery support: cannot import name make_exception\r\n`\r\n\r\nIn the python notebook, I am doing:\r\n\r\n```\r\nimport math\r\nimport shutil\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nimport re\r\nimport matplotlib.pyplot as plt\r\nimport IPython.display as ipd\r\nimport os\r\nimport io\r\nimport sys\r\nimport base64\r\nimport hashlib\r\nfrom sklearn import preprocessing\r\nimport datetime\r\nfrom pandas.io import gbq\r\n\r\n\r\nimport apache_beam as beam\r\nprint tf.__version__\r\n```\r\n\r\nAnd prior to that, I do this in the datalab notebook\r\n\r\n`!pip install librosa soundfile google-cloud-storage pandas-gbq google-cloud-bigquery pandas-gbq google-cloud -U`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/202", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/202/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/202/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/202/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/202", "id": 354834838, "node_id": "MDU6SXNzdWUzNTQ4MzQ4Mzg=", "number": 202, "title": "_try_credentials requires read permissions", "user": {"login": "telenieko", "id": 10505, "node_id": "MDQ6VXNlcjEwNTA1", "avatar_url": "https://avatars2.githubusercontent.com/u/10505?v=4", "gravatar_id": "", "url": "https://api.github.com/users/telenieko", "html_url": "https://github.com/telenieko", "followers_url": "https://api.github.com/users/telenieko/followers", "following_url": "https://api.github.com/users/telenieko/following{/other_user}", "gists_url": "https://api.github.com/users/telenieko/gists{/gist_id}", "starred_url": "https://api.github.com/users/telenieko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/telenieko/subscriptions", "organizations_url": "https://api.github.com/users/telenieko/orgs", "repos_url": "https://api.github.com/users/telenieko/repos", "events_url": "https://api.github.com/users/telenieko/events{/privacy}", "received_events_url": "https://api.github.com/users/telenieko/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-08-28T17:43:20Z", "updated_at": "2018-08-31T20:49:26Z", "closed_at": "2018-08-31T20:49:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am trying out pandas-gbq as part of a data loading process (we load lots of stuff into DataFrame's for cleanup and processing, and the final result is loaded into BigQuery).\r\n\r\nOn that use case, the account used needs only write access to BigQuery but _try_credentials issues a SELECT which makes it fail.\r\n\r\nMoreover, this is run on GCP so google.auth.default() succeeds but as the SELECT fails, the library tries interactive authentication which fails.\r\n\r\nEither _try_credentials should not require read permissions (unless on a read operation) or the method should be optional.\r\n\r\nRelated to  #198 ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/199", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/199/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/199/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/199/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/199", "id": 353272770, "node_id": "MDU6SXNzdWUzNTMyNzI3NzA=", "number": 199, "title": "support new version of datalab", "user": {"login": "yoavMoon", "id": 36665648, "node_id": "MDQ6VXNlcjM2NjY1NjQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/36665648?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yoavMoon", "html_url": "https://github.com/yoavMoon", "followers_url": "https://api.github.com/users/yoavMoon/followers", "following_url": "https://api.github.com/users/yoavMoon/following{/other_user}", "gists_url": "https://api.github.com/users/yoavMoon/gists{/gist_id}", "starred_url": "https://api.github.com/users/yoavMoon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yoavMoon/subscriptions", "organizations_url": "https://api.github.com/users/yoavMoon/orgs", "repos_url": "https://api.github.com/users/yoavMoon/repos", "events_url": "https://api.github.com/users/yoavMoon/events{/privacy}", "received_events_url": "https://api.github.com/users/yoavMoon/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-08-23T08:17:16Z", "updated_at": "2018-08-23T18:06:18Z", "closed_at": "2018-08-23T18:06:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm getting this incompatibility error when upgrading pandas-gbq:\r\n\r\n**google-cloud-monitoring 0.28.0 has requirement google-api-core<0.2.0dev,>=0.1.1, but you'll have google-api-core 1.3.0 which is incompatible.**\r\n\r\n My datalab version is: 1.2.20180818", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/198", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/198/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/198/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/198/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/198", "id": 352653826, "node_id": "MDU6SXNzdWUzNTI2NTM4MjY=", "number": 198, "title": "Do we need to SELECT 1 before each query?", "user": {"login": "max-sixty", "id": 5635139, "node_id": "MDQ6VXNlcjU2MzUxMzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/max-sixty", "html_url": "https://github.com/max-sixty", "followers_url": "https://api.github.com/users/max-sixty/followers", "following_url": "https://api.github.com/users/max-sixty/following{/other_user}", "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}", "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions", "organizations_url": "https://api.github.com/users/max-sixty/orgs", "repos_url": "https://api.github.com/users/max-sixty/repos", "events_url": "https://api.github.com/users/max-sixty/events{/privacy}", "received_events_url": "https://api.github.com/users/max-sixty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-08-21T18:16:19Z", "updated_at": "2018-09-05T21:23:57Z", "closed_at": "2018-09-05T21:23:57Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "With the recent clustering release, we're looking at whether we can use BQ for queries which previously required an indexed DB.\r\n\r\nFor these, the overhead is more important than the throughput. The overhead is high - in the case that the query is cached (if not, add 1s to all these, for a 700 row query on a small cluster):\r\n- 73ms: query time reported by BQ\r\n- 1160ms: query time logged by `pandas-gbq`\r\n- 3100ms: wall time reported by `%timeit -n 1 -r 1 gbq.read_gbq(query)`\r\n\r\nThe latter two are particularly far apart. One of the reasons for this is that we issue a `SELECT 1` query before each query the user submits. This happens as part of `_try_credentials`: https://github.com/pydata/pandas-gbq/blob/e753cc4e61b0089dcea6330eb8c77e93a62984a7/pandas_gbq/auth.py#L281\r\n\r\nIs this required? Could we instead attempt the query, and only attempt different auth methods if there's a failure?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/197", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/197/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/197/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/197/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/197", "id": 350906288, "node_id": "MDU6SXNzdWUzNTA5MDYyODg=", "number": 197, "title": "TST: Test on Python 3.7", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535013928, "node_id": "MDU6TGFiZWw1MzUwMTM5Mjg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20cleanup", "name": "type: cleanup", "color": "c5def5", "default": false, "description": "An internal cleanup or hygiene concern."}, {"id": 535065536, "node_id": "MDU6TGFiZWw1MzUwNjU1MzY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20process", "name": "type: process", "color": "c5def5", "default": false, "description": "A process-releated concern. May include testing, release, or the like."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-08-15T18:01:29Z", "updated_at": "2018-11-09T17:33:48Z", "closed_at": "2018-11-09T17:33:46Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/195", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/195/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/195/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/195/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/195", "id": 347216746, "node_id": "MDU6SXNzdWUzNDcyMTY3NDY=", "number": 195, "title": "Make Standard SQL Default", "user": {"login": "RafaelAMello", "id": 35910026, "node_id": "MDQ6VXNlcjM1OTEwMDI2", "avatar_url": "https://avatars0.githubusercontent.com/u/35910026?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RafaelAMello", "html_url": "https://github.com/RafaelAMello", "followers_url": "https://api.github.com/users/RafaelAMello/followers", "following_url": "https://api.github.com/users/RafaelAMello/following{/other_user}", "gists_url": "https://api.github.com/users/RafaelAMello/gists{/gist_id}", "starred_url": "https://api.github.com/users/RafaelAMello/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RafaelAMello/subscriptions", "organizations_url": "https://api.github.com/users/RafaelAMello/orgs", "repos_url": "https://api.github.com/users/RafaelAMello/repos", "events_url": "https://api.github.com/users/RafaelAMello/events{/privacy}", "received_events_url": "https://api.github.com/users/RafaelAMello/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2018-08-03T00:16:22Z", "updated_at": "2019-01-25T20:14:38Z", "closed_at": "2019-01-25T20:14:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "Heya!\r\n\r\nIn the new BigQuery UI Google is rolling out standard SQL as the default for queries, I am wondering if we can do the same with operations using this package?\r\n\r\nThis is a small connivance but it gets me every time.\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/194", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/194/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/194/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/194/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/194", "id": 346362299, "node_id": "MDU6SXNzdWUzNDYzNjIyOTk=", "number": 194, "title": "option to suppress index column in to_gbq", "user": {"login": "dkapitan", "id": 4090894, "node_id": "MDQ6VXNlcjQwOTA4OTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/4090894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dkapitan", "html_url": "https://github.com/dkapitan", "followers_url": "https://api.github.com/users/dkapitan/followers", "following_url": "https://api.github.com/users/dkapitan/following{/other_user}", "gists_url": "https://api.github.com/users/dkapitan/gists{/gist_id}", "starred_url": "https://api.github.com/users/dkapitan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dkapitan/subscriptions", "organizations_url": "https://api.github.com/users/dkapitan/orgs", "repos_url": "https://api.github.com/users/dkapitan/repos", "events_url": "https://api.github.com/users/dkapitan/events{/privacy}", "received_events_url": "https://api.github.com/users/dkapitan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-31T21:19:22Z", "updated_at": "2018-08-01T06:52:58Z", "closed_at": "2018-08-01T06:52:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Not sure if this has been requested before. I would like to be able to suppress the index column of the dataframe when using `df.to_gbq`.\r\n\r\nWould like to hear if this is a reasonable request. If so, I would be happy to contribute (medior experience with Python) if someone could point me in te right direction where to add this feature.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/192", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/192/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/192/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/192/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/192", "id": 343437805, "node_id": "MDU6SXNzdWUzNDM0Mzc4MDU=", "number": 192, "title": "Writing to CSV buffer with default float format causes numerical overflow in BigQuery", "user": {"login": "anthonydelage", "id": 1356592, "node_id": "MDQ6VXNlcjEzNTY1OTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/1356592?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anthonydelage", "html_url": "https://github.com/anthonydelage", "followers_url": "https://api.github.com/users/anthonydelage/followers", "following_url": "https://api.github.com/users/anthonydelage/following{/other_user}", "gists_url": "https://api.github.com/users/anthonydelage/gists{/gist_id}", "starred_url": "https://api.github.com/users/anthonydelage/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anthonydelage/subscriptions", "organizations_url": "https://api.github.com/users/anthonydelage/orgs", "repos_url": "https://api.github.com/users/anthonydelage/repos", "events_url": "https://api.github.com/users/anthonydelage/events{/privacy}", "received_events_url": "https://api.github.com/users/anthonydelage/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-07-22T20:53:58Z", "updated_at": "2018-07-26T15:41:58Z", "closed_at": "2018-07-26T15:41:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm using `to_gbq()` to load a local DataFrame into BigQuery. I'm running into an issue where floating point numbers are gaining significant figures and therefore causing numerical overflow errors when loaded to BigQuery.\r\n\r\nThe `load.py` module's `encode_chunk()` function writes to a local CSV buffer using Pandas' `to_csv()` function, which has a known issue regarding added significant figures on some operating systems (read more [here](https://stackoverflow.com/questions/12877189/float64-with-pandas-to-csv)).\r\n\r\nIn my case, 0.208 was transformed to 0.20800000000000002.\r\n\r\nI've been able to solve the issue locally by changing the `float_format` parameter to `'%g'` in the `encode_chunk()` function's `pd.to_csv()` [call](https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/load.py#L16):\r\n```python\r\ndataframe.to_csv(\r\n    csv_buffer, index=False, header=False, encoding='utf-8',\r\n    float_format='%g', date_format='%Y-%m-%d %H:%M:%S.%f')\r\n```\r\n\r\nCan this be safely applied as a default?\r\n\r\nVersions:\r\n```\r\npandas==0.22.0\r\npandas-gbq==0.5.0\r\n```\r\n\r\nOS details:\r\n```\r\nMacOS 10.13.4\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/189", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/189/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/189/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/189/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/189", "id": 332847760, "node_id": "MDU6SXNzdWUzMzI4NDc3NjA=", "number": 189, "title": "Travis build fails for Conda package", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535013928, "node_id": "MDU6TGFiZWw1MzUwMTM5Mjg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20cleanup", "name": "type: cleanup", "color": "c5def5", "default": false, "description": "An internal cleanup or hygiene concern."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-06-15T16:54:16Z", "updated_at": "2018-12-19T18:20:16Z", "closed_at": "2018-12-19T18:20:16Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "See: https://travis-ci.org/pydata/pandas-gbq/jobs/392794382\r\n\r\nPer https://github.com/conda-forge/staged-recipes/wiki/Namespace-packages, I think we'll probably need to create some empty `google-namespace` and `google-cloud-namespace` Conda packages.\r\n\r\nApplying my previous fix of locking the miniconda version didn't work this time. (https://github.com/pydata/pandas-gbq/pull/187)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/186", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/186/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/186/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/186/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/186", "id": 330837365, "node_id": "MDU6SXNzdWUzMzA4MzczNjU=", "number": 186, "title": "New release to pick up latest google-cloud-bigquery which supports numerics", "user": {"login": "melissachang", "id": 10929390, "node_id": "MDQ6VXNlcjEwOTI5Mzkw", "avatar_url": "https://avatars1.githubusercontent.com/u/10929390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/melissachang", "html_url": "https://github.com/melissachang", "followers_url": "https://api.github.com/users/melissachang/followers", "following_url": "https://api.github.com/users/melissachang/following{/other_user}", "gists_url": "https://api.github.com/users/melissachang/gists{/gist_id}", "starred_url": "https://api.github.com/users/melissachang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/melissachang/subscriptions", "organizations_url": "https://api.github.com/users/melissachang/orgs", "repos_url": "https://api.github.com/users/melissachang/repos", "events_url": "https://api.github.com/users/melissachang/events{/privacy}", "received_events_url": "https://api.github.com/users/melissachang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-06-09T00:33:54Z", "updated_at": "2018-06-12T18:30:20Z", "closed_at": "2018-06-12T18:30:20Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "[4 days ago, bigquery-1.3.0 was released.](https://github.com/GoogleCloudPlatform/google-cloud-python/issues/5432) Can you make a new pandas-gbq release to pick this up? I'm working with a BigQuery table which has a NUMERIC field. read_gbq() throws an error. I'm not sure exactly what combination of record nesting triggers the bug, but it boils down to [_SCALAR_VALUE_TO_JSON_ROW](https://github.com/GoogleCloudPlatform/google-cloud-python/blob/4cea94970a13590f9b79ecc278606e72ff529c8e/bigquery/google/cloud/bigquery/_helpers.py#L311) not having a 'NUMERIC' key.\r\n\r\n@eap", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/182", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/182/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/182/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/182/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/182", "id": 325780393, "node_id": "MDU6SXNzdWUzMjU3ODAzOTM=", "number": 182, "title": "ENH: show progress while fetching rows for query", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}, {"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-05-23T16:21:26Z", "updated_at": "2019-10-28T21:30:16Z", "closed_at": "2019-10-28T21:30:16Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "As reported by @QuinRiva in https://github.com/pydata/pandas-gbq/issues/12#issuecomment-391212920\r\n\r\nProgress is written to logging while a query is running, but no progress is reported between when a query finishes and while the data is being downloaded to be added to a DataFrame. The problem is that we call `list(rows_iter)` to fetch all pages. Previously, progress was written as each page was downloaded.\r\n\r\nhttps://github.com/pydata/pandas-gbq/blob/08166685d3305a57fbfd3bc4c41a1cf5df98ebcf/pandas_gbq/gbq.py#L294-L299\r\n\r\nA possible solution is to loop over [`rows_iter.pages`](https://google-cloud-python.readthedocs.io/en/latest/bigquery/reference.html#google.cloud.bigquery.table.RowIterator.pages) instead. After the first page is fetched, the `rows_iter.total_rows` property is available, so it would be possible to display a percent complete or even use `tqdm` as done in https://github.com/pydata/pandas-gbq/pull/166.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/180", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/180/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/180/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/180/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/180", "id": 324705332, "node_id": "MDU6SXNzdWUzMjQ3MDUzMzI=", "number": 180, "title": "load job config allow quoted newlines ", "user": {"login": "jwBoral", "id": 39459150, "node_id": "MDQ6VXNlcjM5NDU5MTUw", "avatar_url": "https://avatars0.githubusercontent.com/u/39459150?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwBoral", "html_url": "https://github.com/jwBoral", "followers_url": "https://api.github.com/users/jwBoral/followers", "following_url": "https://api.github.com/users/jwBoral/following{/other_user}", "gists_url": "https://api.github.com/users/jwBoral/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwBoral/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwBoral/subscriptions", "organizations_url": "https://api.github.com/users/jwBoral/orgs", "repos_url": "https://api.github.com/users/jwBoral/repos", "events_url": "https://api.github.com/users/jwBoral/events{/privacy}", "received_events_url": "https://api.github.com/users/jwBoral/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-05-20T12:23:18Z", "updated_at": "2018-10-26T18:13:39Z", "closed_at": "2018-10-26T18:13:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/load.py\r\n\r\nneeds to add the condition\r\n\r\njob_config.allow_quoted_newlines = True \r\n\r\ncurrent work around is: \r\ndf = df.replace({'\\n': ' ', '\\r\\n': ' ', '\\r': ' '}, regex=True)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/179", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/179/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/179/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/179/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/179", "id": 322513242, "node_id": "MDU6SXNzdWUzMjI1MTMyNDI=", "number": 179, "title": "Difference between pandas.read_gbq vs pandas_gbq.read_gbq in reading large tables?", "user": {"login": "heoa", "id": 1807927, "node_id": "MDQ6VXNlcjE4MDc5Mjc=", "avatar_url": "https://avatars2.githubusercontent.com/u/1807927?v=4", "gravatar_id": "", "url": "https://api.github.com/users/heoa", "html_url": "https://github.com/heoa", "followers_url": "https://api.github.com/users/heoa/followers", "following_url": "https://api.github.com/users/heoa/following{/other_user}", "gists_url": "https://api.github.com/users/heoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/heoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/heoa/subscriptions", "organizations_url": "https://api.github.com/users/heoa/orgs", "repos_url": "https://api.github.com/users/heoa/repos", "events_url": "https://api.github.com/users/heoa/events{/privacy}", "received_events_url": "https://api.github.com/users/heoa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-05-12T13:53:36Z", "updated_at": "2018-05-12T20:19:53Z", "closed_at": "2018-05-12T20:19:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "It looks like `pandas.read_gbq` and `pandas_gbq.read_gbq` are about the same. I am getting memory alloted errors, even with chunksize option, with large tables using the equivalent reading functions of the packages. I am wondering whether this package `pandas_gbg.read_gbq` has the same interface as the `pandas.read_gbq`? Are they the same?\r\n\r\nWith both packages `pandas.read_gbq` and `pandas_gbq.read_gbq`, the error is like\r\n\r\n> google.api_core.exceptions.BadRequest: 400 GET https://www.googleapis.com/bigquery/v2/projects/yyy/queries/xxx?maxResults=0&timeoutMs=900: Resources exceeded during query execution: The query could not be executed in the allotted memory. Sort operator used for PARTITION BY used too much memory.\r\n\r\nwhere the error is ambiguous because of no `sort` and no `partition by`, the table is just too large for BigQuery to handle. Things work fine with smaller tables.\r\n\r\n**What is the difference between `pandas.read_gbq` and `pandas_gbq.read_gbq`? What are options to read large tables with `pandas_gbq.read_gbq` or `pandas.read_gbq`?**", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/178", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/178/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/178/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/178/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/178", "id": 322260952, "node_id": "MDU6SXNzdWUzMjIyNjA5NTI=", "number": 178, "title": "Conflicting requirements for google-cloud 0.32", "user": {"login": "aktech", "id": 5647941, "node_id": "MDQ6VXNlcjU2NDc5NDE=", "avatar_url": "https://avatars2.githubusercontent.com/u/5647941?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aktech", "html_url": "https://github.com/aktech", "followers_url": "https://api.github.com/users/aktech/followers", "following_url": "https://api.github.com/users/aktech/following{/other_user}", "gists_url": "https://api.github.com/users/aktech/gists{/gist_id}", "starred_url": "https://api.github.com/users/aktech/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aktech/subscriptions", "organizations_url": "https://api.github.com/users/aktech/orgs", "repos_url": "https://api.github.com/users/aktech/repos", "events_url": "https://api.github.com/users/aktech/events{/privacy}", "received_events_url": "https://api.github.com/users/aktech/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-11T11:17:51Z", "updated_at": "2018-05-11T14:10:42Z", "closed_at": "2018-05-11T14:10:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Here are the two conflicting requirements:\r\n\r\n`pandas-gbq` doesn't works with google-cloud 0.32\r\n\r\n```\r\npandas-gbq 0.4.1 has requirement google-cloud-bigquery>=0.29.0, but you'll have google-cloud-bigquery 0.28.0 which is incompatible.\r\n```\r\n\r\n```\r\ngoogle-cloud 0.32.0 has requirement google-cloud-bigquery<0.29dev,>=0.28.0, but you'll have google-cloud-bigquery 0.30.0 which is incompatible.\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/177", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/177/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/177/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/177/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/177", "id": 320837836, "node_id": "MDU6SXNzdWUzMjA4Mzc4MzY=", "number": 177, "title": "specify geographical location of table in pandas read_gbq", "user": {"login": "rmporsch", "id": 3382854, "node_id": "MDQ6VXNlcjMzODI4NTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/3382854?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmporsch", "html_url": "https://github.com/rmporsch", "followers_url": "https://api.github.com/users/rmporsch/followers", "following_url": "https://api.github.com/users/rmporsch/following{/other_user}", "gists_url": "https://api.github.com/users/rmporsch/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmporsch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmporsch/subscriptions", "organizations_url": "https://api.github.com/users/rmporsch/orgs", "repos_url": "https://api.github.com/users/rmporsch/repos", "events_url": "https://api.github.com/users/rmporsch/events{/privacy}", "received_events_url": "https://api.github.com/users/rmporsch/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-05-07T14:59:04Z", "updated_at": "2018-06-25T18:00:00Z", "closed_at": "2018-06-25T18:00:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am having trouble setting the geographical location in `pandas.read_gbq`.\r\n\r\nIn `google.cloud.bigquery` I can set the location to `asia-northeast1` the following:\r\n\r\n```\r\nfrom google.cloud import bigquery\r\nbigquery_client = bigquery.Client(project_name)    \r\nquery_job = bigquery_client.query(query, location='asia-northeast1')\r\n\r\n```\r\nHowever, I fail to do this in `read_gbq`. The following seems not to  work:\r\n\r\n```\r\nfrom pandas_gbq import gbq    \r\ndat = gbq.read_gbq(query, project_id=project_name, jobReference={'location':'asia-northeast1'}, dialect='standard')\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/175", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/175/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/175/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/175/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/175", "id": 320449806, "node_id": "MDU6SXNzdWUzMjA0NDk4MDY=", "number": 175, "title": "TIMESTAMP columns should include timezone in datetime dtype", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-05-04T22:37:32Z", "updated_at": "2019-06-14T17:33:21Z", "closed_at": "2019-06-14T17:33:20Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "I would expect the dtype for a TIMESTAMP column to be time zone aware.\r\n\r\n```\r\nIn [1]: import pandas_gbq\r\n\r\nIn [2]: df = pandas_gbq.read_gbq('SELECT TIMESTAMP(\"2004-09-15 05:00:00\") AS valid_timestamp')\r\n\r\nIn [3]: df.dtypes\r\nOut[3]:\r\nvalid_timestamp    datetime64[ns]\r\ndtype: object\r\n```\r\n\r\nNote: I believe the behavior used to be correct (include the timezone). [NumPy 1.11 stopped defaulting to UTC and instead uses a naive datetime](https://github.com/numpy/numpy/blob/master/doc/source/reference/arrays.datetime.rst#changes-with-numpy-111).\r\n\r\nRelated: see https://github.com/pydata/pandas-gbq/issues/69 for support for DATETIME columns (which do expect a naive datetime).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/174", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/174/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/174/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/174/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/174", "id": 320434476, "node_id": "MDU6SXNzdWUzMjA0MzQ0NzY=", "number": 174, "title": "pandas-gbq handles nulls in numeric columns differently from pandas", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-05-04T21:23:02Z", "updated_at": "2018-11-09T05:16:09Z", "closed_at": "2018-10-13T02:36:14Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "[Pandas encodes missing / null data as NaN in numeric columns](https://pandas.pydata.org/pandas-docs/stable/missing_data.html).\r\n\r\npandas-gbq expects the type of a column containing Nulls to be object.\r\nhttps://github.com/pydata/pandas-gbq/blob/f301442082bab62c793b6a80cf00c03f97938609/tests/system.py#L295-L302\r\n\r\nShouldn't pandas-gbq align with the choice of pandas in this case?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/168", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/168/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/168/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/168/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/168", "id": 316524346, "node_id": "MDU6SXNzdWUzMTY1MjQzNDY=", "number": 168, "title": "Tests failing on master", "user": {"login": "max-sixty", "id": 5635139, "node_id": "MDQ6VXNlcjU2MzUxMzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/max-sixty", "html_url": "https://github.com/max-sixty", "followers_url": "https://api.github.com/users/max-sixty/followers", "following_url": "https://api.github.com/users/max-sixty/following{/other_user}", "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}", "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions", "organizations_url": "https://api.github.com/users/max-sixty/orgs", "repos_url": "https://api.github.com/users/max-sixty/repos", "events_url": "https://api.github.com/users/max-sixty/events{/privacy}", "received_events_url": "https://api.github.com/users/max-sixty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-04-21T20:52:17Z", "updated_at": "2018-04-25T03:48:08Z", "closed_at": "2018-04-25T03:48:08Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "@tswast do you recognize these? https://travis-ci.org/pydata/pandas-gbq/jobs/364877445\r\n\r\nI can't immediately see how 8f49ec3f134cc0a85f541116c42647c515fdc7e6 could have caused those\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/167", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/167/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/167/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/167/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/167", "id": 316522858, "node_id": "MDU6SXNzdWUzMTY1MjI4NTg=", "number": 167, "title": "'Bulk' download", "user": {"login": "max-sixty", "id": 5635139, "node_id": "MDQ6VXNlcjU2MzUxMzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/max-sixty", "html_url": "https://github.com/max-sixty", "followers_url": "https://api.github.com/users/max-sixty/followers", "following_url": "https://api.github.com/users/max-sixty/following{/other_user}", "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}", "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions", "organizations_url": "https://api.github.com/users/max-sixty/orgs", "repos_url": "https://api.github.com/users/max-sixty/repos", "events_url": "https://api.github.com/users/max-sixty/events{/privacy}", "received_events_url": "https://api.github.com/users/max-sixty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-21T20:29:00Z", "updated_at": "2019-08-09T22:38:19Z", "closed_at": "2019-08-09T22:38:18Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "ref: https://github.com/pydata/pandas-gbq/issues/133\r\n\r\nHere's some code we're trying internally to make larger downloads possible / faster.\r\n\r\nLet me know thoughts (and anyone is welcome to take this and do a PR if they'd like, similar to bulk upload)\r\n\r\n```python\r\nfrom google.cloud import bigquery, storage\r\n\r\n\r\n# https://stackoverflow.com/questions/14622526\r\ndef create_from_query(query, dataset, table, block=False, if_exists='fail',\r\n                      project=None, credentials=None):\r\n    \"\"\"\r\n    Create a bigquery table from a query\r\n\r\n    Parameters\r\n    ----------\r\n    query : str\r\n        SQL-Like Query to return data values\r\n    dataset : str\r\n        dataset id\r\n    table : str\r\n        name of table\r\n    block : bool (default False)\r\n    if_exists : str (default: 'fail')\r\n        append - Specifies that rows may be appended to an existing table\r\n        fail - Specifies that the output table must be empty\r\n        replace - Specifies that write should replace a table\r\n    project : str (default to env var GOOGLE_CLOUD_PROJECT)\r\n        Google BigQuery Account project ID.\r\n    credentials : GoogleCredentials (optional)\r\n        Name of result column to use for index in results DataFrame\r\n\r\n    Returns\r\n    -------\r\n    job: google.cloud.bigquery.job.QueryJob\r\n        Returns the inserted QueryJob\r\n    \"\"\"\r\n    client = bigquery.Client(project=project, credentials=credentials)\r\n    if dataset not in [x.dataset_id for x in client.list_datasets()]:\r\n        # https://github.com/GoogleCloudPlatform/google-cloud-python/issues/4930\r\n        dataset = bigquery.Dataset(client.dataset(dataset))\r\n        client.create_dataset(dataset)\r\n    config = bigquery.job.QueryJobConfig()\r\n    config.use_legacy_sql = False\r\n    config.allow_large_results = True\r\n    config.destination = client.dataset(dataset).table(table)\r\n    config.write_disposition = if_exists_map[if_exists]\r\n    job_id = uuid.uuid4().hex[:10]\r\n    job = client.query(query=query, job_id=job_id, job_config=config)\r\n    if block:\r\n        wait_for_job(job)\r\n    return job\r\n\r\n\r\ndef export_table_to_gcs(\r\n    dataset,\r\n    table,\r\n    timeout_in_seconds=600,\r\n    bucket=None,\r\n    blob=None,\r\n    zipped=True,\r\n):\r\n    \"\"\"\r\n    export table to gcs.  returns tuple of (bucket, blob)\r\n    \"\"\"\r\n    client = bigquery.Client(GOOGLE_CLOUD_PROJECT)\r\n    table_ref = client.dataset(dataset).table(table)\r\n    job_config = ExtractJobConfig()\r\n    job_config.compression = 'GZIP' if zipped else 'NONE'\r\n    bucket = bucket or '{}-temp'.format(client.project)\r\n    blob = blob or '{}/{}.csv'.format(dataset, table)\r\n    if zipped and not blob.endswith('.gz'):\r\n        blob += '.gz'\r\n    destination_uri = 'gs://{}/{}'.format(bucket, blob)\r\n    extract_job = client.extract_table(\r\n        table_ref, destination_uri, job_config=job_config)\r\n    extract_job.result(timeout=timeout_in_seconds)\r\n    logger.info('Exported {}.{} -> {}'.format(dataset, table, destination_uri))\r\n    return bucket, blob\r\n\r\n\r\nDEFAULT_BUCKET = '{}-temp'.format(GOOGLE_CLOUD_PROJECT)\r\n\r\n\r\ndef read_table(\r\n        dataset,\r\n        table,\r\n        project=None,\r\n        credentials=None,\r\n        timeout_in_seconds=600,\r\n        bucket=DEFAULT_BUCKET,\r\n):\r\n    \"\"\"\r\n    reads an entire table from gbq into a dataframe\r\n    \"\"\"\r\n\r\n    storage = storage.Client(project, credentials)\r\n    prefix = 'gbq-exports/{}/{}/'.format(dataset, table)\r\n    bucket = storage.get_bucket(bucket)\r\n\r\n    for old_blob in bucket.list_blobs(prefix=prefix):\r\n        old_blob.delete()\r\n        logger.info('Old Blob Deleted: {}'.format(old_blob.name))\r\n\r\n    bq = bigquery.Client(project=project, credentials=credentials)\r\n    table = bq.dataset(dataset).table(table)\r\n\r\n    conf = ExtractJobConfig()\r\n    conf.compression = 'GZIP'\r\n\r\n    extract_job = bq.extract_table(\r\n        table,\r\n        'gs://{}/{}*.csv.gz'.format(bucket.name, prefix),\r\n        job_config=conf)\r\n\r\n    extract_job.result(timeout=timeout_in_seconds)\r\n\r\n    frames = []\r\n\r\n    path = tempfile.mkdtemp()\r\n    for blob in bucket.list_blobs(prefix=prefix):\r\n        filename = '{}/{}'.format(path, blob.name.replace('/', '__'))\r\n\r\n        with open(filename, 'wb') as f:\r\n            blob.download_to_file(f)\r\n\r\n        frames.append(pd.read_csv(filename))\r\n        blob.delete()\r\n        logger.info('Processed: {}'.format(blob.name))\r\n\r\n    return pd.concat(frames)\r\n\r\n\r\ndef read_gbq_bulk(\r\n    query,\r\n    project=None,\r\n    bucket=None,\r\n    dataset='temp_pandas',\r\n    credentials=None,\r\n):\r\n\r\n    table_name = uuid.uuid4().hex[:6]\r\n    create_from_query(\r\n        query=query,\r\n        dataset=dataset,\r\n        table=table_name,\r\n        project=project,\r\n        credentials=credentials,\r\n        block=True,\r\n    )\r\n\r\n    df = read_table(\r\n        dataset=dataset,\r\n        table=table_name,\r\n        project=project,\r\n    )\r\n\r\n    bq = bigquery.Client(project=project, credentials=credentials)\r\n    table = bq.dataset(dataset).table(table_name)\r\n    bq.delete_table(table)\r\n\r\n    return df\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/165", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/165/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/165/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/165/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/165", "id": 313807728, "node_id": "MDU6SXNzdWUzMTM4MDc3Mjg=", "number": 165, "title": "google-cloud-bigquery version conflicts with google-cloud", "user": {"login": "macklin", "id": 2181195, "node_id": "MDQ6VXNlcjIxODExOTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/2181195?v=4", "gravatar_id": "", "url": "https://api.github.com/users/macklin", "html_url": "https://github.com/macklin", "followers_url": "https://api.github.com/users/macklin/followers", "following_url": "https://api.github.com/users/macklin/following{/other_user}", "gists_url": "https://api.github.com/users/macklin/gists{/gist_id}", "starred_url": "https://api.github.com/users/macklin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/macklin/subscriptions", "organizations_url": "https://api.github.com/users/macklin/orgs", "repos_url": "https://api.github.com/users/macklin/repos", "events_url": "https://api.github.com/users/macklin/events{/privacy}", "received_events_url": "https://api.github.com/users/macklin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-04-12T16:49:06Z", "updated_at": "2018-04-12T23:37:07Z", "closed_at": "2018-04-12T20:09:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "In a python environment [1] with the following packages installed:\r\n\r\n```bash\r\n$ pip list\r\ncertifi (2018.1.18)\r\nnumpy (1.14.2)\r\npandas (0.22.0)\r\npip (9.0.3)\r\npython-dateutil (2.7.2)\r\npytz (2018.4)\r\nsetuptools (39.0.1)\r\nsix (1.11.0)\r\nwheel (0.31.0)\r\n```\r\n\r\nand with a minimal `setup.py`:\r\n\r\n```python\r\nfrom setuptools import setup, find_packages\r\n\r\nsetup(name='foobar',\r\n      version='0.0.1',\r\n      install_requires=['google-auth', 'google-cloud', 'pandas-gbq']\r\n     )\r\n```\r\n\r\nif I run `python setup.py install`, I get the following (truncated) log messages that end with an error:\r\n\r\n```\r\n...\r\nSearching for google-cloud-bigquery>=0.29.0\r\nReading https://pypi.python.org/simple/google-cloud-bigquery/\r\nDownloading https://files.pythonhosted.org/packages/f5/46/118110e0115628eef49577cb639bf6aaa545fbd860dfb336f5b0d81789d5/google_cloud_bigquery-1.0.0-py2.py3-none-any.whl#sha256=593cc03a06f88cccd9c73a10610145e23229e07e2b97c613995968a2efbe7362\r\nBest match: google-cloud-bigquery 1.0.0\r\nProcessing google_cloud_bigquery-1.0.0-py2.py3-none-any.whl\r\nInstalling google_cloud_bigquery-1.0.0-py2.py3-none-any.whl to /.../anaconda3/envs/delete_me/lib/python3.5/site-packages\r\nwriting requirements to /.../anaconda3/envs/delete_me/lib/python3.5/site-packages/google_cloud_bigquery-1.0.0-py3.5.egg/EGG-INFO/requires.txt\r\nAdding google-cloud-bigquery 1.0.0 to easy-install.pth file\r\n\r\nInstalled /.../anaconda3/envs/delete_me/lib/python3.5/site-packages/google_cloud_bigquery-1.0.0-py3.5.egg\r\n...\r\n\r\nerror: google-cloud-bigquery 1.0.0 is installed but google-cloud-bigquery<0.29dev,>=0.28.0 is required by {'google-cloud'}\r\n```\r\nAre there bleeding-edge features of `google-cloud-bigquery` that `pandas-gbq` relies on?  It'd be nice to maintain consistency with `google-cloud`, but maybe the solution is to push `google-cloud` to update their dependencies to use more recent versions of `google-cloud-bigquery`?  In the meantime, are there any relatively clean workarounds to this issue?\r\n\r\nThank you!\r\n\r\n[1] The python environment was created by running:\r\n```\r\nconda create -n delete_me python=3.5\r\nsource activate delete_me\r\npip install pandas\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/162", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/162/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/162/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/162/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/162", "id": 312164225, "node_id": "MDU6SXNzdWUzMTIxNjQyMjU=", "number": 162, "title": "Progress bar for to_gbq", "user": {"login": "cgarciae", "id": 5862228, "node_id": "MDQ6VXNlcjU4NjIyMjg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5862228?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgarciae", "html_url": "https://github.com/cgarciae", "followers_url": "https://api.github.com/users/cgarciae/followers", "following_url": "https://api.github.com/users/cgarciae/following{/other_user}", "gists_url": "https://api.github.com/users/cgarciae/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgarciae/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgarciae/subscriptions", "organizations_url": "https://api.github.com/users/cgarciae/orgs", "repos_url": "https://api.github.com/users/cgarciae/repos", "events_url": "https://api.github.com/users/cgarciae/events{/privacy}", "received_events_url": "https://api.github.com/users/cgarciae/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-04-07T02:44:55Z", "updated_at": "2018-04-29T04:48:36Z", "closed_at": "2018-04-29T04:48:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "It would be awesome to get some feed back on the status of the upload if possible. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/161", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/161/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/161/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/161/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/161", "id": 312156054, "node_id": "MDU6SXNzdWUzMTIxNTYwNTQ=", "number": 161, "title": "pandas-gbq auth proposal", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-04-07T00:41:31Z", "updated_at": "2019-09-09T20:53:35Z", "closed_at": "2019-01-04T17:18:06Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "## Overview\r\n\r\nThe current auth flows for pandas-gbq are a bit confusing and hard to customize. \r\n\r\n**Final desired state**. The `pandas_gbq` module should have the following (changes in **bold**):\r\n\r\n*   read_gbq(query, project_id [**optional**], index_col=None, col_order=None, reauth, verbose [deprecated], private_key [**deprecated**], auth_local_webserver, dialect='legacy', configuration [optional], credentials [**new param, optional**])\r\n*   to_gbq(dataframe, destination_table, project_id [**optional**], chunksize=None, verbose [deprecated], reauth, if_exists='fail', private_key [**deprecated**], auth_local_webserver, table_schema=None, credentials [**new param, optional**])\r\n*   **CredentialsCache** (and **WriteOnlyCredentialsCache**, **NoopCredentialsCache**) - new class (and subclasses) for configuring user credentials caching behavior\r\n*   **context** - global singleton with \"client\" property for caching default client in-memory.\r\n*   **get_user_credentials**(**scopes**=None, **credentials_cache**=None, **client_secrets**=None, **use_localhost_webserver**=False) - Helper function to get user authentication credentials.\r\n\r\n**Tasks**:\r\n\r\n*   [x] Add authentication documentation with examples.\r\n*   [x] Add optional credentials parameter to `read_gbq`, taking a google.cloud.bigquery.Client object.\r\n*   [x] Add optional credentials parameter to `to_gbq`, taking a google.cloud.bigquery.Client object.\r\n*   [x] Add pandas_gbq.get_user_credentials() helper for fetching user credentials with installed-app OAuth2 flow.\r\n*   [x] Add pandas_gbq.CredentialsCache and related subclasses for managing user credentials cache.\r\n*   [x] Add pandas_gbq.context global for caching a default Client in-memory. Add examples for manually setting pandas_gbq.context.client (so that default project and other values like location can be set).\r\n*   [x] Update minimum google-cloud-bigquery version to 0.32.0 so that the project ID in the client can be overridden when creating query & load jobs. (Done in https://github.com/pydata/pandas-gbq/pull/185)\r\n*   [x] Deprecate `private_key` argument. Show examples of how to do the same thing by passing  [Credentials](https://google-auth.readthedocs.io/en/latest/reference/google.auth.credentials.html#google.auth.credentials.Credentials)  to the Client constructor.\r\n*   [x] Deprecate PANDAS_GBQ_CREDENTIALS_FILE environment variable. Show example using `pandas_gbq.get_user_credentials` with `credentials_cache` argument.\r\n~*   [ ] Deprecate `reauth` argument. Show examples using `pandas_gbq.get_user_credentials` with `credentials_cache` argument and  WriteOnlyCredentialsCache or NoopCredentialsCache.~ **Edit**: No reason to deprecate reauth, since we don't need to complicate pandas-gbq's auth with pydata-google-auth's implementation details. \r\n~*   [ ] Deprecate `auth_local_webserver` argument. Show example using `pandas_gbq.get_user_credentials` with `auth_local_webserver` argument.~ **Edit**: No reason to deprecate auth_local_webserver, as that feature is still needed. We don't actually want to force people to use pydata-google-auth for the default credentials case.\r\n\r\n\r\n## Background\r\n\r\npandas-gbq has its own auth flows, which include but are distinct from \"application default credentials\".\r\n\r\nSee issue: https://github.com/pydata/pandas-gbq/issues/129\r\n\r\nCurrent (0.4.0) [state of pandas-gbq auth](https://github.com/pydata/pandas-gbq/blob/9ced97b19e24ff503330ed108547dd4bf9c422c9/pandas_gbq/gbq.py#L187-L195):\r\n\r\n\r\n\r\n1.  Use service account key file passed in as `private_key` parameter. Parameter can be either as JSON bytes or a file path.\r\n1.  Use [application default credentials](https://cloud.google.com/docs/authentication/production#providing_credentials_to_your_application).\r\n    1.  Use service account key at GOOGLE_APPLICATION_CREDENTIALS environment variable.\r\n    1.  Use service account associated with Compute Engine, Kubernetes Engine, App Engine, or Cloud Functions.\r\n1.  Use user authentication.\r\n    1.  Attempt to load user credentials from cache stored at `~/.config/pandas_gbq/bigquery_credentials.dat` or in path specified by `PANDAS_GBQ_CREDENTIALS_FILE` environment variable.\r\n    1.  Do 3-legged OAuth flow.\r\n    1.  Cache the user credentials to disk.\r\n\r\nWhy does pandas-gbq do user auth at all? Aren't application default credentials enough?\r\n\r\n\r\n\r\n*   It's difficult in some environments to set the right environment variables, so a way to explicitly provide credentials is desired.\r\n*   BigQuery does resource-based billing, so it is possible to use user-based authentication.\r\n    *   User-based authentication eliminates the unnecessary step of creating a service account.\r\n    *   A user with the BigQuery User IAM role wouldn't be allowed to create a service account.\r\n    *   Often datasets are shared with a specific user. Querying with user account credentials will allow them to access those shared datasets / tables.\r\n    *   User-based authentication is more intuitive in shared notebook environments like Colab, where the compute credentials might be associated with a service account in a shadow project or not available at all.\r\n\r\n\r\n### Problems with the current flow\r\n\r\n\r\n\r\n*   The credentials order [isn't always ideal](https://github.com/pydata/pandas-gbq/issues/129#issuecomment-368515825).\r\n*   It's not possible to specify user credentials in environments where application default credentials are available.\r\n*   If someone is familiar with the google-auth library, the current auth mechanisms do not allow passing in an arbitrary [Credentials](https://google-auth.readthedocs.io/en/latest/reference/google.auth.credentials.html#google.auth.credentials.Credentials) object.\r\n*   It is verbose and error-prone to pass in explicit service account credentials every time. See https://github.com/pydata/pandas-gbq/issues/103 for a feature request for more configurable defaults.\r\n    *   Error-prone? More than once have I and the other pandas-gbq contributors forgot to add a `private_key` argument to a call in a test, resulting in surprising failures in CI builds.\r\n*   It's not possible to override the scopes for the credentials. For example, it is useful to add Drive / Sheets scopes for querying external data sources.\r\n\r\n\r\n## Proposal\r\n\r\n\r\n### Document default auth behavior\r\n\r\nCurrent behavior (not changing, except for deprecations).\r\n\r\n\r\n\r\n1.  Use client if passed in.\r\n1.  Deprecated. Use private_key to create a Client if passed in. Use google-auth and credentials argument instead.\r\n1.  Attempt to create client using application default credentials. Intersphinx link to google.auth.default\r\n1.  Attempt to construct client using user credentials (project_id parameter must be passed in). Link to pandas_gbq.get_user_credentials().\r\n\r\nNew default auth behavior.\r\n\r\n\r\n\r\n*   1b. If client not passed in, attempt to use global client at pandas_gbq.context (similar to [google.cloud.bigquery.magics.context](https://github.com/GoogleCloudPlatform/google-cloud-python/blob/f3d9a90f476723864ad6dc18e5b3dcfc8c865345/bigquery/google/cloud/bigquery/magics.py#L188)). If there is no client in the global context: run steps 2-4 and set the client it creates to the global context.\r\n\r\n\r\n### Add `client` parameter to `read_gbq` and `to_gbq`\r\n\r\nThe new client parameter, if provided, would bypass all other credentials fetching mechanisms.\r\n\r\nWhy a Client and not an explicit [Credentials](https://google-auth.readthedocs.io/en/latest/reference/google.auth.credentials.html#google.auth.credentials.Credentials) object?\r\n\r\n\r\n\r\n*   A Client contains a default project (See feature request for default projects at https://github.com/pydata/pandas-gbq/issues/103) and will eventually handle other defaults, such as [location](https://github.com/GoogleCloudPlatform/google-cloud-python/issues/5148), encryption configuration, and maximum bytes billed.\r\n*   A Client object supports more BigQuery operations than will ever be exposed by pandas-gbq (creating datasets, modifying ACLs, other property updates). Passing this in as a parameter could hint to developers that they can use the Client directly for those things.\r\n*   It is more clear that BigQuery magic command is provided by google-cloud-bigquery not pandas-gbq.\r\n\r\n\r\n### Helpers for user-based authentication\r\n\r\nNo helpers are needed for default credentials or service account credentials because these can easily be constructed with the google-auth library. Link to samples for constructing these from the docs.\r\n\r\n\r\n#### pandas_gbq.get_user_credentials(scopes=None, credentials_cache=None, client_secrets=None, use_localhost_webserver=False):\r\n\r\nIf credentials_cache is None, construct a pandas_gbq.CredentialsCache with defaults for arguments.\r\n\r\nAttempt to load credentials from cache.\r\n\r\nIf credentials can't be loaded, start 3-legged oauth2 flow for installed applications. Use provided client secrets if given, otherwise use Pandas-GBQ client secrets. Use command-line flow by default. Use localhost webserver if set to True.\r\n\r\nNo credentials could be fetched? Raise an AccessDenied error. (Existing behavior of GbqConnector.get_user_account_credentials())\r\n\r\nSave credentials to cache.\r\n\r\nReturn credentials.\r\n\r\n\r\n#### pandas_gbq.CredentialsCache\r\n\r\nConstructor takes optional <span style=\"color:#000000;\">credentials_path.</span>\r\n\r\nIf credentials_path not provided, set self._credentials_path to\r\n\r\n\r\n\r\n*   `PANDAS_GBQ_CREDENTIALS_FILE - show deprecation warning that this environment variable will be ignored at a later date.`\r\n*   `Default user credentials path `at `~/.config/pandas_gbq/bigquery_credentials.dat`\r\n\r\nMethods\r\n\r\n\r\n\r\n*   load() - load credentials from self._credentials_path, refresh them, and return them. Otherwise, return None if credentials not found.\r\n*   save(credentials) - write credentials as JSON to self._credentials_path.\r\n\r\n\r\n##### pandas_gbq.WriteOnlyCredentialsCache\r\n\r\nSame as CredentialsCache, but load() is a no-op. Equivalent to \"force reauth\" in current versions.\r\n\r\n\r\n##### pandas_gbq.NoopCredentialsCache\r\n\r\nSatisfies the credentials cache interface, but does nothing. Useful for shared systems where you want credentials to stay in memory (e.g. Colab).\r\n\r\n\r\n## Deprecations\r\n\r\nSome time should be given (1-year deprecation?) for folks to migrate to the new `client` argument.  It might be used in scripts and older notebooks, and also is a parameter upstream in Pandas.\r\n\r\n\r\n### Deprecate the PANDAS_GBQ_CREDENTIALS_FILE environment variable\r\n\r\nLog a deprecation warning suggesting `pandas_gbq.get_user_credentials` with a `pandas_gbq.CredentialsCache` argument.\r\n\r\n\r\n### Deprecate `private_key` argument\r\n\r\nLog a deprecation warning suggesting [google.oauth2.service_account.Credentials.from_service_account_info](https://google-auth.readthedocs.io/en/latest/reference/google.oauth2.service_account.html#google.oauth2.service_account.Credentials.from_service_account_info) instead of passing in bytes and [google.oauth2.service_account.Credentials.from_service_account_file](https://google-auth.readthedocs.io/en/latest/reference/google.oauth2.service_account.html#google.oauth2.service_account.Credentials.from_service_account_file) instead of passing in a path.\r\n\r\nAdd / link to service account examples in the docs.\r\n\r\n\r\n### Deprecate `reauth` argument\r\n\r\nLog a deprecation warning suggesting creating a client using credentials from pandas_gbq.get_user_credentials and a pandas_gbq.WriteOnlyCredentialsCache\r\n\r\nAdd user authentication examples in the docs.\r\n\r\n\r\n### Deprecate `auth_local_webserver` argument\r\n\r\nLog a deprecation warning suggesting creating a client using credentials from pandas_gbq.get_user_credentials and set the auth_local_webserver argument there.\r\n\r\nAdd user authentication examples in the docs.\r\n\r\n\r\n/cc @craigcitro @maxim-lian ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/157", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/157/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/157/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/157/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/157", "id": 311776784, "node_id": "MDU6SXNzdWUzMTE3NzY3ODQ=", "number": 157, "title": "`verbosity` warning is overzealous", "user": {"login": "craigcitro", "id": 468559, "node_id": "MDQ6VXNlcjQ2ODU1OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/468559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/craigcitro", "html_url": "https://github.com/craigcitro", "followers_url": "https://api.github.com/users/craigcitro/followers", "following_url": "https://api.github.com/users/craigcitro/following{/other_user}", "gists_url": "https://api.github.com/users/craigcitro/gists{/gist_id}", "starred_url": "https://api.github.com/users/craigcitro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/craigcitro/subscriptions", "organizations_url": "https://api.github.com/users/craigcitro/orgs", "repos_url": "https://api.github.com/users/craigcitro/repos", "events_url": "https://api.github.com/users/craigcitro/events{/privacy}", "received_events_url": "https://api.github.com/users/craigcitro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-04-05T21:32:39Z", "updated_at": "2018-04-06T19:16:20Z", "closed_at": "2018-04-06T18:29:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "I just installed 0.4.0 (\ud83c\udf89), and a call to `read_gbq` with no `verbose` argument still complained at me.\r\n\r\nI realized the issue is because pandas [still provides a default](https://github.com/pandas-dev/pandas/blob/6d610a4d9393c0d0335267dc3252ccabb9e51e43/pandas/io/gbq.py#L25).\r\n\r\nWAI?\r\n\r\n(/cc @tswast)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/156", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/156/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/156/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/156/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/156", "id": 311735565, "node_id": "MDU6SXNzdWUzMTE3MzU1NjU=", "number": 156, "title": "Authenticate with credentials", "user": {"login": "rxuniverse", "id": 36429502, "node_id": "MDQ6VXNlcjM2NDI5NTAy", "avatar_url": "https://avatars3.githubusercontent.com/u/36429502?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rxuniverse", "html_url": "https://github.com/rxuniverse", "followers_url": "https://api.github.com/users/rxuniverse/followers", "following_url": "https://api.github.com/users/rxuniverse/following{/other_user}", "gists_url": "https://api.github.com/users/rxuniverse/gists{/gist_id}", "starred_url": "https://api.github.com/users/rxuniverse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rxuniverse/subscriptions", "organizations_url": "https://api.github.com/users/rxuniverse/orgs", "repos_url": "https://api.github.com/users/rxuniverse/repos", "events_url": "https://api.github.com/users/rxuniverse/events{/privacy}", "received_events_url": "https://api.github.com/users/rxuniverse/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-04-05T19:16:00Z", "updated_at": "2018-04-07T01:05:37Z", "closed_at": "2018-04-07T00:44:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Provide an option to authenticate with credentials instead of private keys.\r\n\r\nExample use case: On Google Cloud compute engine, I can [obtain credentials](https://cloud.google.com/docs/authentication/production#obtaining_credentials_on_compute_engine_kubernetes_engine_app_engine_flexible_environment_and_cloud_functions) in a compute engine instance based on the service account assigned to compute engine, but I can not directly get the private key. \r\n\r\nIf I pass credentials in the private key field, it fails as expected.\r\n`>>> from google.auth import compute_engine`\r\n`>>> credentials = compute_engine.Credentials()`\r\n`>>> import pandas`\r\n`>>> pandas.io.gbq.read_gbq(sql, project, private_key=credentials)`\r\n`/env/local/lib/python2.7/site-packages/pandas_gbq/gbq.py:798: FutureWarning: verbose is deprecated and will be removed in a future version. Set logging level in order to vary verbosity\r\n  \"verbosity\", FutureWarning, stacklevel=1)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/env/local/lib/python2.7/site-packages/pandas/io/gbq.py\", line 99, in read_gbq\r\n    **kwargs)\r\n  File \"/env/local/lib/python2.7/site-packages/pandas_gbq/gbq.py\", line 810, in read_gbq\r\n    dialect=dialect, auth_local_webserver=auth_local_webserver)\r\n  File \"/env/local/lib/python2.7/site-packages/pandas_gbq/gbq.py\", line 180, in __init__\r\n    self.credentials = self.get_credentials()\r\n  File \"/env/local/lib/python2.7/site-packages/pandas_gbq/gbq.py\", line 189, in get_credentials\r\n    return self.get_service_account_credentials()\r\n  File \"/env/local/lib/python2.7/site-packages/pandas_gbq/gbq.py\", line 409, in get_service_account_credentials\r\n    \"Private key is missing or invalid. It should be service \"\r\npandas_gbq.gbq.InvalidPrivateKeyFormat: Private key is missing or invalid. It should be service account private key JSON (file path or string contents) with at least two keys: 'client_email' and 'private_key'. Can be obtained from: https://console.developers.google.com/permissions/serviceaccounts`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/154", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/154/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/154/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/154/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/154", "id": 310982630, "node_id": "MDU6SXNzdWUzMTA5ODI2MzA=", "number": 154, "title": "CLN: No need to use private module names.", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-04-03T20:17:38Z", "updated_at": "2018-04-10T23:45:16Z", "closed_at": "2018-04-10T23:45:16Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Anything in `pandas_gbq.__init__` is considered public. Everything else should be considered private. No need to put underscore before the private module names.\r\n\r\nSee: https://github.com/pydata/pandas-gbq/pull/152#issuecomment-378379342\r\n\r\nWe could do a refactor PR to rename the existing modules and test modules.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/151", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/151/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/151/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/151/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/151", "id": 307605193, "node_id": "MDU6SXNzdWUzMDc2MDUxOTM=", "number": 151, "title": "Uploading DateTime field via to_gbq() leads to missing seconds/milliseconds data", "user": {"login": "ptrvtch", "id": 14279370, "node_id": "MDQ6VXNlcjE0Mjc5Mzcw", "avatar_url": "https://avatars3.githubusercontent.com/u/14279370?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ptrvtch", "html_url": "https://github.com/ptrvtch", "followers_url": "https://api.github.com/users/ptrvtch/followers", "following_url": "https://api.github.com/users/ptrvtch/following{/other_user}", "gists_url": "https://api.github.com/users/ptrvtch/gists{/gist_id}", "starred_url": "https://api.github.com/users/ptrvtch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ptrvtch/subscriptions", "organizations_url": "https://api.github.com/users/ptrvtch/orgs", "repos_url": "https://api.github.com/users/ptrvtch/repos", "events_url": "https://api.github.com/users/ptrvtch/events{/privacy}", "received_events_url": "https://api.github.com/users/ptrvtch/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-22T11:30:43Z", "updated_at": "2018-03-22T14:32:14Z", "closed_at": "2018-03-22T14:32:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I used the following code to reproduce the issue:\r\n```python\r\nimport pandas as pd, pandas_gbq\r\ndata = {\"date\": datetime.datetime.now()} # 2018-03-22 13:27:03.230384\r\ndf = pd.DataFrame(data, index=[0]\r\n\r\ndestination_table = 'test_tables.test_datetime'\r\nproject_id = 'my-project-11111'\r\nprivate_key = 'path-to-key.json'\r\npandas_gbq.to_gbq(\r\n  df,\r\n  destination_table,\r\n  project_id,\r\n  private_key=private_key\r\n)\r\n```\r\n\r\nWhen I check the values in the created table in Google BigQuery, the value doesn't keep seconds and milliseconds part of the DateTime:  `2018-03-22 13:27:00.000 `\r\n\r\nStandard bigquery library doesn't have this problem.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/144", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/144/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/144/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/144/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/144", "id": 302080646, "node_id": "MDU6SXNzdWUzMDIwODA2NDY=", "number": 144, "title": "Improve error message: `pandas requires google-cloud-python for Google BigQuery support`", "user": {"login": "parthea", "id": 5184014, "node_id": "MDQ6VXNlcjUxODQwMTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parthea", "html_url": "https://github.com/parthea", "followers_url": "https://api.github.com/users/parthea/followers", "following_url": "https://api.github.com/users/parthea/following{/other_user}", "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}", "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parthea/subscriptions", "organizations_url": "https://api.github.com/users/parthea/orgs", "repos_url": "https://api.github.com/users/parthea/repos", "events_url": "https://api.github.com/users/parthea/events{/privacy}", "received_events_url": "https://api.github.com/users/parthea/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-03-04T12:11:23Z", "updated_at": "2018-03-08T00:08:51Z", "closed_at": "2018-03-08T00:08:51Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "While testing locally, I received this message `'pandas requires google-cloud-python for Google BigQuery support`' (https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/gbq.py#L59)\r\n\r\nWe should change the message to `'pandas-gbq requires google-cloud-bigquery for Google BigQuery support'`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/142", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/142/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/142/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/142/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/142", "id": 302046584, "node_id": "MDU6SXNzdWUzMDIwNDY1ODQ=", "number": 142, "title": "Do we use merge-py.py?", "user": {"login": "max-sixty", "id": 5635139, "node_id": "MDQ6VXNlcjU2MzUxMzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/max-sixty", "html_url": "https://github.com/max-sixty", "followers_url": "https://api.github.com/users/max-sixty/followers", "following_url": "https://api.github.com/users/max-sixty/following{/other_user}", "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}", "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions", "organizations_url": "https://api.github.com/users/max-sixty/orgs", "repos_url": "https://api.github.com/users/max-sixty/repos", "events_url": "https://api.github.com/users/max-sixty/events{/privacy}", "received_events_url": "https://api.github.com/users/max-sixty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-03-04T00:58:33Z", "updated_at": "2018-03-21T22:34:36Z", "closed_at": "2018-03-21T22:34:36Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Let's remove if not \r\nhttps://github.com/pydata/pandas-gbq/blob/master/scripts/merge-py.py", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/136", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/136/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/136/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/136/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/136", "id": 301225911, "node_id": "MDU6SXNzdWUzMDEyMjU5MTE=", "number": 136, "title": "Hide google auth warning", "user": {"login": "melissachang", "id": 10929390, "node_id": "MDQ6VXNlcjEwOTI5Mzkw", "avatar_url": "https://avatars1.githubusercontent.com/u/10929390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/melissachang", "html_url": "https://github.com/melissachang", "followers_url": "https://api.github.com/users/melissachang/followers", "following_url": "https://api.github.com/users/melissachang/following{/other_user}", "gists_url": "https://api.github.com/users/melissachang/gists{/gist_id}", "starred_url": "https://api.github.com/users/melissachang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/melissachang/subscriptions", "organizations_url": "https://api.github.com/users/melissachang/orgs", "repos_url": "https://api.github.com/users/melissachang/repos", "events_url": "https://api.github.com/users/melissachang/events{/privacy}", "received_events_url": "https://api.github.com/users/melissachang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-28T23:38:20Z", "updated_at": "2018-03-31T19:32:07Z", "closed_at": "2018-03-31T19:32:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Every time I use pandas_gbq, a google auth warning is printed. The warning is harmless; pandas_gbq still works. But it would be nice if the warning wasn't printed. Perhaps pandas_gbq could set GOOGLE_CLOUD_PROJECT.\r\n\r\n```python\r\nimport logging\r\n\r\nimport pandas as pd\r\nimport pandas_gbq\r\n\r\n\r\n# Log to stderr.\r\nlogging.basicConfig(level=logging.WARNING,\r\n    format='%(asctime)s %(filename)10s:%(lineno)s %(levelname)s %(message)s',\r\n    datefmt='%Y%m%d%H:%M:%S')\r\nlogger = logging.getLogger('warning')\r\n\r\n\r\ndef main():\r\n  project_id = 'MY_PROJECT'\r\n  dataset_id = 'MY_DATASET'\r\n  table_name = 'MY_TABLE'\r\n  df = pd.read_gbq(\r\n      'SELECT * FROM `%s.%s.%s`' % (project_id, dataset_id, table_name),\r\n      project_id=project_id, dialect='standard')\r\n  print('%d rows read.' % len(df))\r\n  print('pandas version %s' % pandas_gbq.__version__)\r\n\r\nif __name__ == '__main__':\r\n  main()\r\n```\r\n\r\n```\r\n2018022815:32:50 _default.py:280 WARNING No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\r\nRequesting query... ok.\r\nJob ID: 82276626-c62f-4e58-ba0b-2adba047c7bd\r\nQuery running...\r\nQuery done.\r\nCache hit.\r\n\r\nRetrieving results...\r\nGot 901 rows.\r\n\r\nTotal time taken 0.91 s.\r\nFinished at 2018-02-28 15:32:52.\r\n901 rows read.\r\npandas version 0.3.1\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/135", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/135/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/135/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/135/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/135", "id": 299678287, "node_id": "MDU6SXNzdWUyOTk2NzgyODc=", "number": 135, "title": "TST: Unit tests in `test_gbq.py` aren't running", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-02-23T11:15:27Z", "updated_at": "2018-04-03T22:47:24Z", "closed_at": "2018-04-03T22:47:24Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "As pointed out in https://github.com/pydata/pandas-gbq/pull/125, `pytest` was skipping the unit tests in `test_gbq.py`. Many of the unit tests are now failing due to other changes. I've created a `unit-tests` branch to push fixes to the unit tests before we merge the class rename to `master`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/133", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/133/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/133/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/133/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/133", "id": 298720841, "node_id": "MDU6SXNzdWUyOTg3MjA4NDE=", "number": 133, "title": "Performance ", "user": {"login": "max-sixty", "id": 5635139, "node_id": "MDQ6VXNlcjU2MzUxMzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/max-sixty", "html_url": "https://github.com/max-sixty", "followers_url": "https://api.github.com/users/max-sixty/followers", "following_url": "https://api.github.com/users/max-sixty/following{/other_user}", "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}", "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions", "organizations_url": "https://api.github.com/users/max-sixty/orgs", "repos_url": "https://api.github.com/users/max-sixty/repos", "events_url": "https://api.github.com/users/max-sixty/events{/privacy}", "received_events_url": "https://api.github.com/users/max-sixty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 45, "created_at": "2018-02-20T19:35:25Z", "updated_at": "2019-04-25T17:26:42Z", "closed_at": "2019-04-25T16:16:04Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "We're starting to use BigQuery heavily but becoming increasingly 'bottlenecked' with the performance of moving moderate amounts of data from BigQuery to python.\r\n\r\nHere's a few stats:\r\n- **29.1s**: Pulling 500k rows with 3 columns of data (with cached data) using pandas-gbq \r\n- **36.5s**: Pulling the same query with `google-cloud-bigquery` - i.e. `client.query(query)..to_dataframe()` \r\n- **2.4s**: Pulling very similar data - same types, same size, from our existing MSSQL box hosted in AWS  (using `pd.read_sql`). That's on standard drivers, nothing like `turbodbc` involved\r\n\r\n...so using BigQuery with python is *at least an order of magnitude slower than traditional DBs*.\r\n\r\nWe've tried exporting tables to CSV on GCS and reading those in, which works fairly well for data processes, though not for exploration.\r\n\r\n A few questions - feel free to jump in with partial replies:\r\n- Are these results expected, or are we doing something very wrong? \r\n- My prior is that a lot of this slowdown is caused by pulling in HTTP pages, converting to python objects, and then writing those into arrays. Is this approach really scalable? Should `pandas-gbq` invest resources into getting a format that's query-able in exploratory workflows that can deal with more reasonable datasets? (or at least encourage Google to)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/132", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/132/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/132/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/132/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/132", "id": 298564475, "node_id": "MDU6SXNzdWUyOTg1NjQ0NzU=", "number": 132, "title": "User-provided schema is not used when loading data", "user": {"login": "mremes", "id": 24524415, "node_id": "MDQ6VXNlcjI0NTI0NDE1", "avatar_url": "https://avatars3.githubusercontent.com/u/24524415?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mremes", "html_url": "https://github.com/mremes", "followers_url": "https://api.github.com/users/mremes/followers", "following_url": "https://api.github.com/users/mremes/following{/other_user}", "gists_url": "https://api.github.com/users/mremes/gists{/gist_id}", "starred_url": "https://api.github.com/users/mremes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mremes/subscriptions", "organizations_url": "https://api.github.com/users/mremes/orgs", "repos_url": "https://api.github.com/users/mremes/repos", "events_url": "https://api.github.com/users/mremes/events{/privacy}", "received_events_url": "https://api.github.com/users/mremes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-02-20T11:45:51Z", "updated_at": "2018-03-27T14:11:14Z", "closed_at": "2018-03-27T14:11:14Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Schema is always inferred from the DataFrame object as `schema` is not provided to the `_load.load_chunks` call.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/129", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/129/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/129/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/129/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/129", "id": 298461175, "node_id": "MDU6SXNzdWUyOTg0NjExNzU=", "number": 129, "title": "ENH: Clear authentication defaults with more fine-grained control", "user": {"login": "max-sixty", "id": 5635139, "node_id": "MDQ6VXNlcjU2MzUxMzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/max-sixty", "html_url": "https://github.com/max-sixty", "followers_url": "https://api.github.com/users/max-sixty/followers", "following_url": "https://api.github.com/users/max-sixty/following{/other_user}", "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}", "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions", "organizations_url": "https://api.github.com/users/max-sixty/orgs", "repos_url": "https://api.github.com/users/max-sixty/repos", "events_url": "https://api.github.com/users/max-sixty/events{/privacy}", "received_events_url": "https://api.github.com/users/max-sixty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2018-02-20T03:25:33Z", "updated_at": "2018-04-07T00:45:07Z", "closed_at": "2018-04-07T00:45:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "We have about 220 lines of code which handles authentication - do we need that? Generally the answer to \"do we need something we do a lot of\" is 'Yes', but asking regardless\r\n\r\nMy prior is that  we could:\r\n1. Check if creds are passed by the user\r\n2. Otherwise pass nothing through to the Google libraries, and let them manage the defaults\r\n\r\n\r\nThat would reduced the code we needed to maintain and conform to standards - Google have very reasonable defaults, and we make it harder for those to flow through - e.g. `PANDAS_GBQ_CREDENTIALS_FILE` is non-standard, every other implementation uses `GOOGLE_APPLICATION_CREDENTIALS`, so users need to have an additional setting to use this library", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/123", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/123/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/123/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/123/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/123", "id": 298031450, "node_id": "MDU6SXNzdWUyOTgwMzE0NTA=", "number": 123, "title": "ValueError: setting an array element with a sequence.", "user": {"login": "MtDersvan", "id": 7069222, "node_id": "MDQ6VXNlcjcwNjkyMjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7069222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MtDersvan", "html_url": "https://github.com/MtDersvan", "followers_url": "https://api.github.com/users/MtDersvan/followers", "following_url": "https://api.github.com/users/MtDersvan/following{/other_user}", "gists_url": "https://api.github.com/users/MtDersvan/gists{/gist_id}", "starred_url": "https://api.github.com/users/MtDersvan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MtDersvan/subscriptions", "organizations_url": "https://api.github.com/users/MtDersvan/orgs", "repos_url": "https://api.github.com/users/MtDersvan/repos", "events_url": "https://api.github.com/users/MtDersvan/events{/privacy}", "received_events_url": "https://api.github.com/users/MtDersvan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-02-17T19:52:40Z", "updated_at": "2018-02-23T13:26:11Z", "closed_at": "2018-02-23T11:00:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "INFO:\r\n`pandas_gbq.__version__ : '0.3.0', '0.3.1'`\r\n`python`:  `3.6.2,  3.5.2`\r\n\r\nSNIPPET:\r\n~~~python\r\nfrom pandas.io import gbq\r\ndf  = gbq.read_gbq(\r\n    \"\"\"\r\n    #standardSQL\r\n    SELECT embedding_v1\r\n    FROM `{TABLE_ID}` LIMIT 10\r\n    \"\"\".format(TABLE_ID='patents-public-data.google_patents_research.publications'),\r\n    dialect='standard',\r\n    project_id='XXXXXXX',\r\n    configuration={'query': {'useQueryCache': True}}\r\n    )\r\n~~~\r\nERROR:\r\n~~~console\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 9, in <module>\r\n  File \"/Users/xxxxxx/tf/lib/python3.6/site-packages/pandas/io/gbq.py\", line 99, in read_gbq\r\n    **kwargs)\r\n  File \"/Users/xxxxxx/tf/lib/python3.6/site-packages/pandas_gbq/gbq.py\", line 828, in read_gbq\r\n    final_df = _parse_data(schema, rows)\r\n  File \"/Users/xxxxxx/tf/lib/python3.6/site-packages/pandas_gbq/gbq.py\", line 729, in _parse_data\r\n    page_array[row_num][col_num] = field_value\r\nValueError: setting an array element with a sequence.\r\n~~~\r\nISSUE:\r\n`'patents-public-data.google_patents_research.publications'` - a public dataset.\r\n`'embedding_v1'` - a repeated float field.\r\nGoogle BigQuery tools parses this query without a problem, but pandas-gbq outputs the upper-mentioned issue. \r\nMaybe related to https://github.com/pydata/pandas-gbq/pull/101", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/120", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/120/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/120/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/120/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/120", "id": 296901139, "node_id": "MDU6SXNzdWUyOTY5MDExMzk=", "number": 120, "title": "BUG: version of google-cloud-bigquery not recognized", "user": {"login": "IamGianluca", "id": 4025968, "node_id": "MDQ6VXNlcjQwMjU5Njg=", "avatar_url": "https://avatars0.githubusercontent.com/u/4025968?v=4", "gravatar_id": "", "url": "https://api.github.com/users/IamGianluca", "html_url": "https://github.com/IamGianluca", "followers_url": "https://api.github.com/users/IamGianluca/followers", "following_url": "https://api.github.com/users/IamGianluca/following{/other_user}", "gists_url": "https://api.github.com/users/IamGianluca/gists{/gist_id}", "starred_url": "https://api.github.com/users/IamGianluca/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/IamGianluca/subscriptions", "organizations_url": "https://api.github.com/users/IamGianluca/orgs", "repos_url": "https://api.github.com/users/IamGianluca/repos", "events_url": "https://api.github.com/users/IamGianluca/events{/privacy}", "received_events_url": "https://api.github.com/users/IamGianluca/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-02-13T22:01:04Z", "updated_at": "2018-02-14T17:45:18Z", "closed_at": "2018-02-14T17:45:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've create a virtual environment with the following dependencies:\r\n\r\n\r\n```\r\npip freeze                      \r\ncachetools==2.0.1\r\ncertifi==2018.1.18\r\nchardet==3.0.4\r\ndecorator==4.2.1\r\ngoogle-api-core==0.1.4\r\ngoogle-auth==1.4.1\r\ngoogle-auth-oauthlib==0.2.0\r\ngoogle-cloud-bigquery==0.30.0\r\ngoogle-cloud-core==0.28.0\r\ngoogle-resumable-media==0.3.1\r\ngoogleapis-common-protos==1.5.3\r\nidna==2.6\r\nipython==6.2.1\r\nipython-genutils==0.2.0\r\njedi==0.11.1\r\nnumpy==1.14.0\r\noauthlib==2.0.6\r\npandas==0.22.0\r\npandas-gbq==0.3.1\r\nparso==0.1.1\r\npexpect==4.4.0\r\npickleshare==0.7.4\r\nprompt-toolkit==1.0.15\r\nprotobuf==3.5.1\r\nptyprocess==0.5.2\r\npyasn1==0.4.2\r\npyasn1-modules==0.2.1\r\nPygments==2.2.0\r\npython-dateutil==2.6.1\r\npytz==2018.3\r\nrequests==2.18.4\r\nrequests-oauthlib==0.8.0\r\nrsa==3.4.2\r\nsimplegeneric==0.8.1\r\nsix==1.11.0\r\ntraitlets==4.3.2\r\nurllib3==1.22\r\nwcwidth==0.1.7\r\n```\r\n\r\nYou can recreate the same envinronment with the following commands:\r\n\r\n```\r\n$ pip install pandas-gbq -U\r\n$ pip install google-cloud-bigquery -U\r\n$ pip install ipython\r\n```\r\n\r\nIf I execute the following commands in an `ipython` console: \r\n\r\n```\r\nIn [1]: from pandas_gbq import read_gbq\r\n\r\nIn [2]: projectid = '<my_project_id>'\r\n\r\nIn [3]: read_gbq(query=\"\"\"<my_query>\"\"\", project_id=projectid, dialect='standard', verbose=True)\r\nERROR:root:An unexpected error occurred while tokenizing input\r\nThe following traceback may be corrupted or invalid\r\nThe error message is: ('EOF in multi-line string', (1, 0))\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-3-6abe92bd8bd2> in <module>()\r\n      9       adgroupid\r\n     10       , baseadgroupid\r\n---> 11 \"\"\", project_id=projectid, dialect='standard', verbose=True)\r\n\r\n~/.virtualenvs/bigquery/lib/python3.6/site-packages/pandas_gbq/gbq.py in read_gbq(query, project_id, index_col, col_order, reauth, verbose, private_key, auth_local_webserver, dialect, **kwargs)\r\n    814     \"\"\"\r\n    815 \r\n--> 816     _test_google_api_imports()\r\n    817 \r\n    818     if not project_id:\r\n\r\n~/.virtualenvs/bigquery/lib/python3.6/site-packages/pandas_gbq/gbq.py in _test_google_api_imports()\r\n     60             \"{0}\".format(ex))\r\n     61 \r\n---> 62     _check_google_client_version()\r\n     63 \r\n     64 \r\n\r\n~/.virtualenvs/bigquery/lib/python3.6/site-packages/pandas_gbq/gbq.py in _check_google_client_version()\r\n     34                           'current version {1}'\r\n     35                           .format(bigquery_client_minimum_version,\r\n---> 36                                   _BIGQUERY_CLIENT_VERSION))\r\n     37 \r\n     38 \r\n\r\nImportError: pandas requires google-cloud-bigquery >= 0.29.0 for Google BigQuery support, current version 0.28.0\r\n```\r\n\r\nHowever I do have a version of `google-cloud-bigquery` more recent than the minimum requirement.\r\n\r\n```\r\n$ pip freeze | grep 'google'\r\ngoogle-api-core==0.1.4\r\ngoogle-auth==1.4.1\r\ngoogle-auth-oauthlib==0.2.0\r\ngoogle-cloud-bigquery==0.30.0\r\ngoogle-cloud-core==0.28.0\r\ngoogle-resumable-media==0.3.1\r\ngoogleapis-common-protos==1.5.3\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/119", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/119/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/119/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/119/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/119", "id": 296681985, "node_id": "MDU6SXNzdWUyOTY2ODE5ODU=", "number": 119, "title": "fail to read INT64 values on Windows", "user": {"login": "blose", "id": 8558961, "node_id": "MDQ6VXNlcjg1NTg5NjE=", "avatar_url": "https://avatars2.githubusercontent.com/u/8558961?v=4", "gravatar_id": "", "url": "https://api.github.com/users/blose", "html_url": "https://github.com/blose", "followers_url": "https://api.github.com/users/blose/followers", "following_url": "https://api.github.com/users/blose/following{/other_user}", "gists_url": "https://api.github.com/users/blose/gists{/gist_id}", "starred_url": "https://api.github.com/users/blose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/blose/subscriptions", "organizations_url": "https://api.github.com/users/blose/orgs", "repos_url": "https://api.github.com/users/blose/repos", "events_url": "https://api.github.com/users/blose/events{/privacy}", "received_events_url": "https://api.github.com/users/blose/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2018-02-13T10:15:41Z", "updated_at": "2018-08-21T17:37:56Z", "closed_at": "2018-08-21T17:37:56Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "On pandas-gbq-0.3.0 it fails to get INT64 values:\r\n`\r\nnew_df = gbq.read_gbq(\r\n    \"SELECT  12345678901234567 as iii\",\r\n    project_id=project_id,\r\n    dialect=\"standard\"\r\n)\r\n`\r\n\r\nboth on standard and legacy dialects. Querying from the real database does the same.\r\n\r\n\r\n> Requesting query... ok.\r\n> Job ID: 82d0024d-3e31-4518-a6d5-755cf96f108c\r\n> Query running...\r\n> Query done.\r\n> Processed: 0.0 B Billed: 0.0 B\r\n> Standard price: $0.00 USD\r\n> \r\n> Retrieving results...\r\n> Got 1 rows.\r\n> \r\n> \r\n> ---------------------------------------------------------------------------\r\n> OverflowError                             Traceback (most recent call last)\r\n> <ipython-input-14-a22ed4823734> in <module>()\r\n>       7 top10_active_users_df = gbq.read_gbq(\r\n>       8     \"SELECT  12345678901234567 as iii\",\r\n> ----> 9     project_id=project_id\r\n>      10 )\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\gbq.py in read_gbq(query, project_id, index_col, col_order, reauth, verbose, private_key, dialect, **kwargs)\r\n>      98         private_key=private_key,\r\n>      99         dialect=dialect,\r\n> --> 100         **kwargs)\r\n>     101 \r\n>     102 \r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas_gbq\\gbq.py in read_gbq(query, project_id, index_col, col_order, reauth, verbose, private_key, auth_local_webserver, dialect, **kwargs)\r\n>     875                 field['mode'] != 'repeated':\r\n>     876             final_df[field['name']] = \\\r\n> --> 877                 final_df[field['name']].astype(type_map[field['type'].upper()])\r\n>     878 \r\n>     879     connector.print_elapsed_seconds(\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py in wrapper(*args, **kwargs)\r\n>      89                 else:\r\n>      90                     kwargs[new_arg_name] = new_arg_value\r\n> ---> 91             return func(*args, **kwargs)\r\n>      92         return wrapper\r\n>      93     return _deprecate_kwarg\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors, **kwargs)\r\n>    3408         # else, only a single dtype is given\r\n>    3409         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\r\n> -> 3410                                      **kwargs)\r\n>    3411         return self._constructor(new_data).__finalize__(self)\r\n>    3412 \r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in astype(self, dtype, **kwargs)\r\n>    3222 \r\n>    3223     def astype(self, dtype, **kwargs):\r\n> -> 3224         return self.apply('astype', dtype=dtype, **kwargs)\r\n>    3225 \r\n>    3226     def convert(self, **kwargs):\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\r\n>    3089 \r\n>    3090             kwargs['mgr'] = self\r\n> -> 3091             applied = getattr(b, f)(**kwargs)\r\n>    3092             result_blocks = _extend_blocks(applied, result_blocks)\r\n>    3093 \r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in astype(self, dtype, copy, errors, values, **kwargs)\r\n>     469     def astype(self, dtype, copy=False, errors='raise', values=None, **kwargs):\r\n>     470         return self._astype(dtype, copy=copy, errors=errors, values=values,\r\n> --> 471                             **kwargs)\r\n>     472 \r\n>     473     def _astype(self, dtype, copy=False, errors='raise', values=None,\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py in _astype(self, dtype, copy, errors, values, klass, mgr, raise_on_error, **kwargs)\r\n>     519 \r\n>     520                 # _astype_nansafe works fine with 1-d only\r\n> --> 521                 values = astype_nansafe(values.ravel(), dtype, copy=True)\r\n>     522                 values = values.reshape(self.shape)\r\n>     523 \r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy)\r\n>     623     elif arr.dtype == np.object_ and np.issubdtype(dtype.type, np.integer):\r\n>     624         # work around NumPy brokenness, #1987\r\n> --> 625         return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape)\r\n>     626 \r\n>     627     if dtype.name in (\"datetime64\", \"timedelta64\"):\r\n> \r\n> pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe()\r\n> \r\n> pandas/_libs/src\\util.pxd in util.set_value_at_unsafe()\r\n> \r\n> OverflowError: Python int too large to convert to C long\r\n> \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/116", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/116/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/116/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/116/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/116", "id": 295508424, "node_id": "MDU6SXNzdWUyOTU1MDg0MjQ=", "number": 116, "title": "BUG: Wrong JSON sent to BigQuery when both integer and float fields in schema", "user": {"login": "peshitz", "id": 3264902, "node_id": "MDQ6VXNlcjMyNjQ5MDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/3264902?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peshitz", "html_url": "https://github.com/peshitz", "followers_url": "https://api.github.com/users/peshitz/followers", "following_url": "https://api.github.com/users/peshitz/following{/other_user}", "gists_url": "https://api.github.com/users/peshitz/gists{/gist_id}", "starred_url": "https://api.github.com/users/peshitz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peshitz/subscriptions", "organizations_url": "https://api.github.com/users/peshitz/orgs", "repos_url": "https://api.github.com/users/peshitz/repos", "events_url": "https://api.github.com/users/peshitz/events{/privacy}", "received_events_url": "https://api.github.com/users/peshitz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-02-08T13:18:13Z", "updated_at": "2018-02-13T21:40:20Z", "closed_at": "2018-02-12T19:30:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "When both a float and integer field exist, integer fields (int64) are serialized as floats, resulting in an error from BigQuery (because in schema the field is defined as Integer).\r\n\r\n```\r\ndf = pd.DataFrame([[1,1.1],[2,2.2] ],\r\n                   index=['row 1', 'row 2'],\r\n                   columns=['intColumn','floatColumn'])\r\n \r\n# correct output\r\ndf.to_json()\r\n\r\n# incorrect output (method used by pandas-gbq)\r\nrow = df.iloc[0]\r\nrow.to_json()\r\n\r\n# correct output\r\ndf[['intColumn']].iloc[0].to_json()\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/115", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/115/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/115/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/115/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/115", "id": 294472843, "node_id": "MDU6SXNzdWUyOTQ0NzI4NDM=", "number": 115, "title": "JSON error python 3", "user": {"login": "caiolopes", "id": 4184169, "node_id": "MDQ6VXNlcjQxODQxNjk=", "avatar_url": "https://avatars1.githubusercontent.com/u/4184169?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caiolopes", "html_url": "https://github.com/caiolopes", "followers_url": "https://api.github.com/users/caiolopes/followers", "following_url": "https://api.github.com/users/caiolopes/following{/other_user}", "gists_url": "https://api.github.com/users/caiolopes/gists{/gist_id}", "starred_url": "https://api.github.com/users/caiolopes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caiolopes/subscriptions", "organizations_url": "https://api.github.com/users/caiolopes/orgs", "repos_url": "https://api.github.com/users/caiolopes/repos", "events_url": "https://api.github.com/users/caiolopes/events{/privacy}", "received_events_url": "https://api.github.com/users/caiolopes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-02-05T17:15:58Z", "updated_at": "2018-02-05T20:03:55Z", "closed_at": "2018-02-05T18:38:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I upgraded my script that uses pandas-gbq from python 2.7 to python 3.6 and it started to give me an error when trying to load the dataframe:\r\n\r\n```\r\nErrors:\r\n--\r\nfile-00000000: Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 329; errors: 1. (error code:\u00a0invalid)\r\nfile-00000000: Error while reading data, error message: JSON parsing error in row starting at position 30858: Parser terminated before end of string (error code:\u00a0invalid)\r\n```\r\n\r\nUsing the [python client for bigquery](https://github.com/GoogleCloudPlatform/google-cloud-python/tree/master/bigquery) directly I found out that the problem was related to `load_table_from_file` function.\r\n\r\nIt turns out that these lines (586, 587) in the gbq.py file was not right for the file_obj parameter, as stated at the API Reference here (https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/reference.html)\r\n\r\n- file_obj (file) \u2013 A file handle opened in binary mode for reading.\r\n\r\n```python\r\nbody = body.encode('utf-8')\r\nbody = BytesIO(body)\r\n\r\ntry:\r\n    self.client.load_table_from_file(\r\n        body,\r\n        destination_table,\r\n        job_config=job_config).result()\r\nexcept self.http_error as ex:\r\n    self.process_http_error(ex)\r\n```\r\n\r\nSo I changed it to look like this:\r\n\r\n```python\r\nfd = tempfile.NamedTemporaryFile(mode=\"w\", delete=False)\r\nfd.write('{}\\n'.format('\\n'.join(rows)))\r\nfd.close()\r\n\r\nwith open(fd.name, 'rb') as body:\r\n    try:\r\n        self.client.load_table_from_file(\r\n            body,\r\n            destination_table,\r\n            job_config=job_config).result()\r\n    except self.http_error as ex:\r\n        self.process_http_error(ex)\r\n\r\nos.remove(fd.name)\r\n```\r\n\r\nIn this way it works.\r\n\r\nI know it has something to do with special characters like \u00e7 and \u00e3\u00e9\u00f3, etc, but I don't know another way to solve this.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/114", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/114/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/114/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/114/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/114", "id": 292589543, "node_id": "MDU6SXNzdWUyOTI1ODk1NDM=", "number": 114, "title": "_parse_data fails when Rows object has only one column and one row", "user": {"login": "csmc88", "id": 7208365, "node_id": "MDQ6VXNlcjcyMDgzNjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/7208365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/csmc88", "html_url": "https://github.com/csmc88", "followers_url": "https://api.github.com/users/csmc88/followers", "following_url": "https://api.github.com/users/csmc88/following{/other_user}", "gists_url": "https://api.github.com/users/csmc88/gists{/gist_id}", "starred_url": "https://api.github.com/users/csmc88/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/csmc88/subscriptions", "organizations_url": "https://api.github.com/users/csmc88/orgs", "repos_url": "https://api.github.com/users/csmc88/repos", "events_url": "https://api.github.com/users/csmc88/events{/privacy}", "received_events_url": "https://api.github.com/users/csmc88/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-01-29T22:48:33Z", "updated_at": "2018-08-23T22:16:27Z", "closed_at": "2018-08-23T22:16:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "When making a call to `parse_data` in `pandas-gbq/gbq.py` I'm getting the following error.\r\n\r\n```\r\nTypeError: 'int' object has no attribute '__getitem__'\r\n```\r\n\r\nI'm attempting to recover results from a Google Big Query table. However, I'm expecting a single  numeric value in a 1x1 table. This can be reproduced manually with the following inputs to `_parse_data`. \r\n\r\n```\r\nschema = {'fields':[{'type': u'integer',\r\n                     'mode': u'nullable',\r\n                     'name': u'test_count'\r\n                    }\r\n                   ]\r\n         }\r\npages = [Row((36678925,), {u'test_count': 0})]\r\n```\r\n\r\nWhere `Row` is an object from module `google.cloud.bigquery.table`\r\n\r\nThis causes `_parse_data` to fail at line 751\r\n\r\n`field_value = entries[col_num]`\r\n\r\nSince the value in `entries` is not a dict but an integer with no `__getitem__`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/110", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/110/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/110/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/110/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/110", "id": 289322729, "node_id": "MDU6SXNzdWUyODkzMjI3Mjk=", "number": 110, "title": "JSON errors with valid JSON", "user": {"login": "harrypropellernet", "id": 35535197, "node_id": "MDQ6VXNlcjM1NTM1MTk3", "avatar_url": "https://avatars3.githubusercontent.com/u/35535197?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harrypropellernet", "html_url": "https://github.com/harrypropellernet", "followers_url": "https://api.github.com/users/harrypropellernet/followers", "following_url": "https://api.github.com/users/harrypropellernet/following{/other_user}", "gists_url": "https://api.github.com/users/harrypropellernet/gists{/gist_id}", "starred_url": "https://api.github.com/users/harrypropellernet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harrypropellernet/subscriptions", "organizations_url": "https://api.github.com/users/harrypropellernet/orgs", "repos_url": "https://api.github.com/users/harrypropellernet/repos", "events_url": "https://api.github.com/users/harrypropellernet/events{/privacy}", "received_events_url": "https://api.github.com/users/harrypropellernet/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-01-17T16:12:20Z", "updated_at": "2018-01-18T17:41:58Z", "closed_at": "2018-01-18T17:41:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there,\r\n\r\nTo preface this, the code works perfectly as expected on a windows machine, however when run on a linux machine I am encountering the following error.\r\n\r\nwhen attempting to upload a dataframe from pandas to GBQ I encounter:\r\n```\r\ngoogle.api_core.exceptions.BadRequest: 400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1.\r\n```\r\nI've searched through the code and extracted the json that it is sending to GBQ and the json is valid,\r\n\r\n```\r\n{\"Mobile\":\"100.00%\",\"Channelgrouping\":\"Organic Search\",\"Date\":\"2017-12-26\",\"Date4weeksago\":\"2017-11-28\",\"Devicecategory\":\"mobile\",\"Goal7completions\":180,\"Goal7completionsLastYear\":0,\"Goal7completionsLastYearMobileAdjustment\":0,\"Goal7completionsMobileAdjustment\":180,\"MobileAdjustment\":1.0,\"Month\":12,\"Newusers\":\"31,095\",\"NewusersLastYear\":0,\"NewusersLastYearMobileAdjustment\":0,\"NewusersMobileAdjustment\":\"31,095\",\"Period\":11,\"SEORevenueContribPast4Weeks\":\"0.00%\",\"SEORevenueContribThisWeek\":\"39.90%\",\"SEOSessionsContribPast4Weeks\":\"0.00%\",\"SEOSessionsContribPastWeek\":\"54.04%\",\"Sessions\":\"64,848\",\"SessionsLastYear\":0,\"SessionsLastYearMobileAdjustment\":0,\"SessionsMobileAdjustment\":\"64,848\",\"Transactionrevenue\":\"16,106\",\"TransactionrevenueLastYear\":0,\"TransactionrevenueLastYearMobileAdjustment\":0,\"TransactionrevenueMobileAdjustment\":\"16,106\",\"Transactions\":179,\"TransactionsLastYear\":0,\"TransactionsLastYearMobileAdjustment\":0,\"TransactionsMobileAdjustment\":179,\"WeekSunSat\":52,\"Year\":2017}\r\n```\r\n\r\nI've also tried all the to_json orient methods e.g. split index etc.\r\n\r\n\r\n\r\nIs this a known issue?\r\n\r\n\r\n\r\nfull traceback:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/pandas_gbq/gbq.py\", line 592, in load_data\r\n    job_config=job_config).result()\r\n  File \"/usr/local/lib/python3.6/site-packages/google/cloud/bigquery/job.py\", line 528, in result\r\n    return super(_AsyncJob, self).result(timeout=timeout)\r\n  File \"/usr/local/lib/python3.6/site-packages/google/api_core/future/polling.py\", line 111, in result\r\n    raise self._exception\r\ngoogle.api_core.exceptions.BadRequest: 400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"WaitroseMain.py\", line 133, in <module>\r\n    load = Waitrose.load(df)\r\n  File \"WaitroseMain.py\", line 114, in load\r\n    uploader.update(client, dataframes['gad'],'WaitroseAuto.gad')\r\n  File \"/home/harry/Automation/ReportingAutomation/DataStorage/BigQueryTools.py\", line 155, in update\r\n    pd.DataFrame.to_gbq(dataframe, destination_table=destination_table, project_id='joe-python-analytics', chunksize=5000, if_exists='append')\r\n  File \"/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\", line 1060, in to_gbq\r\n    if_exists=if_exists, private_key=private_key)\r\n  File \"/usr/local/lib/python3.6/site-packages/pandas/io/gbq.py\", line 108, in to_gbq\r\n    if_exists=if_exists, private_key=private_key)\r\n  File \"/usr/local/lib/python3.6/site-packages/pandas_gbq/gbq.py\", line 990, in to_gbq\r\n    connector.load_data(dataframe, dataset_id, table_id, chunksize)\r\n  File \"/usr/local/lib/python3.6/site-packages/pandas_gbq/gbq.py\", line 594, in load_data\r\n    self.process_http_error(ex)\r\n  File \"/usr/local/lib/python3.6/site-packages/pandas_gbq/gbq.py\", line 456, in process_http_error\r\n    raise GenericGBQException(\"Reason: {0}\".format(ex))\r\npandas_gbq.gbq.GenericGBQException: Reason: 400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1.\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/109", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/109/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/109/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/109/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/109", "id": 288245981, "node_id": "MDU6SXNzdWUyODgyNDU5ODE=", "number": 109, "title": "Tests flexible to auth method", "user": {"login": "max-sixty", "id": 5635139, "node_id": "MDQ6VXNlcjU2MzUxMzk=", "avatar_url": "https://avatars0.githubusercontent.com/u/5635139?v=4", "gravatar_id": "", "url": "https://api.github.com/users/max-sixty", "html_url": "https://github.com/max-sixty", "followers_url": "https://api.github.com/users/max-sixty/followers", "following_url": "https://api.github.com/users/max-sixty/following{/other_user}", "gists_url": "https://api.github.com/users/max-sixty/gists{/gist_id}", "starred_url": "https://api.github.com/users/max-sixty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/max-sixty/subscriptions", "organizations_url": "https://api.github.com/users/max-sixty/orgs", "repos_url": "https://api.github.com/users/max-sixty/repos", "events_url": "https://api.github.com/users/max-sixty/events{/privacy}", "received_events_url": "https://api.github.com/users/max-sixty/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-01-12T21:04:55Z", "updated_at": "2018-08-21T17:33:04Z", "closed_at": "2018-08-21T17:33:04Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "At the moment, each auth method (Service key path / service key contents / user) has a separate class with tested functions\r\n\r\nI think we could make this much simpler and more flexible - have a pytest fixture that generates a GBQConnector, and use that in each function. Then we can test on whatever auth method is available (and set a minimum if preferred: https://github.com/pydata/pandas-gbq/issues/72)\r\n\r\nSeparately, there is a lot of setup & teardown code that could be simplified through fixtures. And some manual `test_id`s that could be automated through pytest", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/106", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/106/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/106/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/106/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/106", "id": 287284864, "node_id": "MDU6SXNzdWUyODcyODQ4NjQ=", "number": 106, "title": "to_gbq result in UnicodeEncodeError", "user": {"login": "2legit", "id": 9961676, "node_id": "MDQ6VXNlcjk5NjE2NzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/9961676?v=4", "gravatar_id": "", "url": "https://api.github.com/users/2legit", "html_url": "https://github.com/2legit", "followers_url": "https://api.github.com/users/2legit/followers", "following_url": "https://api.github.com/users/2legit/following{/other_user}", "gists_url": "https://api.github.com/users/2legit/gists{/gist_id}", "starred_url": "https://api.github.com/users/2legit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/2legit/subscriptions", "organizations_url": "https://api.github.com/users/2legit/orgs", "repos_url": "https://api.github.com/users/2legit/repos", "events_url": "https://api.github.com/users/2legit/events{/privacy}", "received_events_url": "https://api.github.com/users/2legit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 24, "created_at": "2018-01-10T01:18:31Z", "updated_at": "2018-02-10T01:00:19Z", "closed_at": "2018-02-10T00:59:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I'm using Heroku to run a python based ETL process where I'm pushing the contents of a Pandas dataframe into Google BQ using to_gbq. However, it's generating a UnicodeEncodeError with the following stack trace, due to some non-latin characters. \r\n\r\nStrangely this works fine on my Mac but when I try to run it on Heroku, it's failing. It seems that for some reason, http.client.py is getting an un-encoded string rather than bytes and therefore, it's trying to encode with latin-1, which is the default but obviously would choke on anything non-latin, like Chinese chars.\r\n\r\n2018-01-08T04:54:17.307496+00:00 app[run.2251]:\r\nLoad is 100.0% Complete044+00:00 app[run.2251]:\r\n2018-01-08T04:54:20.443238+00:00 app[run.2251]: Traceback (most recent call last):\r\n2018-01-08T04:54:20.443267+00:00 app[run.2251]:   File \"AllCostAndRev.py\", line 534, in <module>\r\n2018-01-08T04:54:20.443708+00:00 app[run.2251]:     main(yaml.dump(data=ads_dict))\r\n2018-01-08T04:54:20.443710+00:00 app[run.2251]:   File \"AllCostAndRev.py\", line 475, in main\r\n2018-01-08T04:54:20.443915+00:00 app[run.2251]:     private_key=environ['skynet_bq_pk']\r\n2018-01-08T04:54:20.443917+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/pandas_gbq/gbq.py\", line 989, in to_gbq\r\n2018-01-08T04:54:20.444390+00:00 app[run.2251]:     connector.load_data(dataframe, dataset_id, table_id, chunksize)\r\n2018-01-08T04:54:20.444391+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/pandas_gbq/gbq.py\", line 590, in load_data\r\n2018-01-08T04:54:20.444653+00:00 app[run.2251]:     job_config=job_config).result()\r\n2018-01-08T04:54:20.444656+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/google/cloud/bigquery/client.py\", line 748, in load_table_from_file\r\n2018-01-08T04:54:20.445248+00:00 app[run.2251]:     response = upload.transmit_next_chunk(transport)\r\n2018-01-08T04:54:20.445250+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/google/resumable_media/requests/upload.py\", line 395, in transmit_next_chunk\r\n2018-01-08T04:54:20.444942+00:00 app[run.2251]:     file_obj, job_resource, num_retries)\r\n2018-01-08T04:54:20.445457+00:00 app[run.2251]:     retry_strategy=self._retry_strategy)\r\n2018-01-08T04:54:20.444943+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/google/cloud/bigquery/client.py\", line 777, in _do_resumable_upload\r\n2018-01-08T04:54:20.445458+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/google/resumable_media/requests/_helpers.py\", line 101, in http_request\r\n2018-01-08T04:54:20.445592+00:00 app[run.2251]:     func, RequestsMixin._get_status_code, retry_strategy)\r\n2018-01-08T04:54:20.445594+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/google/resumable_media/_helpers.py\", line 146, in wait_and_retry\r\n2018-01-08T04:54:20.445725+00:00 app[run.2251]:     response = func()\r\n2018-01-08T04:54:20.445726+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/google/auth/transport/requests.py\", line 186, in request\r\n2018-01-08T04:54:20.445866+00:00 app[run.2251]:     method, url, data=data, headers=request_headers, **kwargs)\r\n2018-01-08T04:54:20.445867+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/requests/sessions.py\", line 508, in request\r\n2018-01-08T04:54:20.446099+00:00 app[run.2251]:     resp = self.send(prep, **send_kwargs)\r\n2018-01-08T04:54:20.446101+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/requests/sessions.py\", line 618, in send\r\n2018-01-08T04:54:20.446456+00:00 app[run.2251]:     r = adapter.send(request, **kwargs)\r\n2018-01-08T04:54:20.446457+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/requests/adapters.py\", line 440, in send\r\n2018-01-08T04:54:20.446728+00:00 app[run.2251]:     timeout=timeout\r\n2018-01-08T04:54:20.446730+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 601, in urlopen\r\n2018-01-08T04:54:20.446969+00:00 app[run.2251]:     chunked=chunked)\r\n2018-01-08T04:54:20.446970+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 357, in _make_request\r\n2018-01-08T04:54:20.447229+00:00 app[run.2251]:     conn.request(method, url, **httplib_request_kw)\r\n2018-01-08T04:54:20.447231+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/http/client.py\", line 1239, in request\r\n2018-01-08T04:54:20.447690+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/http/client.py\", line 1284, in _send_request\r\n2018-01-08T04:54:20.448232+00:00 app[run.2251]:     body = _encode(body, 'body')\r\n2018-01-08T04:54:20.448234+00:00 app[run.2251]:   File \"/app/.heroku/python/lib/python3.6/http/client.py\", line 161, in _encode\r\n2018-01-08T04:54:20.448405+00:00 app[run.2251]: UnicodeEncodeError: 'latin-1' codec can't encode characters in position 553626-553628: Body ('\u4fe1\u7528\u5361') is not valid Latin-1. Use body.encode('utf-8') if you want to send it encoded in UTF-8.\r\n2018-01-08T04:54:20.447689+00:00 app[run.2251]:     self._send_request(method, url, body, headers, encode_chunked)\r\n2018-01-08T04:54:20.448396+00:00 app[run.2251]:     (name.title(), data[err.start:err.end], name)) from None\r\n2018-01-08T04:54:20.621819+00:00 heroku[run.2251]: State changed from up to complete\r\n2018-01-08T04:54:20.609814+00:00 heroku[run.2251]: Process exited with status 1", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/103", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/103/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/103/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/103/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/103", "id": 285511957, "node_id": "MDU6SXNzdWUyODU1MTE5NTc=", "number": 103, "title": "Set project_id (and other settings) once for all subsequent queries so you don't have to pass every time", "user": {"login": "jasonqng", "id": 3181961, "node_id": "MDQ6VXNlcjMxODE5NjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/3181961?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasonqng", "html_url": "https://github.com/jasonqng", "followers_url": "https://api.github.com/users/jasonqng/followers", "following_url": "https://api.github.com/users/jasonqng/following{/other_user}", "gists_url": "https://api.github.com/users/jasonqng/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasonqng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasonqng/subscriptions", "organizations_url": "https://api.github.com/users/jasonqng/orgs", "repos_url": "https://api.github.com/users/jasonqng/repos", "events_url": "https://api.github.com/users/jasonqng/events{/privacy}", "received_events_url": "https://api.github.com/users/jasonqng/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2018-01-02T19:10:41Z", "updated_at": "2018-09-05T16:54:29Z", "closed_at": "2018-09-05T16:54:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "One frustrating thing is having to pass the `project_id` (among other parameters) every time you write a query. For example, personally, I usually use the same project_id, almost always query with standard sql, and usually turn off verbose. I have to pass those three with every `read_gbq`, typing which adds up.\r\n\r\nPotential options include setting an environment variable and reading from these default settings, but sometimes it can be different each time and fiddling with environment variables feels unfriendly. My suggestion would perhaps be to add a class that can wrap `read_gbq()` and `to_gbq()` in a client object. You could set the project_id attribute and dialect and whatever else in the client object, then re-use the object every time you want a query with those settings.\r\n\r\nA very naive implementation here in this branch:\r\nhttps://github.com/pydata/pandas-gbq/compare/master...jasonqng:client-object-class?expand=1\r\n\r\nUsage would be like:\r\n\r\n```\r\n>>> import gbq\r\n>>> client = gbq.Client(project_id='project-name',dialect='standard',verbose=False)\r\n>>> client.read(\"select 1\")\r\n   f0_\r\n0    1\r\n>>> client.read(\"select 2\")\r\n   f0_\r\n0    2\r\n>>> client.verbose=True\r\n>>> client.read(\"select 3\")\r\nRequesting query... ok.\r\nJob ID: c7d7e4c0-883a-4e14-b35f-61c9fae0c08b\r\nQuery running...\r\nQuery done.\r\nProcessed: 0.0 B Billed: 0.0 B\r\nStandard price: $0.00 USD\r\n\r\nRetrieving results...\r\nGot 1 rows.\r\n\r\nTotal time taken 1.66 s.\r\nFinished at 2018-01-02 14:06:01.\r\n   f0_\r\n0    3\r\n```\r\n\r\nDoes that seem like a reasonable solution to all this extra typing or is there another preferred way? If so, I can open up a PR with the above branch.\r\n\r\nThanks, my tired fingers thank you all!\r\n\r\n@tswast @jreback @parthea @maxim-lian", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/102", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/102/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/102/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/102/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/102", "id": 285229993, "node_id": "MDU6SXNzdWUyODUyMjk5OTM=", "number": 102, "title": "Add option for limiting rows of retrieved of results", "user": {"login": "bburky", "id": 140526, "node_id": "MDQ6VXNlcjE0MDUyNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/140526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bburky", "html_url": "https://github.com/bburky", "followers_url": "https://api.github.com/users/bburky/followers", "following_url": "https://api.github.com/users/bburky/following{/other_user}", "gists_url": "https://api.github.com/users/bburky/gists{/gist_id}", "starred_url": "https://api.github.com/users/bburky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bburky/subscriptions", "organizations_url": "https://api.github.com/users/bburky/orgs", "repos_url": "https://api.github.com/users/bburky/repos", "events_url": "https://api.github.com/users/bburky/events{/privacy}", "received_events_url": "https://api.github.com/users/bburky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-12-30T23:27:46Z", "updated_at": "2019-08-09T22:30:29Z", "closed_at": "2019-08-09T22:30:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "I found the pandas-gbq interface easy to use and wanted to also use it for creating tables in BigQuery, not just downloading all the results at once. The existing capabilities of read_gbq() is actually already sufficient to do this, because you can just set `query.destinationTable` in the job configuration. However, I would like to limit the number of retrieved rows to a small sample of the whole table that was created instead of downloading the many thousands of rows that were created.\r\n\r\nI've already played with making the changes myself in a project I'm working on:\r\n\r\nhttp://nbviewer.jupyter.org/github/bburky/subredditgenderratios/blob/master/Subreddit%20Gender%20Ratios.ipynb\r\n\r\nIn the [current code](https://github.com/pydata/pandas-gbq/blob/4cab83cefb7df190bf3e5b43168c2cb53f596c31/pandas_gbq/gbq.py#L547) for run_query(), you read all rows from the table by converting the iterator into a list. Instead, you could pass the iterator to `itertools.islice()` first to limit it to a configurable limit. You can look at my code to see how it could be done.\r\n\r\nAlso, if you're interested I could contribute the IPython `%%bigquery` cell magic I am using in that project. It should be a very simple wrapper around `read_gbq()`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/98", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/98/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/98/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/98/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/98", "id": 283716806, "node_id": "MDU6SXNzdWUyODM3MTY4MDY=", "number": 98, "title": "Travis builds fail with CondaError: BlockingIOError(11, 'write could not complete without blocking', 0)", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535065536, "node_id": "MDU6TGFiZWw1MzUwNjU1MzY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20process", "name": "type: process", "color": "c5def5", "default": false, "description": "A process-releated concern. May include testing, release, or the like."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2017-12-20T22:36:55Z", "updated_at": "2017-12-21T01:07:26Z", "closed_at": "2017-12-21T01:07:26Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Builds are failing with\r\n\r\n```\r\nCondaError: BlockingIOError(11, 'write could not complete without blocking', 0)\r\n```\r\n\r\nSee: https://travis-ci.org/pydata/pandas-gbq/jobs/319413385\r\n\r\nBased on https://github.com/conda/conda/issues/6468 it is because Conda is a bit too verbose for Travis. Suggested fix is to use ` --quiet` parameter for `conda` commands.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/97", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/97/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/97/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/97/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/97", "id": 280572917, "node_id": "MDU6SXNzdWUyODA1NzI5MTc=", "number": 97, "title": "Do not manually loop over all rows when reading a dataframe", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-12-08T18:10:44Z", "updated_at": "2018-02-12T04:24:58Z", "closed_at": "2018-02-12T04:24:58Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "See: https://github.com/pydata/pandas-gbq/pull/25#discussion_r155356025\r\n\r\nPerhaps there is a faster way to construct a dataframe from the results returned by the client library than looping over rows individually?\r\n\r\nNote: the client library ends up effectively looping over all rows as well by returning an [iterator](https://github.com/GoogleCloudPlatform/google-cloud-python/blob/061011d0213f82ca5ccaa9dec0a12713faaa2899/bigquery/google/cloud/bigquery/table.py#L1057) that does the type conversions / parsing over the actual API results. I imagine some profiling might reveal places where the performance there can also be improved.\r\n\r\nP.S. version 0.29.0 of the BigQuery client library (not yet released, as of 2017-12-08) will expose a `to_dataframe()` method. The actual implementation of this issue may be to just use that method here.\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-python/blob/061011d0213f82ca5ccaa9dec0a12713faaa2899/bigquery/google/cloud/bigquery/table.py#L1103-L1123\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/96", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/96/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/96/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/96/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/96", "id": 280567529, "node_id": "MDU6SXNzdWUyODA1Njc1Mjk=", "number": 96, "title": "Do not manually loop over all rows when encoding a dataframe as JSON", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980918, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20feature%20request", "name": "type: feature request", "color": "c5def5", "default": false, "description": "'Nice-to-have' improvement, new feature or different behavior or design."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2017-12-08T17:49:14Z", "updated_at": "2018-02-12T19:30:44Z", "closed_at": "2018-02-12T19:30:44Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "See: https://github.com/pydata/pandas-gbq/pull/25#discussion_r155355165\r\n\r\nCurrently the code loops over each row to encode it as JSON. This could be sped up by calling `to_json()` on the whole dataframe instead.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/95", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/95/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/95/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/95/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/95", "id": 280102889, "node_id": "MDU6SXNzdWUyODAxMDI4ODk=", "number": 95, "title": "Keeps asking for authentication when running as a cron job on EC2 instance", "user": {"login": "Sarickshah", "id": 28224649, "node_id": "MDQ6VXNlcjI4MjI0NjQ5", "avatar_url": "https://avatars2.githubusercontent.com/u/28224649?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sarickshah", "html_url": "https://github.com/Sarickshah", "followers_url": "https://api.github.com/users/Sarickshah/followers", "following_url": "https://api.github.com/users/Sarickshah/following{/other_user}", "gists_url": "https://api.github.com/users/Sarickshah/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sarickshah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sarickshah/subscriptions", "organizations_url": "https://api.github.com/users/Sarickshah/orgs", "repos_url": "https://api.github.com/users/Sarickshah/repos", "events_url": "https://api.github.com/users/Sarickshah/events{/privacy}", "received_events_url": "https://api.github.com/users/Sarickshah/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980921, "node_id": "MDU6TGFiZWw1MzQ5ODA5MjE=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20question", "name": "type: question", "color": "c5def5", "default": false, "description": "Request for information or clarification. Not an issue."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-12-07T11:55:14Z", "updated_at": "2018-02-12T04:16:22Z", "closed_at": "2018-02-12T04:16:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there any way to streaming insert from ec2? When I run as a cron job the streaming insert doesn't work but if I manually run it myself it does.... anyone have insight as to if this is impossible or can guide in any way? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/93", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/93/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/93/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/93/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/93", "id": 277124656, "node_id": "MDU6SXNzdWUyNzcxMjQ2NTY=", "number": 93, "title": "Use google-cloud-bigquery instead of google-api-client", "user": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-27T18:41:59Z", "updated_at": "2018-01-04T20:21:51Z", "closed_at": "2018-01-04T20:21:51Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Follow-up to https://github.com/pydata/pandas-gbq/issues/26, since `google-cloud-bigquery` is a more complete replacement for `google-api-client`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/92", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/92/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/92/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/92/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/92", "id": 276320631, "node_id": "MDU6SXNzdWUyNzYzMjA2MzE=", "number": 92, "title": "read_gbq uses excessive amounts of memory", "user": {"login": "Stigjb", "id": 418181, "node_id": "MDQ6VXNlcjQxODE4MQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/418181?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Stigjb", "html_url": "https://github.com/Stigjb", "followers_url": "https://api.github.com/users/Stigjb/followers", "following_url": "https://api.github.com/users/Stigjb/following{/other_user}", "gists_url": "https://api.github.com/users/Stigjb/gists{/gist_id}", "starred_url": "https://api.github.com/users/Stigjb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Stigjb/subscriptions", "organizations_url": "https://api.github.com/users/Stigjb/orgs", "repos_url": "https://api.github.com/users/Stigjb/repos", "events_url": "https://api.github.com/users/Stigjb/events{/privacy}", "received_events_url": "https://api.github.com/users/Stigjb/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980921, "node_id": "MDU6TGFiZWw1MzQ5ODA5MjE=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20question", "name": "type: question", "color": "c5def5", "default": false, "description": "Request for information or clarification. Not an issue."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-11-23T10:11:07Z", "updated_at": "2017-11-25T15:10:22Z", "closed_at": "2017-11-23T15:26:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have noticed that reading large tables uses far more RAM than I think it should. For example, the following snippet that queries a public table uses around 4 GiB of memory while loading the pages (34 in total), as I watch the process in the system monitor. The final Dataframe, however, only uses 88.5+ MB, as told by `df.info()`.\r\n```python\r\nimport pandas\r\nquery = ('SELECT * FROM `bigquery-public-data.noaa_gsod.gsod2016` WHERE mo = \"01\"')\r\ndf = pandas.read_gbq(query, project_id=<ID>, dialect='standard')\r\ndf.info()\r\n```\r\nI know that `read_gbq` keeps the partial pages in a list before concatenating them all into a result DataFrame, but it seems to me that this should not require 50 times the memory, but rather an order of magnitude less.\r\n\r\nHere is the actual output from `df.info()`:\r\n```\r\n<class 'pandas.core.frame.DataFrame'>\r\nRangeIndex: 362568 entries, 0 to 362567\r\nData columns (total 32 columns):\r\nstn                     362568 non-null object\r\nwban                    362568 non-null object\r\nyear                    362568 non-null object\r\nmo                      362568 non-null object\r\nda                      362568 non-null object\r\ntemp                    362568 non-null float64\r\ncount_temp              362568 non-null int64\r\ndewp                    362568 non-null float64\r\ncount_dewp              362568 non-null int64\r\nslp                     362568 non-null float64\r\ncount_slp               362568 non-null int64\r\nstp                     362568 non-null float64\r\ncount_stp               362568 non-null int64\r\nvisib                   362568 non-null float64\r\ncount_visib             362568 non-null int64\r\nwdsp                    362568 non-null object\r\ncount_wdsp              362568 non-null object\r\nmxpsd                   362568 non-null object\r\ngust                    362568 non-null float64\r\nmax                     362568 non-null float64\r\nflag_max                362568 non-null object\r\nmin                     362568 non-null float64\r\nflag_min                362568 non-null object\r\nprcp                    362568 non-null float64\r\nflag_prcp               362568 non-null object\r\nsndp                    362568 non-null float64\r\nfog                     362568 non-null object\r\nrain_drizzle            362568 non-null object\r\nsnow_ice_pellets        362568 non-null object\r\nhail                    362568 non-null object\r\nthunder                 362568 non-null object\r\ntornado_funnel_cloud    362568 non-null object\r\ndtypes: float64(10), int64(5), object(17)\r\nmemory usage: 88.5+ MB\r\n```\r\n\r\nPandas version: 0.20.3\r\nPython version: 3.5.2", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/91", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/91/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/91/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/91/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/91", "id": 266495882, "node_id": "MDU6SXNzdWUyNjY0OTU4ODI=", "number": 91, "title": "Bug in if_exists='replace'", "user": {"login": "jstypka", "id": 4479536, "node_id": "MDQ6VXNlcjQ0Nzk1MzY=", "avatar_url": "https://avatars0.githubusercontent.com/u/4479536?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jstypka", "html_url": "https://github.com/jstypka", "followers_url": "https://api.github.com/users/jstypka/followers", "following_url": "https://api.github.com/users/jstypka/following{/other_user}", "gists_url": "https://api.github.com/users/jstypka/gists{/gist_id}", "starred_url": "https://api.github.com/users/jstypka/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jstypka/subscriptions", "organizations_url": "https://api.github.com/users/jstypka/orgs", "repos_url": "https://api.github.com/users/jstypka/repos", "events_url": "https://api.github.com/users/jstypka/events{/privacy}", "received_events_url": "https://api.github.com/users/jstypka/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-10-18T13:36:58Z", "updated_at": "2018-02-12T04:26:16Z", "closed_at": "2018-02-12T04:26:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey, we're running into trouble with overwriting tables. When we want to overwrite an existing table, the table is recreated (you can see by the modification date), but nothing is inserted and it's left empty.\r\n\r\nHere's the code to reproduce it:\r\n```python\r\n> df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\r\n> df.to_gbq('tmp.table', 'my-project', if_exists='replace') # table doesn't exist yet\r\nStreaming Insert is 100% Complete\r\n # The table was successfully created and there is data in the streaming buffer\r\n> df.to_gbq('tmp.table', 'my-project', if_exists='replace')\r\nStreaming Insert is 100% Complete\r\n# Table was recreated but it's now empty\r\n```\r\n\r\nThe streaming is successful both times.\r\nThe tables have the same schema and no error about schema is displayed.\r\nAfter the first write, the table seems empty but there's data in the streaming buffer that you can query. After the second write, it's completely empty.\r\n\r\n**pandas-gbq version:** 0.2.0\r\n**Pandas version:** 0.20.3\r\n**OS:** macOS High Sierra\r\n**Python:** 2.7.10\r\n\r\nLet me know if I can provide more info!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/89", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/89/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/89/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/89/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/89", "id": 260275996, "node_id": "MDU6SXNzdWUyNjAyNzU5OTY=", "number": 89, "title": "Question: Is it possible to use pandas_gbq behind a proxy?", "user": {"login": "andrelu", "id": 1228471, "node_id": "MDQ6VXNlcjEyMjg0NzE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1228471?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrelu", "html_url": "https://github.com/andrelu", "followers_url": "https://api.github.com/users/andrelu/followers", "following_url": "https://api.github.com/users/andrelu/following{/other_user}", "gists_url": "https://api.github.com/users/andrelu/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrelu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrelu/subscriptions", "organizations_url": "https://api.github.com/users/andrelu/orgs", "repos_url": "https://api.github.com/users/andrelu/repos", "events_url": "https://api.github.com/users/andrelu/events{/privacy}", "received_events_url": "https://api.github.com/users/andrelu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-09-25T13:26:19Z", "updated_at": "2018-05-11T23:23:20Z", "closed_at": "2018-05-11T23:23:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello everyone, i have an situation where we here have a data science environment and we use this library, but connecting to BQ is being a problem because the environment is behind a corporate proxy. I tried setting environment variables **http_proxy** and **https_proxy** but without success. Is there an easy way to do this? Or am i missing something? \r\n\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/86", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/86/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/86/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/86/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/86", "id": 257128218, "node_id": "MDU6SXNzdWUyNTcxMjgyMTg=", "number": 86, "title": "Define path of bigquery_credentials.dat by environment var", "user": {"login": "jonathansp", "id": 457972, "node_id": "MDQ6VXNlcjQ1Nzk3Mg==", "avatar_url": "https://avatars0.githubusercontent.com/u/457972?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonathansp", "html_url": "https://github.com/jonathansp", "followers_url": "https://api.github.com/users/jonathansp/followers", "following_url": "https://api.github.com/users/jonathansp/following{/other_user}", "gists_url": "https://api.github.com/users/jonathansp/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonathansp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonathansp/subscriptions", "organizations_url": "https://api.github.com/users/jonathansp/orgs", "repos_url": "https://api.github.com/users/jonathansp/repos", "events_url": "https://api.github.com/users/jonathansp/events{/privacy}", "received_events_url": "https://api.github.com/users/jonathansp/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-09-12T17:48:31Z", "updated_at": "2017-09-19T11:43:43Z", "closed_at": "2017-09-19T11:43:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "In a shared environment, the use of [hard-coded bigquery_credentials.dat](https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/gbq.py#L282) file name could be a problem. We should be able to define this path by using an environment variable, for instance, `PANDAS_GBQ_CREDENTIALS_FILE`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/84", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/84/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/84/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/84/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/84", "id": 252715076, "node_id": "MDU6SXNzdWUyNTI3MTUwNzY=", "number": 84, "title": "Scope should be configurable", "user": {"login": "cneerdaels", "id": 15041962, "node_id": "MDQ6VXNlcjE1MDQxOTYy", "avatar_url": "https://avatars1.githubusercontent.com/u/15041962?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cneerdaels", "html_url": "https://github.com/cneerdaels", "followers_url": "https://api.github.com/users/cneerdaels/followers", "following_url": "https://api.github.com/users/cneerdaels/following{/other_user}", "gists_url": "https://api.github.com/users/cneerdaels/gists{/gist_id}", "starred_url": "https://api.github.com/users/cneerdaels/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cneerdaels/subscriptions", "organizations_url": "https://api.github.com/users/cneerdaels/orgs", "repos_url": "https://api.github.com/users/cneerdaels/repos", "events_url": "https://api.github.com/users/cneerdaels/events{/privacy}", "received_events_url": "https://api.github.com/users/cneerdaels/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-08-24T20:02:43Z", "updated_at": "2017-09-11T20:26:19Z", "closed_at": "2017-09-11T20:26:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've been joining a table in BQ, to a federated one (looks like a BQ table, but its actually a Google Sheet). It throws the error: \u201cEncountered an error while globbing file pattern\u201d \r\n\r\nI've found I needed to change:\r\nscope = 'https://www.googleapis.com/auth/bigquery'     <in class GbqConnector>\r\n  to:\r\nscope = ['https://www.googleapis.com/auth/bigquery', 'https://www.googleapis.com/auth/drive']\r\n\r\nthough I suppose with other federated sources, the scope may need to be configurable.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/82", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/82/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/82/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/82/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/82", "id": 249423555, "node_id": "MDU6SXNzdWUyNDk0MjM1NTU=", "number": 82, "title": "Request payload size exceeds the limit: 10485760 bytes.", "user": {"login": "pkallos", "id": 382249, "node_id": "MDQ6VXNlcjM4MjI0OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/382249?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pkallos", "html_url": "https://github.com/pkallos", "followers_url": "https://api.github.com/users/pkallos/followers", "following_url": "https://api.github.com/users/pkallos/following{/other_user}", "gists_url": "https://api.github.com/users/pkallos/gists{/gist_id}", "starred_url": "https://api.github.com/users/pkallos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pkallos/subscriptions", "organizations_url": "https://api.github.com/users/pkallos/orgs", "repos_url": "https://api.github.com/users/pkallos/repos", "events_url": "https://api.github.com/users/pkallos/events{/privacy}", "received_events_url": "https://api.github.com/users/pkallos/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-08-10T17:41:01Z", "updated_at": "2018-02-12T04:28:46Z", "closed_at": "2018-02-12T04:28:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am writing a dataframe to pandas and have received this error:\r\n\r\n`pandas_gbq.gbq.GenericGBQException: Reason: badRequest, Message: Request payload size exceeds the limit: 10485760 bytes`\r\n\r\nStrangely I see the message that streaming insert was 100% complete:\r\n```\r\nStreaming Insert is 100% Complete\r\n\r\nTraceback (most recent call last):\r\n  File \"...lib/python2.7/site-packages/pandas/core/frame.py\", line 957, in to_gbq\r\n    if_exists=if_exists, private_key=private_key)\r\n  File \"...lib/python2.7/site-packages/pandas/io/gbq.py\", line 109, in to_gbq\r\n    if_exists=if_exists, private_key=private_key)\r\n  File \"...lib/python2.7/site-packages/pandas_gbq/gbq.py\", line 1056, in to_gbq\r\n    connector.load_data(dataframe, dataset_id, table_id, chunksize)\r\n  File \"...lib/python2.7/site-packages/pandas_gbq/gbq.py\", line 643, in load_data\r\n    self.process_http_error(ex)\r\n  File \"...lib/python2.7/site-packages/pandas_gbq/gbq.py\", line 454, in process_http_error\r\n    \"Reason: {0}, Message: {1}\".format(reason, message))\r\npandas_gbq.gbq.GenericGBQException: Reason: badRequest, Message: Request payload size exceeds the limit: 10485760 bytes.\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/81", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/81/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/81/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/81/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/81", "id": 248045893, "node_id": "MDU6SXNzdWUyNDgwNDU4OTM=", "number": 81, "title": "GenericGBQException may be raised when listing dataset", "user": {"login": "parthea", "id": 5184014, "node_id": "MDQ6VXNlcjUxODQwMTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parthea", "html_url": "https://github.com/parthea", "followers_url": "https://api.github.com/users/parthea/followers", "following_url": "https://api.github.com/users/parthea/following{/other_user}", "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}", "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parthea/subscriptions", "organizations_url": "https://api.github.com/users/parthea/orgs", "repos_url": "https://api.github.com/users/parthea/repos", "events_url": "https://api.github.com/users/parthea/events{/privacy}", "received_events_url": "https://api.github.com/users/parthea/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 535065536, "node_id": "MDU6TGFiZWw1MzUwNjU1MzY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20process", "name": "type: process", "color": "c5def5", "default": false, "description": "A process-releated concern. May include testing, release, or the like."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-04T15:51:01Z", "updated_at": "2020-04-21T11:26:57Z", "closed_at": "2020-04-21T11:26:56Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "I saw the following error today in a Travis-CI build log when listing tables under a dataset: `'GenericGBQException: Reason: notFound, Message: Not found: Token pandas_gbq_xxx'`\r\n\r\n@tswast also experienced this in https://github.com/pydata/pandas-gbq/pull/39#issuecomment-302790335\r\n\r\nSince the failure is intermittent we may be able to handle the 404 error from BQ in the first attempt and re-attempt the request to list tables under a dataset. I think we should raise GenericGBQException after a second attempt though and monitor for unit test failures.\r\n\r\n```\r\n==================================== ERRORS ====================================\r\n ERROR at teardown of TestToGBQIntegrationWithServiceAccountKeyPath.test_dataset_exists \r\n\r\nself = <pandas_gbq.gbq._Dataset object at 0x7f358b3736d8>\r\n\r\n    def datasets(self):\r\n        \"\"\" Return a list of datasets in Google BigQuery\r\n    \r\n            Parameters\r\n            ----------\r\n            None\r\n    \r\n            Returns\r\n            -------\r\n            list\r\n                List of datasets under the specific project\r\n            \"\"\"\r\n    \r\n        dataset_list = []\r\n        next_page_token = None\r\n        first_query = True\r\n    \r\n        while first_query or next_page_token:\r\n            first_query = False\r\n    \r\n            try:\r\n                list_dataset_response = self.service.datasets().list(\r\n                    projectId=self.project_id,\r\n>                   pageToken=next_page_token).execute()\r\n\r\npandas_gbq/gbq.py:1247: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nargs = (<googleapiclient.http.HttpRequest object at 0x7f358b352588>,)\r\nkwargs = {}\r\n\r\n    @functools.wraps(wrapped)\r\n    def positional_wrapper(*args, **kwargs):\r\n        if len(args) > max_positional_args:\r\n            plural_s = ''\r\n            if max_positional_args != 1:\r\n                plural_s = 's'\r\n            message = ('{function}() takes at most {args_max} positional '\r\n                       'argument{plural} ({args_given} given)'.format(\r\n                           function=wrapped.__name__,\r\n                           args_max=max_positional_args,\r\n                           args_given=len(args),\r\n                           plural=plural_s))\r\n            if positional_parameters_enforcement == POSITIONAL_EXCEPTION:\r\n                raise TypeError(message)\r\n            elif positional_parameters_enforcement == POSITIONAL_WARNING:\r\n                logger.warning(message)\r\n>       return wrapped(*args, **kwargs)\r\n\r\n../../../miniconda/envs/test-environment/lib/python3.6/site-packages/oauth2client/_helpers.py:133: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <googleapiclient.http.HttpRequest object at 0x7f358b352588>\r\nhttp = <google_auth_httplib2.AuthorizedHttp object at 0x7f358b378128>\r\nnum_retries = 0\r\n\r\n    @util.positional(1)\r\n    def execute(self, http=None, num_retries=0):\r\n      \"\"\"Execute the request.\r\n    \r\n        Args:\r\n          http: httplib2.Http, an http object to be used in place of the\r\n                one the HttpRequest request object was constructed with.\r\n          num_retries: Integer, number of times to retry with randomized\r\n                exponential backoff. If all retries fail, the raised HttpError\r\n                represents the last request. If zero (default), we attempt the\r\n                request only once.\r\n    \r\n        Returns:\r\n          A deserialized object model of the response body as determined\r\n          by the postproc.\r\n    \r\n        Raises:\r\n          googleapiclient.errors.HttpError if the response was not a 2xx.\r\n          httplib2.HttpLib2Error if a transport error has occured.\r\n        \"\"\"\r\n      if http is None:\r\n        http = self.http\r\n    \r\n      if self.resumable:\r\n        body = None\r\n        while body is None:\r\n          _, body = self.next_chunk(http=http, num_retries=num_retries)\r\n        return body\r\n    \r\n      # Non-resumable case.\r\n    \r\n      if 'content-length' not in self.headers:\r\n        self.headers['content-length'] = str(self.body_size)\r\n      # If the request URI is too long then turn it into a POST request.\r\n      if len(self.uri) > MAX_URI_LENGTH and self.method == 'GET':\r\n        self.method = 'POST'\r\n        self.headers['x-http-method-override'] = 'GET'\r\n        self.headers['content-type'] = 'application/x-www-form-urlencoded'\r\n        parsed = urlparse(self.uri)\r\n        self.uri = urlunparse(\r\n            (parsed.scheme, parsed.netloc, parsed.path, parsed.params, None,\r\n             None)\r\n            )\r\n        self.body = parsed.query\r\n        self.headers['content-length'] = str(len(self.body))\r\n    \r\n      # Handle retries for server-side errors.\r\n      resp, content = _retry_request(\r\n            http, num_retries, 'request', self._sleep, self._rand, str(self.uri),\r\n            method=str(self.method), body=self.body, headers=self.headers)\r\n    \r\n      for callback in self.response_callbacks:\r\n        callback(resp)\r\n      if resp.status >= 300:\r\n>       raise HttpError(resp, content, uri=self.uri)\r\nE       googleapiclient.errors.HttpError: <HttpError 404 when requesting https://www.googleapis.com/bigquery/v2/projects/[secure]/datasets?pageToken=pandas_gbq_923881&alt=json returned \"Not found: Token pandas_gbq_923881\">\r\n\r\n../../../miniconda/envs/test-environment/lib/python3.6/site-packages/googleapiclient/http.py:840: HttpError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nself = <pandas_gbq.tests.test_gbq.TestToGBQIntegrationWithServiceAccountKeyPath object at 0x7f358b4293c8>\r\nmethod = <bound method TestToGBQIntegrationWithServiceAccountKeyPath.test_dataset_exists of <pandas_gbq.tests.test_gbq.TestToGBQIntegrationWithServiceAccountKeyPath object at 0x7f358b4293c8>>\r\n\r\n    def teardown_method(self, method):\r\n        # - PER-TEST FIXTURES -\r\n        # put here any instructions you want to be run *AFTER* *EVERY* test is\r\n        # executed.\r\n>       clean_gbq_environment(self.dataset_prefix, _get_private_key_path())\r\n\r\npandas_gbq/tests/test_gbq.py:949: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\npandas_gbq/tests/test_gbq.py:116: in clean_gbq_environment\r\n    all_datasets = dataset.datasets()\r\npandas_gbq/gbq.py:1263: in datasets\r\n    self.process_http_error(ex)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nex = <HttpError 404 when requesting https://www.googleapis.com/bigquery/v2/projects/[secure]/datasets?pageToken=pandas_gbq_923881&alt=json returned \"Not found: Token pandas_gbq_923881\">\r\n\r\n    @staticmethod\r\n    def process_http_error(ex):\r\n        # See `BigQuery Troubleshooting Errors\r\n        # <https://cloud.google.com/bigquery/troubleshooting-errors>`__\r\n    \r\n        status = json.loads(bytes_to_str(ex.content))['error']\r\n        errors = status.get('errors', None)\r\n    \r\n        if errors:\r\n            for error in errors:\r\n                reason = error['reason']\r\n                message = error['message']\r\n    \r\n                raise GenericGBQException(\r\n>                   \"Reason: {0}, Message: {1}\".format(reason, message))\r\nE               pandas_gbq.gbq.GenericGBQException: Reason: notFound, Message: Not found: Token pandas_gbq_923881\r\n\r\npandas_gbq/gbq.py:450: GenericGBQException\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/78", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/78/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/78/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/78/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/78", "id": 247747079, "node_id": "MDU6SXNzdWUyNDc3NDcwNzk=", "number": 78, "title": "Google auth error - invalid_grant: Token has been expired or revoked", "user": {"login": "parthea", "id": 5184014, "node_id": "MDQ6VXNlcjUxODQwMTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parthea", "html_url": "https://github.com/parthea", "followers_url": "https://api.github.com/users/parthea/followers", "following_url": "https://api.github.com/users/parthea/following{/other_user}", "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}", "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parthea/subscriptions", "organizations_url": "https://api.github.com/users/parthea/orgs", "repos_url": "https://api.github.com/users/parthea/repos", "events_url": "https://api.github.com/users/parthea/events{/privacy}", "received_events_url": "https://api.github.com/users/parthea/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 606481943, "node_id": "MDU6TGFiZWw2MDY0ODE5NDM=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/accepting%20pull%20requests", "name": "accepting pull requests", "color": "0e8a16", "default": false, "description": null}, {"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": {"login": "parthea", "id": 5184014, "node_id": "MDQ6VXNlcjUxODQwMTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parthea", "html_url": "https://github.com/parthea", "followers_url": "https://api.github.com/users/parthea/followers", "following_url": "https://api.github.com/users/parthea/following{/other_user}", "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}", "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parthea/subscriptions", "organizations_url": "https://api.github.com/users/parthea/orgs", "repos_url": "https://api.github.com/users/parthea/repos", "events_url": "https://api.github.com/users/parthea/events{/privacy}", "received_events_url": "https://api.github.com/users/parthea/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "parthea", "id": 5184014, "node_id": "MDQ6VXNlcjUxODQwMTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parthea", "html_url": "https://github.com/parthea", "followers_url": "https://api.github.com/users/parthea/followers", "following_url": "https://api.github.com/users/parthea/following{/other_user}", "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}", "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parthea/subscriptions", "organizations_url": "https://api.github.com/users/parthea/orgs", "repos_url": "https://api.github.com/users/parthea/repos", "events_url": "https://api.github.com/users/parthea/events{/privacy}", "received_events_url": "https://api.github.com/users/parthea/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-08-03T15:32:20Z", "updated_at": "2018-08-21T17:55:07Z", "closed_at": "2018-08-21T17:55:07Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "From #76 , unit test `TestGBQConnectorIntegrationWithLocalUserAccountAuth.test_get_user_account_credentials_bad_file_returns_credentials` was failing for @hagino3000 with `invalid_grant: Token has been expired or revoked`. I believe I've seen this error also. I'll try to reproduce this.\r\n\r\n```\r\n========================================================================== FAILURES ===========================================================================\r\n_____________________ TestGBQConnectorIntegrationWithLocalUserAccountAuth.test_get_user_account_credentials_bad_file_returns_credentials ______________________\r\n\r\nself = <pandas_gbq.tests.test_gbq.TestGBQConnectorIntegrationWithLocalUserAccountAuth object at 0x11327ba90>\r\n\r\n    def test_get_user_account_credentials_bad_file_returns_credentials(self):\r\n        import mock\r\n        from google.auth.credentials import Credentials\r\n>       with mock.patch('__main__.open', side_effect=IOError()):\r\n\r\npandas_gbq/tests/test_gbq.py:231:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n../../env/lib/python3.6/site-packages/mock.py:1268: in __enter__\r\n    original, local = self.get_original()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = <mock._patch object at 0x112f1c978>\r\n\r\n    def get_original(self):\r\n        target = self.getter()\r\n        name = self.attribute\r\n\r\n        original = DEFAULT\r\n        local = False\r\n\r\n        try:\r\n            original = target.__dict__[name]\r\n        except (AttributeError, KeyError):\r\n            original = getattr(target, name, DEFAULT)\r\n        else:\r\n            local = True\r\n\r\n        if not self.create and original is DEFAULT:\r\n            raise AttributeError(\r\n>               \"%s does not have the attribute %r\" % (target, name)\r\n            )\r\nE           AttributeError: <module '__main__' from '/Users/t-nishibayashi/dev/workspace/BigQuery-Python-dev/env/bin/pytest'> does not have the attribute 'open\r\n'\r\n\r\n../../env/lib/python3.6/site-packages/mock.py:1242: AttributeError\r\n__________________________ TestGBQConnectorIntegrationWithLocalUserAccountAuth.test_get_user_account_credentials_returns_credentials __________________________\r\n\r\nself = <pandas_gbq.tests.test_gbq.TestGBQConnectorIntegrationWithLocalUserAccountAuth object at 0x11301d940>\r\n\r\n    def test_get_user_account_credentials_returns_credentials(self):\r\n        from google.auth.credentials import Credentials\r\n>       credentials = self.sut.get_user_account_credentials()\r\n\r\npandas_gbq/tests/test_gbq.py:237:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\npandas_gbq/gbq.py:340: in get_user_account_credentials\r\n    credentials = self.load_user_account_credentials()\r\npandas_gbq/gbq.py:298: in load_user_account_credentials\r\n    credentials.refresh(request)\r\n../../env/lib/python3.6/site-packages/google/oauth2/credentials.py:126: in refresh\r\n    self._client_secret))\r\n../../env/lib/python3.6/site-packages/google/oauth2/_client.py:189: in refresh_grant\r\n    response_data = _token_endpoint_request(request, token_uri, body)\r\n../../env/lib/python3.6/site-packages/google/oauth2/_client.py:109: in _token_endpoint_request\r\n    _handle_error_response(response_body)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nresponse_body = '{\\n  \"error\" : \"invalid_grant\",\\n  \"error_description\" : \"Token has been expired or revoked.\"\\n}'\r\n\r\n    def _handle_error_response(response_body):\r\n        \"\"\"\"Translates an error response into an exception.\r\n\r\n        Args:\r\n            response_body (str): The decoded response data.\r\n\r\n        Raises:\r\n            google.auth.exceptions.RefreshError\r\n        \"\"\"\r\n        try:\r\n            error_data = json.loads(response_body)\r\n            error_details = '{}: {}'.format(\r\n                error_data['error'],\r\n                error_data.get('error_description'))\r\n        # If no details could be extracted, use the response data.\r\n        except (KeyError, ValueError):\r\n            error_details = response_body\r\n\r\n        raise exceptions.RefreshError(\r\n>           error_details, response_body)\r\nE       google.auth.exceptions.RefreshError: ('invalid_grant: Token has been expired or revoked.', '{\\n  \"error\" : \"invalid_grant\",\\n  \"error_description\" : \"T\r\noken has been expired or revoked.\"\\n}')\r\n\r\n../../env/lib/python3.6/site-packages/google/oauth2/_client.py:59: RefreshError\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/75", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/75/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/75/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/75/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/75", "id": 244966454, "node_id": "MDU6SXNzdWUyNDQ5NjY0NTQ=", "number": 75, "title": "StreamingInsertError occurs when uploading to a table with a new schema", "user": {"login": "parthea", "id": 5184014, "node_id": "MDQ6VXNlcjUxODQwMTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parthea", "html_url": "https://github.com/parthea", "followers_url": "https://api.github.com/users/parthea/followers", "following_url": "https://api.github.com/users/parthea/following{/other_user}", "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}", "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parthea/subscriptions", "organizations_url": "https://api.github.com/users/parthea/orgs", "repos_url": "https://api.github.com/users/parthea/repos", "events_url": "https://api.github.com/users/parthea/events{/privacy}", "received_events_url": "https://api.github.com/users/parthea/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}], "state": "closed", "locked": false, "assignee": {"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tswast", "id": 247555, "node_id": "MDQ6VXNlcjI0NzU1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/247555?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tswast", "html_url": "https://github.com/tswast", "followers_url": "https://api.github.com/users/tswast/followers", "following_url": "https://api.github.com/users/tswast/following{/other_user}", "gists_url": "https://api.github.com/users/tswast/gists{/gist_id}", "starred_url": "https://api.github.com/users/tswast/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tswast/subscriptions", "organizations_url": "https://api.github.com/users/tswast/orgs", "repos_url": "https://api.github.com/users/tswast/repos", "events_url": "https://api.github.com/users/tswast/events{/privacy}", "received_events_url": "https://api.github.com/users/tswast/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-07-24T03:58:47Z", "updated_at": "2018-02-12T04:23:25Z", "closed_at": "2018-02-12T04:23:25Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "As mentioned in #74, around July 11th `pandas-gbq` [builds started failing](https://travis-ci.org/pydata/pandas-gbq/builds) this test: `test_gbq.py::TestToGBQIntegrationWithServiceAccountKeyPath::test_upload_data_if_table_exists_replace`.\r\n\r\nI reviewed the test failure and my initial thought is that there was change made in the BigQuery backend recently that triggered this.  The issue is related to deleting and recreating a table with a different schema. Currently we [force a delay of 2 minutes](https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/gbq.py#L762) when a table with a modified schema is recreated. This delay is suggested in [this StackOverflow post](https://stackoverflow.com/questions/25279116/cannot-insert-new-value-to-bigquery-table-after-updating-with-new-column-using-s) and [this entry in the BigQuery issue tracker](https://issuetracker.google.com/issues/35905247) . Based on my limited testing, it seems that in addition to waiting 2 minutes, you also need to upload the data twice in order to see the data in BigQuery. During the first upload `StreamingInsertError` is raised. The second upload is successful. \r\n\r\nYou can easily confirm this when running the test locally. The test failure no longer appears when I change \r\n```\r\n        connector.load_data(dataframe, dataset_id, table_id, chunksize)\r\n``` \r\nat\r\nhttps://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/gbq.py#L1056\r\nto\r\n```\r\n    try:\r\n        connector.load_data(dataframe, dataset_id, table_id, chunksize)\r\n    except:\r\n        connector.load_data(dataframe, dataset_id, table_id, chunksize)\r\n```\r\n\r\nBased on this behaviour, I believe that now you need to upload data twice after changing the schema. It seems like this issue could be a regression on the BigQuery side (since re-uploading data wasn't required before). \r\n\r\nI was also able to create this issue with the `google-cloud-bigquery` package with the following code:\r\n```\r\nfrom google.cloud import bigquery\r\nfrom google.cloud.bigquery import SchemaField\r\nimport time\r\n\r\nclient = bigquery.Client(project=<your_project_id>)\r\n\r\ndataset = client.dataset('test_dataset')\r\nif not dataset.exists():\r\n    dataset.create()\r\n\r\nSCHEMA = [\r\n    SchemaField('full_name', 'STRING', mode='required'),\r\n    SchemaField('age', 'INTEGER', mode='required'),\r\n]\r\n\r\ntable = dataset.table('test_table', SCHEMA)\r\n\r\nif table.exists:\r\n    try:\r\n        table.delete()\r\n    except:\r\n        pass\r\n    \r\ntable.create()\r\nROWS_TO_INSERT = [\r\n    (u'Phred Phlyntstone', 32),\r\n    (u'Wylma Phlyntstone', 29),\r\n]\r\ntable.insert_data(ROWS_TO_INSERT)\r\n\r\n# Now change the schema\r\nSCHEMA = [\r\n    SchemaField('name', 'STRING', mode='required'),\r\n    SchemaField('age', 'STRING', mode='required'),\r\n]\r\ntable = dataset.table('test_table', SCHEMA)\r\n\r\n# Delete the table, wait 2 minutes and re-create the table\r\ntable.delete()\r\ntime.sleep(120)\r\ntable.create()\r\n\r\nROWS_TO_INSERT = [\r\n    (u'Phred Phlyntstone', '32'),\r\n    (u'Wylma Phlyntstone', '29'),\r\n]\r\nfor _ in range(5):\r\n    insert_errors = table.insert_data(ROWS_TO_INSERT)\r\n    if len(insert_errors):\r\n        print(insert_errors)\r\n        print('Retrying')\r\n    else:\r\n        break\r\n```\r\n\r\nThe output was :\r\n```\r\n>>[{'index': 0, 'errors': [{u'debugInfo': u'generic::not_found: no such field.', u'reason': u'invalid', u'message': u'no such field.', u'location': u'name'}]}, {'index': 1, 'errors': [{u'debugInfo': u'generic::not_found: no such field.', u'reason': u'invalid', u'message': u'no such field.', u'location': u'name'}]}]\r\n>>Retrying\r\n```\r\n but prior to July 11th (or so) the retry wasn't required.\r\n\r\nOne thing that `google-cloud-bigquery` does is return streaming insert errors rather than raising  `StreamingInsertError` like we do in `pandas-gbq`. See https://github.com/GoogleCloudPlatform/google-cloud-python/blob/master/bigquery/google/cloud/bigquery/table.py#L826 .\r\n\r\nWe could follow a similar behaviour and add a return in `to_gbq` which contains the streaming insert errors rather than raising `StreamingInsertError`. We can leave it up to the user to check for streaming insert errors and retry if needed https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/gbq.py#L1056\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/74", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/74/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/74/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/74/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/74", "id": 244867413, "node_id": "MDU6SXNzdWUyNDQ4Njc0MTM=", "number": 74, "title": "RLS: 0.2.0", "user": {"login": "jreback", "id": 953992, "node_id": "MDQ6VXNlcjk1Mzk5Mg==", "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jreback", "html_url": "https://github.com/jreback", "followers_url": "https://api.github.com/users/jreback/followers", "following_url": "https://api.github.com/users/jreback/following{/other_user}", "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}", "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jreback/subscriptions", "organizations_url": "https://api.github.com/users/jreback/orgs", "repos_url": "https://api.github.com/users/jreback/repos", "events_url": "https://api.github.com/users/jreback/events{/privacy}", "received_events_url": "https://api.github.com/users/jreback/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/pydata/pandas-gbq/milestones/1", "html_url": "https://github.com/pydata/pandas-gbq/milestone/1", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/milestones/1/labels", "id": 2309498, "node_id": "MDk6TWlsZXN0b25lMjMwOTQ5OA==", "number": 1, "title": "0.2.0", "description": "", "creator": {"login": "jreback", "id": 953992, "node_id": "MDQ6VXNlcjk1Mzk5Mg==", "avatar_url": "https://avatars2.githubusercontent.com/u/953992?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jreback", "html_url": "https://github.com/jreback", "followers_url": "https://api.github.com/users/jreback/followers", "following_url": "https://api.github.com/users/jreback/following{/other_user}", "gists_url": "https://api.github.com/users/jreback/gists{/gist_id}", "starred_url": "https://api.github.com/users/jreback/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jreback/subscriptions", "organizations_url": "https://api.github.com/users/jreback/orgs", "repos_url": "https://api.github.com/users/jreback/repos", "events_url": "https://api.github.com/users/jreback/events{/privacy}", "received_events_url": "https://api.github.com/users/jreback/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 22, "state": "closed", "created_at": "2017-02-08T14:00:39Z", "updated_at": "2017-07-25T09:49:07Z", "due_on": "2017-07-31T07:00:00Z", "closed_at": "2017-07-25T09:49:07Z"}, "comments": 7, "created_at": "2017-07-22T19:44:03Z", "updated_at": "2017-07-25T09:50:28Z", "closed_at": "2017-07-25T09:48:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "@parthea can you do this release?\r\n\r\nwhatsnew needs updating to the date of the release and otherwise follow the release-procedure.\r\n\r\nalso some things failing which :<\r\n\r\nhttps://travis-ci.org/pydata/pandas-gbq/builds/256434923", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/73", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/73/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/73/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/73/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/73", "id": 243082472, "node_id": "MDU6SXNzdWUyNDMwODI0NzI=", "number": 73, "title": "read_gbq() unnecessarily waiting on getting default credentials from Google", "user": {"login": "dfontenot", "id": 174527, "node_id": "MDQ6VXNlcjE3NDUyNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/174527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dfontenot", "html_url": "https://github.com/dfontenot", "followers_url": "https://api.github.com/users/dfontenot/followers", "following_url": "https://api.github.com/users/dfontenot/following{/other_user}", "gists_url": "https://api.github.com/users/dfontenot/gists{/gist_id}", "starred_url": "https://api.github.com/users/dfontenot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dfontenot/subscriptions", "organizations_url": "https://api.github.com/users/dfontenot/orgs", "repos_url": "https://api.github.com/users/dfontenot/repos", "events_url": "https://api.github.com/users/dfontenot/events{/privacy}", "received_events_url": "https://api.github.com/users/dfontenot/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 534980916, "node_id": "MDU6TGFiZWw1MzQ5ODA5MTY=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20bug", "name": "type: bug", "color": "db4437", "default": false, "description": "Error or flaw in code with unintended results or allowing sub-optimal usage patterns."}, {"id": 535013928, "node_id": "MDU6TGFiZWw1MzUwMTM5Mjg=", "url": "https://api.github.com/repos/pydata/pandas-gbq/labels/type:%20cleanup", "name": "type: cleanup", "color": "c5def5", "default": false, "description": "An internal cleanup or hygiene concern."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2017-07-14T18:57:28Z", "updated_at": "2018-03-31T19:32:31Z", "closed_at": "2018-03-31T19:32:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "When attempting to grant pandas access to my GBQ project, I am running into an issue where `read_gbq` is trying to get default credentials, failing / timing out, then printing out a URL to go to to grant the credentials. Since I'm not running this on google cloud platform, I do not expect to be able to get default credentials. In my case, I only want to run the CLI flow (without having oauth call back to my local server).\r\n\r\nHere's the code\r\n```\r\n>>> import pandas_gbq as gbq\r\n>>> gbq.read_gbq('SELECT 1', project_id=<project_id>, auth_local_webserver=False)\r\n```\r\n\r\nHere's what I see when I trigger a SIGINT once the query is invoked:\r\n```\r\n  File \"/usr/lib/python3.5/site-packages/pandas_gbq/gbq.py\", line 214, in get_credentials\r\n    credentials = self.get_application_default_credentials()\r\n  File \"/usr/lib/python3.5/site-packages/pandas_gbq/gbq.py\", line 243, in get_application_default_credentials\r\n    credentials, _ = google.auth.default(scopes=[self.scope])\r\n  File \"/usr/lib/python3.5/site-packages/google/auth/_default.py\", line 277, in default\r\n    credentials, project_id = checker()\r\n  File \"/usr/lib/python3.5/site-packages/google/auth/_default.py\", line 274, in <lambda>\r\n    lambda: _get_gce_credentials(request))\r\n  File \"/usr/lib/python3.5/site-packages/google/auth/_default.py\", line 176, in _get_gce_credentials\r\n    if _metadata.ping(request=request):\r\n  File \"/usr/lib/python3.5/site-packages/google/auth/compute_engine/_metadata.py\", line 73, in ping\r\n    timeout=timeout)\r\n  File \"/usr/lib/python3.5/site-packages/google/auth/transport/_http_client.py\", line 103, in __call__\r\n    method, path, body=body, headers=headers, **kwargs)\r\n  File \"/usr/lib/python3.5/http/client.py\", line 1106, in request\r\n    self._send_request(method, url, body, headers)\r\n  File \"/usr/lib/python3.5/http/client.py\", line 1151, in _send_request\r\n    self.endheaders(body)\r\n  File \"/usr/lib/python3.5/http/client.py\", line 1102, in endheaders\r\n    self._send_output(message_body)\r\n  File \"/usr/lib/python3.5/http/client.py\", line 934, in _send_output\r\n    self.send(msg)\r\n  File \"/usr/lib/python3.5/http/client.py\", line 877, in send\r\n    self.connect()\r\n  File \"/usr/lib/python3.5/http/client.py\", line 849, in connect\r\n    (self.host,self.port), self.timeout, self.source_address)\r\n  File \"/usr/lib/python3.5/socket.py\", line 702, in create_connection\r\n    sock.connect(sa)\r\nKeyboardInterrupt\r\n```\r\n\r\nI've also tried setting the env variable `GOOGLE_APPLICATIONS_CREDENTIALS` to empty. I'm using pandas-gbq version at commit 64a19b.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/pydata/pandas-gbq/issues/72", "repository_url": "https://api.github.com/repos/pydata/pandas-gbq", "labels_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/72/labels{/name}", "comments_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/72/comments", "events_url": "https://api.github.com/repos/pydata/pandas-gbq/issues/72/events", "html_url": "https://github.com/pydata/pandas-gbq/issues/72", "id": 241918282, "node_id": "MDU6SXNzdWUyNDE5MTgyODI=", "number": 72, "title": "Integration tests should fail rather than skip if project id is not set in Travis", "user": {"login": "parthea", "id": 5184014, "node_id": "MDQ6VXNlcjUxODQwMTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5184014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parthea", "html_url": "https://github.com/parthea", "followers_url": "https://api.github.com/users/parthea/followers", "following_url": "https://api.github.com/users/parthea/following{/other_user}", "gists_url": "https://api.github.com/users/parthea/gists{/gist_id}", "starred_url": "https://api.github.com/users/parthea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parthea/subscriptions", "organizations_url": "https://api.github.com/users/parthea/orgs", "repos_url": "https://api.github.com/users/parthea/repos", "events_url": "https://api.github.com/users/parthea/events{/privacy}", "received_events_url": "https://api.github.com/users/parthea/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-07-11T04:00:52Z", "updated_at": "2018-08-21T17:34:22Z", "closed_at": "2018-08-21T17:34:21Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "Certain integration tests are [skipped](https://github.com/pydata/pandas-gbq/blob/master/pandas_gbq/tests/test_gbq.py#L25) if a BigQuery project is not set in Travis. My initial thought is that the tests should fail if a BigQuery project id is not provided. \r\n\r\nFor reference, here are the steps to run the BigQuery integration tests on Travis:\r\nhttps://pandas-gbq.readthedocs.io/en/latest/contributing.html#running-google-bigquery-integration-tests", "performed_via_github_app": null, "score": 1.0}]}