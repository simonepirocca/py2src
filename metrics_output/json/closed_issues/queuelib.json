{"total_count": 9, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/scrapy/queuelib/issues/31", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/31/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/31/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/31/events", "html_url": "https://github.com/scrapy/queuelib/issues/31", "id": 616546089, "node_id": "MDU6SXNzdWU2MTY1NDYwODk=", "number": 31, "title": "multithread unit-test performance test", "user": {"login": "rizplate", "id": 3771231, "node_id": "MDQ6VXNlcjM3NzEyMzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/3771231?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rizplate", "html_url": "https://github.com/rizplate", "followers_url": "https://api.github.com/users/rizplate/followers", "following_url": "https://api.github.com/users/rizplate/following{/other_user}", "gists_url": "https://api.github.com/users/rizplate/gists{/gist_id}", "starred_url": "https://api.github.com/users/rizplate/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rizplate/subscriptions", "organizations_url": "https://api.github.com/users/rizplate/orgs", "repos_url": "https://api.github.com/users/rizplate/repos", "events_url": "https://api.github.com/users/rizplate/events{/privacy}", "received_events_url": "https://api.github.com/users/rizplate/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-12T10:31:33Z", "updated_at": "2020-05-12T15:27:47Z", "closed_at": "2020-05-12T15:27:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "do you have unit tests or performance tests using using multiple threads or multiple processes ?\r\n\r\nhow are you sure that it will work in above cases. I see that sqlite connection is not synchronized in your code", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/queuelib/issues/17", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/17/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/17/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/17/events", "html_url": "https://github.com/scrapy/queuelib/issues/17", "id": 188161116, "node_id": "MDU6SXNzdWUxODgxNjExMTY=", "number": 17, "title": "Question: can I load a queue from previous disk file", "user": {"login": "peter-wangxu", "id": 3829504, "node_id": "MDQ6VXNlcjM4Mjk1MDQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/3829504?v=4", "gravatar_id": "", "url": "https://api.github.com/users/peter-wangxu", "html_url": "https://github.com/peter-wangxu", "followers_url": "https://api.github.com/users/peter-wangxu/followers", "following_url": "https://api.github.com/users/peter-wangxu/following{/other_user}", "gists_url": "https://api.github.com/users/peter-wangxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/peter-wangxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/peter-wangxu/subscriptions", "organizations_url": "https://api.github.com/users/peter-wangxu/orgs", "repos_url": "https://api.github.com/users/peter-wangxu/repos", "events_url": "https://api.github.com/users/peter-wangxu/events{/privacy}", "received_events_url": "https://api.github.com/users/peter-wangxu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2016-11-09T03:39:16Z", "updated_at": "2017-02-17T01:05:25Z", "closed_at": "2017-02-17T01:05:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thanks for this easy to use library,\r\n\r\nI can easily store data to file, If process quits, can i load stored data from existing file?\r\n\r\nThanks\r\nPeter", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/queuelib/issues/12", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/12/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/12/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/12/events", "html_url": "https://github.com/scrapy/queuelib/issues/12", "id": 136244260, "node_id": "MDU6SXNzdWUxMzYyNDQyNjA=", "number": 12, "title": "Too many open files", "user": {"login": "base698", "id": 207514, "node_id": "MDQ6VXNlcjIwNzUxNA==", "avatar_url": "https://avatars1.githubusercontent.com/u/207514?v=4", "gravatar_id": "", "url": "https://api.github.com/users/base698", "html_url": "https://github.com/base698", "followers_url": "https://api.github.com/users/base698/followers", "following_url": "https://api.github.com/users/base698/following{/other_user}", "gists_url": "https://api.github.com/users/base698/gists{/gist_id}", "starred_url": "https://api.github.com/users/base698/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/base698/subscriptions", "organizations_url": "https://api.github.com/users/base698/orgs", "repos_url": "https://api.github.com/users/base698/repos", "events_url": "https://api.github.com/users/base698/events{/privacy}", "received_events_url": "https://api.github.com/users/base698/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-02-25T01:26:08Z", "updated_at": "2019-08-22T17:05:34Z", "closed_at": "2019-08-22T17:05:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "Adding lots of stuff to the queue results in this error: \n\n**Test case:\n\n```\nfrom queuelib import FifoDiskQueue, PriorityQueue as DiskPriorityQueue\nfor i in xrange(0, 100000):\n   pq.push(str(i), i)\n\n```\n\nTraceback (most recent call last):\n  File \"fit.py\", line 595, in <module>\n  File \"fit.py\", line 557, in **init**\n  File \"/usr/local/lib/python2.7/site-packages/queuelib/pqueue.py\", line 33, in push\n  File \"fit.py\", line 541, in <lambda>\n  File \"/usr/local/lib/python2.7/site-packages/queuelib/queue.py\", line 47, in **init**\n  File \"/usr/local/lib/python2.7/site-packages/queuelib/queue.py\", line 67, in _openchunk\nIOError: [Errno 24] Too many open files: 'queue-dir-113/q00000'\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/queuelib/issues/11", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/11/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/11/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/11/events", "html_url": "https://github.com/scrapy/queuelib/issues/11", "id": 105598162, "node_id": "MDU6SXNzdWUxMDU1OTgxNjI=", "number": 11, "title": "scrapy tests fail with queuelib 1.4.0", "user": {"login": "kmike", "id": 107893, "node_id": "MDQ6VXNlcjEwNzg5Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/107893?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmike", "html_url": "https://github.com/kmike", "followers_url": "https://api.github.com/users/kmike/followers", "following_url": "https://api.github.com/users/kmike/following{/other_user}", "gists_url": "https://api.github.com/users/kmike/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmike/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmike/subscriptions", "organizations_url": "https://api.github.com/users/kmike/orgs", "repos_url": "https://api.github.com/users/kmike/repos", "events_url": "https://api.github.com/users/kmike/events{/privacy}", "received_events_url": "https://api.github.com/users/kmike/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2015-09-09T13:37:56Z", "updated_at": "2015-09-09T19:43:33Z", "closed_at": "2015-09-09T19:42:37Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Hey @dangra, \n\nScrapy tests start to fail after https://github.com/scrapy/queuelib/commit/89f6df01f1dc43b938243d9c3fa3aa75e5dddda2 (see https://travis-ci.org/scrapy/scrapy/jobs/79465256). It looks like a test-only issue: `.qdir` was renamed to `.qpath`.\n\nWhat do you prefer - fix it in Scrapy (1.0 and master branches) or add .qdir alias to queuelib?\n\nA part of the problem is that we're not running `trunk` tests for Scrapy on Travis; maybe we should start doing this (likely with failures allowed).\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/queuelib/issues/9", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/9/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/9/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/9/events", "html_url": "https://github.com/scrapy/queuelib/issues/9", "id": 103466096, "node_id": "MDU6SXNzdWUxMDM0NjYwOTY=", "number": 9, "title": "In FifoDiskQueue, os.makedirs(path) occassionally fails with WindowsError [Error 5] in Windows", "user": {"login": "foresightyj", "id": 1296736, "node_id": "MDQ6VXNlcjEyOTY3MzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1296736?v=4", "gravatar_id": "", "url": "https://api.github.com/users/foresightyj", "html_url": "https://github.com/foresightyj", "followers_url": "https://api.github.com/users/foresightyj/followers", "following_url": "https://api.github.com/users/foresightyj/following{/other_user}", "gists_url": "https://api.github.com/users/foresightyj/gists{/gist_id}", "starred_url": "https://api.github.com/users/foresightyj/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/foresightyj/subscriptions", "organizations_url": "https://api.github.com/users/foresightyj/orgs", "repos_url": "https://api.github.com/users/foresightyj/repos", "events_url": "https://api.github.com/users/foresightyj/events{/privacy}", "received_events_url": "https://api.github.com/users/foresightyj/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2015-08-27T09:23:02Z", "updated_at": "2019-08-22T17:07:03Z", "closed_at": "2019-08-22T17:07:03Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Here comes a windows-specific problem again. It is not be a big issue but I think it is worth letting you guys know.\n\nI posted this question to stackoverflow, [see here](http://stackoverflow.com/questions/32243199/python-rapidly-creating-and-removing-directories-will-cause-windowserror-error?noredirect=1#comment52371092_32243199)\n\nFor the moment, I simply changed the line to:\n\n```\ntry:\n    os.makedirs(path)\nexcept WindowsError as e:\n    os.makedirs(path)\n```\n\nThis will make it a hell of a lot better.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/queuelib/issues/6", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/6/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/6/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/6/events", "html_url": "https://github.com/scrapy/queuelib/issues/6", "id": 95661030, "node_id": "MDU6SXNzdWU5NTY2MTAzMA==", "number": 6, "title": "  PickleFifoDiskQueue and FifoMemoryQueue throw EOF when used to persist a crawl", "user": {"login": "nramirezuy", "id": 1042865, "node_id": "MDQ6VXNlcjEwNDI4NjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1042865?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nramirezuy", "html_url": "https://github.com/nramirezuy", "followers_url": "https://api.github.com/users/nramirezuy/followers", "following_url": "https://api.github.com/users/nramirezuy/following{/other_user}", "gists_url": "https://api.github.com/users/nramirezuy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nramirezuy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nramirezuy/subscriptions", "organizations_url": "https://api.github.com/users/nramirezuy/orgs", "repos_url": "https://api.github.com/users/nramirezuy/repos", "events_url": "https://api.github.com/users/nramirezuy/events{/privacy}", "received_events_url": "https://api.github.com/users/nramirezuy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2015-07-17T13:57:45Z", "updated_at": "2015-09-02T02:08:31Z", "closed_at": "2015-09-02T02:08:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "AUTHOR: @Varriount\n\nWhen using scrapy's PickleFifoDiskQueue and FifoMemoryQueue objects for persistence and request scheduling, an EOF exception is thrown:\n\n```\nTraceback (most recent call last):\n  File \"C:\\x64\\python27\\lib\\site-packages\\scrapy-1.1.0dev1-py2.7.egg\\scrapy\\commands\\crawl.py\", line 58, in run\n    self.crawler_process.start()\n  File \"C:\\x64\\python27\\lib\\site-packages\\scrapy-1.1.0dev1-py2.7.egg\\scrapy\\crawler.py\", line 253, in start\n    reactor.run(installSignalHandlers=False)  # blocking call\n  File \"C:\\x64\\python27\\lib\\site-packages\\twisted\\internet\\base.py\", line 1194, in run\n    self.mainLoop()\n  File \"C:\\x64\\python27\\lib\\site-packages\\twisted\\internet\\base.py\", line 1203, in mainLoop\n    self.runUntilCurrent()\n--- <exception caught here> ---\n  File \"C:\\x64\\python27\\lib\\site-packages\\twisted\\internet\\base.py\", line 825, in runUntilCurrent\n    call.func(*call.args, **call.kw)\n  File \"C:\\x64\\python27\\lib\\site-packages\\scrapy-1.1.0dev1-py2.7.egg\\scrapy\\utils\\reactor.py\", line 41, in __call__\n    return self._func(*self._a, **self._kw)\n  File \"C:\\x64\\python27\\lib\\site-packages\\scrapy-1.1.0dev1-py2.7.egg\\scrapy\\core\\engine.py\", line 105, in _next_request\n    if not self._next_request_from_scheduler(spider):\n  File \"C:\\x64\\python27\\lib\\site-packages\\scrapy-1.1.0dev1-py2.7.egg\\scrapy\\core\\engine.py\", line 132, in _next_request_from_scheduler\n    request = slot.scheduler.next_request()\n  File \"C:\\x64\\python27\\lib\\site-packages\\scrapy-1.1.0dev1-py2.7.egg\\scrapy\\core\\scheduler.py\", line 68, in next_request\n    request = self._dqpop()\n  File \"C:\\x64\\python27\\lib\\site-packages\\scrapy-1.1.0dev1-py2.7.egg\\scrapy\\core\\scheduler.py\", line 98, in _dqpop\n    d = self.dqs.pop()\n  File \"C:\\x64\\python27\\lib\\site-packages\\queuelib\\pqueue.py\", line 43, in pop\n    m = q.pop()\n  File \"C:\\x64\\python27\\lib\\site-packages\\scrapy-1.1.0dev1-py2.7.egg\\scrapy\\squeues.py\", line 21, in pop\n    return deserialize(s)\nexceptions.EOFError:\n```\n\nThere isn't any problem when not persisting the crawl (omitting '-s JOBDIR=crawl-1'), so my best guess is that the problem lies mainly with  PickleFifoDiskQueue.\nI'm running Python 2.7 x64 on Windows 8 x64, using the latest Scrapy from the master branch. This bug affects the latest stable Scrapy build as well. \n\nEdit: After some investigation, it seems that a race condition is occurring when the FifoDiskQueue object's headf and tailf file descriptors point to the same file. Adding a 'sleep' to the pop() method greatly decreases the occurrence of the EOF exception over multiple runs.\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/queuelib/issues/5", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/5/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/5/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/5/events", "html_url": "https://github.com/scrapy/queuelib/issues/5", "id": 55471210, "node_id": "MDU6SXNzdWU1NTQ3MTIxMA==", "number": 5, "title": "FifoDiskQueue appears empty after process exit without closing file", "user": {"login": "obeleh", "id": 174411, "node_id": "MDQ6VXNlcjE3NDQxMQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/174411?v=4", "gravatar_id": "", "url": "https://api.github.com/users/obeleh", "html_url": "https://github.com/obeleh", "followers_url": "https://api.github.com/users/obeleh/followers", "following_url": "https://api.github.com/users/obeleh/following{/other_user}", "gists_url": "https://api.github.com/users/obeleh/gists{/gist_id}", "starred_url": "https://api.github.com/users/obeleh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/obeleh/subscriptions", "organizations_url": "https://api.github.com/users/obeleh/orgs", "repos_url": "https://api.github.com/users/obeleh/repos", "events_url": "https://api.github.com/users/obeleh/events{/privacy}", "received_events_url": "https://api.github.com/users/obeleh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2015-01-26T11:16:22Z", "updated_at": "2015-09-02T02:09:29Z", "closed_at": "2015-09-02T02:09:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was looking at using FifoDiskQueue to write incoming messages to disk before processing them. In case of a crash I then could re-open the queue and continue processing. But it seems that the queue thinks its' empty. \n\nAm I correct to conclude that this scenario is not a usecase for FifoDiskQueue?\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/queuelib/issues/3", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/3/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/3/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/3/events", "html_url": "https://github.com/scrapy/queuelib/issues/3", "id": 29798616, "node_id": "MDU6SXNzdWUyOTc5ODYxNg==", "number": 3, "title": "Is three any wrong with the example code of PriorityQueue?", "user": {"login": "futork", "id": 1085665, "node_id": "MDQ6VXNlcjEwODU2NjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1085665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/futork", "html_url": "https://github.com/futork", "followers_url": "https://api.github.com/users/futork/followers", "following_url": "https://api.github.com/users/futork/following{/other_user}", "gists_url": "https://api.github.com/users/futork/gists{/gist_id}", "starred_url": "https://api.github.com/users/futork/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/futork/subscriptions", "organizations_url": "https://api.github.com/users/futork/orgs", "repos_url": "https://api.github.com/users/futork/repos", "events_url": "https://api.github.com/users/futork/events{/privacy}", "received_events_url": "https://api.github.com/users/futork/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2014-03-20T07:27:42Z", "updated_at": "2014-03-20T13:51:11Z", "closed_at": "2014-03-20T13:50:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "> > > from queuelib import FifoDiskQueue\n> > > q = FifoDiskQueue(\"/home/lf\")\n> > > from queuelib import PriorityQueue\n> > > pq = PriorityQueue(q)\n> > > pq.push(b'a', 3)\n> > > Traceback (most recent call last):\n> > >   File \"<stdin>\", line 1, in <module>\n> > >   File \"/usr/lib/python2.7/dist-packages/queuelib/pqueue.py\", line 33, in push\n> > >     self.queues[priority] = self.qfactory(priority)\n> > > TypeError: 'FifoDiskQueue' object is not callable\n\nShould q be a factory generate FifoDiskQueue object? \n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/scrapy/queuelib/issues/1", "repository_url": "https://api.github.com/repos/scrapy/queuelib", "labels_url": "https://api.github.com/repos/scrapy/queuelib/issues/1/labels{/name}", "comments_url": "https://api.github.com/repos/scrapy/queuelib/issues/1/comments", "events_url": "https://api.github.com/repos/scrapy/queuelib/issues/1/events", "html_url": "https://github.com/scrapy/queuelib/issues/1", "id": 25883184, "node_id": "MDU6SXNzdWUyNTg4MzE4NA==", "number": 1, "title": "README example opens a FIFO queue but result shown is a LIFO queue", "user": {"login": "kseistrup", "id": 25586, "node_id": "MDQ6VXNlcjI1NTg2", "avatar_url": "https://avatars2.githubusercontent.com/u/25586?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kseistrup", "html_url": "https://github.com/kseistrup", "followers_url": "https://api.github.com/users/kseistrup/followers", "following_url": "https://api.github.com/users/kseistrup/following{/other_user}", "gists_url": "https://api.github.com/users/kseistrup/gists{/gist_id}", "starred_url": "https://api.github.com/users/kseistrup/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kseistrup/subscriptions", "organizations_url": "https://api.github.com/users/kseistrup/orgs", "repos_url": "https://api.github.com/users/kseistrup/repos", "events_url": "https://api.github.com/users/kseistrup/events{/privacy}", "received_events_url": "https://api.github.com/users/kseistrup/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2014-01-19T16:32:33Z", "updated_at": "2014-01-20T17:13:58Z", "closed_at": "2014-01-20T17:13:58Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "The first example \u2014 and FIFO queue \u2014 pushes `a`, `b`, and `c`, then pops `c`, `b`, and `a`, which is LIFO.  I believe the README should have looked like this:\n\n``` diff\ndiff --git a/README.rst b/README.rst\nindex e3dd7ae..0b2dbb5 100644\n--- a/README.rst\n+++ b/README.rst\n@@ -48,13 +48,13 @@ Here is an example usage of the FIFO queue::\n     >>> q.push(b'b')\n     >>> q.push(b'c')\n     >>> q.pop()\n-    'c'\n+    b'a'\n     >>> q.close()\n     >>> q = FifoDiskQueue(\"queuefile\")\n     >>> q.pop()\n     b'b'\n     >>> q.pop()\n-    b'a'\n+    b'c'\n     >>> q.pop()\n     >>>\n\n```\n", "performed_via_github_app": null, "score": 1.0}]}