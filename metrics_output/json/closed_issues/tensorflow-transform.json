{"total_count": 104, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/tensorflow/transform/issues/196", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/196/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/196/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/196/events", "html_url": "https://github.com/tensorflow/transform/issues/196", "id": 680118900, "node_id": "MDU6SXNzdWU2ODAxMTg5MDA=", "number": 196, "title": "tfx.components.Evaluator Index error in one_hot (metric_util.py)", "user": {"login": "AlexandrePieroux", "id": 5711883, "node_id": "MDQ6VXNlcjU3MTE4ODM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5711883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AlexandrePieroux", "html_url": "https://github.com/AlexandrePieroux", "followers_url": "https://api.github.com/users/AlexandrePieroux/followers", "following_url": "https://api.github.com/users/AlexandrePieroux/following{/other_user}", "gists_url": "https://api.github.com/users/AlexandrePieroux/gists{/gist_id}", "starred_url": "https://api.github.com/users/AlexandrePieroux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AlexandrePieroux/subscriptions", "organizations_url": "https://api.github.com/users/AlexandrePieroux/orgs", "repos_url": "https://api.github.com/users/AlexandrePieroux/repos", "events_url": "https://api.github.com/users/AlexandrePieroux/events{/privacy}", "received_events_url": "https://api.github.com/users/AlexandrePieroux/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-17T10:16:38Z", "updated_at": "2020-08-17T10:20:51Z", "closed_at": "2020-08-17T10:20:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI've got an issue and I don't know if it's a bug or just a lack of understanding from me. \r\n\r\nI'm trying to make an Evaluator for my model. Until now every other components are fine but when I try this config:\r\n```\r\neval_config = tfma.EvalConfig(\r\n    model_specs=[\r\n        tfma.ModelSpec(label_key='Category'),\r\n    ],\r\n    metrics_specs=tfma.metrics.default_multi_class_classification_specs(),\r\n    slicing_specs=[\r\n        tfma.SlicingSpec(),\r\n        tfma.SlicingSpec(feature_keys=['Category'])\r\n    ])\r\n```\r\nto make this evaluator:\r\n\r\n```\r\nmodel_resolver = ResolverNode(\r\n      instance_name='latest_blessed_model_resolver',\r\n      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\r\n      model=Channel(type=Model),\r\n      model_blessing=Channel(type=ModelBlessing))\r\ncontext.run(model_resolver)\r\n\r\nevaluator = Evaluator(\r\n    examples=example_gen.outputs['examples'],\r\n    model=trainer.outputs['model'],\r\n    baseline_model=model_resolver.outputs['model'],\r\n    eval_config=eval_config)\r\ncontext.run(evaluator)\r\n````\r\n\r\nI get this:\r\n```\r\n[...]\r\nIndexError                                Traceback (most recent call last)\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-darwin.so in apache_beam.runners.common.DoFnRunner.process()\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-darwin.so in apache_beam.runners.common.PerWindowInvoker.invoke_process()\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-darwin.so in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window()\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/apache_beam/runners/common.cpython-37m-darwin.so in apache_beam.runners.common._OutputProcessor.process_outputs()\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-darwin.so in apache_beam.runners.worker.operations.SingletonConsumerSet.receive()\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-darwin.so in apache_beam.runners.worker.operations.PGBKCVOperation.process()\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/apache_beam/runners/worker/operations.cpython-37m-darwin.so in apache_beam.runners.worker.operations.PGBKCVOperation.process()\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/tensorflow_model_analysis/evaluators/metrics_and_plots_evaluator_v2.py in add_input(self, accumulator, element)\r\n    355     for i, (c, a) in enumerate(zip(self._combiners, accumulator)):\r\n--> 356       result = c.add_input(a, get_combiner_input(elements[0], i))\r\n    357       for e in elements[1:]:\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/tensorflow_model_analysis/metrics/calibration_histogram.py in add_input(self, accumulator, element)\r\n    141             flatten=True,\r\n--> 142             class_weights=self._class_weights)):\r\n    143       example_weight = float(example_weight)\r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py in to_label_prediction_example_weight(inputs, eval_config, model_name, output_name, sub_key, class_weights, flatten, squeeze, allow_none)\r\n    283     elif sub_key.top_k is not None:\r\n--> 284       label, prediction = select_top_k(sub_key.top_k, label, prediction)\r\n    285 \r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py in select_top_k(top_k, labels, predictions, scores)\r\n    621   if not labels.shape or labels.shape[-1] == 1:\r\n--> 622     labels = one_hot(labels, predictions)\r\n    623 \r\n\r\n/opt/miniconda3/envs/archiving/lib/python3.7/site-packages/tensorflow_model_analysis/metrics/metric_util.py in one_hot(tensor, target)\r\n    671   # indexing the -1 and then removing it after.\r\n--> 672   tensor = np.delete(np.eye(target.shape[-1] + 1)[tensor], -1, axis=-1)\r\n    673   return tensor.reshape(target.shape)\r\n\r\nIndexError: arrays used as indices must be of integer (or boolean) type\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n[...]\r\n\r\nIndexError: arrays used as indices must be of integer (or boolean) type [while running 'ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots()/ComputePerSlice/ComputeUnsampledMetrics/CombinePerSliceKey/WindowIntoDiscarding']\r\n```\r\nI thought it was my config, but I don't get what is wrong with this.\r\n\r\n\r\nNote: The model I'm using look like this:\r\n\r\n```\r\ndef _build_keras_model(vectorize_layer: TextVectorization) -> tf.keras.Model: \r\n\r\n  input_layer = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\r\n\r\n  deep = vectorize_layer(input_layer)\r\n  deep = layers.Embedding(_max_features + 1, _embedding_dim)(deep)\r\n  deep = layers.Dropout(0.5)(deep)\r\n  deep = layers.GlobalAveragePooling1D()(deep)\r\n  deep = layers.Dropout(0.5)(deep)\r\n\r\n  output = layers.Dense(5, activation=tf.nn.softmax)(deep)\r\n\r\n  model = tf.keras.Model(input_layer, output)\r\n  model.compile(\r\n      loss=losses.SparseCategoricalCrossentropy(from_logits=True),\r\n      optimizer='adam', \r\n      metrics=['accuracy'])\r\n  model.summary(print_fn=absl.logging.info)  \r\n  return model\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/194", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/194/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/194/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/194/events", "html_url": "https://github.com/tensorflow/transform/issues/194", "id": 676692380, "node_id": "MDU6SXNzdWU2NzY2OTIzODA=", "number": 194, "title": " Incompatible shapes when saving a Keras model", "user": {"login": "tillwf", "id": 7115035, "node_id": "MDQ6VXNlcjcxMTUwMzU=", "avatar_url": "https://avatars3.githubusercontent.com/u/7115035?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tillwf", "html_url": "https://github.com/tillwf", "followers_url": "https://api.github.com/users/tillwf/followers", "following_url": "https://api.github.com/users/tillwf/following{/other_user}", "gists_url": "https://api.github.com/users/tillwf/gists{/gist_id}", "starred_url": "https://api.github.com/users/tillwf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tillwf/subscriptions", "organizations_url": "https://api.github.com/users/tillwf/orgs", "repos_url": "https://api.github.com/users/tillwf/repos", "events_url": "https://api.github.com/users/tillwf/events{/privacy}", "received_events_url": "https://api.github.com/users/tillwf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-08-11T08:39:59Z", "updated_at": "2020-08-12T09:11:24Z", "closed_at": "2020-08-12T09:07:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nAn issue has been opened in the TFRanking repo ([#218](https://github.com/tensorflow/ranking/issues/218)), but it seems there hasn't been that much activity recently. As it is related to TFTransform, does someone has a any clue of what is wrong ?\r\n\r\nAs a summary, we are working on a training pipeline using TFTransform and TFRanking (https://github.com/phaidara/tfranking-example) and the transformation of VarLenFeatures breaks the model saving in TFRanking.\r\n\r\n```\r\n./train_keras_model.py:81 serve_tf_examples_fn  *\r\n        transformed_features = model.tft_layer(parsed_features)\r\n    /../../../../../venv/lib/python3.5/site-packages/tensorflow_transform/output_wrapper.py:303 call  *\r\n        return self._saved_model_loader.apply_v1_transform_model_in_v2(inputs)\r\n    ../../../../../../venv/lib/python3.5/site-packages/tensorflow_transform/saved/saved_transform_io_v2.py:155 apply_v1_transform_model_in_v2  *\r\n        tensor.shape.assert_is_compatible_with(input_map[name].shape)\r\n    ../../../../../venv/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with  **\r\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\n    ValueError: Shapes (2,) and (3,) are incompatible\r\n```\r\n\r\nThank you for your help", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/190", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/190/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/190/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/190/events", "html_url": "https://github.com/tensorflow/transform/issues/190", "id": 665668095, "node_id": "MDU6SXNzdWU2NjU2NjgwOTU=", "number": 190, "title": "Question: setting prediction with keras model using transform function", "user": {"login": "Shishir-Suman", "id": 8422789, "node_id": "MDQ6VXNlcjg0MjI3ODk=", "avatar_url": "https://avatars1.githubusercontent.com/u/8422789?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Shishir-Suman", "html_url": "https://github.com/Shishir-Suman", "followers_url": "https://api.github.com/users/Shishir-Suman/followers", "following_url": "https://api.github.com/users/Shishir-Suman/following{/other_user}", "gists_url": "https://api.github.com/users/Shishir-Suman/gists{/gist_id}", "starred_url": "https://api.github.com/users/Shishir-Suman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Shishir-Suman/subscriptions", "organizations_url": "https://api.github.com/users/Shishir-Suman/orgs", "repos_url": "https://api.github.com/users/Shishir-Suman/repos", "events_url": "https://api.github.com/users/Shishir-Suman/events{/privacy}", "received_events_url": "https://api.github.com/users/Shishir-Suman/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2020-07-25T22:04:36Z", "updated_at": "2020-08-21T06:52:32Z", "closed_at": "2020-08-21T06:52:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Have been trying to setup prediction pipeline for a keras model that uses transform function generated during model training. The generated transform function contains additional attributes which are not available during prediction and objective is to drop them and apply transforms on remaining features before running the model prediction.  \r\n\r\nCame across https://www.tensorflow.org/tfx/guide/keras#keras_module_file_with_transform. The link provides an example \r\n\r\n```def _get_serve_tf_examples_fn(model, tf_transform_output):\r\n  model.tft_layer = tf_transform_output.transform_features_layer()\r\n\r\n  @tf.function\r\n  def serve_tf_examples_fn(serialized_tf_examples):\r\n    feature_spec = tf_transform_output.raw_feature_spec()\r\n    feature_spec.pop(_LABEL_KEY)\r\n    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\r\n\r\n    transformed_features = model.tft_layer(parsed_features)\r\n\r\n    return model(transformed_features)\r\n\r\n  return serve_tf_examples_fn\r\n```\r\n\r\nand is referred later via\r\n\r\n```\r\nsignatures = {\r\n      'serving_default':\r\n          _get_serve_tf_examples_fn(model,\r\n                                    tf_transform_output).get_concrete_function(\r\n                                        tf.TensorSpec(\r\n                                            shape=[None],\r\n                                            dtype=tf.string,\r\n                                            name='examples')),\r\n  }\r\n  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)\r\n```\r\n\r\nIn here, executing tf_transform_output.transform_raw_features(raw_features) standalone gave me eager exception errors. Is that not supported yet. \r\n\r\nThanks in advance. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/189", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/189/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/189/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/189/events", "html_url": "https://github.com/tensorflow/transform/issues/189", "id": 664998778, "node_id": "MDU6SXNzdWU2NjQ5OTg3Nzg=", "number": 189, "title": "Add the ability to have the transform tfx component output only transform_graph and not transformed_examples", "user": {"login": "ntakouris", "id": 5436722, "node_id": "MDQ6VXNlcjU0MzY3MjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5436722?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ntakouris", "html_url": "https://github.com/ntakouris", "followers_url": "https://api.github.com/users/ntakouris/followers", "following_url": "https://api.github.com/users/ntakouris/following{/other_user}", "gists_url": "https://api.github.com/users/ntakouris/gists{/gist_id}", "starred_url": "https://api.github.com/users/ntakouris/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ntakouris/subscriptions", "organizations_url": "https://api.github.com/users/ntakouris/orgs", "repos_url": "https://api.github.com/users/ntakouris/repos", "events_url": "https://api.github.com/users/ntakouris/events{/privacy}", "received_events_url": "https://api.github.com/users/ntakouris/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-24T08:18:32Z", "updated_at": "2020-07-24T08:25:22Z", "closed_at": "2020-07-24T08:25:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "This issue was originally posted on `tensorflow/tfx` [here](https://github.com/tensorflow/tfx/issues/2207), but I was redirected here.\r\n\r\nThe dataset is already read from a 'slower' datasource (for example, csv files) and fed into example gen to split performant .tfrecord files.\r\n\r\nNo need to force re-duplicating the preprocessed whole dataset to the transform component's staging directory, the preprocessing could be done via the map function of `tf.data.Dataset`, on train data loading time, with the prefetch and autotune parallel calls optimisations, without performance drop. (Imagine duplicating TBs of data on the transform step)\r\n\r\nThe current behaviour of the Transform component with arg `transformed_examples=None` is to allocate a directory `<pipeline root>/Transform/transformed_examples/` and save the preprocessed tf records there.\r\n\r\nCould not avoid it with `transformed_examples=external_input(/dev/null)` and there is no documentation of a channel as far as I am aware of (that acts as a no-output flag).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/187", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/187/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/187/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/187/events", "html_url": "https://github.com/tensorflow/transform/issues/187", "id": 656790671, "node_id": "MDU6SXNzdWU2NTY3OTA2NzE=", "number": 187, "title": "Error when pre_processing includes tfp.stats functions", "user": {"login": "agonojo", "id": 67916189, "node_id": "MDQ6VXNlcjY3OTE2MTg5", "avatar_url": "https://avatars1.githubusercontent.com/u/67916189?v=4", "gravatar_id": "", "url": "https://api.github.com/users/agonojo", "html_url": "https://github.com/agonojo", "followers_url": "https://api.github.com/users/agonojo/followers", "following_url": "https://api.github.com/users/agonojo/following{/other_user}", "gists_url": "https://api.github.com/users/agonojo/gists{/gist_id}", "starred_url": "https://api.github.com/users/agonojo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/agonojo/subscriptions", "organizations_url": "https://api.github.com/users/agonojo/orgs", "repos_url": "https://api.github.com/users/agonojo/repos", "events_url": "https://api.github.com/users/agonojo/events{/privacy}", "received_events_url": "https://api.github.com/users/agonojo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-07-14T17:51:36Z", "updated_at": "2020-08-03T11:09:23Z", "closed_at": "2020-08-03T11:09:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "I wanted to try computing feature medians instead of means. My code works properly with:\r\n\r\n`mean = tf.reduce_mean(inputs[key])`\r\nbut not with\r\n`median = tfp.stats.percentile(inputs[key], 0.50, interpolation='midpoint')`\r\n\r\nI end up with error:\r\n```\r\n...\r\n  File \"apache_beam/runners/common.py\", line 961, in apache_beam.runners.common.DoFnRunner.process\r\n  File \"apache_beam/runners/common.py\", line 726, in apache_beam.runners.common.PerWindowInvoker.invoke_process\r\n  File \"apache_beam/runners/common.py\", line 807, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\r\n  File \"apache_beam/runners/common.py\", line 1095, in apache_beam.runners.common._OutputProcessor.process_outputs\r\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 422, in process\r\n    yield self._handle_batch(batch)\r\n  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 367, in _handle_batch\r\n    str(e), batch, self._graph_state.outputs_tensor_keys))\r\nValueError: An error occured while trying to apply the transformation: \"indices = 0 is not in [0, 0)\r\n         [[{{node percentile/GatherV2_1}}]]\".\r\n          Batch instances: [{'bed_bath_ratio': [0.9411764705882352], 'property_type': b'single-family', 'sold_price_mix': 470000.0, 'square_feet': [-999.0]}],\r\n          Fetching the values for the following Tensor keys: ['bed_bath_ratio', 'bed_bath_ratio_missing', 'property_type', 'sold_price_mix', 'square_feet', 'square_feet_missing']. [while running 'TransformDataset/Transform']\r\n```\r\n\r\nUtilizing\r\napache-beam==2.22.0\r\ntensorflow==2.2.0\r\ntensorflow-transform==0.22.0\r\ntensorflow-probability==0.10.1", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/177", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/177/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/177/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/177/events", "html_url": "https://github.com/tensorflow/transform/issues/177", "id": 623856137, "node_id": "MDU6SXNzdWU2MjM4NTYxMzc=", "number": 177, "title": "ExampleGen crashes in Colab repeatedly", "user": {"login": "wed0itagain", "id": 24192657, "node_id": "MDQ6VXNlcjI0MTkyNjU3", "avatar_url": "https://avatars0.githubusercontent.com/u/24192657?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wed0itagain", "html_url": "https://github.com/wed0itagain", "followers_url": "https://api.github.com/users/wed0itagain/followers", "following_url": "https://api.github.com/users/wed0itagain/following{/other_user}", "gists_url": "https://api.github.com/users/wed0itagain/gists{/gist_id}", "starred_url": "https://api.github.com/users/wed0itagain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wed0itagain/subscriptions", "organizations_url": "https://api.github.com/users/wed0itagain/orgs", "repos_url": "https://api.github.com/users/wed0itagain/repos", "events_url": "https://api.github.com/users/wed0itagain/events{/privacy}", "received_events_url": "https://api.github.com/users/wed0itagain/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-24T12:36:17Z", "updated_at": "2020-05-24T13:36:57Z", "closed_at": "2020-05-24T13:36:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, \r\n\r\nI'm experimenting with TFX notebook and wanted to upload and process by own csv in colab. I've downsized it and now it is only around 500kb (only the first few rows).  \r\n\r\nINFO:absl:Running driver for CsvExampleGen\r\nINFO:absl:MetadataStore with DB connection initialized\r\nINFO:absl:Running executor for CsvExampleGen\r\nINFO:absl:Generating examples.\r\nINFO:absl:Using 1 process(es) for Beam pipeline execution.\r\nINFO:absl:Processing input csv data /tmp/tfx-data#####/* to TFExample.\r\n\r\nAnd then it runs out of RAM (12gb version - will soon upgrade but i dont think that it will fix the problem). I also made sure to use only string values but would that even help?\r\n\r\nHope somebody can help \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/176", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/176/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/176/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/176/events", "html_url": "https://github.com/tensorflow/transform/issues/176", "id": 620540116, "node_id": "MDU6SXNzdWU2MjA1NDAxMTY=", "number": 176, "title": "count_per_key not working with SparseTensor input", "user": {"login": "JakeTheWise", "id": 13136287, "node_id": "MDQ6VXNlcjEzMTM2Mjg3", "avatar_url": "https://avatars2.githubusercontent.com/u/13136287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JakeTheWise", "html_url": "https://github.com/JakeTheWise", "followers_url": "https://api.github.com/users/JakeTheWise/followers", "following_url": "https://api.github.com/users/JakeTheWise/following{/other_user}", "gists_url": "https://api.github.com/users/JakeTheWise/gists{/gist_id}", "starred_url": "https://api.github.com/users/JakeTheWise/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JakeTheWise/subscriptions", "organizations_url": "https://api.github.com/users/JakeTheWise/orgs", "repos_url": "https://api.github.com/users/JakeTheWise/repos", "events_url": "https://api.github.com/users/JakeTheWise/events{/privacy}", "received_events_url": "https://api.github.com/users/JakeTheWise/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-05-18T22:18:01Z", "updated_at": "2020-05-27T13:46:17Z", "closed_at": "2020-05-27T13:46:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "tensorflow==2.1.0\r\ntensorflow-data-validation==0.22.0\r\ntensorflow-transform==0.22.0\r\n\r\nTrying to compute `tft.count_per_key` on a `tf.SparseTensor` gives an `AttributeError: 'SparseTensor' object has no attribute 'set_shape'` even though the documentation says it will work with a sparse tensor.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/173", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/173/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/173/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/173/events", "html_url": "https://github.com/tensorflow/transform/issues/173", "id": 614315113, "node_id": "MDU6SXNzdWU2MTQzMTUxMTM=", "number": 173, "title": "ptransform_analyzer: unexpected output shape and behaviour", "user": {"login": "iainwo", "id": 50518594, "node_id": "MDQ6VXNlcjUwNTE4NTk0", "avatar_url": "https://avatars1.githubusercontent.com/u/50518594?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iainwo", "html_url": "https://github.com/iainwo", "followers_url": "https://api.github.com/users/iainwo/followers", "following_url": "https://api.github.com/users/iainwo/following{/other_user}", "gists_url": "https://api.github.com/users/iainwo/gists{/gist_id}", "starred_url": "https://api.github.com/users/iainwo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iainwo/subscriptions", "organizations_url": "https://api.github.com/users/iainwo/orgs", "repos_url": "https://api.github.com/users/iainwo/repos", "events_url": "https://api.github.com/users/iainwo/events{/privacy}", "received_events_url": "https://api.github.com/users/iainwo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-05-07T20:13:04Z", "updated_at": "2020-06-22T16:03:37Z", "closed_at": "2020-06-22T16:03:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi team,\r\n\r\n# Motivation\r\nRecently, I've been attempting to augment TFX and TFT with Apache Beam and I have run into an issue - or perhaps, a lack of understanding.\r\nMy motivation is to produce a reusable hermetic artifact to satisfy common inference tasks like model scoring and deployment. Within that artifact will include the mechanics for preprocessing, feature-engineering and modelling.\r\n\r\n# Issue\r\nThe shape and behaviour produced by tft.ptransform_analyzer seems contradictory to the documentation within the method signature.\r\n- It seems, that applications of ptransform_analyzer which produce tensors with parameterized shapes that are greater-than rank-0, instead produces tensors of the intended rank but with shapes that are stretched by a constant factor\r\n\r\n# Related Issue\r\nThere is another similar issue open: https://github.com/tensorflow/transform/issues/166.\r\n\r\nWould love to get your input,\r\n- Thanks, Iain\r\n\r\n# Code Sketch\r\nThe code looks something like this, at the bottom of the issue I will include a Colab notebook with a full implementation.\r\n\r\n## Control preprocessing_fn()\r\nA straight pass-through replicates the same number of raw ingested samples.\r\n```python\r\ndef preprocessing_fn(inputs):\r\n  return inputs # producing tensor shape (9909, 18)\r\n```\r\n\r\n## Trial preprocessing_fn()\r\nA beam transformation employed on the raw samples produces duplicated output.\r\n```python\r\ndef preprocessing_fn(inputs):\r\n  outputs = dict()\r\n  preprocessed_data = tft.ptransform_analyzer(\r\n      inputs=[\r\n        _fill_in_missing(inputs['trip_seconds']),\r\n        _fill_in_missing(inputs['fare']),\r\n      ],\r\n      output_dtypes=[tf.string for feat in _ALL_COLUMNS],\r\n      output_shapes=[(None,) for feat in _ALL_COLUMNS],\r\n      ptransform=Preprocessing(),\r\n      name='PtransformAnalyzerPreprocessingTrial',\r\n  )\r\n  for label, tup in enumerate(preprocessed_data):\r\n    outputs[f'beam_feature_{label}'] = tup\r\n\r\n  return outputs # producing shape of (138740, 2). expected to be (9909, 2)\r\n```\r\n\r\n## Ratio of preprocessing_fn#1 vs preprocessing_fn#2\r\n```python\r\n>>> trial_df.shape[0]/(control_df.shape[0]+1)\r\n14.0\r\n```\r\n\r\n# Colab Notebook\r\nhttps://gist.github.com/iainwo/ccfd4d37bee12994ab734007c0cebcb1", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/172", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/172/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/172/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/172/events", "html_url": "https://github.com/tensorflow/transform/issues/172", "id": 602559720, "node_id": "MDU6SXNzdWU2MDI1NTk3MjA=", "number": 172, "title": "Can we specify the deferred_vocab_filename_tensor attribute in tft.apply_vocabulary() as a file that was returned by a tft.vocabulary() from another function?", "user": {"login": "hanglearning", "id": 13460425, "node_id": "MDQ6VXNlcjEzNDYwNDI1", "avatar_url": "https://avatars2.githubusercontent.com/u/13460425?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hanglearning", "html_url": "https://github.com/hanglearning", "followers_url": "https://api.github.com/users/hanglearning/followers", "following_url": "https://api.github.com/users/hanglearning/following{/other_user}", "gists_url": "https://api.github.com/users/hanglearning/gists{/gist_id}", "starred_url": "https://api.github.com/users/hanglearning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hanglearning/subscriptions", "organizations_url": "https://api.github.com/users/hanglearning/orgs", "repos_url": "https://api.github.com/users/hanglearning/repos", "events_url": "https://api.github.com/users/hanglearning/events{/privacy}", "received_events_url": "https://api.github.com/users/hanglearning/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-18T21:50:51Z", "updated_at": "2020-05-21T19:08:46Z", "closed_at": "2020-05-21T19:08:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "I followed this tutorial https://github.com/tensorflow/transform/blob/599691c8b94bbd6ee7f67c11542e7fef1792a566/examples/sentiment_example.py to build my beam data pipeline to preprocess my dataset which is basically transforming all the vocabulary to word embeddings.\r\n\r\nHowever, since my training data and test data have different structures, I have written two different preprocessing functions inside of transform_data(), which are like:\r\n\r\n```\r\ndef transform_data(working_dir):\r\n\r\n    with beam.Pipeline() as pipeline:\r\n            # Read Train Data\r\n            # Read Test Data\r\n\r\n            def preprocessing_fn_train(inputs):\r\n                # preprocess function for training dataset\r\n\r\n            def preprocessing_fn_test(inputs):\r\n                # preprocess function for test dataset\r\n```\r\n\r\nAs I need to make preprocessing_fn_test() use the vocab generated in preprocessing_fn_train(), I have made the following attemp:\r\n\r\n```\r\ndef transform_data(working_dir):\r\n\r\n    with beam.Pipeline() as pipeline:\r\n            # Read Train Data\r\n            # Read Test Data\r\n\r\n            def preprocessing_fn_train(inputs):\r\n                # preprocess function for training dataset\r\n                ...\r\n                train_vocab_mapping_file_path = tft.vocabulary(train_vocab_tokens, vocab_filename='train_vocab')\r\n                # my train set has these 2 attributes\r\n                mapped_context = tft.apply_vocabulary(context_tokens, deferred_vocab_filename_tensor=train_vocab_mapping_file_path)\r\n                mapped_utterance = tft.apply_vocabulary(utterance_tokens, deferred_vocab_filename_tensor=train_vocab_mapping_file_path)\r\n                ...\r\n\r\n            def preprocessing_fn_test(inputs):\r\n                # preprocess function for test dataset\r\n                # my test set has these 4 attributes\r\n                mapped_context = tft.apply_vocabulary(context_tokens, deferred_vocab_filename_tensor=train_vocab_mapping_file_path)\r\n                mapped_utterance = tft.apply_vocabulary(utterance_tokens, deferred_vocab_filename_tensor=train_vocab_mapping_file_path)\r\n                mapped_distractor_1 = tft.apply_vocabulary(distractor_1_tokens, deferred_vocab_filename_tensor=train_vocab_mapping_file_path)\r\n                mapped_distractor_2 = tft.apply_vocabulary(distractor_1_tokens, deferred_vocab_filename_tensor=train_vocab_mapping_file_path)\r\n```\r\n\r\n\r\nApparently, running apply_vocabulary() in preprocessing_fn_test() in this way will result error that train_vocab_mapping_file_path is not defined as it was defined in another function. \r\n\r\nAs stated in https://www.tensorflow.org/tfx/transform/api_docs/python/tft/apply_vocabulary, the difficulty is that in apply_vocabulary(), deferred_vocab_filename_tensor must be a tensor that is returned from tft.vocabulary(). However, in our case, tft.vocabulary() must be called only in preprocessing_fn_train() but its returned value has to be used in both preprocessing_fn_train() and preprocessing_fn_test().\r\n\r\nIs there a way to specify deferred_vocab_filename_tensor in preprocessing_fn_test() as something like the path to the vocab file generated in preprocessing_fn_train()? Or if there is a more elegant or standard way to do this?\r\n\r\nThank you!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/170", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/170/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/170/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/170/events", "html_url": "https://github.com/tensorflow/transform/issues/170", "id": 592027678, "node_id": "MDU6SXNzdWU1OTIwMjc2Nzg=", "number": 170, "title": "`Op type not registered: 'RegexSplitWithOffsets'` with Tensorflow Text v1.15.1", "user": {"login": "jshph", "id": 6334450, "node_id": "MDQ6VXNlcjYzMzQ0NTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/6334450?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jshph", "html_url": "https://github.com/jshph", "followers_url": "https://api.github.com/users/jshph/followers", "following_url": "https://api.github.com/users/jshph/following{/other_user}", "gists_url": "https://api.github.com/users/jshph/gists{/gist_id}", "starred_url": "https://api.github.com/users/jshph/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jshph/subscriptions", "organizations_url": "https://api.github.com/users/jshph/orgs", "repos_url": "https://api.github.com/users/jshph/repos", "events_url": "https://api.github.com/users/jshph/events{/privacy}", "received_events_url": "https://api.github.com/users/jshph/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2020-04-01T16:01:00Z", "updated_at": "2020-07-22T10:13:40Z", "closed_at": "2020-07-22T10:13:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to run TF Text's BertTokenizer within TF Transform's preprocessing_fn, and this is running on Kubeflow. I'm getting `RuntimeError: tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'RegexSplitWithOffsets' in binary ...` and this looks like it resembles something that was addressed before: https://github.com/tensorflow/text/releases/tag/v1.15.0\r\n\r\nWe've verified that TF Text is installed on the Dataflow workers, so maybe that is not the issue?\r\n\r\nAlso, I ran the TF Transform component with a local beam graph and the whole graph executed successfully and wrote to local output.\r\n\r\nI'm running TF Transform version 0.15.0, TF 1.15.2, and TF Text v1.15.1.\r\n\r\nAny pointers would be appreciated! Thank you in advance!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/169", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/169/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/169/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/169/events", "html_url": "https://github.com/tensorflow/transform/issues/169", "id": 591902685, "node_id": "MDU6SXNzdWU1OTE5MDI2ODU=", "number": 169, "title": "TypeError: Dimension value must be integer got <tf.Tensor 'max/min_and_max/Placeholder_1:0' while using tft Analyzer inside preprocessing function", "user": {"login": "rakeshmothukuru1", "id": 39580561, "node_id": "MDQ6VXNlcjM5NTgwNTYx", "avatar_url": "https://avatars3.githubusercontent.com/u/39580561?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rakeshmothukuru1", "html_url": "https://github.com/rakeshmothukuru1", "followers_url": "https://api.github.com/users/rakeshmothukuru1/followers", "following_url": "https://api.github.com/users/rakeshmothukuru1/following{/other_user}", "gists_url": "https://api.github.com/users/rakeshmothukuru1/gists{/gist_id}", "starred_url": "https://api.github.com/users/rakeshmothukuru1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rakeshmothukuru1/subscriptions", "organizations_url": "https://api.github.com/users/rakeshmothukuru1/orgs", "repos_url": "https://api.github.com/users/rakeshmothukuru1/repos", "events_url": "https://api.github.com/users/rakeshmothukuru1/events{/privacy}", "received_events_url": "https://api.github.com/users/rakeshmothukuru1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-04-01T13:08:29Z", "updated_at": "2020-04-07T04:26:45Z", "closed_at": "2020-04-07T04:26:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "How can I use a tf.Transform analyzer variable within the preprocessing_fn of my TFX pipeline?\r\n\r\nI am using the `tft.max` function to compute the maximum value over the whole dataset, which is defined as an analyzer from looking at the source code. I want to use the result of this analyser in the following function call, but get the following error:\r\n\r\n**The transform function**:\r\n\r\n```\r\ndef preprocessing_fn(inputs):\r\n    outputs = {}\r\n    max_length = tft.max(inputs['MFCC_frame_count'], reduce_instance_dims=True)\r\n    outputs['MFCC_data'] = tft.sparse_tensor_to_dense_with_shape(\r\n        inputs['MFCC_data'],\r\n        [max_length, 26],\r\n        default_value=0\r\n    )\r\n    return outputs\r\n```\r\n**The Error:**\r\n`TypeError: Dimension value must be integer or None or have an __index__ method, got <tf.Tensor 'max/min_and_max/Placeholder_1:0' shape=() dtype=int64>\r\n`\r\nThis [Github Issue](https://github.com/tensorflow/tensorflow/issues/27519) looks similar but I couldn't find the solution there. \r\n\r\nThank you in advance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/168", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/168/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/168/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/168/events", "html_url": "https://github.com/tensorflow/transform/issues/168", "id": 585812782, "node_id": "MDU6SXNzdWU1ODU4MTI3ODI=", "number": 168, "title": "Type hint violation when the inputs to AnalyzeAndTransformDataset are tf tensors", "user": {"login": "sainathadapa", "id": 4915751, "node_id": "MDQ6VXNlcjQ5MTU3NTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/4915751?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sainathadapa", "html_url": "https://github.com/sainathadapa", "followers_url": "https://api.github.com/users/sainathadapa/followers", "following_url": "https://api.github.com/users/sainathadapa/following{/other_user}", "gists_url": "https://api.github.com/users/sainathadapa/gists{/gist_id}", "starred_url": "https://api.github.com/users/sainathadapa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sainathadapa/subscriptions", "organizations_url": "https://api.github.com/users/sainathadapa/orgs", "repos_url": "https://api.github.com/users/sainathadapa/repos", "events_url": "https://api.github.com/users/sainathadapa/events{/privacy}", "received_events_url": "https://api.github.com/users/sainathadapa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-03-22T21:09:28Z", "updated_at": "2020-03-25T15:58:05Z", "closed_at": "2020-03-25T15:58:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "From the guide (https://www.tensorflow.org/tfx/tutorials/transform/simple), I'm running the following piece of code:\r\n\r\n```\r\nwith tft_beam.Context(temp_dir=tempfile.mkdtemp()):\r\n    transformed_dataset, transform_fn = (  # pylint: disable=unused-variable\r\n        (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(\r\n            preprocessing_fn))\r\n```\r\n\r\nI changed the raw_data to contain some SparseTensor values. Then, I get the following error:\r\n\r\n```\r\nTypeCheckError: Type hint violation for 'ApplySavedModel': requires List[Dict[Any, Union[List[Any], bytes, float, generic, int, ndarray, str]]] but got List[Dict[str, SparseTensor]] for batch\r\n```\r\n\r\nShould the inputs to `AnalyzeAndTransformDataset` not be tf tensors?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/167", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/167/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/167/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/167/events", "html_url": "https://github.com/tensorflow/transform/issues/167", "id": 585789040, "node_id": "MDU6SXNzdWU1ODU3ODkwNDA=", "number": 167, "title": "Unit testing the preprocessing_fn", "user": {"login": "sainathadapa", "id": 4915751, "node_id": "MDQ6VXNlcjQ5MTU3NTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/4915751?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sainathadapa", "html_url": "https://github.com/sainathadapa", "followers_url": "https://api.github.com/users/sainathadapa/followers", "following_url": "https://api.github.com/users/sainathadapa/following{/other_user}", "gists_url": "https://api.github.com/users/sainathadapa/gists{/gist_id}", "starred_url": "https://api.github.com/users/sainathadapa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sainathadapa/subscriptions", "organizations_url": "https://api.github.com/users/sainathadapa/orgs", "repos_url": "https://api.github.com/users/sainathadapa/repos", "events_url": "https://api.github.com/users/sainathadapa/events{/privacy}", "received_events_url": "https://api.github.com/users/sainathadapa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2020-03-22T19:05:55Z", "updated_at": "2020-03-25T15:58:15Z", "closed_at": "2020-03-25T15:58:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Can you provide some examples that illustrate the way to unit test the preprocessing functions?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/165", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/165/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/165/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/165/events", "html_url": "https://github.com/tensorflow/transform/issues/165", "id": 577216960, "node_id": "MDU6SXNzdWU1NzcyMTY5NjA=", "number": 165, "title": "Scalar value in tf.string VarLenFeature breaks into each character.", "user": {"login": "ucdmkt", "id": 3142598, "node_id": "MDQ6VXNlcjMxNDI1OTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/3142598?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ucdmkt", "html_url": "https://github.com/ucdmkt", "followers_url": "https://api.github.com/users/ucdmkt/followers", "following_url": "https://api.github.com/users/ucdmkt/following{/other_user}", "gists_url": "https://api.github.com/users/ucdmkt/gists{/gist_id}", "starred_url": "https://api.github.com/users/ucdmkt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ucdmkt/subscriptions", "organizations_url": "https://api.github.com/users/ucdmkt/orgs", "repos_url": "https://api.github.com/users/ucdmkt/repos", "events_url": "https://api.github.com/users/ucdmkt/events{/privacy}", "received_events_url": "https://api.github.com/users/ucdmkt/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-03-06T22:50:45Z", "updated_at": "2020-03-09T16:38:57Z", "closed_at": "2020-03-09T16:38:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Problem reported in https://stackoverflow.com/questions/59864588/feeding-nullable-data-from-bigquery-into-tensorflow-transform\r\n\r\nBrief reproduction is as follows.\r\n\r\n```\r\nsource_query = \"\"\"\r\n    SELECT company FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips` \r\n\"\"\"\r\n\r\nraw_metadata = dataset_metadata.DatasetMetadata(\r\n    schema_utils.schema_from_feature_spec(\r\n        { 'company': tf.io.VarLenFeature(tf.string) }\r\n    )\r\n)\r\n\r\ndef preprocessing_fn(inputs):\r\n    outputs = inputs.copy()\r\n    # pass through\r\n    return outputs\r\n\r\nwith beam.Pipeline(options=options) as pipeline:\r\n    with tft_beam.impl.Context(temp_dir=tempfile.mkdtemp()):\r\n        raw_data = (pipeline\r\n              | 'read_from_bq' >> beam.io.Read(\r\n                  beam.io.BigQuerySource(query=source_query,\r\n                                         use_standard_sql=True,\r\n                                         project='...'\r\n                                          ))\r\n                )\r\n        (transformed_examples, transformed_metadata), transform_fn = (\r\n            (raw_data, raw_metadata) \r\n            | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)\r\n        )\r\n          \r\n        encoder = tft.coders.ExampleProtoCoder(transformed_metadata.schema)\r\n        (transformed_examples\r\n         | 'EncodeTrainData' >> beam.Map(encoder.encode)\r\n         | 'WriteTrainData' >> beam.io.WriteToTFRecord(\r\n             os.path.join('transformed_examples.gz'),\r\n             coder=beam.coders.BytesCoder()))\r\n```\r\n\r\n```\r\nfor example in tf.compat.v1.python_io.tf_record_iterator(\r\n    os.path.join('transformed_examples.gz-00000-of-00001'),\r\n    tf.io.TFRecordOptions(compression_type='GZIP')\r\n):\r\n    print(tf.train.Example.FromString(example))\r\n```\r\n\r\nIt would yield records like below.\r\n\r\n```\r\nfeatures {\r\n  feature {\r\n    key: \"company\"\r\n    value {\r\n      bytes_list {\r\n        value: \"S\"\r\n        value: \"u\"\r\n        value: \"n\"\r\n        value: \" \"\r\n        value: \"T\"\r\n        value: \"a\"\r\n        value: \"x\"\r\n        value: \"i\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nExpected result is \r\n\r\n```\r\nfeatures {\r\n  feature {\r\n    key: \"company\"\r\n    value {\r\n      bytes_list {\r\n        value: \"Sun Taxi\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/162", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/162/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/162/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/162/events", "html_url": "https://github.com/tensorflow/transform/issues/162", "id": 568103840, "node_id": "MDU6SXNzdWU1NjgxMDM4NDA=", "number": 162, "title": "Is there any example of nlp, like text classification? string input, not other data preprocess outside.", "user": {"login": "yongzhuo", "id": 31341349, "node_id": "MDQ6VXNlcjMxMzQxMzQ5", "avatar_url": "https://avatars3.githubusercontent.com/u/31341349?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yongzhuo", "html_url": "https://github.com/yongzhuo", "followers_url": "https://api.github.com/users/yongzhuo/followers", "following_url": "https://api.github.com/users/yongzhuo/following{/other_user}", "gists_url": "https://api.github.com/users/yongzhuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/yongzhuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yongzhuo/subscriptions", "organizations_url": "https://api.github.com/users/yongzhuo/orgs", "repos_url": "https://api.github.com/users/yongzhuo/repos", "events_url": "https://api.github.com/users/yongzhuo/events{/privacy}", "received_events_url": "https://api.github.com/users/yongzhuo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101994909, "node_id": "MDU6TGFiZWwxMTAxOTk0OTA5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2020-02-20T07:27:34Z", "updated_at": "2020-03-26T11:08:33Z", "closed_at": "2020-03-26T11:08:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there any example of nlp, like text classification? string input, not other data preprocess outside.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/159", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/159/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/159/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/159/events", "html_url": "https://github.com/tensorflow/transform/issues/159", "id": 564192014, "node_id": "MDU6SXNzdWU1NjQxOTIwMTQ=", "number": 159, "title": "(tft/beam Outdated) AnalyzeAndTransformDataset Creates Extra Rows Within Preproc Function", "user": {"login": "luischinchillagarcia", "id": 50338632, "node_id": "MDQ6VXNlcjUwMzM4NjMy", "avatar_url": "https://avatars3.githubusercontent.com/u/50338632?v=4", "gravatar_id": "", "url": "https://api.github.com/users/luischinchillagarcia", "html_url": "https://github.com/luischinchillagarcia", "followers_url": "https://api.github.com/users/luischinchillagarcia/followers", "following_url": "https://api.github.com/users/luischinchillagarcia/following{/other_user}", "gists_url": "https://api.github.com/users/luischinchillagarcia/gists{/gist_id}", "starred_url": "https://api.github.com/users/luischinchillagarcia/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/luischinchillagarcia/subscriptions", "organizations_url": "https://api.github.com/users/luischinchillagarcia/orgs", "repos_url": "https://api.github.com/users/luischinchillagarcia/repos", "events_url": "https://api.github.com/users/luischinchillagarcia/events{/privacy}", "received_events_url": "https://api.github.com/users/luischinchillagarcia/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2020-02-12T18:41:40Z", "updated_at": "2020-05-28T23:18:38Z", "closed_at": "2020-05-28T23:18:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "In the following example which uses TF Hub to change text to vectors [found here](https://cloud.google.com/solutions/machine-learning/analyzing-text-semantic-similarity-using-tensorflow-and-cloud-dataflow), it uses a function `preproc_fn` in AnalyzeAndTransformDataset(preproc_fn) to split a string into an array of elements[str], change them to vectors, then reduce_mean them into a single output.\r\n\r\nHowever, during the step of splitting a string into an array of elements, it immediately just creates new rows with each element rather than having the intended array. This seems to point to an unintended consequence of how beam used to work since the example above states the preproc_fn should create an array of items within the function->change them to vectors->concatenate them back into a single vector, then output that vector within that function; you cannot reduce_mean (or any operations) across rows. \r\n\r\nMy reasoning for this is that FlatMap (below) behaves in this same manner as AnalyzeAndTransformDataset; as soon as the function encounters any kind of function that outputs a list rather than a single value, it separates them into new rows. Is there any way to make AnalyzeAndTransformDataset work like Map instead of FlatMap? It may also be that this is occurring because tft is outdated relative to new versions of beam.\r\n\r\nNote: Both impl.AnalyzeAndTransformDataset and tft_beam.AnalyzeAndTransformDataset seem to behave the same.\r\n\r\n```python \r\ndef _split(row):\r\n    row = row.split(' ')\r\n    row = ' '.join(row)\r\n    return row\r\n\r\nwith beam.Pipeline() as pipeline:\r\n  plants = (\r\n      pipeline\r\n      | 'input_text' >> beam.Create([\r\n          \"This is a random sentence\",\r\n      ])\r\n      | 'Transform' >> beam.FlatMap(_split)\r\n      | 'Writeout' >> beam.io.WriteOut('fruits', '.txt')\r\n      )\r\n\r\n>> \"This\"\r\n>> \"is\"\r\n>> \"a\"\r\n...\r\n>> \"sentence\"\r\n```\r\n\r\n```python \r\n...\r\n      | 'Transform' >> beam.Map(_split)\r\n      | 'Writeout' >> beam.io.WriteOut('fruits', '.txt')\r\n      )\r\n\r\n>> [\"This is a random sentence\"]\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/157", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/157/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/157/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/157/events", "html_url": "https://github.com/tensorflow/transform/issues/157", "id": 559964048, "node_id": "MDU6SXNzdWU1NTk5NjQwNDg=", "number": 157, "title": "Cannot initialize lookup table in preprocessing_fn", "user": {"login": "JakeTheWise", "id": 13136287, "node_id": "MDQ6VXNlcjEzMTM2Mjg3", "avatar_url": "https://avatars2.githubusercontent.com/u/13136287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JakeTheWise", "html_url": "https://github.com/JakeTheWise", "followers_url": "https://api.github.com/users/JakeTheWise/followers", "following_url": "https://api.github.com/users/JakeTheWise/following{/other_user}", "gists_url": "https://api.github.com/users/JakeTheWise/gists{/gist_id}", "starred_url": "https://api.github.com/users/JakeTheWise/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JakeTheWise/subscriptions", "organizations_url": "https://api.github.com/users/JakeTheWise/orgs", "repos_url": "https://api.github.com/users/JakeTheWise/repos", "events_url": "https://api.github.com/users/JakeTheWise/events{/privacy}", "received_events_url": "https://api.github.com/users/JakeTheWise/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-04T20:35:52Z", "updated_at": "2020-02-04T21:11:48Z", "closed_at": "2020-02-04T21:11:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a preprocessing function that calculates sample weights like so:\r\n```python\r\ndef balanced_sample_weight(t: tf.Tensor, ) -> tf.Tensor:\r\n    vocab, counts = tft.count_per_key(t)\r\n    n_samples = tft.size(t)\r\n    n_classes = tf.shape(vocab)[0]\r\n    class_weights = tf.math.divide(n_samples, tf.math.multiply(tf.cast(n_classes, tf.int64), counts)) # n_samples / (n_classes * np.bincount(y))\r\n    table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys=vocab, values=tf.cast(class_weights, tf.float32)), default_value=0)\r\n    return table.lookup(t)\r\n```\r\nThis is used in my `preprocessing_fn`:\r\n```python\r\ndef preprocessing_fn(inputs: dict) -> dict:\r\n    return {\r\n        'x': ...,\r\n        'label': inputs['label'],\r\n        'sample_weight': balanced_sample_weight(tf.squeeze(inputs['label'], axis=-1))\r\n    }\r\n```\r\n\r\nHowever, this breaks calls to `TFTOutput.transform_raw_features(x, drop_unused_features=True)` down the line because the lookup table maintains a graph dependency on the `label`. How can I compute sample weights with tf-transform the right way?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/156", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/156/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/156/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/156/events", "html_url": "https://github.com/tensorflow/transform/issues/156", "id": 557654093, "node_id": "MDU6SXNzdWU1NTc2NTQwOTM=", "number": 156, "title": "Example export using build_raw_serving_input_receiver_fn", "user": {"login": "JakeTheWise", "id": 13136287, "node_id": "MDQ6VXNlcjEzMTM2Mjg3", "avatar_url": "https://avatars2.githubusercontent.com/u/13136287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JakeTheWise", "html_url": "https://github.com/JakeTheWise", "followers_url": "https://api.github.com/users/JakeTheWise/followers", "following_url": "https://api.github.com/users/JakeTheWise/following{/other_user}", "gists_url": "https://api.github.com/users/JakeTheWise/gists{/gist_id}", "starred_url": "https://api.github.com/users/JakeTheWise/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JakeTheWise/subscriptions", "organizations_url": "https://api.github.com/users/JakeTheWise/orgs", "repos_url": "https://api.github.com/users/JakeTheWise/repos", "events_url": "https://api.github.com/users/JakeTheWise/events{/privacy}", "received_events_url": "https://api.github.com/users/JakeTheWise/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-01-30T17:49:02Z", "updated_at": "2020-03-06T15:26:21Z", "closed_at": "2020-01-30T17:58:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "All the export examples use`build_parsing_serving_input_receiver_fn`. Is there a best practice for using `build_raw_serving_input_receiver_fn`? Since `tf.placeholder` is deprecated, the only thing I've found that works to specify the receiver tensors is `tf.keras.Input`...\r\n```python\r\ndef build_serving_input_receiver_fn(tft_output, raw_feature_spec):\r\n        def serving_input_fn():\r\n            raw_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({k: tf.keras.Input(name=k, shape=v.shape, dtype=v.dtype) for k, v in raw_feature_spec.items() if k in feature_keys}, default_batch_size=None)\r\n            serving_input_receiver = raw_input_fn()\r\n            raw_features = serving_input_receiver.features\r\n            transformed_features = tft_output.transform_raw_features(raw_features, True)\r\n            return tf.estimator.export.ServingInputReceiver(transformed_features, serving_input_receiver.receiver_tensors)\r\n        return serving_input_fn\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/154", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/154/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/154/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/154/events", "html_url": "https://github.com/tensorflow/transform/issues/154", "id": 553177534, "node_id": "MDU6SXNzdWU1NTMxNzc1MzQ=", "number": 154, "title": "scale_to_z_score_per_key with elementwise=True", "user": {"login": "K-Niu", "id": 6972205, "node_id": "MDQ6VXNlcjY5NzIyMDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/6972205?v=4", "gravatar_id": "", "url": "https://api.github.com/users/K-Niu", "html_url": "https://github.com/K-Niu", "followers_url": "https://api.github.com/users/K-Niu/followers", "following_url": "https://api.github.com/users/K-Niu/following{/other_user}", "gists_url": "https://api.github.com/users/K-Niu/gists{/gist_id}", "starred_url": "https://api.github.com/users/K-Niu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/K-Niu/subscriptions", "organizations_url": "https://api.github.com/users/K-Niu/orgs", "repos_url": "https://api.github.com/users/K-Niu/repos", "events_url": "https://api.github.com/users/K-Niu/events{/privacy}", "received_events_url": "https://api.github.com/users/K-Niu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-01-21T22:25:41Z", "updated_at": "2020-01-27T16:11:26Z", "closed_at": "2020-01-27T16:11:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've noticed that trying to use `tft.scale_to_z_score_per_key` with `elementwise=True` raises:\r\n```\r\nNotImplementedError: Per-key elementwise reduction not supported\r\n```\r\n\r\nI have a vector field in my data that can be missing (and a missing indicator field), and I would like to scale only the non-missing part of the data using my `preprocessing_fn`. \r\n\r\n---\r\nThis is my input spec:\r\n```\r\nINPUT_FEATURE_SPEC = {\r\n        \"vector\": tf.io.FixedLenFeature([300], tf.float32), # 300 dimensional vector that is all 0's when missing\r\n        \"vector_missing\": tf.io.FixedLenFeature([], tf.int64), # 1 if vector is missing else 0\r\n}\r\n```\r\n\r\nand I would like to do something like:\r\n```\r\ndef preprocessing_fn(input):\r\n    vector_missing = tf.map_fn(\r\n        lambda x: tf.cond(tf.equal(x, 1), lambda: \"yes\", lambda: \"no\"),\r\n        input[\"vector_missing\"],\r\n        dtype=tf.string\r\n    )\r\n    # Use per_key version to exclude missing vectors in calculation of mean and std\r\n    vector_scaled = tft.scale_to_z_score_per_key(input[\"vector\"], key=vector_missing, elementwise=True)\r\n\r\n    output = {\r\n        \"vector\": vector_scaled,\r\n        \"vector_missing\": input[\"vector_missing\"],\r\n    }\r\n\r\n    return output\r\n```\r\n\r\nIs there anyway around this?\r\n\r\n---\r\nI've tried something like this:\r\n```\r\ndef preprocessing_fn(input):\r\n    vector_missing = tf.map_fn(\r\n        lambda x: tf.cond(tf.equal(x, 1), lambda: \"yes\", lambda: \"no\"),\r\n        input[\"vector_missing\"],\r\n        dtype=tf.string\r\n    )\r\n\r\n    # Try to apply scale_to_z_score_per_key with elementwise=False to each element of each vector\r\n    vector_scaled = tf.transpose(\r\n        tf.map_fn(\r\n            lambda i: tft.scale_to_z_score_per_key(input[\"vector\"][:, i], key=vector_missing, elementwise=False),\r\n            tf.range(300),\r\n            dtype=tf.float32\r\n        ),\r\n    )\r\n\r\n    output = {\r\n        \"vector\": vector_scaled,\r\n        \"vector_missing\": input[\"vector_missing\"]\r\n    }\r\n\r\n    return output\r\n```\r\nbut I get the following error:\r\n```\r\nValueError: The tensor_or_op Tensor(\"scale_to_z_score_per_key/mean_and_var_per_key/UniqueWithCounts:0\", shape=(None,), dtype=string) depended on a placeholder (Tensor(\"scale_to_z_score_per_key/mean_and_var_per_key/UniqueWithCounts/map/TensorArrayV2Stack/TensorListStack:0\", shape=(None,), dtype=string)) that was not in the input_signature.  This may have be caused by manually adding a placeholder to the graph\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/152", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/152/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/152/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/152/events", "html_url": "https://github.com/tensorflow/transform/issues/152", "id": 539573356, "node_id": "MDU6SXNzdWU1Mzk1NzMzNTY=", "number": 152, "title": "Unable to impute missing values with the mean using tf.Transform", "user": {"login": "thisisandreeeee", "id": 11587285, "node_id": "MDQ6VXNlcjExNTg3Mjg1", "avatar_url": "https://avatars2.githubusercontent.com/u/11587285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thisisandreeeee", "html_url": "https://github.com/thisisandreeeee", "followers_url": "https://api.github.com/users/thisisandreeeee/followers", "following_url": "https://api.github.com/users/thisisandreeeee/following{/other_user}", "gists_url": "https://api.github.com/users/thisisandreeeee/gists{/gist_id}", "starred_url": "https://api.github.com/users/thisisandreeeee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thisisandreeeee/subscriptions", "organizations_url": "https://api.github.com/users/thisisandreeeee/orgs", "repos_url": "https://api.github.com/users/thisisandreeeee/repos", "events_url": "https://api.github.com/users/thisisandreeeee/events{/privacy}", "received_events_url": "https://api.github.com/users/thisisandreeeee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2019-12-18T09:55:10Z", "updated_at": "2020-02-04T22:54:52Z", "closed_at": "2019-12-22T07:12:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.14.106+-x86_64-with-debian-buster-sid\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.6\r\n\r\n**Describe the current behavior**\r\nI am trying to impute the missing values in a tensor with the sample mean. As the size of my dataset is potentially quite large and the calculation of means require a full pass of the dataset, I am using tf.Transform to perform this computation.\r\n\r\nAs there is no native support for imputation on tf.Transform, I am implementing this by creating a `SparseTensor`, and specifying a default_value when converting to a dense tensor (as suggested by @KesterTong in https://github.com/tensorflow/transform/issues/78#issuecomment-427919062).\r\n\r\nHowever, this does not seem to be successful as the output tensor still contains `nan`.\r\n\r\n**Describe the expected behavior**\r\nI expect the missing values in the output tensor to be replaced by the mean of the non-null values.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tempfile\r\nfrom glob import glob\r\n\r\nimport apache_beam as beam\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nimport tensorflow_transform as tft\r\nimport tensorflow_transform.beam as tft_beam\r\nfrom tensorflow_transform.tf_metadata import dataset_metadata, schema_utils\r\n\r\nassert tf.__version__ == \"2.0.0\" and tft.__version__ == \"0.15.0\" and beam.__version__ == \"2.16.0\"\r\n\r\ndef create_raw_data(output_file):\r\n    df = pd.DataFrame({\"age\": [35.2, 17.3, None, 25.0]})\r\n    with tf.io.TFRecordWriter(output_file) as writer:\r\n        for _, row in df.iterrows():\r\n            features = tf.train.Features(\r\n                feature={\"age\": tf.train.Feature(float_list=tf.train.FloatList(value=[row]))}\r\n            )\r\n            example_proto = tf.train.Example(features=features)\r\n            writer.write(example_proto.SerializeToString())\r\n\r\n            \r\ndef run_tftransform(input_file, output_file):\r\n    def preprocessing_fn(inputs):\r\n        def _impute(tensor, replacement):\r\n            sparse = tf.sparse.SparseTensor(\r\n                tensor.indices, tensor.values, [tensor.dense_shape[0], 1]\r\n            )\r\n            dense = tf.sparse.to_dense(sp_input=sparse, default_value=replacement)\r\n            dense = tf.squeeze(dense, axis=1)\r\n            return dense\r\n\r\n        outputs = inputs.copy()\r\n        mean_age = tft.mean(outputs[\"age\"])\r\n        outputs[\"age\"] = _impute(outputs[\"age\"], mean_age)  # mean is 25.833333333\r\n        return outputs\r\n\r\n    RAW_DATA_FEATURE_SPEC = {\"age\": tf.io.VarLenFeature(tf.float32)}\r\n    RAW_DATA_METADATA = dataset_metadata.DatasetMetadata(\r\n        schema_utils.schema_from_feature_spec(RAW_DATA_FEATURE_SPEC)\r\n    )\r\n\r\n    with beam.Pipeline() as pipeline:\r\n        with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\r\n            raw_data_coder = tft.coders.ExampleProtoCoder(RAW_DATA_METADATA.schema)\r\n            raw_train_data = (\r\n                pipeline | beam.io.ReadFromTFRecord(input_file, coder=raw_data_coder)\r\n            )\r\n            (transformed_train_data, transformed_metadata), transform_fn = (\r\n                (raw_train_data, RAW_DATA_METADATA)| tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)\r\n            )\r\n            transformed_data_coder = tft.coders.ExampleProtoCoder(transformed_metadata.schema)\r\n            _ = (\r\n                transformed_train_data| beam.io.WriteToTFRecord(\r\n                    output_file, coder=transformed_data_coder\r\n                )\r\n            )\r\n            \r\n            \r\nif __name__ == \"__main__\":\r\n    create_raw_data(\"raw_data.tfrecord\")\r\n    run_tftransform(\"raw_data.tfrecord\", \"transformed_data.tfrecord\")\r\n\r\n    TRANSFORMED_FEATURE_SPEC = {\"age\": tf.io.FixedLenFeature([], tf.float32)}\r\n    raw_dataset = tf.data.TFRecordDataset(filenames=glob(\"transformed_data.tfrecord*\"))\r\n    parsed_dataset = raw_dataset.map(lambda x: tf.io.parse_single_example(x, TRANSFORMED_FEATURE_SPEC)).batch(4)\r\n\r\n    print(next(iter(parsed_dataset.take(1))))\r\n```\r\n\r\nExpected output:\r\n```python\r\n{'age': <tf.Tensor: id=533, shape=(4,), dtype=float32, numpy=array([35.2, 17.3,  25.8333, 25. ], dtype=float32)>}\r\n```\r\nActual (incorrect) output which still contains `nan` values:\r\n```python\r\n{'age': <tf.Tensor: id=533, shape=(4,), dtype=float32, numpy=array([35.2, 17.3,  nan, 25. ], dtype=float32)>}\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/151", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/151/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/151/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/151/events", "html_url": "https://github.com/tensorflow/transform/issues/151", "id": 523699435, "node_id": "MDU6SXNzdWU1MjM2OTk0MzU=", "number": 151, "title": "Adapting census_example_v2 for different shaped input features", "user": {"login": "K-Niu", "id": 6972205, "node_id": "MDQ6VXNlcjY5NzIyMDU=", "avatar_url": "https://avatars3.githubusercontent.com/u/6972205?v=4", "gravatar_id": "", "url": "https://api.github.com/users/K-Niu", "html_url": "https://github.com/K-Niu", "followers_url": "https://api.github.com/users/K-Niu/followers", "following_url": "https://api.github.com/users/K-Niu/following{/other_user}", "gists_url": "https://api.github.com/users/K-Niu/gists{/gist_id}", "starred_url": "https://api.github.com/users/K-Niu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/K-Niu/subscriptions", "organizations_url": "https://api.github.com/users/K-Niu/orgs", "repos_url": "https://api.github.com/users/K-Niu/repos", "events_url": "https://api.github.com/users/K-Niu/events{/privacy}", "received_events_url": "https://api.github.com/users/K-Niu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2019-11-15T21:34:34Z", "updated_at": "2020-01-06T16:40:24Z", "closed_at": "2019-11-25T15:07:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to train adapt `examples/census_example_v2.py` to train an autoencoder using an estimator from keras. I am wondering how to structure the input to a keras model if some of my inputs of different shape.\r\n\r\nMy output feature spec for the tfrecords from a tf transform job looks something like\r\n```\r\nFEATURE_SPEC = {\r\n    'numerical_feature_A': tf.io.FixedLenFeature(shape=[], tf.float32),\r\n    'numerical_feature_B': tf.io.FixedLenFeature(shape=[], tf.float32),\r\n    'vector_feature_C': tf.io.FixedLenFeature(shape=[300], tf.float32), \r\n    'vector_feature_D': tf.io.FixedLenFeature(shape=[768], tf.float32), \r\n}\r\n```\r\n\r\nI've tried using `tf.feature_column` (like in `census_example`) and also `tf.keras.Input` (like in `census_example_v2`).\r\n\r\nWith `tf.feature_column`:\r\n```\r\ndef model_fn(run_config):\r\n    feature_columns = [\r\n        tf.feature_column.numeric_column(\"numerical_feature_A\", shape=()),\r\n        tf.feature_column.numeric_column(\"numerical_feature_B\", shape=()),\r\n        tf.feature_column.numeric_column(\"vector_feature_C\", shape=(300,)),\r\n        tf.feature_column.numeric_column(\"vector_feature_D\", shape=(768,)),\r\n    ]\r\n    \r\n    autoencoder = tf.keras.Sequential()\r\n    autoencoder.add(tf.keras.layers.DenseFeatures(feature_columns))\r\n    # Encoder\r\n    autoencoder.add(tf.keras.layers.Dense(512, activation=\"relu\"))\r\n    autoencoder.add(tf.keras.layers.Dense(256, activation=\"relu\"))\r\n    autoencoder.add(tf.keras.layers.Dense(128, activation=\"relu\"))\r\n    # Decoder\r\n    autoencoder.add(tf.keras.layers.Dense(256, activation=\"relu\"))\r\n    autoencoder.add(tf.keras.layers.Dense(512, activation=\"relu\"))\r\n    autoencoder.add(\r\n        tf.keras.layers.Dense(1070, activation=\"relu\")\r\n    )\r\n    \r\n    autoencoder.compile(\r\n        optimizer=tf.keras.optimizers.Adam(),\r\n        loss=tf.keras.losses.MeanSquaredError(),\r\n        metrics=[\"mse\"],\r\n    )\r\n\r\n    return tf.keras.estimator.model_to_estimator(\r\n        keras_model=autoencoder, config=run_config\r\n    )\r\n```\r\nDuring training, I get an error like:\r\n```\r\nKeyError: \"The dictionary passed into features does not have the expected inputs keys defined in the keras model.\\n\\tExpected keys: {'input_1', input_2', 'input_3', 'input_4'}\\n\\tfeatures keys: {'numerical_feature_A', 'numerical_feature_B', 'vector_feature_C', 'vector_feature_D'}\\n\\tDifference: {'input_1', input_2', 'input_3', 'input_4', 'numerical_feature_A', 'numerical_feature_B', 'vector_feature_C', 'vector_feature_D'}\"\r\n```\r\n\r\nWith `tf.keras.Input`, `stacked_inputs = tf.stack(list(inputs.values()), axis=-1)`  doesn't work because the size of the inputs are different:\r\n```\r\ndef model_fn(run_config):\r\n    inputs = {\r\n        \"numerical_feature_A\": tf.keras.layers.Input(shape=(1,), name=\"numerical_feature_A\"),\r\n        \"numerical_feature_B\": tf.keras.layers.Input(shape=(1,), name=\"numerical_feature_B\"),\r\n        \"vector_feature_C\": tf.keras.layers.Input(shape=(300,), name=\"vector_feature_C\"),\r\n        \"vector_feature_D\": tf.keras.layers.Input(shape=(768,), name=\"vector_feature_D\")\r\n    }\r\n    stacked_inputs = tf.stack(list(inputs.values()), axis=-1) # Doesn't work because of mismatched size\r\n    encoder = tf.keras.layers.Dense(512, activation=\"relu\")(stacked_inputs)\r\n    encoder = tf.keras.layers.Dense(256, activation=\"relu\")(encoder)\r\n    encoder = tf.keras.layers.Dense(128, activation=\"relu\")(encoder)\r\n    decoder = tf.keras.layers.Dense(256, activation=\"relu\")(encoder)\r\n    decoder = tf.keras.layers.Dense(512, activation=\"relu\")(decoder)\r\n    decoder = tf.keras.layers.Dense(1070, activation=\"relu\")(decoder)\r\n\r\n    autoencoder = tf.keras.Model(inputs=inputs, outputs=decoder)\r\n\r\n    autoencoder.compile(\r\n        optimizer=tf.keras.optimizers.Adam(),\r\n        loss=tf.keras.losses.MeanSquaredError(),\r\n        metrics=[\"mse\"],\r\n    )\r\n\r\n    return tf.keras.estimator.model_to_estimator(\r\n        keras_model=autoencoder, config=run_config\r\n    )\r\n```\r\n\r\nAlso wondering which of the two methods above is better practice to use. Thanks!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/148", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/148/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/148/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/148/events", "html_url": "https://github.com/tensorflow/transform/issues/148", "id": 520507100, "node_id": "MDU6SXNzdWU1MjA1MDcxMDA=", "number": 148, "title": "tft.tfidf does not work with tensorflow v2.0", "user": {"login": "wolfiex", "id": 15582577, "node_id": "MDQ6VXNlcjE1NTgyNTc3", "avatar_url": "https://avatars3.githubusercontent.com/u/15582577?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wolfiex", "html_url": "https://github.com/wolfiex", "followers_url": "https://api.github.com/users/wolfiex/followers", "following_url": "https://api.github.com/users/wolfiex/following{/other_user}", "gists_url": "https://api.github.com/users/wolfiex/gists{/gist_id}", "starred_url": "https://api.github.com/users/wolfiex/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wolfiex/subscriptions", "organizations_url": "https://api.github.com/users/wolfiex/orgs", "repos_url": "https://api.github.com/users/wolfiex/repos", "events_url": "https://api.github.com/users/wolfiex/events{/privacy}", "received_events_url": "https://api.github.com/users/wolfiex/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2019-11-09T20:08:29Z", "updated_at": "2019-11-15T11:07:37Z", "closed_at": "2019-11-15T11:05:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\n   2626   if context.executing_eagerly():\r\n-> 2627     raise RuntimeError(\"tf.placeholder() is not compatible with \"\r\n   2628                        \"eager execution.\")\r\n   2629 \r\n\r\nRuntimeError: tf.placeholder() is not compatible with eager execution.\r\n```\r\nWhen using eager evaluation, but asking for a feed value placeholder without : \r\n`InvalidArgumentError: You must feed value for placeholder tensor 'tfidf/sum/Placeholder' with dtype double and shape `", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/147", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/147/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/147/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/147/events", "html_url": "https://github.com/tensorflow/transform/issues/147", "id": 519432279, "node_id": "MDU6SXNzdWU1MTk0MzIyNzk=", "number": 147, "title": "transform raw categorical features using custom mapping function", "user": {"login": "rahulrajpl", "id": 279503, "node_id": "MDQ6VXNlcjI3OTUwMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/279503?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rahulrajpl", "html_url": "https://github.com/rahulrajpl", "followers_url": "https://api.github.com/users/rahulrajpl/followers", "following_url": "https://api.github.com/users/rahulrajpl/following{/other_user}", "gists_url": "https://api.github.com/users/rahulrajpl/gists{/gist_id}", "starred_url": "https://api.github.com/users/rahulrajpl/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rahulrajpl/subscriptions", "organizations_url": "https://api.github.com/users/rahulrajpl/orgs", "repos_url": "https://api.github.com/users/rahulrajpl/repos", "events_url": "https://api.github.com/users/rahulrajpl/events{/privacy}", "received_events_url": "https://api.github.com/users/rahulrajpl/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-11-07T18:17:33Z", "updated_at": "2020-05-30T13:47:02Z", "closed_at": "2019-11-09T03:31:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, \r\n\r\nAs I understand from the documentation [here](https://www.tensorflow.org/tfx/transform/get_started), I can have a call like `tft.compute_and_apply_vocabulary(s)` in order to convert a categorical column to numerical feature.\r\n\r\nAs a beginner in tensorflow, I am wondering if there exists a custom mapping of raw feature column to a numerical column? I have already seen that hash_bucket method described [here](https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_hash_bucket) almost does the job I want. But instead of hash of the entries, I need a **custom mapping function** to be called so that 'm' unique elements in the categorical column is mapped to 'n' unique elements of numerical or string, where n < m.\r\n\r\n**Use case.** I bumped into this issue during my experiment with the KDD CUP 99 dataset where target class of training set contains 23 different attack types where they are required to be identified and categorized into four class of attacks. If there is a transformation function I could use so that all 23 unique elements in target class could be mapped to 4 classes of attack numbered [1,2,3,4]. Including a normal connection that could be mapped to [0], the target class will contain 5 classes and thus I can directly train a multiclass classification model. More on KDD CUP 99 dataset is [here](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)\r\n\r\nCan anyone help?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/145", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/145/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/145/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/145/events", "html_url": "https://github.com/tensorflow/transform/issues/145", "id": 516111103, "node_id": "MDU6SXNzdWU1MTYxMTExMDM=", "number": 145, "title": "tft.compute_sample_weight()?", "user": {"login": "JakeTheWise", "id": 13136287, "node_id": "MDQ6VXNlcjEzMTM2Mjg3", "avatar_url": "https://avatars2.githubusercontent.com/u/13136287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JakeTheWise", "html_url": "https://github.com/JakeTheWise", "followers_url": "https://api.github.com/users/JakeTheWise/followers", "following_url": "https://api.github.com/users/JakeTheWise/following{/other_user}", "gists_url": "https://api.github.com/users/JakeTheWise/gists{/gist_id}", "starred_url": "https://api.github.com/users/JakeTheWise/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JakeTheWise/subscriptions", "organizations_url": "https://api.github.com/users/JakeTheWise/orgs", "repos_url": "https://api.github.com/users/JakeTheWise/repos", "events_url": "https://api.github.com/users/JakeTheWise/events{/privacy}", "received_events_url": "https://api.github.com/users/JakeTheWise/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2019-11-01T13:26:27Z", "updated_at": "2020-01-30T15:35:27Z", "closed_at": "2020-01-30T14:42:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "Sample or class weighting for imbalanced classification tasks requires a full pass over the training labels. It's a \"temporary\" transformation that will be thrown out after training, but would it make sense to implement this in tft?\r\n\r\nCould I accomplish this with `sample_weights = tft.size(labels) / (n_classes * tf.unique_with_counts(labels)[2])`?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/142", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/142/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/142/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/142/events", "html_url": "https://github.com/tensorflow/transform/issues/142", "id": 504431687, "node_id": "MDU6SXNzdWU1MDQ0MzE2ODc=", "number": 142, "title": "tensorflow_transform.vocabulary() returns vocabulary files with dummy values for all categorical variables transformed", "user": {"login": "junbopark", "id": 49727418, "node_id": "MDQ6VXNlcjQ5NzI3NDE4", "avatar_url": "https://avatars3.githubusercontent.com/u/49727418?v=4", "gravatar_id": "", "url": "https://api.github.com/users/junbopark", "html_url": "https://github.com/junbopark", "followers_url": "https://api.github.com/users/junbopark/followers", "following_url": "https://api.github.com/users/junbopark/following{/other_user}", "gists_url": "https://api.github.com/users/junbopark/gists{/gist_id}", "starred_url": "https://api.github.com/users/junbopark/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/junbopark/subscriptions", "organizations_url": "https://api.github.com/users/junbopark/orgs", "repos_url": "https://api.github.com/users/junbopark/repos", "events_url": "https://api.github.com/users/junbopark/events{/privacy}", "received_events_url": "https://api.github.com/users/junbopark/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-10-09T05:54:10Z", "updated_at": "2019-10-11T07:41:06Z", "closed_at": "2019-10-11T07:41:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was using the census example as the template for my code, and found that sometimes all the entries for transform_fn/asset/(some categorical variable) are \"49d0cd50-04bb-48c0-bc6f-5b575dce351a\"\r\n\r\nI found from the repo that's actually a dummy value  [(link to the code from tensorflow-transform repo specifying this behavior)](https://github.com/tensorflow/transform/blob/master/tensorflow_transform/beam/analyzer_impls.py#L78).\r\n\r\nUnder what condition is this usually triggered? I have about ~60 categorical variables in my example, and when I transform several of them the work fine. When I try to transform all of them, all categorical variables are basically \"transformed\" to that dummy variable.\r\n\r\nI thought that if there was a problem with the input for some reason, that feature would fail and return the dummy constant but the rest would transform properly.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/141", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/141/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/141/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/141/events", "html_url": "https://github.com/tensorflow/transform/issues/141", "id": 503137222, "node_id": "MDU6SXNzdWU1MDMxMzcyMjI=", "number": 141, "title": "Support for TF 2.0", "user": {"login": "maxzoech", "id": 8182914, "node_id": "MDQ6VXNlcjgxODI5MTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/8182914?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxzoech", "html_url": "https://github.com/maxzoech", "followers_url": "https://api.github.com/users/maxzoech/followers", "following_url": "https://api.github.com/users/maxzoech/following{/other_user}", "gists_url": "https://api.github.com/users/maxzoech/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxzoech/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxzoech/subscriptions", "organizations_url": "https://api.github.com/users/maxzoech/orgs", "repos_url": "https://api.github.com/users/maxzoech/repos", "events_url": "https://api.github.com/users/maxzoech/events{/privacy}", "received_events_url": "https://api.github.com/users/maxzoech/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-10-06T18:03:28Z", "updated_at": "2019-12-06T17:25:34Z", "closed_at": "2019-10-14T20:09:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "What's the status on support for TensorFlow 2.0 and is there a workaround in the meantime?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/140", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/140/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/140/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/140/events", "html_url": "https://github.com/tensorflow/transform/issues/140", "id": 495935063, "node_id": "MDU6SXNzdWU0OTU5MzUwNjM=", "number": 140, "title": "The saved path to vocabulary file is absolute", "user": {"login": "wsuchy", "id": 5363614, "node_id": "MDQ6VXNlcjUzNjM2MTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5363614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wsuchy", "html_url": "https://github.com/wsuchy", "followers_url": "https://api.github.com/users/wsuchy/followers", "following_url": "https://api.github.com/users/wsuchy/following{/other_user}", "gists_url": "https://api.github.com/users/wsuchy/gists{/gist_id}", "starred_url": "https://api.github.com/users/wsuchy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wsuchy/subscriptions", "organizations_url": "https://api.github.com/users/wsuchy/orgs", "repos_url": "https://api.github.com/users/wsuchy/repos", "events_url": "https://api.github.com/users/wsuchy/events{/privacy}", "received_events_url": "https://api.github.com/users/wsuchy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 11, "created_at": "2019-09-19T17:35:29Z", "updated_at": "2019-10-03T03:01:23Z", "closed_at": "2019-10-03T03:01:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "In my `preprocessing_fn` I am defining a vocabulary using `tft.compute_and_apply_vocabulary`. Unfortunately when I save the graph, it contains an absolute reference to the vocab file: `/var/folders/h3/zt26x1d93hq49vff996w04pc0000gq/T/tmpkj5__87_/tftransform_tmp/workclass` in the generated pb file.\r\nHow do I initialize the hash table back given I the vocab file is in different location?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/138", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/138/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/138/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/138/events", "html_url": "https://github.com/tensorflow/transform/issues/138", "id": 495417247, "node_id": "MDU6SXNzdWU0OTU0MTcyNDc=", "number": 138, "title": "Generated model should have named outputs", "user": {"login": "wsuchy", "id": 5363614, "node_id": "MDQ6VXNlcjUzNjM2MTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5363614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wsuchy", "html_url": "https://github.com/wsuchy", "followers_url": "https://api.github.com/users/wsuchy/followers", "following_url": "https://api.github.com/users/wsuchy/following{/other_user}", "gists_url": "https://api.github.com/users/wsuchy/gists{/gist_id}", "starred_url": "https://api.github.com/users/wsuchy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wsuchy/subscriptions", "organizations_url": "https://api.github.com/users/wsuchy/orgs", "repos_url": "https://api.github.com/users/wsuchy/repos", "events_url": "https://api.github.com/users/wsuchy/events{/privacy}", "received_events_url": "https://api.github.com/users/wsuchy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-09-18T19:38:45Z", "updated_at": "2019-09-18T21:15:00Z", "closed_at": "2019-09-18T21:15:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "I would like to train my processing model and then load the graph and perhaps merge it with my target DNN graph. There is a problem, however:\r\nYou see, when I define my operations in `preprocessing_fn` I can name inputs like this:\r\n` tft.scale_to_0_1(dense, name = \"myfeature_1\")` so in the resulting graph I will be able to feed it with my data. \r\nUnfortunately there is no easy way of getting the output other than traversing the generated sub graph in order to find the last operation.\r\nTwo things would be helpful here:\r\n1) function should name last operation (or even create a new dummy identity op) based on `name` parameter \r\n2) there should be a way of merging outputs of all functions into one dense tensor \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/136", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/136/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/136/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/136/events", "html_url": "https://github.com/tensorflow/transform/issues/136", "id": 494829320, "node_id": "MDU6SXNzdWU0OTQ4MjkzMjA=", "number": 136, "title": "Schema and statistics in Transform TFX Pipeline Component", "user": {"login": "wsuchy", "id": 5363614, "node_id": "MDQ6VXNlcjUzNjM2MTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/5363614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wsuchy", "html_url": "https://github.com/wsuchy", "followers_url": "https://api.github.com/users/wsuchy/followers", "following_url": "https://api.github.com/users/wsuchy/following{/other_user}", "gists_url": "https://api.github.com/users/wsuchy/gists{/gist_id}", "starred_url": "https://api.github.com/users/wsuchy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wsuchy/subscriptions", "organizations_url": "https://api.github.com/users/wsuchy/orgs", "repos_url": "https://api.github.com/users/wsuchy/repos", "events_url": "https://api.github.com/users/wsuchy/events{/privacy}", "received_events_url": "https://api.github.com/users/wsuchy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-17T20:14:01Z", "updated_at": "2019-12-02T21:23:13Z", "closed_at": "2019-12-02T21:23:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "The main entry point in Transform component (`preprocessing_fn`) should also provide computed Stats and Schema next to the inputs. In some scenarios users might want to benefit from the statistics e.g. to eliminate unnecessary features.\r\n(also posted here: https://github.com/tensorflow/tfx/issues/629, it looks like the changes might be needed in both repos) ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/135", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/135/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/135/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/135/events", "html_url": "https://github.com/tensorflow/transform/issues/135", "id": 480890945, "node_id": "MDU6SXNzdWU0ODA4OTA5NDU=", "number": 135, "title": "When calling Map or ParDo inside an tensorflow transform analyzer only the last batch is returned", "user": {"login": "joshbarth", "id": 9043470, "node_id": "MDQ6VXNlcjkwNDM0NzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9043470?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joshbarth", "html_url": "https://github.com/joshbarth", "followers_url": "https://api.github.com/users/joshbarth/followers", "following_url": "https://api.github.com/users/joshbarth/following{/other_user}", "gists_url": "https://api.github.com/users/joshbarth/gists{/gist_id}", "starred_url": "https://api.github.com/users/joshbarth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joshbarth/subscriptions", "organizations_url": "https://api.github.com/users/joshbarth/orgs", "repos_url": "https://api.github.com/users/joshbarth/repos", "events_url": "https://api.github.com/users/joshbarth/events{/privacy}", "received_events_url": "https://api.github.com/users/joshbarth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2019-08-14T21:11:22Z", "updated_at": "2019-12-13T03:45:28Z", "closed_at": "2019-12-13T03:45:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have some code that needs to be able to call an apache beam Map or ParDo function inside of a custom analyzer function (it looks like that is being done internally, in the analyzer_impls.py file). Unfortunately, when I call either of those functions inside of an analyzer, it just returns whatever was in the last batch, times however many times the apache beam function ended up being called. For example, if your input data is `[1, 2, 3, 4, 5]`, it might end up being split into 3 batches, like `[1, 2], [3], [4, 5]`, then the output would be [4, 5, 4, 5, 4, 5]. My work around so far has been to create a list in the DoFn and return that every time, but that's consuming too much memory on larger datasets. I have attached some unit tests that should make it easy to reproduce this problem:\r\n```python\r\nimport unittest\r\nimport apache_beam as beam\r\nfrom tensorflow_transform import beam as tft_beam\r\nimport tempfile\r\nimport tensorflow as tf\r\nimport tensorflow_transform as tft\r\nfrom tensorflow_transform.tf_metadata import dataset_metadata\r\nfrom tensorflow_transform.tf_metadata import dataset_schema\r\nimport collections\r\nfrom tensorflow_transform.beam import common\r\n\r\n\r\ndef lambda_analyzer(data):\r\n    with tf.name_scope(\"lambda_analyzer\"):\r\n        input_values_node = tft.analyzer_nodes.get_input_tensors_value_nodes([data])\r\n        outputs_value_node = tft.nodes.apply_operation(LambdaAnalyzer, input_values_node)\r\n        output = tft.analyzer_nodes.wrap_as_tensor(outputs_value_node)\r\n        return output\r\n\r\n\r\nclass LambdaAnalyzer(collections.namedtuple('LambdaAnalyzer', ['label']),\r\n                     tft.analyzer_nodes.AnalyzerDef):\r\n    def __new__(cls, label=None):\r\n        if label is None:\r\n            scope = tf.get_default_graph().get_name_scope()\r\n            label = '{}[{}]'.format(cls.__name__, scope)\r\n        return super(LambdaAnalyzer, cls).__new__(cls, label=label)\r\n\r\n    @property\r\n    def output_tensor_infos(self):\r\n        return [tft.analyzer_nodes.TensorInfo(tf.float32, [None, ], False)]\r\n\r\n\r\n@common.register_ptransform(LambdaAnalyzer)\r\nclass LambdaAnalyzerImpl(beam.PTransform):\r\n\r\n    def __init__(self, operation, extra_args):\r\n        pass\r\n\r\n    def expand(self, inputs):\r\n        pcoll, = inputs\r\n        return pcoll | beam.FlatMap(lambda x: x)\r\n\r\ndef par_do_analyzer(data):\r\n    with tf.name_scope(\"lambda_analyzer\"):\r\n        input_values_node = tft.analyzer_nodes.get_input_tensors_value_nodes([data])\r\n        outputs_value_node = tft.nodes.apply_operation(ParDoAnalyzer, input_values_node)\r\n        output = tft.analyzer_nodes.wrap_as_tensor(outputs_value_node)\r\n        return output\r\n\r\n\r\nclass ParDoAnalyzer(collections.namedtuple('ParDoAnalyzer', ['label']),\r\n                     tft.analyzer_nodes.AnalyzerDef):\r\n    def __new__(cls, label=None):\r\n        if label is None:\r\n            scope = tf.get_default_graph().get_name_scope()\r\n            label = '{}[{}]'.format(cls.__name__, scope)\r\n        return super(ParDoAnalyzer, cls).__new__(cls, label=label)\r\n\r\n    @property\r\n    def output_tensor_infos(self):\r\n        return [tft.analyzer_nodes.TensorInfo(tf.float32, [None, ], False)]\r\n\r\n\r\n@common.register_ptransform(ParDoAnalyzer)\r\nclass ParDoAnalyzerImpl(beam.PTransform):\r\n\r\n    def __init__(self, operation, extra_args):\r\n        pass\r\n\r\n    def expand(self, inputs):\r\n        pcoll, = inputs\r\n        return pcoll | beam.ParDo(TestDoFn())\r\n\r\n\r\nclass TestDoFn(beam.DoFn):\r\n    def __init__(self, *unused_args, **unused_kwargs):\r\n        super().__init__(*unused_args, **unused_kwargs)\r\n\r\n    def process(self, element):\r\n        # return element[0] # crashes, you need the square brackets, or you can say `yield element[0]`\r\n        return [element[0]]  # element is a tuple\r\n\r\n\r\ndef working_par_do_analyzer(data):\r\n    with tf.name_scope(\"lambda_analyzer\"):\r\n        input_values_node = tft.analyzer_nodes.get_input_tensors_value_nodes([data])\r\n        outputs_value_node = tft.nodes.apply_operation(WorkingParDoAnalyzer, input_values_node)\r\n        output = tft.analyzer_nodes.wrap_as_tensor(outputs_value_node)\r\n        return output\r\n\r\n\r\nclass WorkingParDoAnalyzer(collections.namedtuple('WorkingParDoAnalyzer', ['label']),\r\n                     tft.analyzer_nodes.AnalyzerDef):\r\n    def __new__(cls, label=None):\r\n        if label is None:\r\n            scope = tf.get_default_graph().get_name_scope()\r\n            label = '{}[{}]'.format(cls.__name__, scope)\r\n        return super(WorkingParDoAnalyzer, cls).__new__(cls, label=label)\r\n\r\n    @property\r\n    def output_tensor_infos(self):\r\n        return [tft.analyzer_nodes.TensorInfo(tf.float32, [None, ], False)]\r\n\r\n\r\n@common.register_ptransform(WorkingParDoAnalyzer)\r\nclass WorkingParDoAnalyzerImpl(beam.PTransform):\r\n\r\n    def __init__(self, operation, extra_args):\r\n        pass\r\n\r\n    def expand(self, inputs):\r\n        pcoll, = inputs\r\n        return pcoll | beam.ParDo(WorkingTestDoFn())\r\n\r\n\r\nclass WorkingTestDoFn(beam.DoFn):\r\n    def __init__(self, *unused_args, **unused_kwargs):\r\n        self.test = []\r\n        super().__init__(*unused_args, **unused_kwargs)\r\n\r\n    def process(self, element):\r\n        for i in element[0]:  # element[0] may have more than one entry (really it's a batch)\r\n            self.test.append(i)\r\n        # return self.test  # crashes\r\n        # yield self.test  # works\r\n        return [self.test]  # works\r\n\r\n\r\nclass ApacheBeamTest(unittest.TestCase):\r\n\r\n    # works\r\n    def test_beam_lambda(self):\r\n        class TestDoFn(beam.DoFn):\r\n            def __init__(self):\r\n                self.test = []\r\n\r\n            def process(self, element, **kwargs):\r\n                self.test.append(element)\r\n                return self.test\r\n\r\n        with beam.Pipeline() as pipeline:\r\n            data = (pipeline | beam.Create([1, 2, 3, 4, 5])\r\n                    | beam.Map(lambda x: x))\r\n            data | beam.io.WriteToText('tmp/test_data.csv')\r\n\r\n    # works\r\n    def test_beam_dofn(self):\r\n        class TestDoFn(beam.DoFn):\r\n            def __init__(self):\r\n                self.test = []\r\n\r\n            def process(self, element, **kwargs):\r\n                self.test.append(element)\r\n                return self.test\r\n\r\n        with beam.Pipeline() as pipeline:\r\n            data = (pipeline | beam.Create([1, 2, 3, 4, 5])\r\n                    | beam.ParDo(TestDoFn()))\r\n            data | beam.io.WriteToText('tmp/test_data.csv')\r\n\r\n    # works\r\n    def test_tft_beam(self):\r\n        def preprocessing_fn(inputs):\r\n            test = inputs[\"test\"]\r\n            return {\r\n                \"test\": test\r\n            }\r\n\r\n        with beam.Pipeline() as pipeline:\r\n            with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\r\n                ordered_columns = [\"test\"]\r\n                metadata = dataset_metadata.DatasetMetadata(\r\n                    dataset_schema.from_feature_spec({\"test\": tf.io.FixedLenFeature([], tf.float32)}))\r\n                converter = tft.coders.CsvCoder(ordered_columns, metadata.schema)\r\n\r\n                data = (pipeline | beam.Create([1, 2, 3, 4, 5] | beam.Map(converter.decode)))\r\n\r\n                dataset = (data, metadata)\r\n                transformed_inputs_dataset, _ = (\r\n                        dataset\r\n                        | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\r\n                transformed_data, _ = transformed_inputs_dataset\r\n\r\n                _ = (\r\n                        transformed_data | beam.Map(converter.encode)\r\n                        | beam.io.WriteToText(\"tmp/test_data.csv\"))\r\n\r\n    # fails\r\n    def test_tft_beam_lambda(self):\r\n        def preprocessing_fn(inputs):\r\n            test = inputs[\"test\"]\r\n            return {\r\n                \"test\": lambda_analyzer(test)\r\n            }\r\n\r\n        with beam.Pipeline() as pipeline:\r\n            with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\r\n                ordered_columns = [\"test\"]\r\n                metadata = dataset_metadata.DatasetMetadata(\r\n                    dataset_schema.from_feature_spec({\"test\": tf.io.FixedLenFeature([], tf.float32)}))\r\n                converter = tft.coders.CsvCoder(ordered_columns, metadata.schema)\r\n\r\n                data = (pipeline | beam.Create([1, 2, 3, 4, 5] | beam.Map(converter.decode)))\r\n\r\n                dataset = (data, metadata)\r\n                transformed_inputs_dataset, _ = (\r\n                        dataset\r\n                        | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\r\n                transformed_data, _ = transformed_inputs_dataset\r\n\r\n                _ = (\r\n                        transformed_data | beam.Map(converter.encode)\r\n                        | beam.io.WriteToText(\"tmp/test_data.csv\"))\r\n\r\n    # fails, outputs whatever the `process` function saw last, times how ever many times the process function saw.\r\n    def test_tft_beam_do_fn(self):\r\n        def preprocessing_fn(inputs):\r\n            test = inputs[\"test\"]\r\n            return {\r\n                \"test\": par_do_analyzer(test)\r\n            }\r\n\r\n        with beam.Pipeline() as pipeline:\r\n            with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\r\n                ordered_columns = [\"test\"]\r\n                metadata = dataset_metadata.DatasetMetadata(\r\n                    dataset_schema.from_feature_spec({\"test\": tf.io.FixedLenFeature([], tf.float32)}))\r\n                converter = tft.coders.CsvCoder(ordered_columns, metadata.schema)\r\n\r\n                data = (pipeline | beam.Create([1, 2, 3, 4, 5] | beam.Map(converter.decode)))\r\n\r\n                dataset = (data, metadata)\r\n                transformed_inputs_dataset, _ = (\r\n                        dataset\r\n                        | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\r\n                transformed_data, _ = transformed_inputs_dataset\r\n\r\n                _ = (\r\n                        transformed_data | beam.Map(converter.encode)\r\n                        | beam.io.WriteToText(\"tmp/test_data.csv\"))\r\n\r\n    # works-ish, but is repeated (n times, where n is the number of times WorkingTestDoFn.process is called)\r\n    # consumes lots of memory on a larger dataset\r\n    def test_tft_beam_do_fn_working(self):\r\n        def preprocessing_fn(inputs):\r\n            test = inputs[\"test\"]\r\n            return {\r\n                \"test\": working_par_do_analyzer(test)\r\n            }\r\n\r\n        with beam.Pipeline() as pipeline:\r\n            with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\r\n                ordered_columns = [\"test\"]\r\n                metadata = dataset_metadata.DatasetMetadata(\r\n                    dataset_schema.from_feature_spec({\"test\": tf.io.FixedLenFeature([], tf.float32)}))\r\n                converter = tft.coders.CsvCoder(ordered_columns, metadata.schema)\r\n\r\n                data = (pipeline | beam.Create([1, 2, 3, 4, 5] | beam.Map(converter.decode)))\r\n\r\n                dataset = (data, metadata)\r\n                transformed_inputs_dataset, _ = (\r\n                        dataset\r\n                        | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\r\n                transformed_data, _ = transformed_inputs_dataset\r\n\r\n                _ = (\r\n                        transformed_data | beam.Map(converter.encode)\r\n                        | beam.io.WriteToText(\"tmp/test_data.csv\"))\r\n\r\n\r\nif __name__ == '__main__':\r\n    unittest.main()\r\n```\r\nI'm not sure if this is a bug or if I'm missing something, please let me know if I'm doing something wrong. Thank you, and sorry for the large amount of code.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/134", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/134/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/134/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/134/events", "html_url": "https://github.com/tensorflow/transform/issues/134", "id": 474609328, "node_id": "MDU6SXNzdWU0NzQ2MDkzMjg=", "number": 134, "title": "No variables to save error when applying function with checkpoint", "user": {"login": "jasonquekavalon", "id": 37621839, "node_id": "MDQ6VXNlcjM3NjIxODM5", "avatar_url": "https://avatars0.githubusercontent.com/u/37621839?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jasonquekavalon", "html_url": "https://github.com/jasonquekavalon", "followers_url": "https://api.github.com/users/jasonquekavalon/followers", "following_url": "https://api.github.com/users/jasonquekavalon/following{/other_user}", "gists_url": "https://api.github.com/users/jasonquekavalon/gists{/gist_id}", "starred_url": "https://api.github.com/users/jasonquekavalon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jasonquekavalon/subscriptions", "organizations_url": "https://api.github.com/users/jasonquekavalon/orgs", "repos_url": "https://api.github.com/users/jasonquekavalon/repos", "events_url": "https://api.github.com/users/jasonquekavalon/events{/privacy}", "received_events_url": "https://api.github.com/users/jasonquekavalon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-07-30T14:11:31Z", "updated_at": "2019-07-30T21:13:12Z", "closed_at": "2019-07-30T20:42:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nMy tensorflow version is 1.13.2, tft version is 0.13.0, apache-beam version is 2.13.0.\r\n\r\nI am receiving a No variables to save exception when running apply_function_with_checkpoint and supplying a path to the inceptionv3 checkpoints.\r\n\r\n    def _image_to_vec(image_str_tensor):\r\n\r\n        def _decode_and_resize(image_str_tensor):\r\n            \"\"\"Decodes jpeg string, resizes it and returns a uint8 tensor.\"\"\"\r\n\r\n            # These constants are set by Inception v3's expectations.\r\n            height = 299\r\n            width = 299\r\n            channels = 3\r\n\r\n            image = tf.read_file(image_str_tensor)\r\n            image = tf.image.decode_jpeg(image, channels=channels)\r\n            image = tf.expand_dims(image, 0)\r\n            image = tf.image.resize_bilinear(image, [height, width],\r\n                                            align_corners=False)\r\n            image = tf.squeeze(image, squeeze_dims=[0])\r\n            image = tf.cast(image, dtype=tf.uint8)\r\n            return image\r\n\r\n            image = tf.map_fn(_decode_and_resize, image_str_tensor,\r\n                            back_prop=False, dtype=tf.uint8)\r\n\r\n            image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n            image = tf.subtract(image, 0.5)\r\n            inception_input = tf.multiply(image, 2.0)\r\n\r\n            # Build Inception layers, which expect a tensor of type float from [-1, 1)\r\n            # and shape [batch_size, height, width, channels].\r\n            with tf.contrib.slim.arg_scope(inception_v3_arg_scope()):\r\n                _, end_points = inception_v3(inception_input, is_training=False)\r\n            \r\n            embeddings = end_points['PreLogits']\r\n            inception_embeddings = tf.squeeze(embeddings, [1, 2], name='SpatialSqueeze')\r\n            return inception_embeddings\r\n\r\n    def make_tft_input_metadata():\r\n\r\n        return dataset_metadata.DatasetMetadata(\r\n            dataset_schema.from_feature_spec({\r\n                'image': tf.FixedLenFeature([], tf.string),\r\n                'label': tf.FixedLenFeature([], tf.string)\r\n            })\r\n        )\r\n\r\n    def preprocessing_fn(inputs):\r\n        \"\"\"TFT preprocessing function.\r\n        Args:\r\n        inputs: dictionary of input `tensorflow_transform.Column`.\r\n        Returns:\r\n        A dictionary of `tensorflow_transform.Column` representing the transformed\r\n            columns.\r\n        \"\"\"\r\n\r\n        features_dict = {}\r\n\r\n        features_dict['image'] = tft.apply_function_with_checkpoint(\r\n                _image_to_vec,\r\n                [inputs['image']],\r\n                INCEPTION_V3_CHECKPOINT,\r\n                exclude=INCEPTION_EXCLUDED_VARIABLES)\r\n\r\n        features_dict['label'] = tft.string_to_int(\r\n            inputs['label'],\r\n            vocab_filename='vocab_label')\r\n\r\n        return features_dict\r\n\r\n    def run_transform(output_dir, train_data_file, eval_data_file,\r\n                    project, mode):\r\n        tft_input_metadata = make_tft_input_metadata()\r\n        temp_dir = os.path.join(output_dir, 'tmp')\r\n\r\n        if mode == 'local':\r\n            pipeline_options = None\r\n            runner = 'DirectRunner'\r\n        elif mode == 'cloud':\r\n            options = {\r\n            'job_name': 'pipeline-tft-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\r\n            'temp_location': temp_dir,\r\n            'project': project\r\n            }\r\n            pipeline_options = beam.pipeline.PipelineOptions(flags=[], **options)\r\n            runner = 'DataFlowRunner'\r\n        else:\r\n            raise ValueError(\"Invalid mode %s.\" % mode)\r\n\r\n        with beam.Pipeline(runner, options=pipeline_options) as p:\r\n            with beam_impl.Context(temp_dir=temp_dir):\r\n                names = ['image', 'label']\r\n                converter = CsvCoder(names, tft_input_metadata.schema)\r\n                train_data = (\r\n                    p\r\n                    | 'ReadTrainData' >> textio.ReadFromText(train_data_file)\r\n                    | 'DecodeTrainData' >> beam.Map(converter.decode))\r\n\r\n                train_dataset = (train_data, tft_input_metadata)\r\n                transformed_dataset, transform_fn = (\r\n                    train_dataset | beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\r\n                transformed_data, transformed_metadata = transformed_dataset\r\n\r\nThe exception occurrs at AnalyzeAndTransformDataset.\r\n\r\nHere is the stack trace\r\n\r\n```\r\nFile \"src/preprocess.py\", line 131, in preprocessing_fn\r\n    exclude=INCEPTION_EXCLUDED_VARIABLES)\r\n  File \"/Users/jason.quek/virtualenvs/comex-preprocess-9xyR313c/lib/python3.5/site-packages/tensorflow_transform/pretrained_models.py\", line 201, in apply_function_with_checkpoint\r\n    saver = tf.train.Saver(vars_to_restore)\r\n  File \"/Users/jason.quek/virtualenvs/comex-preprocess-9xyR313c/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\r\n    self.build()\r\n  File \"/Users/jason.quek/virtualenvs/comex-preprocess-9xyR313c/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 844, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/Users/jason.quek/virtualenvs/comex-preprocess-9xyR313c/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 869, in _build\r\n    raise ValueError(\"No variables to save\")\r\n```\r\n\r\nTracing the code, it looks like tf.contrib.slim.get_variables_to_restore is used to get the variables from an empty Graph, but I'm not certain. I adapted the code samples from the flower kubeflow pipeline, but it was on tf 1.6.0 and tft 0.6.0, so I wanted to move to the latest versions. Might you have any idea on the reason behind this ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/133", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/133/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/133/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/133/events", "html_url": "https://github.com/tensorflow/transform/issues/133", "id": 474542557, "node_id": "MDU6SXNzdWU0NzQ1NDI1NTc=", "number": 133, "title": "Shouldn't categorical_column_with_vocabulary_file be wrapped with indicator_column in census_example.py?", "user": {"login": "Efaq", "id": 42271354, "node_id": "MDQ6VXNlcjQyMjcxMzU0", "avatar_url": "https://avatars2.githubusercontent.com/u/42271354?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Efaq", "html_url": "https://github.com/Efaq", "followers_url": "https://api.github.com/users/Efaq/followers", "following_url": "https://api.github.com/users/Efaq/following{/other_user}", "gists_url": "https://api.github.com/users/Efaq/gists{/gist_id}", "starred_url": "https://api.github.com/users/Efaq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Efaq/subscriptions", "organizations_url": "https://api.github.com/users/Efaq/orgs", "repos_url": "https://api.github.com/users/Efaq/repos", "events_url": "https://api.github.com/users/Efaq/events{/privacy}", "received_events_url": "https://api.github.com/users/Efaq/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101994909, "node_id": "MDU6TGFiZWwxMTAxOTk0OTA5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2019-07-30T11:59:05Z", "updated_at": "2019-12-06T17:42:58Z", "closed_at": "2019-12-02T22:05:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "I was working with census_example.py and noticed that the one_hot feature columns are being declared this way:\r\n\r\n```\r\n# Wrap categorical columns.\r\n  one_hot_columns = [\r\n      tf.feature_column.categorical_column_with_vocabulary_file(\r\n          key=key,\r\n          vocabulary_file=tf_transform_output.vocabulary_file_by_name(\r\n              vocab_filename=key))\r\n      for key in CATEGORICAL_FEATURE_KEYS]\r\n```\r\n\r\nAs far as I could understand, the categorical_column_with_vocabulary_file feature column is mapping strings to integers, but no one-hot encoding is being performed. The encoding would be achieved using tf.feature_column.indicator_column around the resulting categorical column.\r\n\r\nThus, I would write it this way:\r\n\r\n```\r\n# Wrap categorical columns.\r\n  one_hot_columns = [\r\ntf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_file(\r\n          key=key,\r\n          vocabulary_file=tf_transform_output.vocabulary_file_by_name(\r\n              vocab_filename=key)))\r\n      for key in CATEGORICAL_FEATURE_KEYS]\r\n```\r\nAm I correct or have I misunderstood the usage of these tf.feature_column.*?\r\n\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/131", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/131/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/131/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/131/events", "html_url": "https://github.com/tensorflow/transform/issues/131", "id": 469937059, "node_id": "MDU6SXNzdWU0Njk5MzcwNTk=", "number": 131, "title": "Mean/Median value Imputation", "user": {"login": "jhoh10", "id": 17030269, "node_id": "MDQ6VXNlcjE3MDMwMjY5", "avatar_url": "https://avatars0.githubusercontent.com/u/17030269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhoh10", "html_url": "https://github.com/jhoh10", "followers_url": "https://api.github.com/users/jhoh10/followers", "following_url": "https://api.github.com/users/jhoh10/following{/other_user}", "gists_url": "https://api.github.com/users/jhoh10/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhoh10/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhoh10/subscriptions", "organizations_url": "https://api.github.com/users/jhoh10/orgs", "repos_url": "https://api.github.com/users/jhoh10/repos", "events_url": "https://api.github.com/users/jhoh10/events{/privacy}", "received_events_url": "https://api.github.com/users/jhoh10/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2019-07-18T19:00:30Z", "updated_at": "2020-02-03T15:39:31Z", "closed_at": "2019-07-29T09:31:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there any plans to introduce imputation to tensorflow transform? Believe this could be very helpful, particularly mean and median value imputation.\r\n\r\n------------------------------------------------------------\r\nWe will be adding imputation support soon.\r\n\r\n_Originally posted by @sharifgamal in https://github.com/tensorflow/transform/issues/67#issuecomment-401363792_", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/130", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/130/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/130/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/130/events", "html_url": "https://github.com/tensorflow/transform/issues/130", "id": 468935273, "node_id": "MDU6SXNzdWU0Njg5MzUyNzM=", "number": 130, "title": "Is MeanAndVarCombiner a public API?", "user": {"login": "shoyer", "id": 1217238, "node_id": "MDQ6VXNlcjEyMTcyMzg=", "avatar_url": "https://avatars2.githubusercontent.com/u/1217238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shoyer", "html_url": "https://github.com/shoyer", "followers_url": "https://api.github.com/users/shoyer/followers", "following_url": "https://api.github.com/users/shoyer/following{/other_user}", "gists_url": "https://api.github.com/users/shoyer/gists{/gist_id}", "starred_url": "https://api.github.com/users/shoyer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shoyer/subscriptions", "organizations_url": "https://api.github.com/users/shoyer/orgs", "repos_url": "https://api.github.com/users/shoyer/repos", "events_url": "https://api.github.com/users/shoyer/events{/privacy}", "received_events_url": "https://api.github.com/users/shoyer/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2019-07-17T00:58:27Z", "updated_at": "2019-07-23T20:14:54Z", "closed_at": "2019-07-22T19:14:44Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I'm interested in using the `tensorflow_transform.MeanAndVarCombiner` directly in my own Beam pipeline, without relying (yet) upon the rest of tf.Transform.\r\n\r\nIs this API supported for external use?\r\n\r\nI would have said yes, since it's exposed in the top level namespace in the latest release, but I noticed that it as replaced by `WeightedMeanAndVarCombiner` and is it's actually no longer available on master:\r\nhttps://github.com/tensorflow/transform/commit/b6c3e02c0e86e091ab260f9c72cfe61917990fd8\r\n\r\nWas this a mistake -- perhaps there should still be an alias `MeanAndVarCombiner = WeightedMeanAndVarCombiner` exposed? Or should I refrain from using either of these unless I'm willing to be broken? I It's a little hard to know what's a public API without API docs :).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/128", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/128/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/128/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/128/events", "html_url": "https://github.com/tensorflow/transform/issues/128", "id": 467027011, "node_id": "MDU6SXNzdWU0NjcwMjcwMTE=", "number": 128, "title": "Some analyzers error with `Tensor had invalid shape () for FixedLenFeature: must have rank at least 1` when returning results in AnalyzeAndTransformDataset", "user": {"login": "joshbarth", "id": 9043470, "node_id": "MDQ6VXNlcjkwNDM0NzA=", "avatar_url": "https://avatars2.githubusercontent.com/u/9043470?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joshbarth", "html_url": "https://github.com/joshbarth", "followers_url": "https://api.github.com/users/joshbarth/followers", "following_url": "https://api.github.com/users/joshbarth/following{/other_user}", "gists_url": "https://api.github.com/users/joshbarth/gists{/gist_id}", "starred_url": "https://api.github.com/users/joshbarth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joshbarth/subscriptions", "organizations_url": "https://api.github.com/users/joshbarth/orgs", "repos_url": "https://api.github.com/users/joshbarth/repos", "events_url": "https://api.github.com/users/joshbarth/events{/privacy}", "received_events_url": "https://api.github.com/users/joshbarth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-07-11T17:51:51Z", "updated_at": "2019-07-11T21:05:09Z", "closed_at": "2019-07-11T21:05:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "Certain analyzers, like tft.max, tft.min, tft.mean, and tft.vocabulary give a\r\n```ValueError: Tensor(\"vocabulary/Placeholder:0\", shape=(), dtype=string) had invalid shape () for FixedLenFeature: must have rank at least 1```\r\nwhen returned via AnalyzeAndTransformDataset like this:\r\n```python\r\n        def preprocessing_inputs_fn(inputs):\r\n            values = inputs[\"Values\"]\r\n            test = tft.max(values)\r\n            return {\r\n                \"test\": test\r\n            }\r\nwith beam.Pipeline() as pipeline:\r\n    with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\r\n       raw_dataset = load_csv(pipeline)\r\n\r\n        transformed_inputs_dataset, transform_input_fn = (\r\n               raw_dataset\r\n               | tft_beam.AnalyzeAndTransformDataset(preprocessing_inputs_fn))\r\n\r\n        self.save_tf_record(transformed_inputs_dataset)\r\n\r\n        tf_transform_output = tft.TFTransformOutput(self.working_dir)\r\n\r\n        def input_fn():\r\n            dataset = tf.data.experimental.make_batched_features_dataset(\r\n                file_pattern=os.path.join(self.working_dir, self.transform_data_file) + \"*\",\r\n                batch_size=self.batch_size,\r\n                features=tf_transform_output.transformed_feature_spec(),\r\n                reader=tf.data.TFRecordDataset,\r\n                shuffle=self.shuffle)\r\n\r\n            transformed_features = tf.compat.v1.data.make_one_shot_iterator(\r\n                dataset).get_next()\r\n\r\n            transformed_labels = {}\r\n            for i in transformed_features:\r\n                if i.startswith(\"label-\"):\r\n                    transformed_labels[i[6:]] = transformed_features[i]\r\n\r\n            return transformed_features, transformed_labels\r\n\r\n        return input_fn\r\n```\r\nThe full stack is \r\n```\r\nError\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\r\n    yield\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/unittest/case.py\", line 605, in run\r\n    testMethod()\r\n  File \"/Users/josh/workspace/VisibleAIUtils/tests/test_tensorflow_data_transforms.py\", line 84, in test_group_by\r\n    test_fn = csv_loader.load_and_transform_csv()\r\n  File \"/Users/josh/workspace/VisibleAIUtils/VisibleAIUtils/tensorflow_load_data.py\", line 118, in load_and_transform_csv\r\n    | tft_beam.AnalyzeAndTransformDataset(self.transform_inputs_fn))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/transforms/ptransform.py\", line 510, in __ror__\r\n    result = p.apply(self, pvalueish, label)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/pipeline.py\", line 516, in apply\r\n    pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/runner.py\", line 193, in apply\r\n    return m(transform, input, options)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/runner.py\", line 199, in apply_PTransform\r\n    return transform.expand(input)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 872, in expand\r\n    dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/transforms/ptransform.py\", line 896, in __ror__\r\n    return self.transform.__ror__(pvalueish, self.label)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/transforms/ptransform.py\", line 510, in __ror__\r\n    result = p.apply(self, pvalueish, label)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/pipeline.py\", line 480, in apply\r\n    return self.apply(transform, pvalueish)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/pipeline.py\", line 516, in apply\r\n    pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/runner.py\", line 193, in apply\r\n    return m(transform, input, options)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/runner.py\", line 199, in apply_PTransform\r\n    return transform.expand(input)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 825, in expand\r\n    input_metadata))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 761, in expand\r\n    schema=schema_inference.infer_feature_schema(output_signature, graph))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/schema_inference.py\", line 121, in infer_feature_schema\r\n    feature_spec = _feature_spec_from_batched_tensors(features)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/schema_inference.py\", line 67, in _feature_spec_from_batched_tensors\r\n    'at least 1'.format(tensor, shape))\r\nValueError: Tensor(\"vocabulary/Placeholder:0\", shape=(), dtype=string) had invalid shape () for FixedLenFeature: must have rank at least 1\r\n```\r\nThis is also affecting a customer analyzer I wrote to try to get unique values without generating a vocabulary file, but the exact stack is slightly different:\r\n```\r\nError\r\nTraceback (most recent call last):\r\n  File \"apache_beam/runners/common.py\", line 751, in apache_beam.runners.common.DoFnRunner.process\r\n  File \"apache_beam/runners/common.py\", line 423, in apache_beam.runners.common.SimpleInvoker.invoke_process\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1265, in <lambda>\r\n    wrapper = lambda x: [fn(x)]\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 656, in _infer_metadata_from_saved_model\r\n    schema=schema_inference.infer_feature_schema(outputs, graph, session))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/schema_inference.py\", line 121, in infer_feature_schema\r\n    feature_spec = _feature_spec_from_batched_tensors(features)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/schema_inference.py\", line 67, in _feature_spec_from_batched_tensors\r\n    'at least 1'.format(tensor, shape))\r\nValueError: Tensor(\"transform/Const_8:0\", shape=(), dtype=string) had invalid shape () for FixedLenFeature: must have rank at least 1\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\r\n    yield\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/unittest/case.py\", line 605, in run\r\n    testMethod()\r\n  File \"/Users/josh/workspace/VisibleAIUtils/tests/test_tensorflow_data_transforms.py\", line 84, in test_group_by\r\n    test_fn = csv_loader.load_and_transform_csv()\r\n  File \"/Users/josh/workspace/VisibleAIUtils/VisibleAIUtils/tensorflow_load_data.py\", line 124, in load_and_transform_csv\r\n    return self.get_input_fn()\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/pipeline.py\", line 426, in __exit__\r\n    self.run().wait_until_finish()\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/pipeline.py\", line 406, in run\r\n    self._options).run(False)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/pipeline.py\", line 419, in run\r\n    return self.runner.run_pipeline(self, self._options)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/direct/direct_runner.py\", line 128, in run_pipeline\r\n    return runner.run_pipeline(pipeline, options)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/portability/fn_api_runner.py\", line 277, in run_pipeline\r\n    default_environment=self._default_environment))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/portability/fn_api_runner.py\", line 281, in run_via_runner_api\r\n    return self.run_stages(*self.create_stages(pipeline_proto))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/portability/fn_api_runner.py\", line 357, in run_stages\r\n    stage_context.safe_coders)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/portability/fn_api_runner.py\", line 521, in run_stage\r\n    data_input, data_output)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/portability/fn_api_runner.py\", line 1227, in process_bundle\r\n    result_future = self._controller.control_handler.push(process_bundle)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/portability/fn_api_runner.py\", line 842, in push\r\n    response = self.worker.do_instruction(request)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 333, in do_instruction\r\n    request.instruction_id)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 359, in process_bundle\r\n    bundle_processor.process_bundle(instruction_id))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 589, in process_bundle\r\n    ].process_encoded(data.data)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 143, in process_encoded\r\n    self.output(decoded_value)\r\n  File \"apache_beam/runners/worker/operations.py\", line 246, in apache_beam.runners.worker.operations.Operation.output\r\n  File \"apache_beam/runners/worker/operations.py\", line 247, in apache_beam.runners.worker.operations.Operation.output\r\n  File \"apache_beam/runners/worker/operations.py\", line 143, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\r\n  File \"apache_beam/runners/worker/operations.py\", line 419, in apache_beam.runners.worker.operations.ImpulseReadOperation.process\r\n  File \"apache_beam/runners/worker/operations.py\", line 426, in apache_beam.runners.worker.operations.ImpulseReadOperation.process\r\n  File \"apache_beam/runners/worker/operations.py\", line 247, in apache_beam.runners.worker.operations.Operation.output\r\n  File \"apache_beam/runners/worker/operations.py\", line 143, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\r\n  File \"apache_beam/runners/worker/operations.py\", line 583, in apache_beam.runners.worker.operations.DoOperation.process\r\n  File \"apache_beam/runners/worker/operations.py\", line 584, in apache_beam.runners.worker.operations.DoOperation.process\r\n  File \"apache_beam/runners/common.py\", line 747, in apache_beam.runners.common.DoFnRunner.receive\r\n  File \"apache_beam/runners/common.py\", line 753, in apache_beam.runners.common.DoFnRunner.process\r\n  File \"apache_beam/runners/common.py\", line 792, in apache_beam.runners.common.DoFnRunner._reraise_augmented\r\n  File \"apache_beam/runners/common.py\", line 751, in apache_beam.runners.common.DoFnRunner.process\r\n  File \"apache_beam/runners/common.py\", line 563, in apache_beam.runners.common.PerWindowInvoker.invoke_process\r\n  File \"apache_beam/runners/common.py\", line 630, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\r\n  File \"apache_beam/runners/common.py\", line 838, in apache_beam.runners.common._OutputProcessor.process_outputs\r\n  File \"apache_beam/runners/common.py\", line 877, in apache_beam.runners.common._OutputProcessor.process_outputs\r\n  File \"apache_beam/runners/worker/operations.py\", line 100, in apache_beam.runners.worker.operations.ConsumerSet.receive\r\n  File \"apache_beam/runners/worker/operations.py\", line 583, in apache_beam.runners.worker.operations.DoOperation.process\r\n  File \"apache_beam/runners/worker/operations.py\", line 584, in apache_beam.runners.worker.operations.DoOperation.process\r\n  File \"apache_beam/runners/common.py\", line 747, in apache_beam.runners.common.DoFnRunner.receive\r\n  File \"apache_beam/runners/common.py\", line 753, in apache_beam.runners.common.DoFnRunner.process\r\n  File \"apache_beam/runners/common.py\", line 807, in apache_beam.runners.common.DoFnRunner._reraise_augmented\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/future/utils/__init__.py\", line 421, in raise_with_traceback\r\n    raise exc.with_traceback(traceback)\r\n  File \"apache_beam/runners/common.py\", line 751, in apache_beam.runners.common.DoFnRunner.process\r\n  File \"apache_beam/runners/common.py\", line 423, in apache_beam.runners.common.SimpleInvoker.invoke_process\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/apache_beam/transforms/core.py\", line 1265, in <lambda>\r\n    wrapper = lambda x: [fn(x)]\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/beam/impl.py\", line 656, in _infer_metadata_from_saved_model\r\n    schema=schema_inference.infer_feature_schema(outputs, graph, session))\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/schema_inference.py\", line 121, in infer_feature_schema\r\n    feature_spec = _feature_spec_from_batched_tensors(features)\r\n  File \"/Users/josh/workspace/VisibleAIUtils/venv/lib/python3.6/site-packages/tensorflow_transform/schema_inference.py\", line 67, in _feature_spec_from_batched_tensors\r\n    'at least 1'.format(tensor, shape))\r\nValueError: Tensor(\"transform/Const_8:0\", shape=(), dtype=string) had invalid shape () for FixedLenFeature: must have rank at least 1 [while running 'AnalyzeAndTransformDataset/AnalyzeDataset/ComputeDeferredMetadata']\r\n```\r\nThe custom analyzer used there is nearly the same as the built in vocabulary method, only with a custom node that converts the results to an AnalyzerDef node instead of the last step writing to a file. Interestingly, this method should actually return more than one value, unlike the max and mean functions.\r\n\r\nIs this error intended behavior? Am I missing something that will allow me to return the result of methods like these, or is this a bug?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/127", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/127/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/127/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/127/events", "html_url": "https://github.com/tensorflow/transform/issues/127", "id": 462801287, "node_id": "MDU6SXNzdWU0NjI4MDEyODc=", "number": 127, "title": "Tag-set transform is not easily reusable for serving", "user": {"login": "cyrilou242", "id": 27781189, "node_id": "MDQ6VXNlcjI3NzgxMTg5", "avatar_url": "https://avatars3.githubusercontent.com/u/27781189?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cyrilou242", "html_url": "https://github.com/cyrilou242", "followers_url": "https://api.github.com/users/cyrilou242/followers", "following_url": "https://api.github.com/users/cyrilou242/following{/other_user}", "gists_url": "https://api.github.com/users/cyrilou242/gists{/gist_id}", "starred_url": "https://api.github.com/users/cyrilou242/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cyrilou242/subscriptions", "organizations_url": "https://api.github.com/users/cyrilou242/orgs", "repos_url": "https://api.github.com/users/cyrilou242/repos", "events_url": "https://api.github.com/users/cyrilou242/events{/privacy}", "received_events_url": "https://api.github.com/users/cyrilou242/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-07-01T16:17:16Z", "updated_at": "2019-07-04T07:52:24Z", "closed_at": "2019-07-03T18:47:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI am trying to serve a transform model on Google AI Platform.   \r\nUnfortunately, when I check the tag-set with the cli utility, I see that a tensorflow transform model is saved with the tag `transform`. The AI Platform is expecting the tag `serve`.\r\n\t\r\n\tsaved_model_cli show --dir out/transform/transform_fn\r\n\ttransform\r\n\r\nThe tag `transform` seems to be a tag specific to tf transform that is not in the documentation of [tensorflow tags](https://www.tensorflow.org/api_docs/python/tf/saved_model/tag_constants), namely 'gpu', 'serve', 'tpu', and 'train'.\r\n\r\nIt's usage can be found here in the `write_saved_transform_from_session` function.\r\nhttps://github.com/tensorflow/transform/blob/d3d4d1c7fa183866cb6ba5124be0b51d8b42af2d/tensorflow_transform/saved/saved_transform_io.py#L385\r\n\r\nWhat is the reason for this `transform` tag ? \r\nIs reloading the model in a session and saving with the correct `serve` tag enough to have a working model, or will it break something ?\r\n\r\nWould it be interesting to be able to pass the `serve` tag instead of the `transform` tag when saving in tensorflow transform ?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/126", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/126/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/126/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/126/events", "html_url": "https://github.com/tensorflow/transform/issues/126", "id": 461800677, "node_id": "MDU6SXNzdWU0NjE4MDA2Nzc=", "number": 126, "title": "Reading vocabulary file during AnalyzeAndTransformDataset", "user": {"login": "TimSmole", "id": 3829086, "node_id": "MDQ6VXNlcjM4MjkwODY=", "avatar_url": "https://avatars2.githubusercontent.com/u/3829086?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TimSmole", "html_url": "https://github.com/TimSmole", "followers_url": "https://api.github.com/users/TimSmole/followers", "following_url": "https://api.github.com/users/TimSmole/following{/other_user}", "gists_url": "https://api.github.com/users/TimSmole/gists{/gist_id}", "starred_url": "https://api.github.com/users/TimSmole/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TimSmole/subscriptions", "organizations_url": "https://api.github.com/users/TimSmole/orgs", "repos_url": "https://api.github.com/users/TimSmole/repos", "events_url": "https://api.github.com/users/TimSmole/events{/privacy}", "received_events_url": "https://api.github.com/users/TimSmole/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2019-06-28T00:13:15Z", "updated_at": "2020-07-18T21:05:11Z", "closed_at": "2019-07-17T21:53:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I would like to read vocabulary file during [AnalyzeAndTransformDataset](https://www.tensorflow.org/tfx/transform/api_docs/python/tft_beam/AnalyzeAndTransformDataset). \r\n\r\nI found that [TFTransformOutput](https://www.tensorflow.org/tfx/transform/api_docs/python/tft/TFTransformOutput) provides such functionalities, however these methods are not available during [AnalyzeAndTransformDataset](https://www.tensorflow.org/tfx/transform/api_docs/python/tft_beam/AnalyzeAndTransformDataset) since [TFTransformOutput](https://www.tensorflow.org/tfx/transform/api_docs/python/tft/TFTransformOutput) searches for vocabulary files inside [TRANSFORM_FN_DIR](https://www.tensorflow.org/tfx/transform/api_docs/python/tft/TFTransformOutput#TRANSFORM_FN_DIR) which is not yet generated at that time. \r\n\r\nAnother way I found is using same functions that apply_vocabulary is using - e.g. by using [tf.lookup.TextFileInitializer](https://www.tensorflow.org/api_docs/python/tf/lookup/TextFileInitializer) and [tf.lookup.StaticHashTable](https://www.tensorflow.org/api_docs/python/tf/lookup/StaticHashTable), however this seems as a lot of duplicated and boilerplate code only to read the size of just created look-up table/vocabulary.\r\n\r\nAre there any better ways to read vocabulary files?\r\n\r\nAny advice will be highly appreciated! Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/125", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/125/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/125/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/125/events", "html_url": "https://github.com/tensorflow/transform/issues/125", "id": 458735181, "node_id": "MDU6SXNzdWU0NTg3MzUxODE=", "number": 125, "title": "TF hub module variables used in preprocessing not exported in Checkpoints during training", "user": {"login": "lbeisteiner", "id": 13013630, "node_id": "MDQ6VXNlcjEzMDEzNjMw", "avatar_url": "https://avatars2.githubusercontent.com/u/13013630?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lbeisteiner", "html_url": "https://github.com/lbeisteiner", "followers_url": "https://api.github.com/users/lbeisteiner/followers", "following_url": "https://api.github.com/users/lbeisteiner/following{/other_user}", "gists_url": "https://api.github.com/users/lbeisteiner/gists{/gist_id}", "starred_url": "https://api.github.com/users/lbeisteiner/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lbeisteiner/subscriptions", "organizations_url": "https://api.github.com/users/lbeisteiner/orgs", "repos_url": "https://api.github.com/users/lbeisteiner/repos", "events_url": "https://api.github.com/users/lbeisteiner/events{/privacy}", "received_events_url": "https://api.github.com/users/lbeisteiner/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2019-06-20T15:46:15Z", "updated_at": "2019-07-24T09:37:14Z", "closed_at": "2019-07-24T09:37:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm using `tensorflow_transform` to pre-process text data using a [TF Hub Module](https://www.tensorflow.org/hub) and later use the derived features for model training. I tried to provide a minimum working example below.\r\n\r\n###  pipeline.py  \r\n1) embeds two texts using [NNLM](https://tfhub.dev/google/nnlm-de-dim128-with-normalization/1)  \r\n2) calculates the cosine distance between them  \r\n3) writes the preprocessed data into a `.csv` file.  \r\n4) exports the `transform_fn` function/preprocessing graph to be used later for serving  \r\n5) run `python pipeline.py`\r\n```python\r\n    import tensorflow as tf\r\n    \r\n    import apache_beam as beam\r\n    from tensorflow_transform.beam.tft_beam_io import transform_fn_io\r\n    from apache_beam.options.pipeline_options import SetupOptions\r\n    from apache_beam.options.pipeline_options import PipelineOptions\r\n    from apache_beam.io import WriteToText\r\n    \r\n    import tensorflow_transform.beam.impl as beam_impl\r\n    from tensorflow_transform.coders.csv_coder import CsvCoder\r\n    from tensorflow_transform.tf_metadata import dataset_metadata, dataset_schema\r\n    \r\n    import tensorflow_hub as hub\r\n    \r\n    tf_input_raw_feature_spec = {\r\n        'text_1': tf.FixedLenFeature([], tf.string),\r\n        'text_2': tf.FixedLenFeature([], tf.string),\r\n        'y': tf.FixedLenFeature([], tf.float32),\r\n    }\r\n    \r\n    SAMPLE_INPUT = [({\r\n        'text_1': 'Help me embed this!',\r\n        'text_2': 'Help me embed this!',\r\n        'y': 1\r\n    }), ({\r\n        'text_1': 'And this as well',\r\n        'text_2': 'Lunch Lunch Lunch',\r\n        'y': 0\r\n    })]\r\n    \r\n    tf_input_metadata = dataset_metadata.DatasetMetadata(dataset_schema.from_feature_spec(tf_input_raw_feature_spec))\r\n    \r\n    \r\n    def tf_transform_preprocessing(inputs):\r\n        outputs = {}\r\n    \r\n        module = hub.Module(\"https://tfhub.dev/google/nnlm-de-dim128-with-normalization/1\")\r\n    \r\n        text_1_embed = module(inputs['text_1'])\r\n        text_2_embed = module(inputs['text_2'])\r\n    \r\n        # Calculate Cosine Similarity\r\n        question_normalized = tf.nn.l2_normalize(text_1_embed, 1)\r\n        content_normalized = tf.nn.l2_normalize(text_2_embed, 1)\r\n        outputs['cosine_similarity'] = tf.reduce_sum(tf.multiply(question_normalized, content_normalized),\r\n                                                     keepdims=True,\r\n                                                     axis=1)\r\n        outputs['y'] = inputs['y']\r\n    \r\n        return outputs\r\n    \r\n    \r\n    def run():\r\n        pipeline_options = PipelineOptions()\r\n        pipeline_options.view_as(SetupOptions).save_main_session = True\r\n    \r\n        with beam.Pipeline(options=pipeline_options) as p,\\\r\n                beam_impl.Context(temp_dir='./tmp'):\r\n    \r\n            pcoll_text = p | beam.Create(SAMPLE_INPUT)\r\n    \r\n            transformed_dataset, transform_fn = (\r\n                (pcoll_text, tf_input_metadata)\r\n                | 'Analyze and Transform' >> beam_impl.AnalyzeAndTransformDataset(tf_transform_preprocessing))\r\n    \r\n            transformed_data, transformed_metadata = transformed_dataset\r\n    \r\n            column_names = transformed_metadata.schema.as_feature_spec().keys()\r\n    \r\n            (transformed_data | ' Write PCollection to GCS, csv' >> WriteToText(\r\n                file_path_prefix='./preprocessed_output',\r\n                num_shards=1,\r\n                coder=CsvCoder(column_names=column_names, schema=transformed_metadata.schema),\r\n                compression_type='uncompressed',\r\n                header=','.join(column_names)))\r\n    \r\n            transform_fn | 'Write transformFn' >> transform_fn_io.WriteTransformFn('./metadata')\r\n    \r\n    \r\n    if __name__ == '__main__':\r\n        run()\r\n```\r\n\r\n_Input:_\r\n```\r\nSAMPLE_INPUT = [({\r\n    'text_1': 'Help me embed this!',\r\n    'text_2': 'Help me embed this!',\r\n    'y': 1\r\n}), ({\r\n    'text_1': 'And this as well',\r\n    'text_2': 'Lunch Lunch Lunch',\r\n    'y': 0\r\n})]\r\n```\r\n\r\n_Preprocessed Output in `preprocessed_output-00000-of-00001.csv`:_\r\n```\r\ny,cosine_similarity\r\n1.0,1.0000001\r\n0.0,0.1290714\r\n```\r\n\r\n### train.py\r\n1) trains a `tf.estimator.LinearRegressor` on the pre-processed data  \r\n2) Periodically evaluates and exports the model using `Checkpoints`  \r\n3) During this evaluation it also exports the `serving_input_receiver_fn` that I later want to use for serving it in production. Since I want to feed \r\n**raw** data to the model while serving, I apply the exported `tf-transform` transformations in the `serving_input_fn`.  \r\n4) run `python train.py`\r\n\r\n```python\r\nfrom sys import argv\r\nimport tensorflow as tf\r\nimport tensorflow_transform as tft\r\nfrom tensorflow_transform.tf_metadata import dataset_metadata\r\nfrom tensorflow_transform.tf_metadata import dataset_schema\r\n\r\ntf_input_raw_feature_spec = {\r\n    'text_1': tf.FixedLenFeature([], tf.string),\r\n    'text_2': tf.FixedLenFeature([], tf.string),\r\n    'y': tf.FixedLenFeature([], tf.float32),\r\n}\r\n\r\ntf_input_metadata = dataset_metadata.DatasetMetadata(dataset_schema.from_feature_spec(tf_input_raw_feature_spec))\r\n\r\n\r\ndef make_input_fn(input_file_pattern, num_epochs, batch_size, label_variable, shuffle=False):\r\n    return tf.contrib.data.make_csv_dataset(file_pattern=input_file_pattern,\r\n                                            batch_size=batch_size,\r\n                                            label_name=label_variable,\r\n                                            num_epochs=num_epochs,\r\n                                            shuffle=shuffle)\r\n\r\n\r\ndef make_serving_input_fn(tf_transform_output):\r\n    tf_transform_output.load_transform_graph()\r\n    raw_feature_spec = tf_input_metadata.schema.as_feature_spec()\r\n    raw_feature_spec.pop('y')\r\n\r\n    def serving_input_fn():\r\n        raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(raw_feature_spec,\r\n                                                                                   default_batch_size=None)\r\n        serving_input_receiver = raw_input_fn()\r\n\r\n        # Apply the transform function on raw input\r\n        raw_features = serving_input_receiver.features\r\n        transformed_features = tf_transform_output.transform_raw_features(raw_features)\r\n        return tf.estimator.export.ServingInputReceiver(transformed_features, serving_input_receiver.receiver_tensors)\r\n\r\n    return serving_input_fn\r\n\r\n\r\ndef train(args):\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    tf_transform_output = tft.TFTransformOutput(args['tf_transform'])\r\n\r\n    # model and all outputs under this relative path\r\n    model_dir = './logs/'\r\n\r\n    train_input_files = ['preprocessed_output-00000-of-00001']\r\n\r\n    tf.logging.info(train_input_files)\r\n\r\n    def train_input_fn():\r\n        return make_input_fn(input_file_pattern=train_input_files,\r\n                             num_epochs=args['num_epochs'],\r\n                             batch_size=args['batch_size'],\r\n                             label_variable=args['label_variable'],\r\n                             shuffle=True)\r\n\r\n    eval_input_files = ['preprocessed_output-00000-of-00001']\r\n\r\n    tf.logging.info(eval_input_files)\r\n\r\n    def eval_input_fn():\r\n        return make_input_fn(input_file_pattern=eval_input_files,\r\n                             num_epochs=1,\r\n                             batch_size=args['batch_size'],\r\n                             label_variable=args['label_variable'])\r\n\r\n    feature_columns = [tf.feature_column.numeric_column(key='cosine_similarity')]\r\n\r\n    estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns, model_dir=model_dir)\r\n\r\n    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=args['train_max_steps'])\r\n\r\n    serving_input_receiver_fn = make_serving_input_fn(tf_transform_output)\r\n\r\n    exporter = tf.estimator.LatestExporter(name='model_export', serving_input_receiver_fn=serving_input_receiver_fn)\r\n\r\n    eval_spec = tf.estimator.EvalSpec(eval_input_fn, steps=None, exporters=[exporter], throttle_secs=150)\r\n\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n\r\n\r\nif __name__ == '__main__':\r\n    args = {\r\n        'tf_transform': './metadata',\r\n        'num_epochs': 10,\r\n        'batch_size': 1,\r\n        'label_variable': 'y',\r\n        'train_max_steps': 1000\r\n    }\r\n    train(args)\r\n```\r\n\r\n### Issue\r\nWhenever I run `train.py` it successfully\r\n\r\n * loads the training data    \r\n * builds the model  \r\n * trains until the first `Checkpoint`,\r\n\r\nbut always fails when it tries to restore from `Checkpoint` and\r\n   continue training with the following Error message:\r\n\r\n```python\r\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nKey transform/module/embeddings not found in checkpoint\r\n         [[node save/RestoreV2_1 (defined at /.../env/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.py:924) ]]\r\n```\r\n\r\nFrom what I understand it fails to restore parts of the `TF Hub` module graph used in the preprocessing step (`transform/module/embeddings`). Removing the `exporter` from `eval_spec = tf.estimator.EvalSpec(eval_input_fn, steps=None, exporters=[exporter], throttle_secs=150)` lets training complete successfully, but obviously doesn't export any `saved_model`. \r\n\r\n### TLDR\r\nHow do I use a `TF Hub` module in `tf-transform` preprocessing and apply those data transformations in a `serving` environment in conjunction with a trained model?\r\n\r\n### Appendix\r\n_requirements.txt_\r\n```\r\napache-beam[gcp]==2.11\r\ntensorflow-transform==0.13\r\ntensorflow==1.13.1\r\ntensorflow-hub==0.4.0\r\n```\r\n\r\nThanks a lot in advance!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/123", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/123/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/123/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/123/events", "html_url": "https://github.com/tensorflow/transform/issues/123", "id": 458047669, "node_id": "MDU6SXNzdWU0NTgwNDc2Njk=", "number": 123, "title": "TF=GPU 2.0.0b TF Transform missing AUTOTUNE on import", "user": {"login": "Ryandry1st", "id": 20748832, "node_id": "MDQ6VXNlcjIwNzQ4ODMy", "avatar_url": "https://avatars2.githubusercontent.com/u/20748832?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ryandry1st", "html_url": "https://github.com/Ryandry1st", "followers_url": "https://api.github.com/users/Ryandry1st/followers", "following_url": "https://api.github.com/users/Ryandry1st/following{/other_user}", "gists_url": "https://api.github.com/users/Ryandry1st/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ryandry1st/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ryandry1st/subscriptions", "organizations_url": "https://api.github.com/users/Ryandry1st/orgs", "repos_url": "https://api.github.com/users/Ryandry1st/repos", "events_url": "https://api.github.com/users/Ryandry1st/events{/privacy}", "received_events_url": "https://api.github.com/users/Ryandry1st/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2019-06-19T14:27:49Z", "updated_at": "2020-06-25T07:31:30Z", "closed_at": "2019-06-20T17:20:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): POSIX\r\n- TensorFlow version: 2.0.0b-gpu\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: \r\n- GPU model and memory: Tesla T4\r\n\r\n\r\n\r\n**Describe the problem**\r\nAttempted to use TFX, specifically TF Transform, however when importing TF Transform it throws the error that AUTOTUNE is unknown.\r\n\r\n`!pip install tensorflow_transform`\r\n`import tensorflow_transform as tft`\r\n\r\n**Any other info / logs**\r\nAttributeError: module 'tensorflow.python.data.experimental.ops.optimization' has no attribute 'AUTOTUNE'\r\nFor the full log see the attached file\r\n\r\n[TF_Transform_Import_Error.txt](https://github.com/tensorflow/tensorflow/files/3302615/TF_Transform_Import_Error.txt)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/122", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/122/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/122/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/122/events", "html_url": "https://github.com/tensorflow/transform/issues/122", "id": 457766133, "node_id": "MDU6SXNzdWU0NTc3NjYxMzM=", "number": 122, "title": "TF Transform RuntimeError: AssertionError [while running 'AnalyzeAndTransformDataset/TransformDataset/Transform']", "user": {"login": "WillianFuks", "id": 4665485, "node_id": "MDQ6VXNlcjQ2NjU0ODU=", "avatar_url": "https://avatars2.githubusercontent.com/u/4665485?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WillianFuks", "html_url": "https://github.com/WillianFuks", "followers_url": "https://api.github.com/users/WillianFuks/followers", "following_url": "https://api.github.com/users/WillianFuks/following{/other_user}", "gists_url": "https://api.github.com/users/WillianFuks/gists{/gist_id}", "starred_url": "https://api.github.com/users/WillianFuks/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WillianFuks/subscriptions", "organizations_url": "https://api.github.com/users/WillianFuks/orgs", "repos_url": "https://api.github.com/users/WillianFuks/repos", "events_url": "https://api.github.com/users/WillianFuks/events{/privacy}", "received_events_url": "https://api.github.com/users/WillianFuks/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2019-06-19T01:39:51Z", "updated_at": "2019-08-01T05:08:41Z", "closed_at": "2019-08-01T02:33:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Asked this question on SO, will try to also start a thread here to see if we can find what's going on:\r\n\r\nI'm working with the following code using tensorflow-transform:\r\n```\r\nimport tensorflow as tf\r\nimport apache_beam as beam\r\nimport tensorflow_transform as tft\r\nfrom tensorflow_transform.beam import impl as beam_impl\r\nfrom tensorflow_transform.coders import example_proto_coder\r\nfrom tensorflow_transform.tf_metadata import dataset_metadata\r\nfrom tensorflow_transform.tf_metadata import dataset_schema\r\nfrom tensorflow_transform.beam.tft_beam_io import transform_fn_io\r\nimport tempfile\r\n\r\n\r\nimport ast\r\nimport six\r\nimport apache_beam as beam\r\n# Beam Pipelines must receive a set of config options to set how it should run.\r\nfrom apache_beam.options.pipeline_options import PipelineOptions\r\n\r\nassert six.PY2\r\n\r\noptions = {\r\n    'runner': 'DirectRunner'\r\n}\r\n\r\npipeline_options = PipelineOptions(**options)\r\n\r\nRAW_DATA_SCHEMA = {\r\n    'customer_id': dataset_schema.ColumnSchema(tf.string, [], dataset_schema.ListColumnRepresentation())\r\n}\r\nRAW_DATA_METADATA = dataset_metadata.DatasetMetadata(dataset_schema.Schema(RAW_DATA_SCHEMA))\r\n\r\n\r\ndef preprocess_fn(dictrow):\r\n    return {\r\n        'customer_id': tft.string_to_int(dictrow['customer_id'], vocab_filename='vocab_result')\r\n    }\r\n\r\nworking_dir = tempfile.mkdtemp(dir='/tmp/')\r\n\r\nwith beam.Pipeline(options=pipeline_options) as pipeline:\r\n    with beam_impl.Context(tempfile.mkdtemp()):\r\n        raw_data = (\r\n            pipeline\r\n            | 'create' >> beam.Create([\r\n                {'customer_id': ['customer_0']},\r\n                {'customer_id': ['customer1', 'customer2']},\r\n                {'customer_id': ['customer_0']}\r\n            ])\r\n        )\r\n\r\n        raw_dataset = (raw_data, RAW_DATA_METADATA)\r\n        transformed_dataset, transform_fn = (\r\n            raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocess_fn))\r\n\r\n        transformed_data, transformed_metadata = transformed_dataset\r\n\r\n        OUTPUT_SCHEMA = {\r\n            'customer_id': dataset_schema.ColumnSchema(tf.int64, [], dataset_schema.ListColumnRepresentation())\r\n        }\r\n\r\n        _ = transformed_data | 'writing' >> beam.io.tfrecordio.WriteToTFRecord(\r\n            working_dir + '/tf', coder=example_proto_coder.ExampleProtoCoder(dataset_schema.Schema(OUTPUT_SCHEMA)))\r\n\r\n        pipeline.run().wait_until_finish()\r\n```\r\n\r\nBut it gives me the error:\r\n\r\n> tftrec/local/lib/python2.7/site-packages/tensorflow_transform/beam/impl.pyc in process(self, batch, saved_model_dir) 438 # This should remain true throughout the lifetime of this DoFn, regardless 439 # of whether or not self._graph_state was cached. --> 440 assert self._graph_state.saved_model_dir == saved_model_dir 441 442 yield self._handle_batch(batch)\r\n> \r\n> RuntimeError: AssertionError [while running 'AnalyzeAndTransformDataset/TransformDataset/Transform']\r\n\r\nI wonder what could be wrong. I tried printing self._graph_state.saved_model_dir and indeed it does change but not sure why this happens.\r\n\r\nRunning tensorflow==1.13.1, tensorflow-transform==0.13.0, apache_beam[gcp]==2.11 on Python2\r\n\r\nTesting for transform version 0.8 works (but still throws this error at times)\r\n\r\nIt seems to be an issue related to the final writing tfrecord process (when I remove it the error seems to go away)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/121", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/121/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/121/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/121/events", "html_url": "https://github.com/tensorflow/transform/issues/121", "id": 452749424, "node_id": "MDU6SXNzdWU0NTI3NDk0MjQ=", "number": 121, "title": "incorrect variance result in scale_to_z_score for tf.SparseTensor when elementwise=True", "user": {"login": "yanyachen", "id": 6893682, "node_id": "MDQ6VXNlcjY4OTM2ODI=", "avatar_url": "https://avatars3.githubusercontent.com/u/6893682?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yanyachen", "html_url": "https://github.com/yanyachen", "followers_url": "https://api.github.com/users/yanyachen/followers", "following_url": "https://api.github.com/users/yanyachen/following{/other_user}", "gists_url": "https://api.github.com/users/yanyachen/gists{/gist_id}", "starred_url": "https://api.github.com/users/yanyachen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yanyachen/subscriptions", "organizations_url": "https://api.github.com/users/yanyachen/orgs", "repos_url": "https://api.github.com/users/yanyachen/repos", "events_url": "https://api.github.com/users/yanyachen/events{/privacy}", "received_events_url": "https://api.github.com/users/yanyachen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-06-05T22:42:25Z", "updated_at": "2019-06-27T04:59:00Z", "closed_at": "2019-06-18T21:11:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "I think this part of the code needs to be updated: https://github.com/tensorflow/transform/blob/master/tensorflow_transform/tf_utils.py#L302-L303\r\n\r\nSince the `x_minus_mean ` is 1-D tensor when the `x` is `tf.sparse.SparseTensor`, the `tf.reduce_sum` will not return expected variance vector but a scalar.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/120", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/120/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/120/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/120/events", "html_url": "https://github.com/tensorflow/transform/issues/120", "id": 444140443, "node_id": "MDU6SXNzdWU0NDQxNDA0NDM=", "number": 120, "title": "SavedModel exported from TFT still contains references to TFT assets", "user": {"login": "cyc", "id": 1501289, "node_id": "MDQ6VXNlcjE1MDEyODk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1501289?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cyc", "html_url": "https://github.com/cyc", "followers_url": "https://api.github.com/users/cyc/followers", "following_url": "https://api.github.com/users/cyc/following{/other_user}", "gists_url": "https://api.github.com/users/cyc/gists{/gist_id}", "starred_url": "https://api.github.com/users/cyc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cyc/subscriptions", "organizations_url": "https://api.github.com/users/cyc/orgs", "repos_url": "https://api.github.com/users/cyc/repos", "events_url": "https://api.github.com/users/cyc/events{/privacy}", "received_events_url": "https://api.github.com/users/cyc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2019-05-14T21:48:17Z", "updated_at": "2019-09-19T00:05:54Z", "closed_at": "2019-08-05T05:37:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "In order to reproduce this, you will need a dataset with some string features, and a TFT preprocessing_fn with `tft.compute_and_apply_vocabulary`. When you export the SavedModel as shown in [census_example.py](https://github.com/tensorflow/transform/blob/master/examples/census_example.py#L300-L307), the resulting SavedModel `${SAVED_MODEL_DIR}/saved_model.pb` will contain URL references to the `${TFT_DIR}/transform_fn/assets/${FEATURE_NAME}` file instead of the `${SAVED_MODEL_DIR}/assets/${FEATURE_NAME}` file. This seems to violate the stated design goal that SavedModels should be a hermetic representation of the resulting model.\r\n\r\nIn particular, this can cause problems if TFT and TF model training output to different GCS buckets and consumers of the resulting TF SavedModel have read permissions to only the TF model training bucket but not the TFT bucket. Or if there are different data retention policies for the two buckets and once the assets in the TFT bucket expire the SavedModel will no longer be initializable. It seems to me that once you export the SavedModel it should be self-contained and should no longer have any references to the TFT graph that helped produce it.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/119", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/119/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/119/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/119/events", "html_url": "https://github.com/tensorflow/transform/issues/119", "id": 442743155, "node_id": "MDU6SXNzdWU0NDI3NDMxNTU=", "number": 119, "title": "Are there transforms for Image tasks like image classification or object detection?", "user": {"login": "aaronlelevier", "id": 5514112, "node_id": "MDQ6VXNlcjU1MTQxMTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/5514112?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaronlelevier", "html_url": "https://github.com/aaronlelevier", "followers_url": "https://api.github.com/users/aaronlelevier/followers", "following_url": "https://api.github.com/users/aaronlelevier/following{/other_user}", "gists_url": "https://api.github.com/users/aaronlelevier/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaronlelevier/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaronlelevier/subscriptions", "organizations_url": "https://api.github.com/users/aaronlelevier/orgs", "repos_url": "https://api.github.com/users/aaronlelevier/repos", "events_url": "https://api.github.com/users/aaronlelevier/events{/privacy}", "received_events_url": "https://api.github.com/users/aaronlelevier/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2019-05-10T14:18:53Z", "updated_at": "2019-10-16T18:39:51Z", "closed_at": "2019-05-13T05:08:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nAre there transforms for Image tasks like image classification or object detection?\r\n\r\nI'm would like to use `tf.transform` for something very simple to learn and understand the library. How would I do something like normalize an image input Tensor for example that has pixel values of 0-255 to 0-1 for example in `tf.transform`? \r\n\r\nI have been trying to do an MNIST example. My code runs, but I have an empty `preprocessing_fn` here:\r\n\r\nhttps://github.com/aaronlelevier/transform/blob/try_examples/examples/aaron_simple_example.py#L191\r\n\r\nI am doing a `normalize` 0-1 in `_make_training_input_fn`, but I'm pretty sure that I need to move that to the `preprocessing_fn` so the `normalize` becomes part of the serving graph. \r\n\r\nWhen looking at the value of `inputs` in my current `preprocessing_fn` it's:\r\n\r\n```\r\n{u'image': <tf.Tensor 'inputs/inputs/image_copy:0' shape=(?,) dtype=string>, u'label': <tf.Tensor 'inputs/inputs/label_copy:0' shape=(?,) dtype=int64>}\r\n```\r\n\r\nI'm just not sure if I can do a `tf.transform` here using `tft.scale_to_0_1` or if I need to do more Beam Pipeline steps before running the `preprocessing_fn`. \r\n\r\nIt seems like it needs to work with `tft.coders.ExampleProtoCoder(RAW_DATA_METADATA.schema)`.\r\n\r\nI'm a little lost. Really enjoying `tf.Transform`. Any help is appreciated. Maybe some of this is built in to `tf.Tranform` and I just haven't found it. \r\n\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/118", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/118/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/118/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/118/events", "html_url": "https://github.com/tensorflow/transform/issues/118", "id": 442345376, "node_id": "MDU6SXNzdWU0NDIzNDUzNzY=", "number": 118, "title": "\"bad inputs\" error very challenging to debug", "user": {"login": "cyc", "id": 1501289, "node_id": "MDQ6VXNlcjE1MDEyODk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1501289?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cyc", "html_url": "https://github.com/cyc", "followers_url": "https://api.github.com/users/cyc/followers", "following_url": "https://api.github.com/users/cyc/following{/other_user}", "gists_url": "https://api.github.com/users/cyc/gists{/gist_id}", "starred_url": "https://api.github.com/users/cyc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cyc/subscriptions", "organizations_url": "https://api.github.com/users/cyc/orgs", "repos_url": "https://api.github.com/users/cyc/repos", "events_url": "https://api.github.com/users/cyc/events{/privacy}", "received_events_url": "https://api.github.com/users/cyc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-05-09T17:21:00Z", "updated_at": "2019-05-20T20:11:42Z", "closed_at": "2019-05-20T20:11:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Are there any tips for how to properly debug a \"[bad inputs](https://github.com/tensorflow/transform/blob/9aa8819a415fb7d0473323043d8d17f609a18cc7/tensorflow_transform/beam/impl.py#L396)\" error? This seems to happen fairly frequently, especially when working with sparse tensors (I most commonly see it when working with sparse-to-dense conversions).\r\n\r\nThe problem is that this error just dumps a single row of data without any context for what caused the error. There is a [TF error log](https://github.com/tensorflow/transform/blob/9aa8819a415fb7d0473323043d8d17f609a18cc7/tensorflow_transform/beam/impl.py#L393-L395) that gets printed right before the exception is raised, which provides marginally more context, but it seems like I am only able to see it when using `DirectRunner`. When I run this with `DataflowRunner` the TF error is nowhere to be found in the logs.\r\n\r\nWhat can be done to make \"bad inputs\" easier to debug?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/117", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/117/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/117/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/117/events", "html_url": "https://github.com/tensorflow/transform/issues/117", "id": 439790445, "node_id": "MDU6SXNzdWU0Mzk3OTA0NDU=", "number": 117, "title": "metadata_io.write_metadata is a lossy encoding", "user": {"login": "cyc", "id": 1501289, "node_id": "MDQ6VXNlcjE1MDEyODk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1501289?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cyc", "html_url": "https://github.com/cyc", "followers_url": "https://api.github.com/users/cyc/followers", "following_url": "https://api.github.com/users/cyc/following{/other_user}", "gists_url": "https://api.github.com/users/cyc/gists{/gist_id}", "starred_url": "https://api.github.com/users/cyc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cyc/subscriptions", "organizations_url": "https://api.github.com/users/cyc/orgs", "repos_url": "https://api.github.com/users/cyc/repos", "events_url": "https://api.github.com/users/cyc/events{/privacy}", "received_events_url": "https://api.github.com/users/cyc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-05-02T21:11:14Z", "updated_at": "2019-05-06T23:26:51Z", "closed_at": "2019-05-06T23:26:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am not sure if this is intentional, but I have noticed this pattern several times in the codebase and I'm not sure why (it also happens in `metadata_io.read_metadata`).\r\n\r\n```\r\nschema_proto = schema_utils.schema_from_feature_spec(\r\n      metadata.schema.as_feature_spec(), metadata.schema.domains())\r\n```\r\n\r\nConverting to feature spec is a lossy transformation, and it loses metadata from the underlying schema proto, such as which features should be available at serving time or not. Why not just write the schema proto that's already in the `DatasetMetadata` object?\r\n\r\nFor context: I use TFT to transform some labels into derived labels and derived label weights. At training time I want to use the metadata produced from TFT to determine which input \"features\" I can train with and which I should filter out from training by using the `Schema` environment fields. This doesn't seem possible with the way that TFT handles reading and writing metadata at the moment.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/115", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/115/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/115/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/115/events", "html_url": "https://github.com/tensorflow/transform/issues/115", "id": 439058294, "node_id": "MDU6SXNzdWU0MzkwNTgyOTQ=", "number": 115, "title": "Can AnalyzeDataset/TransformDataset take metadata as a Singleton side-input?", "user": {"login": "cyc", "id": 1501289, "node_id": "MDQ6VXNlcjE1MDEyODk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1501289?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cyc", "html_url": "https://github.com/cyc", "followers_url": "https://api.github.com/users/cyc/followers", "following_url": "https://api.github.com/users/cyc/following{/other_user}", "gists_url": "https://api.github.com/users/cyc/gists{/gist_id}", "starred_url": "https://api.github.com/users/cyc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cyc/subscriptions", "organizations_url": "https://api.github.com/users/cyc/orgs", "repos_url": "https://api.github.com/users/cyc/repos", "events_url": "https://api.github.com/users/cyc/events{/privacy}", "received_events_url": "https://api.github.com/users/cyc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "gowthamkpr", "id": 47574994, "node_id": "MDQ6VXNlcjQ3NTc0OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/47574994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gowthamkpr", "html_url": "https://github.com/gowthamkpr", "followers_url": "https://api.github.com/users/gowthamkpr/followers", "following_url": "https://api.github.com/users/gowthamkpr/following{/other_user}", "gists_url": "https://api.github.com/users/gowthamkpr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gowthamkpr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gowthamkpr/subscriptions", "organizations_url": "https://api.github.com/users/gowthamkpr/orgs", "repos_url": "https://api.github.com/users/gowthamkpr/repos", "events_url": "https://api.github.com/users/gowthamkpr/events{/privacy}", "received_events_url": "https://api.github.com/users/gowthamkpr/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-05-01T03:31:56Z", "updated_at": "2019-05-03T18:59:55Z", "closed_at": "2019-05-03T18:59:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm currently struggling with an issue where I would like to pass in the input data metadata as a side-input to AnalyzeDataset or TransformDataset instead of as a fully-materialized DatasetMetadata instance. Is this possible to do?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/114", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/114/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/114/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/114/events", "html_url": "https://github.com/tensorflow/transform/issues/114", "id": 436833995, "node_id": "MDU6SXNzdWU0MzY4MzM5OTU=", "number": 114, "title": "Using Tensorflow Transform without using Tensorflow for training", "user": {"login": "srirampmalladi", "id": 452371, "node_id": "MDQ6VXNlcjQ1MjM3MQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/452371?v=4", "gravatar_id": "", "url": "https://api.github.com/users/srirampmalladi", "html_url": "https://github.com/srirampmalladi", "followers_url": "https://api.github.com/users/srirampmalladi/followers", "following_url": "https://api.github.com/users/srirampmalladi/following{/other_user}", "gists_url": "https://api.github.com/users/srirampmalladi/gists{/gist_id}", "starred_url": "https://api.github.com/users/srirampmalladi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/srirampmalladi/subscriptions", "organizations_url": "https://api.github.com/users/srirampmalladi/orgs", "repos_url": "https://api.github.com/users/srirampmalladi/repos", "events_url": "https://api.github.com/users/srirampmalladi/events{/privacy}", "received_events_url": "https://api.github.com/users/srirampmalladi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-04-24T18:02:48Z", "updated_at": "2019-05-06T22:43:55Z", "closed_at": "2019-05-06T22:43:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "We would like to use Tensorflow Transform for our Feature Transformation step but use XGBoost to actually train our model. We ran TF transform on some tf.Examples that we\u2019ve generated without performing any model training. When we inspected the resulting transformation graph, we noticed that there were three placeholders for each feature whose names were: \r\n\r\n- \u201cinputs/feature-name/shape\u201d\r\n- \u201cinputs/feature-name/values\u201d\r\n- \u201cinputs/feature-name/indices\u201d\r\n\r\nWhen we run the same pipeline with a Tensorflow Training training component following the transformation, an additional placeholder is present in the resulting graph called:\r\n\r\n- \u201cinput_example_tensor\u201d\r\n\r\n\r\nThis placeholder is how we would feed tf.Examples into the combined transformation and prediction graph. However, it is unclear how we would feed our tf.Examples into just the transformation graph which does not have this placeholder. Is there a recommended strategy for feeding untransformed tf.Examples into a Tensorflow Transform graph, without a Tensorflow\t model involved, to get transformed features to input into our XGBoost model?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/111", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/111/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/111/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/111/events", "html_url": "https://github.com/tensorflow/transform/issues/111", "id": 431505174, "node_id": "MDU6SXNzdWU0MzE1MDUxNzQ=", "number": 111, "title": "BoolDomain not supported in tf_metadata.schema_utils._set_domain", "user": {"login": "TimSmole", "id": 3829086, "node_id": "MDQ6VXNlcjM4MjkwODY=", "avatar_url": "https://avatars2.githubusercontent.com/u/3829086?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TimSmole", "html_url": "https://github.com/TimSmole", "followers_url": "https://api.github.com/users/TimSmole/followers", "following_url": "https://api.github.com/users/TimSmole/following{/other_user}", "gists_url": "https://api.github.com/users/TimSmole/gists{/gist_id}", "starred_url": "https://api.github.com/users/TimSmole/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TimSmole/subscriptions", "organizations_url": "https://api.github.com/users/TimSmole/orgs", "repos_url": "https://api.github.com/users/TimSmole/repos", "events_url": "https://api.github.com/users/TimSmole/events{/privacy}", "received_events_url": "https://api.github.com/users/TimSmole/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-10T13:30:51Z", "updated_at": "2019-05-06T23:28:34Z", "closed_at": "2019-05-06T23:28:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am having trouble reading schema a simple schema that contains only one boolean feature. The schema was generated with `tfdv.infer_schema` function and saved to file using `tfdv.write_schema_text` function. The file looks like this:\r\n\r\n```\r\nfeature {\r\n  name: \"test\"\r\n  value_count {\r\n    min: 1\r\n    max: 1\r\n  }\r\n  type: INT\r\n  bool_domain {\r\n  }\r\n  presence {\r\n    min_fraction: 1.0\r\n    min_count: 1\r\n  }\r\n}\r\n```\r\n\r\nWhen I try to read it in the following way:\r\n\r\n```\r\nfrom tensorflow_transform.tf_metadata import metadata_io\r\n\r\nmetadata_io.read_metadata(\".\") # \".\" is path to directory where schema.pbtxt is stored\r\n```\r\n\r\nI get the following ValueError:\r\n\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-39-68264a3c7170> in <module>\r\n      9 \r\n     10 from tensorflow_transform.tf_metadata import metadata_io\r\n---> 11 metadata_io.read_metadata(\".\")\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_transform/tf_metadata/metadata_io.py in read_metadata(path)\r\n     49   features_spec, domains = schema_utils.schema_as_feature_spec(schema_proto)\r\n     50   return dataset_metadata.DatasetMetadata(\r\n---> 51       dataset_schema.from_feature_spec(features_spec, domains))\r\n     52 \r\n     53 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_transform/tf_metadata/dataset_schema.py in from_feature_spec(feature_spec, domains)\r\n    151   column_schemas = {name: (domains.get(name), spec)\r\n    152                     for name, spec in feature_spec.items()}\r\n--> 153   return Schema(column_schemas)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_transform/tf_metadata/dataset_schema.py in __init__(self, column_schemas)\r\n     45                if domain is not None}\r\n     46     self._schema_proto = schema_utils.schema_from_feature_spec(\r\n---> 47         feature_spec, domains)\r\n     48 \r\n     49   def __eq__(self, other):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_transform/tf_metadata/schema_utils.py in schema_from_feature_spec(feature_spec, domains)\r\n     69     else:\r\n     70       result.feature.add().CopyFrom(\r\n---> 71           _feature_from_feature_spec(spec, name, domains))\r\n     72   return result\r\n     73 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_transform/tf_metadata/schema_utils.py in _feature_from_feature_spec(spec, name, domains)\r\n    127 \r\n    128   _set_type(name, feature, spec.dtype)\r\n--> 129   _set_domain(name, feature, domains.get(name))\r\n    130   return feature\r\n    131 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_transform/tf_metadata/schema_utils.py in _set_domain(name, feature, domain)\r\n    157   else:\r\n    158     raise ValueError(\r\n--> 159         'Feature \"{}\" has invalid domain {}'.format(name, domain))\r\n    160 \r\n    161 \r\n\r\nValueError: Feature \"test\" has invalid domain \r\n\r\n```\r\n\r\nDebugging shows that [_set_domain](https://github.com/tensorflow/transform/blob/master/tensorflow_transform/tf_metadata/schema_utils.py#L146) function supports only IntDomain, StringDomain and FloatDomain, but not BoolDomain and other (StructDomain, NaturalLanguageDomain, ImageDomain, MIDDomain, URLDomain, TimeDomain). \r\n\r\nIs there a reason for this? Is this still work in progress, should it be considered as a bug or am I missing something?\r\n\r\nI am using:\r\n\r\n> tensorflow-data-validation==0.13.1\r\n> tensorflow-transform==0.13.0\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/110", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/110/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/110/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/110/events", "html_url": "https://github.com/tensorflow/transform/issues/110", "id": 431352738, "node_id": "MDU6SXNzdWU0MzEzNTI3Mzg=", "number": 110, "title": "Does apply_buckets_with_interpolation support higher-dimensional inputs?", "user": {"login": "cyc", "id": 1501289, "node_id": "MDQ6VXNlcjE1MDEyODk=", "avatar_url": "https://avatars0.githubusercontent.com/u/1501289?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cyc", "html_url": "https://github.com/cyc", "followers_url": "https://api.github.com/users/cyc/followers", "following_url": "https://api.github.com/users/cyc/following{/other_user}", "gists_url": "https://api.github.com/users/cyc/gists{/gist_id}", "starred_url": "https://api.github.com/users/cyc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cyc/subscriptions", "organizations_url": "https://api.github.com/users/cyc/orgs", "repos_url": "https://api.github.com/users/cyc/repos", "events_url": "https://api.github.com/users/cyc/events{/privacy}", "received_events_url": "https://api.github.com/users/cyc/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2019-04-10T07:45:39Z", "updated_at": "2019-06-24T22:02:30Z", "closed_at": "2019-06-24T22:02:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "`tft.apply_buckets_with_interpolation` is a super useful transformation for training neural networks. However, it would be best if I could concatenate all my dense features together and then compute `tft.quantiles` and `tft.apply_buckets_with_interpolation` as one transformation. Is this supported?\r\n\r\nAlso, to answer the question in the comments of the code (`# TODO(b/127971746): Consider if/how SparseTensor input should be handled.`), my preference would be to have the option to impute with the median (that is, 0.5).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/109", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/109/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/109/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/109/events", "html_url": "https://github.com/tensorflow/transform/issues/109", "id": 430548525, "node_id": "MDU6SXNzdWU0MzA1NDg1MjU=", "number": 109, "title": "Boosted trees fail to run with apply_saved_model api", "user": {"login": "rajkiran2190", "id": 12685375, "node_id": "MDQ6VXNlcjEyNjg1Mzc1", "avatar_url": "https://avatars0.githubusercontent.com/u/12685375?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rajkiran2190", "html_url": "https://github.com/rajkiran2190", "followers_url": "https://api.github.com/users/rajkiran2190/followers", "following_url": "https://api.github.com/users/rajkiran2190/following{/other_user}", "gists_url": "https://api.github.com/users/rajkiran2190/gists{/gist_id}", "starred_url": "https://api.github.com/users/rajkiran2190/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rajkiran2190/subscriptions", "organizations_url": "https://api.github.com/users/rajkiran2190/orgs", "repos_url": "https://api.github.com/users/rajkiran2190/repos", "events_url": "https://api.github.com/users/rajkiran2190/events{/privacy}", "received_events_url": "https://api.github.com/users/rajkiran2190/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmothukuru", "id": 48206667, "node_id": "MDQ6VXNlcjQ4MjA2NjY3", "avatar_url": "https://avatars3.githubusercontent.com/u/48206667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmothukuru", "html_url": "https://github.com/rmothukuru", "followers_url": "https://api.github.com/users/rmothukuru/followers", "following_url": "https://api.github.com/users/rmothukuru/following{/other_user}", "gists_url": "https://api.github.com/users/rmothukuru/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmothukuru/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmothukuru/subscriptions", "organizations_url": "https://api.github.com/users/rmothukuru/orgs", "repos_url": "https://api.github.com/users/rmothukuru/repos", "events_url": "https://api.github.com/users/rmothukuru/events{/privacy}", "received_events_url": "https://api.github.com/users/rmothukuru/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-04-08T16:36:51Z", "updated_at": "2019-07-29T09:49:41Z", "closed_at": "2019-07-29T09:49:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "```\r\nprobabilities, predicted_class = apply_saved_model(model_dir='/Users/raj.katakam/Projects/vega/testing/ml_vega/GBTEstimatorBuilder__test/1', inputs={\"features\": [element['features']]}, tags=['serve'], signature_name=\"predict\", output_keys_in_signature=['probabilities', 'class_ids'])\r\n  File \"/Users/raj.katakam/Projects/vega/testing/ml_vega/testing-venv/lib/python2.7/site-packages/tensorflow_transform/pretrained_models.py\", line 133, in apply_saved_model\r\n    returned_elements = tf.import_graph_def(\r\n  File \"/Users/raj.katakam/Projects/vega/testing/ml_vega/testing-venv/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/Users/raj.katakam/Projects/vega/testing/ml_vega/testing-venv/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\r\n    _ProcessNewOps(graph)\r\n  File \"/Users/raj.katakam/Projects/vega/testing/ml_vega/testing-venv/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 235, in _ProcessNewOps\r\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\r\n  File \"/Users/raj.katakam/Projects/vega/testing/ml_vega/testing-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3433, in _add_new_tf_operations\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/Users/raj.katakam/Projects/vega/testing/ml_vega/testing-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3325, in _create_op_from_tf_operation\r\n    ret = Operation(c_op, self)\r\n  File \"/Users/raj.katakam/Projects/vega/testing/ml_vega/testing-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nNotFoundError (see above for traceback): Container localhost does not exist. (Could not find resource: localhost/boosted_trees/)\r\n\t [[node import/boosted_trees/BoostedTreesPredict (defined at /Users/raj.katakam/Projects/vega/testing/ml_vega/testing-venv/lib/python2.7/site-packages/tensorflow_transform/pretrained_models.py:133) ]]\r\n```\r\nI see the above error when trying to load an estimator tf.estimator.BoostedTreesClassifier().\r\nIt works fine with tf.contrib.predictor.from_saved_model", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/107", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/107/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/107/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/107/events", "html_url": "https://github.com/tensorflow/transform/issues/107", "id": 426824376, "node_id": "MDU6SXNzdWU0MjY4MjQzNzY=", "number": 107, "title": "Implementing word2vec using TF Transform", "user": {"login": "xennygrimmato", "id": 4271899, "node_id": "MDQ6VXNlcjQyNzE4OTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/4271899?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xennygrimmato", "html_url": "https://github.com/xennygrimmato", "followers_url": "https://api.github.com/users/xennygrimmato/followers", "following_url": "https://api.github.com/users/xennygrimmato/following{/other_user}", "gists_url": "https://api.github.com/users/xennygrimmato/gists{/gist_id}", "starred_url": "https://api.github.com/users/xennygrimmato/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xennygrimmato/subscriptions", "organizations_url": "https://api.github.com/users/xennygrimmato/orgs", "repos_url": "https://api.github.com/users/xennygrimmato/repos", "events_url": "https://api.github.com/users/xennygrimmato/events{/privacy}", "received_events_url": "https://api.github.com/users/xennygrimmato/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2019-03-29T05:34:20Z", "updated_at": "2019-07-19T16:54:56Z", "closed_at": "2019-07-19T16:54:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Usecase**:\r\n- Given a PCollection of sentences, create word embeddings using word2vec (skip-gram model)\r\n\r\n**Questions**:\r\n1. Is there an existing Beam implementation that the developers and contributors of TF Transform can share that serves my purpose?\r\n2. If not, is there some example that I can refer to so that I can implement it myself? Something that takes inputs from a PCollection and passes it on to a Tensorflow model.\r\n\r\nI would like to understand thoroughly how I can operate with both Beam and Tensorflow.\r\n\r\nApologies in advance if these seem to be novice questions, but I would really like to implement this in the best possible way.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/105", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/105/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/105/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/105/events", "html_url": "https://github.com/tensorflow/transform/issues/105", "id": 419997535, "node_id": "MDU6SXNzdWU0MTk5OTc1MzU=", "number": 105, "title": "when does spark runner release\uff1f", "user": {"login": "zhaiyuyong", "id": 4199724, "node_id": "MDQ6VXNlcjQxOTk3MjQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/4199724?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhaiyuyong", "html_url": "https://github.com/zhaiyuyong", "followers_url": "https://api.github.com/users/zhaiyuyong/followers", "following_url": "https://api.github.com/users/zhaiyuyong/following{/other_user}", "gists_url": "https://api.github.com/users/zhaiyuyong/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhaiyuyong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhaiyuyong/subscriptions", "organizations_url": "https://api.github.com/users/zhaiyuyong/orgs", "repos_url": "https://api.github.com/users/zhaiyuyong/repos", "events_url": "https://api.github.com/users/zhaiyuyong/events{/privacy}", "received_events_url": "https://api.github.com/users/zhaiyuyong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1270083523, "node_id": "MDU6TGFiZWwxMjcwMDgzNTIz", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:others", "name": "type:others", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2019-03-12T13:51:20Z", "updated_at": "2019-03-12T18:26:01Z", "closed_at": "2019-03-12T18:26:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://qcon.ai/system/files/presentation-slides/simplifying_ml_workflows_with_apache_beam.pdf", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/104", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/104/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/104/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/104/events", "html_url": "https://github.com/tensorflow/transform/issues/104", "id": 419914794, "node_id": "MDU6SXNzdWU0MTk5MTQ3OTQ=", "number": 104, "title": "No module named 'tensorflow.contrib.proto'", "user": {"login": "manuzhang", "id": 1191767, "node_id": "MDQ6VXNlcjExOTE3Njc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1191767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manuzhang", "html_url": "https://github.com/manuzhang", "followers_url": "https://api.github.com/users/manuzhang/followers", "following_url": "https://api.github.com/users/manuzhang/following{/other_user}", "gists_url": "https://api.github.com/users/manuzhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/manuzhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manuzhang/subscriptions", "organizations_url": "https://api.github.com/users/manuzhang/orgs", "repos_url": "https://api.github.com/users/manuzhang/repos", "events_url": "https://api.github.com/users/manuzhang/events{/privacy}", "received_events_url": "https://api.github.com/users/manuzhang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-12T10:40:16Z", "updated_at": "2019-03-12T18:29:07Z", "closed_at": "2019-03-12T18:29:07Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm trying out the [simple example](https://github.com/tensorflow/transform/blob/master/examples/simple_example.py) with tensorflow-transform 0.13.0 and tensorflow 1.7. It seems a newer tensorflow version is required.\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-2-789161ab3248> in <module>\r\n      9 \r\n     10 import tensorflow as tf\r\n---> 11 import tensorflow_transform as tft\r\n     12 import tensorflow_transform.beam.impl as tft_beam\r\n     13 from tensorflow_transform.tf_metadata import dataset_metadata\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_transform/__init__.py in <module>\r\n     17 # pylint: disable=wildcard-import\r\n     18 from tensorflow_transform import coders\r\n---> 19 from tensorflow_transform.analyzers import *\r\n     20 from tensorflow_transform.api import apply_function\r\n     21 from tensorflow_transform.inspect_preprocessing_fn import *\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_transform/analyzers.py in <module>\r\n     37 from tensorflow_transform import analyzer_nodes\r\n     38 from tensorflow_transform import nodes\r\n---> 39 from tensorflow_transform import tf_utils\r\n     40 \r\n     41 from tensorflow.contrib.boosted_trees.python.ops import quantile_ops\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow_transform/tf_utils.py in <module>\r\n     22 import tensorflow as tf\r\n     23 \r\n---> 24 from tensorflow.contrib.proto.python.ops import encode_proto_op\r\n     25 \r\n     26 _FLOATING_NAN = float('nan')\r\n\r\nModuleNotFoundError: No module named 'tensorflow.contrib.proto'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/103", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/103/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/103/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/103/events", "html_url": "https://github.com/tensorflow/transform/issues/103", "id": 419442533, "node_id": "MDU6SXNzdWU0MTk0NDI1MzM=", "number": 103, "title": "Advanced transformers", "user": {"login": "HugoDLopes", "id": 16132356, "node_id": "MDQ6VXNlcjE2MTMyMzU2", "avatar_url": "https://avatars0.githubusercontent.com/u/16132356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HugoDLopes", "html_url": "https://github.com/HugoDLopes", "followers_url": "https://api.github.com/users/HugoDLopes/followers", "following_url": "https://api.github.com/users/HugoDLopes/following{/other_user}", "gists_url": "https://api.github.com/users/HugoDLopes/gists{/gist_id}", "starred_url": "https://api.github.com/users/HugoDLopes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HugoDLopes/subscriptions", "organizations_url": "https://api.github.com/users/HugoDLopes/orgs", "repos_url": "https://api.github.com/users/HugoDLopes/repos", "events_url": "https://api.github.com/users/HugoDLopes/events{/privacy}", "received_events_url": "https://api.github.com/users/HugoDLopes/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-03-11T12:25:13Z", "updated_at": "2020-02-03T15:45:31Z", "closed_at": "2019-03-26T17:13:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, it's not still clear for me if the TFT can scale for more complex transformers. For instance:\r\n* Missing Value Imputation\r\n* Outliers detection and removal\r\n\r\nIf it is possible, what is the recommended way to proceed? Implement the above transformers using the core tft functions? \r\n\r\nThanks for the explanation. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/102", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/102/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/102/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/102/events", "html_url": "https://github.com/tensorflow/transform/issues/102", "id": 419130178, "node_id": "MDU6SXNzdWU0MTkxMzAxNzg=", "number": 102, "title": "Can't stage 0.12.0 or 0.13.0 for Beam/Dataflow usage due to missing pyarrow 0.11.1 source release", "user": {"login": "ryan-williams", "id": 465045, "node_id": "MDQ6VXNlcjQ2NTA0NQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/465045?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ryan-williams", "html_url": "https://github.com/ryan-williams", "followers_url": "https://api.github.com/users/ryan-williams/followers", "following_url": "https://api.github.com/users/ryan-williams/following{/other_user}", "gists_url": "https://api.github.com/users/ryan-williams/gists{/gist_id}", "starred_url": "https://api.github.com/users/ryan-williams/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ryan-williams/subscriptions", "organizations_url": "https://api.github.com/users/ryan-williams/orgs", "repos_url": "https://api.github.com/users/ryan-williams/repos", "events_url": "https://api.github.com/users/ryan-williams/events{/privacy}", "received_events_url": "https://api.github.com/users/ryan-williams/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-03-10T00:15:35Z", "updated_at": "2019-03-14T17:58:30Z", "closed_at": "2019-03-14T17:38:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "TFT 0.12.0 and 0.13.0 depend on Beam 2.10.0 and 2.11.0, resp., which both [depend on pyarrow 0.11.1](https://github.com/apache/beam/blob/v2.11.0/sdks/python/setup.py#L120).\r\n\r\nWhen staging TFT for use on Dataflow worker nodes:\r\n\r\n```\r\n%%writefile requirements.txt\r\ntensorflow-transform==0.13.0\r\n```\r\n\r\nBeam attempts to install TFT [source artifacts](https://github.com/apache/beam/blob/v2.11.0/sdks/python/apache_beam/runners/portability/stager.py#L423), but [pyarrow 0.11.1 sources aren't on pypi](https://github.com/apache/arrow/issues/3855), and it fails.\r\n\r\nIs this a known issue?\r\n\r\nxref: [BEAM-6765](https://issues.apache.org/jira/browse/BEAM-6765)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/98", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/98/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/98/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/98/events", "html_url": "https://github.com/tensorflow/transform/issues/98", "id": 406504046, "node_id": "MDU6SXNzdWU0MDY1MDQwNDY=", "number": 98, "title": "quatile_ops is from tf.contrib and explicitly loading is required in model serving", "user": {"login": "daikeshi", "id": 475945, "node_id": "MDQ6VXNlcjQ3NTk0NQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/475945?v=4", "gravatar_id": "", "url": "https://api.github.com/users/daikeshi", "html_url": "https://github.com/daikeshi", "followers_url": "https://api.github.com/users/daikeshi/followers", "following_url": "https://api.github.com/users/daikeshi/following{/other_user}", "gists_url": "https://api.github.com/users/daikeshi/gists{/gist_id}", "starred_url": "https://api.github.com/users/daikeshi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/daikeshi/subscriptions", "organizations_url": "https://api.github.com/users/daikeshi/orgs", "repos_url": "https://api.github.com/users/daikeshi/repos", "events_url": "https://api.github.com/users/daikeshi/events{/privacy}", "received_events_url": "https://api.github.com/users/daikeshi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2019-02-04T20:25:06Z", "updated_at": "2019-12-11T15:49:07Z", "closed_at": "2019-12-11T15:49:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "When we use `bucketize` transformation, it calls `quatile_ops` from `tensorflow.contrib.boosted_trees.python.ops` module.  Since it's from `tf.contrib` module, We have to explicitly load the shared library during the model serving. \r\n\r\nIt's probably OK in python as we only need to add an extra `import` statement. However, we are doing model serving in JVM, in java we'll have to find the path to the shared object file `_boosted_trees_ops.so` and explicitly load it using `TensorFlow.loadLibrary(\"/path/to/_boosted_trees_ops.so\")`. This is really annoying since the `.so` file is system dependent.  \r\n\r\nTFT is officially supported in model serving and one of the biggest benefits of using TFT is to simplify the model serving. We wonder if you guys consider moving `quatile_ops` into the standard tensorflow lib, so we don't need to explicitly locate and load the share library file when we are serving the model in JVM.\r\n\r\nThanks a lot!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/97", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/97/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/97/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/97/events", "html_url": "https://github.com/tensorflow/transform/issues/97", "id": 400933742, "node_id": "MDU6SXNzdWU0MDA5MzM3NDI=", "number": 97, "title": "Error when dataset_schema.FixedColumnRepresentation has default_value == 0", "user": {"login": "AdrianLsk", "id": 4333307, "node_id": "MDQ6VXNlcjQzMzMzMDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/4333307?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AdrianLsk", "html_url": "https://github.com/AdrianLsk", "followers_url": "https://api.github.com/users/AdrianLsk/followers", "following_url": "https://api.github.com/users/AdrianLsk/following{/other_user}", "gists_url": "https://api.github.com/users/AdrianLsk/gists{/gist_id}", "starred_url": "https://api.github.com/users/AdrianLsk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AdrianLsk/subscriptions", "organizations_url": "https://api.github.com/users/AdrianLsk/orgs", "repos_url": "https://api.github.com/users/AdrianLsk/repos", "events_url": "https://api.github.com/users/AdrianLsk/events{/privacy}", "received_events_url": "https://api.github.com/users/AdrianLsk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2019-01-19T00:05:20Z", "updated_at": "2020-08-19T21:08:49Z", "closed_at": "2019-02-11T21:50:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "It's caused by this piece of code:\r\n\r\n```python\r\nif spec.default_value is not None:\r\n      raise ValueError(\r\n          'feature \"{}\" had default_value {}, but FixedLenFeature must have '\r\n          'default_value=None'.format(name, spec.default_value))\r\n```\r\n\r\n[Link to source](https://github.com/tensorflow/transform/blob/master/tensorflow_transform/tf_metadata/schema_utils.py#L98-L101)\r\n\r\nWhat's the rationale behind enforcing `default_value=None`? Usually a default value corresponding to the data type should be OK. It seems like there is a bug in the condition and it should be without `not`:\r\n`if spec.default_value is None:`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/95", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/95/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/95/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/95/events", "html_url": "https://github.com/tensorflow/transform/issues/95", "id": 391162003, "node_id": "MDU6SXNzdWUzOTExNjIwMDM=", "number": 95, "title": "Support for (weighted) N-hot encoder", "user": {"login": "martin-laurent", "id": 17744754, "node_id": "MDQ6VXNlcjE3NzQ0NzU0", "avatar_url": "https://avatars2.githubusercontent.com/u/17744754?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martin-laurent", "html_url": "https://github.com/martin-laurent", "followers_url": "https://api.github.com/users/martin-laurent/followers", "following_url": "https://api.github.com/users/martin-laurent/following{/other_user}", "gists_url": "https://api.github.com/users/martin-laurent/gists{/gist_id}", "starred_url": "https://api.github.com/users/martin-laurent/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martin-laurent/subscriptions", "organizations_url": "https://api.github.com/users/martin-laurent/orgs", "repos_url": "https://api.github.com/users/martin-laurent/repos", "events_url": "https://api.github.com/users/martin-laurent/events{/privacy}", "received_events_url": "https://api.github.com/users/martin-laurent/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-14T15:45:34Z", "updated_at": "2019-03-14T02:03:17Z", "closed_at": "2019-03-14T02:03:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am working on a use case where we have a categorical feature associated with a weight. We would like to transform it to a \"weighted N-Hot encoder\". The use case is the following: \r\nIn the field of music taste, we have a feature called \"genre affinities\".\r\nFor one example, it could look like this:\r\n```json\r\n{\r\n\"rock\": 0.75,\r\n\"pop\": 0.12,\r\n\"rap\": 0.88\r\n}\r\n```\r\nThere could be a variable number of entries (possibly 0).\r\n\r\nThe \"vocabulary\" of possible keys/genres is not explicitly known beforehand.\r\nWe would like a set of analyzer and transformer to compute the vocabulary of possible keys and then build a SparseVector that would represent this N-hot encoded feature with the weights instead of ones. Expected output would look like this:\r\n\r\nWith the previous example and another presented this way:\r\n```json\r\n{\r\n\"rock\": 0.13,\r\n\"latin\": 0.96,\r\n\"k-pop\": 0.76,\r\n\"country\": 0.08\r\n}\r\n```\r\nthen an analyzed and transformed batch of these would give:\r\n```python\r\ntf.SparseVector(\r\n    indices = [[0, 0], [0, 4], [0, 5], [1, 0], [1, 1], [1, 2], [1, 3]],\r\n    values = [0.75, 0.12, 0.88, 0.13, 0.96, 0.76, 0.08], \r\n    dense_shape = [2, 6])\r\n```\r\n\r\nWe're not sure yet how to build a `tf.Example` to present the input yet, since this transformation does not exist at all yet.\r\nAny ideas of how that could be done?\r\n\r\nA basic N-Hot encoder would be great to have as well (same thing but with only ones the weights in the values).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/94", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/94/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/94/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/94/events", "html_url": "https://github.com/tensorflow/transform/issues/94", "id": 387970292, "node_id": "MDU6SXNzdWUzODc5NzAyOTI=", "number": 94, "title": "Add tensorflow_transform.__version__", "user": {"login": "brianmartin", "id": 130559, "node_id": "MDQ6VXNlcjEzMDU1OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/130559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brianmartin", "html_url": "https://github.com/brianmartin", "followers_url": "https://api.github.com/users/brianmartin/followers", "following_url": "https://api.github.com/users/brianmartin/following{/other_user}", "gists_url": "https://api.github.com/users/brianmartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/brianmartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brianmartin/subscriptions", "organizations_url": "https://api.github.com/users/brianmartin/orgs", "repos_url": "https://api.github.com/users/brianmartin/repos", "events_url": "https://api.github.com/users/brianmartin/events{/privacy}", "received_events_url": "https://api.github.com/users/brianmartin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "brianmartin", "id": 130559, "node_id": "MDQ6VXNlcjEzMDU1OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/130559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brianmartin", "html_url": "https://github.com/brianmartin", "followers_url": "https://api.github.com/users/brianmartin/followers", "following_url": "https://api.github.com/users/brianmartin/following{/other_user}", "gists_url": "https://api.github.com/users/brianmartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/brianmartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brianmartin/subscriptions", "organizations_url": "https://api.github.com/users/brianmartin/orgs", "repos_url": "https://api.github.com/users/brianmartin/repos", "events_url": "https://api.github.com/users/brianmartin/events{/privacy}", "received_events_url": "https://api.github.com/users/brianmartin/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "brianmartin", "id": 130559, "node_id": "MDQ6VXNlcjEzMDU1OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/130559?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brianmartin", "html_url": "https://github.com/brianmartin", "followers_url": "https://api.github.com/users/brianmartin/followers", "following_url": "https://api.github.com/users/brianmartin/following{/other_user}", "gists_url": "https://api.github.com/users/brianmartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/brianmartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brianmartin/subscriptions", "organizations_url": "https://api.github.com/users/brianmartin/orgs", "repos_url": "https://api.github.com/users/brianmartin/repos", "events_url": "https://api.github.com/users/brianmartin/events{/privacy}", "received_events_url": "https://api.github.com/users/brianmartin/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-12-05T22:16:43Z", "updated_at": "2019-02-21T17:55:22Z", "closed_at": "2019-02-21T17:55:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi! For running Dataflow jobs it is sometimes required for us to ensure that Dataflow workers have certain required packages installed. For this reason, it would be useful to be able to determine the `tensorflow_transform` version at runtime.\r\n\r\nIdeally, this would follow the common python convention of a `__version__` in the top-level module. For example, how `tensorflow-data-validation` does:\r\n\r\n```\r\nIn [1]: import tensorflow_data_validation\r\nIn [2]: tensorflow_data_validation.__version__\r\nOut[2]: '0.11.0'\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/93", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/93/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/93/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/93/events", "html_url": "https://github.com/tensorflow/transform/issues/93", "id": 384527161, "node_id": "MDU6SXNzdWUzODQ1MjcxNjE=", "number": 93, "title": "InvalidArgumentError  tft.compute_and_apply_vocabulary to dense vector ", "user": {"login": "NikeNano", "id": 22057410, "node_id": "MDQ6VXNlcjIyMDU3NDEw", "avatar_url": "https://avatars2.githubusercontent.com/u/22057410?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NikeNano", "html_url": "https://github.com/NikeNano", "followers_url": "https://api.github.com/users/NikeNano/followers", "following_url": "https://api.github.com/users/NikeNano/following{/other_user}", "gists_url": "https://api.github.com/users/NikeNano/gists{/gist_id}", "starred_url": "https://api.github.com/users/NikeNano/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NikeNano/subscriptions", "organizations_url": "https://api.github.com/users/NikeNano/orgs", "repos_url": "https://api.github.com/users/NikeNano/repos", "events_url": "https://api.github.com/users/NikeNano/events{/privacy}", "received_events_url": "https://api.github.com/users/NikeNano/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-11-26T21:55:35Z", "updated_at": "2019-03-06T15:13:17Z", "closed_at": "2019-03-06T15:13:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi! \r\n\r\nI am trying to convert the sparse output vector from compute_and_apply_vocabulary to a dense vector using sparse_tensor_to_dense_with_shape. \r\n~~~~\r\n  def preprocessing_fn(inputs):\r\n     words = tf.string_split(inputs['tweet'],DELIMITERS)\r\n     int_representation = tft.compute_and_apply_vocabulary(words,top_k=10000)\r\n     int_representation = tft.sparse_tensor_to_dense_with_shape(int_representation,[None,43])\r\n     outputs = inputs\r\n     outputs[\"int_representation\"] = int_representation \r\n     return outputs\r\n~~~~\r\nOn small samples it works great but on a bigger batch work using Dataflow it crashes with the following log:\r\n\r\nCaused by op u'transform/transform/SparseToDense', defined at:\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/usr/local/lib/python2.7/dist-packages/dataflow_worker/start.py\", line 86, in <module>\r\n    main()\r\n  File \"/usr/local/lib/python2.7/dist-packages/dataflow_worker/start.py\", line 82, in main\r\n    batchworker.BatchWorker(properties, sdk_pipeline_options).run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/dataflow_worker/batchworker.py\", line 839, in run\r\n    deferred_exception_details=deferred_exception_details)\r\n  File \"/usr/local/lib/python2.7/dist-packages/dataflow_worker/batchworker.py\", line 642, in do_work\r\n    work_executor.execute()\r\n  File \"/usr/local/lib/python2.7/dist-packages/dataflow_worker/executor.py\", line 156, in execute\r\n    op.start()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/beam/impl.py\", line 396, in process\r\n    lambda: self._make_graph_state(saved_model_dir))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/beam/shared.py\", line 221, in acquire\r\n    return _shared_map.acquire(self._key, constructor_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/beam/shared.py\", line 183, in acquire\r\n    result = control_block.acquire(constructor_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/beam/shared.py\", line 85, in acquire\r\n    result = constructor_fn()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/beam/impl.py\", line 396, in <lambda>\r\n    lambda: self._make_graph_state(saved_model_dir))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/beam/impl.py\", line 372, in _make_graph_state\r\n    self._exclude_outputs, tf_config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/beam/impl.py\", line 287, in __init__\r\n    saved_model_dir, {}))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/saved/saved_transform_io.py\", line 360, in partially_apply_saved_transform_internal\r\n    saved_model_dir, logical_input_map, tensor_replacement_map)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/saved/saved_transform_io.py\", line 218, in _partially_apply_saved_transform_impl\r\n    input_map=input_map)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1666, in import_meta_graph\r\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1688, in _import_meta_graph_with_return_elements\r\n    **kwargs))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\r\n    return_elements=return_elements)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\r\n    _ProcessNewOps(graph)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\r\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3438, in _add_new_tf_operations\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3297, in _create_op_from_tf_operation\r\n    ret = Operation(c_op, self)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): indices[11913] = [942,43] is out of bounds: need 0 <= index < [10000,43]\r\n\t [[{{node transform/transform/SparseToDense}} = SparseToDense[T=DT_INT64, Tindices=DT_INT64, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transform/transform/StringSplit, transform/transform/SparseToDense/output_shape, transform/transform/compute_and_apply_vocabulary/apply_vocab/hash_table_Lookup, transform/transform/SparseToDense/default_value)]] [while running 's54']\r\n\r\nThank full for any help to solve this!\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/92", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/92/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/92/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/92/events", "html_url": "https://github.com/tensorflow/transform/issues/92", "id": 383336286, "node_id": "MDU6SXNzdWUzODMzMzYyODY=", "number": 92, "title": "installing on Datalab is not possible due to pytz incompatibility", "user": {"login": "PicarusW", "id": 43196561, "node_id": "MDQ6VXNlcjQzMTk2NTYx", "avatar_url": "https://avatars2.githubusercontent.com/u/43196561?v=4", "gravatar_id": "", "url": "https://api.github.com/users/PicarusW", "html_url": "https://github.com/PicarusW", "followers_url": "https://api.github.com/users/PicarusW/followers", "following_url": "https://api.github.com/users/PicarusW/following{/other_user}", "gists_url": "https://api.github.com/users/PicarusW/gists{/gist_id}", "starred_url": "https://api.github.com/users/PicarusW/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/PicarusW/subscriptions", "organizations_url": "https://api.github.com/users/PicarusW/orgs", "repos_url": "https://api.github.com/users/PicarusW/repos", "events_url": "https://api.github.com/users/PicarusW/events{/privacy}", "received_events_url": "https://api.github.com/users/PicarusW/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-22T00:20:04Z", "updated_at": "2018-11-22T00:26:07Z", "closed_at": "2018-11-22T00:26:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have created a datalab in GCP and installed tensorflow-gpu.\r\nWhen I have tried to install tensorflow-transform I received the following error:\r\n\r\nInstalling collected packages: pytz, monotonic, fasteners, google-apitools, proto-google-cloud-pubsub-v1, google-cloud-core, google-cloud-bigquery, grpc-google-iam-v1, ply, google-gax, gapic-google-cloud-pubsub-v1, google-cloud-pubsub, apache-beam, tensorflow-transform\r\n  Found existing installation: pytz 2016.7\r\nCannot uninstall 'pytz'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/90", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/90/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/90/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/90/events", "html_url": "https://github.com/tensorflow/transform/issues/90", "id": 380830032, "node_id": "MDU6SXNzdWUzODA4MzAwMzI=", "number": 90, "title": "chain SavedModel in tf.Transform using Beam ", "user": {"login": "flyingclouds", "id": 6694353, "node_id": "MDQ6VXNlcjY2OTQzNTM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6694353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flyingclouds", "html_url": "https://github.com/flyingclouds", "followers_url": "https://api.github.com/users/flyingclouds/followers", "following_url": "https://api.github.com/users/flyingclouds/following{/other_user}", "gists_url": "https://api.github.com/users/flyingclouds/gists{/gist_id}", "starred_url": "https://api.github.com/users/flyingclouds/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flyingclouds/subscriptions", "organizations_url": "https://api.github.com/users/flyingclouds/orgs", "repos_url": "https://api.github.com/users/flyingclouds/repos", "events_url": "https://api.github.com/users/flyingclouds/events{/privacy}", "received_events_url": "https://api.github.com/users/flyingclouds/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-14T18:29:45Z", "updated_at": "2018-11-16T22:09:22Z", "closed_at": "2018-11-16T22:09:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Can we use pretrained_models.apply_saved_model() funcion to chain transform_fn?\r\nHow to combine the SavedModel into transformation graph? \r\n\r\nBasically I want to chain models: have one SavedModel (1st model); based on the output of 1st model, I want to train 2nd model.  My current idea is to combine 1st model's (SavedModel) into the transformation of 2nd model's preprocess pipeline.  The target model (1st model + 2nd model) will be exported for final tf serving.\r\n\r\nI  generated the combined transform_fn , and even the final combined SavedModel. But testing the final model serving function will throw error: ValueError: Attempted to map inputs that were not found in graph_def: [input_example_tensor:0]\r\n\r\nAlso the final model graph (visualized in tensorboard)  is really overly complicated ( not what I expected). \r\n\r\nthe code I used to combine the SavedModel into 2nd' model's preprocess pipeline (using beam): \r\n\r\n            input_function = lambda inputs: self.transform_fn(inputs, self.params) # which call pretrained_models.apply_saved_model\r\n            self.tensorflow_transform = (dataset.pcollection, dataset.dataset_schema.convert_dict_to_tft_schema()) | \\\r\n                                        self.transform_fn.func_name + \"GetTransformationFunction\" >> \\\r\n                                        impl.AnalyzeDataset(input_function)\r\n            _ = self.tensorflow_transform | self.transform_fn.func_name + \"WriteTransformFn\" >> \\\r\n                transform_fn_io.WriteTransformFn(path=transform_export_path)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/88", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/88/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/88/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/88/events", "html_url": "https://github.com/tensorflow/transform/issues/88", "id": 377515796, "node_id": "MDU6SXNzdWUzNzc1MTU3OTY=", "number": 88, "title": "csv_coder.py 'encode' error", "user": {"login": "amygdala", "id": 115093, "node_id": "MDQ6VXNlcjExNTA5Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/115093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amygdala", "html_url": "https://github.com/amygdala", "followers_url": "https://api.github.com/users/amygdala/followers", "following_url": "https://api.github.com/users/amygdala/following{/other_user}", "gists_url": "https://api.github.com/users/amygdala/gists{/gist_id}", "starred_url": "https://api.github.com/users/amygdala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amygdala/subscriptions", "organizations_url": "https://api.github.com/users/amygdala/orgs", "repos_url": "https://api.github.com/users/amygdala/repos", "events_url": "https://api.github.com/users/amygdala/events{/privacy}", "received_events_url": "https://api.github.com/users/amygdala/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-05T18:00:46Z", "updated_at": "2019-03-26T19:38:14Z", "closed_at": "2019-03-26T19:38:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have an adapted version of the 'chicago taxi' tft pipeline (from the TFMA ex), where after applying:\r\n`beam.Map(csv_coder.decode)`\r\nI later in the same pipeline apply the following to `raw_data`:\r\n`beam.Map(csv_coder.encode)`\r\n\r\nThis used to work for a previous version of TFT, but for the current version (0.11.0) I get the following error on encode (guessing it's for the case where a field is missing).  I think it may just need additional handling in `_utf8(s)` for when s == None.\r\n\r\n```\r\nFile \"apache_beam/runners/common.py\", line 677, in apache_beam.runners.common.DoFnRunner.process\r\n    self.do_fn_invoker.invoke_process(windowed_value)\r\n  File \"apache_beam/runners/common.py\", line 414, in apache_beam.runners.common.SimpleInvoker.invoke_process\r\n    windowed_value, self.process_method(windowed_value.value))\r\n  File \"/usr/local/lib/python2.7/dist-packages/apache_beam/transforms/core.py\", line 1068, in <lambda>\r\n    wrapper = lambda x: [fn(x)]\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/coders/csv_coder.py\", line 498, in encode\r\n    return self._encoder.encode_record(string_list)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/coders/csv_coder.py\", line 385, in encode_record\r\n    self._writer.writerow(_to_string(record))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/coders/csv_coder.py\", line 38, in _to_string\r\n    return list(map(_utf8, x)) if isinstance(x, (list, np.ndarray)) else _utf8(x)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_transform/coders/csv_coder.py\", line 33, in _utf8\r\n    return s if isinstance(s, bytes) else s.encode('utf-8')\r\n```\r\nAFAICT, something like this will fix things:\r\n\r\n```\r\ndef _utf8(s):\r\n  if s is None:\r\n    return ''\r\n  else:\r\n    return s if isinstance(s, bytes) else s.encode('utf-8')\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/87", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/87/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/87/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/87/events", "html_url": "https://github.com/tensorflow/transform/issues/87", "id": 376651033, "node_id": "MDU6SXNzdWUzNzY2NTEwMzM=", "number": 87, "title": "AttributeError: 'module' object has no attribute 'Context'", "user": {"login": "Alex-zhai", "id": 11607954, "node_id": "MDQ6VXNlcjExNjA3OTU0", "avatar_url": "https://avatars1.githubusercontent.com/u/11607954?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Alex-zhai", "html_url": "https://github.com/Alex-zhai", "followers_url": "https://api.github.com/users/Alex-zhai/followers", "following_url": "https://api.github.com/users/Alex-zhai/following{/other_user}", "gists_url": "https://api.github.com/users/Alex-zhai/gists{/gist_id}", "starred_url": "https://api.github.com/users/Alex-zhai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Alex-zhai/subscriptions", "organizations_url": "https://api.github.com/users/Alex-zhai/orgs", "repos_url": "https://api.github.com/users/Alex-zhai/repos", "events_url": "https://api.github.com/users/Alex-zhai/events{/privacy}", "received_events_url": "https://api.github.com/users/Alex-zhai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-11-02T02:58:15Z", "updated_at": "2019-03-13T17:41:24Z", "closed_at": "2019-03-13T17:41:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "When I run sentiment_example.py script,  **AttributeError: 'module' object has no attribute 'Context'**  occured. Anybody else  had encountered this problem???", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/86", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/86/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/86/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/86/events", "html_url": "https://github.com/tensorflow/transform/issues/86", "id": 375120601, "node_id": "MDU6SXNzdWUzNzUxMjA2MDE=", "number": 86, "title": "Beam WriteTransformFn leads to RuntimeError: AlreadyExistsError: file already exists", "user": {"login": "ozgurdemir", "id": 4437660, "node_id": "MDQ6VXNlcjQ0Mzc2NjA=", "avatar_url": "https://avatars0.githubusercontent.com/u/4437660?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ozgurdemir", "html_url": "https://github.com/ozgurdemir", "followers_url": "https://api.github.com/users/ozgurdemir/followers", "following_url": "https://api.github.com/users/ozgurdemir/following{/other_user}", "gists_url": "https://api.github.com/users/ozgurdemir/gists{/gist_id}", "starred_url": "https://api.github.com/users/ozgurdemir/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ozgurdemir/subscriptions", "organizations_url": "https://api.github.com/users/ozgurdemir/orgs", "repos_url": "https://api.github.com/users/ozgurdemir/repos", "events_url": "https://api.github.com/users/ozgurdemir/events{/privacy}", "received_events_url": "https://api.github.com/users/ozgurdemir/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-10-29T17:04:38Z", "updated_at": "2019-01-02T17:49:49Z", "closed_at": "2018-12-17T16:14:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nwhile writing out the transformation function:\r\n\r\n`(transform_fn | 'WriteTransformFn' >> WriteTransformFn(tft_dir))`\r\n\r\nwe get the following error:\r\n\r\n`RuntimeError: AlreadyExistsError: file already exists [while running 'WriteTransformFn/WriteTransformFn']`\r\n\r\nIt seems that multiple saved_model.pb files are generated in the tft-beam.Context tmp dir. WriteTransformFn then tries to copy them leading to above error.\r\n\r\nTensorflow: 1.9.0\r\nTensorflow Transform: 0.9.0\r\nApache Beam: 2.6.0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/85", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/85/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/85/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/85/events", "html_url": "https://github.com/tensorflow/transform/issues/85", "id": 373712437, "node_id": "MDU6SXNzdWUzNzM3MTI0Mzc=", "number": 85, "title": "AttributeError: 'thread._local' object has no attribute 'state'", "user": {"login": "jonathanglima", "id": 1863103, "node_id": "MDQ6VXNlcjE4NjMxMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/1863103?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonathanglima", "html_url": "https://github.com/jonathanglima", "followers_url": "https://api.github.com/users/jonathanglima/followers", "following_url": "https://api.github.com/users/jonathanglima/following{/other_user}", "gists_url": "https://api.github.com/users/jonathanglima/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonathanglima/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonathanglima/subscriptions", "organizations_url": "https://api.github.com/users/jonathanglima/orgs", "repos_url": "https://api.github.com/users/jonathanglima/repos", "events_url": "https://api.github.com/users/jonathanglima/events{/privacy}", "received_events_url": "https://api.github.com/users/jonathanglima/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-24T23:12:09Z", "updated_at": "2019-02-15T12:43:48Z", "closed_at": "2018-10-25T16:39:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm having a thread issue with the following code. The traceback and pip freeze are below as well.\r\n\r\nI'm on a Mac, running beam locally. Already tested for tensorflow==1.9.0 and had the same error. Any ideas?\r\n\r\n### Code\r\n```import tensorflow as tf\r\nimport tensorflow_transform as tft\r\nfrom tensorflow_transform.beam import impl as tft_beam\r\nfrom tensorflow_transform.tf_metadata import dataset_metadata\r\nfrom tensorflow_transform.tf_metadata import dataset_schema\r\nimport apache_beam as beam\r\n\r\nraw_data_metadata = dataset_metadata.DatasetMetadata(\r\n    dataset_schema.from_feature_spec({\r\n        'sku': tf.FixedLenFeature([], tf.string),\r\n}))\r\n\r\ncategorical_columns = [\r\n    'sku',\r\n]\r\n\r\ndef preprocessing_tft_fn(inputs):\r\n    for key in categorical_columns:\r\n        tft.vocabulary(inputs[key], vocab_filename=key)\r\n\r\n    return inputs\r\n\r\nwith beam.Pipeline() as p:\r\n    raw_data = (p\r\n        | beam.Create([{'sku': 'a'}, {'sku': 'b'}])\r\n    )\r\n\r\n    (transformed_data, transformed_metadata), transform_fn = (\r\n        (raw_data, raw_data_metadata)\r\n        | 'AnalyzeAndTransformTrain' >> tft_beam.AnalyzeAndTransformDataset(preprocessing_tft_fn)\r\n    )\r\n```\r\n\r\n### Traceback\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 30, in <module>\r\n    | 'AnalyzeAndTransformTrain' >> tft_beam.AnalyzeAndTransformDataset(preprocessing_tft_fn)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/transforms/ptransform.py\", line 831, in __ror__\r\n    return self.transform.__ror__(pvalueish, self.label)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/transforms/ptransform.py\", line 488, in __ror__\r\n    result = p.apply(self, pvalueish, label)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/pipeline.py\", line 468, in apply\r\n    return self.apply(transform, pvalueish)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/pipeline.py\", line 504, in apply\r\n    pvalueish_result = self.runner.apply(transform, pvalueish)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/runners/runner.py\", line 193, in apply\r\n    return m(transform, input)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/runners/runner.py\", line 199, in apply_PTransform\r\n    return transform.expand(input)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/tensorflow_transform/beam/impl.py\", line 862, in expand\r\n    dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn))\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/transforms/ptransform.py\", line 831, in __ror__\r\n    return self.transform.__ror__(pvalueish, self.label)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/transforms/ptransform.py\", line 488, in __ror__\r\n    result = p.apply(self, pvalueish, label)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/pipeline.py\", line 468, in apply\r\n    return self.apply(transform, pvalueish)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/pipeline.py\", line 504, in apply\r\n    pvalueish_result = self.runner.apply(transform, pvalueish)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/runners/runner.py\", line 193, in apply\r\n    return m(transform, input)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/apache_beam/runners/runner.py\", line 199, in apply_PTransform\r\n    return transform.expand(input)\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/tensorflow_transform/beam/impl.py\", line 717, in expand\r\n    base_temp_dir = Context.create_base_temp_dir()\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/tensorflow_transform/beam/impl.py\", line 207, in create_base_temp_dir\r\n    state = cls._get_topmost_state_frame()\r\n  File \"/Users/jonathangarcialima/.virtualenvs/tft_testing_env/lib/python2.7/site-packages/tensorflow_transform/beam/impl.py\", line 200, in _get_topmost_state_frame\r\n    if cls._thread_local.state.frames:\r\nAttributeError: 'thread._local' object has no attribute 'state'\r\n```\r\n\r\n### Pip Freeze\r\n```\r\nabsl-py==0.5.0\r\napache-beam==2.6.0\r\nastor==0.7.1\r\navro==1.8.2\r\nbackports.weakref==1.0.post1\r\nboto==2.49.0\r\ncachetools==2.1.0\r\ncertifi==2018.8.24\r\nchardet==3.0.4\r\ncrcmod==1.7\r\ndill==0.2.8.2\r\ndocopt==0.6.2\r\nenum34==1.1.6\r\nfasteners==0.14.1\r\nfuncsigs==1.0.2\r\nfuture==0.16.0\r\nfutures==3.2.0\r\ngapic-google-cloud-pubsub-v1==0.15.4\r\ngast==0.2.0\r\ngoogle-api-core==1.5.0\r\ngoogle-api-python-client==1.7.4\r\ngoogle-apitools==0.5.20\r\ngoogle-auth==1.5.1\r\ngoogle-auth-httplib2==0.0.3\r\ngoogle-cloud-bigquery==0.25.0\r\ngoogle-cloud-core==0.25.0\r\ngoogle-cloud-dataflow==2.5.0\r\ngoogle-cloud-pubsub==0.26.0\r\ngoogle-cloud-storage==1.13.0\r\ngoogle-compute-engine==2.8.3\r\ngoogle-gax==0.15.16\r\ngoogle-resumable-media==0.3.1\r\ngoogleapis-common-protos==1.5.3\r\ngoogledatastore==7.0.1\r\ngrpc-google-iam-v1==0.11.4\r\ngrpcio==1.15.0\r\nh5py==2.8.0\r\nhdfs==2.1.0\r\nhttplib2==0.11.3\r\nidna==2.7\r\nKeras-Applications==1.0.6\r\nKeras-Preprocessing==1.0.5\r\nMarkdown==2.6.11\r\nmock==2.0.0\r\nmonotonic==1.5\r\nnumpy==1.14.5\r\noauth2client==4.1.3\r\npandas==0.23.4\r\npbr==4.2.0\r\nply==3.8\r\nproto-google-cloud-datastore-v1==0.90.4\r\nproto-google-cloud-pubsub-v1==0.15.4\r\nprotobuf==3.6.1\r\npsycopg2==2.7.5\r\npyasn1==0.4.4\r\npyasn1-modules==0.2.2\r\npydot==1.2.4\r\npyparsing==2.2.1\r\npython-dateutil==2.7.3\r\npytz==2018.4\r\nPyVCF==0.6.8\r\nPyYAML==3.13\r\nrequests==2.19.1\r\nretrying==1.3.3\r\nrsa==4.0\r\nsh==1.12.14\r\nsix==1.11.0\r\nSQLAlchemy==1.2.12\r\ntensorboard==1.10.0\r\ntensorflow==1.10.0\r\ntensorflow-metadata==0.9.0\r\ntensorflow-transform==0.9.0\r\ntermcolor==1.1.0\r\ntyping==3.6.6\r\nuritemplate==3.0.0\r\nurllib3==1.23\r\nWerkzeug==0.14.1\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/83", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/83/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/83/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/83/events", "html_url": "https://github.com/tensorflow/transform/issues/83", "id": 366045389, "node_id": "MDU6SXNzdWUzNjYwNDUzODk=", "number": 83, "title": "Best practices for interfacing tf.Transform and tf.data.Dataset", "user": {"login": "alshedivat", "id": 2126561, "node_id": "MDQ6VXNlcjIxMjY1NjE=", "avatar_url": "https://avatars3.githubusercontent.com/u/2126561?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alshedivat", "html_url": "https://github.com/alshedivat", "followers_url": "https://api.github.com/users/alshedivat/followers", "following_url": "https://api.github.com/users/alshedivat/following{/other_user}", "gists_url": "https://api.github.com/users/alshedivat/gists{/gist_id}", "starred_url": "https://api.github.com/users/alshedivat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alshedivat/subscriptions", "organizations_url": "https://api.github.com/users/alshedivat/orgs", "repos_url": "https://api.github.com/users/alshedivat/repos", "events_url": "https://api.github.com/users/alshedivat/events{/privacy}", "received_events_url": "https://api.github.com/users/alshedivat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-10-02T19:27:22Z", "updated_at": "2019-03-26T15:58:28Z", "closed_at": "2019-03-26T15:58:28Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "I was looking for the best way to replicate the training data preprocessing at serving time. It looks like `tf.Transform` is the way to go, but it's unclear, what are the best practice of interfacing it with `tf.data.Dataset` pipelines (which also have dataset mappers, etc.)?\r\n\r\nAlso, going forward, will `tf.Transform` and `tf.data.Dataset` co-exist, or one will succeed the other?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/81", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/81/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/81/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/81/events", "html_url": "https://github.com/tensorflow/transform/issues/81", "id": 364081074, "node_id": "MDU6SXNzdWUzNjQwODEwNzQ=", "number": 81, "title": "Can tf.transform handle viewfs:// path?", "user": {"login": "ShangzhiH", "id": 10820168, "node_id": "MDQ6VXNlcjEwODIwMTY4", "avatar_url": "https://avatars1.githubusercontent.com/u/10820168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ShangzhiH", "html_url": "https://github.com/ShangzhiH", "followers_url": "https://api.github.com/users/ShangzhiH/followers", "following_url": "https://api.github.com/users/ShangzhiH/following{/other_user}", "gists_url": "https://api.github.com/users/ShangzhiH/gists{/gist_id}", "starred_url": "https://api.github.com/users/ShangzhiH/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ShangzhiH/subscriptions", "organizations_url": "https://api.github.com/users/ShangzhiH/orgs", "repos_url": "https://api.github.com/users/ShangzhiH/repos", "events_url": "https://api.github.com/users/ShangzhiH/events{/privacy}", "received_events_url": "https://api.github.com/users/ShangzhiH/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-09-26T15:11:39Z", "updated_at": "2019-03-26T17:00:13Z", "closed_at": "2019-03-26T17:00:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "I find after apache beam 2.5.0, the hdfs path can be recognized by beam's python sdk.\r\nBut in \"/python2.7/site-packages/apache_beam/io/hadoopfilesystem.py\", the support schema is only \"hdfs\". When i loaded a viewfs path, i got this error:\r\n\r\n![image](https://user-images.githubusercontent.com/10820168/46090144-aaf8c580-c1e2-11e8-9ae6-540bb4747dd3.png)\r\n\r\nCould anyone give me some advice about use tf.transform to read an file in viewfs filesystem, i really appreciate it.\r\nThank you!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/78", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/78/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/78/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/78/events", "html_url": "https://github.com/tensorflow/transform/issues/78", "id": 355726995, "node_id": "MDU6SXNzdWUzNTU3MjY5OTU=", "number": 78, "title": "NaN values lead to unexpected results in scale_to_z_score", "user": {"login": "baxen", "id": 7858054, "node_id": "MDQ6VXNlcjc4NTgwNTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/7858054?v=4", "gravatar_id": "", "url": "https://api.github.com/users/baxen", "html_url": "https://github.com/baxen", "followers_url": "https://api.github.com/users/baxen/followers", "following_url": "https://api.github.com/users/baxen/following{/other_user}", "gists_url": "https://api.github.com/users/baxen/gists{/gist_id}", "starred_url": "https://api.github.com/users/baxen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/baxen/subscriptions", "organizations_url": "https://api.github.com/users/baxen/orgs", "repos_url": "https://api.github.com/users/baxen/repos", "events_url": "https://api.github.com/users/baxen/events{/privacy}", "received_events_url": "https://api.github.com/users/baxen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-08-30T19:42:07Z", "updated_at": "2019-03-15T17:06:54Z", "closed_at": "2019-03-15T17:06:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "The current implementations of mean and variance in `analyzers.py` don't seem to be able to handle NaN values. This results in the `scale_to_z_score` function giving unexpected results if the data contains any NaNs. For example:\r\n\r\n```python\r\nimport tempfile\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tensorflow_transform as tft\r\nimport tensorflow_transform.beam.impl as beam_impl\r\nfrom tensorflow_transform.tf_metadata import dataset_metadata\r\nfrom tensorflow_transform.tf_metadata import dataset_schema\r\n\r\nsize = 10000\r\nvalues = np.random.normal(10.0, 10.0, size=size) # original has a mean of 10 and std of 10\r\nvalues[np.random.rand(size) < 0.2] = np.nan  # but 20% are NaN\r\n\r\ndef preprocessing_fn(inputs):\r\n    \"\"\"Preprocess input columns into transformed columns.\"\"\"\r\n    x = inputs['x']\r\n    x_zscore = tft.scale_to_z_score(x)\r\n    return {\r\n        'x_zscore': x_zscore,\r\n     }\r\n\r\nraw_data = [{'x': v} for v in values]\r\nraw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.Schema({\r\n    'x': dataset_schema.ColumnSchema(\r\n        tf.float32, [], dataset_schema.FixedColumnRepresentation())\r\n}))\r\n\r\nwith beam_impl.Context(temp_dir=tempfile.mkdtemp()):\r\n    transformed_dataset, transform_fn = (\r\n        (raw_data, raw_data_metadata) | beam_impl.AnalyzeAndTransformDataset(preprocessing_fn)\r\n    )\r\n    transformed_data, transformed_metadata = transformed_dataset  # pylint: disable=unused-variable\r\n\r\ntransformed = np.array([d['x_zscore'] for d in transformed_data])\r\n\r\n\r\nprint(np.nanmean(transformed))  # not close to zero\r\nprint(np.nanvar(transformed))  # not close to one\r\n```\r\n\r\nYou end up with the transformed data having a mean and variance much greater than 0 and 1 respectively. I am pretty sure this is happening because tf.reduce_sum is giving NaN for all batches that contain at least one NaN value here: https://github.com/tensorflow/transform/blob/master/tensorflow_transform/tf_utils.py#L99\r\n\r\nI just closed a PR [#68] that fixed this in an older implementation. I'd be happy to make a PR to fix this in the current as well, I think it would be reasonable to take the mean/var of all non-NaN values and then to set any NaNs to zero as the default behavior.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/77", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/77/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/77/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/77/events", "html_url": "https://github.com/tensorflow/transform/issues/77", "id": 349951957, "node_id": "MDU6SXNzdWUzNDk5NTE5NTc=", "number": 77, "title": "Fail to pip install tensorflow-transform==0.6.0 with docker base image 'python:2.7-slim'", "user": {"login": "cuptea", "id": 5229733, "node_id": "MDQ6VXNlcjUyMjk3MzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/5229733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cuptea", "html_url": "https://github.com/cuptea", "followers_url": "https://api.github.com/users/cuptea/followers", "following_url": "https://api.github.com/users/cuptea/following{/other_user}", "gists_url": "https://api.github.com/users/cuptea/gists{/gist_id}", "starred_url": "https://api.github.com/users/cuptea/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cuptea/subscriptions", "organizations_url": "https://api.github.com/users/cuptea/orgs", "repos_url": "https://api.github.com/users/cuptea/repos", "events_url": "https://api.github.com/users/cuptea/events{/privacy}", "received_events_url": "https://api.github.com/users/cuptea/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101983368, "node_id": "MDU6TGFiZWwxMTAxOTgzMzY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-08-13T09:24:55Z", "updated_at": "2018-11-16T19:27:05Z", "closed_at": "2018-11-16T19:27:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "Previously, everything works fine. This issue appeared very recently.\r\n\r\nDockerFile is the following:\r\n```\r\nFROM python:2.7-slim\r\nRUN pip install tensorflow-transform==0.6.0\r\n...\r\n```\r\n\r\nThe procedure stops with the following error:\r\n```\r\n  Running setup.py bdist_wheel for fastavro: started\r\n  Running setup.py bdist_wheel for fastavro: finished with status 'error'\r\n  Complete output from command /usr/local/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-xzjqeH/fastavro/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-9O9XdV --python-tag cp27:\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  creating build\r\n  creating build/lib.linux-x86_64-2.7\r\n  creating build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/validation.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/_schema_common.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/_read_common.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/_validation_py.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/const.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/read.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/_read_py.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/schema.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/_timezone.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/write.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/_schema_py.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/_write_py.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/__init__.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/_validate_common.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/six.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  copying fastavro/__main__.py -> build/lib.linux-x86_64-2.7/fastavro\r\n  running build_ext\r\n  building 'fastavro._read' extension\r\n  creating build/temp.linux-x86_64-2.7\r\n  creating build/temp.linux-x86_64-2.7/fastavro\r\n  gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/include/python2.7 -c fastavro/_read.c -o build/temp.linux-x86_64-2.7/fastavro/_read.o\r\n  unable to execute 'gcc': No such file or directory\r\n  error: command 'gcc' failed with exit status 1\r\n\r\n  ----------------------------------------\r\n  **Failed building wheel for fastavro**\r\n  Running setup.py clean for fastavro\r\n```\r\n\r\nCurrently, I work around this problem by using the ubuntu base docker image with following installation:\r\n```\r\nRUN apt-get update\r\nRUN apt-get -y install build-essential python-pip python2.7 \r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/76", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/76/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/76/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/76/events", "html_url": "https://github.com/tensorflow/transform/issues/76", "id": 349011198, "node_id": "MDU6SXNzdWUzNDkwMTExOTg=", "number": 76, "title": " tf transform's \"exported model\" use in tf serving issue", "user": {"login": "kt1004", "id": 26303378, "node_id": "MDQ6VXNlcjI2MzAzMzc4", "avatar_url": "https://avatars0.githubusercontent.com/u/26303378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kt1004", "html_url": "https://github.com/kt1004", "followers_url": "https://api.github.com/users/kt1004/followers", "following_url": "https://api.github.com/users/kt1004/following{/other_user}", "gists_url": "https://api.github.com/users/kt1004/gists{/gist_id}", "starred_url": "https://api.github.com/users/kt1004/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kt1004/subscriptions", "organizations_url": "https://api.github.com/users/kt1004/orgs", "repos_url": "https://api.github.com/users/kt1004/repos", "events_url": "https://api.github.com/users/kt1004/events{/privacy}", "received_events_url": "https://api.github.com/users/kt1004/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-08-09T07:35:05Z", "updated_at": "2019-11-05T04:27:23Z", "closed_at": "2018-10-05T04:48:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "I run census_example.py and I check exported model file.\r\nhttps://github.com/tensorflow/transform/blob/master/examples/census_example.py\r\n\r\nAnd, I can check ServingInputReceiver below\r\nprint(\"serving_input_receiver:\", serving_input_receiver)\r\n==>\r\nServingInputReceiver(features={\r\n  'capital-loss': <tf.Tensor 'ParseExample/ParseExample:2' shape=(?,) dtype=float32>, \r\n  'relationship': <tf.Tensor 'ParseExample/ParseExample:10' shape=(?,) dtype=string>, \r\n  'age': <tf.Tensor 'ParseExample/ParseExample:0' shape=(?,) dtype=float32>, \r\n  ...\r\n  receiver_tensors={'examples': <tf.Tensor 'input_example_tensor:0' shape=(?,) dtype=string>}, receiver_tensors_alternatives=None)\r\n\r\nAnd I run tensorflow serving using the model in exported model dir.\r\nAnd I send curl request but, I got error\r\n\r\ncurl -d '{\"instances\": [{\"age\":50, \"workclass\":\"Self-emp-not-inc\", \"education\":\"Bachelors\", \"education-num\":13, \"marital-status\":\"Married-civ-spouse\", \"occupation\":\"Exec-managerial\", \"relationship\":\"Husband\", \"race\":\"White\", \"sex\":\"Male\", \"capital-gain\":0, \"capital-loss\":0, \"hours-per-week\":13, \"native-country\":\"United-States\"}]}'\r\n-X POST http://localhost:8501/v1/models/census:predict\r\n\r\n{ \"error\": \"Failed to process element: 0 key: age of \\'instances\\' list. Error: Invalid argument: JSON object: does not have named input: age\" }\r\n\r\nHow do I call ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/75", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/75/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/75/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/75/events", "html_url": "https://github.com/tensorflow/transform/issues/75", "id": 346266030, "node_id": "MDU6SXNzdWUzNDYyNjYwMzA=", "number": 75, "title": "More docs for apply_function needed?", "user": {"login": "hanneshapke", "id": 1234819, "node_id": "MDQ6VXNlcjEyMzQ4MTk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1234819?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hanneshapke", "html_url": "https://github.com/hanneshapke", "followers_url": "https://api.github.com/users/hanneshapke/followers", "following_url": "https://api.github.com/users/hanneshapke/following{/other_user}", "gists_url": "https://api.github.com/users/hanneshapke/gists{/gist_id}", "starred_url": "https://api.github.com/users/hanneshapke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hanneshapke/subscriptions", "organizations_url": "https://api.github.com/users/hanneshapke/orgs", "repos_url": "https://api.github.com/users/hanneshapke/repos", "events_url": "https://api.github.com/users/hanneshapke/events{/privacy}", "received_events_url": "https://api.github.com/users/hanneshapke/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101994909, "node_id": "MDU6TGFiZWwxMTAxOTk0OTA5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-07-31T16:33:40Z", "updated_at": "2018-10-23T21:42:37Z", "closed_at": "2018-10-23T21:41:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am implementing a conversion from from characters to a list of character indicies (int). To perform the conversion, I wrote a function `convert_character` to split the input string and perform a table lookup for every character.\r\n\r\nThe conversion function runs fine when I convert a `tf.constant('test string')` in a TF graph. The conversion will return something like `[45, 4, 18, 19, 70, 18, 19, 17, 8, 13, 6]`.\r\n\r\nIf I apply the same apply the conversion method in my TF Transform example, every character gets converted individually and the output looks like this:\r\n\r\n```\r\n[{u'indicies': 45},\r\n {u'indicies': 4},\r\n {u'indicies': 18},\r\n {u'indicies': 19},\r\n {u'indicies': 70},\r\n {u'indicies': 18},\r\n {u'indicies': 19},\r\n {u'indicies': 17},\r\n {u'indicies': 8},\r\n {u'indicies': 13},\r\n {u'indicies': 6}]\r\n```\r\n\r\nI would have expected the output to look like \r\n\r\n```\r\n[{u'indicies': [45, 4, 18, 19, 70, 18, 19, 17, 8, 13, 6]},\r\n {u'indicies': [.....]},\r\n]\r\n```\r\n\r\nIs the problem in my case the usage of `apply_function`? I noticed other users struggled with the correct use of the mapper function too (https://github.com/tensorflow/transform/issues/58). \r\n\r\nI also tried to replaced the `apply_function` with `tf.map_fn`, but the conversion was the same. This makes sense to me since `map_fn` is applied to every character in the string.\r\n\r\nIf anyone can point me into the right direction use `apply_function` correctly, I am happy to extend the docs to prevent similar mistakes in the future.\r\n\r\n\r\nHere is my example character conversion code: \r\n\r\n```\r\nimport pprint\r\nimport tempfile\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_transform as tft\r\nimport tensorflow_transform.beam.impl as beam_impl\r\nfrom tensorflow_transform.tf_metadata import dataset_metadata\r\nfrom tensorflow_transform.tf_metadata import dataset_schema\r\n\r\ndef convert_character(input_string):\r\n    input_characters = tf.string_split(input_string, delimiter=\"\") \r\n    characters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\\'?!.,:; '\r\n    mapping_characters = tf.string_split([characters], delimiter=\"\")\r\n    table = tf.contrib.lookup.index_table_from_tensor(\r\n        mapping=mapping_characters.values, default_value=0) \r\n    return table.lookup(input_characters.values)\r\n\r\ndef preprocessing_fn(inputs):\r\n    \"\"\"Preprocess input columns into transformed columns.\"\"\"    \r\n    return {'indicies': tft.apply_function(convert_character, inputs['sentence'])}\r\n\r\n\r\ndef main():\r\n    \r\n    raw_data = [\r\n      {'sentence': 'Test string'},\r\n      {'sentence': 'String Test'},\r\n    ]\r\n\r\n    raw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.Schema({\r\n      'sentence': dataset_schema.ColumnSchema(\r\n          tf.string, [], dataset_schema.FixedColumnRepresentation())\r\n    }))\r\n\r\n    with beam_impl.Context(temp_dir=tempfile.mkdtemp()):\r\n        transformed_dataset, transform_fn = (  # pylint: disable=unused-variable\r\n            (raw_data, raw_data_metadata) | beam_impl.AnalyzeAndTransformDataset(\r\n                preprocessing_fn))\r\n\r\n        transformed_data, transformed_metadata = transformed_dataset  # pylint: disable=unused-variable\r\n\r\n        pprint.pprint(transformed_data)\r\n\r\nmain()\r\n```\r\n \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/72", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/72/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/72/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/72/events", "html_url": "https://github.com/tensorflow/transform/issues/72", "id": 338511437, "node_id": "MDU6SXNzdWUzMzg1MTE0Mzc=", "number": 72, "title": "vocabulary_file no longer set", "user": {"login": "mattiasarro", "id": 53719, "node_id": "MDQ6VXNlcjUzNzE5", "avatar_url": "https://avatars0.githubusercontent.com/u/53719?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mattiasarro", "html_url": "https://github.com/mattiasarro", "followers_url": "https://api.github.com/users/mattiasarro/followers", "following_url": "https://api.github.com/users/mattiasarro/following{/other_user}", "gists_url": "https://api.github.com/users/mattiasarro/gists{/gist_id}", "starred_url": "https://api.github.com/users/mattiasarro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mattiasarro/subscriptions", "organizations_url": "https://api.github.com/users/mattiasarro/orgs", "repos_url": "https://api.github.com/users/mattiasarro/repos", "events_url": "https://api.github.com/users/mattiasarro/events{/privacy}", "received_events_url": "https://api.github.com/users/mattiasarro/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-07-05T10:13:24Z", "updated_at": "2018-07-05T10:35:17Z", "closed_at": "2018-07-05T10:35:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "As of 0.8.0 vocabulary_file is no longer set in schema.json. One of my projects was relying on this to read the relevant vocabulary filenames and manage some index-to-token mapping outside of TensorFlow. \r\n\r\nWhat is the expected way to find the relevant vocabulary filename after v0.8.0? I presume it's written in saved_model somewhere, but it's not human-readable and harder to access programmatically than JSON. What was the reason for this change / what should vocabulary_file in schema.json be used for if not for this purpose?\r\n\r\nAny help or pointers to relevant code is much appreciated! Thanks for all the work on TFT so far.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/70", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/70/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/70/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/70/events", "html_url": "https://github.com/tensorflow/transform/issues/70", "id": 335921707, "node_id": "MDU6SXNzdWUzMzU5MjE3MDc=", "number": 70, "title": "All TensorInfo protos used in the SignatureDefs must have the name field set", "user": {"login": "ravwojdyla", "id": 1419010, "node_id": "MDQ6VXNlcjE0MTkwMTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1419010?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ravwojdyla", "html_url": "https://github.com/ravwojdyla", "followers_url": "https://api.github.com/users/ravwojdyla/followers", "following_url": "https://api.github.com/users/ravwojdyla/following{/other_user}", "gists_url": "https://api.github.com/users/ravwojdyla/gists{/gist_id}", "starred_url": "https://api.github.com/users/ravwojdyla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ravwojdyla/subscriptions", "organizations_url": "https://api.github.com/users/ravwojdyla/orgs", "repos_url": "https://api.github.com/users/ravwojdyla/repos", "events_url": "https://api.github.com/users/ravwojdyla/events{/privacy}", "received_events_url": "https://api.github.com/users/ravwojdyla/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101983368, "node_id": "MDU6TGFiZWwxMTAxOTgzMzY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-06-26T17:31:34Z", "updated_at": "2018-11-16T19:42:29Z", "closed_at": "2018-11-16T19:42:29Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hello.\r\n\r\nI getting this error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/dataflow_worker/batchworker.py\", line 609, in do_work\r\n    work_executor.execute()\r\n  File \"/usr/local/lib/python2.7/dist-packages/dataflow_worker/executor.py\", line 167, in execute\r\n    op.start()\r\n  File \"dataflow_worker/native_operations.py\", line 38, in dataflow_worker.native_operations.NativeReadOperation.start\r\n    def start(self):\r\n  File \"dataflow_worker/native_operations.py\", line 39, in dataflow_worker.native_operations.NativeReadOperation.start\r\n    with self.scoped_start_state:\r\n  File \"dataflow_worker/native_operations.py\", line 44, in dataflow_worker.native_operations.NativeReadOperation.start\r\n    with self.spec.source.reader() as reader:\r\n  File \"dataflow_worker/native_operations.py\", line 54, in dataflow_worker.native_operations.NativeReadOperation.start\r\n    self.output(windowed_value)\r\n  File \"apache_beam/runners/worker/operations.py\", line 159, in apache_beam.runners.worker.operations.Operation.output\r\n    cython.cast(Receiver, self.receivers[output_index]).receive(windowed_value)\r\n  File \"apache_beam/runners/worker/operations.py\", line 85, in apache_beam.runners.worker.operations.ConsumerSet.receive\r\n    cython.cast(Operation, consumer).process(windowed_value)\r\n  File \"apache_beam/runners/worker/operations.py\", line 392, in apache_beam.runners.worker.operations.DoOperation.process\r\n    with self.scoped_process_state:\r\n  File \"apache_beam/runners/worker/operations.py\", line 393, in apache_beam.runners.worker.operations.DoOperation.process\r\n    self.dofn_receiver.receive(o)\r\n  File \"apache_beam/runners/common.py\", line 488, in apache_beam.runners.common.DoFnRunner.receive\r\n    self.process(windowed_value)\r\n  File \"apache_beam/runners/common.py\", line 496, in apache_beam.runners.common.DoFnRunner.process\r\n    self._reraise_augmented(exn)\r\n  File \"apache_beam/runners/common.py\", line 537, in apache_beam.runners.common.DoFnRunner._reraise_augmented\r\n    six.raise_from(new_exn, original_traceback)\r\n  File \"/usr/local/lib/python2.7/dist-packages/six.py\", line 718, in raise_from\r\n    raise value\r\nAssertionError: All TensorInfo protos used in the SignatureDefs must have the name field set: dtype: DT_STRING\r\ntensor_shape {\r\n  dim {\r\n    size: -1\r\n  }\r\n  dim {\r\n    size: -1\r\n  }\r\n}\r\ncoo_sparse {\r\n  values_tensor_name: \"transform/inputs/label/values:0\"\r\n  indices_tensor_name: \"transform/inputs/label/indices:0\"\r\n  dense_shape_tensor_name: \"transform/inputs/label/shape:0\"\r\n}\r\n```\r\n\r\nwhen running TFT on Dataflow Runner, my `label` in `preprocessing_fn` is a sparse tensor of string. Surpassingly I don't see this error in DirectRunner! I'm using current master version 30146171032ed79ec99ff002ef8f7065c70d8536.\r\n\r\nThis might be related to https://github.com/tensorflow/tensorflow/issues/6110\r\n\r\nIf you take a look at `build_tensor_info` (which is used by TFT):\r\n\r\n```\r\n@tf_export(\"saved_model.utils.build_tensor_info\")\r\ndef build_tensor_info(tensor):\r\n  \"\"\"Utility function to build TensorInfo proto.\r\n\r\n  Args:\r\n    tensor: Tensor or SparseTensor whose name, dtype and shape are used to\r\n        build the TensorInfo. For SparseTensors, the names of the three\r\n        constitutent Tensors are used.\r\n\r\n  Returns:\r\n    A TensorInfo protocol buffer constructed based on the supplied argument.\r\n  \"\"\"\r\n  tensor_info = meta_graph_pb2.TensorInfo(\r\n      dtype=dtypes.as_dtype(tensor.dtype).as_datatype_enum,\r\n      tensor_shape=tensor.get_shape().as_proto())\r\n  if isinstance(tensor, sparse_tensor.SparseTensor):\r\n    tensor_info.coo_sparse.values_tensor_name = tensor.values.name\r\n    tensor_info.coo_sparse.indices_tensor_name = tensor.indices.name\r\n    tensor_info.coo_sparse.dense_shape_tensor_name = tensor.dense_shape.name\r\n  else:\r\n    tensor_info.name = tensor.name\r\n  return tensor_info\r\n```\r\n\r\nfrom TF, for SparseTensor there will be no name set (so that would explain the error) and overall issue, but then again why would that work in DirectRunner? Also what is the recommendation for SparseTensor in `preprocessing_fn`?\r\n\r\nExample of Dataflow job: 2018-06-26_10_13_22-11943278300951017592", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/69", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/69/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/69/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/69/events", "html_url": "https://github.com/tensorflow/transform/issues/69", "id": 335552755, "node_id": "MDU6SXNzdWUzMzU1NTI3NTU=", "number": 69, "title": "Request: nightly/dev release", "user": {"login": "ravwojdyla", "id": 1419010, "node_id": "MDQ6VXNlcjE0MTkwMTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1419010?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ravwojdyla", "html_url": "https://github.com/ravwojdyla", "followers_url": "https://api.github.com/users/ravwojdyla/followers", "following_url": "https://api.github.com/users/ravwojdyla/following{/other_user}", "gists_url": "https://api.github.com/users/ravwojdyla/gists{/gist_id}", "starred_url": "https://api.github.com/users/ravwojdyla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ravwojdyla/subscriptions", "organizations_url": "https://api.github.com/users/ravwojdyla/orgs", "repos_url": "https://api.github.com/users/ravwojdyla/repos", "events_url": "https://api.github.com/users/ravwojdyla/events{/privacy}", "received_events_url": "https://api.github.com/users/ravwojdyla/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zoyahav", "id": 17624759, "node_id": "MDQ6VXNlcjE3NjI0NzU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17624759?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zoyahav", "html_url": "https://github.com/zoyahav", "followers_url": "https://api.github.com/users/zoyahav/followers", "following_url": "https://api.github.com/users/zoyahav/following{/other_user}", "gists_url": "https://api.github.com/users/zoyahav/gists{/gist_id}", "starred_url": "https://api.github.com/users/zoyahav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zoyahav/subscriptions", "organizations_url": "https://api.github.com/users/zoyahav/orgs", "repos_url": "https://api.github.com/users/zoyahav/repos", "events_url": "https://api.github.com/users/zoyahav/events{/privacy}", "received_events_url": "https://api.github.com/users/zoyahav/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-06-25T20:19:01Z", "updated_at": "2018-06-28T19:58:28Z", "closed_at": "2018-06-28T19:58:28Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Could we please have a nightly/dev release. FYI using git reference in pip requirements seem to fail on Dataflow runner. But overall it seems like a good idea to make it easier to try new features. What do you think?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/67", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/67/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/67/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/67/events", "html_url": "https://github.com/tensorflow/transform/issues/67", "id": 333026838, "node_id": "MDU6SXNzdWUzMzMwMjY4Mzg=", "number": 67, "title": "Imputing missing values", "user": {"login": "brennon", "id": 159993, "node_id": "MDQ6VXNlcjE1OTk5Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/159993?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brennon", "html_url": "https://github.com/brennon", "followers_url": "https://api.github.com/users/brennon/followers", "following_url": "https://api.github.com/users/brennon/following{/other_user}", "gists_url": "https://api.github.com/users/brennon/gists{/gist_id}", "starred_url": "https://api.github.com/users/brennon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brennon/subscriptions", "organizations_url": "https://api.github.com/users/brennon/orgs", "repos_url": "https://api.github.com/users/brennon/repos", "events_url": "https://api.github.com/users/brennon/events{/privacy}", "received_events_url": "https://api.github.com/users/brennon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-06-17T01:17:09Z", "updated_at": "2019-01-28T06:58:01Z", "closed_at": "2018-11-16T21:42:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'd like to use Tensorflow Transform to impute missing values in a training dataset...it seems like this should be possible, correct? I believe I should save off some analyzers to do this imputing during training, but I'm not certain how to pull out those analyzers and work with them during training. Can someone point me in the right direction?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/66", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/66/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/66/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/66/events", "html_url": "https://github.com/tensorflow/transform/issues/66", "id": 332548641, "node_id": "MDU6SXNzdWUzMzI1NDg2NDE=", "number": 66, "title": "apply tft.TFTransformOutput.transformed_feature_spec to tf.data", "user": {"login": "Debasish-Das-CK", "id": 36423099, "node_id": "MDQ6VXNlcjM2NDIzMDk5", "avatar_url": "https://avatars1.githubusercontent.com/u/36423099?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Debasish-Das-CK", "html_url": "https://github.com/Debasish-Das-CK", "followers_url": "https://api.github.com/users/Debasish-Das-CK/followers", "following_url": "https://api.github.com/users/Debasish-Das-CK/following{/other_user}", "gists_url": "https://api.github.com/users/Debasish-Das-CK/gists{/gist_id}", "starred_url": "https://api.github.com/users/Debasish-Das-CK/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Debasish-Das-CK/subscriptions", "organizations_url": "https://api.github.com/users/Debasish-Das-CK/orgs", "repos_url": "https://api.github.com/users/Debasish-Das-CK/repos", "events_url": "https://api.github.com/users/Debasish-Das-CK/events{/privacy}", "received_events_url": "https://api.github.com/users/Debasish-Das-CK/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-06-14T20:15:48Z", "updated_at": "2018-07-01T21:25:36Z", "closed_at": "2018-06-25T20:17:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "dataset = tf.contrib.data.make_batched_features_dataset(\r\n        file_pattern=transformed_examples,\r\n        batch_size=batch_size,\r\n        features=tf_transform_output.transformed_feature_spec(),\r\n        reader=tf.data.TFRecordDataset,\r\n        shuffle=True)\r\ntft examples uses a contrib API which is not official. Can I use the following ?\r\n\r\ndataset = tf.data.TFRecordDataset(filenames_list)\r\ndataset = dataset.map(_parse_proto)\r\ndataset.map(tf_transform_output.transformed_feature_spec())", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/63", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/63/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/63/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/63/events", "html_url": "https://github.com/tensorflow/transform/issues/63", "id": 327126540, "node_id": "MDU6SXNzdWUzMjcxMjY1NDA=", "number": 63, "title": "tft.quantiles() returns fewer than num of buckets -1 values", "user": {"login": "cnsgsz", "id": 1569955, "node_id": "MDQ6VXNlcjE1Njk5NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/1569955?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cnsgsz", "html_url": "https://github.com/cnsgsz", "followers_url": "https://api.github.com/users/cnsgsz/followers", "following_url": "https://api.github.com/users/cnsgsz/following{/other_user}", "gists_url": "https://api.github.com/users/cnsgsz/gists{/gist_id}", "starred_url": "https://api.github.com/users/cnsgsz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cnsgsz/subscriptions", "organizations_url": "https://api.github.com/users/cnsgsz/orgs", "repos_url": "https://api.github.com/users/cnsgsz/repos", "events_url": "https://api.github.com/users/cnsgsz/events{/privacy}", "received_events_url": "https://api.github.com/users/cnsgsz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-05-28T22:24:27Z", "updated_at": "2018-11-16T19:39:31Z", "closed_at": "2018-11-16T19:39:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "when the input has fewer than number of buckets -1 distinct values.\r\nfor example, if the inputs are 30 negative ones, 40 zeros, and 30 ones. quantiles() with 10 buckets only returns [-1, 0, 1].\r\nsimilarly, when the values are all zeros, quantiles only returns [0].\r\nthis behavior is inconsistent with numpy.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/62", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/62/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/62/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/62/events", "html_url": "https://github.com/tensorflow/transform/issues/62", "id": 327126062, "node_id": "MDU6SXNzdWUzMjcxMjYwNjI=", "number": 62, "title": "support for reduce_instance_dims in quantiles", "user": {"login": "cnsgsz", "id": 1569955, "node_id": "MDQ6VXNlcjE1Njk5NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/1569955?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cnsgsz", "html_url": "https://github.com/cnsgsz", "followers_url": "https://api.github.com/users/cnsgsz/followers", "following_url": "https://api.github.com/users/cnsgsz/following{/other_user}", "gists_url": "https://api.github.com/users/cnsgsz/gists{/gist_id}", "starred_url": "https://api.github.com/users/cnsgsz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cnsgsz/subscriptions", "organizations_url": "https://api.github.com/users/cnsgsz/orgs", "repos_url": "https://api.github.com/users/cnsgsz/repos", "events_url": "https://api.github.com/users/cnsgsz/events{/privacy}", "received_events_url": "https://api.github.com/users/cnsgsz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "michaelwunder", "id": 49796461, "node_id": "MDQ6VXNlcjQ5Nzk2NDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/49796461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwunder", "html_url": "https://github.com/michaelwunder", "followers_url": "https://api.github.com/users/michaelwunder/followers", "following_url": "https://api.github.com/users/michaelwunder/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwunder/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwunder/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwunder/subscriptions", "organizations_url": "https://api.github.com/users/michaelwunder/orgs", "repos_url": "https://api.github.com/users/michaelwunder/repos", "events_url": "https://api.github.com/users/michaelwunder/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwunder/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-05-28T22:19:27Z", "updated_at": "2019-12-02T21:30:48Z", "closed_at": "2019-12-02T21:30:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "just as min, max etc in analyzer.py.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/60", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/60/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/60/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/60/events", "html_url": "https://github.com/tensorflow/transform/issues/60", "id": 325442092, "node_id": "MDU6SXNzdWUzMjU0NDIwOTI=", "number": 60, "title": "'tft.coders' usage in examples doesn't work with packaged release?", "user": {"login": "amygdala", "id": 115093, "node_id": "MDQ6VXNlcjExNTA5Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/115093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amygdala", "html_url": "https://github.com/amygdala", "followers_url": "https://api.github.com/users/amygdala/followers", "following_url": "https://api.github.com/users/amygdala/following{/other_user}", "gists_url": "https://api.github.com/users/amygdala/gists{/gist_id}", "starred_url": "https://api.github.com/users/amygdala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amygdala/subscriptions", "organizations_url": "https://api.github.com/users/amygdala/orgs", "repos_url": "https://api.github.com/users/amygdala/repos", "events_url": "https://api.github.com/users/amygdala/events{/privacy}", "received_events_url": "https://api.github.com/users/amygdala/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-05-22T20:01:22Z", "updated_at": "2018-05-22T22:18:21Z", "closed_at": "2018-05-22T22:13:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "In trying to run the examples, I get an error accessing `tft.coders`, which I see was added to the samples 15 days ago.  I'm using the 'pip install' latest version of TFT, which is 0.6.\r\nWhat version is necessary to run the examples now? (Am I missing something?)\r\n\r\n(my dev rel opinion:  user-facing examples should sync with the publicly released packages so that the examples always work).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/59", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/59/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/59/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/59/events", "html_url": "https://github.com/tensorflow/transform/issues/59", "id": 323807171, "node_id": "MDU6SXNzdWUzMjM4MDcxNzE=", "number": 59, "title": "Migrate examples and documentation to TF core", "user": {"login": "amygdala", "id": 115093, "node_id": "MDQ6VXNlcjExNTA5Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/115093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amygdala", "html_url": "https://github.com/amygdala", "followers_url": "https://api.github.com/users/amygdala/followers", "following_url": "https://api.github.com/users/amygdala/following{/other_user}", "gists_url": "https://api.github.com/users/amygdala/gists{/gist_id}", "starred_url": "https://api.github.com/users/amygdala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amygdala/subscriptions", "organizations_url": "https://api.github.com/users/amygdala/orgs", "repos_url": "https://api.github.com/users/amygdala/repos", "events_url": "https://api.github.com/users/amygdala/events{/privacy}", "received_events_url": "https://api.github.com/users/amygdala/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "amygdala", "id": 115093, "node_id": "MDQ6VXNlcjExNTA5Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/115093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amygdala", "html_url": "https://github.com/amygdala", "followers_url": "https://api.github.com/users/amygdala/followers", "following_url": "https://api.github.com/users/amygdala/following{/other_user}", "gists_url": "https://api.github.com/users/amygdala/gists{/gist_id}", "starred_url": "https://api.github.com/users/amygdala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amygdala/subscriptions", "organizations_url": "https://api.github.com/users/amygdala/orgs", "repos_url": "https://api.github.com/users/amygdala/repos", "events_url": "https://api.github.com/users/amygdala/events{/privacy}", "received_events_url": "https://api.github.com/users/amygdala/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "amygdala", "id": 115093, "node_id": "MDQ6VXNlcjExNTA5Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/115093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amygdala", "html_url": "https://github.com/amygdala", "followers_url": "https://api.github.com/users/amygdala/followers", "following_url": "https://api.github.com/users/amygdala/following{/other_user}", "gists_url": "https://api.github.com/users/amygdala/gists{/gist_id}", "starred_url": "https://api.github.com/users/amygdala/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amygdala/subscriptions", "organizations_url": "https://api.github.com/users/amygdala/orgs", "repos_url": "https://api.github.com/users/amygdala/repos", "events_url": "https://api.github.com/users/amygdala/events{/privacy}", "received_events_url": "https://api.github.com/users/amygdala/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-05-16T22:15:48Z", "updated_at": "2018-10-05T15:05:37Z", "closed_at": "2018-10-05T15:05:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there some reason these examples are still using tf.contrib.learn?\r\ne.g. https://github.com/tensorflow/transform/blob/master/examples/census_example.py#L31\r\n\r\n(seems like that's not going to help demystify tft for users..)\r\n\r\nUpdate: similarly re: mentions of \"tf.Learn\" in the docs, e.g. here: https://github.com/tensorflow/transform/blob/master/getting_started.md\r\nI think this will just confuse people.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/58", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/58/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/58/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/58/events", "html_url": "https://github.com/tensorflow/transform/issues/58", "id": 323496540, "node_id": "MDU6SXNzdWUzMjM0OTY1NDA=", "number": 58, "title": "Help with apply_function", "user": {"login": "codebreach", "id": 501516, "node_id": "MDQ6VXNlcjUwMTUxNg==", "avatar_url": "https://avatars3.githubusercontent.com/u/501516?v=4", "gravatar_id": "", "url": "https://api.github.com/users/codebreach", "html_url": "https://github.com/codebreach", "followers_url": "https://api.github.com/users/codebreach/followers", "following_url": "https://api.github.com/users/codebreach/following{/other_user}", "gists_url": "https://api.github.com/users/codebreach/gists{/gist_id}", "starred_url": "https://api.github.com/users/codebreach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/codebreach/subscriptions", "organizations_url": "https://api.github.com/users/codebreach/orgs", "repos_url": "https://api.github.com/users/codebreach/repos", "events_url": "https://api.github.com/users/codebreach/events{/privacy}", "received_events_url": "https://api.github.com/users/codebreach/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-05-16T07:19:20Z", "updated_at": "2018-10-20T17:44:57Z", "closed_at": "2018-10-20T17:44:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to calculate the length of the input text as part of the `preprocessing_fn` and cant figure out the right way to do it:\r\n\r\n```py\r\n    outputs['text'] = tft.mappers.string_to_int(outputs['text'])\r\n    outputs['text_length'] = tft.apply_function(lambda i: tf.cast(tf.convert_to_tensor(tf.size(i)), tf.int64)], outputs['text'])\r\n    # essentially want to do \r\n    outputs['text_length'] = tft.apply_function(lambda i: tf.size(i), outputs['text'])\r\n```\r\n\r\nbut i get the following error:\r\n\r\n```\r\nFile \"clause_type_raw_to_tf.py\", line 453, in <module>\r\n    main()\r\n  File \"clause_type_raw_to_tf.py\", line 450, in main\r\n    transform_data(train_data_file, test_data_file, working_dir, pipeline_args)\r\n  File \"clause_type_raw_to_tf.py\", line 378, in transform_data\r\n    raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/transforms/ptransform.py\", line 488, in __ror__\r\n    result = p.apply(self, pvalueish, label)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/pipeline.py\", line 479, in apply\r\n    pvalueish_result = self.runner.apply(transform, pvalueish)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/runners/runner.py\", line 174, in apply\r\n    return m(transform, input)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/runners/runner.py\", line 180, in apply_PTransform\r\n    return transform.expand(input)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/tensorflow_transform/beam/impl.py\", line 825, in expand\r\n    dataset | 'AnalyzeDataset' >> AnalyzeDataset(self._preprocessing_fn))\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/transforms/ptransform.py\", line 820, in __ror__\r\n    return self.transform.__ror__(pvalueish, self.label)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/transforms/ptransform.py\", line 488, in __ror__\r\n    result = p.apply(self, pvalueish, label)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/pipeline.py\", line 443, in apply\r\n    return self.apply(transform, pvalueish)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/pipeline.py\", line 479, in apply\r\n    pvalueish_result = self.runner.apply(transform, pvalueish)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/runners/runner.py\", line 174, in apply\r\n    return m(transform, input)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/apache_beam/runners/runner.py\", line 180, in apply_PTransform\r\n    return transform.expand(input)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/tensorflow_transform/beam/impl.py\", line 764, in expand\r\n    schema=impl_helper.infer_feature_schema(outputs))\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/tensorflow_transform/impl_helper.py\", line 60, in infer_feature_schema\r\n    for name, tensor in six.iteritems(tensors)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/tensorflow_transform/impl_helper.py\", line 60, in <dictcomp>\r\n    for name, tensor in six.iteritems(tensors)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/tensorflow_transform/tf_metadata/dataset_schema.py\", line 562, in infer_column_schema_from_tensor\r\n    remove_batch_dimension=True)\r\n  File \"/home/madhav/ml-engine-cnn/beam-pipelines/env/local/lib/python2.7/site-packages/tensorflow_transform/tf_metadata/dataset_schema.py\", line 591, in _shape_to_axes\r\n    raise ValueError('Expected tf_shape to have rank >= 1')\r\nValueError: Expected tf_shape to have rank >= 1\r\n```\r\n\r\n\r\nSeems to be caused by the batching performed by tft automatically. I couldnt find any documentation or guidelines on how to do such a thing... Can someone help with an example? I am sure the community would find it useful.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/56", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/56/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/56/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/56/events", "html_url": "https://github.com/tensorflow/transform/issues/56", "id": 322590062, "node_id": "MDU6SXNzdWUzMjI1OTAwNjI=", "number": 56, "title": "Normalize subgroups", "user": {"login": "The-Fonz", "id": 5527529, "node_id": "MDQ6VXNlcjU1Mjc1Mjk=", "avatar_url": "https://avatars3.githubusercontent.com/u/5527529?v=4", "gravatar_id": "", "url": "https://api.github.com/users/The-Fonz", "html_url": "https://github.com/The-Fonz", "followers_url": "https://api.github.com/users/The-Fonz/followers", "following_url": "https://api.github.com/users/The-Fonz/following{/other_user}", "gists_url": "https://api.github.com/users/The-Fonz/gists{/gist_id}", "starred_url": "https://api.github.com/users/The-Fonz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/The-Fonz/subscriptions", "organizations_url": "https://api.github.com/users/The-Fonz/orgs", "repos_url": "https://api.github.com/users/The-Fonz/repos", "events_url": "https://api.github.com/users/The-Fonz/events{/privacy}", "received_events_url": "https://api.github.com/users/The-Fonz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1102009020, "node_id": "MDU6TGFiZWwxMTAyMDA5MDIw", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:support", "name": "type:support", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-05-13T12:31:44Z", "updated_at": "2018-10-23T20:53:57Z", "closed_at": "2018-10-23T20:53:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nWhat I'd like to be able to do is normalize a column per subgroup, so per key that is contained in another column. Something like `.groupby('column').apply(normalizefunc)` in pandas, and I guess I can implement it in Beam using `GroupByKey` but the prospect of having an automatically generated transform graph for use during inference is just very attractive.\r\n\r\nI looked through the source and can't find this functionality but it looks like you guys are doing similar things with tf-idf and similar computations. Did I overlook this groupby-scale functionality, is it in the works or something you envision implementing in the near future?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/55", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/55/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/55/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/55/events", "html_url": "https://github.com/tensorflow/transform/issues/55", "id": 320463892, "node_id": "MDU6SXNzdWUzMjA0NjM4OTI=", "number": 55, "title": "Regarding writing the files to TFRecord there is an error saying no attribute schema when the transformed schema is provided", "user": {"login": "gaganmalhotra", "id": 10791093, "node_id": "MDQ6VXNlcjEwNzkxMDkz", "avatar_url": "https://avatars3.githubusercontent.com/u/10791093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaganmalhotra", "html_url": "https://github.com/gaganmalhotra", "followers_url": "https://api.github.com/users/gaganmalhotra/followers", "following_url": "https://api.github.com/users/gaganmalhotra/following{/other_user}", "gists_url": "https://api.github.com/users/gaganmalhotra/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaganmalhotra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaganmalhotra/subscriptions", "organizations_url": "https://api.github.com/users/gaganmalhotra/orgs", "repos_url": "https://api.github.com/users/gaganmalhotra/repos", "events_url": "https://api.github.com/users/gaganmalhotra/events{/privacy}", "received_events_url": "https://api.github.com/users/gaganmalhotra/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-05-05T00:23:35Z", "updated_at": "2018-10-23T21:43:02Z", "closed_at": "2018-10-23T20:48:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Even when the transformed schema is provided, there seems to be an error while we write the transformed data to tensorflow record - \r\n\r\n\r\nThe error that is thrown looks something similar - \r\n\r\n\r\n> 'BeamDatasetMetadata' object has no attribute 'schema' [while running 'AnalyzeAndTransformDataset/TransformDataset/ConvertAndUnbatch']\r\n\r\n\r\n\r\nPlease find the snippet of the code below - \r\n\r\n```\r\nraw_data = (\r\n          pipeline\r\n          | 'ReadTrainData' >> textio.ReadFromText(train_data_file)\r\n          | 'FilterTrainData' >> beam.Filter(\r\n              lambda line: line and line != 'app_category,connection_type,creative_id,day_of_week,device_size,geo,hour_of_day,num_of_connects,num_of_conversions,opt_bid,os_version')\r\n          | 'FixCommasTrainData' >> beam.Map(\r\n              lambda line: line.replace(', ', ','))\r\n          | 'DecodeTrainData' >> MapAndFilterErrors(converter.decode))\r\n\r\n      # Combine data and schema into a dataset tuple.  Note that we already used\r\n      # the schema to read the CSV data, but we also need it to interpret\r\n      # raw_data.\r\n\r\n      raw_dataset = (raw_data, RAW_DATA_METADATA)\r\n      transformed_dataset, transform_fn = (\r\n          raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\r\n\r\n      transformed_data, transformed_metadata = transformed_dataset\r\n\r\n      transformed_data_coder = example_proto_coder.ExampleProtoCoder(transformed_metadata.schema)\r\n\r\n      _ = (\r\n          transformed_data\r\n          | 'EncodeTrainData' >> beam.Map(transformed_data_coder.encode)\r\n          | 'WriteTrainData' >> tfrecordio.WriteToTFRecord(\r\n              os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE)))\r\n\r\n      # Now apply transform function to test data.  In this case we also remove\r\n      # the header line from the CSV file and the trailing period at the end of\r\n      # each line.\r\n      raw_test_data = (\r\n         pipeline\r\n          | 'ReadTestData' >> textio.ReadFromText(test_data_file, skip_header_lines=1)\r\n          | 'FixCommasTestData' >> beam.Map(\r\n              lambda line: line.replace(', ', ','))\r\n          | 'DecodeTestData' >> beam.Map(converter.decode))\r\n\r\n      raw_test_dataset = (raw_test_data, RAW_DATA_METADATA)\r\n\r\n      transformed_test_dataset = ((raw_test_dataset, transform_fn) | beam_impl.TransformDataset())\r\n      # Don't need transformed data schema, it's the same as before.\r\n      transformed_test_data, _ = transformed_test_dataset\r\n\r\n      _ = (\r\n          transformed_test_data\r\n          | 'EncodeTestData' >> beam.Map(transformed_data_coder.encode)\r\n          | 'WriteTestData' >> tfrecordio.WriteToTFRecord(\r\n             os.path.join(working_dir, TRANSFORMED_TEST_DATA_FILEBASE)))\r\n\r\n      _ = (\r\n          transform_fn\r\n          | 'WriteTransformFn' >>\r\n          transform_fn_io.WriteTransformFn(working_dir))\r\n```\r\n\r\n\r\n@KesterTong  I hope you can help me out in this case as it looks like it is caused unexpectedly only sometimes while applying transformation to data \r\n\r\n\r\nPS:\r\nTensorflow version - 1.4\r\nTensorflow transform version - 0.4.0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/54", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/54/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/54/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/54/events", "html_url": "https://github.com/tensorflow/transform/issues/54", "id": 319763866, "node_id": "MDU6SXNzdWUzMTk3NjM4NjY=", "number": 54, "title": "Error using apply_function", "user": {"login": "fabito", "id": 308613, "node_id": "MDQ6VXNlcjMwODYxMw==", "avatar_url": "https://avatars2.githubusercontent.com/u/308613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fabito", "html_url": "https://github.com/fabito", "followers_url": "https://api.github.com/users/fabito/followers", "following_url": "https://api.github.com/users/fabito/following{/other_user}", "gists_url": "https://api.github.com/users/fabito/gists{/gist_id}", "starred_url": "https://api.github.com/users/fabito/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fabito/subscriptions", "organizations_url": "https://api.github.com/users/fabito/orgs", "repos_url": "https://api.github.com/users/fabito/repos", "events_url": "https://api.github.com/users/fabito/events{/privacy}", "received_events_url": "https://api.github.com/users/fabito/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101989219, "node_id": "MDU6TGFiZWwxMTAxOTg5MjE5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:bug", "name": "type:bug", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-05-03T01:36:33Z", "updated_at": "2019-03-15T17:06:24Z", "closed_at": "2019-03-15T17:06:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI'm trying to apply the function below:\r\n\r\n```python\r\ndef _group_ethnic(original):\r\n    unknonw_cat = tf.constant(['UNCODABLE', 'UNCODED', 'ASIAN AMERICAN 2', 'NULL'])\r\n    caucasian_cat = tf.constant(['SCANDINAVIAN', 'MEDITERRANEAN', 'WESTERN EUROPEAN'])\r\n    east_asian_cat = tf.constant(['POLYNESIAN', 'EAST ASIAN'])\r\n    zero = tf.constant(0, dtype=tf.int64)\r\n    return tf.case({\r\n        tf.greater(tf.count_nonzero(tf.equal(unknonw_cat, original)), zero): lambda: tf.constant('Unknown'),\r\n        tf.greater(tf.count_nonzero(tf.equal(caucasian_cat, original)), zero): lambda: tf.constant('CAUCASIAN (NON-HISPANIC)'),\r\n        tf.greater(tf.count_nonzero(tf.equal(east_asian_cat, original)), zero): lambda: tf.constant('EAST ASIAN/PACIFIC ISLANDER')\r\n    }, default=lambda: original, exclusive=True, name='group_ethnic')\r\n```\r\nusing `tft.apply_function` like this:\r\n\r\n```python\r\nnew_ethnic_group = tft.apply_function(_group_ethnic, inputs['ethnic'])\r\noutputs['ethnic'] = tft.string_to_int(new_ethnic_group, vocab_filename='ethnic')\r\n```\r\nYou can also see it running on [colab](https://colab.research.google.com/drive/1JInWjkPVQ7jTg92HF7BSEj9aDAnnQgGH).\r\n\r\nBut the following error is being raised:\r\n\r\n```\r\nFile \"/home/user/.virtualenvs/env1/local/lib/python2.7/site-packages/tensorflow_transform/beam/impl.py\", line 670, in expand\r\n  outputs = self._preprocessing_fn(impl_helper.copy_tensors(inputs))\r\nFile \"/home/user/Workspaces/env1/proj/preprocess/transform.py\", line 153, in preprocessing_fn\r\n  new_ethnic_group = tft.apply_function(_group_ethnic, inputs['ethnic'])\r\nFile \"/home/user/.virtualenvs/env1/local/lib/python2.7/site-packages/tensorflow_transform/api.py\", line 161, in apply_function\r\n  return FunctionApplication(fn, args).user_output\r\nFile \"/home/user/.virtualenvs/env1/local/lib/python2.7/site-packages/tensorflow_transform/api.py\", line 89, in __init__\r\n  output = fn(*args)\r\nFile \"/home/user/Workspaces/env1/proj/preprocess/transform.py\", line 148, in _group_ethnic\r\n  tf.greater(tf.count_nonzero(tf.equal(unknown_cat, original)), zero): lambda: tf.constant('Unknown'),\r\nFile \"/home/user/.virtualenvs/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1489, in equal\r\n  \"Equal\", x=x, y=y, name=name)\r\nFile \"/home/user/.virtualenvs/env1/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 519, in _apply_op_helper\r\n  repr(values), type(values).__name__))\r\nTypeError: Expected string passed to parameter 'y' of op 'Equal', got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fbdc112a090> of type 'SparseTensor' instead.\r\n```\r\nDoes anyone know what I'm missing ?\r\n\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/49", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/49/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/49/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/49/events", "html_url": "https://github.com/tensorflow/transform/issues/49", "id": 314648500, "node_id": "MDU6SXNzdWUzMTQ2NDg1MDA=", "number": 49, "title": "Transform without having to write to disk", "user": {"login": "galderic", "id": 12606931, "node_id": "MDQ6VXNlcjEyNjA2OTMx", "avatar_url": "https://avatars3.githubusercontent.com/u/12606931?v=4", "gravatar_id": "", "url": "https://api.github.com/users/galderic", "html_url": "https://github.com/galderic", "followers_url": "https://api.github.com/users/galderic/followers", "following_url": "https://api.github.com/users/galderic/following{/other_user}", "gists_url": "https://api.github.com/users/galderic/gists{/gist_id}", "starred_url": "https://api.github.com/users/galderic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/galderic/subscriptions", "organizations_url": "https://api.github.com/users/galderic/orgs", "repos_url": "https://api.github.com/users/galderic/repos", "events_url": "https://api.github.com/users/galderic/events{/privacy}", "received_events_url": "https://api.github.com/users/galderic/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-04-16T13:22:03Z", "updated_at": "2018-04-18T22:39:11Z", "closed_at": "2018-04-18T10:10:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is it possible to transform features on the fly while feeding the training input pipeline? In a similar way as the 'normalizer_fn' works in tf.feature_column.numeric_column.  In all the examples I've seen everything is transformed, written to disk, and then read back. I'd like to be able to use (or wrap) the PCollection as a tf.data.DataSet.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/48", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/48/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/48/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/48/events", "html_url": "https://github.com/tensorflow/transform/issues/48", "id": 312356026, "node_id": "MDU6SXNzdWUzMTIzNTYwMjY=", "number": 48, "title": "Location of data for examples?", "user": {"login": "jbingham", "id": 563113, "node_id": "MDQ6VXNlcjU2MzExMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/563113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbingham", "html_url": "https://github.com/jbingham", "followers_url": "https://api.github.com/users/jbingham/followers", "following_url": "https://api.github.com/users/jbingham/following{/other_user}", "gists_url": "https://api.github.com/users/jbingham/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbingham/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbingham/subscriptions", "organizations_url": "https://api.github.com/users/jbingham/orgs", "repos_url": "https://api.github.com/users/jbingham/repos", "events_url": "https://api.github.com/users/jbingham/events{/privacy}", "received_events_url": "https://api.github.com/users/jbingham/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101986612, "node_id": "MDU6TGFiZWwxMTAxOTg2NjEy", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false, "description": ""}, {"id": 1101994909, "node_id": "MDU6TGFiZWwxMTAxOTk0OTA5", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-04-09T00:17:29Z", "updated_at": "2018-10-23T20:45:24Z", "closed_at": "2018-10-23T20:45:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "The census and sentiment examples require data files that aren't located in this git repo, and there's no documentation (at least not that I saw) about where to find them.\r\n\r\nShould there be a test data folder? Or if the data is too big, a cloud bucket perhaps?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/45", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/45/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/45/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/45/events", "html_url": "https://github.com/tensorflow/transform/issues/45", "id": 290401687, "node_id": "MDU6SXNzdWUyOTA0MDE2ODc=", "number": 45, "title": "Python 3 syntax error in tensorflow_transform/beam/impl_test.py", "user": {"login": "cclauss", "id": 3709715, "node_id": "MDQ6VXNlcjM3MDk3MTU=", "avatar_url": "https://avatars3.githubusercontent.com/u/3709715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cclauss", "html_url": "https://github.com/cclauss", "followers_url": "https://api.github.com/users/cclauss/followers", "following_url": "https://api.github.com/users/cclauss/following{/other_user}", "gists_url": "https://api.github.com/users/cclauss/gists{/gist_id}", "starred_url": "https://api.github.com/users/cclauss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cclauss/subscriptions", "organizations_url": "https://api.github.com/users/cclauss/orgs", "repos_url": "https://api.github.com/users/cclauss/repos", "events_url": "https://api.github.com/users/cclauss/events{/privacy}", "received_events_url": "https://api.github.com/users/cclauss/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-22T09:39:12Z", "updated_at": "2018-10-17T00:14:23Z", "closed_at": "2018-10-17T00:14:23Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "See https://github.com/tensorflow/transform/issues/1#issuecomment-355901983", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/36", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/36/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/36/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/36/events", "html_url": "https://github.com/tensorflow/transform/issues/36", "id": 264627655, "node_id": "MDU6SXNzdWUyNjQ2Mjc2NTU=", "number": 36, "title": "I can not use Estimator from tf.estimator package  TF 1.3", "user": {"login": "lukashes", "id": 1044059, "node_id": "MDQ6VXNlcjEwNDQwNTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1044059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukashes", "html_url": "https://github.com/lukashes", "followers_url": "https://api.github.com/users/lukashes/followers", "following_url": "https://api.github.com/users/lukashes/following{/other_user}", "gists_url": "https://api.github.com/users/lukashes/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukashes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukashes/subscriptions", "organizations_url": "https://api.github.com/users/lukashes/orgs", "repos_url": "https://api.github.com/users/lukashes/repos", "events_url": "https://api.github.com/users/lukashes/events{/privacy}", "received_events_url": "https://api.github.com/users/lukashes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "davidsoergel", "id": 1347381, "node_id": "MDQ6VXNlcjEzNDczODE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1347381?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidsoergel", "html_url": "https://github.com/davidsoergel", "followers_url": "https://api.github.com/users/davidsoergel/followers", "following_url": "https://api.github.com/users/davidsoergel/following{/other_user}", "gists_url": "https://api.github.com/users/davidsoergel/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidsoergel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidsoergel/subscriptions", "organizations_url": "https://api.github.com/users/davidsoergel/orgs", "repos_url": "https://api.github.com/users/davidsoergel/repos", "events_url": "https://api.github.com/users/davidsoergel/events{/privacy}", "received_events_url": "https://api.github.com/users/davidsoergel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "davidsoergel", "id": 1347381, "node_id": "MDQ6VXNlcjEzNDczODE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1347381?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidsoergel", "html_url": "https://github.com/davidsoergel", "followers_url": "https://api.github.com/users/davidsoergel/followers", "following_url": "https://api.github.com/users/davidsoergel/following{/other_user}", "gists_url": "https://api.github.com/users/davidsoergel/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidsoergel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidsoergel/subscriptions", "organizations_url": "https://api.github.com/users/davidsoergel/orgs", "repos_url": "https://api.github.com/users/davidsoergel/repos", "events_url": "https://api.github.com/users/davidsoergel/events{/privacy}", "received_events_url": "https://api.github.com/users/davidsoergel/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/tensorflow/transform/milestones/1", "html_url": "https://github.com/tensorflow/transform/milestone/1", "labels_url": "https://api.github.com/repos/tensorflow/transform/milestones/1/labels", "id": 2852165, "node_id": "MDk6TWlsZXN0b25lMjg1MjE2NQ==", "number": 1, "title": "0.3.1", "description": "tf.Transform version 0.3.1", "creator": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 2, "state": "closed", "created_at": "2017-10-19T19:06:25Z", "updated_at": "2017-10-22T16:36:17Z", "due_on": "2017-10-27T07:00:00Z", "closed_at": "2017-10-20T21:13:47Z"}, "comments": 5, "created_at": "2017-10-11T15:15:44Z", "updated_at": "2017-10-20T21:14:11Z", "closed_at": "2017-10-20T21:14:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have this bundle:\r\n* TF: 1.3.0\r\n* TFT: 0.1.10\r\n* Python: 2.7.12\r\n\r\nI read TF 1.3 docs [here](https://www.tensorflow.org/programmers_guide/estimators) about Estimators:\r\n\r\n> Note: TensorFlow also provides an Estimator class at tf.contrib.learn.Estimator, which you should not use.\r\n\r\nI tried to change `learn.Estimator` with `tf.estimator.Estomator` and got error (all examples TFT works with `learn.Estimator`):\r\n\r\n> local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 440, in export_savedmodel\r\n>     serving_input_receiver.receiver_tensors,\r\n> AttributeError: 'InputFnOps' object has no attribute 'receiver_tensors'\r\n\r\nI use export_strategy for serving model through `tf.contrib.learn.Experiment` and it should support `tf.estimator.Estomator`, from docs:\r\n> estimator: Object implementing Estimator interface, which could be a combination of ${tf.contrib.learn.Trainable} and ${tf.contrib.learn.Evaluable} (deprecated), or ${tf.estimator.Estimator}.\r\n\r\nCan you explain what version of TFT/TF I should use, or what I am doing wrong?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/35", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/35/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/35/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/35/events", "html_url": "https://github.com/tensorflow/transform/issues/35", "id": 263650819, "node_id": "MDU6SXNzdWUyNjM2NTA4MTk=", "number": 35, "title": "\"Table not initialized\" error", "user": {"login": "jcomfort4", "id": 8152811, "node_id": "MDQ6VXNlcjgxNTI4MTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/8152811?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcomfort4", "html_url": "https://github.com/jcomfort4", "followers_url": "https://api.github.com/users/jcomfort4/followers", "following_url": "https://api.github.com/users/jcomfort4/following{/other_user}", "gists_url": "https://api.github.com/users/jcomfort4/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcomfort4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcomfort4/subscriptions", "organizations_url": "https://api.github.com/users/jcomfort4/orgs", "repos_url": "https://api.github.com/users/jcomfort4/repos", "events_url": "https://api.github.com/users/jcomfort4/events{/privacy}", "received_events_url": "https://api.github.com/users/jcomfort4/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2017-10-07T15:50:38Z", "updated_at": "2017-12-12T16:57:48Z", "closed_at": "2017-12-12T16:57:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Consider the simple example:\r\n\r\n```\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n    comma_separated = tf.constant([\"hello, hello, test, random\"], dtype=tf.string)\r\n    words = tf.string_split(comma_separated, delimiter = \", \")\r\n    indices = tft.string_to_int(words, top_k = 1)\r\n    \r\nsess = tf.InteractiveSession(graph=graph)\r\nprint(sess.run([indices]))\r\n```\r\n\r\nResults in the error:\r\n\r\n```\r\nFailedPreconditionError (see above for traceback): Table not initialized.\r\n\t [[Node: hash_table_Lookup = LookupTableFind[Tin=DT_STRING, Tout=DT_INT64, _class=[\"loc:@string_to_index/hash_table\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](string_to_index/hash_table, StringSplit:1, string_to_index/hash_table/Const)]]\r\n```\r\n\r\nI just ran pip install tensorflow-transform this morning so I believe tf is up to date. I'm guessing that maybe I am not up to date with the most recent tensorflow version that is needed? I am using tensorflow 1.2 because Google Cloud ML Engine does not yet support tensorflow 1.3. Is this the reason for the issue? I am trying to use TFT as a preprocessing script for my GCMLE experiment.\r\n\r\nI separately got a warning that may also be related to the issue:\r\n\r\n\"WARNING:tensorflow:From /Users/user/anaconda/lib/python2.7/site-packages/tensorflow_transform/mappers.py:305: string_to_index_table_from_tensor (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-04-10.\r\nInstructions for updating:\r\nUse `index_table_from_tensor`\"\r\n\r\nAny ideas what may be causing the issue?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/34", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/34/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/34/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/34/events", "html_url": "https://github.com/tensorflow/transform/issues/34", "id": 263649510, "node_id": "MDU6SXNzdWUyNjM2NDk1MTA=", "number": 34, "title": "string_to_index_table_from_tensor to be deprecated warning", "user": {"login": "jcomfort4", "id": 8152811, "node_id": "MDQ6VXNlcjgxNTI4MTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/8152811?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcomfort4", "html_url": "https://github.com/jcomfort4", "followers_url": "https://api.github.com/users/jcomfort4/followers", "following_url": "https://api.github.com/users/jcomfort4/following{/other_user}", "gists_url": "https://api.github.com/users/jcomfort4/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcomfort4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcomfort4/subscriptions", "organizations_url": "https://api.github.com/users/jcomfort4/orgs", "repos_url": "https://api.github.com/users/jcomfort4/repos", "events_url": "https://api.github.com/users/jcomfort4/events{/privacy}", "received_events_url": "https://api.github.com/users/jcomfort4/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/tensorflow/transform/milestones/2", "html_url": "https://github.com/tensorflow/transform/milestone/2", "labels_url": "https://api.github.com/repos/tensorflow/transform/milestones/2/labels", "id": 2852173, "node_id": "MDk6TWlsZXN0b25lMjg1MjE3Mw==", "number": 2, "title": "0.4", "description": "tf.Transform version 0.4", "creator": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 3, "state": "open", "created_at": "2017-10-19T19:10:55Z", "updated_at": "2017-12-12T17:04:18Z", "due_on": null, "closed_at": null}, "comments": 4, "created_at": "2017-10-07T15:31:49Z", "updated_at": "2017-12-12T16:52:47Z", "closed_at": "2017-12-12T16:52:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "WARNING:tensorflow:From /Users/user/anaconda/lib/python2.7/site-packages/tensorflow_transform/mappers.py:305: string_to_index_table_from_tensor (from tensorflow.contrib.lookup.lookup_ops) is deprecated and will be removed after 2017-04-10.\r\nInstructions for updating:\r\nUse `index_table_from_tensor`\r\n\r\nI am getting this warning after a pip install, but I don't see the deprecated function being used in the source code. Is the pip install out of date?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/31", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/31/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/31/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/31/events", "html_url": "https://github.com/tensorflow/transform/issues/31", "id": 258829345, "node_id": "MDU6SXNzdWUyNTg4MjkzNDU=", "number": 31, "title": "train_transformed* does not exist after 'WriteTrainData'", "user": {"login": "lukashes", "id": 1044059, "node_id": "MDQ6VXNlcjEwNDQwNTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/1044059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukashes", "html_url": "https://github.com/lukashes", "followers_url": "https://api.github.com/users/lukashes/followers", "following_url": "https://api.github.com/users/lukashes/following{/other_user}", "gists_url": "https://api.github.com/users/lukashes/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukashes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukashes/subscriptions", "organizations_url": "https://api.github.com/users/lukashes/orgs", "repos_url": "https://api.github.com/users/lukashes/repos", "events_url": "https://api.github.com/users/lukashes/events{/privacy}", "received_events_url": "https://api.github.com/users/lukashes/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2017-09-19T13:54:17Z", "updated_at": "2017-09-21T15:58:22Z", "closed_at": "2017-09-21T13:33:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying TF transform to save model and restore it.\r\n\r\nI wrote function (copied from examples):\r\n\r\n```\r\n    _ = (\r\n        transformed_train_data\r\n        | 'WriteTrainData' >> tfrecordio.WriteToTFRecord(\r\n            transformed_train_filebase,\r\n            coder=example_proto_coder.ExampleProtoCoder(\r\n                transformed_metadata.schema)))\r\n\r\n    ...\r\n    _ = (transformed_metadata\r\n         | 'WriteTransformedMetadata' >> beam_metadata_io.WriteMetadata(transformed_metadata_dir, pipeline=pipeline))\r\n```\r\n\r\nAfter start script I see error: `ValueError: No files match /tmp/aclImdb/tmpm6E1MH/train_transformed*.`\r\n\r\nFile really does not exist, but raw and metadata exists:\r\n\r\n> aclImdb/tmpm6E1MH$ ls -a\r\n> .  ..  metadata  raw\r\n\r\nWhat is problem? How can I debug WriteTrainData function?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/29", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/29/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/29/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/29/events", "html_url": "https://github.com/tensorflow/transform/issues/29", "id": 252218715, "node_id": "MDU6SXNzdWUyNTIyMTg3MTU=", "number": 29, "title": "How can we export the statistics about the dataset?", "user": {"login": "buffxz", "id": 5762852, "node_id": "MDQ6VXNlcjU3NjI4NTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/5762852?v=4", "gravatar_id": "", "url": "https://api.github.com/users/buffxz", "html_url": "https://github.com/buffxz", "followers_url": "https://api.github.com/users/buffxz/followers", "following_url": "https://api.github.com/users/buffxz/following{/other_user}", "gists_url": "https://api.github.com/users/buffxz/gists{/gist_id}", "starred_url": "https://api.github.com/users/buffxz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/buffxz/subscriptions", "organizations_url": "https://api.github.com/users/buffxz/orgs", "repos_url": "https://api.github.com/users/buffxz/repos", "events_url": "https://api.github.com/users/buffxz/events{/privacy}", "received_events_url": "https://api.github.com/users/buffxz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/tensorflow/transform/milestones/2", "html_url": "https://github.com/tensorflow/transform/milestone/2", "labels_url": "https://api.github.com/repos/tensorflow/transform/milestones/2/labels", "id": 2852173, "node_id": "MDk6TWlsZXN0b25lMjg1MjE3Mw==", "number": 2, "title": "0.4", "description": "tf.Transform version 0.4", "creator": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 3, "state": "open", "created_at": "2017-10-19T19:10:55Z", "updated_at": "2017-12-12T17:04:18Z", "due_on": null, "closed_at": null}, "comments": 4, "created_at": "2017-08-23T09:32:29Z", "updated_at": "2017-12-12T16:55:05Z", "closed_at": "2017-12-12T16:55:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "One typical use case about transformation is that, we compute the all the statistics summary about the dataset (e.g. the quantile value for the continuous features), then at training time, we can bucketize our continuous features using those quantile values. \r\n\r\nBut seems like the `statistics` object is not implemented. \r\n\r\nHow can we use the statistics?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/23", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/23/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/23/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/23/events", "html_url": "https://github.com/tensorflow/transform/issues/23", "id": 249679929, "node_id": "MDU6SXNzdWUyNDk2Nzk5Mjk=", "number": 23, "title": "string_to_int() got an unexpected keyword argument 'vocab_filename'", "user": {"login": "jcomfort4", "id": 8152811, "node_id": "MDQ6VXNlcjgxNTI4MTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/8152811?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jcomfort4", "html_url": "https://github.com/jcomfort4", "followers_url": "https://api.github.com/users/jcomfort4/followers", "following_url": "https://api.github.com/users/jcomfort4/following{/other_user}", "gists_url": "https://api.github.com/users/jcomfort4/gists{/gist_id}", "starred_url": "https://api.github.com/users/jcomfort4/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jcomfort4/subscriptions", "organizations_url": "https://api.github.com/users/jcomfort4/orgs", "repos_url": "https://api.github.com/users/jcomfort4/repos", "events_url": "https://api.github.com/users/jcomfort4/events{/privacy}", "received_events_url": "https://api.github.com/users/jcomfort4/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-08-11T16:05:13Z", "updated_at": "2017-08-24T19:04:06Z", "closed_at": "2017-08-24T17:53:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to use tft.string_to_int() with a vocab_filename, but when I ran this I got an error \r\n\r\nTypeError: string_to_int() got an unexpected keyword argument 'vocab_filename'. However, the mappers.py function shown here clearly has vocab_filename listed as an argument. Is this vocab_filename no longer supported?\r\n\r\nMy vocab filename is a .txt file with each vocab word on a newline and I was hoping that this would be usable to create the string_to_int function on the fly.  Is there some step that I am missing?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/17", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/17/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/17/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/17/events", "html_url": "https://github.com/tensorflow/transform/issues/17", "id": 233014779, "node_id": "MDU6SXNzdWUyMzMwMTQ3Nzk=", "number": 17, "title": "support for regular expressions", "user": {"login": "ibrahimiskin", "id": 11655390, "node_id": "MDQ6VXNlcjExNjU1Mzkw", "avatar_url": "https://avatars2.githubusercontent.com/u/11655390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibrahimiskin", "html_url": "https://github.com/ibrahimiskin", "followers_url": "https://api.github.com/users/ibrahimiskin/followers", "following_url": "https://api.github.com/users/ibrahimiskin/following{/other_user}", "gists_url": "https://api.github.com/users/ibrahimiskin/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibrahimiskin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibrahimiskin/subscriptions", "organizations_url": "https://api.github.com/users/ibrahimiskin/orgs", "repos_url": "https://api.github.com/users/ibrahimiskin/repos", "events_url": "https://api.github.com/users/ibrahimiskin/events{/privacy}", "received_events_url": "https://api.github.com/users/ibrahimiskin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1101984068, "node_id": "MDU6TGFiZWwxMTAxOTg0MDY4", "url": "https://api.github.com/repos/tensorflow/transform/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false, "description": ""}, {"id": 1101988236, "node_id": "MDU6TGFiZWwxMTAxOTg4MjM2", "url": "https://api.github.com/repos/tensorflow/transform/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": {"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "Harshini-Gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Harshini-Gadige", "html_url": "https://github.com/Harshini-Gadige", "followers_url": "https://api.github.com/users/Harshini-Gadige/followers", "following_url": "https://api.github.com/users/Harshini-Gadige/following{/other_user}", "gists_url": "https://api.github.com/users/Harshini-Gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/Harshini-Gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Harshini-Gadige/subscriptions", "organizations_url": "https://api.github.com/users/Harshini-Gadige/orgs", "repos_url": "https://api.github.com/users/Harshini-Gadige/repos", "events_url": "https://api.github.com/users/Harshini-Gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/Harshini-Gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2017-06-01T21:23:33Z", "updated_at": "2018-11-16T19:28:44Z", "closed_at": "2018-11-16T19:28:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi all,\r\nI would like to use regular expressions as part of preprocessing text data - so that it is usable by serving input function. I did quite a bit of searching, but could not find anything. Is this something currently not supported? If it is, I would appreciate your help.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/15", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/15/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/15/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/15/events", "html_url": "https://github.com/tensorflow/transform/issues/15", "id": 230855023, "node_id": "MDU6SXNzdWUyMzA4NTUwMjM=", "number": 15, "title": "running sentiment_example.py model as a server", "user": {"login": "ibrahimiskin", "id": 11655390, "node_id": "MDQ6VXNlcjExNjU1Mzkw", "avatar_url": "https://avatars2.githubusercontent.com/u/11655390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibrahimiskin", "html_url": "https://github.com/ibrahimiskin", "followers_url": "https://api.github.com/users/ibrahimiskin/followers", "following_url": "https://api.github.com/users/ibrahimiskin/following{/other_user}", "gists_url": "https://api.github.com/users/ibrahimiskin/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibrahimiskin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibrahimiskin/subscriptions", "organizations_url": "https://api.github.com/users/ibrahimiskin/orgs", "repos_url": "https://api.github.com/users/ibrahimiskin/repos", "events_url": "https://api.github.com/users/ibrahimiskin/events{/privacy}", "received_events_url": "https://api.github.com/users/ibrahimiskin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/tensorflow/transform/milestones/2", "html_url": "https://github.com/tensorflow/transform/milestone/2", "labels_url": "https://api.github.com/repos/tensorflow/transform/milestones/2/labels", "id": 2852173, "node_id": "MDk6TWlsZXN0b25lMjg1MjE3Mw==", "number": 2, "title": "0.4", "description": "tf.Transform version 0.4", "creator": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 3, "state": "open", "created_at": "2017-10-19T19:10:55Z", "updated_at": "2017-12-12T17:04:18Z", "due_on": null, "closed_at": null}, "comments": 10, "created_at": "2017-05-23T21:39:33Z", "updated_at": "2017-12-12T17:04:18Z", "closed_at": "2017-12-12T17:04:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi guys,\r\n\r\nI am new to Tensorflow, so bear with me if I am doing something completely wrong :-) I am following the text classification example at https://github.com/tensorflow/transform/blob/master/examples/sentiment_example.py\r\nModel development worked as expected. I am working on running the developed model on google ml engine environment. \r\n\r\nI added the following lines to \"train_and_evaluate\" function to export the model\r\n\r\n```\r\nfrom tensorflow.contrib.learn.python.learn.utils import input_fn_utils\r\nfrom tensorflow.contrib.layers import create_feature_spec_for_parsing\r\n\r\nfeature_spec = create_feature_spec_for_parsing(train_input_fn)\r\nserving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\r\nestimator.export_savedmodel(job_dir, serving_input_fn)\r\n\r\n```\r\nI am receiving the following error upon a classification request for a sample sentence \"nice piece of work .\" payload looks like this: {\"inputs\": \"nice piece of work .\"}\r\n\r\n```\r\n{\r\n  \"error\": \"Prediction failed: Exception during model execution: AbortionError(code=StatusCode.INVALID_ARGUMENT, details=\\\"Could not parse example input, value: 'nice piece of work .'\\n\\t [[Node: ParseExample/ParseExample = ParseExample[Ndense=0, Nsparse=2, Tdense=[], _output_shapes=[[-1,2], [-1,2], [-1], [-1], [2], [2]], dense_shapes=[], sparse_types=[DT_INT64, DT_FLOAT], _device=\\\"/job:localhost/replica:0/task:0/cpu:0\\\"](_recv_input_example_tensor_0, ParseExample/ParseExample/names, ParseExample/ParseExample/sparse_keys_0, ParseExample/ParseExample/sparse_keys_1)]]\\\")\"\r\n}\r\n\r\n```\r\nAm I getting this error because the model object is expecting integerized tensors? If so, I attempted to use build_parsing_transforming_serving_input_fn function at https://github.com/tensorflow/transform/blob/master/tensorflow_transform/saved/input_fn_maker.py\r\nto perform transformation at run time, it appears that I need a transform_savedmodel_dir that embodies the transformation model with the parsing logic. I figure, this is achieved by using write_saved_transform_from_session at https://github.com/tensorflow/transform/blob/master/tensorflow_transform/saved/saved_transform_io.py\r\n\r\nCan you guys share an example code that exports a transform model? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/12", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/12/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/12/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/12/events", "html_url": "https://github.com/tensorflow/transform/issues/12", "id": 222728567, "node_id": "MDU6SXNzdWUyMjI3Mjg1Njc=", "number": 12, "title": "Using `scale_to_0_1` on list of numbers", "user": {"login": "kbitsakos", "id": 27768872, "node_id": "MDQ6VXNlcjI3NzY4ODcy", "avatar_url": "https://avatars1.githubusercontent.com/u/27768872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kbitsakos", "html_url": "https://github.com/kbitsakos", "followers_url": "https://api.github.com/users/kbitsakos/followers", "following_url": "https://api.github.com/users/kbitsakos/following{/other_user}", "gists_url": "https://api.github.com/users/kbitsakos/gists{/gist_id}", "starred_url": "https://api.github.com/users/kbitsakos/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kbitsakos/subscriptions", "organizations_url": "https://api.github.com/users/kbitsakos/orgs", "repos_url": "https://api.github.com/users/kbitsakos/repos", "events_url": "https://api.github.com/users/kbitsakos/events{/privacy}", "received_events_url": "https://api.github.com/users/kbitsakos/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2017-04-19T12:54:32Z", "updated_at": "2017-04-21T08:51:13Z", "closed_at": "2017-04-21T08:51:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Given a dataset with a numerical column containing a list of numbers, is it possible to normalize each element of the list in the [0,1] range? \r\n\r\nI successfully used the 'scale_to_0_1' function to normalize numerical columns containing a single value, but cannot apply it to a list of numbers.\r\n\r\nOn the following toy dataset\r\n\r\n```\r\nstudent id, previous grades\r\n1, [0, 5, 6]\r\n2, [7, 8, 10]\r\n```\r\nI would like to obtain the following transformed dataset\r\n```\r\nstudent id, previous grades\r\n1, [0, 0.5, 0.6]\r\n2, [0.7, 0.8, 1]\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/11", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/11/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/11/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/11/events", "html_url": "https://github.com/tensorflow/transform/issues/11", "id": 220657235, "node_id": "MDU6SXNzdWUyMjA2NTcyMzU=", "number": 11, "title": "min/max values of transformed metadata", "user": {"login": "pnezis", "id": 1561963, "node_id": "MDQ6VXNlcjE1NjE5NjM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1561963?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pnezis", "html_url": "https://github.com/pnezis", "followers_url": "https://api.github.com/users/pnezis/followers", "following_url": "https://api.github.com/users/pnezis/following{/other_user}", "gists_url": "https://api.github.com/users/pnezis/gists{/gist_id}", "starred_url": "https://api.github.com/users/pnezis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pnezis/subscriptions", "organizations_url": "https://api.github.com/users/pnezis/orgs", "repos_url": "https://api.github.com/users/pnezis/repos", "events_url": "https://api.github.com/users/pnezis/events{/privacy}", "received_events_url": "https://api.github.com/users/pnezis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": {"url": "https://api.github.com/repos/tensorflow/transform/milestones/1", "html_url": "https://github.com/tensorflow/transform/milestone/1", "labels_url": "https://api.github.com/repos/tensorflow/transform/milestones/1/labels", "id": 2852165, "node_id": "MDk6TWlsZXN0b25lMjg1MjE2NQ==", "number": 1, "title": "0.3.1", "description": "tf.Transform version 0.3.1", "creator": {"login": "KesterTong", "id": 5741341, "node_id": "MDQ6VXNlcjU3NDEzNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5741341?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KesterTong", "html_url": "https://github.com/KesterTong", "followers_url": "https://api.github.com/users/KesterTong/followers", "following_url": "https://api.github.com/users/KesterTong/following{/other_user}", "gists_url": "https://api.github.com/users/KesterTong/gists{/gist_id}", "starred_url": "https://api.github.com/users/KesterTong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KesterTong/subscriptions", "organizations_url": "https://api.github.com/users/KesterTong/orgs", "repos_url": "https://api.github.com/users/KesterTong/repos", "events_url": "https://api.github.com/users/KesterTong/events{/privacy}", "received_events_url": "https://api.github.com/users/KesterTong/received_events", "type": "User", "site_admin": false}, "open_issues": 0, "closed_issues": 2, "state": "closed", "created_at": "2017-10-19T19:06:25Z", "updated_at": "2017-10-22T16:36:17Z", "due_on": "2017-10-27T07:00:00Z", "closed_at": "2017-10-20T21:13:47Z"}, "comments": 6, "created_at": "2017-04-10T14:11:06Z", "updated_at": "2017-10-22T16:36:17Z", "closed_at": "2017-10-22T16:36:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Assume I am applying the `string_to_int` function on a categorical column. In the transformed schema this column is mapped to `INT` where the `min` and `max` entries of the domain are the `min` and `max` values of `INT`\r\n\r\n```\r\n\"domain\": {\r\n      \"ints\": {\r\n            \"isCategorical\": false,\r\n            \"max\": \"9223372036854775807\",\r\n            \"min\": \"-9223372036854775808\"\r\n        }\r\n },\r\n```\r\n\r\nI would expect instead the actual `min` (-1) and `max` (`size(vocab)-1`) values of this transformed column. Is there any workaround for this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/10", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/10/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/10/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/10/events", "html_url": "https://github.com/tensorflow/transform/issues/10", "id": 218908500, "node_id": "MDU6SXNzdWUyMTg5MDg1MDA=", "number": 10, "title": "`string_to_int` on multiple columns", "user": {"login": "pnezis", "id": 1561963, "node_id": "MDQ6VXNlcjE1NjE5NjM=", "avatar_url": "https://avatars1.githubusercontent.com/u/1561963?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pnezis", "html_url": "https://github.com/pnezis", "followers_url": "https://api.github.com/users/pnezis/followers", "following_url": "https://api.github.com/users/pnezis/following{/other_user}", "gists_url": "https://api.github.com/users/pnezis/gists{/gist_id}", "starred_url": "https://api.github.com/users/pnezis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pnezis/subscriptions", "organizations_url": "https://api.github.com/users/pnezis/orgs", "repos_url": "https://api.github.com/users/pnezis/repos", "events_url": "https://api.github.com/users/pnezis/events{/privacy}", "received_events_url": "https://api.github.com/users/pnezis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-04-03T11:47:22Z", "updated_at": "2018-07-11T19:53:34Z", "closed_at": "2017-04-10T11:50:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "Given a dataset with two categorical columns of the same feature type, is it possible to map them to an integer value using the same vocabulary? For example by applying `string_to_int` on the following toy dataset\r\n\r\n```\r\nprevious_occupation, current_occupation\r\nprogrammer, analyst\r\nanalyst, programmer\r\n``` \r\n\r\nwe get the transformed dataset\r\n\r\n```\r\nprevious_occupation, current_occupation\r\n0,0\r\n1,1\r\n```\r\n\r\nI would like to get the following instead, given that the two columns contain the same feature type.\r\n\r\n```\r\nprevious_occupation, current_occupation\r\n0,1\r\n1,0\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/transform/issues/6", "repository_url": "https://api.github.com/repos/tensorflow/transform", "labels_url": "https://api.github.com/repos/tensorflow/transform/issues/6/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/transform/issues/6/comments", "events_url": "https://api.github.com/repos/tensorflow/transform/issues/6/events", "html_url": "https://github.com/tensorflow/transform/issues/6", "id": 215683940, "node_id": "MDU6SXNzdWUyMTU2ODM5NDA=", "number": 6, "title": "tf.Transform and Google DataFlow Templates Integration", "user": {"login": "joshreuben456", "id": 22759994, "node_id": "MDQ6VXNlcjIyNzU5OTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/22759994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joshreuben456", "html_url": "https://github.com/joshreuben456", "followers_url": "https://api.github.com/users/joshreuben456/followers", "following_url": "https://api.github.com/users/joshreuben456/following{/other_user}", "gists_url": "https://api.github.com/users/joshreuben456/gists{/gist_id}", "starred_url": "https://api.github.com/users/joshreuben456/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joshreuben456/subscriptions", "organizations_url": "https://api.github.com/users/joshreuben456/orgs", "repos_url": "https://api.github.com/users/joshreuben456/repos", "events_url": "https://api.github.com/users/joshreuben456/events{/privacy}", "received_events_url": "https://api.github.com/users/joshreuben456/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-03-21T10:02:56Z", "updated_at": "2017-03-23T18:58:54Z", "closed_at": "2017-03-23T18:58:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "We are in the process of establishing a Machine Learning pipeline on Google Cloud, leveraging GC ML-Engine for distributed TensorFlow training and model serving, and DataFlow for distributed pre-processing jobs.\r\n\r\n We would like to run our Apache Beam apps as DataFlow jobs on Google Cloud. looking at the [ML-Engine samples](https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/criteo_tft/preprocess.py)\r\n it appears possible to get **tensorflow_transform.beam.impl AnalyzeAndTransformDataset** to specify which **PipelineRunner** to use as follows:\r\n```python\r\nfrom tensorflow_transform.beam import impl as tft\r\npipeline_name = \"DirectRunner\"\r\np = beam.Pipeline(pipeline_name) \r\np | \"xxx\" >> xxx | \"yyy\" >> yyy | tft.AnalyzeAndTransformDataset(...)\r\n``` \r\n\r\n [TemplatingDataflowPipelineRunner](https://cloud.google.com/dataflow/java-sdk/JavaDoc/com/google/cloud/dataflow/sdk/runners/TemplatingDataflowPipelineRunner) provides the ability to separate our preprocessing development from parameterized operations - see here: https://cloud.google.com/dataflow/docs/templates/overview \r\n\r\nwe could leverage this to dynamically generate a  `tf.Transform CsvCoder`\r\n\r\nThe steps of using DataFlow Templates are as follows:\r\n* A) in **PipelineOptions** derived types, change option types to **ValueProvider<T>** \r\n* B) change runner to **TemplatingDataflowPipelineRunner** \r\n* C)  **mvn archetype:generate** to store template in GCS (python way: a yaml file like TF Hypertune ???)\r\n* D) **gcloud beta dataflow jobs run --gcs-location \u2014parameters**\r\n\r\nFor (A), we could define UserOptions subclassed from `PipelineOptions` and use the `add_value_provider_argument` API to add specific arguments to be parameterized:\r\n```\r\nclass UserOptions(PipelineOptions):\r\n     @classmethod\r\n     def _add_argparse_args(cls, parser):\r\n         parser.add_value_provider_argument('--value_provider_arg', default='some_value')\r\n         parser.add_argument('--non_value_provider_arg', default='some_other_value')\r\n```\r\n\r\nThe question is: Can you show me how we can we use **tf.Transform** to leverage **TemplatingDataflowPipelineRunner** (B & C) ?\r\n\r\nLooking at the java [TemplatingDataflowPipelineRunner](https://github.com/GoogleCloudPlatform/DataflowJavaSDK/blob/master/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/TemplatingDataflowPipelineRunner.java) class , it encapsulates **DataflowPipelineRunner** - How can we create a custom python runner that encapsulates the apache beam python API class [DataflowRunner](https://beam.apache.org/documentation/sdks/pydoc/0.6.0/_modules/apache_beam/runners/dataflow/dataflow_runner.html#DataflowRunner) that provides the functionality of the java **TemplatingDataflowPipelineRunner**? \r\n", "performed_via_github_app": null, "score": 1.0}]}