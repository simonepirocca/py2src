{"total_count": 230, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2296", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2296/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2296/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2296/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2296", "id": 681624348, "node_id": "MDU6SXNzdWU2ODE2MjQzNDg=", "number": 2296, "title": "ignore constant column default value is set to true but there is no way to change it in sparkling water", "user": {"login": "elunenule", "id": 33746912, "node_id": "MDQ6VXNlcjMzNzQ2OTEy", "avatar_url": "https://avatars1.githubusercontent.com/u/33746912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/elunenule", "html_url": "https://github.com/elunenule", "followers_url": "https://api.github.com/users/elunenule/followers", "following_url": "https://api.github.com/users/elunenule/following{/other_user}", "gists_url": "https://api.github.com/users/elunenule/gists{/gist_id}", "starred_url": "https://api.github.com/users/elunenule/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/elunenule/subscriptions", "organizations_url": "https://api.github.com/users/elunenule/orgs", "repos_url": "https://api.github.com/users/elunenule/repos", "events_url": "https://api.github.com/users/elunenule/events{/privacy}", "received_events_url": "https://api.github.com/users/elunenule/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-19T07:47:13Z", "updated_at": "2020-08-19T08:08:19Z", "closed_at": "2020-08-19T08:08:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "- All versions\r\nI'm currently using sparkling water, to train and export my models however sometimes the normalized numeric features end up being a constant column when working with a small dateset, is there any chance that we add the ignore_constant_col param to Sparkling water Models or change the default behavior to False?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2290", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2290/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2290/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2290/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2290", "id": 678435148, "node_id": "MDU6SXNzdWU2Nzg0MzUxNDg=", "number": 2290, "title": "model.transform - detailed prediction column missing", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-08-13T13:25:16Z", "updated_at": "2020-08-14T08:37:53Z", "closed_at": "2020-08-14T08:37:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "After upgrade of Sparkling Water from version **3.26.8-2.4** to **3.30.0.7-1-2.4** the type of **PREDICTION** column changed from **struct** which contains detailed probabilities to simple **string** with 0/1 values only.\r\n\r\nIs there way how to get detailed probabilities after model.transform run?\r\n\r\n_Running PySparkling (3.30.0.7-1-2.4) on YARN._", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2289", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2289/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2289/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2289/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2289", "id": 677832487, "node_id": "MDU6SXNzdWU2Nzc4MzI0ODc=", "number": 2289, "title": "XGBoost not found; Cannot initialize XGBoost backend", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-08-12T16:42:09Z", "updated_at": "2020-08-14T08:38:18Z", "closed_at": "2020-08-14T08:38:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Trying to use XGBoost in Sparkling Water but getting following error:**\r\n\r\nPy4JJavaError: An error occurred while calling o699.fit.\r\n: ai.h2o.sparkling.backend.exceptions.RestApiCommunicationException: H2O node 10.245.54.13:54321 responded with\r\nStatus code: 404 : Not Found\r\nServer error: {\"__meta\": {\"schema_version\":3,\"schema_name\":\"H2OErrorV3\",\"schema_type\":\"H2OError\"},\"timestamp\":1597243172772,\"error_url\":\"POST /99/Grid/xgboost\",\"msg\":\"\\n\\nERROR MESSAGE:\\n\\nPOST /99/Grid/**xgboost not found**\\n\\n\"\r\n...\r\n...\r\n\r\n**According to H2O logs there is problem to initialize XGBoost backend:**\r\n\r\n07-28 14:02:38.516 127.0.0.1:54321       18034  main      INFO: **Cannot initialize XGBoost backend**! Xgboost (enabled GPUs) needs: \r\n07-28 14:02:38.516 127.0.0.1:54321       18034  main      INFO:   - CUDA 8.0\r\n07-28 14:02:38.516 127.0.0.1:54321       18034  main      INFO: XGboost (minimal version) needs: \r\n07-28 14:02:38.516 127.0.0.1:54321       18034  main      INFO:   - GCC 4.7+\r\n07-28 14:02:38.516 127.0.0.1:54321       18034  main      INFO: For more details, run in debug mode: `java -Dlog4j.configuration=file:///tmp/log4j.properties -jar h2o.jar`\r\n07-28 14:02:38.569 127.0.0.1:54321       18034  main      INFO: ----- H2O started  -----\r\n07-28 14:02:38.569 127.0.0.1:54321       18034  main      INFO: Build git branch: rel-zahradnik\r\n07-28 14:02:38.570 127.0.0.1:54321       18034  main      INFO: Build git hash: 42bc323d9860bac8b25e904eec22b9cf827abcb5\r\n07-28 14:02:38.570 127.0.0.1:54321       18034  main      INFO: Build git describe: jenkins-3.30.0.6-24-g42bc323\r\n07-28 14:02:38.570 127.0.0.1:54321       18034  main      INFO: Build project version: 3.30.0.7\r\n07-28 14:02:38.570 127.0.0.1:54321       18034  main      INFO: Build age: 6 days\r\n07-28 14:02:38.570 127.0.0.1:54321       18034  main      INFO: Built by: 'jenkins'\r\n07-28 14:02:38.570 127.0.0.1:54321       18034  main      INFO: Built on: '2020-07-21 17:20:25'\r\n...\r\n...\r\n\r\nDo you have any idea what should be the problem here?\r\nThanks!\r\n\r\n_Running PySparkling (3.30.0.7-1-2.4) on YARN._", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2264", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2264/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2264/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2264/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2264", "id": 668618179, "node_id": "MDU6SXNzdWU2Njg2MTgxNzk=", "number": 2264, "title": "Kerberos: keytab instead of password", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-30T11:12:00Z", "updated_at": "2020-08-12T14:39:11Z", "closed_at": "2020-08-12T14:39:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "According to the guidelines mentioned in this link: [http://docs.h2o.ai/sparkling-water/2.4/latest-stable/doc/tutorials/kerberos_auth.html](http://docs.h2o.ai/sparkling-water/2.4/latest-stable/doc/tutorials/kerberos_auth.html) you have to provide password explicitly during initialization of H2OContext.\r\n\r\nThis way it is working with no issues.\r\n\r\nBut is there way to use kerberos **keytab file** instead of **password** in code?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2262", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2262/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2262/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2262/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2262", "id": 666992087, "node_id": "MDU6SXNzdWU2NjY5OTIwODc=", "number": 2262, "title": "External backend - auto mode: failed to start ", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-28T11:18:15Z", "updated_at": "2020-07-30T10:37:03Z", "closed_at": "2020-07-30T10:37:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "Trying to launch Sparkling water H2OContext with **External backend - auto mode**, but getting following error:\r\n\r\n```\r\nPy4JJavaError: An error occurred while calling o180.getOrCreate.\r\n: java.lang.RuntimeException: \r\nCluster notification file /home/jnovotny/notify_prd_ml.h2o_server could not be created. The possible causes are:\r\n\r\n1) External H2O cluster did not cloud within the pre-defined timeout. In that case, please try\r\n   to increase the timeout for starting the external cluster as:\r\n\r\n   H2OContext.getOrCrete(H2OConf().setClusterStartTimeout(timeout))\r\n\r\n2) The file could not be created because of missing write rights.\r\n\tat ai.h2o.sparkling.backend.external.ExternalH2OBackend.launchExternalH2OOnYarn(ExternalH2OBackend.scala:69)\r\n\tat ai.h2o.sparkling.backend.external.ExternalH2OBackend.startH2OCluster(ExternalH2OBackend.scala:37)\r\n\tat org.apache.spark.h2o.H2OContext.<init>(H2OContext.scala:85)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:509)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nDuring start I can see in YARN applications that External backend MapReduce job is launched but then after 180s (timeout duration) this job is terminated and original SparkSession gets error provided above.\r\n\r\nThere was no problem to start H2OContext with Internal backend.\r\n\r\n_Running PySparkling (3.30.0.7-1-2.4) on YARN._", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2222", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2222/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2222/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2222/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2222", "id": 655225099, "node_id": "MDU6SXNzdWU2NTUyMjUwOTk=", "number": 2222, "title": "No man pages found in package  'rsparkling' !", "user": {"login": "SieSiongWong", "id": 52974088, "node_id": "MDQ6VXNlcjUyOTc0MDg4", "avatar_url": "https://avatars0.githubusercontent.com/u/52974088?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SieSiongWong", "html_url": "https://github.com/SieSiongWong", "followers_url": "https://api.github.com/users/SieSiongWong/followers", "following_url": "https://api.github.com/users/SieSiongWong/following{/other_user}", "gists_url": "https://api.github.com/users/SieSiongWong/gists{/gist_id}", "starred_url": "https://api.github.com/users/SieSiongWong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SieSiongWong/subscriptions", "organizations_url": "https://api.github.com/users/SieSiongWong/orgs", "repos_url": "https://api.github.com/users/SieSiongWong/repos", "events_url": "https://api.github.com/users/SieSiongWong/events{/privacy}", "received_events_url": "https://api.github.com/users/SieSiongWong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-07-11T15:09:03Z", "updated_at": "2020-07-15T03:30:57Z", "closed_at": "2020-07-15T03:30:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI try to follow what is given in this link to install H2O and rsparkling: http://docs.h2o.ai/sparkling-water/2.4/latest-stable/doc/rsparkling.html, successfully getting H2O installed but for rsparkling I'm getting the: No man pages found in package  'rsparkling' . Below is the info.\r\n\r\ntrying URL 'http://h2o-release.s3.amazonaws.com/sparkling-water/spark-2.4/3.30.0.6-1-2.4/R/src/contrib/rsparkling_3.30.0.6-1-2.4.tar.gz'\r\nContent type 'application/x-tar' length 116101431 bytes (110.7 MB)\r\ndownloaded 110.7 MB\r\n\r\n* installing *source* package 'rsparkling' ...\r\n** using staged installation\r\n** R\r\n** inst\r\n** byte-compile and prepare package for lazy loading\r\nFound more than one class \"H2OMOJOModelBase\" in cache; using the first, from namespace 'rsparkling'\r\nAlso defined by '.GlobalEnv'\r\n** help\r\nNo man pages found in package  'rsparkling' \r\n*** installing help indices\r\n** building package indices\r\n** testing if installed package can be loaded from temporary location\r\n*** arch - i386\r\nError: package or namespace load failed for 'rsparkling' in library.dynam(lib, package, package.lib):\r\n DLL 'htmltools' not found: maybe not installed for this architecture?\r\nError: loading failed\r\nExecution halted\r\n*** arch - x64\r\nERROR: loading failed for 'i386'\r\n* removing 'C:/Users/Gang Zhang/Documents/R/win-library/3.6/rsparkling'\r\nWarning in install.packages :\r\n  installation of package \u2018rsparkling\u2019 had non-zero exit status", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2221", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2221/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2221/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2221/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2221", "id": 655132282, "node_id": "MDU6SXNzdWU2NTUxMzIyODI=", "number": 2221, "title": "as_h2o_frame() function could not be found!", "user": {"login": "SieSiongWong", "id": 52974088, "node_id": "MDQ6VXNlcjUyOTc0MDg4", "avatar_url": "https://avatars0.githubusercontent.com/u/52974088?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SieSiongWong", "html_url": "https://github.com/SieSiongWong", "followers_url": "https://api.github.com/users/SieSiongWong/followers", "following_url": "https://api.github.com/users/SieSiongWong/following{/other_user}", "gists_url": "https://api.github.com/users/SieSiongWong/gists{/gist_id}", "starred_url": "https://api.github.com/users/SieSiongWong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SieSiongWong/subscriptions", "organizations_url": "https://api.github.com/users/SieSiongWong/orgs", "repos_url": "https://api.github.com/users/SieSiongWong/repos", "events_url": "https://api.github.com/users/SieSiongWong/events{/privacy}", "received_events_url": "https://api.github.com/users/SieSiongWong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-11T04:31:39Z", "updated_at": "2020-07-14T04:45:48Z", "closed_at": "2020-07-14T04:45:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, \r\n\r\nI'm facing the issue of getting the as_h2o_frame() function. I have installed the **rsparkling_3.30.0.6-1-2.4**, **h2o_3.30.0.1 , sparklyr_1.3.1**   and **spark 2.4.3**.  \r\n\r\nNote that I can connect to spark and would like to convert the spark dataframe to h2o dataframe for using h2o machine learning algorithms.\r\n\r\nCan someone help how to resolve this issue?\r\n\r\nThanks,\r\nSiong", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2217", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2217/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2217/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2217/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2217", "id": 653761951, "node_id": "MDU6SXNzdWU2NTM3NjE5NTE=", "number": 2217, "title": "cross validation of sparkling water in spark", "user": {"login": "jayden526", "id": 31317737, "node_id": "MDQ6VXNlcjMxMzE3NzM3", "avatar_url": "https://avatars1.githubusercontent.com/u/31317737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jayden526", "html_url": "https://github.com/jayden526", "followers_url": "https://api.github.com/users/jayden526/followers", "following_url": "https://api.github.com/users/jayden526/following{/other_user}", "gists_url": "https://api.github.com/users/jayden526/gists{/gist_id}", "starred_url": "https://api.github.com/users/jayden526/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jayden526/subscriptions", "organizations_url": "https://api.github.com/users/jayden526/orgs", "repos_url": "https://api.github.com/users/jayden526/repos", "events_url": "https://api.github.com/users/jayden526/events{/privacy}", "received_events_url": "https://api.github.com/users/jayden526/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-09T04:53:10Z", "updated_at": "2020-07-14T09:13:41Z", "closed_at": "2020-07-14T09:13:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI am new to this tool, could you please help me with a few questions?\r\nI am training a logistic regression with thousands of features using ML lib in spark, while it has poor efficiency, especially with cross-validation. So I am looking to try sparkling water in spark.\r\nDoes the sparkling water code works with existing spark scala code in the pipeline, I try to only replace existing model training part with sparkling water code (GLM). It will be great if they work together and will save me a lot of work.\r\nThanks a lot!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2213", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2213/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2213/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2213/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2213", "id": 651928819, "node_id": "MDU6SXNzdWU2NTE5Mjg4MTk=", "number": 2213, "title": "Caused by: ai.h2o.sparkling.backend.exceptions.RestApiCommunicationException Status code: 404 : Not Found", "user": {"login": "kmullapudi-11", "id": 54163071, "node_id": "MDQ6VXNlcjU0MTYzMDcx", "avatar_url": "https://avatars1.githubusercontent.com/u/54163071?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmullapudi-11", "html_url": "https://github.com/kmullapudi-11", "followers_url": "https://api.github.com/users/kmullapudi-11/followers", "following_url": "https://api.github.com/users/kmullapudi-11/following{/other_user}", "gists_url": "https://api.github.com/users/kmullapudi-11/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmullapudi-11/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmullapudi-11/subscriptions", "organizations_url": "https://api.github.com/users/kmullapudi-11/orgs", "repos_url": "https://api.github.com/users/kmullapudi-11/repos", "events_url": "https://api.github.com/users/kmullapudi-11/events{/privacy}", "received_events_url": "https://api.github.com/users/kmullapudi-11/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-07-07T01:51:54Z", "updated_at": "2020-07-13T19:17:52Z", "closed_at": "2020-07-13T19:17:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI'm trying to create a basic Sparkling Water app but I keep running into errors while trying to run my application through the command line (even though it runs just fine when I run the main method directly through the IntelliJ UI). \r\n\r\nWhen I tried to run the app using spark-submit, I got the `\u201cCaused by: java.lang.IllegalStateException: HTTP Server cannot be loaded: No implementation of HttpServerFacade found on classpath\u201d` error. I tried adding all the dependencies listed here https://0xdata.atlassian.net/browse/TN-13 to try and solve the error but my `build.sbt` couldn't find `h2o-jetty-8`. So I resorted using the following command to run my app after creating a fat jar using `sbt clean assembly`:\r\n`spark-submit --master=\"local\" --packages ai.h2o:h2o-jetty-8:3.30.0.5 target/scala-2.11/demo-dockerized-app-assembly-0.1.jar`\r\n\r\nThe error seems to be due to a misconfigured `spark.ext.h2o.cloud.name` but I don't know where this is being set or what I need to set it to. I'm trying to run this locally on my Mac.  \r\n\r\nHowever, I get the following error:\r\n```\r\nIvy Default Cache set to: /Users/karthikmullapudi/.ivy2/cache\r\nThe jars for the packages stored in: /Users/karthikmullapudi/.ivy2/jars\r\n:: loading settings :: url = jar:file:/usr/local/Cellar/apache-spark/2.4.5/libexec/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\r\nai.h2o#h2o-jetty-8 added as a dependency\r\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-40a40425-62e9-48e8-8d2b-ed0e385b9422;1.0\r\n        confs: [default]\r\n        found ai.h2o#h2o-jetty-8;3.30.0.5 in central\r\n        found ai.h2o#h2o-webserver-iface;3.30.0.5 in central\r\n        found commons-codec#commons-codec;1.9 in spark-list\r\n        found org.eclipse.jetty#jetty-server;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty.orbit#javax.servlet;3.0.0.v201112011016 in central\r\n        found org.eclipse.jetty#jetty-continuation;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-http;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-io;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-util;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-servlets;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-client;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-plus;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty.orbit#javax.transaction;1.1.1.v201105210645 in central\r\n        found org.eclipse.jetty#jetty-webapp;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-xml;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-servlet;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-security;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty#jetty-jndi;8.1.21.v20160908 in central\r\n        found org.eclipse.jetty.orbit#javax.mail.glassfish;1.4.1.v201005082020 in central\r\n        found org.eclipse.jetty.orbit#javax.activation;1.1.0.v201105071233 in central\r\n:: resolution report :: resolve 539ms :: artifacts dl 14ms\r\n        :: modules in use:\r\n        ai.h2o#h2o-jetty-8;3.30.0.5 from central in [default]\r\n        ai.h2o#h2o-webserver-iface;3.30.0.5 from central in [default]\r\n        commons-codec#commons-codec;1.9 from spark-list in [default]\r\n        org.eclipse.jetty#jetty-client;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-continuation;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-http;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-io;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-jndi;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-plus;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-security;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-server;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-servlet;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-servlets;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-util;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-webapp;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty#jetty-xml;8.1.21.v20160908 from central in [default]\r\n        org.eclipse.jetty.orbit#javax.activation;1.1.0.v201105071233 from central in [default]\r\n        org.eclipse.jetty.orbit#javax.mail.glassfish;1.4.1.v201005082020 from central in [default]\r\n        org.eclipse.jetty.orbit#javax.servlet;3.0.0.v201112011016 from central in [default]\r\n        org.eclipse.jetty.orbit#javax.transaction;1.1.1.v201105210645 from central in [default]\r\n        ---------------------------------------------------------------------\r\n        |                  |            modules            ||   artifacts   |\r\n        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|\r\n        ---------------------------------------------------------------------\r\n        |      default     |   20  |   0   |   0   |   0   ||   20  |   0   |\r\n        ---------------------------------------------------------------------\r\n:: retrieving :: org.apache.spark#spark-submit-parent-40a40425-62e9-48e8-8d2b-ed0e385b9422\r\n        confs: [default]\r\n        0 artifacts copied, 20 already retrieved (0kB/11ms)\r\n20/07/06 20:35:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n20/07/06 20:35:31 INFO SparkContext: Running Spark version 2.4.5\r\n20/07/06 20:35:31 INFO SparkContext: Submitted application: demo-dockerized-app\r\n20/07/06 20:35:31 INFO SecurityManager: Changing view acls to: karthikmullapudi\r\n20/07/06 20:35:31 INFO SecurityManager: Changing modify acls to: karthikmullapudi\r\n20/07/06 20:35:31 INFO SecurityManager: Changing view acls groups to: \r\n20/07/06 20:35:31 INFO SecurityManager: Changing modify acls groups to: \r\n20/07/06 20:35:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(karthikmullapudi); groups with view permissions: Set(); users  with modify permissions: Set(karthikmullapudi); groups with modify permissions: Set()\r\n20/07/06 20:35:31 INFO Utils: Successfully started service 'sparkDriver' on port 52331.\r\n20/07/06 20:35:31 INFO SparkEnv: Registering MapOutputTracker\r\n20/07/06 20:35:31 INFO SparkEnv: Registering BlockManagerMaster\r\n20/07/06 20:35:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\r\n20/07/06 20:35:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\r\n20/07/06 20:35:32 INFO DiskBlockManager: Created local directory at /private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/blockmgr-f006e212-8dba-46f5-97aa-d1a1bdce4034\r\n20/07/06 20:35:32 INFO MemoryStore: MemoryStore started with capacity 366.3 MB\r\n20/07/06 20:35:32 INFO SparkEnv: Registering OutputCommitCoordinator\r\n20/07/06 20:35:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.\r\n20/07/06 20:35:32 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://localhost:4040\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/ai.h2o_h2o-jetty-8-3.30.0.5.jar at spark://localhost:52331/jars/ai.h2o_h2o-jetty-8-3.30.0.5.jar with timestamp 1594085732338\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/ai.h2o_h2o-webserver-iface-3.30.0.5.jar at spark://localhost:52331/jars/ai.h2o_h2o-webserver-iface-3.30.0.5.jar with timestamp 1594085732338\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-server-8.1.21.v20160908.jar with timestamp 1594085732339\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-servlets-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-servlets-8.1.21.v20160908.jar with timestamp 1594085732339\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-plus-8.1.21.v20160908.jar with timestamp 1594085732339\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/commons-codec_commons-codec-1.9.jar at spark://localhost:52331/jars/commons-codec_commons-codec-1.9.jar with timestamp 1594085732339\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://localhost:52331/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1594085732339\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-continuation-8.1.21.v20160908.jar with timestamp 1594085732339\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-http-8.1.21.v20160908.jar with timestamp 1594085732339\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-io-8.1.21.v20160908.jar with timestamp 1594085732340\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-util-8.1.21.v20160908.jar with timestamp 1594085732340\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-client-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-client-8.1.21.v20160908.jar with timestamp 1594085732340\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://localhost:52331/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1594085732340\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-webapp-8.1.21.v20160908.jar with timestamp 1594085732340\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-jndi-8.1.21.v20160908.jar with timestamp 1594085732340\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-xml-8.1.21.v20160908.jar with timestamp 1594085732340\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-servlet-8.1.21.v20160908.jar with timestamp 1594085732340\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.21.v20160908.jar at spark://localhost:52331/jars/org.eclipse.jetty_jetty-security-8.1.21.v20160908.jar with timestamp 1594085732341\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://localhost:52331/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1594085732341\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://localhost:52331/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1594085732341\r\n20/07/06 20:35:32 INFO SparkContext: Added JAR file:/Users/karthikmullapudi/Ex%20Machina/demo-dockerized-app/target/scala-2.11/demo-dockerized-app-assembly-0.1.jar at spark://localhost:52331/jars/demo-dockerized-app-assembly-0.1.jar with timestamp 1594085732342\r\n20/07/06 20:35:32 INFO Executor: Starting executor ID driver on host localhost\r\n20/07/06 20:35:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52332.\r\n20/07/06 20:35:32 INFO NettyBlockTransferService: Server created on localhost:52332\r\n20/07/06 20:35:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\r\n20/07/06 20:35:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 52332, None)\r\n20/07/06 20:35:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52332 with 366.3 MB RAM, BlockManagerId(driver, localhost, 52332, None)\r\n20/07/06 20:35:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 52332, None)\r\n20/07/06 20:35:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 52332, None)\r\n20/07/06 20:35:32 WARN InternalH2OBackend: To avoid non-deterministic behavior of Spark broadcast-based joins,\r\nwe recommend to set `spark.sql.autoBroadcastJoinThreshold` property of SparkSession to -1.\r\nE.g. spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\r\nWe also recommend to avoid using broadcast hints in your Spark SQL code.\r\n20/07/06 20:35:32 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 0 (Infinitive) as we need to ensure we run on the nodes with H2O\r\n20/07/06 20:35:32 INFO SparkContext: Added file /private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/spark-a3ccc0d6-7b87-49c0-b0df-37383a55d4c0/hdfs_conf3467413423044342091.xml at file:/private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/spark-a3ccc0d6-7b87-49c0-b0df-37383a55d4c0/hdfs_conf3467413423044342091.xml with timestamp 1594085732978\r\n20/07/06 20:35:32 INFO Utils: Copying /private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/spark-a3ccc0d6-7b87-49c0-b0df-37383a55d4c0/hdfs_conf3467413423044342091.xml to /private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/spark-a3ccc0d6-7b87-49c0-b0df-37383a55d4c0/userFiles-8c4aee40-741b-4fc9-a129-f9e8f3780ef1/hdfs_conf3467413423044342091.xml\r\n20/07/06 20:35:33 INFO H2OContext: Sparkling Water version: 3.30.0.5-1-2.4\r\n20/07/06 20:35:33 INFO H2OContext: Spark version: 2.4.5\r\n20/07/06 20:35:33 INFO H2OContext: Integrated H2O version: 3.30.0.5\r\n20/07/06 20:35:33 INFO H2OContext: The following Spark configuration is used: \r\n    (spark.ext.h2o.client.log.dir,/Users/karthikmullapudi/Ex Machina/demo-dockerized-app/h2ologs/local-1594085732387)\r\n    (spark.ext.h2o.hdfs_conf,/private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/spark-a3ccc0d6-7b87-49c0-b0df-37383a55d4c0/hdfs_conf3467413423044342091.xml)\r\n    (spark.app.id,local-1594085732387)\r\n    (spark.app.name,demo-dockerized-app)\r\n    (spark.ext.h2o.cloud.name,sparkling-water-karthikmullapudi_local-1594085732387)\r\n    (spark.locality.wait,0)\r\n    (spark.master,local[*])\r\n    (spark.driver.port,52331)\r\n    (spark.executor.id,driver)\r\n    (spark.submit.deployMode,client)\r\n    (spark.driver.host,localhost)\r\n    (spark.repl.local.jars,file:///Users/karthikmullapudi/.ivy2/jars/ai.h2o_h2o-jetty-8-3.30.0.5.jar,file:///Users/karthikmullapudi/.ivy2/jars/ai.h2o_h2o-webserver-iface-3.30.0.5.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-servlets-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/commons-codec_commons-codec-1.9.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-client-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar)\r\n    (spark.jars,file:///Users/karthikmullapudi/.ivy2/jars/ai.h2o_h2o-jetty-8-3.30.0.5.jar,file:///Users/karthikmullapudi/.ivy2/jars/ai.h2o_h2o-webserver-iface-3.30.0.5.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-servlets-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/commons-codec_commons-codec-1.9.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-client-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.21.v20160908.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar,file:///Users/karthikmullapudi/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar,file:/Users/karthikmullapudi/Ex%20Machina/demo-dockerized-app/target/scala-2.11/demo-dockerized-app-assembly-0.1.jar)\r\n20/07/06 20:35:33 INFO InternalH2OBackend: Starting the H2O cluster inside Spark.\r\n20/07/06 20:35:33 INFO Server: jetty-8.1.21.v20160908\r\n20/07/06 20:35:33 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54321\r\n20/07/06 20:35:34 INFO H2OContext: Connecting to H2O cluster.\r\nException in thread \"main\" ai.h2o.sparkling.backend.exceptions.H2OClusterNotReachableException: H2O cluster 192.168.10.81:54321 - sparkling-water-karthikmullapudi_local-1594085732387 is not reachable.\r\nH2OContext has not been created.\r\n        at ai.h2o.sparkling.backend.utils.H2OContextExtensions$class.getAndVerifyWorkerNodes(H2OContextExtensions.scala:131)\r\n        at org.apache.spark.h2o.H2OContext.getAndVerifyWorkerNodes(H2OContext.scala:66)\r\n        at org.apache.spark.h2o.H2OContext.connectToH2OCluster(H2OContext.scala:386)\r\n        at org.apache.spark.h2o.H2OContext.<init>(H2OContext.scala:86)\r\n        at org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:481)\r\n        at org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:519)\r\n        at com.demo.DeepLearningDemo$.main(DeepLearningDemo.scala:23)\r\n        at com.demo.DeepLearningDemo.main(DeepLearningDemo.scala)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\r\n        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)\r\n        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)\r\n        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)\r\n        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\r\n        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)\r\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)\r\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: ai.h2o.sparkling.backend.exceptions.RestApiCommunicationException: H2O node 192.168.10.81:54321 responded with\r\nStatus code: 404 : Not Found\r\nServer error: <html>\r\n<head>\r\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=ISO-8859-1\"/>\r\n<title>Error 404 Not Found</title>\r\n</head>\r\n<body>\r\n<h2>HTTP ERROR: 404</h2>\r\n<p>Problem accessing /3/CloudLock. Reason:\r\n<pre>    Not Found</pre></p>\r\n\r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n                                                \r\n</body>\r\n</html>\r\n\r\n        at ai.h2o.sparkling.backend.utils.RestCommunication$class.checkResponseCode(RestCommunication.scala:273)\r\n        at ai.h2o.sparkling.backend.utils.RestApiUtils$.checkResponseCode(RestApiUtils.scala:96)\r\n        at ai.h2o.sparkling.backend.utils.RestCommunication$class.readURLContent(RestCommunication.scala:252)\r\n        at ai.h2o.sparkling.backend.utils.RestApiUtils$.readURLContent(RestApiUtils.scala:96)\r\n        at ai.h2o.sparkling.backend.utils.RestCommunication$class.request(RestCommunication.scala:151)\r\n        at ai.h2o.sparkling.backend.utils.RestApiUtils$.request(RestApiUtils.scala:96)\r\n        at ai.h2o.sparkling.backend.utils.RestCommunication$class.update(RestCommunication.scala:75)\r\n        at ai.h2o.sparkling.backend.utils.RestApiUtils$.update(RestApiUtils.scala:96)\r\n        at ai.h2o.sparkling.backend.utils.H2OContextExtensions$class.lockCloud(H2OContextExtensions.scala:184)\r\n        at ai.h2o.sparkling.backend.utils.H2OContextExtensions$class.getAndVerifyWorkerNodes(H2OContextExtensions.scala:119)\r\n        ... 19 more\r\n20/07/06 20:35:34 INFO SparkContext: Invoking stop() from shutdown hook\r\n20/07/06 20:35:34 INFO SparkUI: Stopped Spark web UI at http://localhost:4040\r\n20/07/06 20:35:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\r\n20/07/06 20:35:34 INFO MemoryStore: MemoryStore cleared\r\n20/07/06 20:35:34 INFO BlockManager: BlockManager stopped\r\n20/07/06 20:35:34 INFO BlockManagerMaster: BlockManagerMaster stopped\r\n20/07/06 20:35:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\r\n20/07/06 20:35:34 INFO SparkContext: Successfully stopped SparkContext\r\n20/07/06 20:35:34 INFO ShutdownHookManager: Shutdown hook called\r\n20/07/06 20:35:34 INFO ShutdownHookManager: Deleting directory /private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/spark-a3ccc0d6-7b87-49c0-b0df-37383a55d4c0/sparkling-water-72b1a9d3-0f82-4cf9-9804-bf6fd42448fa\r\n20/07/06 20:35:34 INFO ShutdownHookManager: Deleting directory /private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/spark-a3ccc0d6-7b87-49c0-b0df-37383a55d4c0\r\n20/07/06 20:35:34 INFO ShutdownHookManager: Deleting directory /private/var/folders/xn/j6sg7zws2nz1j5kvsv677_5m0000gq/T/spark-fce7dd4b-d0ad-46e4-b86f-7e3dc8c637c0\r\n\r\n```\r\n\r\nMinimal reproducible code:\r\n\r\n***build.sbt***\r\n```\r\nname := \"demo-dockerized-app\"\r\n\r\nversion := \"0.1\"\r\n\r\nscalaVersion := \"2.11.12\"\r\n\r\nlogLevel := Level.Error\r\n\r\nmainClass in Compile := Some(\"com.demo.DeepLearningDemo\")\r\n\r\nlazy val versions = new {\r\n  val spark = \"2.4.5\"\r\n  val sparklingWater = \"3.30.0.5-1-2.4\"\r\n  val h2oprojectversion = \"3.30.0.5\"\r\n  val scala = \"2.11.12\"\r\n}\r\n\r\ncompileOrder in Compile := CompileOrder.JavaThenScala\r\n\r\nlibraryDependencies ++= Seq(\r\n  \"org.apache.spark\" % \"spark-core_2.11\" % versions.spark,\r\n  \"org.apache.spark\" % \"spark-mllib_2.11\" % versions.spark,\r\n  \"org.apache.spark\" % \"spark-sql_2.11\" % versions.spark,\r\n  \"org.apache.spark\" % \"spark-repl_2.11\" % versions.spark,\r\n  \"ai.h2o\" % \"sparkling-water-package_2.11\" % versions.sparklingWater,\r\n  \"org.scala-lang\" % \"scala-compiler\" % versions.scala,\r\n  \"org.scala-lang\" % \"scala-library\" % versions.scala,\r\n  \"org.scala-lang\" % \"scala-reflect\" % versions.scala,\r\n)\r\n\r\nassemblyMergeStrategy in assembly := {\r\n  case PathList(\"META-INF\", xs @ _*) => MergeStrategy.discard\r\n  case x => MergeStrategy.first\r\n}\r\n\r\n```\r\n\r\n***DeepLearningDemo.scala***\r\n```java\r\nobject DeepLearningDemo {\r\n  def main(args: Array[String]) {\r\n    val session: SparkSession = {\r\n      SparkSession\r\n        .builder()\r\n        .master(\"local[*]\")\r\n        .appName(\"demo-dockerized-app\")\r\n        .config(\"spark.driver.host\",\"localhost\")\r\n        .getOrCreate()\r\n    }\r\n\r\n    import session.implicits._\r\n\r\n    H2OContext.getOrCreate()\r\n}\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2201", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2201/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2201/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2201/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2201", "id": 644526457, "node_id": "MDU6SXNzdWU2NDQ1MjY0NTc=", "number": 2201, "title": "Speed-up training of H2OGradientBoosting estimator", "user": {"login": "alexHeu", "id": 8157458, "node_id": "MDQ6VXNlcjgxNTc0NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/8157458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexHeu", "html_url": "https://github.com/alexHeu", "followers_url": "https://api.github.com/users/alexHeu/followers", "following_url": "https://api.github.com/users/alexHeu/following{/other_user}", "gists_url": "https://api.github.com/users/alexHeu/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexHeu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexHeu/subscriptions", "organizations_url": "https://api.github.com/users/alexHeu/orgs", "repos_url": "https://api.github.com/users/alexHeu/repos", "events_url": "https://api.github.com/users/alexHeu/events{/privacy}", "received_events_url": "https://api.github.com/users/alexHeu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-24T11:06:00Z", "updated_at": "2020-07-28T05:45:50Z", "closed_at": "2020-07-28T05:45:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nin my current project I am using H2O together with sparkling-water on Databricks to train a H2OGradientBoosting estimator on a dataset with roughly 130M rows and 80 columns.\r\nI am using 2 Azure D64s_v3 instances that each have 64 cores and 256GB memory. \r\n\r\nTraining is working well, however it takes around 5.5 hours to train 600 trees. If possible, we would like to improve the training runtime.\r\n\r\nDo you have any suggestions on how to speed up the training process apart from adding more nodes?\r\nIm open to switching to another algorithm like XGBoost. Is GPU support for XGBoost also available in sparkling-water?\r\n\r\nThanks and regards\r\nAlexander", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2199", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2199/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2199/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2199/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2199", "id": 643382640, "node_id": "MDU6SXNzdWU2NDMzODI2NDA=", "number": 2199, "title": "Stopping parameters in H2OXGBoost - missing", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-22T21:50:37Z", "updated_at": "2020-06-23T05:12:26Z", "closed_at": "2020-06-23T05:12:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, is it possible to add these parameters (**stoppingMetric**, **stoppingRounds**, **stoppingTolerance**) to **H2OXGBoost** algorithm?\r\n\r\nNow I am getting following error: `AttributeError: 'H2OXGBoost' object has no attribute 'stoppingMetric'`\r\n\r\n\r\n_Running PySparkling (3.26.8-2.4) on YARN._", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2194", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2194/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2194/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2194/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2194", "id": 641702767, "node_id": "MDU6SXNzdWU2NDE3MDI3Njc=", "number": 2194, "title": "Setting impurity for tree based algorithms", "user": {"login": "kmullapudi-11", "id": 54163071, "node_id": "MDQ6VXNlcjU0MTYzMDcx", "avatar_url": "https://avatars1.githubusercontent.com/u/54163071?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmullapudi-11", "html_url": "https://github.com/kmullapudi-11", "followers_url": "https://api.github.com/users/kmullapudi-11/followers", "following_url": "https://api.github.com/users/kmullapudi-11/following{/other_user}", "gists_url": "https://api.github.com/users/kmullapudi-11/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmullapudi-11/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmullapudi-11/subscriptions", "organizations_url": "https://api.github.com/users/kmullapudi-11/orgs", "repos_url": "https://api.github.com/users/kmullapudi-11/repos", "events_url": "https://api.github.com/users/kmullapudi-11/events{/privacy}", "received_events_url": "https://api.github.com/users/kmullapudi-11/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-06-19T04:52:49Z", "updated_at": "2020-06-29T09:00:25Z", "closed_at": "2020-06-29T09:00:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nIs there a way to set the impurity to 'entropy' or 'gini' while using tree based algorithms? If not, will it ever be supported in a future release? Also, what is the impurity currently being used by default? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2176", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2176/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2176/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2176/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2176", "id": 637835822, "node_id": "MDU6SXNzdWU2Mzc4MzU4MjI=", "number": 2176, "title": "GridSchemaV99 possibly misconfigured. Results in a JsonSyntaxException when using setNfolds() on algorithm.", "user": {"login": "kmullapudi-11", "id": 54163071, "node_id": "MDQ6VXNlcjU0MTYzMDcx", "avatar_url": "https://avatars1.githubusercontent.com/u/54163071?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kmullapudi-11", "html_url": "https://github.com/kmullapudi-11", "followers_url": "https://api.github.com/users/kmullapudi-11/followers", "following_url": "https://api.github.com/users/kmullapudi-11/following{/other_user}", "gists_url": "https://api.github.com/users/kmullapudi-11/gists{/gist_id}", "starred_url": "https://api.github.com/users/kmullapudi-11/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kmullapudi-11/subscriptions", "organizations_url": "https://api.github.com/users/kmullapudi-11/orgs", "repos_url": "https://api.github.com/users/kmullapudi-11/repos", "events_url": "https://api.github.com/users/kmullapudi-11/events{/privacy}", "received_events_url": "https://api.github.com/users/kmullapudi-11/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-12T15:33:15Z", "updated_at": "2020-06-17T05:11:21Z", "closed_at": "2020-06-15T20:27:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "Providing us with the observed and expected behavior definitely helps. Giving us with the following information definitively helps:\r\n\r\n- Sparkling Water/PySparkling/RSparkling version\r\n- Hadoop Version & Distribution\r\n- Execution mode `YARN-client`, `YARN-cluster`, standalone, local ..\r\n- YARN logs in case of running on yarn. To collect such a logs you may run `yarn logs -applicationId <application ID>` where the application ID is displayed when Sparkling Water is started\r\n- H2O & Spark logs if not running on YARN. You can find these logs in Spark work directory\r\n- Are you using Windows/Linux/MAC?\r\n- Spark & Sparkling Water configuration including the memory configuration\r\n\r\n**Environment Details**\r\nI'm using using the following Maven package for Sparkling Water: `ai.h2o:sparkling-water-package_2.11:3.30.0.4-1-2.4`. I'm running the code locally in a Zeppelin notebook inside a docker container. I'm using a Mac and using Spark version 2.4.4, Scala Version 2.11.12. However, I was able to reproduce this issue even by changing tests to the below mentioned code within the `H2OGridSearchTestSuite.scala` file.\r\n\r\n**Issue**\r\nWhen I `setNfolds()` for any of the `H2OSupervisedAlgorithms`, do grid search using `H2OGridSearch` and then call `fit()` on the dataset, I get a `JsonSyntaxException`. I was able to get the expected data by setting a breakpoint inside the `RestCommunication.scala` file. The error seems to be thrown by a misconfigured `GridSchemaV99` which results in an error when `deserialize()` is called the `RestCommunication.request` method Line 169. \r\n\r\n```\r\ncom.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 608096 path $.cross_validation_metrics_summary[0].data[0][0]\r\n  at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:224)\r\n  at com.google.gson.internal.bind.TypeAdapterRuntimeTypeWrapper.read(TypeAdapterRuntimeTypeWrapper.java:41)\r\n  at com.google.gson.internal.bind.ArrayTypeAdapter.read(ArrayTypeAdapter.java:72)\r\n  at com.google.gson.internal.bind.TypeAdapterRuntimeTypeWrapper.read(TypeAdapterRuntimeTypeWrapper.java:41)\r\n  at com.google.gson.internal.bind.ArrayTypeAdapter.read(ArrayTypeAdapter.java:72)\r\n  at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:129)\r\n  at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:220)\r\n  at com.google.gson.internal.bind.TypeAdapterRuntimeTypeWrapper.read(TypeAdapterRuntimeTypeWrapper.java:41)\r\n  at com.google.gson.internal.bind.ArrayTypeAdapter.read(ArrayTypeAdapter.java:72)\r\n  at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:129)\r\n  at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:220)\r\n  at com.google.gson.Gson.fromJson(Gson.java:887)\r\n  at com.google.gson.Gson.fromJson(Gson.java:852)\r\n  at com.google.gson.Gson.fromJson(Gson.java:801)\r\n  at ai.h2o.sparkling.backend.utils.RestCommunication$class.ai$h2o$sparkling$backend$utils$RestCommunication$$deserialize(RestCommunication.scala:164)\r\n  at ai.h2o.sparkling.backend.utils.RestCommunication$$anonfun$request$1.apply(RestCommunication.scala:147)\r\n  at ai.h2o.sparkling.backend.utils.RestCommunication$$anonfun$request$1.apply(RestCommunication.scala:145)\r\n  at ai.h2o.sparkling.utils.ScalaUtils$.withResource(ScalaUtils.scala:28)\r\n  at ai.h2o.sparkling.backend.utils.RestCommunication$class.request(RestCommunication.scala:145)\r\n  at ai.h2o.sparkling.ml.algos.H2OGridSearch.request(H2OGridSearch.scala:46)\r\n  at ai.h2o.sparkling.backend.utils.RestCommunication$class.query(RestCommunication.scala:54)\r\n  at ai.h2o.sparkling.ml.algos.H2OGridSearch.query(H2OGridSearch.scala:46)\r\n  at ai.h2o.sparkling.ml.algos.H2OGridSearch.getGridModels(H2OGridSearch.scala:129)\r\n  at ai.h2o.sparkling.ml.algos.H2OGridSearch.fit(H2OGridSearch.scala:163)\r\n  at ai.h2o.sparkling.ml.algos.H2OGridSearch.fit(H2OGridSearch.scala:46)\r\n  at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:153)\r\n  at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:149)\r\n  at scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n  at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\r\n  at scala.collection.IterableViewLike$Transformed$class.foreach(IterableViewLike.scala:44)\r\n  at scala.collection.SeqViewLike$AbstractTransformed.foreach(SeqViewLike.scala:37)\r\n  at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:149)\r\n  ... 59 elided\r\nCaused by: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 608096 path $.cross_validation_metrics_summary[0].data[0][0]\r\n  at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:385)\r\n  at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:213)\r\n  ... 90 more\r\n```\r\n\r\nPlease also provide us with the full and minimal reproducible code.\r\n```\r\nimport org.apache.spark.h2o._\r\nimport ai.h2o.sparkling.ml.algos._\r\nimport ai.h2o.sparkling.ml.models._\r\nimport org.apache.spark.ml.Pipeline\r\n\r\nval hc = H2OContext.getOrCreate()\r\nimport hc._\r\nimport hc.implicits._\r\n\r\nvar data = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/path/to/prostate.csv\")\r\n// Link to data: https://github.com/h2oai/sparkling-water/blob/master/examples/smalldata/prostate/prostate.csv\r\n\r\nval drf =  new H2ODRF()\r\n    .setFeaturesCols(Array(\"AGE\", \"RACE\", \"DPROS\", \"DCAPS\", \"PSA\", \"VOL\", \"GLEASON\"))\r\n    .setLabelCol(\"CAPSULE\")\r\n    .setColumnsToCategorical(Array(\"RACE\", \"DPROS\", \"DCAPS\",\"GLEASON\", \"CAPSULE\"))\r\n    .setSplitRatio(0.8)\r\n    .setNfolds(4)\r\n\r\nval nps = Map(\r\n        \"ntrees\" -> Array(10, 50).map(_.asInstanceOf[AnyRef]))\r\n\r\nval search = new H2OGridSearch()\r\n    .setHyperParameters(hyperParams)\r\n    .setAlgo(drf)\r\n    .setStrategy(\"Random Discrete\")\r\n\r\nval model = search.fit(data)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2171", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2171/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2171/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2171/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2171", "id": 635357868, "node_id": "MDU6SXNzdWU2MzUzNTc4Njg=", "number": 2171, "title": "setSparkVersionCheckDisabled() no work", "user": {"login": "shaoweijob", "id": 18146142, "node_id": "MDQ6VXNlcjE4MTQ2MTQy", "avatar_url": "https://avatars1.githubusercontent.com/u/18146142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shaoweijob", "html_url": "https://github.com/shaoweijob", "followers_url": "https://api.github.com/users/shaoweijob/followers", "following_url": "https://api.github.com/users/shaoweijob/following{/other_user}", "gists_url": "https://api.github.com/users/shaoweijob/gists{/gist_id}", "starred_url": "https://api.github.com/users/shaoweijob/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shaoweijob/subscriptions", "organizations_url": "https://api.github.com/users/shaoweijob/orgs", "repos_url": "https://api.github.com/users/shaoweijob/repos", "events_url": "https://api.github.com/users/shaoweijob/events{/privacy}", "received_events_url": "https://api.github.com/users/shaoweijob/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-09T11:45:00Z", "updated_at": "2020-06-11T06:05:04Z", "closed_at": "2020-06-11T06:05:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "ai.h2o:sparkling-water-package_2.11:3.28.0.1-1-2.4\r\n\r\nscala 2.11.8\r\nspark 2.2\r\n\r\n   ```\r\n val spark = SparkSession.builder.appName(\"auto train\").master(\"local[2]\").enableHiveSupport()\r\n    import org.apache.spark.h2o._\r\n    val conf = new H2OConf(spark).setInternalClusterMode().setSparkVersionCheckDisabled()\r\n    val hc = H2OContext.getOrCreate(spark, conf)\r\n```\r\nIn Doc:\r\nsetSparkVersionCheckDisabled() --> enables check if run-time Spark version matches build time Spark version.\r\n\r\nBut,  I found that there is no logic to judge this configuration after I read the source code of H2OContent.  \r\n![image](https://user-images.githubusercontent.com/18146142/84143703-9bd6ab80-aa89-11ea-90e7-0c1cefbcedaa.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2113", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2113/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2113/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2113/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2113", "id": 618820179, "node_id": "MDU6SXNzdWU2MTg4MjAxNzk=", "number": 2113, "title": "Calibrate Model in new api", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-15T09:12:28Z", "updated_at": "2020-05-15T10:32:16Z", "closed_at": "2020-05-15T10:31:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi. \r\nI'm using sparkling-water-3.30.0.2-1-2.3 with new api spark friendly and I don't find how to specify calibration frame. \r\n\r\n```scala\r\nval piloto = raw_piloto.select(featCols: _*)\r\n  \r\nval calib_df = spark.table(\"default.calib_table\").\r\n  filter($\"mes_campana\" === \"201911\" )\r\n\r\nval Array(trainingDF, validDF, testingDF) = piloto.randomSplit(Array(0.8, 0.1, 0.1))\r\n\r\n\r\nval estimator = new H2OXGBoost().\r\n      setLabelCol(\"target_residencial\").\r\n      setNtrees(20).\r\n      setMaxDepth(3).\r\n      setGamma(15).\r\n      setRegAlpha(6).\r\n      setRegLambda(6).\r\n      setColSampleRate(0.8).\r\n      setSampleRate(0.8).\r\n      setMinChildWeight(20).\r\n      setNfolds(3).\r\n      setSeed(42)\r\n\r\nval model = estimator.fit(trainingDF)\r\n``` \r\nWhere can I specify calib_df as a calibration frame? I don't find this in doc", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2096", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2096/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2096/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2096/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2096", "id": 615265549, "node_id": "MDU6SXNzdWU2MTUyNjU1NDk=", "number": 2096, "title": "Custom metric implementation Scala", "user": {"login": "palbha", "id": 20269788, "node_id": "MDQ6VXNlcjIwMjY5Nzg4", "avatar_url": "https://avatars1.githubusercontent.com/u/20269788?v=4", "gravatar_id": "", "url": "https://api.github.com/users/palbha", "html_url": "https://github.com/palbha", "followers_url": "https://api.github.com/users/palbha/followers", "following_url": "https://api.github.com/users/palbha/following{/other_user}", "gists_url": "https://api.github.com/users/palbha/gists{/gist_id}", "starred_url": "https://api.github.com/users/palbha/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/palbha/subscriptions", "organizations_url": "https://api.github.com/users/palbha/orgs", "repos_url": "https://api.github.com/users/palbha/repos", "events_url": "https://api.github.com/users/palbha/events{/privacy}", "received_events_url": "https://api.github.com/users/palbha/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-09T21:42:31Z", "updated_at": "2020-05-13T17:37:32Z", "closed_at": "2020-05-13T15:58:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi all, \r\n\r\nI was trying H2o models on spark(2.4.5) in scala.\r\nCan someone share details around creating a custom metric function to calculate relative error or is there Mean absolute percentage error directly available in models like GBM GLM in spark(Scala).\r\nEven the documentation around Sparkling water implementation in scala is limited .\r\n\r\nTIA\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2095", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2095/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2095/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2095/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2095", "id": 614645333, "node_id": "MDU6SXNzdWU2MTQ2NDUzMzM=", "number": 2095, "title": "Error connecting rsparkling with sparkling-water in aws", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-05-08T10:07:40Z", "updated_at": "2020-05-12T14:08:46Z", "closed_at": "2020-05-12T14:08:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi. I'm using sparkling-water 3.30.0.1 in aws fusing spark-scala , but I have problem with connecting with R. \r\nR version in aws is 3.4.1. My code is \r\n\r\n```r\r\nlibrary(tidyverse)\r\nlibrary(rsparkling)\r\nlibrary(sparklyr)\r\nlibrary(h2o)\r\n\r\noptions(rsparkling.sparklingwater.version = \"3.30.0.1-1-2.3\")\r\noptions(rsparkling.sparklingwater.location = \"/home/jcanadar/sparkling-water-3.30.0.1-1-2.3/jars/sparkling-water-assembly_2.11-3.30.0.1-1-2.3-all.jar\")\r\n\r\nspark_path <- \"/usr/lib/spark\"\r\nSys.setenv(SPARK_HOME = spark_path)\r\n\r\nconf <- sparklyr::spark_config()\r\nconf$spark.sql.catalogImplementation <- \"hive\"\r\nconf$spark.dynamicAllocation.enabled <- \"false\"\r\nconf$spark.executor.instances <- 10\r\n\r\nconf$spark.executor.cores <- 5\r\nconf$spark.executor.memory <-  \"10G\"\r\nconf$spark.driver.memory <- \"2g\"\r\nconf$spark.memory.fraction <- 0.95\r\n\r\nspark <- spark_connect(master = \"yarn\",\r\n                    version = \"2.3.2\",\r\n                    config = conf)\r\n\r\n# error initialize spark with rsparkling before create h2ocontext\r\nhc <- H2OContext.getOrCreate() \r\n\r\n```\r\n```\r\nError: org.apache.spark.sql.AnalysisException: java.lang.NoSuchMethodError: com.amazonaws.transform.JsonErrorUnmarshaller.<init>(Ljava/lang/Class;Ljava/lang/String;)V;\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:106)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:194)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:114)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:102)\r\n\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:39)\r\n\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog$lzycompute(HiveSessionStateBuilder.scala:54)\r\n\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog(HiveSessionStateBuilder.scala:52)\r\n\tat org.apache.spark.sql.hive.HiveSessionStateBuilder$$anon$1.<init>(HiveSessionStateBuilder.scala:69)\r\n\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.analyzer(HiveSessionStateBuilder.scala:69)\r\n\tat org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\r\n\tat org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\r\n\tat org.apache.spark.sql.internal.SessionState.analyzer$lzycompute(SessionState.scala:79)\r\n\tat org.apache.spark.sql.internal.SessionState.analyzer(SessionState.scala:79)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\r\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat sparklyr.Invoke.invoke(invoke.scala:147)\r\n\tat sparklyr.StreamHandler.handleMethodCall(stream.scala:136)\r\n\tat sparklyr.StreamHandler.read(stream.scala:61)\r\n\tat sparklyr.BackendHandler$$anonfun$channelRead0$1.apply$mcV$sp(handler.scala:58)\r\n\tat scala.util.control.Breaks.breakable(Breaks.scala:38)\r\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:38)\r\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:14)\r\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.NoSuchMethodError: com.amazonaws.transform.JsonErrorUnmarshaller.<init>(Ljava/lang/Class;Ljava/lang/String;)V\r\n\tat com.amazonaws.protocol.json.SdkJsonProtocolFactory.createErrorUnmarshallers(SdkJsonProtocolFactory.java:105)\r\n\tat com.amazonaws.protocol.json.SdkJsonProtocolFactory.<init>(SdkJsonProtocolFactory.java:49)\r\n\tat com.amazonaws.services.glue.AWSGlueClient.<clinit>(AWSGlueClient.java:140)\r\n\tat com.amazonaws.services.glue.AWSGlueClientBuilder.build(AWSGlueClientBuilder.java:61)\r\n\tat com.amazonaws.services.glue.AWSGlueClientBuilder.build(AWSGlueClientBuilder.java:27)\r\n\tat com.amazonaws.client.builder.AwsSyncClientBuilder.build(AwsSyncClientBuilder.java:46)\r\n\tat com.amazonaws.glue.catalog.metastore.AWSGlueClientFactory.newClient(AWSGlueClientFactory.java:70)\r\n\tat com.amazonaws.glue.catalog.metastore.AWSCatalogMetastoreClient.<init>(AWSCatalogMetastoreClient.java:146)\r\n\tat com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory.createMetaStoreClient(AWSGlueDataCatalogHiveClientFactory.java:16)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3007)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3042)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllDatabases(Hive.java:1235)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:175)\r\n\tat org.apache.hadoop.hive.ql.metadata.Hive.<clinit>(Hive.java:167)\r\n\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\r\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.newState(HiveClientImpl.scala:180)\r\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.<init>(HiveClientImpl.scala:114)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:264)\r\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:385)\r\n\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:287)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:66)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:65)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:195)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\r\n\t... 53 more\r\n```\r\nAnd before ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2074", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2074/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2074/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2074/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2074", "id": 611643459, "node_id": "MDU6SXNzdWU2MTE2NDM0NTk=", "number": 2074, "title": "Cannot start h2O context on databricks cluster", "user": {"login": "AnishDeepak", "id": 59416407, "node_id": "MDQ6VXNlcjU5NDE2NDA3", "avatar_url": "https://avatars0.githubusercontent.com/u/59416407?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AnishDeepak", "html_url": "https://github.com/AnishDeepak", "followers_url": "https://api.github.com/users/AnishDeepak/followers", "following_url": "https://api.github.com/users/AnishDeepak/following{/other_user}", "gists_url": "https://api.github.com/users/AnishDeepak/gists{/gist_id}", "starred_url": "https://api.github.com/users/AnishDeepak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AnishDeepak/subscriptions", "organizations_url": "https://api.github.com/users/AnishDeepak/orgs", "repos_url": "https://api.github.com/users/AnishDeepak/repos", "events_url": "https://api.github.com/users/AnishDeepak/events{/privacy}", "received_events_url": "https://api.github.com/users/AnishDeepak/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-05-04T06:54:21Z", "updated_at": "2020-05-04T16:00:37Z", "closed_at": "2020-05-04T16:00:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "#this is the code i used 2 months ago, It worked. but now its getting error.\r\nfrom pysparkling import *\r\nfrom pyspark.sql import SparkSession\r\nimport h2o\r\nspark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\nh2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\")\r\nhc = H2OContext.getOrCreate(conf=h2oConf)\r\n\r\n#spark run time version 5.5LTS\r\n#this is the error i am getting\r\n![databricks_error](https://user-images.githubusercontent.com/59416407/80942170-c043c600-8e01-11ea-89b9-d4d6d214b914.PNG)\r\n #after removing spark argument also getting this error\r\n![Capture](https://user-images.githubusercontent.com/59416407/80942291-0bf66f80-8e02-11ea-9756-bd2a6dd3a0f4.PNG)\r\n\r\n\r\n#these are the dependencies i have installed\r\nh2o_pysparkling_2.4\r\nrequests\r\ntabulate\r\nfuture\r\ncolorama>=0.3.8", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2073", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2073/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2073/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2073/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2073", "id": 610254379, "node_id": "MDU6SXNzdWU2MTAyNTQzNzk=", "number": 2073, "title": "Mojo predict probabilities in sparkling water", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-30T17:23:15Z", "updated_at": "2020-05-06T07:07:49Z", "closed_at": "2020-05-02T17:33:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, again. \r\nI'm trained my model and save it in s3, I'm using the latest stable sparkling water version. But when I want to load mojo I can only predict the prediction column, not the po, p1 columns. However, if I import the mojo model in h2oflow (with sparkling water) I can predict and get the probabilities.\r\n\r\n```scala\r\nval settings = H2OMOJOSettings(convertUnknownCategoricalLevelsToNa = true, convertInvalidNumbersToNa = true)\r\n\r\nval model= H2OMOJOModel.createFromMojo(\"s3a://bucket/mymodel.zip\", settings)\r\nval diciembre_df = spark.table(\"mytable\")\r\n\r\nval predicciones = model.transform(diciembre_df)\r\npredicciones.select(\"prediction\").show()\r\n+----------+\r\n|prediction|\r\n+----------+\r\n|         0|\r\n|         0|\r\n|         0|\r\n|         0|\r\n|         1|\r\n\r\n\r\n```\r\n\r\nBut I don't find how to get p0 and p1 probabilities. My model is a xgboost model with binomial distribution", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2044", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2044/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2044/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2044/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2044", "id": 601653253, "node_id": "MDU6SXNzdWU2MDE2NTMyNTM=", "number": 2044, "title": "Error while initiating H2OConnect in Databricks", "user": {"login": "DarthSimian", "id": 63828857, "node_id": "MDQ6VXNlcjYzODI4ODU3", "avatar_url": "https://avatars2.githubusercontent.com/u/63828857?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DarthSimian", "html_url": "https://github.com/DarthSimian", "followers_url": "https://api.github.com/users/DarthSimian/followers", "following_url": "https://api.github.com/users/DarthSimian/following{/other_user}", "gists_url": "https://api.github.com/users/DarthSimian/gists{/gist_id}", "starred_url": "https://api.github.com/users/DarthSimian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DarthSimian/subscriptions", "organizations_url": "https://api.github.com/users/DarthSimian/orgs", "repos_url": "https://api.github.com/users/DarthSimian/repos", "events_url": "https://api.github.com/users/DarthSimian/events{/privacy}", "received_events_url": "https://api.github.com/users/DarthSimian/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-17T02:14:59Z", "updated_at": "2020-04-17T06:04:17Z", "closed_at": "2020-04-17T06:04:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am getting the below error while trying to initiate PySparkiling in a Databricks cluster.\r\nThe cluster is a Spark 2.4.5, Scala 2.11 environment and is not a ML cluster\r\nAlso, I tried turning off Autoscaling and that didn't help either\r\n\r\n\r\n\r\n```\r\nfrom pysparkling import *\r\nfrom pyspark.sql import SparkSession\r\nimport h2o\r\n\r\nspark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\n\r\nh2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\").set('spark.dynamicAllocation', 'false')\r\nhc = H2OContext.getOrCreate(spark, conf=h2oConf)\r\n\r\n```\r\n\r\n\r\n\r\n---------------------------------------------------------------------------\r\nPy4JJavaError                             Traceback (most recent call last)\r\n<command-418156289286121> in <module>\r\n      4 spark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\n      5 h2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\").set('spark.dynamicAllocation', 'false')\r\n----> 6 hc = H2OContext.getOrCreate(spark, conf=h2oConf)\r\n      7 #spark.conf.get(\"spark.databricks.clusterUsageTags.sparkVersion\")\r\n      8 \r\n\r\n/databricks/python/lib/python3.7/site-packages/ai/h2o/sparkling/H2OContext.py in getOrCreate(spark, conf)\r\n     97         package = getattr(_jvm().org.apache.spark.h2o, \"H2OContext$\")\r\n     98         module = package.__getattr__(\"MODULE$\")\r\n---> 99         jhc = module.getOrCreate(selected_conf._jconf)\r\n    100         h2o_context._jhc = jhc\r\n    101         h2o_context._conf = selected_conf\r\n\r\n/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)\r\n   1255         answer = self.gateway_client.send_command(command)\r\n   1256         return_value = get_return_value(\r\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\r\n   1258 \r\n   1259         for temp_arg in temp_args:\r\n\r\n/databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw)\r\n     61     def deco(*a, **kw):\r\n     62         try:\r\n---> 63             return f(*a, **kw)\r\n     64         except py4j.protocol.Py4JJavaError as e:\r\n     65             s = e.java_exception.toString()\r\n\r\n/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\r\n    326                 raise Py4JJavaError(\r\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\r\n--> 328                     format(target_id, \".\", name), value)\r\n    329             else:\r\n    330                 raise Py4JError(\r\n\r\nPy4JJavaError: An error occurred while calling o265.getOrCreate.\r\n: java.lang.NoClassDefFoundError: org/spark_project/jetty/util/thread/ThreadPool\r\n\tat org.apache.spark.h2o.H2OContext.<init>(H2OContext.scala:98)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:492)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\r\n\tat py4j.Gateway.invoke(Gateway.java:295)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassNotFoundException: org.spark_project.jetty.util.thread.ThreadPool\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:419)\r\n\tat com.databricks.backend.daemon.driver.ClassLoaders$LibraryClassLoader.loadClass(ClassLoaders.scala:151)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:352)\r\n\t... 13 more\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2042", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2042/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2042/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2042/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2042", "id": 601083249, "node_id": "MDU6SXNzdWU2MDEwODMyNDk=", "number": 2042, "title": "How to export mojo in spark scala", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-16T14:04:07Z", "updated_at": "2020-04-22T09:37:34Z", "closed_at": "2020-04-22T09:36:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi @jakubhava  again. \r\nI have mi model training in EMR cluster with \r\n```scala\r\nval estimator = new H2OXGBoost().\r\n      setLabelCol(\"target_residencial\").\r\n      setNtrees(3).\r\n      setMaxDepth(3)\r\nval model = estimator.fit(trainingDF)\r\n```  \r\nBut I don't know how to export model to mojo . I'm trying\r\n```scala\r\nval destination = \"file:///home/jcanadar/rosetta_train_models/modelos/jj.zip\"\r\nmodel.write.overwrite().save(destination)\r\n```\r\n\r\nBut I get `Caused by: java.io.IOException: Mkdirs failed to create file:` error. I'm a bit desperate, All things run correctly with old hex.tree.xgboost._  H2O algorithms, but I know you plan to deprecate this in sparkling-water, and maybe for good reasons. \r\nI need to pass to my engineer a fully functional scala script to train model and save mojo. They will write a complete gradle project to deploy train an prediction model in our production environment as well than other gradle project only for prediction using mojo, based in my old code https://github.com/joscani/predict_binary_h2o \r\nThanks for your fantastic work. \r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2037", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2037/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2037/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/2037/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/2037", "id": 599647261, "node_id": "MDU6SXNzdWU1OTk2NDcyNjE=", "number": 2037, "title": "which xgboost  hex.tree.xgboost._ vs ai.h2o.sparkling.ml.algos.H2OXGBoost", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-04-14T15:10:11Z", "updated_at": "2020-07-21T12:25:41Z", "closed_at": "2020-04-30T17:17:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi. \r\nIn my job I found that \r\nai.h2o.sparkling.ml.algos.H2OXGBoost is so slow and cluster crash but if I use h2o algortithm import hex.tree.xgboost._ works fine. \r\nThe last works with H2OFrames and the first with spark dataframes. Is some reason to use one or other? In my experience algorithm from hex.tree over H2OFrame (sparkdatafrme to h2oframe converts) is better than the other, at least in my case.  My dataset has over 10 million of rows and around 120 columns", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1987", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1987/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1987/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1987/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1987", "id": 586888581, "node_id": "MDU6SXNzdWU1ODY4ODg1ODE=", "number": 1987, "title": "java.nio.channels.ClosedChannelException in Standalone Mode", "user": {"login": "Huagela", "id": 26166111, "node_id": "MDQ6VXNlcjI2MTY2MTEx", "avatar_url": "https://avatars2.githubusercontent.com/u/26166111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Huagela", "html_url": "https://github.com/Huagela", "followers_url": "https://api.github.com/users/Huagela/followers", "following_url": "https://api.github.com/users/Huagela/following{/other_user}", "gists_url": "https://api.github.com/users/Huagela/gists{/gist_id}", "starred_url": "https://api.github.com/users/Huagela/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Huagela/subscriptions", "organizations_url": "https://api.github.com/users/Huagela/orgs", "repos_url": "https://api.github.com/users/Huagela/repos", "events_url": "https://api.github.com/users/Huagela/events{/privacy}", "received_events_url": "https://api.github.com/users/Huagela/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-03-24T11:25:46Z", "updated_at": "2020-04-06T19:56:14Z", "closed_at": "2020-04-06T19:56:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "\r\n\r\n- Sparkling Water version\r\n- Execution mode  standalone\r\n- Are you using Windows/Linux/MAC? ubuntu\r\n\r\nI had a SPARK cluster with one master and two workers, and had tested SparkPi successfully.\r\n\r\nwhen trying to start  Sparkling Water as a Spark Package, like this:\r\n```$SPARK_HOME/bin/spark-shell --packages ai.h2o:sparkling-water-package_2.11:3.28.1.2-1-2.4```\r\n\r\nget a spark shell:\r\n```Ivy Default Cache set to: /home/spark/.ivy2/cache\r\nThe jars for the packages stored in: /home/spark/.ivy2/jars\r\n:: loading settings :: url = jar:file:/home/spark/spark-2.4.5-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\r\nai.h2o#sparkling-water-package_2.11 added as a dependency\r\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-f6da72a7-494f-4e9f-87a8-8a1f57d8b9dc;1.0\r\n\tconfs: [default]\r\n\tfound ai.h2o#sparkling-water-package_2.11;3.28.1.2-1-2.4 in central\r\n:: resolution report :: resolve 232ms :: artifacts dl 5ms\r\n\t:: modules in use:\r\n\tai.h2o#sparkling-water-package_2.11;3.28.1.2-1-2.4 from central in [default]\r\n\t---------------------------------------------------------------------\r\n\t|                  |            modules            ||   artifacts   |\r\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\r\n\t---------------------------------------------------------------------\r\n\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\r\n\t---------------------------------------------------------------------\r\n:: retrieving :: org.apache.spark#spark-submit-parent-f6da72a7-494f-4e9f-87a8-8a1f57d8b9dc\r\n\tconfs: [default]\r\n\t0 artifacts copied, 1 already retrieved (0kB/8ms)\r\n20/03/24 18:52:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\r\nSetting default log level to \"WARN\".\r\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\r\nSpark context Web UI available at http://10.18.96.152:4040\r\nSpark context available as 'sc' (master = spark://10.18.96.152:7077, app id = app-20200324185239-0004).\r\nSpark session available as 'spark'.\r\nWelcome to\r\n      ____              __\r\n     / __/__  ___ _____/ /__\r\n    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.5\r\n      /_/\r\n\r\nUsing Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_242)\r\nType in expressions to have them evaluated.\r\nType :help for more information.\r\n\r\nscala>\r\n```\r\nThen, I follow the tutorial ,Create an H2O cloud inside the Spark cluster:\r\n```\r\nimport org.apache.spark.h2o._\r\nval h2oContext = H2OContext.getOrCreate()\r\nimport h2oContext._\r\n```\r\nBUT , I got ERROR when `val h2oContext = H2OContext.getOrCreate()`:\r\n```\r\nscala> val h2oContext = H2OContext.getOrCreate()\r\n20/03/24 19:01:09 WARN InternalH2OBackend: To avoid non-deterministic behavior of Spark broadcast-based joins,\r\nwe recommend to set `spark.sql.autoBroadcastJoinThreshold` property of SparkSession to -1.\r\nE.g. spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\r\nWe also recommend to avoid using broadcast hints in your Spark SQL code.\r\n20/03/24 19:01:09 WARN H2OConf: The method 'clientWebEnabled' is deprecated.  This method will be removed in the release 3.30.\r\n20/03/24 19:01:09 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 0 (Infinitive) as we need to ensure we run on the nodes with H2O\r\n20/03/24 19:01:09 WARN InternalH2OBackend: The property 'spark.scheduler.minRegisteredResourcesRatio' is not specified!\r\nWe recommend to pass `--conf spark.scheduler.minRegisteredResourcesRatio=1`\r\n[Stage 0:>                                                        (0 + 20) / 21]20/03/24 19:03:10 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/ai.h2o_sparkling-water-package_2.11-3.28.1.2-1-2.4.jar, byteCount=118726847, body=FileSegmentManagedBuffer{file=/home/spark/.ivy2/jars/ai.h2o_sparkling-water-package_2.11-3.28.1.2-1-2.4.jar, offset=0, length=118726847}} to /10.18.96.150:53650; closing connection\r\njava.nio.channels.ClosedChannelException\r\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:607)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.closeOnRead(AbstractNioByteChannel.java:105)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:171)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n20/03/24 19:03:10 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/ai.h2o_sparkling-water-package_2.11-3.28.1.2-1-2.4.jar, byteCount=118726847, body=FileSegmentManagedBuffer{file=/home/spark/.ivy2/jars/ai.h2o_sparkling-water-package_2.11-3.28.1.2-1-2.4.jar, offset=0, length=118726847}} to /10.18.96.198:45762; closing connection\r\njava.io.IOException: Connection reset by peer\r\n\tat sun.nio.ch.FileChannelImpl.transferTo0(Native Method)\r\n\tat sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)\r\n\tat sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)\r\n\tat sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)\r\n\tat io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139)\r\n\tat org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)\r\n\tat io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:359)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel.doWriteInternal(AbstractNioByteChannel.java:235)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel.doWrite0(AbstractNioByteChannel.java:209)\r\n\tat io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:397)\r\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:931)\r\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:361)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:694)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n20/03/24 19:03:10 WARN TaskSetManager: Lost task 5.0 in stage 0.0 (TID 5, 10.18.96.150, executor 1): java.nio.channels.ClosedChannelException\r\n\tat org.apache.spark.network.client.StreamInterceptor.channelInactive(StreamInterceptor.java:62)\r\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:176)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:257)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:243)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:236)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1417)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:257)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:243)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:913)\r\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:819)\r\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:510)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:518)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n[Stage 0:>                                                        (0 + 20) / 21]\r\n```\r\n8080 port is shown as normal, but 4040 port always shows 'collect at SpreadRDDBuilder.scala:63'\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1974", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1974/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1974/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1974/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1974", "id": 585440407, "node_id": "MDU6SXNzdWU1ODU0NDA0MDc=", "number": 1974, "title": "java.lang.ClassNotFoundException: ai.h2o.sparkling.ml.models.H2OSupervisedMOJOModel", "user": {"login": "manujchandra", "id": 15191493, "node_id": "MDQ6VXNlcjE1MTkxNDkz", "avatar_url": "https://avatars1.githubusercontent.com/u/15191493?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manujchandra", "html_url": "https://github.com/manujchandra", "followers_url": "https://api.github.com/users/manujchandra/followers", "following_url": "https://api.github.com/users/manujchandra/following{/other_user}", "gists_url": "https://api.github.com/users/manujchandra/gists{/gist_id}", "starred_url": "https://api.github.com/users/manujchandra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manujchandra/subscriptions", "organizations_url": "https://api.github.com/users/manujchandra/orgs", "repos_url": "https://api.github.com/users/manujchandra/repos", "events_url": "https://api.github.com/users/manujchandra/events{/privacy}", "received_events_url": "https://api.github.com/users/manujchandra/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-03-21T06:21:36Z", "updated_at": "2020-04-03T02:08:49Z", "closed_at": "2020-04-03T02:08:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi!,\r\n\r\nI am running a local PySpark cluster. \r\n \r\nVersions:\r\nSpark : v2.4.5\r\nPySparkling 2.4\r\nPython 3.6.10 :: Anaconda\r\n\r\nI did a small SMS spam ham classification model. I am trying to deploy the model as instructed [here](https://github.com/h2oai/h2o-tutorials/blob/master/training/sparkling_water_hands_on/sentiment_analysis/AmazonFineFoodPipeline.ipynb) is the \"Let's Deply the Application\" section\r\n\r\nWhen loading the model, I get the following error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nPy4JJavaError                             Traceback (most recent call last)\r\n<ipython-input-5-53b9ea9fab97> in <module>\r\n      1 # load the exported pipeline model\r\n      2 from pyspark.ml import PipelineModel\r\n----> 3 pipeline_model = PipelineModel.load(\"spam_or_ham.model/\")\r\n\r\n~/anaconda3/envs/spark/lib/python3.6/site-packages/pyspark/ml/util.py in load(cls, path)\r\n    360     def load(cls, path):\r\n    361         \"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\r\n--> 362         return cls.read().load(path)\r\n    363 \r\n    364 \r\n\r\n~/anaconda3/envs/spark/lib/python3.6/site-packages/pyspark/ml/pipeline.py in load(self, path)\r\n    240         metadata = DefaultParamsReader.loadMetadata(path, self.sc)\r\n    241         if 'language' not in metadata['paramMap'] or metadata['paramMap']['language'] != 'Python':\r\n--> 242             return JavaMLReader(self.cls).load(path)\r\n    243         else:\r\n    244             uid, stages = PipelineSharedReadWrite.load(metadata, self.sc, path)\r\n\r\n~/anaconda3/envs/spark/lib/python3.6/site-packages/pyspark/ml/util.py in load(self, path)\r\n    298         if not isinstance(path, basestring):\r\n    299             raise TypeError(\"path should be a basestring, got type %s\" % type(path))\r\n--> 300         java_obj = self._jread.load(path)\r\n    301         if not hasattr(self._clazz, \"_from_java\"):\r\n    302             raise NotImplementedError(\"This Java ML type cannot be loaded into Python currently: %r\"\r\n\r\n~/anaconda3/envs/spark/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args)\r\n   1255         answer = self.gateway_client.send_command(command)\r\n   1256         return_value = get_return_value(\r\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\r\n   1258 \r\n   1259         for temp_arg in temp_args:\r\n\r\n~/anaconda3/envs/spark/lib/python3.6/site-packages/pyspark/sql/utils.py in deco(*a, **kw)\r\n     61     def deco(*a, **kw):\r\n     62         try:\r\n---> 63             return f(*a, **kw)\r\n     64         except py4j.protocol.Py4JJavaError as e:\r\n     65             s = e.java_exception.toString()\r\n\r\n~/anaconda3/envs/spark/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\r\n    326                 raise Py4JJavaError(\r\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\r\n--> 328                     format(target_id, \".\", name), value)\r\n    329             else:\r\n    330                 raise Py4JError(\r\n\r\nPy4JJavaError: An error occurred while calling o40.load.\r\n: java.lang.ClassNotFoundException: ai.h2o.sparkling.ml.models.H2OSupervisedMOJOModel\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat java.lang.Class.forName0(Native Method)\r\n\tat java.lang.Class.forName(Class.java:348)\r\n\tat org.apache.spark.util.Utils$.classForName(Utils.scala:238)\r\n\tat org.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstance(ReadWrite.scala:651)\r\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$$anonfun$4.apply(Pipeline.scala:274)\r\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$$anonfun$4.apply(Pipeline.scala:272)\r\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\r\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\r\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\r\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\r\n\tat org.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:272)\r\n\tat org.apache.spark.ml.PipelineModel$PipelineModelReader.load(Pipeline.scala:348)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nCode is:\r\n\r\n```python\r\nfrom pyspark import SparkContext\r\n\r\nfrom pysparkling import *\r\nfrom pysparkling.ml import *\r\n\r\nfrom pyspark.sql import SQLContext\r\nfrom pyspark.sql.types import StructType\r\n\r\n\r\n\r\nimport json\r\nimport os\r\n```\r\n\r\n\r\n```python\r\nsc = SparkContext(\"local[*]\", \"spamorham\")\r\n```\r\n\r\n\r\n```python\r\n# check we have spark available\r\nsc\r\n```\r\n\r\n\r\n```python\r\nsqlContext = SQLContext(sc)\r\n```\r\n\r\n\r\n```python\r\n# load the exported pipeline model\r\nfrom pyspark.ml import PipelineModel\r\npipeline_model = PipelineModel.load(\"spam_or_ham.model/\")\r\n```\r\n\r\n\r\n```python\r\n\r\n```\r\n\r\n\r\n```python\r\nschema = StructType.fromJson(json.load(open(\"schema.json\", \"r\")))\r\n```\r\n\r\n\r\n```python\r\nprint(schema)\r\n```\r\n\r\n\r\n```python\r\n# Start Streaming\r\nfrom subprocess import Popen\r\nPopen([\"./start_streaming.sh\"])\r\n```\r\n\r\n\r\n```python\r\n!ls output\r\n```\r\n\r\n\r\n```python\r\n\r\n```\r\n\r\n\r\n```python\r\ninput_data_stream = sqlContext.readStream.schema(schema).csv(\"output\")\r\n```\r\n\r\n\r\n```python\r\noutput_data_stream = pipeline_model.transform(input_data_stream)\r\n```\r\n\r\n\r\n```python\r\n# store in memory. Can also store in bucket or another stream\r\noutput_data_stream.writeStream.format(\"memory\").queryName(\"label\").start()\r\n```\r\n\r\n\r\n```python\r\nimport time\r\nwhile(True):\r\n    sqlContext.sql(\"select * from label\").show()\r\n    time.sleep(5)\r\n```\r\n\r\nNote: I have tried in Python 3.7 also with same error. \r\nTried on a fresh conda environment as well.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1959", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1959/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1959/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1959/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1959", "id": 583890847, "node_id": "MDU6SXNzdWU1ODM4OTA4NDc=", "number": 1959, "title": "Cannot convert Spark DF into H2OFrame due to missing extended API endpoint", "user": {"login": "potasz", "id": 1189542, "node_id": "MDQ6VXNlcjExODk1NDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/1189542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/potasz", "html_url": "https://github.com/potasz", "followers_url": "https://api.github.com/users/potasz/followers", "following_url": "https://api.github.com/users/potasz/following{/other_user}", "gists_url": "https://api.github.com/users/potasz/gists{/gist_id}", "starred_url": "https://api.github.com/users/potasz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/potasz/subscriptions", "organizations_url": "https://api.github.com/users/potasz/orgs", "repos_url": "https://api.github.com/users/potasz/repos", "events_url": "https://api.github.com/users/potasz/events{/privacy}", "received_events_url": "https://api.github.com/users/potasz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-18T17:31:01Z", "updated_at": "2020-03-20T02:35:39Z", "closed_at": "2020-03-20T02:35:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI have updated to the latest SparklingWater version 3.28.1.1-1-2.4 and H2OContext#asH2OFrame() started to fail due to missing /3/InitializeFrame endpoint on the remote H2O cluster.\r\n\r\nThe application runs on Yarn with a remote H2O cluster. In version 3.26 I could get the extended H2O driver that included this endpoint. I can see that in 3.28 it was removed but I cannot see how should the code be migrated.\r\n\r\nThe documentation still says to use  H2OContext#asH2OFrame() (http://docs.h2o.ai/sparkling-water/2.4/latest-stable/doc/tutorials/spark_h2o_conversions.html#converting-a-dataframe-into-an-h2oframe)\r\n\r\nWhat is the new way to convert a Spark DF into H2O frame? Or how to get the extended H2O driver for version 3.28.1.1\r\n\r\nThank you.\r\n\r\nThe exception I get is:\r\n\r\n`Exception in thread \"main\" ai.h2o.sparkling.backend.external.RestApiCommunicationException: External H2O node 10.200.128.30:54321 responded with\r\nStatus code: 404 : Not Found\r\nServer error: {\"__meta\":{\"schema_version\":3,\"schema_name\":\"H2OErrorV3\",\"schema_type\":\"H2OError\"},\"timestamp\":1584546486390,\"error_url\":\"POST /3/InitializeFrame\",\"msg\":\"\\n\\nERROR\r\nMESSAGE:\\n\\nPOST /3/InitializeFrame not found\\n\\n\",\"dev_msg\":\"\\n\\nERROR MESSAGE:\\n\\nPOST /3/InitializeFrame not found\\n\\n\",\"http_status\":404,\"values\":{},\"exception_type\":\"water.e\r\nxceptions.H2ONotFoundArgumentException\",\"exception_msg\":\"\\n\\nERROR MESSAGE:\\n\\nPOST /3/InitializeFrame not found\\n\\n\",\"stacktrace\":[\"water.exceptions.H2ONotFoundArgumentException\r\n: POST /3/InitializeFrame not found\",\"    water.api.RequestServer.response404(RequestServer.java:743)\",\"    water.api.RequestServer.serve(RequestServer.java:467)\",\"    water.api.\r\nRequestServer.doGeneric(RequestServer.java:301)\",\"    water.api.RequestServer.doPost(RequestServer.java:227)\",\"    javax.servlet.http.HttpServlet.service(HttpServlet.java:727)\",\"\r\n    javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\",\"    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)\",\"    org.eclipse.jetty.servlet.Serv\r\nletHandler.doHandle(ServletHandler.java:501)\",\"    org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)\",\"    org.eclipse.jetty.servlet.ServletHandl\r\ner.doScope(ServletHandler.java:427)\",\"    org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)\",\"    org.eclipse.jetty.server.handler.ScopedHandler.h\r\nandle(ScopedHandler.java:135)\",\"    org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154)\",\"    org.eclipse.jetty.server.handler.HandlerWrapper.ha\r\nndle(HandlerWrapper.java:116)\",\"    water.webserver.jetty8.Jetty8ServerAdapter$LoginHandler.handle(Jetty8ServerAdapter.java:119)\",\"    org.eclipse.jetty.server.handler.HandlerCol\r\nlection.handle(HandlerCollection.java:154)\",\"    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\",\"    org.eclipse.jetty.server.Server.handle(Serv\r\ner.java:366)\",\"    org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)\",\"    org.eclipse.jetty.server.BlockingHttpConnection.handleRequ\r\nest(BlockingHttpConnection.java:53)\",\"    org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:984)\",\"    org.eclipse.jetty.server.AbstractHttpConn\r\nection$RequestHandler.content(AbstractHttpConnection.java:1045)\",\"    org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:861)\",\"    org.eclipse.jetty.http.HttpParser.par\r\nseAvailable(HttpParser.java:236)\",\"    org.eclipse.jetty.server.BlockingHttpConnection.handle(BlockingHttpConnection.java:72)\",\"    org.eclipse.jetty.server.bio.SocketConnector$C\r\nonnectorEndPoint.run(SocketConnector.java:264)\",\"    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\",\"    org.eclipse.jetty.util.thread.QueuedTh\r\nreadPool$3.run(QueuedThreadPool.java:543)\",\"    java.lang.Thread.run(Thread.java:748)\"]}\r\n        at ai.h2o.sparkling.backend.external.RestCommunication$class.checkResponseCode(RestCommunication.scala:240)\r\n        at ai.h2o.sparkling.frame.H2OFrame$.checkResponseCode(H2OFrame.scala:79)\r\n        at ai.h2o.sparkling.backend.external.RestCommunication$class.readURLContent(RestCommunication.scala:219)\r\n        at ai.h2o.sparkling.frame.H2OFrame$.readURLContent(H2OFrame.scala:79)\r\n        at ai.h2o.sparkling.backend.external.RestCommunication$class.request(RestCommunication.scala:115)\r\n        at ai.h2o.sparkling.frame.H2OFrame$.request(H2OFrame.scala:79)\r\n        at ai.h2o.sparkling.backend.external.RestCommunication$class.update(RestCommunication.scala:73)\r\n        at ai.h2o.sparkling.frame.H2OFrame$.update(H2OFrame.scala:79)\r\n        at ai.h2o.sparkling.frame.H2OFrame$.initializeFrame(H2OFrame.scala:131)\r\n        at ai.h2o.sparkling.backend.external.ExternalBackendConverter$.convert(ExternalBackendConverter.scala:55)\r\n        at ai.h2o.sparkling.backend.converters.SparkDataFrameConverter$.toH2OFrameKeyString(SparkDataFrameConverter.scala:108)\r\n        at ai.h2o.sparkling.backend.converters.SparkDataFrameConverter$.toH2OFrame(SparkDataFrameConverter.scala:76)\r\n        at org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:234)\r\n        at org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:234)\r\n        at org.apache.spark.h2o.utils.H2OContextUtils$class.withConversionDebugPrints(H2OContextUtils.scala:78)\r\n        at org.apache.spark.h2o.H2OContext.withConversionDebugPrints(H2OContext.scala:64)\r\n        at org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:234)`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1953", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1953/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1953/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1953/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1953", "id": 582754040, "node_id": "MDU6SXNzdWU1ODI3NTQwNDA=", "number": 1953, "title": "HTTPS docs website", "user": {"login": "jayvdb", "id": 15092, "node_id": "MDQ6VXNlcjE1MDky", "avatar_url": "https://avatars1.githubusercontent.com/u/15092?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jayvdb", "html_url": "https://github.com/jayvdb", "followers_url": "https://api.github.com/users/jayvdb/followers", "following_url": "https://api.github.com/users/jayvdb/following{/other_user}", "gists_url": "https://api.github.com/users/jayvdb/gists{/gist_id}", "starred_url": "https://api.github.com/users/jayvdb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jayvdb/subscriptions", "organizations_url": "https://api.github.com/users/jayvdb/orgs", "repos_url": "https://api.github.com/users/jayvdb/repos", "events_url": "https://api.github.com/users/jayvdb/events{/privacy}", "received_events_url": "https://api.github.com/users/jayvdb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-17T04:54:19Z", "updated_at": "2020-03-17T23:42:40Z", "closed_at": "2020-03-17T23:42:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://docs.h2o.ai/ (https) fails.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1946", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1946/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1946/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1946/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1946", "id": 579986574, "node_id": "MDU6SXNzdWU1Nzk5ODY1NzQ=", "number": 1946, "title": "Strange error in emr aws", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-12T14:38:21Z", "updated_at": "2020-03-25T16:35:03Z", "closed_at": "2020-03-24T11:30:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "- Sparkling Water/PySparkling/RSparkling version: sparkling-water-3.28.0.4-1-2.3 / rsparkling: \u20183.28.0.4.1.2.3\u2019\r\n- Hadoop Version & Distribution: EMR ver 5.19\r\n- Execution mode `YARN-client`\r\n- spark-version: 2.3.2\r\n- h2oversion:\u20183.28.0.4\u2019\r\n\r\nWhen I try to connect with rsparkling \r\n\r\n`library(tidyverse)\r\nlibrary(sparklyr)\r\nlibrary(DBI)\r\nlibrary(rsparkling)\r\nlibrary(h2o)\r\n\r\nspark_path <- \"/usr/lib/spark\"\r\nSys.setenv(SPARK_HOME = spark_path)\r\n\r\noptions(rsparkling.sparklingwater.version = \"3.28.0.4\")\r\noptions(rsparkling.sparklingwater.location = \"/tmp/sparkling-water/sparkling-water-3.28.0.4-1-2.3/assembly/build/libs/sparkling-water-assembly_2.11-3.28.0.4-1-2.3-all.jar\")\r\n\r\n\r\nconf <- sparklyr::spark_config()\r\nconf$spark.sql.catalogImplementation <- \"hive\"\r\nconf$spark.dynamicAllocation.enabled <- \"false\"\r\n\r\nsc <- spark_connect(master = \"yarn\",\r\n                    version = \"2.3.2\",\r\n                    config = conf)\r\n\r\nsrc_databases(sc)\r\n`\r\n`\r\n > src_databases(sc)\r\nError: org.apache.spark.sql.AnalysisException: java.lang.NoSuchMethodError: com.amazonaws.transform.JsonErrorUnmarshaller.<init>(Ljava/lang/Class;Ljava/lang/String;)V;\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:106)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:194)\r\n        at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:114)\r\n        at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:102)\r\n        at org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:39)\r\n        at org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog$lzycompute(HiveSessionStateBuilder.scala:54)\r\n        at org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog(HiveSessionStateBuilder.scala:52)\r\n        at org.apache.spark.sql.hive.HiveSessionStateBuilder$$anon$1.<init>(HiveSessionStateBuilder.scala:69)\r\n        at org.apache.spark.sql.hive.HiveSessionStateBuilder.analyzer(HiveSessionStateBuilder.scala:69)\r\n        at org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\r\n        at org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\r\n        at org.apache.spark.sql.internal.SessionState.analyzer$lzycompute(SessionState.scala:79)\r\n        at org.apache.spark.sql.internal.SessionState.analyzer(SessionState.scala:79)\r\n        at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\r\n        at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\r\n        at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\r\n        at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\r\n        at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at sparklyr.Invoke.invoke(invoke.scala:147)\r\n        at sparklyr.StreamHandler.handleMethodCall(stream.scala:122)\r\n        at sparklyr.StreamHandler.read(stream.scala:65)\r\n        at sparklyr.BackendHandler.channelRead0(handler.scala:53)\r\n        at sparklyr.BackendHandler.channelRead0(handler.scala:12)\r\n        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n        at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n        at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)\r\n        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)\r\n        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\r\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\r\n        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.NoSuchMethodError: com.amazonaws.transform.JsonErrorUnmarshaller.<init>(Ljava/lang/Class;Ljava/lang/String;)V\r\n        at com.amazonaws.protocol.json.SdkJsonProtocolFactory.createErrorUnmarshallers(SdkJsonProtocolFactory.java:105)\r\n        at com.amazonaws.protocol.json.SdkJsonProtocolFactory.<init>(SdkJsonProtocolFactory.java:49)\r\n        at com.amazonaws.services.glue.AWSGlueClient.<clinit>(AWSGlueClient.java:140)\r\n        at com.amazonaws.services.glue.AWSGlueClientBuilder.build(AWSGlueClientBuilder.java:61)\r\n        at com.amazonaws.services.glue.AWSGlueClientBuilder.build(AWSGlueClientBuilder.java:27)\r\n        at com.amazonaws.client.builder.AwsSyncClientBuilder.build(AwsSyncClientBuilder.java:46)\r\n        at com.amazonaws.glue.catalog.metastore.AWSGlueClientFactory.newClient(AWSGlueClientFactory.java:70)\r\n        at com.amazonaws.glue.catalog.metastore.AWSCatalogMetastoreClient.<init>(AWSCatalogMetastoreClient.java:146)\r\n        at com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory.createMetaStoreClient(AWSGlueDataCatalogHiveClientFactory.java:16)\r\n        at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3007)\r\n        at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3042)\r\n        at org.apache.hadoop.hive.ql.metadata.Hive.getAllDatabases(Hive.java:1235)\r\n        at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:175)\r\n        at org.apache.hadoop.hive.ql.metadata.Hive.<clinit>(Hive.java:167)\r\n        at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.newState(HiveClientImpl.scala:180)\r\n        at org.apache.spark.sql.hive.client.HiveClientImpl.<init>(HiveClientImpl.scala:114)\r\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n        at org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:264)\r\n        at org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:385)\r\n        at org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:287)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:66)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:65)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:195)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\r\n        at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\r\n        ... 51 more\r\n`\r\n\r\nBut, If I try to connect spark without rsparkling it works, and also works if I connect using  sparkling-shell in console.\r\n\r\n`\r\nbin/sparkling-shell \\\r\n--master yarn \\\r\n--conf spark.executor.instances=12 \\\r\n--conf spark.executor.memory=10g \\\r\n--conf spark.driver.memory=8g \\\r\n--conf spark.scheduler.maxRegisteredResourcesWaitingTime=1000000 \\\r\n--conf spark.ext.h2o.fail.on.unsupported.spark.param=false \\\r\n--conf spark.dynamicAllocation.enabled=false \\\r\n--conf spark.sql.autoBroadcastJoinThreshold=-1 \\\r\n--conf spark.locality.wait=30000 \\\r\n--conf spark.scheduler.minRegisteredResourcesRatio=1\r\n`\r\n\r\nAny idea ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1828", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1828/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1828/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1828/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1828", "id": 563849739, "node_id": "MDU6SXNzdWU1NjM4NDk3Mzk=", "number": 1828, "title": "Issue with Obtain SHAP values from MOJO model", "user": {"login": "hemanshupaliwa7", "id": 33899276, "node_id": "MDQ6VXNlcjMzODk5Mjc2", "avatar_url": "https://avatars0.githubusercontent.com/u/33899276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hemanshupaliwa7", "html_url": "https://github.com/hemanshupaliwa7", "followers_url": "https://api.github.com/users/hemanshupaliwa7/followers", "following_url": "https://api.github.com/users/hemanshupaliwa7/following{/other_user}", "gists_url": "https://api.github.com/users/hemanshupaliwa7/gists{/gist_id}", "starred_url": "https://api.github.com/users/hemanshupaliwa7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hemanshupaliwa7/subscriptions", "organizations_url": "https://api.github.com/users/hemanshupaliwa7/orgs", "repos_url": "https://api.github.com/users/hemanshupaliwa7/repos", "events_url": "https://api.github.com/users/hemanshupaliwa7/events{/privacy}", "received_events_url": "https://api.github.com/users/hemanshupaliwa7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-02-12T09:00:13Z", "updated_at": "2020-04-14T04:31:45Z", "closed_at": "2020-02-18T10:06:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nI am facing issue \"Caused by: java.lang.ArrayIndexOutOfBoundsException: -1\" while trying to get the SHAP Values getting details from \"http://docs.h2o.ai/sparkling-water/2.4/latest-stable/doc/tutorials/shap_values.html\"\r\n\r\nMy Sparkling Version is latest \"3.28.0.3-1-2.4\" and Spark Version is 2.4.4. \r\nCode \r\n` import ai.h2o.sparkling.ml.algos.H2OXGBoost\r\n  val xgBoost = new H2OXGBoost()\r\n    .setLabelCol(\"label\")\r\n    .setFeaturesCol(\"indexedFeatures\")\r\n    .setDetailedPredictionCol(\"detailed_prediction\")\r\n    .setWithDetailedPredictionCol(true)\r\n\r\n  val xgBoostModel = xgBoost.fit(trainH2ODf)\r\n\r\n  val testPredictionsXGBoost = xgBoostModel.transform(testH2ODf)\r\n  testPredictionsXGBoost.printSchema()\r\n  testPredictionsXGBoost.select(\"detailed_prediction.contributions\").show()\r\n`\r\n\r\nReceived Error\r\n`*** H2O Configuration and Context\r\n20/02/12 08:57:25 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 0 (Infinitive) as we need to ensure we run on the nodes with H2O\r\n*** H2O Train and Test Frames\r\n*** Perform H2O XGBoost\r\n20/02/12 08:57:27 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 0 (Infinitive) as we need to ensure we run on the nodes with H2O\r\n20/02/12 08:57:36 WARN H2OConf: The method 'externalWriteConfirmationTimeout' is deprecated.\r\nroot\r\n |-- label: string (nullable = false)\r\n |-- indexedFeatures: vector (nullable = true)\r\n |-- detailed_prediction: struct (nullable = true)\r\n |    |-- label: string (nullable = true)\r\n |    |-- p0: double (nullable = false)\r\n |    |-- p1: double (nullable = false)\r\n |    |-- contributions: array (nullable = true)\r\n |    |    |-- element: float (containsNull = false)\r\n |-- prediction: string (nullable = true)\r\n\r\n20/02/12 08:57:51 ERROR Executor: Exception in task 23.0 in stage 295.0 (TID 19159)\r\norg.apache.spark.SparkException: Failed to execute user defined function($anonfun$getBinomialPredictionUDF$3: (struct<indexedFeatures:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>>, double) => struct<label:string,p0:double,p1:double,contributions:array<float>>)\r\n        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\r\n        at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n        at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\r\n        at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\r\n        at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\r\n        at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\r\n        at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\r\n        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n        at org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n        at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException: -1\r\n        at hex.genmodel.algos.tree.TreeSHAP.treeShap(TreeSHAP.java:136)\r\n        at hex.genmodel.algos.tree.TreeSHAP.treeShap(TreeSHAP.java:181)\r\n        at hex.genmodel.algos.tree.TreeSHAP.treeShap(TreeSHAP.java:181)\r\n        at hex.genmodel.algos.tree.TreeSHAP.treeShap(TreeSHAP.java:181)\r\n        at hex.genmodel.algos.tree.TreeSHAP.treeShap(TreeSHAP.java:181)\r\n        at hex.genmodel.algos.tree.TreeSHAP.treeShap(TreeSHAP.java:177)\r\n        at hex.genmodel.algos.tree.TreeSHAP.calculateContributions(TreeSHAP.java:237)\r\n        at hex.genmodel.algos.tree.TreeSHAPEnsemble.calculateContributions(TreeSHAPEnsemble.java:29)\r\n        at hex.genmodel.algos.xgboost.XGBoostJavaMojoModel$XGBoostContributionsPredictor.calculateContributions(XGBoostJavaMojoModel.java:187)\r\n        at hex.genmodel.easy.EasyPredictModelWrapper.predictBinomial(EasyPredictModelWrapper.java:580)\r\n        at ai.h2o.sparkling.ml.models.H2OMOJOPredictionBinomial$$anonfun$getBinomialPredictionUDF$3.apply(H2OMOJOPredictionBinomial.scala:54)\r\n        at ai.h2o.sparkling.ml.models.H2OMOJOPredictionBinomial$$anonfun$getBinomialPredictionUDF$3.apply(H2OMOJOPredictionBinomial.scala:52)\r\n        ... 21 more\r\n`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1809", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1809/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1809/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1809/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1809", "id": 562502730, "node_id": "MDU6SXNzdWU1NjI1MDI3MzA=", "number": 1809, "title": "Quantile Regression", "user": {"login": "alexHeu", "id": 8157458, "node_id": "MDQ6VXNlcjgxNTc0NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/8157458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexHeu", "html_url": "https://github.com/alexHeu", "followers_url": "https://api.github.com/users/alexHeu/followers", "following_url": "https://api.github.com/users/alexHeu/following{/other_user}", "gists_url": "https://api.github.com/users/alexHeu/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexHeu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexHeu/subscriptions", "organizations_url": "https://api.github.com/users/alexHeu/orgs", "repos_url": "https://api.github.com/users/alexHeu/repos", "events_url": "https://api.github.com/users/alexHeu/events{/privacy}", "received_events_url": "https://api.github.com/users/alexHeu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-10T11:35:33Z", "updated_at": "2020-02-10T22:38:31Z", "closed_at": "2020-02-10T22:38:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nis it possible to perform Quantile Regression with H2OGBM? I'm seeing the distribution parameter but no way to set quantile_alpha.\r\n\r\nThanks in advance,\r\nAlex", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1768", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1768/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1768/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1768/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1768", "id": 559242070, "node_id": "MDU6SXNzdWU1NTkyNDIwNzA=", "number": 1768, "title": "java.lang.RuntimeException: Cloud size 1 under 2 Error : java.lang.RuntimeException: Cloud size 1 under 2", "user": {"login": "snallam12", "id": 60621164, "node_id": "MDQ6VXNlcjYwNjIxMTY0", "avatar_url": "https://avatars2.githubusercontent.com/u/60621164?v=4", "gravatar_id": "", "url": "https://api.github.com/users/snallam12", "html_url": "https://github.com/snallam12", "followers_url": "https://api.github.com/users/snallam12/followers", "following_url": "https://api.github.com/users/snallam12/following{/other_user}", "gists_url": "https://api.github.com/users/snallam12/gists{/gist_id}", "starred_url": "https://api.github.com/users/snallam12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/snallam12/subscriptions", "organizations_url": "https://api.github.com/users/snallam12/orgs", "repos_url": "https://api.github.com/users/snallam12/repos", "events_url": "https://api.github.com/users/snallam12/events{/privacy}", "received_events_url": "https://api.github.com/users/snallam12/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-02-03T18:01:23Z", "updated_at": "2020-02-06T07:11:38Z", "closed_at": "2020-02-06T07:11:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "Below are the version of h2o/sparkling water we are using\r\n**install.packages(\"sparklyr\")\r\nlibrary(sparklyr)\r\ninstall.packages(\"h2o\", type = \"source\", repos = \"https://h2o-release.s3.amazonaws.com/h2o/rel-yu/1/R\")\r\ninstall.packages(\"rsparkling\", type = \"source\", repos = \"http://h2o-release.s3.amazonaws.com/sparkling-water/spark-2.4/3.28.0.1-1-2.4/R\")**\r\n\r\nUsing spark 2.4.4\r\n\r\nWe had issues with as_h2o_frame function saying it doesn't exist in a different version so we started using the above. It resolved the issue but we now have a new one. When we try to run our scripts on databricks clusters we see the error when we run as_h2o_frame function again:\r\n\r\n**java.lang.RuntimeException: Cloud size 1 under 2 Error : java.lang.RuntimeException: Cloud size 1 under 2\r\n\tat water.H2O.waitForCloudSize(H2O.java:1860)**\r\n\r\n\r\nThis issue is not consistent and scripts sometimes works well but mostly throw this error. \r\n\r\n[](url)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1767", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1767/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1767/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1767/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1767", "id": 558895057, "node_id": "MDU6SXNzdWU1NTg4OTUwNTc=", "number": 1767, "title": "Reopening Issue: Not able to start external backend on YARN : java.io.IOException: Cannot run program \"hadoop\": error=2, No such file or directory #1759", "user": {"login": "BhushG", "id": 26724287, "node_id": "MDQ6VXNlcjI2NzI0Mjg3", "avatar_url": "https://avatars1.githubusercontent.com/u/26724287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BhushG", "html_url": "https://github.com/BhushG", "followers_url": "https://api.github.com/users/BhushG/followers", "following_url": "https://api.github.com/users/BhushG/following{/other_user}", "gists_url": "https://api.github.com/users/BhushG/gists{/gist_id}", "starred_url": "https://api.github.com/users/BhushG/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BhushG/subscriptions", "organizations_url": "https://api.github.com/users/BhushG/orgs", "repos_url": "https://api.github.com/users/BhushG/repos", "events_url": "https://api.github.com/users/BhushG/events{/privacy}", "received_events_url": "https://api.github.com/users/BhushG/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-02-03T07:30:26Z", "updated_at": "2020-02-03T08:42:32Z", "closed_at": "2020-02-03T08:42:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Reopening the issue. It is not resolved yet: https://github.com/h2oai/sparkling-water/issues/1759\r\n\r\nHadoop is already in PATH. That's why I can execute hadoop commands from anywhere. I don't need to specify full path to hadoop. But when I'm executing a spark job to execute command such as \"hadoop fs -ls /\" then it is not able to find hadoop. In this case, running command through a spark job, I've to specify full path eg. \"/home/bhushan/usr/local/hadoop/bin/hadoop dfs -ls /\", only then it is able to execute that command.\r\n\r\nEven though Hadoop is in PATH. Spark job is not able to detect it.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1763", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1763/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1763/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1763/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1763", "id": 558763928, "node_id": "MDU6SXNzdWU1NTg3NjM5Mjg=", "number": 1763, "title": "H2o context not created in 3.28.0.1 build with spark 2.4.0-cdh6.2.1", "user": {"login": "ananbas", "id": 47935033, "node_id": "MDQ6VXNlcjQ3OTM1MDMz", "avatar_url": "https://avatars1.githubusercontent.com/u/47935033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananbas", "html_url": "https://github.com/ananbas", "followers_url": "https://api.github.com/users/ananbas/followers", "following_url": "https://api.github.com/users/ananbas/following{/other_user}", "gists_url": "https://api.github.com/users/ananbas/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananbas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananbas/subscriptions", "organizations_url": "https://api.github.com/users/ananbas/orgs", "repos_url": "https://api.github.com/users/ananbas/repos", "events_url": "https://api.github.com/users/ananbas/events{/privacy}", "received_events_url": "https://api.github.com/users/ananbas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-02-02T21:50:22Z", "updated_at": "2020-02-06T07:12:26Z", "closed_at": "2020-02-06T07:12:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Issue: H2o cluster formed but h2ocontext is not created in sparkling-shell\r\n\r\n```  \r\nH2O build version         : 3.28.0.1 (yu)\r\nSparkling Water version   : 3.28.0.1-1-2.4.0-cdh6.2\r\nSpark build version       : 2.4.0-cdh6.2.1\r\nScala version             : 2.11\r\nHadoop                    : CDH6.2.1 Hadoop3\r\nExecution mode            : yarn client\r\nOS                        : centos7\r\n```\r\nSpark & Sparkling Water configuration including the memory configuration:\r\n```\r\nspark.blacklist.enabled=false\r\nspark.ext.h2o.cluster.size=10\r\nspark.executor.instances=10\r\nspark.ext.h2o.node.network.mask=10.30.225.0/24\r\nspark.ext.h2o.client.network.mask=10.30.225.0/24\r\nspark.port.maxRetries=50\r\nspark.task.maxFailures=1\r\nspark.scheduler.maxRegisteredResourcesWaitingTime=1000000\r\nspark.sql.autoBroadcastJoinThreshold=-1\r\nspark.locality.wait=0\r\nspark.scheduler.minRegisteredResourcesRatio=1\r\nspark.authenticate=false\r\nspark.dynamicAllocation.enabled=false\r\nspark.eventLog.enabled=true\r\nspark.io.encryption.enabled=false\r\nspark.network.crypto.enabled=false\r\nspark.serializer=org.apache.spark.serializer.KryoSerializer\r\nspark.shuffle.service.enabled=true\r\nspark.shuffle.service.port=7337\r\nspark.ui.enabled=false\r\nspark.ui.killEnabled=false\r\nspark.lineage.log.dir=/var/log/spark/lineage\r\nspark.lineage.enabled=true\r\nspark.default.parallelism=100\r\nspark.driver.memory=2g\r\nspark.driver.memoryOverhead=4g\r\nspark.executor.cores=4\r\nspark.executor.extraJavaOptions=-XX:ParallelGCThreads=4 -XX:+UseParallelGC\r\nspark.executor.memory=30g\r\nspark.executor.memoryOverhead=30g\r\nspark.file.transferTo=false\r\nspark.files.maxPartitionBytes=268435456\r\nspark.network.timeout=600s\r\nspark.rdd.compress=true\r\nspark.rpc.io.serverTreads=64\r\nspark.shuffle.file.buffer=1m\r\nspark.shuffle.io.backLog=8192\r\nspark.shuffle.io.maxRetries=5\r\nspark.shuffle.io.serverThreads=128\r\nspark.shuffle.registration.maxAttempst=5\r\nspark.shuffle.registration.timeout=120000\r\nspark.shuffle.unsafe.file.ouput.buffer=5m\r\nspark.sql.adaptive.enabled=true\r\nspark.sql.parquet.compression.codec=snappy\r\nspark.sql.shuffle.partitions=100\r\nspark.security.credentials.hbase.enabled=false\r\nspark.master=yarn\r\nspark.submit.deployMode=client\r\n```\r\n\r\nCode:\r\n```\r\nsc.setLogLevel(\"INFO\")\r\nimport org.apache.spark.h2o._\r\nval h2oContext = H2OContext.getOrCreate(spark)\r\n```\r\n\r\nError:\r\n```\r\njava.util.NoSuchElementException: None.get\r\n  at scala.None$.get(Option.scala:347)\r\n  at scala.None$.get(Option.scala:345)\r\n  at org.apache.spark.h2o.SparkSpecificUtils$.addSparklingWaterTab(SparkSpecificUtils.scala:43)\r\n  at org.apache.spark.h2o.H2OContext.init(H2OContext.scala:160)\r\n  at org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:606)\r\n  at org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:634)\r\n  ... 51 elided\r\n```\r\n[yarn.log](https://github.com/h2oai/sparkling-water/files/4145445/yarn.log)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1759", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1759/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1759/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1759/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1759", "id": 558155370, "node_id": "MDU6SXNzdWU1NTgxNTUzNzA=", "number": 1759, "title": "Not able to start external backend on YARN : java.io.IOException: Cannot run program \"hadoop\": error=2, No such file or directory", "user": {"login": "BhushG", "id": 26724287, "node_id": "MDQ6VXNlcjI2NzI0Mjg3", "avatar_url": "https://avatars1.githubusercontent.com/u/26724287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BhushG", "html_url": "https://github.com/BhushG", "followers_url": "https://api.github.com/users/BhushG/followers", "following_url": "https://api.github.com/users/BhushG/following{/other_user}", "gists_url": "https://api.github.com/users/BhushG/gists{/gist_id}", "starred_url": "https://api.github.com/users/BhushG/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BhushG/subscriptions", "organizations_url": "https://api.github.com/users/BhushG/orgs", "repos_url": "https://api.github.com/users/BhushG/repos", "events_url": "https://api.github.com/users/BhushG/events{/privacy}", "received_events_url": "https://api.github.com/users/BhushG/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 18, "created_at": "2020-01-31T14:12:16Z", "updated_at": "2020-02-03T18:50:09Z", "closed_at": "2020-02-02T19:08:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Here are the logs\r\n\r\n```\r\n20/01/31 14:06:10 WARN external.ExternalH2OBackend: Increasing 'spark.locality.wait' to value 30000\r\n20/01/31 14:06:10 INFO h2o.H2OContext$H2OContextClientBased: Sparkling Water version: 3.28.0.1-1-2.4\r\n20/01/31 14:06:10 INFO h2o.H2OContext$H2OContextClientBased: Spark version: 2.4.4\r\n20/01/31 14:06:10 INFO h2o.H2OContext$H2OContextClientBased: Integrated H2O version: 3.28.0.1\r\n20/01/31 14:06:10 INFO h2o.H2OContext$H2OContextClientBased: The following Spark configuration is used: \r\n    (spark.ext.h2o.external.cluster.size,2)\r\n    (spark.driver.host,project-master)\r\n    (spark.sql.shuffle.partitions,4)\r\n    (spark.submit.deployMode,cluster)\r\n    (spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS,project-master)\r\n    (spark.ext.h2o.external.h2o.driver,/home/project/sparkling-water-3.28.0.1-1-2.4/h2odriver-sw3.28.0-hdp2.6-extended.jar)\r\n    (spark.ext.h2o.cluster.info.name,notify_H2O_via_SparklingWater_application_1580479162776_0001)\r\n    (spark.app.name,clone3)\r\n    (spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES,http://project-master:8088/proxy/application_1580479162776_0001)\r\n    (spark.executor.id,driver)\r\n    (spark.yarn.dist.files,file:///home/project/dist-0.0.1/project-distribution/application.yml)\r\n    (spark.ext.h2o.hadoop.memory,2G)\r\n    (spark.ext.h2o.cloud.name,H2O_via_SparklingWater_application_1580479162776_0001)\r\n    (spark.yarn.app.container.log.dir,/home/project/usr/local/hadoop/logs/userlogs/application_1580479162776_0001/container_1580479162776_0001_01_000001)\r\n    (spark.master,yarn)\r\n    (spark.ui.port,0)\r\n    (spark.app.id,application_1580479162776_0001)\r\n    (spark.ext.h2o.client.log.dir,logs/H2Ologs)\r\n    (spark.driver.port,38363)\r\n    (spark.locality.wait,30000)\r\n    (spark.executorEnv.JAVA_HOME,/usr/lib/jvm/java-8-openjdk-amd64)\r\n    (spark.ext.h2o.external.start.mode,auto)\r\n    (spark.jars,)\r\n    (spark.ui.filters,org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter)\r\n    (spark.ext.h2o.external.yarn.queue,default)\r\n    (spark.ext.h2o.backend.cluster.mode,external)\r\n    (spark.yarn.app.id,application_1580479162776_0001)\r\n20/01/31 14:06:10 INFO external.ExternalH2OBackend: Starting the external H2O cluster on YARN.\r\n20/01/31 14:06:10 INFO external.ExternalH2OBackend: Command used to start H2O on yarn: hadoop jar /home/project/sparkling-water-3.28.0.1-1-2.4/h2odriver-sw3.28.0-hdp2.6-extended.jar -Dmapreduce.job.queuename=default -Dmapreduce.job.tags=H2O/Sparkling-Water,Sparkling-Water/Spark/application_1580479162776_0001 -Dai.h2o.args.config=sparkling-water-external -nodes 2 -notify notify_H2O_via_SparklingWater_application_1580479162776_0001 -jobname H2O_via_SparklingWater_application_1580479162776_0001 -mapperXmx 2G -nthreads -1 -J -log_level -J INFO -port_offset 1 -baseport 54321 -timeout 120 -disown -sw_ext_backend -J -rest_api_ping_timeout -J 60000 -J -client_disconnect_timeout -J 60000 -extramempercent 10\r\n20/01/31 14:06:10 ERROR job.projectJobDriver$: Job failed in cluster mode with clone3\r\njava.io.IOException: Cannot run program \"hadoop\": error=2, No such file or directory\r\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)\r\n\tat scala.sys.process.ProcessBuilderImpl$Simple.run(ProcessBuilderImpl.scala:69)\r\n\tat scala.sys.process.ProcessBuilderImpl$AbstractBuilder.run(ProcessBuilderImpl.scala:100)\r\n\tat scala.sys.process.ProcessBuilderImpl$AbstractBuilder$$anonfun$runBuffered$1.apply(ProcessBuilderImpl.scala:148)\r\n\tat scala.sys.process.ProcessBuilderImpl$AbstractBuilder$$anonfun$runBuffered$1.apply(ProcessBuilderImpl.scala:148)\r\n\tat scala.sys.process.ProcessLogger$$anon$1.buffer(ProcessLogger.scala:99)\r\n\tat scala.sys.process.ProcessBuilderImpl$AbstractBuilder.runBuffered(ProcessBuilderImpl.scala:148)\r\n\tat scala.sys.process.ProcessBuilderImpl$AbstractBuilder.$bang(ProcessBuilderImpl.scala:114)\r\n\tat org.apache.spark.h2o.backends.external.ExternalBackendUtils$class.launchShellCommand(ExternalBackendUtils.scala:111)\r\n\tat org.apache.spark.h2o.backends.external.ExternalH2OBackend$.launchShellCommand(ExternalH2OBackend.scala:233)\r\n\tat org.apache.spark.h2o.backends.external.ExternalH2OBackend.launchExternalH2OOnYarn(ExternalH2OBackend.scala:104)\r\n\tat org.apache.spark.h2o.backends.external.ExternalH2OBackend.init(ExternalH2OBackend.scala:46)\r\n\tat org.apache.spark.h2o.H2OContext$H2OContextClientBased.initBackend(H2OContext.scala:448)\r\n\tat org.apache.spark.h2o.H2OContext.init(H2OContext.scala:150)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:606)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1758", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1758/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1758/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1758/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1758", "id": 557715951, "node_id": "MDU6SXNzdWU1NTc3MTU5NTE=", "number": 1758, "title": "h2o loadmodel() functions removed starting 1/28/2020 Databricks", "user": {"login": "kaleb-thompson", "id": 29265285, "node_id": "MDQ6VXNlcjI5MjY1Mjg1", "avatar_url": "https://avatars1.githubusercontent.com/u/29265285?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kaleb-thompson", "html_url": "https://github.com/kaleb-thompson", "followers_url": "https://api.github.com/users/kaleb-thompson/followers", "following_url": "https://api.github.com/users/kaleb-thompson/following{/other_user}", "gists_url": "https://api.github.com/users/kaleb-thompson/gists{/gist_id}", "starred_url": "https://api.github.com/users/kaleb-thompson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kaleb-thompson/subscriptions", "organizations_url": "https://api.github.com/users/kaleb-thompson/orgs", "repos_url": "https://api.github.com/users/kaleb-thompson/repos", "events_url": "https://api.github.com/users/kaleb-thompson/events{/privacy}", "received_events_url": "https://api.github.com/users/kaleb-thompson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-30T19:56:16Z", "updated_at": "2020-01-30T20:10:56Z", "closed_at": "2020-01-30T20:08:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "%r\r\ninstall.packages(\"sparklyr\")\r\nlibrary(sparklyr)\r\n\r\n%r\r\ninstall.packages(\"h2o\", type = \"source\", repos = \"https://h2o-release.s3.amazonaws.com/h2o/rel-yu/1/R\")\r\n\r\n%r\r\ninstall.packages(\"rsparkling\", type = \"source\", repos = \"http://h2o-release.s3.amazonaws.com/sparkling-water/spark-2.4/3.28.0.1-1-2.4/R\")\r\n\r\n%r\r\nlibrary(rsparkling)\r\n\r\n%r\r\nsc <- spark_connect(method=\"databricks\", version = \"2.4.0\")\r\n\r\n%r\r\nh2o_context(sc)\r\n\r\n%r\r\n\r\nlayer1model <- file.path(\"/dbfs/mnt/hmescrng/hmemodels\")\r\nmodel1 <- file.path(layer1model,\"layer1_trained_model\")\r\ntrained_model1 <- h2o.loadModel(model1)\r\n\r\n\r\n\r\n**Error in h2o.loadModel(model1) : could not find function \"h2o.loadModel\" Error in h2o.loadModel(model1) : could not find function \"h2o.loadModel\"\r\nError in h2o.loadModel(model1) : could not find function \"h2o.loadModel\"**\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1757", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1757/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1757/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1757/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1757", "id": 557624570, "node_id": "MDU6SXNzdWU1NTc2MjQ1NzA=", "number": 1757, "title": "Possible Bug as of 1/28/2020", "user": {"login": "BrandonRCopeland", "id": 44583531, "node_id": "MDQ6VXNlcjQ0NTgzNTMx", "avatar_url": "https://avatars3.githubusercontent.com/u/44583531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BrandonRCopeland", "html_url": "https://github.com/BrandonRCopeland", "followers_url": "https://api.github.com/users/BrandonRCopeland/followers", "following_url": "https://api.github.com/users/BrandonRCopeland/following{/other_user}", "gists_url": "https://api.github.com/users/BrandonRCopeland/gists{/gist_id}", "starred_url": "https://api.github.com/users/BrandonRCopeland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BrandonRCopeland/subscriptions", "organizations_url": "https://api.github.com/users/BrandonRCopeland/orgs", "repos_url": "https://api.github.com/users/BrandonRCopeland/repos", "events_url": "https://api.github.com/users/BrandonRCopeland/events{/privacy}", "received_events_url": "https://api.github.com/users/BrandonRCopeland/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-01-30T16:54:24Z", "updated_at": "2020-01-30T20:04:47Z", "closed_at": "2020-01-30T18:35:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey folks, my code that's been in production for several months is now breaking when I call h2o_context(sc). I'm wondering if there is a new bug that go introduced somehow. Can you check this out? Again, this code is unchanged and was running successfully in production until Tuesday 1/28/20 when it started crashing at the h2o_context(sc) call. Nothing has change.  Cluster version, spark version, R version, etc. are all the same ad it was running fine before.\r\n\r\n![image](https://user-images.githubusercontent.com/44583531/73471294-fd4d7780-433d-11ea-89ae-e958b022bb9f.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1751", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1751/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1751/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1751/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1751", "id": 556210072, "node_id": "MDU6SXNzdWU1NTYyMTAwNzI=", "number": 1751, "title": "Running Sparkling Water in Kubernetes with Python", "user": {"login": "kimcie", "id": 17066059, "node_id": "MDQ6VXNlcjE3MDY2MDU5", "avatar_url": "https://avatars3.githubusercontent.com/u/17066059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kimcie", "html_url": "https://github.com/kimcie", "followers_url": "https://api.github.com/users/kimcie/followers", "following_url": "https://api.github.com/users/kimcie/following{/other_user}", "gists_url": "https://api.github.com/users/kimcie/gists{/gist_id}", "starred_url": "https://api.github.com/users/kimcie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kimcie/subscriptions", "organizations_url": "https://api.github.com/users/kimcie/orgs", "repos_url": "https://api.github.com/users/kimcie/repos", "events_url": "https://api.github.com/users/kimcie/events{/privacy}", "received_events_url": "https://api.github.com/users/kimcie/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-28T13:29:10Z", "updated_at": "2020-02-11T05:13:19Z", "closed_at": "2020-02-11T05:13:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "According to the documentation (https://github.com/h2oai/sparkling-water/blob/master/doc/src/site/sphinx/deployment/kubernetes.rst) to start sparkling water using python on top of Kubernetes one should use scala sparklng water image. This is probably a bug in a documentation. I tried to use python type image, but also without success.I wonder whether it is even possible to use python image to run sparkling water on Kubernetes. Can you provide more details in documentation, how to run sparkling water on Kubernetes using python? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1750", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1750/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1750/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1750/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1750", "id": 556036911, "node_id": "MDU6SXNzdWU1NTYwMzY5MTE=", "number": 1750, "title": "sparkling-water-3.28.0.3-1 spark 2.4.0-cdh6.2.1, container start, but cluster not formed", "user": {"login": "ananbas", "id": 47935033, "node_id": "MDQ6VXNlcjQ3OTM1MDMz", "avatar_url": "https://avatars1.githubusercontent.com/u/47935033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananbas", "html_url": "https://github.com/ananbas", "followers_url": "https://api.github.com/users/ananbas/followers", "following_url": "https://api.github.com/users/ananbas/following{/other_user}", "gists_url": "https://api.github.com/users/ananbas/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananbas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananbas/subscriptions", "organizations_url": "https://api.github.com/users/ananbas/orgs", "repos_url": "https://api.github.com/users/ananbas/repos", "events_url": "https://api.github.com/users/ananbas/events{/privacy}", "received_events_url": "https://api.github.com/users/ananbas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-01-28T07:43:59Z", "updated_at": "2020-01-30T07:59:11Z", "closed_at": "2020-01-30T07:03:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "Using `spark.ext.h2o.cluster.size=10` and `spark.executor.instances=10`, YARN successfully spawn 10 containers: but not 1 cluster with 10 nodes, but 10 clusters with 1 node each. As if each container act as a H2O cluster. H2o cluster name still the same tho.\r\n\r\n- Sparkling Water: 3.28.0.3-1 build againts spark 2.4.0-cdh6.2.1.\r\n- Hadoop Version & Distribution: CDH 6.2.1, Hadoop 3.\r\n- Execution mode: YARN-client\r\n- OS: Centos7\r\n- Spark & Sparkling Water configuration including the memory configuration\r\n\r\n```\r\nspark.blacklist.enabled=false\r\nspark.ext.h2o.cluster.size=10\r\nspark.executor.instances=10\r\nspark.ext.h2o.node.network.mask=10.30.225.0/24\r\nspark.ext.h2o.client.network.mask=10.30.225.0/24\r\nspark.port.maxRetries=50\r\nspark.task.maxFailures=1\r\nspark.scheduler.maxRegisteredResourcesWaitingTime=1000000\r\nspark.sql.autoBroadcastJoinThreshold=-1\r\nspark.locality.wait=0\r\nspark.scheduler.minRegisteredResourcesRatio=1\r\nspark.authenticate=false\r\nspark.dynamicAllocation.enabled=false\r\nspark.eventLog.enabled=true\r\nspark.io.encryption.enabled=false\r\nspark.network.crypto.enabled=false\r\nspark.serializer=org.apache.spark.serializer.KryoSerializer\r\nspark.shuffle.service.enabled=true\r\nspark.shuffle.service.port=7337\r\nspark.ui.enabled=false\r\nspark.ui.killEnabled=false\r\nspark.lineage.log.dir=/var/log/spark/lineage\r\nspark.lineage.enabled=true\r\nspark.default.parallelism=100\r\nspark.driver.memory=2g\r\nspark.driver.memoryOverhead=4g\r\nspark.executor.cores=4\r\nspark.executor.extraJavaOptions=-XX:ParallelGCThreads=4 -XX:+UseParallelGC\r\nspark.executor.memory=30g\r\nspark.executor.memoryOverhead=30g\r\nspark.file.transferTo=false\r\nspark.files.maxPartitionBytes=268435456\r\nspark.network.timeout=600s\r\nspark.rdd.compress=true\r\nspark.rpc.io.serverTreads=64\r\nspark.shuffle.file.buffer=1m\r\nspark.shuffle.io.backLog=8192\r\nspark.shuffle.io.maxRetries=5\r\nspark.shuffle.io.serverThreads=128\r\nspark.shuffle.registration.maxAttempst=5\r\nspark.shuffle.registration.timeout=120000\r\nspark.shuffle.unsafe.file.ouput.buffer=5m\r\nspark.sql.adaptive.enabled=true\r\nspark.sql.parquet.compression.codec=snappy\r\nspark.sql.shuffle.partitions=100\r\nspark.security.credentials.hbase.enabled=false\r\nspark.master=yarn\r\nspark.submit.deployMode=client\r\n```\r\n\r\nPlease also provide us with the full and minimal reproducible code:\r\n```\r\nJust start as usual in sparkling-shell:\r\nimport org.apache.spark.h2o._\r\nval h2oContext = H2OContext.getOrCreate(spark)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1742", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1742/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1742/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1742/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1742", "id": 554102968, "node_id": "MDU6SXNzdWU1NTQxMDI5Njg=", "number": 1742, "title": "String columns in spark dataframe to enum columns in h2o", "user": {"login": "alexHeu", "id": 8157458, "node_id": "MDQ6VXNlcjgxNTc0NTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/8157458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexHeu", "html_url": "https://github.com/alexHeu", "followers_url": "https://api.github.com/users/alexHeu/followers", "following_url": "https://api.github.com/users/alexHeu/following{/other_user}", "gists_url": "https://api.github.com/users/alexHeu/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexHeu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexHeu/subscriptions", "organizations_url": "https://api.github.com/users/alexHeu/orgs", "repos_url": "https://api.github.com/users/alexHeu/repos", "events_url": "https://api.github.com/users/alexHeu/events{/privacy}", "received_events_url": "https://api.github.com/users/alexHeu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-01-23T11:36:11Z", "updated_at": "2020-02-11T07:23:59Z", "closed_at": "2020-02-11T07:23:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI have a train and test pyspark dataframe and would like to convert them to h2o to be able to distributed training via pysparkling.\r\nI convert the dataframes as follows:\r\n\r\ntrain_hf = hc.as_h2o_frame(Df_Train, framename=\"train_hf\")\r\ntest_hf = hc.as_h2o_frame(Df_Test, framename=\"test_hf\")\r\n\r\nEverything works well except the string columns that are treated as strings and not enum within the h2o frames.\r\nWhat is the best way to convert the string columns to enums? Is there a way to pass the column types during the conversion from spark to h2o?\r\n\r\nThanks in advance\r\nAlex\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1739", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1739/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1739/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1739/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1739", "id": 553368445, "node_id": "MDU6SXNzdWU1NTMzNjg0NDU=", "number": 1739, "title": "java.lang.RuntimeException: Cloud size 1 under 2", "user": {"login": "BhushG", "id": 26724287, "node_id": "MDQ6VXNlcjI2NzI0Mjg3", "avatar_url": "https://avatars1.githubusercontent.com/u/26724287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BhushG", "html_url": "https://github.com/BhushG", "followers_url": "https://api.github.com/users/BhushG/followers", "following_url": "https://api.github.com/users/BhushG/following{/other_user}", "gists_url": "https://api.github.com/users/BhushG/gists{/gist_id}", "starred_url": "https://api.github.com/users/BhushG/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BhushG/subscriptions", "organizations_url": "https://api.github.com/users/BhushG/orgs", "repos_url": "https://api.github.com/users/BhushG/repos", "events_url": "https://api.github.com/users/BhushG/events{/privacy}", "received_events_url": "https://api.github.com/users/BhushG/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2020-01-22T07:52:36Z", "updated_at": "2020-02-06T07:12:45Z", "closed_at": "2020-02-06T07:12:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I'm getting this exception when I'm executing the job on the YARN cluster. There is no problem executing same job on a local machine. \r\nI've tried all of these settings: http://docs.h2o.ai/sparkling-water/2.1/latest-stable/doc/configuration/internal_backend_tuning.html , but still couldn't resolve this exception.\r\nHere are the logs:\r\n\r\n\r\n\r\n```\r\n20/01/22 07:06:53 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 2.\r\n20/01/22 07:06:53 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 18)\r\n20/01/22 07:06:53 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.\r\n20/01/22 07:06:53 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, project-master, 37245, None)\r\n20/01/22 07:06:53 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor\r\n20/01/22 07:06:53 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 2 (epoch 18)\r\n20/01/22 07:06:53 INFO yarn.YarnAllocator: Completed container container_1578919282272_0243_01_000003 on host: project-master (state: COMPLETE, exit status: 50)\r\n20/01/22 07:06:53 WARN yarn.YarnAllocator: Container from a bad node: container_1578919282272_0243_01_000003 on host: project-master. Exit status: 50. Diagnostics: Exception from container-launch.\r\nContainer id: container_1578919282272_0243_01_000003\r\nExit code: 50\r\nStack trace: ExitCodeException exitCode=50: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:582)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:479)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nContainer exited with a non-zero exit code 50\r\n.\r\n20/01/22 07:06:53 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_1578919282272_0243_01_000003 on host: project-master. Exit status: 50. Diagnostics: Exception from container-launch.\r\nContainer id: container_1578919282272_0243_01_000003\r\nExit code: 50\r\nStack trace: ExitCodeException exitCode=50: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:582)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:479)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nContainer exited with a non-zero exit code 50\r\n.\r\n20/01/22 07:06:53 ERROR cluster.YarnClusterScheduler: Lost executor 2 on project-master: Container from a bad node: container_1578919282272_0243_01_000003 on host: project-master. Exit status: 50. Diagnostics: Exception from container-launch.\r\nContainer id: container_1578919282272_0243_01_000003\r\nExit code: 50\r\nStack trace: ExitCodeException exitCode=50: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:582)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:479)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nContainer exited with a non-zero exit code 50\r\n.\r\n20/01/22 07:06:53 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.\r\n20/01/22 07:06:53 INFO storage.BlockManagerMaster: Removal of executor 2 requested\r\n20/01/22 07:06:53 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 2\r\n20/01/22 07:06:56 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (1) reached)\r\n20/01/22 07:07:52 ERROR job.projectJobDriver$: Job failed in cluster mode with IrisMemOverhead\r\njava.lang.RuntimeException: Cloud size 1 under 2\r\n\tat water.H2O.waitForCloudSize(H2O.java:1845)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$.org$apache$spark$h2o$backends$internal$InternalH2OBackend$$startH2OCluster(InternalH2OBackend.scala:92)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend.init(InternalH2OBackend.scala:64)\r\n\tat org.apache.spark.h2o.H2OContext.init(H2OContext.scala:130)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:418)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:446)\r\n\tat ai.h2o.sparkling.ml.algos.H2OAlgoCommonUtils$class.prepareDatasetForFitting(H2OAlgoCommonUtils.scala:47)\r\n\tat ai.h2o.sparkling.ml.algos.H2OAutoML.prepareDatasetForFitting(H2OAutoML.scala:42)\r\n\tat ai.h2o.sparkling.ml.algos.H2OAutoML.fit(H2OAutoML.scala:57)\r\n\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1733", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1733/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1733/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1733/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1733", "id": 548072494, "node_id": "MDU6SXNzdWU1NDgwNzI0OTQ=", "number": 1733, "title": "Sparkling water Scala 2.12 Support.", "user": {"login": "BhushG", "id": 26724287, "node_id": "MDQ6VXNlcjI2NzI0Mjg3", "avatar_url": "https://avatars1.githubusercontent.com/u/26724287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BhushG", "html_url": "https://github.com/BhushG", "followers_url": "https://api.github.com/users/BhushG/followers", "following_url": "https://api.github.com/users/BhushG/following{/other_user}", "gists_url": "https://api.github.com/users/BhushG/gists{/gist_id}", "starred_url": "https://api.github.com/users/BhushG/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BhushG/subscriptions", "organizations_url": "https://api.github.com/users/BhushG/orgs", "repos_url": "https://api.github.com/users/BhushG/repos", "events_url": "https://api.github.com/users/BhushG/events{/privacy}", "received_events_url": "https://api.github.com/users/BhushG/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-01-10T13:13:03Z", "updated_at": "2020-01-30T04:46:24Z", "closed_at": "2020-01-30T04:46:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "When will Sparkling water for Scala 2.12 and Spark 2.4 release?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1728", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1728/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1728/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1728/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1728", "id": 547413674, "node_id": "MDU6SXNzdWU1NDc0MTM2NzQ=", "number": 1728, "title": "Automatic External Backend - multiple instances", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-01-09T11:15:08Z", "updated_at": "2020-01-27T13:41:26Z", "closed_at": "2020-01-27T13:41:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have **multiple applications** where each of them is creating its own H2O Sparkling Water **External Backend in Automatic mode**.\r\nThe problem is when two applications are trying to create its own backend in nearly same time.\r\nBackend of first application is created successfully, however backend of the second application fails in its initialization phase. Is this some kind of know limitation or bug?\r\n_Running PySparkling (3.26.8-2.4) on YARN._", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1722", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1722/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1722/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1722/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1722", "id": 542448101, "node_id": "MDU6SXNzdWU1NDI0NDgxMDE=", "number": 1722, "title": "Exception in model.fit method ", "user": {"login": "BhushG", "id": 26724287, "node_id": "MDQ6VXNlcjI2NzI0Mjg3", "avatar_url": "https://avatars1.githubusercontent.com/u/26724287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BhushG", "html_url": "https://github.com/BhushG", "followers_url": "https://api.github.com/users/BhushG/followers", "following_url": "https://api.github.com/users/BhushG/following{/other_user}", "gists_url": "https://api.github.com/users/BhushG/gists{/gist_id}", "starred_url": "https://api.github.com/users/BhushG/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BhushG/subscriptions", "organizations_url": "https://api.github.com/users/BhushG/orgs", "repos_url": "https://api.github.com/users/BhushG/repos", "events_url": "https://api.github.com/users/BhushG/events{/privacy}", "received_events_url": "https://api.github.com/users/BhushG/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-26T06:19:38Z", "updated_at": "2020-01-05T10:20:04Z", "closed_at": "2020-01-05T10:20:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Exception in thread \"main\" java.lang.IllegalAccessError: tried to access class ml.dmlc.xgboost4j.java.NativeLibLoader from class hex.tree.xgboost.XGBoostExtension\r\n\tat hex.tree.xgboost.XGBoostExtension.initXgboost(XGBoostExtension.java:68)\r\n\tat hex.tree.xgboost.XGBoostExtension.isEnabled(XGBoostExtension.java:49)\r\n\tat water.ExtensionManager.isEnabled(ExtensionManager.java:189)\r\n\tat water.ExtensionManager.registerCoreExtensions(ExtensionManager.java:103)\r\n\tat water.H2O.main(H2O.java:2044)\r\n\tat water.H2OStarter.start(H2OStarter.java:22)\r\n\tat water.H2OStarter.start(H2OStarter.java:52)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$.startH2OWorkerAsClient(InternalH2OBackend.scala:118)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$.org$apache$spark$h2o$backends$internal$InternalH2OBackend$$startH2OCluster(InternalH2OBackend.scala:95)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend.init(InternalH2OBackend.scala:41)\r\n\tat org.apache.spark.h2o.H2OContext$H2OContextClientBased.initBackend(H2OContext.scala:448)\r\n\tat org.apache.spark.h2o.H2OContext.init(H2OContext.scala:150)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:606)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:634)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:641)\r\n\tat org.exadatum.xstream.driver.Utils.automl.components.H2OObj$.main(H2OObj.scala:30)\r\n\tat org.exadatum.xstream.driver.Utils.automl.components.H2OObj.main(H2OObj.scala)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1721", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1721/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1721/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1721/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1721", "id": 542014653, "node_id": "MDU6SXNzdWU1NDIwMTQ2NTM=", "number": 1721, "title": "Fails when passing a vector as an input column through new H2OAutoML.setFeaturesCol()", "user": {"login": "prarshah", "id": 52689055, "node_id": "MDQ6VXNlcjUyNjg5MDU1", "avatar_url": "https://avatars2.githubusercontent.com/u/52689055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prarshah", "html_url": "https://github.com/prarshah", "followers_url": "https://api.github.com/users/prarshah/followers", "following_url": "https://api.github.com/users/prarshah/following{/other_user}", "gists_url": "https://api.github.com/users/prarshah/gists{/gist_id}", "starred_url": "https://api.github.com/users/prarshah/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prarshah/subscriptions", "organizations_url": "https://api.github.com/users/prarshah/orgs", "repos_url": "https://api.github.com/users/prarshah/repos", "events_url": "https://api.github.com/users/prarshah/events{/privacy}", "received_events_url": "https://api.github.com/users/prarshah/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-24T06:45:58Z", "updated_at": "2019-12-24T13:51:17Z", "closed_at": "2019-12-24T13:49:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Providing us with the observed and expected behavior definitely helps. Giving us with the following information definitively helps:\r\n\r\n- Sparkling Water/PySparkling/RSparkling version - LATEST\r\n- Hadoop Version & Distribution\r\n- Execution mode local\r\n- H2O & Spark logs if not running on YARN. You can find these logs in Spark work directory\r\nException in thread \"main\" DistributedException from localhost/127.0.0.1:54321: 'Chunks have different sizes in different vectors: 1203 in vector 1 and608 in vector 7', caused by java.lang.IllegalArgumentException: Chunks have different sizes in different vectors: 1203 in vector 1 and608 in vector 7\r\n\tat water.MRTask.getResult(MRTask.java:479)\r\n\tat water.MRTask.getResult(MRTask.java:487)\r\n\tat water.MRTask.doAll(MRTask.java:391)\r\n\tat water.MRTask.doAll(MRTask.java:386)\r\n\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx$.checkNumberOfEntriesInEachChunk(InternalWriteConverterCtx.scala:177)\r\n\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx$.org$apache$spark$h2o$backends$internal$InternalWriteConverterCtx$$validateFrame(InternalWriteConverterCtx.scala:159)\r\n\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx.finalizeFrame(InternalWriteConverterCtx.scala:58)\r\n\tat org.apache.spark.h2o.converters.WriteConverterCtxUtils$ClientBasedConverter$.convert(WriteConverterCtxUtils.scala:146)\r\n\tat org.apache.spark.h2o.converters.SparkDataFrameConverter$.toH2OFrameKeyString(SparkDataFrameConverter.scala:101)\r\n\tat org.apache.spark.h2o.converters.SparkDataFrameConverter$.toH2OFrame(SparkDataFrameConverter.scala:68)\r\n\tat org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:227)\r\n\tat org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:227)\r\n\tat org.apache.spark.h2o.utils.H2OContextUtils$class.withConversionDebugPrints(H2OContextUtils.scala:78)\r\n\tat org.apache.spark.h2o.H2OContext.withConversionDebugPrints(H2OContext.scala:62)\r\n\tat org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:227)\r\n\tat org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:224)\r\n\tat ai.h2o.sparkling.ml.algos.H2OAlgoCommonUtils$class.prepareDatasetForFitting(H2OAlgoCommonUtils.scala:48)\r\n\tat ai.h2o.sparkling.ml.algos.H2OAutoML.prepareDatasetForFitting(H2OAutoML.scala:38)\r\n\tat ai.h2o.sparkling.ml.algos.H2OAutoML.fit(H2OAutoML.scala:53)\r\n\tat PocSparklingWater.iris$.main(iris.scala:98)\r\n\tat PocSparklingWater.iris.main(iris.scala)\r\nCaused by: java.lang.IllegalArgumentException: Chunks have different sizes in different vectors: 1203 in vector 1 and608 in vector 7\r\n\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx$$anon$1$$anonfun$map$1.apply(InternalWriteConverterCtx.scala:171)\r\n\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx$$anon$1$$anonfun$map$1.apply(InternalWriteConverterCtx.scala:169)\r\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\r\n\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx$$anon$1.map(InternalWriteConverterCtx.scala:169)\r\n\tat water.MRTask.compute2(MRTask.java:641)\r\n\tat water.H2O$H2OCountedCompleter.compute1(H2O.java:1458)\r\n\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx$$anon$1$Icer.compute1(InternalWriteConverterCtx$$anon$1$Icer.java)\r\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1454)\r\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\r\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\r\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\r\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\r\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\r\n19/12/24 11:55:26 INFO SparkContext: Invoking stop() from shutdown hook\r\n\r\n- Are you using Windows/Linux/MAC? MAC\r\n- Spark & Sparkling Water configuration including the memory configuration - Default\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1706", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1706/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1706/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1706/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1706", "id": 538439292, "node_id": "MDU6SXNzdWU1Mzg0MzkyOTI=", "number": 1706, "title": "H2O Connection Error: Unexpected HTTP error", "user": {"login": "ramakrv", "id": 13450415, "node_id": "MDQ6VXNlcjEzNDUwNDE1", "avatar_url": "https://avatars1.githubusercontent.com/u/13450415?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ramakrv", "html_url": "https://github.com/ramakrv", "followers_url": "https://api.github.com/users/ramakrv/followers", "following_url": "https://api.github.com/users/ramakrv/following{/other_user}", "gists_url": "https://api.github.com/users/ramakrv/gists{/gist_id}", "starred_url": "https://api.github.com/users/ramakrv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ramakrv/subscriptions", "organizations_url": "https://api.github.com/users/ramakrv/orgs", "repos_url": "https://api.github.com/users/ramakrv/repos", "events_url": "https://api.github.com/users/ramakrv/events{/privacy}", "received_events_url": "https://api.github.com/users/ramakrv/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-12-16T14:16:07Z", "updated_at": "2020-02-03T21:46:45Z", "closed_at": "2020-02-03T21:46:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to train H2O GBM algorithm on Databricks Cluster. H2O session is created, able to load data in to h2O, split the data , but when i am trying to train the model. I got the below error repeatedly\r\n\r\n**Databricks specs: TestingCluster, 42.00 GB | 12 Cores | DBR 6.2 | Spark 2.4.4 | Scala 2.11**\r\n\r\n> from pysparkling import *\r\n> from pyspark.sql import SparkSession\r\n> import h2o\r\n> spark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\n> h2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\")\r\n> hc = H2OContext.getOrCreate(spark, conf=h2oConf)\r\n\r\n> table_h2o = h2o.import_file(path = \"dbfs:///tables/Somedata.csv\", destination_frame = \"table_h2o.hex\",sep=\"\\t\")\r\n\r\n> train_df,valid_df, test_df = table_h2o.split_frame(ratios=[0.8,0.1])\r\n> \r\n> gbm = H2OGradientBoostingEstimator(ntrees = 1024, max_depth = 8,  stopping_metric = \"misclassification\", learn_rate = 0.02,                                                         \r\n>                      learn_rate_annealing = 0.995,                                               \r\n>                      sample_rate = 0.83,                                                       \r\n>                      col_sample_rate = 0.86, \r\n>                      score_tree_interval = 8, nfolds =16,seed = 123)\r\n> gbm.train(predictors, response, training_frame=train_df,validation_frame  = valid_df)\r\n> h2o.save_model(gbm, path=\"dbfs:///tables/\", force=True)\r\n\r\n**_gbm Model Build progress: |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\r\nH2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='10.139.64.5', port=54321): Max retries exceeded with url: /3/Jobs/$0300ffffffff$_ad6e0e9e06cc863fde0358b6448a48d1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85d79e2a20>: Failed to establish a new connection: [Errno 111] Connection refused'))_**\r\n\r\n\r\nAny help on this is appreciated. Thank You", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1695", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1695/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1695/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1695/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1695", "id": 537491559, "node_id": "MDU6SXNzdWU1Mzc0OTE1NTk=", "number": 1695, "title": "h2o algorithms in pyspark pipeline", "user": {"login": "adbak", "id": 15264471, "node_id": "MDQ6VXNlcjE1MjY0NDcx", "avatar_url": "https://avatars3.githubusercontent.com/u/15264471?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adbak", "html_url": "https://github.com/adbak", "followers_url": "https://api.github.com/users/adbak/followers", "following_url": "https://api.github.com/users/adbak/following{/other_user}", "gists_url": "https://api.github.com/users/adbak/gists{/gist_id}", "starred_url": "https://api.github.com/users/adbak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adbak/subscriptions", "organizations_url": "https://api.github.com/users/adbak/orgs", "repos_url": "https://api.github.com/users/adbak/repos", "events_url": "https://api.github.com/users/adbak/events{/privacy}", "received_events_url": "https://api.github.com/users/adbak/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-12-13T11:12:58Z", "updated_at": "2020-01-26T23:10:01Z", "closed_at": "2020-01-26T23:09:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, thanks for a great repo!\r\n\r\nI have `h2o-pysparkling-2.4==3.26.10` installed and want to enrich pyspark pipeline (including StringIndexer, VectorAssembler) with algorithms from h2o. But when I type `from pysparkling.ml import` ontly few of them are available (H2OXGBoost, H2OAutoML and so on). I wanted to end the pipeline with `H2OStackedEnsembleEstimator` from h2o.estimators. Is it possible? And if not, will it ever be?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1686", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1686/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1686/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1686/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1686", "id": 535680504, "node_id": "MDU6SXNzdWU1MzU2ODA1MDQ=", "number": 1686, "title": "Convert Spark Dataframe to H2o Dataframee", "user": {"login": "hemanshupaliwa7", "id": 33899276, "node_id": "MDQ6VXNlcjMzODk5Mjc2", "avatar_url": "https://avatars0.githubusercontent.com/u/33899276?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hemanshupaliwa7", "html_url": "https://github.com/hemanshupaliwa7", "followers_url": "https://api.github.com/users/hemanshupaliwa7/followers", "following_url": "https://api.github.com/users/hemanshupaliwa7/following{/other_user}", "gists_url": "https://api.github.com/users/hemanshupaliwa7/gists{/gist_id}", "starred_url": "https://api.github.com/users/hemanshupaliwa7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hemanshupaliwa7/subscriptions", "organizations_url": "https://api.github.com/users/hemanshupaliwa7/orgs", "repos_url": "https://api.github.com/users/hemanshupaliwa7/repos", "events_url": "https://api.github.com/users/hemanshupaliwa7/events{/privacy}", "received_events_url": "https://api.github.com/users/hemanshupaliwa7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2019-12-10T11:52:49Z", "updated_at": "2020-02-07T03:11:35Z", "closed_at": "2020-02-07T02:55:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello @jakubhava and Team... Hope you are doing good!!\r\n\r\nI bring another issue of the same topic Spark DF to H2O Df in scala\r\n\r\nI am following this notebook https://docs.databricks.com/_static/notebooks/h2o-sparkling-water-scala.html\r\nAnd i get this error when I am converting spark dataframe to h2o\r\n\r\n`[error] (run-main-0) java.lang.NoSuchMethodError: jsr166y.CountedCompleter.quietlyComplete()V\r\njava.lang.NoSuchMethodError: jsr166y.CountedCompleter.quietlyComplete()V\r\n\tat jsr166y.CountedCompleter.__tryComplete(CountedCompleter.java:427)\r\n\tat jsr166y.CountedCompleter.tryComplete(CountedCompleter.java:383)\r\n\tat water.Atomic.compute2(Atomic.java:78)\r\n\tat water.Atomic.fork(Atomic.java:39)\r\n\tat water.Atomic.invoke(Atomic.java:31)\r\n\tat water.Lockable.write_lock(Lockable.java:61)\r\n\tat water.Lockable.delete_and_lock(Lockable.java:70)\r\n\tat water.Lockable.delete_and_lock(Lockable.java:67)\r\n\tat water.fvec.Frame.preparePartialFrame(Frame.java:1044)\r\n\tat water.fvec.FrameUtils$class.preparePartialFrame(FrameUtils.scala:30)\r\n\tat water.fvec.FrameUtils$.preparePartialFrame(FrameUtils.scala:72)\r\n\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx.initFrame(InternalWriteConverterCtx.scala:43)\r\n\tat org.apache.spark.h2o.converters.WriteConverterCtxUtils$.convert(WriteConverterCtxUtils.scala:85)\r\n\tat org.apache.spark.h2o.converters.SparkDataFrameConverter$.toH2OFrame(SparkDataFrameConverter.scala:81)\r\n\tat org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:215)\r\n\tat org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:215)\r\n\tat org.apache.spark.h2o.utils.H2OContextUtils$class.withConversionDebugPrints(H2OContextUtils.scala:89)\r\n\tat org.apache.spark.h2o.H2OContext.withConversionDebugPrints(H2OContext.scala:64)\r\n\tat org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:215)\r\n\tat org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:212)\r\n\tat analyticsvidya.loanprediction3.H2OMain$.delayedEndpoint$com$vodafone$aquaduct$core$analyticsvidya$loanprediction3$H2OMain$1(H2OMain.scala:34)\r\n\tat analyticsvidya.loanprediction3.H2OMain$delayedInit$body.apply(H2OMain.scala:7)\r\n\tat scala.Function0$class.apply$mcV$sp(Function0.scala:40)\r\n\tat scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)\r\n\tat scala.App$$anonfun$main$1.apply(App.scala:76)\r\n\tat scala.App$$anonfun$main$1.apply(App.scala:76)\r\n\tat scala.collection.immutable.List.foreach(List.scala:383)\r\n\tat scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35)\r\n\tat scala.App$class.main(App.scala:76)\r\n\tat analyticsvidya.loanprediction3.H2OMain$.main(H2OMain.scala:7)\r\n\tat analyticsvidya.loanprediction3.H2OMain.main(H2OMain.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n[trace] Stack trace suppress`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1666", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1666/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1666/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1666/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1666", "id": 533202852, "node_id": "MDU6SXNzdWU1MzMyMDI4NTI=", "number": 1666, "title": "ClassNotFoundException", "user": {"login": "tianangthang7", "id": 33962997, "node_id": "MDQ6VXNlcjMzOTYyOTk3", "avatar_url": "https://avatars3.githubusercontent.com/u/33962997?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tianangthang7", "html_url": "https://github.com/tianangthang7", "followers_url": "https://api.github.com/users/tianangthang7/followers", "following_url": "https://api.github.com/users/tianangthang7/following{/other_user}", "gists_url": "https://api.github.com/users/tianangthang7/gists{/gist_id}", "starred_url": "https://api.github.com/users/tianangthang7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tianangthang7/subscriptions", "organizations_url": "https://api.github.com/users/tianangthang7/orgs", "repos_url": "https://api.github.com/users/tianangthang7/repos", "events_url": "https://api.github.com/users/tianangthang7/events{/privacy}", "received_events_url": "https://api.github.com/users/tianangthang7/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-12-05T08:39:31Z", "updated_at": "2019-12-06T07:33:43Z", "closed_at": "2019-12-06T07:33:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi! I can not run an example of Sparkling water. Plz help me.\r\n\r\n/sparkling-water-3.26.10-2.4$ bash spark-submit --packages ai.h2o:sparkling-water-package_2.11:3.26.10-2.4 --class org.apache.spark.examples.h2o.CraigslistJobTitlesStreamingApp /dev/null\r\nIvy Default Cache set to: /home/d3m-risk/.ivy2/cache\r\nThe jars for the packages stored in: /home/d3m-risk/.ivy2/jars\r\n:: loading settings :: url = jar:file:/opt/spark-2.4.3/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\r\nai.h2o#sparkling-water-package_2.11 added as a dependency\r\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-4458dd0b-4890-4dea-8aca-0756b35222fa;1.0\r\n\tconfs: [default]\r\n\tfound ai.h2o#sparkling-water-package_2.11;3.26.10-2.4 in central\r\n:: resolution report :: resolve 242ms :: artifacts dl 8ms\r\n\t:: modules in use:\r\n\tai.h2o#sparkling-water-package_2.11;3.26.10-2.4 from central in [default]\r\n\t---------------------------------------------------------------------\r\n\t|                  |            modules            ||   artifacts   |\r\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\r\n\t---------------------------------------------------------------------\r\n\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\r\n\t---------------------------------------------------------------------\r\n:: retrieving :: org.apache.spark#spark-submit-parent-4458dd0b-4890-4dea-8aca-0756b35222fa\r\n\tconfs: [default]\r\n\t0 artifacts copied, 1 already retrieved (0kB/6ms)\r\n19/12/05 15:23:53 WARN Utils: Your hostname, d3m-ws resolves to a loopback address: 127.0.1.1; using 103.245.252.14 instead (on interface eno1)\r\n19/12/05 15:23:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\r\n19/12/05 15:23:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n19/12/05 15:23:54 WARN SparkSubmit$$anon$2: Failed to load org.apache.spark.examples.h2o.CraigslistJobTitlesStreamingApp.\r\njava.lang.ClassNotFoundException: org.apache.spark.examples.h2o.CraigslistJobTitlesStreamingApp\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat java.lang.Class.forName0(Native Method)\r\n\tat java.lang.Class.forName(Class.java:348)\r\n\tat org.apache.spark.util.Utils$.classForName(Utils.scala:238)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:810)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19/12/05 15:23:54 INFO ShutdownHookManager: Shutdown hook called\r\n19/12/05 15:23:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-3b8ea4ef-6f4b-474e-8241-524ee7ed4a72\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1617", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1617/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1617/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1617/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1617", "id": 523056546, "node_id": "MDU6SXNzdWU1MjMwNTY1NDY=", "number": 1617, "title": "External Backend - Auto mode - version mismatch", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-11-14T19:25:02Z", "updated_at": "2019-11-18T13:29:46Z", "closed_at": "2019-11-18T13:29:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nIn **Sparkling Water** I'm trying to use **Auto mode** within **External Backend** on **YARN**.\r\nTo obtain **extended H2O driver** I've used **get-extended-h2o.sh** script with value **cdh5.13** as a parameter.\r\n\r\nAfterwards I'm getting following error:\r\n`The external H2O cluster ... is of version 3.24.0.2 but Sparkling Water is using version of H2O 3.26.0.8. Please make sure to use the corresponding extended H2O JAR.`\r\n\r\nI've tried to download extended H2O driver manually from URL: \r\n`https://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.4/10/extended/h2odriver-3.24.0.2-cdh5.13-extended.jar` by modifying version number from 3.24.0.2 to 3.24.0.8, but it looks, that this particular file of extended driver is not available.\r\n\r\nWill there be newer release of extended drivers for cdh5.13 or how should I proceed?\r\nThank you,\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1615", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1615/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1615/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1615/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1615", "id": 522266821, "node_id": "MDU6SXNzdWU1MjIyNjY4MjE=", "number": 1615, "title": "Sparkling Water AutoML validation frame and leaderboard frame", "user": {"login": "novan-p-simanjuntak", "id": 6336741, "node_id": "MDQ6VXNlcjYzMzY3NDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/6336741?v=4", "gravatar_id": "", "url": "https://api.github.com/users/novan-p-simanjuntak", "html_url": "https://github.com/novan-p-simanjuntak", "followers_url": "https://api.github.com/users/novan-p-simanjuntak/followers", "following_url": "https://api.github.com/users/novan-p-simanjuntak/following{/other_user}", "gists_url": "https://api.github.com/users/novan-p-simanjuntak/gists{/gist_id}", "starred_url": "https://api.github.com/users/novan-p-simanjuntak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/novan-p-simanjuntak/subscriptions", "organizations_url": "https://api.github.com/users/novan-p-simanjuntak/orgs", "repos_url": "https://api.github.com/users/novan-p-simanjuntak/repos", "events_url": "https://api.github.com/users/novan-p-simanjuntak/events{/privacy}", "received_events_url": "https://api.github.com/users/novan-p-simanjuntak/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-13T14:42:43Z", "updated_at": "2020-01-26T23:03:32Z", "closed_at": "2020-01-26T23:03:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I am new to H2O.\r\nIn h2o-3 AutoML [docs](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html), I can set validation and leaderboard frame.\r\nCan I do it in Sparkling water AutoML?\r\nI can not find it in the [documentation](http://docs.h2o.ai/sparkling-water/2.4/latest-stable/doc/tutorials/sw_automl.html).\r\n\r\nMy env is:\r\n1. Spark 2.4.4 Local mode\r\n2. sparking water 3.26.0.10\r\n\r\nThank you.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1610", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1610/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1610/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1610/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1610", "id": 521091594, "node_id": "MDU6SXNzdWU1MjEwOTE1OTQ=", "number": 1610, "title": "h2o cluster created, but H2O context hasn't been started successfully", "user": {"login": "ananbas", "id": 47935033, "node_id": "MDQ6VXNlcjQ3OTM1MDMz", "avatar_url": "https://avatars1.githubusercontent.com/u/47935033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ananbas", "html_url": "https://github.com/ananbas", "followers_url": "https://api.github.com/users/ananbas/followers", "following_url": "https://api.github.com/users/ananbas/following{/other_user}", "gists_url": "https://api.github.com/users/ananbas/gists{/gist_id}", "starred_url": "https://api.github.com/users/ananbas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ananbas/subscriptions", "organizations_url": "https://api.github.com/users/ananbas/orgs", "repos_url": "https://api.github.com/users/ananbas/repos", "events_url": "https://api.github.com/users/ananbas/events{/privacy}", "received_events_url": "https://api.github.com/users/ananbas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-11T17:29:46Z", "updated_at": "2020-02-02T22:18:46Z", "closed_at": "2020-02-02T22:18:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Cluster: CDH 5.14\r\nexecute sparkling using:\r\n```\r\nspark2-shell \\ \r\n  --packages ai.h2o:sparkling-water-package_2.11:3.26.10-2.4  \\\r\n  --conf spark.dynamicAllocation.enabled=false\r\n```\r\n\r\nOutput:\r\n```\r\nscala> val h2oContext = H2OContext.getOrCreate(spark)\r\njava.lang.ArrayIndexOutOfBoundsException: 10\r\n\tat water.UDPRebooted.checkForSuicide(UDPRebooted.java:58)\r\n\tat water.TCPReceiverThread.basic_packet_handling(TCPReceiverThread.java:292)\r\n\tat water.TCPReceiverThread$UDP_TCP_ReaderThread.run(TCPReceiverThread.java:249)\r\nonExCompletion for water.FJPacket@7e1a57da\r\njava.lang.ArrayIndexOutOfBoundsException: 10\r\n\tat water.AutoBuffer.getEnum(AutoBuffer.java:1269)\r\n\tat water.UDPClientEvent$ClientEvent$Icer.read9(UDPClientEvent$ClientEvent$Icer.java)\r\n\tat water.UDPClientEvent$ClientEvent$Icer.read(UDPClientEvent$ClientEvent$Icer.java)\r\n\tat water.Iced.read(Iced.java:69)\r\n\tat water.UDPClientEvent.call(UDPClientEvent.java:18)\r\n\tat water.FJPacket.compute2(FJPacket.java:29)\r\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1417)\r\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\r\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\r\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\r\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\r\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\r\njava.util.NoSuchElementException: None.get\r\n  at scala.None$.get(Option.scala:347)\r\n  at scala.None$.get(Option.scala:345)\r\n  at org.apache.spark.h2o.SparkSpecificUtils$.addSparklingWaterTab(SparkSpecificUtils.scala:43)\r\n  at org.apache.spark.h2o.H2OContext.init(H2OContext.scala:139)\r\n  at org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:400)\r\n  at org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:428)\r\n  ... 51 elided\r\n\r\nscala> import h2oContext._\r\n<console>:26: error: not found: value h2oContext\r\n       import h2oContext._\r\n              ^\r\n\r\nscala> val h2oContext = H2OContext.getOrCreate(spark)\r\njava.lang.IllegalArgumentException:\r\nH2O context hasn't been started successfully in the previous attempt and H2O client with previous configuration is already running.\r\nBecause of the current H2O limitation that it can't be restarted within a running JVM,\r\nplease restart your job or spark session and create new H2O context with new configuration.\")\r\n```\r\n\r\nLog attached.\r\n[h2o_10.30.225.202_54321-3-info.log](https://github.com/h2oai/sparkling-water/files/3832512/h2o_10.30.225.202_54321-3-info.log)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1593", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1593/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1593/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1593/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1593", "id": 517590456, "node_id": "MDU6SXNzdWU1MTc1OTA0NTY=", "number": 1593, "title": "Details: ERRR on field: XGBoost: XGBoost is not available on all nodes", "user": {"login": "uzair4520", "id": 57388106, "node_id": "MDQ6VXNlcjU3Mzg4MTA2", "avatar_url": "https://avatars1.githubusercontent.com/u/57388106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/uzair4520", "html_url": "https://github.com/uzair4520", "followers_url": "https://api.github.com/users/uzair4520/followers", "following_url": "https://api.github.com/users/uzair4520/following{/other_user}", "gists_url": "https://api.github.com/users/uzair4520/gists{/gist_id}", "starred_url": "https://api.github.com/users/uzair4520/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/uzair4520/subscriptions", "organizations_url": "https://api.github.com/users/uzair4520/orgs", "repos_url": "https://api.github.com/users/uzair4520/repos", "events_url": "https://api.github.com/users/uzair4520/events{/privacy}", "received_events_url": "https://api.github.com/users/uzair4520/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-11-05T07:21:18Z", "updated_at": "2020-01-26T22:56:36Z", "closed_at": "2020-01-26T22:56:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to use H2O XGBoost model with my pyspark pipeline but i am getting below mentioned exception. I have pip installed following libs for using H2O model with pyspark.\r\n\r\nLibs:\r\n h2o_pysparkling_2.4\r\nh2o\r\nsparkling\r\n\r\nException:\r\n\r\nwater.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for XGBoost model: XGBoost_model_1572937136323_1.  Details: ERRR on field: XGBoost: XGBoost is not available on all nodes!\r\n\r\n\tat water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:19)\r\n\tat hex.tree.xgboost.XGBoost.init(XGBoost.java:119)\r\n\tat hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:234)\r\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:222)\r\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1417)\r\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\r\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\r\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\r\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\r\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\r\n\r\nAny help will be highly appreciated", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1576", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1576/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1576/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1576/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1576", "id": 510570839, "node_id": "MDU6SXNzdWU1MTA1NzA4Mzk=", "number": 1576, "title": "the spark water can not connected to the H2O cluster", "user": {"login": "lmcrazy", "id": 9508140, "node_id": "MDQ6VXNlcjk1MDgxNDA=", "avatar_url": "https://avatars1.githubusercontent.com/u/9508140?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lmcrazy", "html_url": "https://github.com/lmcrazy", "followers_url": "https://api.github.com/users/lmcrazy/followers", "following_url": "https://api.github.com/users/lmcrazy/following{/other_user}", "gists_url": "https://api.github.com/users/lmcrazy/gists{/gist_id}", "starred_url": "https://api.github.com/users/lmcrazy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lmcrazy/subscriptions", "organizations_url": "https://api.github.com/users/lmcrazy/orgs", "repos_url": "https://api.github.com/users/lmcrazy/repos", "events_url": "https://api.github.com/users/lmcrazy/events{/privacy}", "received_events_url": "https://api.github.com/users/lmcrazy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-10-22T10:41:31Z", "updated_at": "2020-02-06T07:27:28Z", "closed_at": "2020-02-06T07:27:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,I want to use sparking water and H2O for data exchange.\r\nI use external model and my env is :\r\n\r\n(1)spark 2.2.0\r\n(2)sparking water 2.2\r\n(3)hadoop CDH.5.10 hadoop 2.6\r\n(4)Execution mode  `YARN-cluster`\r\n\r\nThe program is printed as follows\r\n\r\n'''Sparkling Water Context:\r\n * Sparkling Water Version: 2.2.42\r\n * H2O name: mlp\r\n * cluster size: 1\r\n * list of used nodes:\r\n  (executorId, host, port)\r\n  (0,172.16.161.114,54321)\r\n  Open H2O Flow in browser: http://172.16.7.132:54321 (CMD + click in Mac OSX)'''\r\n\r\nSometimes it works. \r\n![image](https://user-images.githubusercontent.com/9508140/67278137-f8855600-f4fa-11e9-8e5f-3ab3f94a05b9.png)\r\n\r\nSometimes it gets stuck and no output.\r\n![image](https://user-images.githubusercontent.com/9508140/67279379-70548000-f4fd-11e9-8a5d-a1a5eab7fc36.png)\r\n\r\nThank you for your help\uff01\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1535", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1535/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1535/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1535/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1535", "id": 495130609, "node_id": "MDU6SXNzdWU0OTUxMzA2MDk=", "number": 1535, "title": "pysparkling deploy", "user": {"login": "haiyuni", "id": 4526880, "node_id": "MDQ6VXNlcjQ1MjY4ODA=", "avatar_url": "https://avatars2.githubusercontent.com/u/4526880?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haiyuni", "html_url": "https://github.com/haiyuni", "followers_url": "https://api.github.com/users/haiyuni/followers", "following_url": "https://api.github.com/users/haiyuni/following{/other_user}", "gists_url": "https://api.github.com/users/haiyuni/gists{/gist_id}", "starred_url": "https://api.github.com/users/haiyuni/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haiyuni/subscriptions", "organizations_url": "https://api.github.com/users/haiyuni/orgs", "repos_url": "https://api.github.com/users/haiyuni/repos", "events_url": "https://api.github.com/users/haiyuni/events{/privacy}", "received_events_url": "https://api.github.com/users/haiyuni/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-18T10:18:20Z", "updated_at": "2020-02-03T21:45:17Z", "closed_at": "2020-02-03T21:45:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "File \"/mnt/yarn/usercache/hadoop/appcache/application_1568798387424_0005/container_1568798387424_0005_01_000001/PY3/ml_h2o/lib/python3.6/site-packages/ai/h2o/sparkling/H2OContext.py\", line 180, in getOrCreate\r\n    jhc = jvm.org.apache.spark.h2o.JavaH2OContext.getOrCreate(jspark_session, selected_conf._jconf)\r\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1568798387424_0005/container_1568798387424_0005_01_000001/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\r\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1568798387424_0005/container_1568798387424_0005_01_000001/pyspark.zip/pyspark/sql/utils.py\", line 63, in deco\r\n  File \"/mnt/yarn/usercache/hadoop/appcache/application_1568798387424_0005/container_1568798387424_0005_01_000001/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\r\npy4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.h2o.JavaH2OContext.getOrCreate.\r\n: java.lang.RuntimeException: Cloud size 6 under 7\r\n\tat water.H2O.waitForCloudSize(H2O.java:1819)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$.org$apache$spark$h2o$backends$internal$InternalH2OBackend$$startH2OCluster(InternalH2OBackend.scala:102)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend.init(InternalH2OBackend.scala:74)\r\n\tat org.apache.spark.h2o.H2OContext.init(H2OContext.scala:128)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:400)\r\n\tat org.apache.spark.h2o.H2OContext.getOrCreate(H2OContext.scala)\r\n\tat org.apache.spark.h2o.JavaH2OContext.getOrCreate(JavaH2OContext.java:255)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n==============================================\r\nuser pysparkling-3.26.5-2.3  aws emr  c5.4xlarge \r\nsubmit code:\r\n--conf spark.serializer=org.apache.spark.serializer.KryoSerializer \\\r\n--archives s3://spark-ml-train-new/xiaomi_dsp/code/ml_h2o.zip#PY3 \\\r\n--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./PY3/ml_h2o/bin/python3 \\\r\n--conf spark.executorEnv.PYSPARK_PYTHON=./PY3/ml_h2o/bin/python3 \\\r\n--conf spark.ext.h2o.fail.on.unsupported.spark.param=false \\\r\n--conf spark.dynamicAllocation.enabled=false \\", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1491", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1491/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1491/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1491/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1491", "id": 486938527, "node_id": "MDU6SXNzdWU0ODY5Mzg1Mjc=", "number": 1491, "title": "[SW v.3.26.2-2.4] unable to start a cluster", "user": {"login": "MrHadgehog", "id": 16343748, "node_id": "MDQ6VXNlcjE2MzQzNzQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/16343748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MrHadgehog", "html_url": "https://github.com/MrHadgehog", "followers_url": "https://api.github.com/users/MrHadgehog/followers", "following_url": "https://api.github.com/users/MrHadgehog/following{/other_user}", "gists_url": "https://api.github.com/users/MrHadgehog/gists{/gist_id}", "starred_url": "https://api.github.com/users/MrHadgehog/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MrHadgehog/subscriptions", "organizations_url": "https://api.github.com/users/MrHadgehog/orgs", "repos_url": "https://api.github.com/users/MrHadgehog/repos", "events_url": "https://api.github.com/users/MrHadgehog/events{/privacy}", "received_events_url": "https://api.github.com/users/MrHadgehog/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-08-29T12:50:18Z", "updated_at": "2020-02-13T01:20:39Z", "closed_at": "2020-02-11T01:02:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've tried to start sparkling water inside of existing spark session but recevied the error `java.lang.NoClassDefFoundError: scala/tools/nsc/interpreter/InteractiveReader`\r\n`Caused by: java.lang.ClassNotFoundException: scala.tools.nsc.interpreter.InteractiveReader`\r\n\r\n\r\n- Sparkling Water: 3.26.2-2.4 (using via sbt)\r\n- Hadoop Version & Distribution: 2.7.1 with winutils\r\n- Scala version 2.11.12\r\n- local start mode\r\n- Win 10 x64\r\n\r\n**spark config**\r\nspark option spark.driver.maxResultSize = 1g\r\nspark option spark.executor.memory = 4g\r\nspark option spark.executor.extraJavaOptions = -Xsm4g\r\nspark option spark.driver.memory = 4g\r\nspark option driver-java-options = -Xsm4g\r\n\r\n**scala compiler server options**\r\nJVM options: `-server -Xms6g -Xmx8g -Xss8g`\r\nJVM maximum heap size: 8192MB\r\n\r\n**Programm config**\r\nVM options: `-Xms4g -Xmx6g -Xss4g`\r\nProgram arguments: `spark.executor.extraJavaOptions='-Xss4g' --driver-java-options '-Xss4g'`\r\nJRE: Java 8 sdk (1.8.0_211) (Oracle)\r\n\r\n**Minimal code**\r\n`import org.apache.spark.h2o._`\r\n`val h2oContext = H2OContext.getOrCreate(Test.context)`\r\n`import h2oContext._`\r\n\r\n[local-1567080201198.zip](https://github.com/h2oai/sparkling-water/files/3555569/local-1567080201198.zip)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1490", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1490/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1490/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1490/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1490", "id": 486883103, "node_id": "MDU6SXNzdWU0ODY4ODMxMDM=", "number": 1490, "title": "h2o-pysparkling-2.4 | Error when initializing a H2oContext", "user": {"login": "Rize1391", "id": 20426123, "node_id": "MDQ6VXNlcjIwNDI2MTIz", "avatar_url": "https://avatars3.githubusercontent.com/u/20426123?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rize1391", "html_url": "https://github.com/Rize1391", "followers_url": "https://api.github.com/users/Rize1391/followers", "following_url": "https://api.github.com/users/Rize1391/following{/other_user}", "gists_url": "https://api.github.com/users/Rize1391/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rize1391/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rize1391/subscriptions", "organizations_url": "https://api.github.com/users/Rize1391/orgs", "repos_url": "https://api.github.com/users/Rize1391/repos", "events_url": "https://api.github.com/users/Rize1391/events{/privacy}", "received_events_url": "https://api.github.com/users/Rize1391/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2019-08-29T10:46:27Z", "updated_at": "2020-01-26T22:58:41Z", "closed_at": "2020-01-26T22:58:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello Team,\r\n\r\nI am trying to run h2o-pysparkling-2.4 on a Azure Databricks environment.\r\nThe cluster config is\r\nRuntime version - 5.5 LTS or 5.3 (includes Apache Spark 2.4.3, Scala 2.11)\r\nPython version - 3\r\nStandard_D32s_v3 - 10 workers\r\nStandard_DS13_v2 - 1 Driver\r\ncolorama = 0.3.8 package installed\r\n\r\nNote: There are no other pysparkling libraries installed.\r\n\r\nand ran the below code,\r\n\r\nfrom pysparkling import *\r\nfrom pyspark.sql import SparkSession\r\nimport h2o\r\nspark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\nh2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\")\r\nhc = H2OContext.getOrCreate(spark, conf=h2oConf)\r\n\r\nUntil last night it was working fine, but as of now when I am trying to create the H2o cloud I am getting an error of either,\r\n\r\n**'NoneType' object has no attribute 'group'**\r\n\r\nor\r\n\r\n**cannot import name 'Context'**\r\n\r\nI fixed a few library settings and now facing the below error\r\n\r\n**java.lang.RuntimeException: Cloud size 1 under 5**\r\n\r\n\r\nI have tried all types of solutions but to no avail.\r\nAny help would be greatly appreciated.\r\nThanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1474", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1474/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1474/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1474/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1474", "id": 486125275, "node_id": "MDU6SXNzdWU0ODYxMjUyNzU=", "number": 1474, "title": "Classification Prediction Column (no obvious mapping of classes)", "user": {"login": "S-C-H", "id": 54514960, "node_id": "MDQ6VXNlcjU0NTE0OTYw", "avatar_url": "https://avatars1.githubusercontent.com/u/54514960?v=4", "gravatar_id": "", "url": "https://api.github.com/users/S-C-H", "html_url": "https://github.com/S-C-H", "followers_url": "https://api.github.com/users/S-C-H/followers", "following_url": "https://api.github.com/users/S-C-H/following{/other_user}", "gists_url": "https://api.github.com/users/S-C-H/gists{/gist_id}", "starred_url": "https://api.github.com/users/S-C-H/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/S-C-H/subscriptions", "organizations_url": "https://api.github.com/users/S-C-H/orgs", "repos_url": "https://api.github.com/users/S-C-H/repos", "events_url": "https://api.github.com/users/S-C-H/events{/privacy}", "received_events_url": "https://api.github.com/users/S-C-H/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-08-28T02:24:48Z", "updated_at": "2020-02-11T02:12:09Z", "closed_at": "2020-02-11T02:10:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "The Prediction Column for the Classification algorithm returns the probabilities for each of the classes. How can I determine which class the numbers (which go upwards from 0) belong to? Do I need to map each to a 0 to n classes index? And is their a guarantee that this will be the correct index in the prediction array given these will need to be passed as a string to be recognized as a classification problem?\r\n\r\n```\r\nautomlEstimator =H2OAutoML(featuresCols=train_cols, labelCol=\"label\", maxModels=1, keepCrossValidationModels=False, splitRatio=0.9)\r\nmodel = automlEstimator.fit(train_out)\r\npredictions = model.transform(test_out)\r\n```\r\n![image](https://user-images.githubusercontent.com/54514960/63819733-8aa92c00-c99a-11e9-82af-df31c9410982.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1456", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1456/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1456/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1456/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1456", "id": 483244076, "node_id": "MDU6SXNzdWU0ODMyNDQwNzY=", "number": 1456, "title": "I can't understand that Create Spark context which will drive computation", "user": {"login": "JonLeeCSDN", "id": 40761785, "node_id": "MDQ6VXNlcjQwNzYxNzg1", "avatar_url": "https://avatars1.githubusercontent.com/u/40761785?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JonLeeCSDN", "html_url": "https://github.com/JonLeeCSDN", "followers_url": "https://api.github.com/users/JonLeeCSDN/followers", "following_url": "https://api.github.com/users/JonLeeCSDN/following{/other_user}", "gists_url": "https://api.github.com/users/JonLeeCSDN/gists{/gist_id}", "starred_url": "https://api.github.com/users/JonLeeCSDN/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JonLeeCSDN/subscriptions", "organizations_url": "https://api.github.com/users/JonLeeCSDN/orgs", "repos_url": "https://api.github.com/users/JonLeeCSDN/repos", "events_url": "https://api.github.com/users/JonLeeCSDN/events{/privacy}", "received_events_url": "https://api.github.com/users/JonLeeCSDN/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-21T07:22:58Z", "updated_at": "2019-08-28T21:37:11Z", "closed_at": "2019-08-28T21:37:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "I did the exercises based on the examples on this website(https://github.com/h2oai/sparkling-water/blob/master/examples/src/main/scala/org/apache/spark/examples/h2o/DeepLearningDemo.scala).\r\nmaven:\r\n`    <dependency>\r\n        <groupId>ai.h2o</groupId>\r\n        <artifactId>sparkling-water-examples_2.11</artifactId>\r\n        <version>3.26.2-2.4</version>\r\n    </dependency>`\r\nhowever,in our code configure will compilation error,i am codeing by IntelliJ IDEA 2019.1\r\ni dont understand mean of this conf.\r\n`// Create Spark context which will drive computation\r\n    val conf = configure(\"Sparkling Water: Prostate demo\")\r\n    val sc = new SparkContext(conf)`\r\nrunning result\uff1a\r\nError:(14, 16) not found: value configure\r\n    val conf = configure(\"Sparkling Water: Prostate demo\")", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1453", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1453/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1453/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1453/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1453", "id": 482846812, "node_id": "MDU6SXNzdWU0ODI4NDY4MTI=", "number": 1453, "title": "Connecting to H2O External Cluster from Jupyter/Spark Standalone failing", "user": {"login": "ramkrishnan8994", "id": 40425959, "node_id": "MDQ6VXNlcjQwNDI1OTU5", "avatar_url": "https://avatars2.githubusercontent.com/u/40425959?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ramkrishnan8994", "html_url": "https://github.com/ramkrishnan8994", "followers_url": "https://api.github.com/users/ramkrishnan8994/followers", "following_url": "https://api.github.com/users/ramkrishnan8994/following{/other_user}", "gists_url": "https://api.github.com/users/ramkrishnan8994/gists{/gist_id}", "starred_url": "https://api.github.com/users/ramkrishnan8994/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ramkrishnan8994/subscriptions", "organizations_url": "https://api.github.com/users/ramkrishnan8994/orgs", "repos_url": "https://api.github.com/users/ramkrishnan8994/repos", "events_url": "https://api.github.com/users/ramkrishnan8994/events{/privacy}", "received_events_url": "https://api.github.com/users/ramkrishnan8994/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2019-08-20T13:00:56Z", "updated_at": "2020-02-06T07:14:22Z", "closed_at": "2020-02-06T07:14:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm using \"h2odriver-sw2.4.3-extended.jar\" to create an External Standalone H2O Cluster. \r\nFrom jupyter, I'm trying to connect to the Cluster. Jupyter runs on Spark Standalone Cluster.\r\n@jakubhava \r\n```\r\nfrom pysparkling import *\r\nimport pyspark\r\nfrom pyspark.sql import SparkSession\r\n\r\nspark = SparkSession.builder.appName(\"SparklingWaterExternal\").getOrCreate()\r\nconf = H2OConf(spark).set_external_cluster_mode().use_manual_cluster_start().set_h2o_cluster(\"10.xxx.xx.x\", 54321).set_cloud_name(\"h2o\").set_cluster_size(1).set_client_network_mask(\"10.xx.x.x/xx\")\r\nprint(conf)\r\nhc = H2OContext.getOrCreate(spark, conf)\r\nprint(hc)\r\n```\r\n\r\n**The whole setup is in a Kubernetes environment with Spark standalone**. The application NEVER once got connected to the external H2O cluster.\r\n\r\nThese are the issues we've faced:\r\n\r\n**H2O Logs say that a client got accepted, but Spark fails to initalize the context.**\r\n` **H2o Logs**: #P-Accept INFO: Client reconnected with a new timestamp=-1375, old client: /10.xx.x.xx:54321(timestamp=-24176, watchdog=false, cloud_name_hash=xxxxxx)`\r\n```\r\n**Spark Logs** - An error occurred while calling z:org.apache.spark.h2o.JavaH2OContext.getOrCreate.\r\n: java.lang.RuntimeException: Cloud size 0 under 2\r\n\tat water.H2O.waitForCloudSize(H2O.java:1819)\r\n\tat org.apache.spark.h2o.backends.external.ExternalH2OBackend.init(ExternalH2OBackend.scala:203)\r\n\tat org.apache.spark.h2o.H2OContext.init(H2OContext.scala:128)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:396)\r\n\tat org.apache.spark.h2o.H2OContext.getOrCreate(H2OContext.scala)\r\n\tat org.apache.spark.h2o.JavaH2OContext.getOrCreate(JavaH2OContext.java:255)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n```\r\n\r\n**H2O crashes as soon as there's a client connection made**\r\n`Error: #P-Accept FATAL: missing eom sentinel when opening new tcp channel`\r\n\r\n**Also, I get this random error**\r\n`AttributeError: 'H2OConf' object has no attribute 'set_cluster_size'`\r\n\r\nWhat are the reasons behind these errors. It's becoming a pain to set the cluster up.\r\n\r\nInternal mode works for us, but as soon as there is one or more applications submitted, the second application fails with JVM error.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1446", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1446/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1446/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1446/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1446", "id": 481472241, "node_id": "MDU6SXNzdWU0ODE0NzIyNDE=", "number": 1446, "title": "H2OContext.getOrCreate() error on CDH", "user": {"login": "GlockGao", "id": 21698504, "node_id": "MDQ6VXNlcjIxNjk4NTA0", "avatar_url": "https://avatars1.githubusercontent.com/u/21698504?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GlockGao", "html_url": "https://github.com/GlockGao", "followers_url": "https://api.github.com/users/GlockGao/followers", "following_url": "https://api.github.com/users/GlockGao/following{/other_user}", "gists_url": "https://api.github.com/users/GlockGao/gists{/gist_id}", "starred_url": "https://api.github.com/users/GlockGao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GlockGao/subscriptions", "organizations_url": "https://api.github.com/users/GlockGao/orgs", "repos_url": "https://api.github.com/users/GlockGao/repos", "events_url": "https://api.github.com/users/GlockGao/events{/privacy}", "received_events_url": "https://api.github.com/users/GlockGao/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 25, "created_at": "2019-08-16T07:01:12Z", "updated_at": "2019-08-28T07:23:42Z", "closed_at": "2019-08-28T07:23:41Z", "author_association": "NONE", "active_lock_reason": null, "body": " - When trying to start H2OContext on CDSW (Cloudera Data Science Workbench).\r\nCommand is : **spark2-submit pysparkling_test.py** \r\nI got the following error: It repeatedly print the logs.. \r\n19/08/16 06:57:32 INFO spark.SparkContext: Added JAR /home/cdsw/.local/lib/python2.7/site-packages/sparkling_water/sparkling_water_assembly.jar at spark://10.156.4.64:24583/jars/sparkling_water_assembl\r\ny.jar with timestamp 1565938652817\r\n19/08/16 06:57:32 WARN internal.InternalH2OBackend: Increasing 'spark.locality.wait' to value 0 (Infinitive) as we need to ensure we run on the nodes with H2O\r\n19/08/16 06:57:32 WARN internal.InternalBackendUtils: Unsupported options spark.dynamicAllocation.enabled detected!\r\n19/08/16 06:57:32 INFO internal.InternalH2OBackend: Starting H2O services: Sparkling Water configuration:\r\n  backend cluster mode : internal\r\n  workers              : None\r\n  cloudName            : sparkling-water-cdsw_application_1563277926760_191096\r\n  clientBasePort       : 54321\r\n  nodeBasePort         : 54321\r\n  cloudTimeout         : 60000\r\n  h2oNodeLog           : INFO\r\n  h2oClientLog         : INFO\r\n  nthreads             : -1\r\n  drddMulFactor        : 10\r\n19/08/16 06:57:33 INFO spark.SparkContext: Starting job: collect at SpreadRDDBuilder.scala:62\r\n19/08/16 06:57:33 INFO scheduler.DAGScheduler: Registering RDD 2 (distinct at SpreadRDDBuilder.scala:62)\r\n19/08/16 06:57:33 INFO scheduler.DAGScheduler: Got job 0 (collect at SpreadRDDBuilder.scala:62) with 201 output partitions\r\n19/08/16 06:57:33 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (collect at SpreadRDDBuilder.scala:62)\r\n19/08/16 06:57:33 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)\r\n19/08/16 06:57:33 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)\r\n19/08/16 06:57:33 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at distinct at SpreadRDDBuilder.scala:62), which has no missing parents\r\n19/08/16 06:57:33 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 9.3 KB, free 7.6 GB)\r\n19/08/16 06:57:33 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 7.6 GB)\r\n19/08/16 06:57:33 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.156.4.64:21432 (size: 4.9 KB, free: 7.6 GB)\r\n19/08/16 06:57:33 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039\r\n19/08/16 06:57:33 INFO scheduler.DAGScheduler: Submitting 201 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at distinct at SpreadRDDBuilder.scala:62) (first 15 tasks are for partitions Vect\r\nor(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\r\n19/08/16 06:57:33 INFO cluster.YarnScheduler: Adding task set 0.0 with 201 tasks\r\n19/08/16 06:57:34 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)\r\n19/08/16 06:57:35 INFO spark.ExecutorAllocationManager: Requesting 2 new executors because tasks are backlogged (new desired total will be 3)\r\n19/08/16 06:57:36 INFO spark.ExecutorAllocationManager: Requesting 4 new executors because tasks are backlogged (new desired total will be 7)\r\n19/08/16 06:57:37 INFO spark.ExecutorAllocationManager: Requesting 8 new executors because tasks are backlogged (new desired total will be 15)\r\n19/08/16 06:57:38 INFO spark.ExecutorAllocationManager: Requesting 16 new executors because tasks are backlogged (new desired total will be 31)\r\n19/08/16 06:57:39 INFO spark.ExecutorAllocationManager: Requesting 32 new executors because tasks are backlogged (new desired total will be 63)\r\n19/08/16 06:57:40 INFO spark.ExecutorAllocationManager: Requesting 64 new executors because tasks are backlogged (new desired total will be 127)\r\n19/08/16 06:57:40 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (100.66.128.0:58270) with ID 2\r\n19/08/16 06:57:40 INFO spark.ExecutorAllocationManager: New executor 2 has registered (new total is 1)\r\n19/08/16 06:57:40 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, aup7964s.unix.anz, executor 2, partition 0, PROCESS_LOCAL, 7743 bytes)\r\n19/08/16 06:57:40 INFO storage.BlockManagerMasterEndpoint: Registering block manager aup7964s.unix.anz:33662 with 366.3 MB RAM, BlockManagerId(2, aup7964s.unix.anz, 33662, None)\r\n19/08/16 06:57:40 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (100.66.128.0:58280) with ID 4\r\n19/08/16 06:57:40 INFO spark.ExecutorAllocationManager: New executor 4 has registered (new total is 2)\r\n19/08/16 06:57:40 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, aup7964s.unix.anz, executor 4, partition 1, PROCESS_LOCAL, 7743 bytes)\r\n19/08/16 06:57:40 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (100.66.128.0:58282) with ID 14\r\n19/08/16 06:57:40 INFO spark.ExecutorAllocationManager: New executor 14 has registered (new total is 3)\r\n\r\n- Once switch to command: **spark2-submit --master local[2] pysparkling_test.py**\r\nthe errors are below:\r\n19/08/16 06:59:53 INFO spark.SparkContext: Added JAR /home/cdsw/.local/lib/python2.7/site-packages/sparkling_water/sparkling_water_assembly.jar at spark://10.156.4.64:24583/jars/sparkling_water_assembl\r\ny.jar with timestamp 1565938793481\r\n19/08/16 06:59:53 WARN internal.InternalH2OBackend: Increasing 'spark.locality.wait' to value 0 (Infinitive) as we need to ensure we run on the nodes with H2O\r\n19/08/16 06:59:53 WARN internal.InternalBackendUtils: Unsupported options spark.dynamicAllocation.enabled detected!\r\n19/08/16 06:59:53 INFO internal.InternalH2OBackend: Starting H2O services: Sparkling Water configuration:\r\n  backend cluster mode : internal\r\n  workers              : None\r\n  cloudName            : sparkling-water-cdsw_local-1565938791492\r\n  clientBasePort       : 54321\r\n  nodeBasePort         : 54321\r\n  cloudTimeout         : 60000\r\n  h2oNodeLog           : INFO\r\n  h2oClientLog         : INFO\r\n  nthreads             : -1\r\n  drddMulFactor        : 10\r\n19/08/16 06:59:53 INFO java.NativeLibrary: Loaded library from lib/linux_64/libxgboost4j_gpu.so (/tmp/libxgboost4j_gpu392673508027643109.so)\r\nSparkling Water version: 3.26.2-2.3\r\nSpark version: 2.3.0.cloudera3\r\nIntegrated H2O version: 3.26.0.2\r\nThe following Spark configuration is used: \r\n    (spark.eventLog.enabled,true)\r\n    (spark.app.name,SparklingWaterApp)\r\n    (spark.scheduler.minRegisteredResourcesRatio,1)\r\n    (spark.ext.h2o.cloud.name,sparkling-water-cdsw_local-1565938791492)\r\n    (spark.driver.memory,14976m)\r\n    (spark.yarn.jars,local:/app/hadoop/parcels/SPARK2-2.3.0.cloudera3-1.cdh5.13.3.p0.458809/lib/spark2/jars/*)\r\n    (spark.eventLog.dir,hdfs://nameservice1/user/spark/spark2ApplicationHistory)\r\n    (spark.ui.killEnabled,true)\r\n    (spark.yarn.appMasterEnv.PYSPARK_PYTHON,/app/hadoop/parcels/Anaconda-4.3.1/bin/python)\r\n    (spark.ui.port,20049)\r\n    (spark.driver.bindAddress,100.66.128.10)\r\n    (spark.dynamicAllocation.executorIdleTimeout,60)\r\n    (spark.serializer,org.apache.spark.serializer.KryoSerializer)\r\n    (spark.ext.h2o.client.log.dir,/home/cdsw/h2ologs/local-1565938791492)\r\n    (spark.io.encryption.enabled,false)\r\n    (spark.yarn.am.extraLibraryPath,/app/hadoop/parcels/CDH-5.13.3-1.cdh5.13.3.p3486.3704/lib/hadoop/lib/native:/app/hadoop/parcels/GPLEXTRAS-5.13.3-1.cdh5.13.3.p0.2/lib/hadoop/lib/native)\r\n    (spark.authenticate,false)\r\n    (spark.sql.hive.metastore.jars,${env:HADOOP_COMMON_HOME}/../hive/lib/*:${env:HADOOP_COMMON_HOME}/client/*)\r\n    (spark.lineage.log.dir,/var/log/spark2/lineage)\r\n    (spark.app.id,local-1565938791492)\r\n    (spark.serializer.objectStreamReset,100)\r\n    (spark.locality.wait,0)\r\n    (spark.submit.deployMode,client)\r\n    (spark.sql.autoBroadcastJoinThreshold,-1)\r\n    (spark.yarn.historyServer.address,http://aup7727s.unix.anz:18089)\r\n    (spark.network.crypto.enabled,false)\r\n    (spark.dynamicAllocation,false)\r\n    (spark.lineage.enabled,false)\r\n    (spark.shuffle.service.enabled,true)\r\n    (spark.hadoop.hadoop.treat.subject.external,true)\r\n    (spark.executor.id,driver)\r\n    (spark.dynamicAllocation.schedulerBacklogTimeout,1)\r\n    (spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON,/app/hadoop/parcels/Anaconda-4.3.1/bin/python)\r\n    (spark.shuffle.service.port,7337)\r\n    (spark.sql.hive.metastore.version,1.1.0)\r\n    (spark.ext.h2o.fail.on.unsupported.spark.param,false)\r\n    (spark.yarn.rmProxy.enabled,false)\r\n    (spark.sql.warehouse.dir,/user/hive/warehouse)\r\n    (spark.ext.h2o.client.ip,10.156.4.64)\r\n    (spark.sql.catalogImplementation,hive)\r\n    (spark.rdd.compress,True)\r\n    (spark.executor.extraLibraryPath,/app/hadoop/parcels/CDH-5.13.3-1.cdh5.13.3.p3486.3704/lib/hadoop/lib/native:/app/hadoop/parcels/GPLEXTRAS-5.13.3-1.cdh5.13.3.p0.2/lib/hadoop/lib/native)\r\n    (spark.yarn.config.gatewayPath,/app/hadoop/parcels)\r\n    (spark.ui.enabled,false)\r\n    (spark.dynamicAllocation.minExecutors,0)\r\n    (spark.yarn.config.replacementPath,{{HADOOP_COMMON_HOME}}/../../..)\r\n    (spark.dynamicAllocation.enabled,true)\r\n    (spark.driver.extraLibraryPath,/app/hadoop/parcels/CDH-5.13.3-1.cdh5.13.3.p3486.3704/lib/hadoop/lib/native:/app/hadoop/parcels/GPLEXTRAS-5.13.3-1.cdh5.13.3.p0.2/lib/hadoop/lib/native)\r\n    (spark.files,file:/home/cdsw/pysparkling_test.py)\r\n    (spark.driver.blockManager.port,21432)\r\n    (spark.master,local[2])\r\n    (spark.driver.port,24583)\r\n    (spark.driver.host,10.156.4.64)\r\n\r\n----- H2O started  -----\r\nBuild git branch: rel-yau\r\nBuild git hash: 4854053b2e1773e6df02e04895709f692ebf7088\r\nBuild git describe: jenkins-3.26.0.1-71-g4854053\r\nBuild project version: 3.26.0.2\r\nBuild age: 20 days\r\nBuilt by: 'jenkins'\r\nBuilt on: '2019-07-26 23:05:58'\r\nFound H2O Core extensions: [HiveTableImporter, StackTraceCollector, Watchdog, XGBoost]\r\nProcessed H2O arguments: [-name, sparkling-water-cdsw_local-1565938791492, -port_offset, 1, -quiet, -log_level, INFO, -log_dir, /home/cdsw/h2ologs/local-1565938791492, -baseport, 54321, -ip, 10.156.4.64, -flatfile, /tmp/1565938793606-0/flatfile.txt]\r\nJava availableProcessors: 64\r\nJava heap totalMemory: 2.46 GB\r\nJava heap maxMemory: 13.00 GB\r\nJava version: Java 1.8.0_111 (from Oracle Corporation)\r\nJVM launch parameters: [-Xmx14976m]\r\nOS version: Linux 3.10.0-862.25.3.el7.x86_64 (amd64)\r\nMachine physical memory: 251.62 GB\r\nMachine locale: en_US\r\nX-h2o-cluster-id: 1565938793549\r\nUser name: 'cdsw'\r\nIPv6 stack selected: false\r\nPossible IP Address: eth0 (eth0), 100.66.128.10\r\nPossible IP Address: lo (lo), 127.0.0.1\r\nIP address not found on this machine\r\n19/08/16 06:59:54 INFO spark.SparkContext: Invoking stop() from shutdown hook\r\n19/08/16 06:59:54 INFO server.AbstractConnector: Stopped Spark@2b2add4a{HTTP/1.1,[http/1.1]}{0.0.0.0:20049}\r\n19/08/16 06:59:54 INFO ui.SparkUI: Stopped Spark web UI at http://10.156.4.64:20049\r\n19/08/16 06:59:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\r\n19/08/16 06:59:54 INFO memory.MemoryStore: MemoryStore cleared\r\n19/08/16 06:59:54 INFO storage.BlockManager: BlockManager stopped\r\n19/08/16 06:59:54 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\r\n19/08/16 06:59:54 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\r\n19/08/16 06:59:54 INFO spark.SparkContext: Successfully stopped SparkContext\r\n19/08/16 06:59:54 INFO util.ShutdownHookManager: Shutdown hook called\r\n19/08/16 06:59:54 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-ff331aa3-bb6b-474c-80a9-7b887e278c1d\r\n19/08/16 06:59:54 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-ff331aa3-bb6b-474c-80a9-7b887e278c1d/pyspark-4ad91a7c-a673-419e-afa6-d292234f630d\r\n19/08/16 06:59:54 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-83099783-3b75-4c01-a6e9-71db2cd82014\r\n\r\nProviding us with the observed and expected behavior definitely helps. Giving us with the following information definitively helps:\r\n\r\n- Sparkling Water/PySparkling/RSparkling version\r\nh2o_pysparkling_2.3\r\n\r\n- Hadoop Version & Distribution\r\nCDH\r\n\r\n- Execution mode `YARN-client`, `YARN-cluster`, standalone, local ..\r\nYARN-client\r\n\r\nPlease also provide us with the full and minimal reproducible code.\r\nfrom pysparkling import *\r\nimport h2o\r\nfrom h2o.estimators.xgboost import *\r\n\r\nspark = SparkSession \\\r\n  .builder \\\r\n  .appName('SparklingWaterApp') \\\r\n  .getOrCreate()\r\n\r\nh2oConf = H2OConf(spark)\\\r\n  .set('spark.ui.enabled', 'false')\\\r\n  .set('spark.ext.h2o.fail.on.unsupported.spark.param', 'false')\\\r\n  .set('spark.dynamicAllocation', 'false')\\\r\n  .set('spark.scheduler.minRegisteredResourcesRatio', '1')\\\r\n  .set('spark.sql.autoBroadcastJoinThreshold', '-1')\\\r\n  .set('spark.locality.wait', '0')\r\nhc = H2OContext.getOrCreate(spark, conf=h2oConf)\r\n\r\nh2o.cluster().shutdown()\r\nspark.stop()\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1445", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1445/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1445/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1445/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1445", "id": 481388711, "node_id": "MDU6SXNzdWU0ODEzODg3MTE=", "number": 1445, "title": "sparkling water external backend hangs on spark to h2o transfer", "user": {"login": "ssoftcheck", "id": 12905725, "node_id": "MDQ6VXNlcjEyOTA1NzI1", "avatar_url": "https://avatars1.githubusercontent.com/u/12905725?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ssoftcheck", "html_url": "https://github.com/ssoftcheck", "followers_url": "https://api.github.com/users/ssoftcheck/followers", "following_url": "https://api.github.com/users/ssoftcheck/following{/other_user}", "gists_url": "https://api.github.com/users/ssoftcheck/gists{/gist_id}", "starred_url": "https://api.github.com/users/ssoftcheck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ssoftcheck/subscriptions", "organizations_url": "https://api.github.com/users/ssoftcheck/orgs", "repos_url": "https://api.github.com/users/ssoftcheck/repos", "events_url": "https://api.github.com/users/ssoftcheck/events{/privacy}", "received_events_url": "https://api.github.com/users/ssoftcheck/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2019-08-16T00:11:58Z", "updated_at": "2020-02-06T07:15:34Z", "closed_at": "2020-02-06T07:15:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "When transferring spark dataframe to h2o frame on external backend, the python (or scala) interpreter hangs. The data loads into H2o though, it is visible through flow ui but describe hangs there. This problem does not occur in internal backend.\r\n\r\n```\r\nimport pysparkling\r\nimport h2o\r\n\r\nconf = pysparkling.H2OConf(spark)\r\n# external auto\r\n# conf.set_external_cluster_mode()\r\n# conf.use_auto_cluster_start()\r\n# conf.set_cluster_size(50) \r\n# conf.set_mapper_xmx('5g')\r\n# conf.set_yarn_queue('x')\r\n# external manual\r\nconf.set_external_cluster_mode()\r\nconf.use_manual_cluster_start()\r\nconf.set_h2o_cluster('xxx', 54321)\r\nconf.set_cluster_size(50)\r\nconf.set_cloud_name('h2o')\r\n\r\nhc = pysparkling.H2OContext.getOrCreate(spark, conf)\r\n\r\nadd_df = sqlContext.sql('select a,b,c ....')\r\nadd_df_hc = hc.as_h2o_frame(add_df, 'extra_cols') # HANGS HERE, data not usable from other h2o connections either, e.g. get frame hangs.\r\n```\r\nsparkling water 3.26.0\r\nspark 2.3\r\nhadoop 2.7\r\nyarn client\r\nhadoop manual external backend\r\nhadoop jar $H2O_EXTENDED_JAR -Dmapreduce.job.queuename=x -jobname h2o -nodes 50 -mapperXmx 6g\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1425", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1425/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1425/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1425/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1425", "id": 478903262, "node_id": "MDU6SXNzdWU0Nzg5MDMyNjI=", "number": 1425, "title": "h2o-pysparkling-2.4-Error when starting an `H2OContext`", "user": {"login": "Rize1391", "id": 20426123, "node_id": "MDQ6VXNlcjIwNDI2MTIz", "avatar_url": "https://avatars3.githubusercontent.com/u/20426123?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rize1391", "html_url": "https://github.com/Rize1391", "followers_url": "https://api.github.com/users/Rize1391/followers", "following_url": "https://api.github.com/users/Rize1391/following{/other_user}", "gists_url": "https://api.github.com/users/Rize1391/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rize1391/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rize1391/subscriptions", "organizations_url": "https://api.github.com/users/Rize1391/orgs", "repos_url": "https://api.github.com/users/Rize1391/repos", "events_url": "https://api.github.com/users/Rize1391/events{/privacy}", "received_events_url": "https://api.github.com/users/Rize1391/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-09T09:56:24Z", "updated_at": "2019-08-09T10:12:28Z", "closed_at": "2019-08-09T10:06:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello Team,\r\n\r\nI am trying to run h2o-pysparkling-2.4 on a Azure Databricks environment.\r\nThe cluster config is\r\nRuntime version - 5.4 ML (includes Apache Spark 2.4.3, Scala 2.11)\r\nPython version - 3\r\nStandard_DS14_v2 - 10 workers\r\nStandard_DS13_v2 - 1 Driver\r\ncolorama = 0.3.8 package installed\r\n\r\nNote: There are no other pysparkling libraries installed.\r\n\r\nand ran the below code,\r\n\r\nfrom pysparkling import *\r\nfrom pyspark.sql import SparkSession\r\nimport h2o\r\nspark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\nh2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\")\r\nhc = H2OContext.getOrCreate(spark, conf=h2oConf)\r\n\r\nEverything starts to work then I get the below error, for which there is no clear solution.\r\nAny help would be great.\r\n\r\n---------------------------------------------------------------------------\r\nPy4JJavaError                             Traceback (most recent call last)\r\n<command-3818832693841001> in <module>()\r\n      4 spark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\n      5 h2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\")\r\n----> 6 hc = H2OContext.getOrCreate(spark, conf=h2oConf)\r\n\r\n/databricks/python/lib/python3.6/site-packages/pysparkling/context.py in getOrCreate(spark, conf, verbose, pre_create_hook, h2o_connect_hook, **kwargs)\r\n    161 \r\n    162         # Create backing Java H2OContext\r\n--> 163         jhc = jvm.org.apache.spark.h2o.JavaH2OContext.getOrCreate(jspark_session, selected_conf._jconf)\r\n    164         h2o_context._jhc = jhc\r\n    165         h2o_context._conf = selected_conf\r\n\r\n/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)\r\n   1255         answer = self.gateway_client.send_command(command)\r\n   1256         return_value = get_return_value(\r\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\r\n   1258 \r\n   1259         for temp_arg in temp_args:\r\n\r\n/databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw)\r\n     61     def deco(*a, **kw):\r\n     62         try:\r\n---> 63             return f(*a, **kw)\r\n     64         except py4j.protocol.Py4JJavaError as e:\r\n     65             s = e.java_exception.toString()\r\n\r\n/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\r\n    326                 raise Py4JJavaError(\r\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\r\n--> 328                     format(target_id, \".\", name), value)\r\n    329             else:\r\n    330                 raise Py4JError(\r\n\r\nPy4JJavaError: An error occurred while calling z:org.apache.spark.h2o.JavaH2OContext.getOrCreate.\r\n: org.apache.spark.SparkException: Exception thrown in awaitResult: \r\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:355)\r\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$$anonfun$startH2OWorkers$1.apply(InternalH2OBackend.scala:159)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$$anonfun$startH2OWorkers$1.apply(InternalH2OBackend.scala:157)\r\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\r\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\r\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\r\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\r\n\tat scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$.startH2OWorkers(InternalH2OBackend.scala:157)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$.org$apache$spark$h2o$backends$internal$InternalH2OBackend$$startH2OCluster(InternalH2OBackend.scala:95)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend.init(InternalH2OBackend.scala:74)\r\n\tat org.apache.spark.h2o.H2OContext.init(H2OContext.scala:128)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:396)\r\n\tat org.apache.spark.h2o.H2OContext.getOrCreate(H2OContext.scala)\r\n\tat org.apache.spark.h2o.JavaH2OContext.getOrCreate(JavaH2OContext.java:255)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\r\n\tat py4j.Gateway.invoke(Gateway.java:295)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.util.concurrent.ExecutionException: Boxed Error\r\n\tat scala.concurrent.impl.Promise$.resolver(Promise.scala:59)\r\n\tat scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:51)\r\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)\r\n\tat scala.concurrent.Promise$class.tryFailure(Promise.scala:112)\r\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:157)\r\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:206)\r\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onSuccess$1(NettyRpcEnv.scala:215)\r\n\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$3.apply(NettyRpcEnv.scala:233)\r\n\tat org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$3.apply(NettyRpcEnv.scala:233)\r\n\tat org.apache.spark.rpc.netty.RpcOutboxMessage.onSuccess(Outbox.scala:82)\r\n\tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:194)\r\n\tat org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:120)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\r\n\t... 1 more\r\nCaused by: java.lang.IllegalAccessError: tried to access class ml.dmlc.xgboost4j.java.NativeLibLoader from class hex.tree.xgboost.XGBoostExtension\r\n\tat hex.tree.xgboost.XGBoostExtension.initXgboost(XGBoostExtension.java:68)\r\n\tat hex.tree.xgboost.XGBoostExtension.isEnabled(XGBoostExtension.java:49)\r\n\tat water.ExtensionManager.isEnabled(ExtensionManager.java:189)\r\n\tat water.ExtensionManager.registerCoreExtensions(ExtensionManager.java:103)\r\n\tat water.H2O.main(H2O.java:2003)\r\n\tat water.H2OStarter.start(H2OStarter.java:22)\r\n\tat water.H2OStarter.start(H2OStarter.java:47)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend$.startH2OWorker(InternalH2OBackend.scala:124)\r\n\tat org.apache.spark.h2o.backends.internal.H2ORpcEndpoint$$anonfun$receiveAndReply$1.applyOrElse(H2ORpcEndpoint.scala:58)\r\n\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)\r\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)\r\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\r\n\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:226)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n\r\nAppreciate the help.\r\n\r\nRegards\r\nR.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1383", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1383/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1383/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1383/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1383", "id": 473701890, "node_id": "MDU6SXNzdWU0NzM3MDE4OTA=", "number": 1383, "title": "Not able to initiate H2OContext on Windows 10, pysparkling", "user": {"login": "danielhanbitlee", "id": 33950222, "node_id": "MDQ6VXNlcjMzOTUwMjIy", "avatar_url": "https://avatars2.githubusercontent.com/u/33950222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/danielhanbitlee", "html_url": "https://github.com/danielhanbitlee", "followers_url": "https://api.github.com/users/danielhanbitlee/followers", "following_url": "https://api.github.com/users/danielhanbitlee/following{/other_user}", "gists_url": "https://api.github.com/users/danielhanbitlee/gists{/gist_id}", "starred_url": "https://api.github.com/users/danielhanbitlee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/danielhanbitlee/subscriptions", "organizations_url": "https://api.github.com/users/danielhanbitlee/orgs", "repos_url": "https://api.github.com/users/danielhanbitlee/repos", "events_url": "https://api.github.com/users/danielhanbitlee/events{/privacy}", "received_events_url": "https://api.github.com/users/danielhanbitlee/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-28T03:47:56Z", "updated_at": "2019-08-26T06:57:26Z", "closed_at": "2019-08-26T06:57:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to use pysparkling on my system and I'm getting a py4j.protocol.Py4JError.\r\n\r\nSystem I'm using:\r\n\r\n - Windows 10\r\n - Python 3.6.1\r\n - Anaconda 4.4.0\r\n - pyspark 2.4.3\r\n - h2o\r\n - h2o-pysparkling-2.4\r\n\r\nI followed instructions on [h2o website](https://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.4/10/doc/pysparkling.html#what-is-pysparkling) and downloaded and unpacked sparkling-water from [here](https://s3.amazonaws.com/h2o-release/sparkling-water/rel-2.4/13/index.html). I also set SPARK_HOME environment variable to pyspark package in my python virtual environment path. I then go to Sparkling Water project directory and run PySparkling shell using ```bin\\pysparkling```. Then I enter the following code:\r\n\r\n```python\r\nfrom pysparkling import *\r\nimport h2o\r\nhc = H2OContext.getOrCreate(spark)\r\n```\r\n\r\nAnd I get the following error:\r\n\r\n```\r\n19/07/27 18:15:18 WARN InternalH2OBackend: To avoid non-deterministic behavior of Spark broadcast-based joins,\r\nwe recommend to set `spark.sql.autoBroadcastJoinThreshold` property of SparkSession to -1.\r\nE.g. spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\r\nWe also recommend to avoid using broadcast hints in your Spark SQL code.\r\n19/07/27 18:15:18 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 0 (Infinitive) as we need to ensure we run on the nodes with H2O\r\n19/07/27 18:15:18 WARN NativeLibrary: Cannot load library from path lib/windows_32/xgboost4j_gpu.dll\r\n19/07/27 18:15:18 WARN NativeLibrary: Cannot load library from path lib/xgboost4j_gpu.dll\r\n19/07/27 18:15:18 WARN NativeLibrary: Failed to load library from both native path and jar!\r\n19/07/27 18:15:18 WARN NativeLibrary: Cannot load library from path lib/windows_32/xgboost4j_omp.dll\r\n19/07/27 18:15:18 WARN NativeLibrary: Cannot load library from path lib/xgboost4j_omp.dll\r\n19/07/27 18:15:18 WARN NativeLibrary: Failed to load library from both native path and jar!\r\n19/07/27 18:15:18 WARN NativeLibrary: Cannot load library from path lib/windows_32/xgboost4j_minimal.dll\r\n19/07/27 18:15:18 WARN NativeLibrary: Cannot load library from path lib/xgboost4j_minimal.dll\r\n19/07/27 18:15:18 WARN NativeLibrary: Failed to load library from both native path and jar!\r\nERROR:root:Exception while sending command.\r\nTraceback (most recent call last):\r\n  File \"C:\\Documents\\python-virtual-environments\\env_sparkling\\Lib\\site-packages\\pyspark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\", line 1152, in send_command\r\n    answer = smart_decode(self.stream.readline()[:-1])\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\socket.py\", line 586, in readinto\r\n    return self._sock.recv_into(b)\r\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Documents\\python-virtual-environments\\env_sparkling\\Lib\\site-packages\\pyspark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\", line 985, in send_command\r\n    response = connection.send_command(command)\r\n  File \"C:\\Documents\\python-virtual-environments\\env_sparkling\\Lib\\site-packages\\pyspark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\", line 1164, in send_command\r\n    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\r\npy4j.protocol.Py4JNetworkError: Error while receiving\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\AppData\\Local\\Temp\\spark\\work\\spark-73591629-3b87-438c-b5da-06016978b0a1\\userFiles-89ed1c65-8515-4511-b986-6328a42f692d\\h2o_pysparkling_2.4-2.4.13.zip\\pysparkling\\context.py\", line 161, in getOrCreate\r\n  File \"C:\\Documents\\python-virtual-environments\\env_sparkling\\Lib\\site-packages\\pyspark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\", line 1257, in __call__\r\n  File \"C:\\Documents\\python-virtual-environments\\env_sparkling\\lib\\site-packages\\pyspark\\sql\\utils.py\", line 63, in deco\r\n    return f(*a, **kw)\r\n  File \"C:\\Documents\\python-virtual-environments\\env_sparkling\\Lib\\site-packages\\pyspark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\", line 336, in get_return_value\r\npy4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.h2o.JavaH2OContext.getOrCreate\r\n\r\n```\r\n\r\n\r\nAny suggestions on how to resolve this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1357", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1357/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1357/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1357/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1357", "id": 470704247, "node_id": "MDU6SXNzdWU0NzA3MDQyNDc=", "number": 1357, "title": "Not able initiate H2OContext on databricks , pysparkling", "user": {"login": "bharatbargujar", "id": 14944691, "node_id": "MDQ6VXNlcjE0OTQ0Njkx", "avatar_url": "https://avatars3.githubusercontent.com/u/14944691?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bharatbargujar", "html_url": "https://github.com/bharatbargujar", "followers_url": "https://api.github.com/users/bharatbargujar/followers", "following_url": "https://api.github.com/users/bharatbargujar/following{/other_user}", "gists_url": "https://api.github.com/users/bharatbargujar/gists{/gist_id}", "starred_url": "https://api.github.com/users/bharatbargujar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bharatbargujar/subscriptions", "organizations_url": "https://api.github.com/users/bharatbargujar/orgs", "repos_url": "https://api.github.com/users/bharatbargujar/repos", "events_url": "https://api.github.com/users/bharatbargujar/events{/privacy}", "received_events_url": "https://api.github.com/users/bharatbargujar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2019-07-20T18:56:13Z", "updated_at": "2019-12-13T13:32:17Z", "closed_at": "2019-08-14T08:53:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi Team,\r\n\r\nI am trying create H2OContext in python note book on databricks cluster. Following is my environment specs:\r\n\r\nDatabricks runtime environment: 5.3\r\nSpark = 2.4\r\nPython =  3.5\r\ncolorama >= 0.3.8\r\nh2o-pysparkling-2.4\r\n\r\nI am writing following code\r\n`\r\nfrom pysparkling import *\r\n\r\nfrom pyspark.sql import SparkSession\r\n\r\nimport h2o\r\n\r\nspark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\n\r\nh2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\")\r\n\r\nhc = H2OContext.getOrCreate(spark, conf=h2oConf)`\r\n\r\nI am getting following error:\r\n\r\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 1.0 failed 4 times, most recent failure: Lost task 2.3 in stage 1.0 (TID 40, 10.139.64.7, executor 2): java.io.InvalidClassException: org.apache.spark.h2o.backends.internal.InternalBackendUtils$; local class incompatible: stream classdesc serialVersionUID = -279081412540759760, local class serialVersionUID = -4513453206774459154\r\n\r\nPy4JJavaError                             Traceback (most recent call last)\r\n<command-1276558733665018> in <module>()\r\n      4 spark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\n      5 h2oConf = H2OConf(spark).set(\"spark.ui.enabled\", \"false\")\r\n----> 6 hc = H2OContext.getOrCreate(spark, conf=h2oConf)\r\n\r\n/databricks/python/lib/python3.5/site-packages/pysparkling/context.py in getOrCreate(spark, conf, verbose, pre_create_hook, h2o_connect_hook, **kwargs)\r\n    159 \r\n    160         # Create backing Java H2OContext\r\n--> 161         jhc = jvm.org.apache.spark.h2o.JavaH2OContext.getOrCreate(jspark_session, selected_conf._jconf)\r\n    162         h2o_context._jhc = jhc\r\n    163         h2o_context._conf = selected_conf\r\n\r\n/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)\r\n   1255         answer = self.gateway_client.send_command(command)\r\n   1256         return_value = get_return_value(\r\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\r\n   1258 \r\n   1259         for temp_arg in temp_args:\r\n\r\nPlease help in resolving this.\r\n\r\nBR,\r\nBharat", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1312", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1312/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1312/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1312/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1312", "id": 462533147, "node_id": "MDU6SXNzdWU0NjI1MzMxNDc=", "number": 1312, "title": "Any plans to support k8s?", "user": {"login": "haitaodd", "id": 46930826, "node_id": "MDQ6VXNlcjQ2OTMwODI2", "avatar_url": "https://avatars3.githubusercontent.com/u/46930826?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haitaodd", "html_url": "https://github.com/haitaodd", "followers_url": "https://api.github.com/users/haitaodd/followers", "following_url": "https://api.github.com/users/haitaodd/following{/other_user}", "gists_url": "https://api.github.com/users/haitaodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/haitaodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haitaodd/subscriptions", "organizations_url": "https://api.github.com/users/haitaodd/orgs", "repos_url": "https://api.github.com/users/haitaodd/repos", "events_url": "https://api.github.com/users/haitaodd/events{/privacy}", "received_events_url": "https://api.github.com/users/haitaodd/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-01T06:26:24Z", "updated_at": "2019-07-01T07:28:14Z", "closed_at": "2019-07-01T07:28:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1311", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1311/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1311/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1311/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1311", "id": 462339497, "node_id": "MDU6SXNzdWU0NjIzMzk0OTc=", "number": 1311, "title": "java.lang.NullPointerException in hamOrSpamMultiAlgo", "user": {"login": "maziyarpanahi", "id": 5762953, "node_id": "MDQ6VXNlcjU3NjI5NTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/5762953?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maziyarpanahi", "html_url": "https://github.com/maziyarpanahi", "followers_url": "https://api.github.com/users/maziyarpanahi/followers", "following_url": "https://api.github.com/users/maziyarpanahi/following{/other_user}", "gists_url": "https://api.github.com/users/maziyarpanahi/gists{/gist_id}", "starred_url": "https://api.github.com/users/maziyarpanahi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maziyarpanahi/subscriptions", "organizations_url": "https://api.github.com/users/maziyarpanahi/orgs", "repos_url": "https://api.github.com/users/maziyarpanahi/repos", "events_url": "https://api.github.com/users/maziyarpanahi/events{/privacy}", "received_events_url": "https://api.github.com/users/maziyarpanahi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-29T20:26:21Z", "updated_at": "2019-07-01T11:04:32Z", "closed_at": "2019-07-01T11:04:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "- Sparkling Water/PySparkling/RSparkling version\r\nSpark 2.4.0-cdh6.2.0\r\nai.h2o:sparkling-water-package_2.11:2.4.13\r\n- Hadoop Version & Distribution\r\nCloudera 6.2.0\r\n- Execution mode `YARN-client`, `YARN-cluster`, standalone, local ..\r\nYARN-client\r\n- YARN logs in case of running on yarn. To collect such logs you may run `yarn logs -applicationId <application ID>` where the application ID is displayed when Sparkling Water is started\r\nI don't see any error in my YARN logs.\r\n\r\n- Are you using Windows/Linux/MAC?\r\nLinux\r\n- Spark & Sparkling Water configuration including the memory configuration\r\nI just disabled spark.dynamicAllocation.enabled false\r\n\r\nI am trying to test this example inside my Zeppelin which the specs I mentioned:\r\nhttps://github.com/h2oai/sparkling-water/blob/master/examples/pipelines/hamOrSpamMultiAlgo.script.scala\r\n\r\nEverything works all the way to `pipeline.fit(smsDataFrame)`. I get this error:\r\n\r\n```bash\r\njava.lang.NullPointerException\r\n  at org.apache.spark.ml.h2o.models.H2OMOJOModel$.org$apache$spark$ml$h2o$models$H2OMOJOModel$$removeMetaField(H2OMOJOModel.scala:172)\r\n  at org.apache.spark.ml.h2o.models.H2OMOJOModel$.getModelDetails(H2OMOJOModel.scala:188)\r\n  at org.apache.spark.ml.h2o.models.H2OMOJOModel$.createFromMojo(H2OMOJOModel.scala:205)\r\n  at org.apache.spark.ml.h2o.algos.H2OAlgorithm.fit(H2OAlgorithm.scala:69)\r\n  at org.apache.spark.ml.h2o.algos.H2OAlgorithm.fit(H2OAlgorithm.scala:38)\r\n  at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:153)\r\n  at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:149)\r\n  at scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n  at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\r\n  at scala.collection.IterableViewLike$Transformed$class.foreach(IterableViewLike.scala:44)\r\n  at scala.collection.SeqViewLike$AbstractTransformed.foreach(SeqViewLike.scala:37)\r\n  at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:149)\r\n```\r\nThe interesting part is that I can see H2OFlow is still running the job and finishes successfully. I can even do predict without any problem. It just the `.fit()` part fails before H2O job finishes.\r\n\r\nHas anyone ever experienced something similar that can help me narrow it down?\r\n\r\n\r\nSince I have changed some parts of the code, I share my example:\r\n\r\n```scala\r\nimport org.apache.spark.h2o._\r\nval h2oContext = H2OContext.getOrCreate(spark)\r\nimport h2oContext._\r\n\r\nval sparkSmsDF = spark.read\r\n.option(\"header\", false)\r\n.option(\"delimiter\", \"\\t\")\r\n.option(\"mode\", \"DROPMALFORMED\")\r\n.csv(\"/user/maziyar/input/smsData/smsData.txt\") // this is on HDFS\r\n.select($\"_c0\".as(\"label\"), $\"_c1\".as(\"text\"))\r\n\r\nval tokenizer = new RegexTokenizer().\r\n  setInputCol(\"text\").\r\n  setOutputCol(\"words\").\r\n  setMinTokenLength(3).\r\n  setGaps(false).\r\n  setPattern(\"[a-zA-Z]+\")\r\n\r\n// Remove ignored words\r\nval stopWordsRemover = new StopWordsRemover().\r\n  setInputCol(tokenizer.getOutputCol).\r\n  setOutputCol(\"filtered\").\r\n  setStopWords(Array(\"the\", \"a\", \"\", \"in\", \"on\", \"at\", \"as\", \"not\", \"for\")).\r\n  setCaseSensitive(false)\r\n\r\n// Hash the words\r\nval hashingTF = new HashingTF().\r\n  setNumFeatures(1 << 10).\r\n  setInputCol(stopWordsRemover.getOutputCol).\r\n  setOutputCol(\"wordToIndex\")\r\n\r\n// Create inverse document frequencies model\r\nval idf = new IDF().\r\n  setMinDocFreq(4).\r\n  setInputCol(hashingTF.getOutputCol).\r\n  setOutputCol(\"tf_idf\")\r\n\r\n// I removed the rest because H2OXGBoost and H2OGridSearch had some problems\r\nval algo = \"dl\"\r\n\r\nval algoStage = algo match {\r\n//   case \"gbm\" =>\r\n    // Create GBM model\r\n    // new H2OGBM().\r\n    //   setSplitRatio(0.8).\r\n    //   setSeed(1).\r\n    //   setFeaturesCols(\"tf_idf\").\r\n    //   setLabelCol(\"label\")\r\n  case \"dl\" =>\r\n    // Create H2ODeepLearning model\r\n    new H2ODeepLearning().\r\n      setEpochs(10).\r\n      setL1(0.001).\r\n      setL2(0.0).\r\n      setSeed(1).\r\n      setHidden(Array[Int](200, 200)).\r\n      setFeaturesCols(\"tf_idf\").\r\n      setLabelCol(\"label\")\r\n}\r\n\r\n// Create the pipeline by defining all the stages\r\nval pipeline = new Pipeline().\r\n  setStages(Array(tokenizer, stopWordsRemover, hashingTF, idf, algoStage))\r\n\r\n// fails here in Spark, but continues in H2OFlow \r\nval model = pipeline.fit(sparkSmsDF)\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1272", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1272/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1272/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1272/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1272", "id": 456239609, "node_id": "MDU6SXNzdWU0NTYyMzk2MDk=", "number": 1272, "title": "Method close doesn\u00b4t work for H2OContext", "user": {"login": "sergiocalde94", "id": 22750693, "node_id": "MDQ6VXNlcjIyNzUwNjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/22750693?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sergiocalde94", "html_url": "https://github.com/sergiocalde94", "followers_url": "https://api.github.com/users/sergiocalde94/followers", "following_url": "https://api.github.com/users/sergiocalde94/following{/other_user}", "gists_url": "https://api.github.com/users/sergiocalde94/gists{/gist_id}", "starred_url": "https://api.github.com/users/sergiocalde94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sergiocalde94/subscriptions", "organizations_url": "https://api.github.com/users/sergiocalde94/orgs", "repos_url": "https://api.github.com/users/sergiocalde94/repos", "events_url": "https://api.github.com/users/sergiocalde94/events{/privacy}", "received_events_url": "https://api.github.com/users/sergiocalde94/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-14T13:06:23Z", "updated_at": "2019-06-27T06:42:55Z", "closed_at": "2019-06-27T06:42:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi!\r\n\r\nI\u00b4m trying to close the H2OContext but it doesn\u00b4t work. I defined it with this:\r\n\r\n```\r\nval spark: SparkSession = SparkSession\r\n      .builder()\r\n      .appName(AppName)\r\n      .getOrCreate()\r\n\r\nval hc: H2OContext = H2OContext.getOrCreate(spark)\r\n```\r\n\r\nand I try to close with `hc.stop(stopSparkContext = true)` but it throws an error:\r\n\r\n```Exception in thread \"main\" java.lang.NoSuchMethodError: org.apache.http.impl.client.DefaultHttpClient.close()V\r\n        at org.apache.spark.h2o.RestAnnouncementProvider.shutdown(AnnouncementService.scala:156)\r\n        at org.apache.spark.h2o.AnnouncementServiceFactory$AnnouncementServiceImpl$$anonfun$shutdown$1.apply(AnnouncementService.scala:67)\r\n        at org.apache.spark.h2o.AnnouncementServiceFactory$AnnouncementServiceImpl$$anonfun$shutdown$1.apply(AnnouncementService.scala:67)\r\n        at scala.collection.immutable.Stream.foreach(Stream.scala:594)\r\n        at org.apache.spark.h2o.AnnouncementServiceFactory$AnnouncementServiceImpl.shutdown(AnnouncementService.scala:67)\r\n        at org.apache.spark.h2o.H2OContext.stop(H2OContext.scala:309)\r\n```\r\n\r\nThe code is running in a spark application and launched with spark-submit, Using your doc (http://docs.h2o.ai/h2o/latest-stable/h2o-docs/faq/sparkling-water.html) I tried to use `new H2OContext().start()` but it else throws an error `constructor not accesible`.\r\n\r\nI also navigate on sparkling water examples but I didn\u00b4t get my goal :(\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1266", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1266/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1266/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1266/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1266", "id": 455601011, "node_id": "MDU6SXNzdWU0NTU2MDEwMTE=", "number": 1266, "title": "RSparkling installation from source is broken", "user": {"login": "nadenf", "id": 657041, "node_id": "MDQ6VXNlcjY1NzA0MQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/657041?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nadenf", "html_url": "https://github.com/nadenf", "followers_url": "https://api.github.com/users/nadenf/followers", "following_url": "https://api.github.com/users/nadenf/following{/other_user}", "gists_url": "https://api.github.com/users/nadenf/gists{/gist_id}", "starred_url": "https://api.github.com/users/nadenf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nadenf/subscriptions", "organizations_url": "https://api.github.com/users/nadenf/orgs", "repos_url": "https://api.github.com/users/nadenf/repos", "events_url": "https://api.github.com/users/nadenf/events{/privacy}", "received_events_url": "https://api.github.com/users/nadenf/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-06-13T08:22:19Z", "updated_at": "2019-06-18T11:06:37Z", "closed_at": "2019-06-13T08:33:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "Installation from source:\r\ndevtools::install_github(\"h2oai/sparkling-water\", ref=\"master\", subdir=\"r/src\")\r\n\r\nProduces the following error message:\r\n```\r\n* installing *source* package \u2018h2o\u2019 ...\r\n** R\r\n** demo\r\n** inst\r\n** byte-compile and prepare package for lazy loading\r\n** help\r\n*** installing help indices\r\n** building package indices\r\n** testing if installed package can be loaded\r\n* DONE (h2o)\r\n\u2714  checking for file \u2018/mnt/tmp/RtmpFVlJIs/remotes9b477e47b712/h2oai-sparkling-water-a612cee/r/src/DESCRIPTION\u2019 ...\r\n\u2500  preparing \u2018rsparkling\u2019:\r\nE  checking DESCRIPTION meta-information ...\r\n   Malformed package version.\r\n   \r\n   See section 'The DESCRIPTION file' in the 'Writing R Extensions'\r\n   manual.\r\n   \r\nError in (function (command = NULL, args = character(), error_on_status = TRUE,  : \r\n  System command error\r\n```\r\nDue to the following commit from @jakubhava :\r\nhttps://github.com/h2oai/sparkling-water/commit/678e7ed2d7b5345e611a96bf02ca89718c27d476#diff-455fe0e750f4e51b108e12ec3ba46ca1\r\n\r\nSpecifically replacing 0.2.25 with SUBST_PROJECT_VERSION in the DESCRIPTION file. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1253", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1253/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1253/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1253/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1253", "id": 454222677, "node_id": "MDU6SXNzdWU0NTQyMjI2Nzc=", "number": 1253, "title": "Cannot add primary key (or any column) to scoreContributions output", "user": {"login": "sergiocalde94", "id": 22750693, "node_id": "MDQ6VXNlcjIyNzUwNjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/22750693?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sergiocalde94", "html_url": "https://github.com/sergiocalde94", "followers_url": "https://api.github.com/users/sergiocalde94/followers", "following_url": "https://api.github.com/users/sergiocalde94/following{/other_user}", "gists_url": "https://api.github.com/users/sergiocalde94/gists{/gist_id}", "starred_url": "https://api.github.com/users/sergiocalde94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sergiocalde94/subscriptions", "organizations_url": "https://api.github.com/users/sergiocalde94/orgs", "repos_url": "https://api.github.com/users/sergiocalde94/repos", "events_url": "https://api.github.com/users/sergiocalde94/events{/privacy}", "received_events_url": "https://api.github.com/users/sergiocalde94/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-06-10T15:16:15Z", "updated_at": "2019-06-10T15:52:03Z", "closed_at": "2019-06-10T15:50:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi! I\u00b4m using score contributions in sparkling water and it works perfect except of I can\u00b4t add a primary key that I need for joining purpouses.\r\n\r\nMy code is very simple:\r\n\r\n```\r\nval gbmModelToExplain: GBMModel = ModelSerializationSupport\r\n        .loadH2OModel[GBMModel](destinationURI)\r\n\r\nval dataToExplainH2O: H2OFrame = hc\r\n        .asH2OFrame(dataToExplainWithSNAMetrics)\r\n\r\nval explanations: DataFrame = hc\r\n        .asDataFrame(gbmModelToExplain\r\n          .scoreContributions(\r\n            dataToExplainH2O, Key.make()\r\n          )\r\n          .add(dataToExplainH2O('my_primary_key)))\r\n\r\n```\r\n\r\nThis throw an error:\r\n\r\n```\r\njava.lang.ArrayIndexOutOfBoundsException: 59\r\n        at org.apache.spark.h2o.backends.internal.InternalReadConverterCtx.returnOption(InternalReadConverterCtx.scala:46)\r\n        at org.apache.spark.h2o.converters.ReadConverterCtx$$anonfun$org$apache$spark$h2o$converters$ReadConverterCtx$$OptionReadersMap$1$$anonfun$apply$1.apply(ReadConverterCtx.scala:120)\r\n        at org.apache.spark.h2o.converters.ReadConverterCtx$$anonfun$org$apache$spark$h2o$converters$ReadConverterCtx$$OptionReadersMap$1$$anonfun$apply$1.apply(ReadConverterCtx.scala:120)\r\n        at org.apache.spark.h2o.converters.ReadConverterCtx$$anonfun$columnValueProviders$2$$anonfun$1.apply(ReadConverterCtx.scala:69)\r\n        at org.apache.spark.h2o.converters.ReadConverterCtx$$anonfun$columnValueProviders$2$$anonfun$1.apply(ReadConverterCtx.scala:69)\r\n        at org.apache.spark.h2o.converters.H2ODataFrame$$anon$1$$anonfun$readOptionalData$1.apply(H2ODataFrame.scala:90)\r\n        at org.apache.spark.h2o.converters.H2ODataFrame$$anon$1$$anonfun$readOptionalData$1.apply(H2ODataFrame.scala:90)\r\n\r\n```\r\n\r\nMy dataframe has 60 colums (59 predicted variables and 1 primary key), if I execute without the add statement everything goes perfect but the problem is that I haven\u00b4t the primary key.\r\n\r\nAny ideas?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1244", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1244/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1244/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1244/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1244", "id": 453813308, "node_id": "MDU6SXNzdWU0NTM4MTMzMDg=", "number": 1244, "title": "h2o-pysparkling-2-4 2.4.12 incompatible with Spark 2.4", "user": {"login": "argenisleon", "id": 37144, "node_id": "MDQ6VXNlcjM3MTQ0", "avatar_url": "https://avatars0.githubusercontent.com/u/37144?v=4", "gravatar_id": "", "url": "https://api.github.com/users/argenisleon", "html_url": "https://github.com/argenisleon", "followers_url": "https://api.github.com/users/argenisleon/followers", "following_url": "https://api.github.com/users/argenisleon/following{/other_user}", "gists_url": "https://api.github.com/users/argenisleon/gists{/gist_id}", "starred_url": "https://api.github.com/users/argenisleon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/argenisleon/subscriptions", "organizations_url": "https://api.github.com/users/argenisleon/orgs", "repos_url": "https://api.github.com/users/argenisleon/repos", "events_url": "https://api.github.com/users/argenisleon/events{/privacy}", "received_events_url": "https://api.github.com/users/argenisleon/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-08T16:53:20Z", "updated_at": "2019-06-10T06:42:56Z", "closed_at": "2019-06-10T06:42:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "- Sparkling Water/PySparkling/RSparkling version\r\n2.4.12\r\n- Hadoop Version & Distribution\r\n2.7\r\n- Are you using Windows/Linux/MAC?\r\nLinux\r\n\r\nI am using h2o-pysparkling-2-4 2.4.12 as requirement for https://github.com/ironmussa/optimus. But it complains about the pyspark version: \r\n\r\nERROR: h2o-pysparkling-2-4 2.4.12 has requirement pyspark<=2.4.0,>=2.4.0, but you'll have pyspark 2.4.1 which is incompatible.\r\nhttps://travis-ci.org/ironmussa/Optimus/jobs/543180987#L1970\r\n\r\nI had tested with version 2.4.10, 2.4.11 and 2.4.12 without success. Is not the 2.4.x versions the correct on for Spark 2.4.x?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1243", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1243/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1243/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1243/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1243", "id": 453678757, "node_id": "MDU6SXNzdWU0NTM2Nzg3NTc=", "number": 1243, "title": "Consider adding support for Spark pipelines in `rsparkling`", "user": {"login": "javierluraschi", "id": 3478847, "node_id": "MDQ6VXNlcjM0Nzg4NDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3478847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/javierluraschi", "html_url": "https://github.com/javierluraschi", "followers_url": "https://api.github.com/users/javierluraschi/followers", "following_url": "https://api.github.com/users/javierluraschi/following{/other_user}", "gists_url": "https://api.github.com/users/javierluraschi/gists{/gist_id}", "starred_url": "https://api.github.com/users/javierluraschi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/javierluraschi/subscriptions", "organizations_url": "https://api.github.com/users/javierluraschi/orgs", "repos_url": "https://api.github.com/users/javierluraschi/repos", "events_url": "https://api.github.com/users/javierluraschi/events{/privacy}", "received_events_url": "https://api.github.com/users/javierluraschi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-07T20:20:43Z", "updated_at": "2020-02-11T07:23:49Z", "closed_at": "2020-02-11T07:23:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "`sparklyr` supports [Spark pipelines in R](https://blog.rstudio.com/2018/05/14/sparklyr-0-8/) but there is additional work to make them available in `rsparkling`, which would enable users to build H2O pipelines in Spark from R and them move them to production without requiring R at all.\r\n\r\nSee also: https://databricks.com/session/productionizing-h2o-models-with-apache-spark", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1238", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1238/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1238/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1238/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1238", "id": 451709558, "node_id": "MDU6SXNzdWU0NTE3MDk1NTg=", "number": 1238, "title": "as_spark_dataframe broken in R", "user": {"login": "BrandonRCopeland", "id": 44583531, "node_id": "MDQ6VXNlcjQ0NTgzNTMx", "avatar_url": "https://avatars3.githubusercontent.com/u/44583531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BrandonRCopeland", "html_url": "https://github.com/BrandonRCopeland", "followers_url": "https://api.github.com/users/BrandonRCopeland/followers", "following_url": "https://api.github.com/users/BrandonRCopeland/following{/other_user}", "gists_url": "https://api.github.com/users/BrandonRCopeland/gists{/gist_id}", "starred_url": "https://api.github.com/users/BrandonRCopeland/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BrandonRCopeland/subscriptions", "organizations_url": "https://api.github.com/users/BrandonRCopeland/orgs", "repos_url": "https://api.github.com/users/BrandonRCopeland/repos", "events_url": "https://api.github.com/users/BrandonRCopeland/events{/privacy}", "received_events_url": "https://api.github.com/users/BrandonRCopeland/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-06-03T22:02:54Z", "updated_at": "2019-06-04T20:11:42Z", "closed_at": "2019-06-04T15:24:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI'm running into a perplexing issue.  I can convert my sparklyr table (tbl_spark) to an H20Frame, but I cannot get my data out of H2O via as_spark_dataframe.  \r\n\r\nI'm running on Databricks Release version 5.3, which leverages Spark 2.4.  I'm using RSparkling 2.4.1 per the requirements table.\r\n\r\nI convert my tbl_spark to H2O via \"hf <- as_h2o_frame(sc, sdf.scoringData)\".  That works fine, and I can run my models in H2O, etc.  However, as_spark_dataframe(sc, any_H2O_frame) fails with the error below.\r\n\r\nHere is the error message I'm getting:\r\n\r\nThanks for the help!\r\n\r\n______________________________\r\n\r\nError : org.apache.spark.sql.AnalysisException: Table or view not found: hf; line 2 pos 5\r\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:750)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:695)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:731)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:724)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:77)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8.apply(TreeNode.scala:351)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:208)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:349)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8.apply(TreeNode.scala:351)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:208)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:349)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8.apply(TreeNode.scala:351)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:208)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:349)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:724)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:664)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:112)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:109)\r\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\r\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:109)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:101)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:101)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:136)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:130)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:102)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$executeAndTrack$1.apply(RuleExecutor.scala:80)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$executeAndTrack$1.apply(RuleExecutor.scala:80)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:79)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:114)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:113)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:113)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:82)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:72)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:88)\r\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:696)\r\n\tat sun.reflect.GeneratedMethodAccessor257.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat sparklyr.Invoke.invoke(invoke.scala:139)\r\n\tat sparklyr.StreamHandler.handleMethodCall(stream.scala:123)\r\n\tat sparklyr.StreamHandler.read(stream.scala:66)\r\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:51)\r\n\tat sparklyr.BackendHandler.channelRead0(handle", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1235", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1235/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1235/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1235/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1235", "id": 451439510, "node_id": "MDU6SXNzdWU0NTE0Mzk1MTA=", "number": 1235, "title": "Cannot test sparkling water app with Graddle", "user": {"login": "sergiocalde94", "id": 22750693, "node_id": "MDQ6VXNlcjIyNzUwNjkz", "avatar_url": "https://avatars2.githubusercontent.com/u/22750693?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sergiocalde94", "html_url": "https://github.com/sergiocalde94", "followers_url": "https://api.github.com/users/sergiocalde94/followers", "following_url": "https://api.github.com/users/sergiocalde94/following{/other_user}", "gists_url": "https://api.github.com/users/sergiocalde94/gists{/gist_id}", "starred_url": "https://api.github.com/users/sergiocalde94/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sergiocalde94/subscriptions", "organizations_url": "https://api.github.com/users/sergiocalde94/orgs", "repos_url": "https://api.github.com/users/sergiocalde94/repos", "events_url": "https://api.github.com/users/sergiocalde94/events{/privacy}", "received_events_url": "https://api.github.com/users/sergiocalde94/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2019-06-03T11:50:40Z", "updated_at": "2019-08-19T07:29:38Z", "closed_at": "2019-08-19T07:29:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "I\u00b4m using sparkling water with scala and it works excellent in spark2-shell mode. Now I\u00b4m creating a graddle based app to build a fat jar and execute it with spark2-submit.\r\n\r\nI added the needed dependencies to build.graddle file (the same that I used in spark2-shell mode), I\u00b4m usin spark 2.3.0\r\n\r\n```\r\ncompile \"ai.h2o:sparkling-water-core_2.11:2.3.28\"\r\n```\r\n\r\nIf I try to test my application it throws an error:\r\n\r\n```\r\nException in thread \"H2O Launcher thread\" java.lang.NoClassDefFoundError: org/eclipse/jetty/util/component/AggregateLifeCycle\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat water.webserver.jetty8.Jetty8ServerAdapter.create(Jetty8ServerAdapter.java:35)\r\n\tat water.webserver.jetty8.Jetty8Facade.createWebServer(Jetty8Facade.java:12)\r\n\tat water.init.NetworkInit.initializeNetworkSockets(NetworkInit.java:77)\r\n\tat water.H2O.startLocalNode(H2O.java:1620)\r\n\tat water.H2O.main(H2O.java:2080)\r\n\tat water.H2OStarter.start(H2OStarter.java:22)\r\n\tat water.H2OStarter.start(H2OStarter.java:47)\r\n\tat org.apache.spark.h2o.backends.internal.InternalBackendUtils$$anonfun$7$$anon$1.run(InternalBackendUtils.scala:169)\r\nCaused by: java.lang.ClassNotFoundException: org.eclipse.jetty.util.component.AggregateLifeCycle\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\t... 44 more\r\n```\r\n\r\nSo I tried to add jetty util to my app dependencies:\r\n\r\n```\r\ntestCompile \"org.eclipse.jetty:jetty-util:9.4.18.v20190429\"\r\n```\r\n\r\nBut this it throwing the same error.\r\n\r\nAny idea?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1231", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1231/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1231/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1231/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1231", "id": 451075284, "node_id": "MDU6SXNzdWU0NTEwNzUyODQ=", "number": 1231, "title": "scoreContributions problem", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-01T11:23:36Z", "updated_at": "2019-06-09T07:15:23Z", "closed_at": "2019-06-09T07:15:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi again. \r\nMaybe I'm just doing something wrong. I have my gbmmodel in scala api and I want to get shap values over a test h2oframe..\r\nMy code is something like that.\r\n\r\n``` scala\r\nval loadedModel: GBMModel = ModelSerializationSupport.loadH2OModel(destinationURI)\r\nval explain_frame = loadedModel.scoreContributions(test, test.get.key)\r\n\r\n```\r\nThen sparkling water class. It looks that scoreContributions is working but I get\r\n\r\n``` scala \r\npid: 0\r\nnidL: 3\r\nnidR: 4\r\nweightL: 365639.0\r\nweightR: 343416.0\r\npredL: 0.053668547\r\npredR: 0.013306603\r\nsqErrL: 75386.13\r\nsqErrR: 76166.15\r\nreserved: 30\r\n\r\n\r\nTree inconsistency found:\r\n        Node 100 (parent)\r\n            weight:      7491.0\r\n            depth:       6\r\n            colId:       52\r\n            colName:     min_antig\r\n            leftward:    true\r\n            naVsRest:    false\r\n            splitVal:    11.5\r\n            isBitset:    false\r\n            predValue:   0.18581045\r\n            squaredErr:  1126.7651\r\n            leftChild:   Node 327\r\n            rightChild:  Node 328\r\n        Node 327 (left child)\r\n            weight:      4871.0\r\n            depth:       7\r\n            colId:       0\r\n            colName:\r\n            leftward:    false\r\n            naVsRest:    false\r\n            splitVal:    NaN\r\n            isBitset:    false\r\n            predValue:   5.327187E-7\r\n            squaredErr:  850.04004\r\n            leftChild:\r\n            rightChild:\r\n        Node 328 (right child)\r\n            weight:      3432.0\r\n            depth:       7\r\n            colId:       0\r\n            colName:\r\n            leftward:    false\r\n            naVsRest:    false\r\n            splitVal:    NaN\r\n            isBitset:    false\r\n            predValue:   1.4382539E-6\r\n            squaredErr:  487.77805\r\n            leftChild:\r\n            rightChild:\r\n```\r\nAnd it never ends. \r\nAny idea?\r\nThanks in advance\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1229", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1229/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1229/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1229/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1229", "id": 450422796, "node_id": "MDU6SXNzdWU0NTA0MjI3OTY=", "number": 1229, "title": "Lost scoreContributions", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-05-30T17:36:54Z", "updated_at": "2019-06-01T10:17:25Z", "closed_at": "2019-05-31T08:18:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi. I'm using sparkling-water inside spark and when I load a previously saved gbmModel I can't find scoreContributions method which is present in original model.\r\n\r\n```\r\nval gbmModel = new GBM(gbmParams).trainModel.get\r\n\r\n// gbmModel.scoreContributions works\r\n\r\nval destinationURI = URI.create(\"file:///midir/migbm.zip\")\r\n\r\nModelSerializationSupport.exportH2OModel(gbmModel, destinationURI)\r\n\r\nval nuevo_modelo : Model[,_,_] = ModelSerializationSupport.loadH2OModel(destinationURI)\r\n//nuevo_modelo.scoreContributions is not present\r\n```\r\nI can predict using my loaded model but I can't get scoreContribution . \r\nis there anyway to cast model type to hex.tree.gbmModel?\r\n\r\nThanks in advance.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1207", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1207/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1207/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1207/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1207", "id": 445529100, "node_id": "MDU6SXNzdWU0NDU1MjkxMDA=", "number": 1207, "title": "pysparkling.ml.H2OGridSearch - hyperParameters not accepted", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-17T16:46:30Z", "updated_at": "2019-05-22T07:49:39Z", "closed_at": "2019-05-22T07:49:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "Trying to run simple code to test **pysparkling.ml.H2OGridSearch** inside PySpark ML pipeline and getting following error:\r\n\r\n**_code:_**\r\n```\r\nfrom pysparkling.ml import H2OGridSearch, H2OXGBoost\r\n\r\ngrid_params = {'ntrees':[100, 150, 200]}\r\ngrid_search = H2OGridSearch(algo=H2OXGBoost(), hyperParameters=grid_params)\r\ngrid_search.fit(set_train) #set_train is spark dataframe\r\n```\r\n\r\n**_error:_**\r\n```\r\nPy4JJavaError: An error occurred while calling o2966.fit.\r\n: java.lang.NoSuchFieldException: ntrees\r\n\tat java.lang.Class.getField(Class.java:1703)\r\n\tat org.apache.spark.ml.h2o.algos.H2OGridSearch.findField(H2OGridSearch.scala:177)\r\n\tat org.apache.spark.ml.h2o.algos.H2OGridSearch.processHyperParams(H2OGridSearch.scala:161)\r\n\tat org.apache.spark.ml.h2o.algos.H2OGridSearch.fit(H2OGridSearch.scala:73)\r\n\tat org.apache.spark.ml.h2o.algos.H2OGridSearch.fit(H2OGridSearch.scala:49)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nI've tried to tune various algorithm parameters (ntrees, eta, sampleRate..) but still getting same error. \r\nSame situation when I changed algo from XGBoost to GBM.\r\n\r\n`Using PySparkling /2.4.11/ & H2O /3.24.0.3/ on YARN-cluster mode.`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1203", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1203/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1203/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1203/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1203", "id": 444923121, "node_id": "MDU6SXNzdWU0NDQ5MjMxMjE=", "number": 1203, "title": "model_id parameter not available in H2OXGBoost pipeline wrapper", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-16T12:19:17Z", "updated_at": "2019-06-06T16:20:53Z", "closed_at": "2019-06-06T16:20:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Trying to define **model_id** parameter in H2OXGBoost pipeline wrapper but getting following error:\r\n\r\n`classifier = H2OXGBoost(model_id=\"test\", ntrees=200, eta=0.05)`\r\n\r\n`AttributeError: 'H2OXGBoost' object has no attribute 'model_id'`\r\n\r\nAttribute is available within h2o.estimators.H2OXGBoostEstimator.\r\nIs it possible to add it also to pysparkling.ml.H2OXGBoost?\r\n\r\n_Using PySparkling /2.4.10/ & H2O /3.24.0.2/ on YARN-cluster mode._\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1200", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1200/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1200/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1200/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1200", "id": 444550192, "node_id": "MDU6SXNzdWU0NDQ1NTAxOTI=", "number": 1200, "title": "XGBoost in H2OGridSearch", "user": {"login": "dataspekulant", "id": 32393376, "node_id": "MDQ6VXNlcjMyMzkzMzc2", "avatar_url": "https://avatars3.githubusercontent.com/u/32393376?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dataspekulant", "html_url": "https://github.com/dataspekulant", "followers_url": "https://api.github.com/users/dataspekulant/followers", "following_url": "https://api.github.com/users/dataspekulant/following{/other_user}", "gists_url": "https://api.github.com/users/dataspekulant/gists{/gist_id}", "starred_url": "https://api.github.com/users/dataspekulant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dataspekulant/subscriptions", "organizations_url": "https://api.github.com/users/dataspekulant/orgs", "repos_url": "https://api.github.com/users/dataspekulant/repos", "events_url": "https://api.github.com/users/dataspekulant/events{/privacy}", "received_events_url": "https://api.github.com/users/dataspekulant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-15T17:09:16Z", "updated_at": "2019-05-15T18:56:01Z", "closed_at": "2019-05-15T18:56:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to use XGBoost algorithm within H2OGridSearch plugged in Spark ML pipeline but getting following error:\r\n\r\n`classifier = H2OGridSearch(algo=pysparkling.ml.H2OXGBoost(), hyperParameters=params)`\r\n\r\n`...\r\nPy4JJavaError: An error occurred while calling o198.setAlgo.\r\n: java.lang.IllegalArgumentException: Grid Search is not supported for the specified algorithm 'H2OXGBoost_15108b19ed18'. Supported algorithms are gbm, glm, deeplearning\r\n...`\r\n\r\n_Using PySparkling /2.4.10/ & H2O /3.24.0.2/ on YARN-cluster mode._", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1193", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1193/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1193/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1193/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1193", "id": 443086015, "node_id": "MDU6SXNzdWU0NDMwODYwMTU=", "number": 1193, "title": "Unable to create h2o_context on Databricks using R and Scala", "user": {"login": "sasikiran", "id": 1332828, "node_id": "MDQ6VXNlcjEzMzI4Mjg=", "avatar_url": "https://avatars1.githubusercontent.com/u/1332828?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sasikiran", "html_url": "https://github.com/sasikiran", "followers_url": "https://api.github.com/users/sasikiran/followers", "following_url": "https://api.github.com/users/sasikiran/following{/other_user}", "gists_url": "https://api.github.com/users/sasikiran/gists{/gist_id}", "starred_url": "https://api.github.com/users/sasikiran/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sasikiran/subscriptions", "organizations_url": "https://api.github.com/users/sasikiran/orgs", "repos_url": "https://api.github.com/users/sasikiran/repos", "events_url": "https://api.github.com/users/sasikiran/events{/privacy}", "received_events_url": "https://api.github.com/users/sasikiran/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 32, "created_at": "2019-05-12T09:55:15Z", "updated_at": "2020-01-26T23:01:06Z", "closed_at": "2020-01-26T23:01:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to use sparkling water on Azure Databricks and I'm not able to create h2o_context. I tried this in both R and Scala on the same cluster. \r\n\r\nR Sample code:\r\n```\r\ninstall.packages(\"sparklyr\")\r\ninstall.packages(\"rsparkling\")\r\ninstall.packages(\"h2o\", type=\"source\", repos=\"https://h2o-release.s3.amazonaws.com/h2o/rel-yates/2/R\")\r\n\r\nlibrary(rsparkling)\r\nlibrary(sparklyr)\r\n\r\nsc <- spark_connect(method=\"databricks\")\r\nh2o_context(sc)\r\n```\r\n\r\nScala sample code:\r\n```\r\nimport org.apache.spark.h2o._\r\nval hc = H2OContext.getOrCreate(spark)\r\n```\r\n**Configuration details**\r\n- Azure Databricks version: 5.3 ML (includes Apache Spark 2.4.0, Scala 2.11)\r\n- Driver type: Standard_DS3_V2: 14.0 GB Memory, 4 Cores, 0.75 DBU\r\n- Min workers: 2\r\n- Max workers: 8\r\n- Enable autoscaling: Yes\r\n- Sparkling Water library: sparkling_water_assembly_2_11_2_4_10_all.jar\r\n\r\n**Error log**:\r\n`\r\nError : org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 14.0 failed 4 times, most recent failure: Lost task 1.3 in stage 14.0 (TID 144, 10.139.64.6, executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\r\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2355)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2343)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2342)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2342)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1096)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1096)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1096)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2574)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2510)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:893)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2233)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2255)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2274)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2299)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:961)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:379)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:960)\r\n\tat org.apache.spark.h2o.backends.internal.InternalBackendUtils$class.startH2O(InternalBackendUtils.scala:196)\r\n\tat org.apache.spark.h2o.backends.internal.InternalBackendUtils$.startH2O(InternalBackendUtils.scala:306)\r\n\tat org.apache.spark.h2o.backends.internal.InternalH2OBackend.init(InternalH2OBackend.scala:104)\r\n\tat org.apache.spark.h2o.H2OContext.init(H2OContext.scala:129)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:403)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:438)\r\n\tat org.apache.spark.h2o.H2OContext.getOrCreate(H2OContext.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat sparklyr.Invoke.invoke(invoke.scala:139)\r\n\tat sparklyr.StreamHandler.handleMethodCall(stream.scala:123)\r\n\tat sparklyr.StreamHandler.read(stream.scala:66)\r\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:51)\r\n\tat sparklyr.BackendHandler.channelRead0(handler.scala:4)\r\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1121", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1121/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1121/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1121/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1121", "id": 430129974, "node_id": "MDU6SXNzdWU0MzAxMjk5NzQ=", "number": 1121, "title": "Convert h2oframe to spark dataframe using rsparkling", "user": {"login": "joscani", "id": 1321194, "node_id": "MDQ6VXNlcjEzMjExOTQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1321194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joscani", "html_url": "https://github.com/joscani", "followers_url": "https://api.github.com/users/joscani/followers", "following_url": "https://api.github.com/users/joscani/following{/other_user}", "gists_url": "https://api.github.com/users/joscani/gists{/gist_id}", "starred_url": "https://api.github.com/users/joscani/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joscani/subscriptions", "organizations_url": "https://api.github.com/users/joscani/orgs", "repos_url": "https://api.github.com/users/joscani/repos", "events_url": "https://api.github.com/users/joscani/events{/privacy}", "received_events_url": "https://api.github.com/users/joscani/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 15, "created_at": "2019-04-07T10:47:44Z", "updated_at": "2019-12-10T13:26:08Z", "closed_at": "2019-04-25T11:46:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "I can convert spark dataframe to h2oframe but not  h2oframe to sparkdataframe.\r\n```\r\ncalls <- sc %>% tbl(\"default.calls\")\r\n\r\ncalls <- calls %>% \r\n  filter(fecha_inicio == \"20190406\")\r\n\r\n# it works to send a h2o cluster\r\ncalls_hex <- as_h2o_frame(sc, calls,\"calls_hex\")\r\n\r\n# Fail get batk to spark\r\ntmp_spark <- as_spark_dataframe(sc, calls_hex, name=\"tmp_spark\" )\r\n```\r\nError: java.lang.Exception: No matched method found for class org.apache.spark.h2o.H2OContext.asDataFrame\r\n\r\nsessionInfo()\r\nother attached packages:\r\n[1] sparklyr_1.0.0    dplyr_0.8.0.1     h2o_3.24.0.1     \r\n[4] rsparkling_0.2.22", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1108", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1108/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1108/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1108/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1108", "id": 425261030, "node_id": "MDU6SXNzdWU0MjUyNjEwMzA=", "number": 1108, "title": "[Bug] probability calibration does not work in Sparkling Water Dataframe API", "user": {"login": "goldminer09", "id": 25187073, "node_id": "MDQ6VXNlcjI1MTg3MDcz", "avatar_url": "https://avatars2.githubusercontent.com/u/25187073?v=4", "gravatar_id": "", "url": "https://api.github.com/users/goldminer09", "html_url": "https://github.com/goldminer09", "followers_url": "https://api.github.com/users/goldminer09/followers", "following_url": "https://api.github.com/users/goldminer09/following{/other_user}", "gists_url": "https://api.github.com/users/goldminer09/gists{/gist_id}", "starred_url": "https://api.github.com/users/goldminer09/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/goldminer09/subscriptions", "organizations_url": "https://api.github.com/users/goldminer09/orgs", "repos_url": "https://api.github.com/users/goldminer09/repos", "events_url": "https://api.github.com/users/goldminer09/events{/privacy}", "received_events_url": "https://api.github.com/users/goldminer09/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-26T07:18:37Z", "updated_at": "2019-05-01T11:46:09Z", "closed_at": "2019-05-01T11:46:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "Although when calibration is enabled, EasyPredictModelWrapper returns a `BinomialModelPrediction` object which contains both raw probs and calibrated probs, the  \r\nimplicit conversion defined here https://github.com/h2oai/sparkling-water/blob/9968342baa6b00eca2daba628f239a47d08c2ce9/ml/src/main/scala/org/apache/spark/ml/h2o/models/H2OMOJOModel.scala#L81-L83 transforms the `BinomialModelPrediction` object to a `BinomialPrediction`, which only contains raw probs (p0, and p1) and calibrated probabilities are NOT returned.  Both raw and calibrated probabilities should be returned to the user.\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1090", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1090/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1090/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1090/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1090", "id": 419464973, "node_id": "MDU6SXNzdWU0MTk0NjQ5NzM=", "number": 1090, "title": "weights_column is not supported for XGBoost models", "user": {"login": "ahutterTA", "id": 47035943, "node_id": "MDQ6VXNlcjQ3MDM1OTQz", "avatar_url": "https://avatars0.githubusercontent.com/u/47035943?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahutterTA", "html_url": "https://github.com/ahutterTA", "followers_url": "https://api.github.com/users/ahutterTA/followers", "following_url": "https://api.github.com/users/ahutterTA/following{/other_user}", "gists_url": "https://api.github.com/users/ahutterTA/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahutterTA/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahutterTA/subscriptions", "organizations_url": "https://api.github.com/users/ahutterTA/orgs", "repos_url": "https://api.github.com/users/ahutterTA/repos", "events_url": "https://api.github.com/users/ahutterTA/events{/privacy}", "received_events_url": "https://api.github.com/users/ahutterTA/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-03-11T13:19:55Z", "updated_at": "2019-04-17T09:24:48Z", "closed_at": "2019-04-17T09:24:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "[weights_column](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/weights_column.html) is available for XGBoost in H2O-3 but not in sparkling-water. It looks like I could add support for the parameter relatively easily but I'm wondering if not supporting weights_column was done explicitly and, if so, what the reason was. Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1089", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1089/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1089/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1089/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1089", "id": 418906990, "node_id": "MDU6SXNzdWU0MTg5MDY5OTA=", "number": 1089, "title": " Early Stopping Round Parameter (stopping_rounds) in XGBoost is not working properly with PySparkling Water", "user": {"login": "Shiutang-Li", "id": 18773995, "node_id": "MDQ6VXNlcjE4NzczOTk1", "avatar_url": "https://avatars2.githubusercontent.com/u/18773995?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Shiutang-Li", "html_url": "https://github.com/Shiutang-Li", "followers_url": "https://api.github.com/users/Shiutang-Li/followers", "following_url": "https://api.github.com/users/Shiutang-Li/following{/other_user}", "gists_url": "https://api.github.com/users/Shiutang-Li/gists{/gist_id}", "starred_url": "https://api.github.com/users/Shiutang-Li/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Shiutang-Li/subscriptions", "organizations_url": "https://api.github.com/users/Shiutang-Li/orgs", "repos_url": "https://api.github.com/users/Shiutang-Li/repos", "events_url": "https://api.github.com/users/Shiutang-Li/events{/privacy}", "received_events_url": "https://api.github.com/users/Shiutang-Li/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-03-08T18:37:18Z", "updated_at": "2019-03-19T21:07:01Z", "closed_at": "2019-03-19T21:07:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Description**\r\nWhen building an XGBoost model with either cross validation or a single validation set, when the validation metric is not improved in the number of rounds determined by stopping_rounds, it should stop training. Thus the actual number of trees used in the model would be less than what's assigned before training (ntrees).\r\n\r\nBut based on the codes below, stopping_rounds is not doing its job properly. It just keeps training until it reaches the preassigned ntrees. Because more trees then expected are used to build the model, the model obviously overfits.\r\n\r\n**Testing Version**\r\nh2o-pysparkling-2.4   (2.4.6)   on Spark 2.4.0\r\n\r\n**Testing Data and Python Codes to prepare it**\r\nI used kaggle's home credit default risk data to do the test. Download application_train.csv from\r\nhttps://www.kaggle.com/c/home-credit-default-risk/data\r\n\r\nand this is the code I used to prepare train / test set:\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\ndf = pd.read_csv('......./application_train.csv',\r\n                 sep=',',  header = 0)\r\ndf = df[df.NAME_CONTRACT_TYPE == 'Cash loans']\r\nfeatures = [\r\n 'AMT_INCOME_TOTAL',\r\n 'AMT_CREDIT',\r\n 'AMT_ANNUITY',\r\n 'AMT_GOODS_PRICE',\r\n 'DAYS_BIRTH',\r\n 'DAYS_EMPLOYED',\r\n 'DAYS_REGISTRATION',\r\n 'DAYS_ID_PUBLISH', \r\n 'EXT_SOURCE_1',\r\n 'EXT_SOURCE_2',\r\n 'EXT_SOURCE_3',\r\n 'HOUR_APPR_PROCESS_START',\r\n 'REG_REGION_NOT_LIVE_REGION',\r\n 'REG_REGION_NOT_WORK_REGION',\r\n 'LIVE_REGION_NOT_WORK_REGION',\r\n 'REG_CITY_NOT_LIVE_CITY',\r\n 'REG_CITY_NOT_WORK_CITY',\r\n 'LIVE_CITY_NOT_WORK_CITY'\r\n]\r\n\r\ndf[:200000][['SK_ID_CURR','TARGET'] + features].to_csv( '.... HCDR_train.csv', index = False)\r\ndf[200000:][['SK_ID_CURR','TARGET'] + features].to_csv( '.... HCDR_test.csv', index = False)\r\n\r\n**Testing Codes - 1 (for comparison purpose): Python XGBoost on a single machine**\r\nimport xgboost as xgb\r\ntrain_DM = xgb.DMatrix(train[features],label=train['TARGET'])\r\ntest_DM  = xgb.DMatrix(test[features], label=test['TARGET'])\r\nparams = {\r\n              'seed': 0,\r\n              'eta':  0.1,\r\n              'max_leaves' : 60,\r\n              'colsample_bytree': 1,\r\n              'subsample': 1,\r\n              'lambda': 1,\r\n              'gamma':  0,\r\n              'tree_method' :'hist',\r\n              'grow_policy' :'lossguide',\r\n              'objective'   : 'binary:logistic',\r\n              'eval_metric' : 'auc',\r\n              'silent' : 1\r\n          } \r\ncv_table = xgb.cv(params = params,\r\n                  dtrain = train_DM,\r\n                  num_boost_round = 2000,\r\n                  nfold  = 5,\r\n                  stratified = True, \r\n                  shuffle = True,\r\n                  early_stopping_rounds= 10,\r\n                  verbose_eval= 5,\r\n                  seed = 0\r\n                 )\r\nprint(cv_table.shape[0])       # 105\r\n\r\n_Test AUC is around 0.74 with different seeds. Or, instead of doing cv, use watch list:_\r\nwatchlist = [(train_DM, 'train'), (test_DM, 'valid')]\r\nmodel  = xgb.train(params=params,  \r\n                   dtrain=train_DM, \r\n                   num_boost_round=2000,\r\n                   evals=watchlist,\r\n                   early_stopping_rounds=10,\r\n                   verbose_eval=5\r\n                  )   # Stopping. Best iteration:     [138]\ttrain-auc:0.802294\tvalid-auc:0.75009\r\n\r\n**Testing Codes - 2: XGBoost estimator in PySparkling**\r\ntrain = h2o.import_file( \"...HCDR_train.csv\",  sep=',')\r\ntest = h2o.import_file(\"...HCDR_test.csv\",  sep=',')\r\ntrain['TARGET'] = train['TARGET'].asfactor()\r\ntest['TARGET']  = test['TARGET'].asfactor()\r\nfeatures = [\r\n 'AMT_INCOME_TOTAL',\r\n 'AMT_CREDIT',\r\n 'AMT_ANNUITY',\r\n 'AMT_GOODS_PRICE',\r\n 'DAYS_BIRTH',\r\n 'DAYS_EMPLOYED',\r\n 'DAYS_REGISTRATION',\r\n 'DAYS_ID_PUBLISH', \r\n 'EXT_SOURCE_1',\r\n 'EXT_SOURCE_2',\r\n 'EXT_SOURCE_3',\r\n 'HOUR_APPR_PROCESS_START',\r\n 'REG_REGION_NOT_LIVE_REGION',\r\n 'REG_REGION_NOT_WORK_REGION',\r\n 'LIVE_REGION_NOT_WORK_REGION',\r\n 'REG_CITY_NOT_LIVE_CITY',\r\n 'REG_CITY_NOT_WORK_CITY',\r\n 'LIVE_CITY_NOT_WORK_CITY'\r\n]\r\nxgb_estimator = H2OXGBoostEstimator(\r\n    ntrees = 2000,\r\n    learn_rate = 0.1,\r\n    max_leaves = 60,\r\n    stopping_rounds = 10,\r\n    stopping_metric = \"AUC\",\r\n    tree_method=\"hist\",\r\n    grow_policy=\"lossguide\",\r\n    seed=0)\r\nxgb_estimator.train(x = features, y = 'TARGET', training_frame = train, validation_frame=test)\r\nprint(xgb_estimator.params['ntrees'])    # {'actual': 2000, 'default': 50} <- should be much less than 2000 \r\n\r\nprint(xgb_estimator.model_performance(train[features + ['TARGET']]).auc())\r\nprint(xgb_estimator.model_performance(test[features + ['TARGET']]).auc())  # 0.8018227468242209,  0.6965668370478819  <- cuz too many trees were built, it overfits\r\n\r\n_CV is not working properly either_:\r\ncv_xgb = H2OXGBoostEstimator(\r\n    ntrees = 2000,\r\n    learn_rate = 0.1,\r\n    max_leaves = 60,\r\n    stopping_rounds = 10,\r\n    stopping_metric = \"AUC\",\r\n    tree_method=\"hist\",\r\n    grow_policy=\"lossguide\",\r\n    nfolds=5, \r\n    seed=0)\r\ncv_xgb.train(x = features, y = 'TARGET', training_frame = train)\r\ncv_xgb.params['ntrees']  # {'actual': 2000, 'default': 50} <- should be much less than 2000 \r\n\r\nprint(cv_xgb.model_performance(train[features + ['TARGET']]).auc())\r\nprint(cv_xgb.model_performance(test[features + ['TARGET']]).auc()) # 0.8018227468242209,  0.6965668370478819\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1078", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1078/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1078/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1078/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1078", "id": 413538097, "node_id": "MDU6SXNzdWU0MTM1MzgwOTc=", "number": 1078, "title": "rsparkling connection issue using latest packages", "user": {"login": "javierluraschi", "id": 3478847, "node_id": "MDQ6VXNlcjM0Nzg4NDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/3478847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/javierluraschi", "html_url": "https://github.com/javierluraschi", "followers_url": "https://api.github.com/users/javierluraschi/followers", "following_url": "https://api.github.com/users/javierluraschi/following{/other_user}", "gists_url": "https://api.github.com/users/javierluraschi/gists{/gist_id}", "starred_url": "https://api.github.com/users/javierluraschi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/javierluraschi/subscriptions", "organizations_url": "https://api.github.com/users/javierluraschi/orgs", "repos_url": "https://api.github.com/users/javierluraschi/repos", "events_url": "https://api.github.com/users/javierluraschi/events{/privacy}", "received_events_url": "https://api.github.com/users/javierluraschi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "jakubhava", "id": 4374603, "node_id": "MDQ6VXNlcjQzNzQ2MDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4374603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubhava", "html_url": "https://github.com/jakubhava", "followers_url": "https://api.github.com/users/jakubhava/followers", "following_url": "https://api.github.com/users/jakubhava/following{/other_user}", "gists_url": "https://api.github.com/users/jakubhava/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubhava/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubhava/subscriptions", "organizations_url": "https://api.github.com/users/jakubhava/orgs", "repos_url": "https://api.github.com/users/jakubhava/repos", "events_url": "https://api.github.com/users/jakubhava/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubhava/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jakubhava", "id": 4374603, "node_id": "MDQ6VXNlcjQzNzQ2MDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4374603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubhava", "html_url": "https://github.com/jakubhava", "followers_url": "https://api.github.com/users/jakubhava/followers", "following_url": "https://api.github.com/users/jakubhava/following{/other_user}", "gists_url": "https://api.github.com/users/jakubhava/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubhava/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubhava/subscriptions", "organizations_url": "https://api.github.com/users/jakubhava/orgs", "repos_url": "https://api.github.com/users/jakubhava/repos", "events_url": "https://api.github.com/users/jakubhava/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubhava/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2019-02-22T19:08:11Z", "updated_at": "2019-02-27T13:33:22Z", "closed_at": "2019-02-27T13:33:22Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "I'm trying the following with the latest versions of `sparklyr` and `rsparkling` but hitting dependency check errors, looks related to https://github.com/h2oai/sparkling-water/issues/960:\r\n\r\n```r\r\nlibrary(sparklyr)\r\nlibrary(rsparkling)\r\nlibrary(dplyr)\r\nlibrary(h2o)\r\n\r\nsc <- spark_connect(master = \"local\", version = '2.3.2')\r\n```\r\n\r\n```\r\nSpark version 2.3 detected. Will call latest Sparkling Water version 2.3.23\r\nError in force(code) : \r\n  Failed while connecting to sparklyr to port (8880) for sessionid (90150): Gateway in localhost:8880 did not respond.\r\n    Path: /Users/javierluraschi/spark/spark-2.3.2-bin-hadoop2.7/bin/spark-submit\r\n    Parameters: --class, sparklyr.Shell, --packages, 'ai.h2o:sparkling-water-core_2.11:2.3.23','ai.h2o:sparkling-water-ml_2.11:2.3.23','ai.h2o:sparkling-water-repl_2.11:2.3.23','no.priv.garshol.duke:duke:1.2', '/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.3-2.11.jar', 8880, 90150\r\n    Log: /var/folders/ks/wm_bx4cn70s6h0r5vgqpsldm0000gn/T//RtmpFvkprS/file181ed73a9408d_spark.log\r\n\r\n\r\n---- Output Log ----\r\n\tcom.google.protobuf#protobuf-java-util;3.5.1 from central in [default]\r\n\tcom.googlecode.matrix-toolkits-java#mtj;1.0.4 from central in [default]\r\n\tcom.jamesmurty.utils#java-xmlbuilder;0.4 from central in [default]\r\n\tcom.spatial4j#spatial4j;0.3 from central in [default]\r\n\tcommons-codec#commons-codec;1.9 from central in [default]\r\n\tcommons-io#commons-io;2.4 from local-m2-cache in [default]\r\n\tcommons-lang#commons-lang;2.6 from local-m2-cache in [default]\r\n\tcommons-logging#commons-logging;1.2 from local-m2-cache in [default]\r\n\tgov.nist.math#jama;1.0.3 from central in [default]\r\n\tio.grpc#grpc-context;1.9.0 from central in [default]\r\n\tio.opencensus#opencensus-api;0.11.1 from central in [default]\r\n\tio.opencensus#opencensus-contrib-http-util;0.11.1 from central in [default]\r\n\tjavax.xml.bind#jaxb-api;2.3.0 from central in [default]\r\n\tjoda-time#joda-time;2.9.9 from central in [default]\r\n\tlog4j#log4j;1.2.17 from local-m2-cache in [default]\r\n\tnet.java.dev.jets3t#jets3t;0.9.0 from central in [default]\r\n\tnet.java.dev.jna#jna;4.0.0 from central in [default]\r\n\tnet.sf.opencsv#opencsv;2.3 from local-m2-cache in [default]\r\n\tnet.sourceforge.f2j#arpack_combined_all;0.1 from local-m2-cache in [default]\r\n\tno.priv.garshol.duke#duke;1.2 from central in [default]\r\n\torg.apache.commons#commons-math3;3.3 from central in [default]\r\n\torg.apache.httpcomponents#httpclient;4.3.6 from central in [default]\r\n\torg.apache.httpcomponents#httpcore;4.3.3 from central in [default]\r\n\torg.apache.lucene#lucene-analyzers-common;4.0.0 from central in [default]\r\n\torg.apache.lucene#lucene-core;4.0.0 from central in [default]\r\n\torg.apache.lucene#lucene-queries;4.0.0 from central in [default]\r\n\torg.apache.lucene#lucene-spatial;4.0.0 from central in [default]\r\n\torg.codehaus.jackson#jackson-core-asl;1.9.11 from central in [default]\r\n\torg.eclipse.jetty#jetty-client;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-continuation;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-http;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-io;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-jndi;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-plus;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-security;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-server;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-servlet;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-servlets;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-util;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-webapp;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty#jetty-xml;8.1.21.v20160908 from central in [default]\r\n\torg.eclipse.jetty.orbit#javax.activation;1.1.0.v201105071233 from central in [default]\r\n\torg.eclipse.jetty.orbit#javax.mail.glassfish;1.4.1.v201005082020 from central in [default]\r\n\torg.eclipse.jetty.orbit#javax.servlet;3.0.0.v201112011016 from central in [default]\r\n\torg.eclipse.jetty.orbit#javax.transaction;1.1.1.v201105210645 from central in [default]\r\n\torg.javassist#javassist;3.23.1-GA from central in [default]\r\n\torg.joda#joda-convert;1.7 from central in [default]\r\n\torg.kohsuke#libpam4j;1.8 from central in [default]\r\n\torg.mapdb#mapdb;0.9.9 from central in [default]\r\n\torg.threeten#threetenbp;1.3.3 from central in [default]\r\n\t:: evicted modules:\r\n\tcom.google.code.gson#gson;2.6.2 by [com.google.code.gson#gson;2.7] in [default]\r\n\tcom.github.fommil.netlib#core;1.1 by [com.github.fommil.netlib#core;1.1.2] in [default]\r\n\tcommons-codec#commons-codec;1.4 by [commons-codec#commons-codec;1.9] in [default]\r\n\tcommons-logging#commons-logging;1.1.1 by [commons-logging#commons-logging;1.2] in [default]\r\n\torg.apache.httpcomponents#httpclient;4.1.2 by [org.apache.httpcomponents#httpclient;4.3.6] in [default]\r\n\torg.apache.httpcomponents#httpcore;4.1.2 by [org.apache.httpcomponents#httpcore;4.3.3] in [default]\r\n\tcommons-logging#commons-logging;1.1.3 by [commons-logging#commons-logging;1.2] in [default]\r\n\tcommons-codec#commons-codec;1.6 by [commons-codec#commons-codec;1.9] in [default]\r\n\tjoda-time#joda-time;2.8.1 by [joda-time#joda-time;2.9.9] in [default]\r\n\tjoda-time#joda-time;2.9.2 by [joda-time#joda-time;2.9.9] in [default]\r\n\torg.apache.httpcomponents#httpclient;4.0.1 by [org.apache.httpcomponents#httpclient;4.3.6] in [default]\r\n\t---------------------------------------------------------------------\r\n\t|                  |            modules            ||   artifacts   |\r\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\r\n\t---------------------------------------------------------------------\r\n\t|      default     |  129  |   0   |   0   |   11  ||  118  |   0   |\r\n\t---------------------------------------------------------------------\r\n\r\n:: problems summary ::\r\n:::: WARNINGS\r\n\t\t[NOT FOUND  ] net.sourceforge.f2j#arpack_combined_all;0.1!arpack_combined_all.jar (2ms)\r\n\r\n\t==== local-m2-cache: tried\r\n\r\n\t  file:/Users/javierluraschi/.m2/repository/net/sourceforge/f2j/arpack_combined_all/0.1/arpack_combined_all-0.1-javadoc.jar\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n\r\n\t\t::              FAILED DOWNLOADS            ::\r\n\r\n\t\t:: ^ see resolution messages for details  ^ ::\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n\r\n\t\t:: net.sourceforge.f2j#arpack_combined_all;0.1!arpack_combined_all.jar\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n\r\n\r\n\r\n:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\r\nException in thread \"main\" java.lang.RuntimeException: [download failed: net.sourceforge.f2j#arpack_combined_all;0.1!arpack_combined_all.jar]\r\n\tat org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1303)\r\n\tat org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:53)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)\r\n\tat org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n\r\n---- Error Log ----\r\n```\r\n\r\n```r\r\nsessionInfo()\r\n```\r\n```\r\nR version 3.5.1 (2018-07-02)\r\nPlatform: x86_64-apple-darwin15.6.0 (64-bit)\r\nRunning under: macOS  10.14.1\r\n\r\nMatrix products: default\r\nBLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\r\nLAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib\r\n\r\nlocale:\r\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r\n\r\nattached base packages:\r\n[1] stats     graphics  grDevices utils     datasets  methods   base     \r\n\r\nother attached packages:\r\n[1] h2o_3.22.1.3      dplyr_0.8.0.9002  rsparkling_0.2.18 sparklyr_0.9.4   \r\n\r\nloaded via a namespace (and not attached):\r\n [1] Rcpp_1.0.0.3      dbplyr_1.3.0.9000 compiler_3.5.1    pillar_1.3.1      later_0.7.5       bitops_1.0-6     \r\n [7] r2d3_0.2.3        base64enc_0.1-3   tools_3.5.1       digest_0.6.18     packrat_0.4.9-3   jsonlite_1.6     \r\n[13] tibble_2.0.1      nlme_3.1-137      lattice_0.20-35   pkgconfig_2.0.2   rlang_0.3.1.9000  shiny_1.2.0      \r\n[19] DBI_1.0.0.9001    rstudioapi_0.9.0  parallel_3.5.1    yaml_2.2.0        knitr_1.20        withr_2.1.2.9000 \r\n[25] httr_1.4.0        askpass_1.1       rappdirs_0.3.1    generics_0.0.2    htmlwidgets_1.3   rprojroot_1.3-2  \r\n[31] grid_3.5.1        tidyselect_0.2.5  glue_1.3.0        forge_0.1.9002    R6_2.4.0          purrr_0.3.0      \r\n[37] tidyr_0.8.2       magrittr_1.5      backports_1.1.3   promises_1.0.1    htmltools_0.3.6   assertthat_0.2.0 \r\n[43] mime_0.6          xtable_1.8-3      httpuv_1.4.5      config_0.3        openssl_1.2.1     RCurl_1.95-4.11  \r\n[49] lazyeval_0.2.1    broom_0.5.1       crayon_1.3.4 \r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1056", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1056/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1056/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1056/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1056", "id": 403515793, "node_id": "MDU6SXNzdWU0MDM1MTU3OTM=", "number": 1056, "title": "h2o.ls() produces java.lang.ArrayIndexOutOfBoundsException: 71", "user": {"login": "Tagar", "id": 3013418, "node_id": "MDQ6VXNlcjMwMTM0MTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/3013418?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tagar", "html_url": "https://github.com/Tagar", "followers_url": "https://api.github.com/users/Tagar/followers", "following_url": "https://api.github.com/users/Tagar/following{/other_user}", "gists_url": "https://api.github.com/users/Tagar/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tagar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tagar/subscriptions", "organizations_url": "https://api.github.com/users/Tagar/orgs", "repos_url": "https://api.github.com/users/Tagar/repos", "events_url": "https://api.github.com/users/Tagar/events{/privacy}", "received_events_url": "https://api.github.com/users/Tagar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-01-27T05:28:28Z", "updated_at": "2019-02-11T14:02:00Z", "closed_at": "2019-02-11T14:02:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "After SW was upgraded to 2.3.22 (and a matching h2o backend cluster version),\r\n`h2o.ls()` started producing following exception on a freshly created session / freshly created \r\nh2o backend cluster\r\n\r\n```\r\nFail to execute line 2: h2o.ls()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/h2o.py\", line 915, in ls\r\n    return H2OFrame._expr(expr=ExprNode(\"ls\")).as_data_frame(use_pandas=True)\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/frame.py\", line 1297, in as_data_frame\r\n    return pandas.read_csv(StringIO(self.get_frame_data()), low_memory=False, skip_blank_lines=False)\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/frame.py\", line 1311, in get_frame_data\r\n    return h2o.api(\"GET /3/DownloadDataset\", data={\"frame_id\": self.frame_id, \"hex_string\": False})\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/frame.py\", line 276, in frame_id\r\n    return self._frame()._ex._cache._id\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/frame.py\", line 504, in _frame\r\n    self._ex._eager_frame()\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/expr.py\", line 95, in _eager_frame\r\n    self._eval_driver(True)\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/expr.py\", line 113, in _eval_driver\r\n    res = ExprNode.rapids(exec_str)\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/expr.py\", line 241, in rapids\r\n    return h2o.api(\"POST /99/Rapids\", data={\"ast\": expr, \"session_id\": h2o.connection().session_id})\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/h2o.py\", line 104, in api\r\n    return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/backend/connection.py\", line 407, in request\r\n    return self._process_response(resp, save_to)\r\n  File \"/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/h2o/backend/connection.py\", line 748, in _process_response\r\n    raise H2OServerError(\"HTTP %d %s:\\n%r\" % (status_code, response.reason, data))\r\nH2OServerError: HTTP 500 Server Error:\r\nServer error java.lang.RuntimeException:\r\n  Error: DistributedException from pc1udatahad30/10.20.33.144:55099: '71', caused by java.lang.ArrayIndexOutOfBoundsException: 71\r\n  Request: None\r\n\r\n```\r\n\r\nSW (PySpark) connects to a h2o backend cluster.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1008", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1008/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1008/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/1008/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/1008", "id": 391926920, "node_id": "MDU6SXNzdWUzOTE5MjY5MjA=", "number": 1008, "title": "h2o_pysparkling_2.4 - for Spark 2.4.x", "user": {"login": "dvanasseldonk", "id": 39174311, "node_id": "MDQ6VXNlcjM5MTc0MzEx", "avatar_url": "https://avatars0.githubusercontent.com/u/39174311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dvanasseldonk", "html_url": "https://github.com/dvanasseldonk", "followers_url": "https://api.github.com/users/dvanasseldonk/followers", "following_url": "https://api.github.com/users/dvanasseldonk/following{/other_user}", "gists_url": "https://api.github.com/users/dvanasseldonk/gists{/gist_id}", "starred_url": "https://api.github.com/users/dvanasseldonk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dvanasseldonk/subscriptions", "organizations_url": "https://api.github.com/users/dvanasseldonk/orgs", "repos_url": "https://api.github.com/users/dvanasseldonk/repos", "events_url": "https://api.github.com/users/dvanasseldonk/events{/privacy}", "received_events_url": "https://api.github.com/users/dvanasseldonk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-17T23:03:56Z", "updated_at": "2018-12-20T07:01:12Z", "closed_at": "2018-12-17T23:52:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "is \r\nh2o_pysparkling_2.4 - for Spark 2.4.x\r\ncurrently available on pip?\r\n\r\nI am having issues installing it", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/985", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/985/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/985/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/985/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/985", "id": 378269201, "node_id": "MDU6SXNzdWUzNzgyNjkyMDE=", "number": 985, "title": "DRF training is not really distributed", "user": {"login": "RefiPeretz", "id": 12611928, "node_id": "MDQ6VXNlcjEyNjExOTI4", "avatar_url": "https://avatars1.githubusercontent.com/u/12611928?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RefiPeretz", "html_url": "https://github.com/RefiPeretz", "followers_url": "https://api.github.com/users/RefiPeretz/followers", "following_url": "https://api.github.com/users/RefiPeretz/following{/other_user}", "gists_url": "https://api.github.com/users/RefiPeretz/gists{/gist_id}", "starred_url": "https://api.github.com/users/RefiPeretz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RefiPeretz/subscriptions", "organizations_url": "https://api.github.com/users/RefiPeretz/orgs", "repos_url": "https://api.github.com/users/RefiPeretz/repos", "events_url": "https://api.github.com/users/RefiPeretz/events{/privacy}", "received_events_url": "https://api.github.com/users/RefiPeretz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-07T12:34:36Z", "updated_at": "2018-11-11T08:50:37Z", "closed_at": "2018-11-11T08:50:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm ruining on Spark 1.6 , sparkling water: 2.1 trying to train DRF model in yarn mode internal server mode.\r\nAfter  some research I mange to read h2o client logs which gives you some idea on H2O progress while running.\r\n\r\nFor our case I have 10 executors devoted for the job. \r\nWhen I trying to asses which work is done in each executor it seems none of the executors except one(which hold the flow UI web) participating in the training process. \r\nI can't find any h2o log in these executors.\r\nWhen I'm looking in the log of the flow UI machine I can see the progress of the training for example:\r\n![image](https://user-images.githubusercontent.com/12611928/48131593-4d53a080-e299-11e8-9314-db2c720e9484.png)\r\n\r\nInspecting the log validates my concerns, since the creation of the trees suppose to be independent and distributed I was expecting to see bunch of trees created simultaneously. Looking on this log and tree creation timestamps it seems the trees created linearly and only on one machine.\r\nIf you need more info I would be happy to some guidance where I can find it.\r\n\r\nAny idea what is happen here? Maybe there is some configuration I missed?\r\n\r\n`11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO: Model Summary:\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:               92                       92            63385102         20         20   20.00000       52928       56600 54884.34766\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO: Scoring History:\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:            Timestamp          Duration Number of Trees Training RMSE Training MAE Training Deviance\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:53:12         0.188 sec               0           NaN          NaN               NaN\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:54:35  1 min 23.198 sec               1       0.38238      0.22723           0.14621\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:55:53  2 min 41.497 sec               2       0.37699      0.22670           0.14212\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:57:10  3 min 57.828 sec               3       0.37230      0.22662           0.13860\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:58:30  5 min 18.481 sec               4       0.36841      0.22668           0.13573\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:59:47  6 min 35.201 sec               5       0.36480      0.22662           0.13308\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 05:01:02  7 min 50.472 sec               6       0.36166      0.22666           0.13080\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 05:02:15  9 min  2.837 sec               7       0.35876      0.22668           0.12871\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 05:03:35 10 min 22.740 sec               8       0.35637      0.22666           0.12700\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 05:04:51 11 min 39.404 sec               9       0.35429      0.22663           0.12552\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO: ---\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:43:02       1:49:50.508              83       0.33850      0.22658           0.11458\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:44:20       1:51:07.841              84       0.33848      0.22657           0.11457\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:45:40       1:52:27.943              85       0.33846      0.22657           0.11455\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:46:59       1:53:46.691              86       0.33843      0.22657           0.11454\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:48:17       1:55:05.156              87       0.33842      0.22657           0.11453\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:49:36       1:56:24.202              88       0.33840      0.22657           0.11451\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:50:54       1:57:42.127              89       0.33838      0.22657           0.11450\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:52:12       1:58:59.949              90       0.33837      0.22657           0.11449\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:53:34       2:00:22.198              91       0.33835      0.22657           0.11448\r\n11-07 06:54:48.956 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:54:48       2:01:36.566              92       0.33834      0.22658           0.11447\r\n11-07 06:56:08.219 10.10.236.117:54321   66310  FJ-1-7    INFO: 93. tree was built in 00:01:19.259 (Wall: 07-Nov 06:56:08.218)\r\n11-07 06:56:08.236 10.10.236.117:54321   66310  FJ-1-7    INFO: ==============================================================\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO: Model Metrics Type: Regression\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  Description: Metrics reported on Out-Of-Bag training samples\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  model id: DRF_model_1541584225605_1\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  frame id: frame_rdd_20_9f76692aa179944982973aed605545b4\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  MSE: 0.11446071\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  RMSE: 0.33832043\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  mean residual deviance: 0.11446071\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  mean absolute error: 0.22657463\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  root mean squared log error: 0.2371628\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO: Variable Importances:\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:               Variable Relative Importance Scaled Importance Percentage\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:     max_domain_fg_prop     21002234.000000          1.000000   0.785118\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:   log_session_ip_count       933733.250000          0.044459   0.034905\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO: app_log_ip_count_delta       929603.875000          0.044262   0.034751\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:    log_session_ip_rate       805776.687500          0.038366   0.030122\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:           log_ip_count       753496.937500          0.035877   0.028168\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:       app_domain_delta       679922.687500          0.032374   0.025417\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:        unique_ip_ratio       542801.812500          0.025845   0.020291\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:          log_unique_ip       496994.843750          0.023664   0.018579\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:          unique_domain       389672.031250          0.018554   0.014567\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  session_unique_domain       216181.984375          0.010293   0.008081\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:       is_10min_session            0.000000          0.000000   0.000000\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO: Model Summary:\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  Number of Trees Number of Internal Trees Model Size in Bytes Min. Depth Max. Depth Mean Depth Min. Leaves Max. Leaves Mean Leaves\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:               93                       93            64082409         20         20   20.00000       52928       56600 54891.53906\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO: Scoring History:\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:            Timestamp          Duration Number of Trees Training RMSE Training MAE Training Deviance\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:53:12         0.188 sec               0           NaN          NaN               NaN\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:54:35  1 min 23.198 sec               1       0.38238      0.22723           0.14621\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:55:53  2 min 41.497 sec               2       0.37699      0.22670           0.14212\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:57:10  3 min 57.828 sec               3       0.37230      0.22662           0.13860\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:58:30  5 min 18.481 sec               4       0.36841      0.22668           0.13573\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 04:59:47  6 min 35.201 sec               5       0.36480      0.22662           0.13308\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 05:01:02  7 min 50.472 sec               6       0.36166      0.22666           0.13080\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 05:02:15  9 min  2.837 sec               7       0.35876      0.22668           0.12871\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 05:03:35 10 min 22.740 sec               8       0.35637      0.22666           0.12700\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 05:04:51 11 min 39.404 sec               9       0.35429      0.22663           0.12552\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO: ---\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:44:20       1:51:07.841              84       0.33848      0.22657           0.11457\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:45:40       1:52:27.943              85       0.33846      0.22657           0.11455\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:46:59       1:53:46.691              86       0.33843      0.22657           0.11454\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:48:17       1:55:05.156              87       0.33842      0.22657           0.11453\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:49:36       1:56:24.202              88       0.33840      0.22657           0.11451\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:50:54       1:57:42.127              89       0.33838      0.22657           0.11450\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:52:12       1:58:59.949              90       0.33837      0.22657           0.11449\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:53:34       2:00:22.198              91       0.33835      0.22657           0.11448\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:54:48       2:01:36.566              92       0.33834      0.22658           0.11447\r\n11-07 06:56:08.283 10.10.236.117:54321   66310  FJ-1-7    INFO:  2018-11-07 06:56:08       2:02:55.894              93       0.33832      0.22657           0.11446\r\n`\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/976", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/976/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/976/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/976/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/976", "id": 371662696, "node_id": "MDU6SXNzdWUzNzE2NjI2OTY=", "number": 976, "title": "SW 2.3.16 release broken when connecting to h2o backend cluster? java.util.NoSuchElementException: None.get", "user": {"login": "Tagar", "id": 3013418, "node_id": "MDQ6VXNlcjMwMTM0MTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/3013418?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Tagar", "html_url": "https://github.com/Tagar", "followers_url": "https://api.github.com/users/Tagar/followers", "following_url": "https://api.github.com/users/Tagar/following{/other_user}", "gists_url": "https://api.github.com/users/Tagar/gists{/gist_id}", "starred_url": "https://api.github.com/users/Tagar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Tagar/subscriptions", "organizations_url": "https://api.github.com/users/Tagar/orgs", "repos_url": "https://api.github.com/users/Tagar/repos", "events_url": "https://api.github.com/users/Tagar/events{/privacy}", "received_events_url": "https://api.github.com/users/Tagar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-10-18T18:49:35Z", "updated_at": "2018-10-18T20:17:20Z", "closed_at": "2018-10-18T20:16:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Just upgraded to SW to 2.3.16 and couldn't connect to backend h2o external cluster anymore.\r\n\r\n```\r\nTraceback (most recent call last)\r\n<ipython-input-6-c37d158031d0> in <module>()\r\n     15             ## .set(\"spark.ext.h2o.cloud.representative\", \"10.210.44.109:33105\")\r\n     16         )\r\n---> 17 hc = H2OContext.getOrCreate(spark, conf)\r\n\r\n/opt/cloudera/parcels/Anaconda/lib/python2.7/site-packages/pysparkling/context.pyc in getOrCreate(spark, conf, verbose, pre_create_hook, h2o_connect_hook, **kwargs)\r\n    159 \r\n    160         # Create backing Java H2OContext\r\n--> 161         jhc = jvm.org.apache.spark.h2o.JavaH2OContext.getOrCreate(jspark_session, selected_conf._jconf)\r\n    162         h2o_context._jhc = jhc\r\n    163         h2o_context._conf = selected_conf\r\n\r\n/opt/cloudera/parcels/SPARK2-2.3.0.cloudera3-1.cdh5.13.3.p0.458809/lib/spark2/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)\r\n   1255         answer = self.gateway_client.send_command(command)\r\n   1256         return_value = get_return_value(\r\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\r\n   1258 \r\n   1259         for temp_arg in temp_args:\r\n\r\n/opt/cloudera/parcels/SPARK2-2.3.0.cloudera3-1.cdh5.13.3.p0.458809/lib/spark2/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\r\n     61     def deco(*a, **kw):\r\n     62         try:\r\n---> 63             return f(*a, **kw)\r\n     64         except py4j.protocol.Py4JJavaError as e:\r\n     65             s = e.java_exception.toString()\r\n\r\n/opt/cloudera/parcels/SPARK2-2.3.0.cloudera3-1.cdh5.13.3.p0.458809/lib/spark2/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\r\n    326                 raise Py4JJavaError(\r\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\r\n--> 328                     format(target_id, \".\", name), value)\r\n    329             else:\r\n    330                 raise Py4JError(\r\n\r\nPy4JJavaError: An error occurred while calling z:org.apache.spark.h2o.JavaH2OContext.getOrCreate.\r\n: java.util.NoSuchElementException: None.get\r\n\tat scala.None$.get(Option.scala:347)\r\n\tat scala.None$.get(Option.scala:345)\r\n\tat org.apache.spark.h2o.backends.SharedBackendUtils$$anonfun$getH2OClientArgsLocalNode$4.apply(SharedBackendUtils.scala:148)\r\n\tat org.apache.spark.h2o.backends.SharedBackendUtils$$anonfun$getH2OClientArgsLocalNode$4.apply(SharedBackendUtils.scala:148)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.h2o.backends.SharedBackendUtils$class.getH2OClientArgsLocalNode(SharedBackendUtils.scala:148)\r\n\tat org.apache.spark.h2o.backends.external.ExternalH2OBackend.getH2OClientArgsLocalNode(ExternalH2OBackend.scala:38)\r\n\tat org.apache.spark.h2o.backends.SharedBackendUtils$class.getH2OClientArgs(SharedBackendUtils.scala:156)\r\n\tat org.apache.spark.h2o.backends.external.ExternalH2OBackend.org$apache$spark$h2o$backends$external$ExternalBackendUtils$$super$getH2OClientArgs(ExternalH2OBackend.scala:38)\r\n\tat org.apache.spark.h2o.backends.external.ExternalBackendUtils$class.getH2OClientArgs(ExternalBackendUtils.scala:37)\r\n\tat org.apache.spark.h2o.backends.external.ExternalH2OBackend.getH2OClientArgs(ExternalH2OBackend.scala:38)\r\n\tat org.apache.spark.h2o.backends.external.ExternalH2OBackend.init(ExternalH2OBackend.scala:195)\r\n\tat org.apache.spark.h2o.H2OContext.init(H2OContext.scala:130)\r\n\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:401)\r\n\tat org.apache.spark.h2o.H2OContext.getOrCreate(H2OContext.scala)\r\n\tat org.apache.spark.h2o.JavaH2OContext.getOrCreate(JavaH2OContext.java:261)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.zeppelin.py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\r\n\tat org.apache.zeppelin.py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\r\n\tat org.apache.zeppelin.py4j.Gateway.invoke(Gateway.java:290)\r\n\tat org.apache.zeppelin.py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\r\n\tat org.apache.zeppelin.py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat org.apache.zeppelin.py4j.GatewayConnection.run(GatewayConnection.java:209)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/970", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/970/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/970/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/970/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/970", "id": 369635975, "node_id": "MDU6SXNzdWUzNjk2MzU5NzU=", "number": 970, "title": "Support for lime in PySparkling", "user": {"login": "FavioVazquez", "id": 10162068, "node_id": "MDQ6VXNlcjEwMTYyMDY4", "avatar_url": "https://avatars2.githubusercontent.com/u/10162068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/FavioVazquez", "html_url": "https://github.com/FavioVazquez", "followers_url": "https://api.github.com/users/FavioVazquez/followers", "following_url": "https://api.github.com/users/FavioVazquez/following{/other_user}", "gists_url": "https://api.github.com/users/FavioVazquez/gists{/gist_id}", "starred_url": "https://api.github.com/users/FavioVazquez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/FavioVazquez/subscriptions", "organizations_url": "https://api.github.com/users/FavioVazquez/orgs", "repos_url": "https://api.github.com/users/FavioVazquez/repos", "events_url": "https://api.github.com/users/FavioVazquez/events{/privacy}", "received_events_url": "https://api.github.com/users/FavioVazquez/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-10-12T17:09:52Z", "updated_at": "2018-10-14T01:07:27Z", "closed_at": "2018-10-14T01:07:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi everyone. Just a quick question. Is there support for lime and its API for models in PySpakling? Let's say I run something close to the examples here: https://github.com/h2oai/sparkling-water/blob/master/py/examples/pipelines/ham_or_spam_multi_algo.py can I use Lime afterwards? \r\n\r\nThanks. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/960", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/960/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/960/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/960/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/960", "id": 366382724, "node_id": "MDU6SXNzdWUzNjYzODI3MjQ=", "number": 960, "title": "Could not create spark connection using rsparkling", "user": {"login": "ravirajuv", "id": 35996663, "node_id": "MDQ6VXNlcjM1OTk2NjYz", "avatar_url": "https://avatars3.githubusercontent.com/u/35996663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ravirajuv", "html_url": "https://github.com/ravirajuv", "followers_url": "https://api.github.com/users/ravirajuv/followers", "following_url": "https://api.github.com/users/ravirajuv/following{/other_user}", "gists_url": "https://api.github.com/users/ravirajuv/gists{/gist_id}", "starred_url": "https://api.github.com/users/ravirajuv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ravirajuv/subscriptions", "organizations_url": "https://api.github.com/users/ravirajuv/orgs", "repos_url": "https://api.github.com/users/ravirajuv/repos", "events_url": "https://api.github.com/users/ravirajuv/events{/privacy}", "received_events_url": "https://api.github.com/users/ravirajuv/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2018-10-03T14:57:37Z", "updated_at": "2018-10-17T14:31:36Z", "closed_at": "2018-10-03T15:04:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "Providing us with the observed and expected behavior definitely helps. Giving us with the following information definitively helps:\r\n\r\n- Sparkling Water/PySparkling/RSparkling version\r\n- Hadoop Version & Distribution\r\n- Execution mode `YARN-client`, `YARN-cluster`, standalone, local ..\r\n- YARN logs in case of running on yarn. To collect such a logs you may run `yarn logs -applicationId <application ID>` where the application ID is displayed when Sparkling Water is started\r\n- H2O & Spark logs if not running on YARN. You can find these logs in Spark work directory\r\n- Are you using Windows/Linux/MAC?\r\n- Spark & Sparkling Water configuration including the memory configuration\r\n\r\nPlease also provide us with the full and minimal reproducible code.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/959", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/959/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/959/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/959/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/959", "id": 366084402, "node_id": "MDU6SXNzdWUzNjYwODQ0MDI=", "number": 959, "title": "RSparkling unresolved dependencies ai.h2o#mojo2-runtime-api;0.13.2: not found", "user": {"login": "ndegara", "id": 10181087, "node_id": "MDQ6VXNlcjEwMTgxMDg3", "avatar_url": "https://avatars2.githubusercontent.com/u/10181087?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ndegara", "html_url": "https://github.com/ndegara", "followers_url": "https://api.github.com/users/ndegara/followers", "following_url": "https://api.github.com/users/ndegara/following{/other_user}", "gists_url": "https://api.github.com/users/ndegara/gists{/gist_id}", "starred_url": "https://api.github.com/users/ndegara/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ndegara/subscriptions", "organizations_url": "https://api.github.com/users/ndegara/orgs", "repos_url": "https://api.github.com/users/ndegara/repos", "events_url": "https://api.github.com/users/ndegara/events{/privacy}", "received_events_url": "https://api.github.com/users/ndegara/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-10-02T21:19:32Z", "updated_at": "2018-10-03T14:44:58Z", "closed_at": "2018-10-02T21:40:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "Could anyone help with this please? I'm trying to install rsparkling as described in:\r\nhttps://github.com/h2oai/sparkling-water/tree/master/r\r\n\r\nHowever I get the following error:\r\n\r\n::          UNRESOLVED DEPENDENCIES         ::\r\n\r\n:: ai.h2o#mojo2-runtime-api;0.13.2: not found\r\n\r\nThis is the information about the system and versions:\r\n- rsparkling_0.2.10\r\n- observed in yarn-client and also local\r\n- h2o, spark and sparkling water versions according to rsparkling::h2o_release_table()\r\nSpark_Version: 2.3.1\r\nSparkling_Water_Version: 2.3.15\r\nH2O_Version: 3.20.0.9\r\n\r\nThis is the sessionInfo():\r\n```\r\nR version 3.4.1 (2017-06-30)\r\nPlatform: x86_64-redhat-linux-gnu (64-bit)\r\nRunning under: Amazon Linux AMI 2018.03\r\n\r\nMatrix products: default\r\nBLAS/LAPACK: /usr/lib64/R/lib/libRblas.so\r\n\r\nlocale:\r\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \r\n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C                 \r\n [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \r\n\r\nattached base packages:\r\n[1] stats     graphics  grDevices utils     datasets  methods   base     \r\n\r\nother attached packages:\r\n[1] rsparkling_0.2.10 sparklyr_0.9.1   \r\n\r\nloaded via a namespace (and not attached):\r\n [1] Rcpp_0.12.19     dbplyr_1.2.2     compiler_3.4.1   pillar_1.3.0     later_0.7.5      bindr_0.1.1     \r\n [7] bitops_1.0-6     r2d3_0.2.2       base64enc_0.1-3  tools_3.4.1      digest_0.6.17    jsonlite_1.5    \r\n[13] tibble_1.4.2     nlme_3.1-131     lattice_0.20-35  pkgconfig_2.0.2  rlang_0.2.2      shiny_1.1.0     \r\n[19] DBI_1.0.0        rstudioapi_0.7   parallel_3.4.1   yaml_2.2.0       bindrcpp_0.2.2   withr_2.1.2     \r\n[25] dplyr_0.7.6      httr_1.3.1       rappdirs_0.3.1   htmlwidgets_1.3  rprojroot_1.3-2  grid_3.4.1      \r\n[31] tidyselect_0.2.4 glue_1.3.0       forge_0.1.0      R6_2.2.2         h2o_3.20.0.9     purrr_0.2.5     \r\n[37] tidyr_0.8.1      magrittr_1.5     backports_1.1.2  promises_1.0.1   htmltools_0.3.6  assertthat_0.2.0\r\n[43] mime_0.5         xtable_1.8-3     httpuv_1.4.5     config_0.3       openssl_1.0.2    RCurl_1.95-4.11 \r\n[49] lazyeval_0.2.1   broom_0.5.0      crayon_1.3.4    \r\n```\r\n\r\n\r\nThis is a log of the error I get according to the following code:\r\n```\r\n> library(sparklyr)\r\n> options(rsparkling.sparklingwater.version = \"2.3.15\")\r\n> library(rsparkling)\r\n> sc <- spark_connect(master = \"yarn-client\", spark_home = '/usr/lib/spark')\r\n\r\n\r\n.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:53)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)\r\n\tat org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n\r\n---- Error Log ----\r\n> sc <- spark_connect(master = \"yarn-client\", spark_home = '/usr/lib/spark')\r\nError in force(code) : \r\n  Failed while connecting to sparklyr to port (8880) for sessionid (79922): Gateway in localhost:8880 did not respond.\r\n    Path: /usr/lib/spark/bin/spark-submit\r\n    Parameters: --class, sparklyr.Shell, --packages, 'ai.h2o:sparkling-water-core_2.11:2.3.15','ai.h2o:sparkling-water-ml_2.11:2.3.15','ai.h2o:sparkling-water-repl_2.11:2.3.15','no.priv.garshol.duke:duke:1.2', '/home/ndegara/R/x86_64-redhat-linux-gnu-library/3.4/sparklyr/java/sparklyr-2.3-2.11.jar', 8880, 79922\r\n    Log: /tmp/Rtmp512jiH/file15bd72d2fd738_spark.log\r\n\r\n\r\n---- Output Log ----\r\n\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\r\n\torg.eclipse.jetty#jetty-continuation;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-http;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-io;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-jndi;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-plus;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-security;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-server;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-servlet;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-util;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-webapp;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty#jetty-xml;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty.aggregate#jetty-servlet;8.1.17.v20150415 from central in [default]\r\n\torg.eclipse.jetty.orbit#javax.activation;1.1.0.v201105071233 from central in [default]\r\n\torg.eclipse.jetty.orbit#javax.mail.glassfish;1.4.1.v201005082020 from central in [default]\r\n\torg.eclipse.jetty.orbit#javax.servlet;3.0.0.v201112011016 from central in [default]\r\n\torg.eclipse.jetty.orbit#javax.transaction;1.1.1.v201105210645 from central in [default]\r\n\torg.fusesource.leveldbjni#leveldbjni-all;1.8 from central in [default]\r\n\torg.javassist#javassist;3.18.2-GA from central in [default]\r\n\torg.joda#joda-convert;1.7 from central in [default]\r\n\torg.kohsuke#libpam4j;1.8 from central in [default]\r\n\torg.mapdb#mapdb;0.9.9 from central in [default]\r\n\torg.mortbay.jetty#jetty;6.1.26 from central in [default]\r\n\torg.mortbay.jetty#jetty-util;6.1.26 from central in [default]\r\n\txerces#xercesImpl;2.9.1 from central in [default]\r\n\txml-apis#xml-apis;1.3.04 from central in [default]\r\n\txmlenc#xmlenc;0.52 from central in [default]\r\n\t:: evicted modules:\r\n\tcom.github.fommil.netlib#core;1.1 by [com.github.fommil.netlib#core;1.1.2] in [default]\r\n\tcommons-codec#commons-codec;1.4 by [commons-codec#commons-codec;1.6] in [default]\r\n\tcommons-logging#commons-logging;1.1.1 by [commons-logging#commons-logging;1.2] in [default]\r\n\torg.apache.httpcomponents#httpclient;4.1.2 by [org.apache.httpcomponents#httpclient;4.3.6] in [default]\r\n\torg.apache.httpcomponents#httpcore;4.1.2 by [org.apache.httpcomponents#httpcore;4.3.3] in [default]\r\n\tcom.google.guava#guava;11.0.2 by [com.google.guava#guava;16.0.1] in [default]\r\n\tcommons-logging#commons-logging;1.1.3 by [commons-logging#commons-logging;1.2] in [default]\r\n\tjoda-time#joda-time;2.8.1 by [joda-time#joda-time;2.9.9] in [default]\r\n\t---------------------------------------------------------------------\r\n\t|                  |            modules            ||   artifacts   |\r\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\r\n\t---------------------------------------------------------------------\r\n\t|      default     |  113  |   0   |   0   |   8   ||  104  |   0   |\r\n\t---------------------------------------------------------------------\r\n\r\n:: problems summary ::\r\n:::: WARNINGS\r\n\t\tmodule not found: ai.h2o#mojo2-runtime-api;0.13.2\r\n\r\n\t==== local-m2-cache: tried\r\n\r\n\t  file:/home/ndegara/.m2/repository/ai/h2o/mojo2-runtime-api/0.13.2/mojo2-runtime-api-0.13.2.pom\r\n\r\n\t  -- artifact ai.h2o#mojo2-runtime-api;0.13.2!mojo2-runtime-api.jar:\r\n\r\n\t  file:/home/ndegara/.m2/repository/ai/h2o/mojo2-runtime-api/0.13.2/mojo2-runtime-api-0.13.2.jar\r\n\r\n\t==== local-ivy-cache: tried\r\n\r\n\t  /home/ndegara/.ivy2/local/ai.h2o/mojo2-runtime-api/0.13.2/ivys/ivy.xml\r\n\r\n\t  -- artifact ai.h2o#mojo2-runtime-api;0.13.2!mojo2-runtime-api.jar:\r\n\r\n\t  /home/ndegara/.ivy2/local/ai.h2o/mojo2-runtime-api/0.13.2/jars/mojo2-runtime-api.jar\r\n\r\n\t==== central: tried\r\n\r\n\t  https://repo1.maven.org/maven2/ai/h2o/mojo2-runtime-api/0.13.2/mojo2-runtime-api-0.13.2.pom\r\n\r\n\t  -- artifact ai.h2o#mojo2-runtime-api;0.13.2!mojo2-runtime-api.jar:\r\n\r\n\t  https://repo1.maven.org/maven2/ai/h2o/mojo2-runtime-api/0.13.2/mojo2-runtime-api-0.13.2.jar\r\n\r\n\t==== spark-packages: tried\r\n\r\n\t  http://dl.bintray.com/spark-packages/maven/ai/h2o/mojo2-runtime-api/0.13.2/mojo2-runtime-api-0.13.2.pom\r\n\r\n\t  -- artifact ai.h2o#mojo2-runtime-api;0.13.2!mojo2-runtime-api.jar:\r\n\r\n\t  http://dl.bintray.com/spark-packages/maven/ai/h2o/mojo2-runtime-api/0.13.2/mojo2-runtime-api-0.13.2.jar\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n\r\n\t\t::          UNRESOLVED DEPENDENCIES         ::\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n\r\n\t\t:: ai.h2o#mojo2-runtime-api;0.13.2: not found\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n\r\n\r\n\r\n:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\r\nException in thread \"main\" java.lang.RuntimeException: [unresolved dependency: ai.h2o#mojo2-runtime-api;0.13.2: not found]\r\n\tat org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1303)\r\n\tat org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:53)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)\r\n\tat org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n\r\n---- Error Log ----\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/949", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/949/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/949/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/949/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/949", "id": 364051673, "node_id": "MDU6SXNzdWUzNjQwNTE2NzM=", "number": 949, "title": "rsparkling error with spark 2.2.1", "user": {"login": "rajkumarraibis", "id": 29438959, "node_id": "MDQ6VXNlcjI5NDM4OTU5", "avatar_url": "https://avatars1.githubusercontent.com/u/29438959?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rajkumarraibis", "html_url": "https://github.com/rajkumarraibis", "followers_url": "https://api.github.com/users/rajkumarraibis/followers", "following_url": "https://api.github.com/users/rajkumarraibis/following{/other_user}", "gists_url": "https://api.github.com/users/rajkumarraibis/gists{/gist_id}", "starred_url": "https://api.github.com/users/rajkumarraibis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rajkumarraibis/subscriptions", "organizations_url": "https://api.github.com/users/rajkumarraibis/orgs", "repos_url": "https://api.github.com/users/rajkumarraibis/repos", "events_url": "https://api.github.com/users/rajkumarraibis/events{/privacy}", "received_events_url": "https://api.github.com/users/rajkumarraibis/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2018-09-26T14:14:25Z", "updated_at": "2018-10-02T01:39:28Z", "closed_at": "2018-09-27T09:59:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "We are trying to run rsparkling on AWS EMR 5.11.1 , spark 2.2.1\r\nFollowing is the code\r\n> library(sparklyr)\r\n> options(rsparkling.sparklingwater.version = \"2.2.19\")\r\n> library(rsparkling)\r\n> sessionInfo()\r\nR version 3.4.1 (2017-06-30)\r\nPlatform: x86_64-redhat-linux-gnu (64-bit)\r\nRunning under: Amazon Linux AMI 2017.09\r\nother attached packages:\r\nrsparkling_0.2.9 sparklyr_0.8.4  \r\n#EMR already has spark 2.2.1 , no need to install\r\n> Sys.setenv(SPARK_HOME = \"/usr/lib/spark\")\r\n> Sys.setenv(SPARK_DIST_CLASSPATH = \"/usr/lib/hadoop:/usr/lib/hadoop/lib\")\r\n \r\n> conf <- spark_config()\r\n> conf$`spark.ext.h2o.cloud.representative`=\"<CoreNodeIP>\"\r\n> conf$`spark.ext.h2o.node.port.base`=54323\r\n> spark.ext.h2o.client.ip=\"<CoreNodeIP>\"\r\n> conf$`spark.ext.h2o.node.port.base`=54323\r\n> conf$`spark.ext.h2o.client.port.base`=54323\r\n> conf$`spark.ext.h2o.external.start.mode`=\"manual\"\r\n> conf$`spark.ext.h2o.backend.cluster.mode`=\"external\"\r\n> conf$`spark.ext.h2o.cloud.name`=\"h2osparklingcloud\"\r\n> conf$`spark.ext.h2o.spark.version.check.enabled`=\"false\"\r\n> conf$`spark.ext.h2o.internal_security_conf`=\"/mnt/opt/h2o-sparkling/security.properties\"\r\n> conf$`spark.ext.h2o.context.path`=\"h2o-sparkling\"\r\n> sc <- spark_connect(master = \"yarn-client\", config = conf , version = \"2.2.1\")\r\nError in force(code) : \r\n  Failed while connecting to sparklyr to port (8880) for sessionid (1749): Gateway in port (8880) did not respond.\r\n    Path: /usr/lib/spark/bin/spark-submit\r\n    Parameters: --class, sparklyr.Shell, --packages, 'ai.h2o:sparkling-water-core_2.11:2.2.19','ai.h2o:sparkling-water-ml_2.11:2.2.19','ai.h2o:sparkling-water-repl_2.11:2.2.19','no.priv.garshol.duke:duke:1.2', \r\n\t'/mnt/usr/lib64/R/library/sparklyr/java/sparklyr-2.2-2.11.jar', 8880, 1749\r\n    Log: /tmp/RtmpLDfEkG/file2ed9221cc4b7_spark.log\r\n\r\n**Getting following error**\r\n:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\r\nException in thread \"main\" java.lang.RuntimeException: [unresolved dependency: ai.h2o#sparkling-water-core_2.11;2.2.19: not found, unresolved dependency: ai.h2o#sparkling-water-ml_2.11;2.2.19: not found, unresolved dependency: \r\nai.h2o#sparkling-water-repl_2.11;2.2.19: not found, unresolved dependency: no.priv.garshol.duke#duke;1.2: not found]\r\n\tat org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1197)\r\n\tat org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:304)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:153)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n\r\nSimilar code is running fine in EMR 5.15 , Spark  2.3.0 .\r\n\r\nAny help would be appreciated.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/920", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/920/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/920/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/920/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/920", "id": 359553649, "node_id": "MDU6SXNzdWUzNTk1NTM2NDk=", "number": 920, "title": "sparklingWater - local class incompatible / cloud size under ###", "user": {"login": "hugoJuhel", "id": 22279443, "node_id": "MDQ6VXNlcjIyMjc5NDQz", "avatar_url": "https://avatars0.githubusercontent.com/u/22279443?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hugoJuhel", "html_url": "https://github.com/hugoJuhel", "followers_url": "https://api.github.com/users/hugoJuhel/followers", "following_url": "https://api.github.com/users/hugoJuhel/following{/other_user}", "gists_url": "https://api.github.com/users/hugoJuhel/gists{/gist_id}", "starred_url": "https://api.github.com/users/hugoJuhel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hugoJuhel/subscriptions", "organizations_url": "https://api.github.com/users/hugoJuhel/orgs", "repos_url": "https://api.github.com/users/hugoJuhel/repos", "events_url": "https://api.github.com/users/hugoJuhel/events{/privacy}", "received_events_url": "https://api.github.com/users/hugoJuhel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-09-12T16:12:13Z", "updated_at": "2018-10-22T07:24:58Z", "closed_at": "2018-10-22T07:22:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "Set up\r\n----------\r\n\r\nI'm running into troubles setupping sparkling-water on a standalone spark-cluster.  \r\nI have a two-nodes and one master Spark cluster deployed on the top of a kubernetes cluster.  \r\nI have been able to connect Python / R to my remote Spark cluster and perform several Spark operations.\r\nSo I'm pretty sure that my spark cluster is properly working. \r\n\r\n    Alive Workers: 2\r\n    Cores in use: 8 Total, 8 Used\r\n    Memory in use: 29.3 GB Total, 28.0 GB Used\r\n\r\nI'm using the following Spark / H20 configuration with Sparkpling Water 2.1.35\r\n\r\n    Spark master (MASTER)     : spark://spark-master:7077\r\n    Spark home   (SPARK_HOME) : C:\\spark-2.1.3-bin-hadoop2.6\r\n    H2O build version         : 3.20.0.4 (wright)\r\n    Spark build version       : 2.1.3\r\n    Scala version             : 2.11\r\n\r\nAccording to [this table][1], all versions should be compatible. \r\n\r\nProblem\r\n----------\r\nI have followed [this][2] tutorial, to set up pysparkling. However, none of the two provided ways to deploy sparkling-water work for me.\r\n\r\n### Using `bin/pysparkling` ###\r\nIf i use the `bin/pysparkling` shell, I run into `java.lang.RuntimeException: Cloud size under xxx` error.\r\n\r\nI have followed [this thread][3], and tried to twick the pysparkling command in several ways. I have also disabled the dynamic allocation in spark.\r\n    \r\n    bin/pysparkling --master spark://spark-master:70177 \r\n    --conf \"spark.dynamicAllocation.enabled=false\" \r\n    --num-executors 1 --executor-cores 1 --executor-memory 8G \r\n    --driver-memory 4G --conf \"spark.sql.autoBroadcastJoinThreshold=-1\" \r\n    --conf \"spark.scheduler.minRegisteredResourcesRatio=1\" \r\n    --conf \"spark.ext.h2o.client.log.dir=C:/Users/<username>/logs\" \r\n    --conf \"spark.ext.h2o.fail.on.unsupported.spark.param=false\" \r\n    --conf \"spark.ext.h2o.topology.change.listener.enabled=false\"\r\n\r\nEven with the above command, I get the `java.lang.RuntimeException: Cloud size under xxx`.\r\n\r\n### Using PySparkling installed from PyPi repository (2.1) ###\r\nIf I launch Python fron a shell and directly create a Spark session using this code snippet, \r\n\r\n    from pyspark.sql import SparkSession\r\n    spark = SparkSession.builder.appName(\"SparklingWaterApp\").getOrCreate()\r\n    from pysparkling import *\r\n    hc = H2OContext.getOrCreate(spark)\r\n\r\nWhen python try to execute `hc = H2OContext.getOrCreate(spark)`, I get an error message about `java.io.InvalidClassException: org.apache.spark.h2o.backends.internal.InternalBackendUtils$; local class incompatible: stream classdesc serialVersionUID = -9254888608862`.\r\n\r\nThe detailled error message is [here][4].\r\n\r\nI have tried both of the procedure on my local computer, and directly from a worker in the kubernetes cluster, to check for potential connectivty issues. But the outcome is the same.\r\n\r\nDoes anyone get an idea about how i can troubleshoot my problem ?\r\n\r\n\r\n\r\nThanks in advance, jugo.\r\n\r\n\r\n  [1]: https://github.com/h2oai/sparkling-water/tree/master/r\r\n  [2]: https://s3.amazonaws.com/h2o-release/sparkling-water/rel-2.1/35/index.html\r\n  [3]: https://github.com/h2oai/sparkling-water/issues/433\r\n  [4]: https://pastebin.com/33251KUH", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/919", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/919/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/919/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/919/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/919", "id": 358910308, "node_id": "MDU6SXNzdWUzNTg5MTAzMDg=", "number": 919, "title": "Sparkling Water on Zeppelin - RuntimeException", "user": {"login": "hakangurel", "id": 32629168, "node_id": "MDQ6VXNlcjMyNjI5MTY4", "avatar_url": "https://avatars3.githubusercontent.com/u/32629168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hakangurel", "html_url": "https://github.com/hakangurel", "followers_url": "https://api.github.com/users/hakangurel/followers", "following_url": "https://api.github.com/users/hakangurel/following{/other_user}", "gists_url": "https://api.github.com/users/hakangurel/gists{/gist_id}", "starred_url": "https://api.github.com/users/hakangurel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hakangurel/subscriptions", "organizations_url": "https://api.github.com/users/hakangurel/orgs", "repos_url": "https://api.github.com/users/hakangurel/repos", "events_url": "https://api.github.com/users/hakangurel/events{/privacy}", "received_events_url": "https://api.github.com/users/hakangurel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-09-11T06:53:13Z", "updated_at": "2018-09-14T06:45:50Z", "closed_at": "2018-09-14T06:45:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nTrying to follow the [documentation](https://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.3/10/doc/tutorials/use_on_zeppelin.html)\r\n\r\n`export SPARK_HOME=...# Spark 2.3 home\r\nexport SPARK_SUBMIT_OPTIONS=\"--packages ai.h2o:sparkling-water-package_2.11:2.3.10\"\r\nbin/zeppelin.sh -Pspark-2.3`\r\n\r\ngenerates the following error:\r\n\r\n`Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: ai.h2o#mojo2-runtime-api;0.12.1: not found, download failed: commons-logging#commons-logging;1.2!commons-logging.jar]\r\n\tat org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1303)\r\n\tat org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:53)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:364)\r\n\tat org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:250)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:171)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)`\r\n\r\nWorking on zeppelin-0.8.0-bin-all and spark-2.3.1\r\n\r\nThanks,\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/918", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/918/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/918/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/918/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/918", "id": 355413631, "node_id": "MDU6SXNzdWUzNTU0MTM2MzE=", "number": 918, "title": "can H2OMOJOModel prediction  give the result directly?", "user": {"login": "lppsuixn", "id": 12748339, "node_id": "MDQ6VXNlcjEyNzQ4MzM5", "avatar_url": "https://avatars0.githubusercontent.com/u/12748339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lppsuixn", "html_url": "https://github.com/lppsuixn", "followers_url": "https://api.github.com/users/lppsuixn/followers", "following_url": "https://api.github.com/users/lppsuixn/following{/other_user}", "gists_url": "https://api.github.com/users/lppsuixn/gists{/gist_id}", "starred_url": "https://api.github.com/users/lppsuixn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lppsuixn/subscriptions", "organizations_url": "https://api.github.com/users/lppsuixn/orgs", "repos_url": "https://api.github.com/users/lppsuixn/repos", "events_url": "https://api.github.com/users/lppsuixn/events{/privacy}", "received_events_url": "https://api.github.com/users/lppsuixn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-08-30T03:48:12Z", "updated_at": "2019-09-05T13:45:24Z", "closed_at": "2018-09-14T07:12:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "As title.I use \r\n```scala\r\nval mojo = H2OMOJOModel.createFromMojo(\"file:///data1/mojo\")\r\nval predictions =  mojo.transform(df)\r\n```\r\nand the predictions has  a  column named prediction_output  like\r\n|-- prediction_output: struct (nullable = true)\r\n |    |-- p0: double (nullable = false)\r\n |    |-- p1: double (nullable = false)\r\nor\r\n |-- prediction_output: struct (nullable = true)\r\n |    |-- value: double (nullable = false)\r\nor\r\n |-- prediction_output: struct (nullable = true)\r\n |    |-- probabilities: array (nullable = true)\r\n |    |    |-- element: double (containsNull = false)\r\n\r\n\r\nI should write a udf to add a result column.so is there any solution to give the result directly?\r\nThanks.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/916", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/916/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/916/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/916/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/916", "id": 354154444, "node_id": "MDU6SXNzdWUzNTQxNTQ0NDQ=", "number": 916, "title": "Rsparkling h2o_context water.fvec.frame Error ", "user": {"login": "munsheet", "id": 14006875, "node_id": "MDQ6VXNlcjE0MDA2ODc1", "avatar_url": "https://avatars1.githubusercontent.com/u/14006875?v=4", "gravatar_id": "", "url": "https://api.github.com/users/munsheet", "html_url": "https://github.com/munsheet", "followers_url": "https://api.github.com/users/munsheet/followers", "following_url": "https://api.github.com/users/munsheet/following{/other_user}", "gists_url": "https://api.github.com/users/munsheet/gists{/gist_id}", "starred_url": "https://api.github.com/users/munsheet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/munsheet/subscriptions", "organizations_url": "https://api.github.com/users/munsheet/orgs", "repos_url": "https://api.github.com/users/munsheet/repos", "events_url": "https://api.github.com/users/munsheet/events{/privacy}", "received_events_url": "https://api.github.com/users/munsheet/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-08-27T02:03:39Z", "updated_at": "2018-09-05T08:50:26Z", "closed_at": "2018-09-05T08:50:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I'm trying to set up my R environment to run h2o algorithms on a YARN cluster. \r\n(have no access to the internet due to security reasons - running on R Server) \r\n\r\nHere are my current environment settings:\r\n\r\n- spark version: 2.2.0.2.6.3.0-235 (2.2) \r\n- master: YARN client\r\n- _rsparkling_ version: 0.2.5\r\n- sparkling water: 2.2.16 \r\n- _h2o_ version: 3.18.0.10 \r\n- _sparklyr_ version: 0.7.0 \r\n\r\nI checked the h2o_version table for all the version mappings, but still get this error when I run the code: \r\n```\r\noptions(rsparkling.sparklingwater.version = \"2.2.16\")\r\noptions(rsparkling.sparklingwater.location = \"path to my sparkling water.jar\") \r\n\r\nSys.setenv(SPARK_HOME = \"path to my spark\") \r\nSys.setenv(SPARK_VERSION = \"2.2.0\") \r\nSys.setenv(HADOOP_CONF_DIR = \"...\") \r\nSys.setenv(MASTER = \"yarn-client\") \r\n\r\nlibrary(sparklyr) \r\nlibrary(h2o) \r\nlibrary(rsparkling) \r\n\r\nsc = spark_connect(master = Sys.getenv(\"SPARK_MASTER\"), spark_home = Sys.getenv(\"SPARK_HOME\"), version = Sys.getenv(\"SPARK_VERSION\")) \r\nh2o_context(sc) \r\n\r\n**R Server ERROR output: \r\nError: java.lang.ClassNotFoundExecption: water.fvec.Frame \r\n       at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n       at java.lang.ClassLoader.loadClass(ClassLoader.java:424) \r\n...** \r\n```\r\n\r\nThings I've tried: \r\n- Follow the instructions [here](https://github.com/h2oai/rsparkling/blob/master/inst/examples/using-sparkling-water-in-YARN.Rmd) \r\n- Reinstalling the h2o package and multiple retries \r\n- Trying different versions of h2o and sparkling water (3.18.0.5 and 2.2.11 respectively) \r\nI am sure it would not be a version error since I've been matching them according to h2o_release_table() as shown. Please help or guide me to a solution.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/861", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/861/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/861/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/861/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/861", "id": 344123518, "node_id": "MDU6SXNzdWUzNDQxMjM1MTg=", "number": 861, "title": "Correct way to stop h2o cluster/context", "user": {"login": "simonvdk", "id": 36668828, "node_id": "MDQ6VXNlcjM2NjY4ODI4", "avatar_url": "https://avatars2.githubusercontent.com/u/36668828?v=4", "gravatar_id": "", "url": "https://api.github.com/users/simonvdk", "html_url": "https://github.com/simonvdk", "followers_url": "https://api.github.com/users/simonvdk/followers", "following_url": "https://api.github.com/users/simonvdk/following{/other_user}", "gists_url": "https://api.github.com/users/simonvdk/gists{/gist_id}", "starred_url": "https://api.github.com/users/simonvdk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/simonvdk/subscriptions", "organizations_url": "https://api.github.com/users/simonvdk/orgs", "repos_url": "https://api.github.com/users/simonvdk/repos", "events_url": "https://api.github.com/users/simonvdk/events{/privacy}", "received_events_url": "https://api.github.com/users/simonvdk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-07-24T17:00:20Z", "updated_at": "2018-07-30T06:44:15Z", "closed_at": "2018-07-30T06:44:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there,\r\n\r\nI am using h2o-pysparkling-2.2==2.2.20 and am searching for the correct way to stop an h2o cluster/context.\r\nI need this because in my use case I sequentially spawn and stop spark sessions (one for each task) and want to be able to follow this logic with h2o contexts (sequentially spawn/stop spark sessions with if needed the creation/stop of an h2o context)\r\n\r\n\r\nI tried H2OContext.stop(), which returns:\r\n```\r\n/home/svandekerckhove/smart-sending/.smart-sending/lib/python3.4/site-packages/pysparkling/context.py:181: UserWarning: Stopping H2OContext from PySparkling is not fully supported. Please restart your PySpark session and create a new H2OContext.\r\n```\r\nThen when I start the second spark session and try to create a new h2o context, it creates one that links to the previous h2o cluster (I can see that thanks to the cluster uptime), which now has the status `locked, healthy`. Nothing is done, and I have to key interrupt the script to exit.\r\n\r\n\r\nI also tried h2o.cluster().shutdown(prompt=False), but this returns errors saying the the executors `exited because of a YARN event (e.g. pre-emption) and not because of an error in the running job`. This exits the script and my second task can not be done.\r\n\r\n\r\nWhat is the correct way to stop an h2o context/cluster, so that in the same script one can sequentially use different clusters for different tasks ?\r\n\r\nThank you for your help", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/857", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/857/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/857/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/857/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/857", "id": 343270435, "node_id": "MDU6SXNzdWUzNDMyNzA0MzU=", "number": 857, "title": "unresolved dependencies for 2.3.9", "user": {"login": "salivian", "id": 2488412, "node_id": "MDQ6VXNlcjI0ODg0MTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/2488412?v=4", "gravatar_id": "", "url": "https://api.github.com/users/salivian", "html_url": "https://github.com/salivian", "followers_url": "https://api.github.com/users/salivian/followers", "following_url": "https://api.github.com/users/salivian/following{/other_user}", "gists_url": "https://api.github.com/users/salivian/gists{/gist_id}", "starred_url": "https://api.github.com/users/salivian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/salivian/subscriptions", "organizations_url": "https://api.github.com/users/salivian/orgs", "repos_url": "https://api.github.com/users/salivian/repos", "events_url": "https://api.github.com/users/salivian/events{/privacy}", "received_events_url": "https://api.github.com/users/salivian/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-07-20T23:01:36Z", "updated_at": "2018-09-14T06:30:37Z", "closed_at": "2018-07-23T06:14:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "Fail to start sparkling water as \r\n\r\nspark-shell  --packages ai.h2o:sparkling-water-package_2.11:2.3.9\r\n\r\nMissing modules biz.k11i#xgboost-predictor;0.3.0 and ai.h2o#mojo2-runtime;0.10.7\r\n\r\nxgboost-predictor may be resolved to specifying additional repo\r\nyet\r\nmojo2-runtime is really unavailable\r\n\r\n```\r\n:: problems summary ::\r\n:::: WARNINGS\r\n\t\tmodule not found: biz.k11i#xgboost-predictor;0.3.0\r\n\r\n\t==== local-m2-cache: tried\r\n\r\n\t  file:/home/ipcy/.m2/repository/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom\r\n\r\n\t  -- artifact biz.k11i#xgboost-predictor;0.3.0!xgboost-predictor.jar:\r\n\r\n\t  file:/home/ipcy/.m2/repository/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.jar\r\n\r\n\t==== local-ivy-cache: tried\r\n\r\n\t  /home/ipcy/.ivy2/local/biz.k11i/xgboost-predictor/0.3.0/ivys/ivy.xml\r\n\r\n\t  -- artifact biz.k11i#xgboost-predictor;0.3.0!xgboost-predictor.jar:\r\n\r\n\t  /home/ipcy/.ivy2/local/biz.k11i/xgboost-predictor/0.3.0/jars/xgboost-predictor.jar\r\n\r\n\t==== central: tried\r\n\r\n\t  https://repo1.maven.org/maven2/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom\r\n\r\n\t  -- artifact biz.k11i#xgboost-predictor;0.3.0!xgboost-predictor.jar:\r\n\r\n\t  https://repo1.maven.org/maven2/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.jar\r\n\r\n\t==== spark-packages: tried\r\n\r\n\t  http://dl.bintray.com/spark-packages/maven/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom\r\n\r\n\t  -- artifact biz.k11i#xgboost-predictor;0.3.0!xgboost-predictor.jar:\r\n\r\n\t  http://dl.bintray.com/spark-packages/maven/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.jar\r\n\r\n\t\tmodule not found: ai.h2o#mojo2-runtime;0.10.7\r\n\r\n\t==== local-m2-cache: tried\r\n\r\n\t  file:/home/ipcy/.m2/repository/ai/h2o/mojo2-runtime/0.10.7/mojo2-runtime-0.10.7.pom\r\n\r\n\t  -- artifact ai.h2o#mojo2-runtime;0.10.7!mojo2-runtime.jar:\r\n\r\n\t  file:/home/ipcy/.m2/repository/ai/h2o/mojo2-runtime/0.10.7/mojo2-runtime-0.10.7.jar\r\n\r\n\t==== local-ivy-cache: tried\r\n\r\n\t  /home/ipcy/.ivy2/local/ai.h2o/mojo2-runtime/0.10.7/ivys/ivy.xml\r\n\r\n\t  -- artifact ai.h2o#mojo2-runtime;0.10.7!mojo2-runtime.jar:\r\n\r\n\t  /home/ipcy/.ivy2/local/ai.h2o/mojo2-runtime/0.10.7/jars/mojo2-runtime.jar\r\n\r\n\t==== central: tried\r\n\r\n\t  https://repo1.maven.org/maven2/ai/h2o/mojo2-runtime/0.10.7/mojo2-runtime-0.10.7.pom\r\n\r\n\t  -- artifact ai.h2o#mojo2-runtime;0.10.7!mojo2-runtime.jar:\r\n\r\n\t  https://repo1.maven.org/maven2/ai/h2o/mojo2-runtime/0.10.7/mojo2-runtime-0.10.7.jar\r\n\r\n\t==== spark-packages: tried\r\n\r\n\t  http://dl.bintray.com/spark-packages/maven/ai/h2o/mojo2-runtime/0.10.7/mojo2-runtime-0.10.7.pom\r\n\r\n\t  -- artifact ai.h2o#mojo2-runtime;0.10.7!mojo2-runtime.jar:\r\n\r\n\t  http://dl.bintray.com/spark-packages/maven/ai/h2o/mojo2-runtime/0.10.7/mojo2-runtime-0.10.7.jar\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n\r\n\t\t::          UNRESOLVED DEPENDENCIES         ::\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n\r\n\t\t:: biz.k11i#xgboost-predictor;0.3.0: not found\r\n\r\n\t\t:: ai.h2o#mojo2-runtime;0.10.7: not found\r\n\r\n\t\t::::::::::::::::::::::::::::::::::::::::::::::\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/850", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/850/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/850/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/850/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/850", "id": 342670430, "node_id": "MDU6SXNzdWUzNDI2NzA0MzA=", "number": 850, "title": "Cloudera/Data Science Workbench session initialization problem", "user": {"login": "urbaman", "id": 26753344, "node_id": "MDQ6VXNlcjI2NzUzMzQ0", "avatar_url": "https://avatars2.githubusercontent.com/u/26753344?v=4", "gravatar_id": "", "url": "https://api.github.com/users/urbaman", "html_url": "https://github.com/urbaman", "followers_url": "https://api.github.com/users/urbaman/followers", "following_url": "https://api.github.com/users/urbaman/following{/other_user}", "gists_url": "https://api.github.com/users/urbaman/gists{/gist_id}", "starred_url": "https://api.github.com/users/urbaman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/urbaman/subscriptions", "organizations_url": "https://api.github.com/users/urbaman/orgs", "repos_url": "https://api.github.com/users/urbaman/repos", "events_url": "https://api.github.com/users/urbaman/events{/privacy}", "received_events_url": "https://api.github.com/users/urbaman/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-07-19T10:26:29Z", "updated_at": "2018-08-02T15:25:06Z", "closed_at": "2018-07-23T06:13:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nwe're trying to use h2oai inside our environment (Cloudera 5x, Workbench 1.3.0, Spark 2.3) but it fails during initialization, with the attached log (full with commands and resulting error): \r\n[errors_sparklyr_h2o.txt](https://github.com/h2oai/sparkling-water/files/2209437/errors_sparklyr_h2o.txt)\r\n\r\nUltimately, without h2o we can open Spark or R sessions without any problems, but with h2o  we can't connect:\r\n\r\n> Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: biz.k11i#xgboost-predictor;0.3.0: not found]\r\n\tat org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1283)\r\n\tat org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:50)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doPrepareSubmitEnvironment(SparkSubmit.scala:363)\r\n\tat org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:249)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:170)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nError in force(code) : \r\n  Failed while connecting to sparklyr to port (8880) for sessionid (54132): Gateway in port (8880) did not respond.\r\n    Path: /opt/cloudera/parcels/SPARK2-2.3.0.cloudera2-1.cdh5.13.3.p0.316101/lib/spark2/bin/spark-submit\r\n    Parameters: --class, sparklyr.Shell, --packages, 'ai.h2o:sparkling-water-core_2.11:2.3.8','ai.h2o:sparkling-water-ml_2.11:2.3.8','ai.h2o:sparkling-water-repl_2.11:2.3.8','no.priv.garshol.duke:duke:1.2', '/home/cdsw/R/sparklyr/java/sparklyr-2.3-2.11.jar', 8880, 54132\r\n    Log: /tmp/RtmpjsDpxa/fileef69cfd95b_spark.log\r\n\r\nOnly thing we can find is that xgboost-predictor's repos are under \"http://dl.bintray.com/komiya-atsushi/maven/\" instead of \"http://dl.bintray.com/spark-packages/maven/\", and it's the only dependency not found.\r\nWe don't even know if that's the real problem with the connection error.\r\n\r\nThank you.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/844", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/844/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/844/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/844/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/844", "id": 342593458, "node_id": "MDU6SXNzdWUzNDI1OTM0NTg=", "number": 844, "title": "Could not resolve all files for configuration ':sparkling-water-py:compile'", "user": {"login": "sukumaar", "id": 22831093, "node_id": "MDQ6VXNlcjIyODMxMDkz", "avatar_url": "https://avatars1.githubusercontent.com/u/22831093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sukumaar", "html_url": "https://github.com/sukumaar", "followers_url": "https://api.github.com/users/sukumaar/followers", "following_url": "https://api.github.com/users/sukumaar/following{/other_user}", "gists_url": "https://api.github.com/users/sukumaar/gists{/gist_id}", "starred_url": "https://api.github.com/users/sukumaar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sukumaar/subscriptions", "organizations_url": "https://api.github.com/users/sukumaar/orgs", "repos_url": "https://api.github.com/users/sukumaar/repos", "events_url": "https://api.github.com/users/sukumaar/events{/privacy}", "received_events_url": "https://api.github.com/users/sukumaar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-19T06:21:31Z", "updated_at": "2018-07-19T06:27:53Z", "closed_at": "2018-07-19T06:22:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "getting below issue while performing gradle build:\r\n\r\n```\r\nFAILURE: Build failed with an exception.\r\n\r\n* Where:\r\nBuild file '/home/sukumaar.mane/projects/sparkling-water/py/build.gradle' line: 57\r\n\r\n* What went wrong:\r\nA problem occurred evaluating project ':sparkling-water-py'.\r\n> Could not resolve all files for configuration ':sparkling-water-py:compile'.\r\n   > Could not resolve ai.h2o:mojo2-runtime:0.10.7.\r\n     Required by:\r\n         project :sparkling-water-py > project :sparkling-water-assembly > project :sparkling-water-ml\r\n      > Could not resolve ai.h2o:mojo2-runtime:0.10.7.\r\n         > Could not get resource 'http://nexus:8081/nexus/repository/releases/ai/h2o/mojo2-runtime/0.10.7/mojo2-runtime-0.10.7.pom'.\r\n            > Could not GET 'http://nexus:8081/nexus/repository/releases/ai/h2o/mojo2-runtime/0.10.7/mojo2-runtime-0.10.7.pom'.\r\n               > nexus: Name or service not known\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/h2oai/sparkling-water/issues/842", "repository_url": "https://api.github.com/repos/h2oai/sparkling-water", "labels_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/842/labels{/name}", "comments_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/842/comments", "events_url": "https://api.github.com/repos/h2oai/sparkling-water/issues/842/events", "html_url": "https://github.com/h2oai/sparkling-water/issues/842", "id": 342581655, "node_id": "MDU6SXNzdWUzNDI1ODE2NTU=", "number": 842, "title": "There is no feature named STABLE_PUBLISHING", "user": {"login": "sukumaar", "id": 22831093, "node_id": "MDQ6VXNlcjIyODMxMDkz", "avatar_url": "https://avatars1.githubusercontent.com/u/22831093?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sukumaar", "html_url": "https://github.com/sukumaar", "followers_url": "https://api.github.com/users/sukumaar/followers", "following_url": "https://api.github.com/users/sukumaar/following{/other_user}", "gists_url": "https://api.github.com/users/sukumaar/gists{/gist_id}", "starred_url": "https://api.github.com/users/sukumaar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sukumaar/subscriptions", "organizations_url": "https://api.github.com/users/sukumaar/orgs", "repos_url": "https://api.github.com/users/sukumaar/repos", "events_url": "https://api.github.com/users/sukumaar/events{/privacy}", "received_events_url": "https://api.github.com/users/sukumaar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-07-19T05:14:31Z", "updated_at": "2018-07-19T06:19:34Z", "closed_at": "2018-07-19T06:19:34Z", "author_association": "NONE", "active_lock_reason": null, "body": "I did git clone of **sparkling-water** repo and tried **gradle clean** . I have received below error\r\nA problem occurred evaluating settings 'sparkling-water'.\r\n> There is no feature named STABLE_PUBLISHING\r\n\r\n\r\nThen I ran with **--stacktrace** , it is showing below error in **sparkling-water/settings.gradle**:\r\n```\r\n* Exception is:\r\norg.gradle.api.GradleScriptException: A problem occurred evaluating settings 'sparkling-water'.\r\n        at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92)\r\n        at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:204)\r\n        at org.gradle.configuration.DefaultScriptTarget.addConfiguration(DefaultScriptTarget.java:74)\r\n        at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:209)\r\n        at org.gradle.configuration.BuildOperationScriptPlugin$1.run(BuildOperationScriptPlugin.java:61)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:317)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:309)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:185)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:97)\r\n        at org.gradle.internal.operations.DelegatingBuildOperationExecutor.run(DelegatingBuildOperationExecutor.java:31)\r\n        at org.gradle.configuration.BuildOperationScriptPlugin.apply(BuildOperationScriptPlugin.java:58)\r\n        at org.gradle.initialization.ScriptEvaluatingSettingsProcessor.applySettingsScript(ScriptEvaluatingSettingsProcessor.java:67)\r\n        at org.gradle.initialization.ScriptEvaluatingSettingsProcessor.process(ScriptEvaluatingSettingsProcessor.java:58)\r\n        at org.gradle.initialization.PropertiesLoadingSettingsProcessor.process(PropertiesLoadingSettingsProcessor.java:37)\r\n        at org.gradle.initialization.SettingsEvaluatedCallbackFiringSettingsProcessor.process(SettingsEvaluatedCallbackFiringSettingsProcessor.java:34)\r\n        at org.gradle.initialization.RootBuildCacheControllerSettingsProcessor.process(RootBuildCacheControllerSettingsProcessor.java:36)\r\n        at org.gradle.initialization.BuildOperationSettingsProcessor$2.call(BuildOperationSettingsProcessor.java:48)\r\n        at org.gradle.initialization.BuildOperationSettingsProcessor$2.call(BuildOperationSettingsProcessor.java:45)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:331)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:321)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:185)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:107)\r\n        at org.gradle.internal.operations.DelegatingBuildOperationExecutor.call(DelegatingBuildOperationExecutor.java:36)\r\n        at org.gradle.initialization.BuildOperationSettingsProcessor.process(BuildOperationSettingsProcessor.java:45)\r\n        at org.gradle.initialization.DefaultSettingsLoader.findSettingsAndLoadIfAppropriate(DefaultSettingsLoader.java:109)\r\n        at org.gradle.initialization.DefaultSettingsLoader.findAndLoadSettings(DefaultSettingsLoader.java:48)\r\n        at org.gradle.initialization.DefaultSettingsLoaderFactory$1.findAndLoadSettings(DefaultSettingsLoaderFactory.java:67)\r\n        at org.gradle.internal.composite.CompositeBuildSettingsLoader.findAndLoadSettings(CompositeBuildSettingsLoader.java:45)\r\n        at org.gradle.initialization.DefaultGradleLauncher$LoadBuild.run(DefaultGradleLauncher.java:240)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:317)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:309)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:185)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:97)\r\n        at org.gradle.internal.operations.DelegatingBuildOperationExecutor.run(DelegatingBuildOperationExecutor.java:31)\r\n        at org.gradle.initialization.DefaultGradleLauncher.loadSettings(DefaultGradleLauncher.java:165)\r\n        at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:128)\r\n        at org.gradle.initialization.DefaultGradleLauncher.executeTasks(DefaultGradleLauncher.java:115)\r\n        at org.gradle.internal.invocation.GradleBuildController$1.call(GradleBuildController.java:78)\r\n        at org.gradle.internal.invocation.GradleBuildController$1.call(GradleBuildController.java:75)\r\n        at org.gradle.internal.work.DefaultWorkerLeaseService.withLocks(DefaultWorkerLeaseService.java:152)\r\n        at org.gradle.internal.work.StopShieldingWorkerLeaseService.withLocks(StopShieldingWorkerLeaseService.java:38)\r\n        at org.gradle.internal.invocation.GradleBuildController.doBuild(GradleBuildController.java:100)\r\n        at org.gradle.internal.invocation.GradleBuildController.run(GradleBuildController.java:75)\r\n        at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28)\r\n        at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35)\r\n        at org.gradle.tooling.internal.provider.ValidatingBuildActionRunner.run(ValidatingBuildActionRunner.java:32)\r\n        at org.gradle.launcher.exec.RunAsBuildOperationBuildActionRunner$3.run(RunAsBuildOperationBuildActionRunner.java:45)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:317)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:309)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:185)\r\n        at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:97)\r\n        at org.gradle.internal.operations.DelegatingBuildOperationExecutor.run(DelegatingBuildOperationExecutor.java:31)\r\n        at org.gradle.launcher.exec.RunAsBuildOperationBuildActionRunner.run(RunAsBuildOperationBuildActionRunner.java:42)\r\n        at org.gradle.tooling.internal.provider.SubscribableBuildActionRunner.run(SubscribableBuildActionRunner.java:51)\r\n        at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:47)\r\n        at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:31)\r\n        at org.gradle.launcher.exec.BuildTreeScopeBuildActionExecuter.execute(BuildTreeScopeBuildActionExecuter.java:39)\r\n        at org.gradle.launcher.exec.BuildTreeScopeBuildActionExecuter.execute(BuildTreeScopeBuildActionExecuter.java:25)\r\n        at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:80)\r\n        at org.gradle.tooling.internal.provider.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:53)\r\n        at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:61)\r\n        at org.gradle.tooling.internal.provider.ServicesSetupBuildActionExecuter.execute(ServicesSetupBuildActionExecuter.java:34)\r\n        at org.gradle.tooling.internal.provider.GradleThreadBuildActionExecuter.execute(GradleThreadBuildActionExecuter.java:36)\r\n        at org.gradle.tooling.internal.provider.GradleThreadBuildActionExecuter.execute(GradleThreadBuildActionExecuter.java:25)\r\n        at org.gradle.tooling.internal.provider.ParallelismConfigurationBuildActionExecuter.execute(ParallelismConfigurationBuildActionExecuter.java:43)\r\n        at org.gradle.tooling.internal.provider.ParallelismConfigurationBuildActionExecuter.execute(ParallelismConfigurationBuildActionExecuter.java:29)\r\n        at org.gradle.tooling.internal.provider.StartParamsValidatingActionExecuter.execute(StartParamsValidatingActionExecuter.java:64)\r\n        at org.gradle.tooling.internal.provider.StartParamsValidatingActionExecuter.execute(StartParamsValidatingActionExecuter.java:29)\r\n        at org.gradle.tooling.internal.provider.SessionFailureReportingActionExecuter.execute(SessionFailureReportingActionExecuter.java:59)\r\n        at org.gradle.tooling.internal.provider.SessionFailureReportingActionExecuter.execute(SessionFailureReportingActionExecuter.java:44)\r\n        at org.gradle.tooling.internal.provider.SetupLoggingActionExecuter.execute(SetupLoggingActionExecuter.java:46)\r\n        at org.gradle.tooling.internal.provider.SetupLoggingActionExecuter.execute(SetupLoggingActionExecuter.java:30)\r\n        at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:67)\r\n        at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36)\r\n        at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:122)\r\n        at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:37)\r\n        at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:122)\r\n        at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26)\r\n        at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:122)\r\n        at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34)\r\n        at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:122)\r\n        at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74)\r\n        at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72)\r\n        at org.gradle.util.Swapper.swap(Swapper.java:38)\r\n        at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72)\r\n        at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:122)\r\n        at org.gradle.launcher.daemon.server.exec.LogAndCheckHealth.execute(LogAndCheckHealth.java:55)\r\n        at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:122)\r\n        at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:62)\r\n        at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36)\r\n        at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:122)\r\n        at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:82)\r\n        at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36)\r\n        at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:122)\r\n        at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50)\r\n        at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:295)\r\n        at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)\r\n        at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46)\r\n        at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)\r\nCaused by: java.lang.IllegalArgumentException: There is no feature named STABLE_PUBLISHING\r\n        at org.gradle.api.internal.FeaturePreviews$Feature.withName(FeaturePreviews.java:37)\r\n        at org.gradle.api.internal.FeaturePreviews.enableFeature(FeaturePreviews.java:76)\r\n        at org.gradle.initialization.DefaultSettings.enableFeaturePreview(DefaultSettings.java:321)\r\n        at org.gradle.internal.metaobject.BeanDynamicObject$MetaClassAdapter.invokeMethod(BeanDynamicObject.java:479)\r\n        at org.gradle.internal.metaobject.BeanDynamicObject.tryInvokeMethod(BeanDynamicObject.java:191)\r\n        at org.gradle.internal.metaobject.CompositeDynamicObject.tryInvokeMethod(CompositeDynamicObject.java:98)\r\n        at org.gradle.internal.metaobject.MixInClosurePropertiesAsMethodsDynamicObject.tryInvokeMethod(MixInClosurePropertiesAsMethodsDynamicObject.java:30)\r\n        at org.gradle.groovy.scripts.BasicScript$ScriptDynamicObject.tryInvokeMethod(BasicScript.java:134)\r\n        at org.gradle.internal.metaobject.AbstractDynamicObject.invokeMethod(AbstractDynamicObject.java:160)\r\n        at org.gradle.groovy.scripts.BasicScript.invokeMethod(BasicScript.java:83)\r\n        at settings_8r59w32kw9pn8tq4bx7ufdy3g.run(/home/sukumaar.mane/projects/sparkling-water/settings.gradle:26)\r\n        at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:90)\r\n        ... 98 more\r\n\r\n```", "performed_via_github_app": null, "score": 1.0}]}