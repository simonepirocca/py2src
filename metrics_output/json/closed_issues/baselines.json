{"total_count": 416, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/openai/baselines/issues/1132", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1132/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1132/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1132/events", "html_url": "https://github.com/openai/baselines/issues/1132", "id": 670822883, "node_id": "MDU6SXNzdWU2NzA4MjI4ODM=", "number": 1132, "title": "How to visualize the learned Q function for a trained agent?", "user": {"login": "sophiagu", "id": 14866379, "node_id": "MDQ6VXNlcjE0ODY2Mzc5", "avatar_url": "https://avatars0.githubusercontent.com/u/14866379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sophiagu", "html_url": "https://github.com/sophiagu", "followers_url": "https://api.github.com/users/sophiagu/followers", "following_url": "https://api.github.com/users/sophiagu/following{/other_user}", "gists_url": "https://api.github.com/users/sophiagu/gists{/gist_id}", "starred_url": "https://api.github.com/users/sophiagu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sophiagu/subscriptions", "organizations_url": "https://api.github.com/users/sophiagu/orgs", "repos_url": "https://api.github.com/users/sophiagu/repos", "events_url": "https://api.github.com/users/sophiagu/events{/privacy}", "received_events_url": "https://api.github.com/users/sophiagu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-01T12:21:29Z", "updated_at": "2020-08-12T13:50:28Z", "closed_at": "2020-08-12T13:50:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "I recently trained A2C and PPO2 agents for a continuous action space and continuous observation space problem. How can I plot their learned Q functions as functions of the states?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1126", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1126/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1126/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1126/events", "html_url": "https://github.com/openai/baselines/issues/1126", "id": 655212203, "node_id": "MDU6SXNzdWU2NTUyMTIyMDM=", "number": 1126, "title": "SubprocVecEnv not receiving any data", "user": {"login": "praetorianer777", "id": 6584303, "node_id": "MDQ6VXNlcjY1ODQzMDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/6584303?v=4", "gravatar_id": "", "url": "https://api.github.com/users/praetorianer777", "html_url": "https://github.com/praetorianer777", "followers_url": "https://api.github.com/users/praetorianer777/followers", "following_url": "https://api.github.com/users/praetorianer777/following{/other_user}", "gists_url": "https://api.github.com/users/praetorianer777/gists{/gist_id}", "starred_url": "https://api.github.com/users/praetorianer777/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/praetorianer777/subscriptions", "organizations_url": "https://api.github.com/users/praetorianer777/orgs", "repos_url": "https://api.github.com/users/praetorianer777/repos", "events_url": "https://api.github.com/users/praetorianer777/events{/privacy}", "received_events_url": "https://api.github.com/users/praetorianer777/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-11T13:49:00Z", "updated_at": "2020-07-14T09:12:05Z", "closed_at": "2020-07-14T09:12:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, I have the same problem as #1117.\r\nI am also on Windows 10. DummyVenc works fine, but SubprocVecEnv not.\r\nI don't know what was the problem with observation spaces in #1117 , but the env_check works fine.\r\nMy package list:\r\n\r\nabsl-py              0.9.0\r\nastor                0.8.1\r\natari-py             0.2.6\r\ncertifi              2020.6.20\r\ncloudpickle          1.3.0\r\ncycler               0.10.0\r\nfuture               0.18.2\r\ngast                 0.2.2\r\ngoogle-pasta         0.2.0\r\ngrpcio               1.30.0\r\ngym                  0.17.2\r\nh5py                 2.10.0\r\nimportlib-metadata   1.7.0\r\njoblib               0.16.0\r\nKeras-Applications   1.0.8\r\nKeras-Preprocessing  1.1.2\r\nkiwisolver           1.2.0\r\nMarkdown             3.2.2\r\nmatplotlib           3.2.2\r\nnumpy                1.19.0\r\nopencv-python        4.3.0.36\r\nopt-einsum           3.2.1\r\npandas               1.0.5\r\nPillow               7.2.0\r\npip                  20.1.1\r\nprotobuf             3.12.2\r\npyglet               1.5.0\r\npyparsing            2.4.7\r\npython-dateutil      2.8.1\r\npytz                 2020.1\r\nscipy                1.5.1\r\nsetuptools           47.3.1.post20200622\r\nsimple-pid           0.2.4\r\nsix                  1.15.0\r\nstable-baselines     2.10.0\r\ntensorboard          1.15.0\r\ntensorflow-estimator 1.15.1\r\ntensorflow-gpu       1.15.0\r\ntermcolor            1.1.0\r\nWerkzeug             1.0.1\r\nwheel                0.34.2\r\nwincertstore         0.2\r\nwrapt                1.12.1\r\nzipp                 3.1.0\r\n\r\nMy custom environment and also the regular environments don't work with SubprocVecEnv.\r\nSomeone has an idea?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1123", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1123/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1123/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1123/events", "html_url": "https://github.com/openai/baselines/issues/1123", "id": 651231740, "node_id": "MDU6SXNzdWU2NTEyMzE3NDA=", "number": 1123, "title": "Saving Video Help!", "user": {"login": "ryanmaxwell96", "id": 19628119, "node_id": "MDQ6VXNlcjE5NjI4MTE5", "avatar_url": "https://avatars2.githubusercontent.com/u/19628119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ryanmaxwell96", "html_url": "https://github.com/ryanmaxwell96", "followers_url": "https://api.github.com/users/ryanmaxwell96/followers", "following_url": "https://api.github.com/users/ryanmaxwell96/following{/other_user}", "gists_url": "https://api.github.com/users/ryanmaxwell96/gists{/gist_id}", "starred_url": "https://api.github.com/users/ryanmaxwell96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ryanmaxwell96/subscriptions", "organizations_url": "https://api.github.com/users/ryanmaxwell96/orgs", "repos_url": "https://api.github.com/users/ryanmaxwell96/repos", "events_url": "https://api.github.com/users/ryanmaxwell96/events{/privacy}", "received_events_url": "https://api.github.com/users/ryanmaxwell96/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-06T04:08:48Z", "updated_at": "2020-07-08T16:46:54Z", "closed_at": "2020-07-08T16:46:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to use \r\n\r\npython3 -m baselines.run --alg=trpo_mpi --env=Ant-v2 --num_timesteps=1e7 --log_path=~/Documents/MyAntFile --save_video_interval=33333 \r\n\r\nto save videos. However, it seriously degrades speed as well as record a ridiculous number of videos that I don't need. All I want is a video, say, every 1000 iterations, not 5 or 10 every iteration. \r\n\r\nCan someone help with this?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1121", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1121/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1121/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1121/events", "html_url": "https://github.com/openai/baselines/issues/1121", "id": 650929170, "node_id": "MDU6SXNzdWU2NTA5MjkxNzA=", "number": 1121, "title": "HER+DDPG algorithm doesn't work on FetchReach environment", "user": {"login": "alessandro-a", "id": 61650288, "node_id": "MDQ6VXNlcjYxNjUwMjg4", "avatar_url": "https://avatars1.githubusercontent.com/u/61650288?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alessandro-a", "html_url": "https://github.com/alessandro-a", "followers_url": "https://api.github.com/users/alessandro-a/followers", "following_url": "https://api.github.com/users/alessandro-a/following{/other_user}", "gists_url": "https://api.github.com/users/alessandro-a/gists{/gist_id}", "starred_url": "https://api.github.com/users/alessandro-a/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alessandro-a/subscriptions", "organizations_url": "https://api.github.com/users/alessandro-a/orgs", "repos_url": "https://api.github.com/users/alessandro-a/repos", "events_url": "https://api.github.com/users/alessandro-a/events{/privacy}", "received_events_url": "https://api.github.com/users/alessandro-a/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-04T17:38:49Z", "updated_at": "2020-07-08T10:49:32Z", "closed_at": "2020-07-08T10:49:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "I tried to test the algorithm in question with the environment in question as written on the readme of the algorithm at the following link:\r\n\r\n[https://github.com/openai/baselines/tree/master/baselines/her](url)\r\n\r\nHowever the behavior is not as I would have expected, even sometimes it gets to be inaccurate as in the picture:\r\n\r\n![Schermata](https://user-images.githubusercontent.com/61650288/86517933-42b22b80-be2d-11ea-98c3-f8f2592ff164.png)\r\n\r\nAlso there are some things not clear to me, I can't understand what they mean with \"train / success_rate\" and \"test / success_rate\", what would be the difference?\r\n\r\n![Schermata del 2020-07-04 19-36-13](https://user-images.githubusercontent.com/61650288/86517982-a6d4ef80-be2d-11ea-8391-28af1c7f7961.png)\r\n\r\nBecause the last one converges to 1 but the first one doesn't, however, being a simple problem, even without reproducing the same configuration used in the paper, the success_rate should converge as written at the previous link, this makes me think that the important one is the \"test\", anyway  as shown in the photos, it cannot be said to work.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1117", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1117/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1117/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1117/events", "html_url": "https://github.com/openai/baselines/issues/1117", "id": 648120233, "node_id": "MDU6SXNzdWU2NDgxMjAyMzM=", "number": 1117, "title": "SubprocVecEnv not receiving any data ", "user": {"login": "DavidS32", "id": 55147912, "node_id": "MDQ6VXNlcjU1MTQ3OTEy", "avatar_url": "https://avatars3.githubusercontent.com/u/55147912?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DavidS32", "html_url": "https://github.com/DavidS32", "followers_url": "https://api.github.com/users/DavidS32/followers", "following_url": "https://api.github.com/users/DavidS32/following{/other_user}", "gists_url": "https://api.github.com/users/DavidS32/gists{/gist_id}", "starred_url": "https://api.github.com/users/DavidS32/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DavidS32/subscriptions", "organizations_url": "https://api.github.com/users/DavidS32/orgs", "repos_url": "https://api.github.com/users/DavidS32/repos", "events_url": "https://api.github.com/users/DavidS32/events{/privacy}", "received_events_url": "https://api.github.com/users/DavidS32/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-06-30T12:09:16Z", "updated_at": "2020-07-14T09:08:27Z", "closed_at": "2020-07-01T13:09:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a problem similar to issue #640 \r\n\r\nFor a long time it worked without any problem and now the code get's stuck in the initilization of the  SubprocVecEnv. The line with causes the problem is: \r\n\r\nobservation_space, action_space = self.remotes[0].recv()\r\n\r\nThere it gets stuck without any problem. it just receives no data.... \r\nThe problem occurs with any anvironment. I want to use the SubprocVecEnv and not the DummyVecEnv.\r\n\r\n\r\nI am on windows 10 with the following packeges:\r\n`\r\nPackage                            Version            \r\n---------------------------------- -------------------\r\n-tari-py                           1.2.1              \r\nabsl-py                            0.9.0              \r\nalabaster                          0.7.12             \r\nanaconda-client                    1.7.2              \r\nanaconda-navigator                 1.9.12             \r\nanaconda-project                   0.8.3              \r\nargh                               0.26.2             \r\nasn1crypto                         1.3.0              \r\nastor                              0.8.1              \r\nastroid                            2.3.3              \r\nastropy                            4.0                \r\natari-py                           0.2.6              \r\natomicwrites                       1.3.0              \r\nattrs                              19.3.0             \r\nautopep8                           1.4.4              \r\nBabel                              2.8.0              \r\nbackcall                           0.1.0              \r\nbackports.functools-lru-cache      1.6.1              \r\nbackports.os                       0.1.1              \r\nbackports.shutil-get-terminal-size 1.0.0              \r\nbackports.tempfile                 1.0                \r\nbackports.weakref                  1.0.post1          \r\nbcrypt                             3.1.7              \r\nbeautifulsoup4                     4.8.2              \r\nbitarray                           1.2.1              \r\nbkcharts                           0.2                \r\nbleach                             3.1.0              \r\nblinker                            1.4                \r\nbokeh                              1.4.0              \r\nboto                               2.49.0             \r\nBottleneck                         1.3.2              \r\nBox2D                              2.3.10             \r\nBox2D-kengz                        2.3.3              \r\nbox2d-py                           2.3.8              \r\ncachetools                         4.0.0              \r\ncertifi                            2020.4.5.1         \r\ncffi                               1.14.0             \r\nchardet                            3.0.4              \r\nclick                              7.1.1              \r\ncloudpickle                        1.3.0              \r\nclyent                             1.2.2              \r\ncolorama                           0.4.3              \r\ncomtypes                           1.1.7              \r\nconda-package-handling             1.6.0              \r\nconda-verify                       3.4.2              \r\ncontextlib2                        0.6.0.post1        \r\ncryptography                       2.8                \r\ncycler                             0.10.0             \r\nCython                             0.29.15            \r\ncytoolz                            0.10.1             \r\ndask                               2.12.0             \r\ndecorator                          4.4.2              \r\ndefusedxml                         0.6.0              \r\ndiff-match-patch                   20181111           \r\ndistributed                        2.12.0             \r\ndocutils                           0.16               \r\nentrypoints                        0.3                \r\net-xmlfile                         1.0.1              \r\nfastcache                          1.1.0              \r\nfilelock                           3.0.12             \r\nflake8                             3.7.9              \r\nFlask                              1.1.1              \r\nfsspec                             0.6.3              \r\nfuture                             0.18.2             \r\ngast                               0.2.2              \r\ngevent                             1.4.0              \r\nglfw                               1.11.2             \r\nglob2                              0.7                \r\ngoogle-auth                        1.12.0             \r\ngoogle-auth-oauthlib               0.4.1              \r\ngoogle-pasta                       0.2.0              \r\ngreenlet                           0.4.15             \r\ngrpcio                             1.27.2             \r\ngym                                0.17.1             \r\nh5py                               2.10.0             \r\nHeapDict                           1.0.1              \r\nhtml5lib                           1.0.1              \r\nhypothesis                         5.5.4              \r\nidna                               2.9                \r\nimageio                            2.8.0              \r\nimagesize                          1.2.0              \r\nimportlib-metadata                 1.5.0              \r\nintervaltree                       3.0.2              \r\nipykernel                          5.1.4              \r\nipython                            7.13.0             \r\nipython-genutils                   0.2.0              \r\nipywidgets                         7.5.1              \r\nisort                              4.3.21             \r\nitsdangerous                       1.1.0              \r\njdcal                              1.4.1              \r\njedi                               0.15.2             \r\nJinja2                             2.11.1             \r\njoblib                             0.14.1             \r\njson5                              0.9.3              \r\njsonschema                         3.2.0              \r\njupyter                            1.0.0              \r\njupyter-client                     6.1.0              \r\njupyter-console                    6.1.0              \r\njupyter-core                       4.6.1              \r\njupyterlab                         1.2.6              \r\njupyterlab-server                  1.0.7              \r\nKeras-Applications                 1.0.8              \r\nKeras-Preprocessing                1.1.0              \r\nkeyring                            21.1.0             \r\nkiwisolver                         1.1.0              \r\nlazy-object-proxy                  1.4.3              \r\nlibarchive-c                       2.8                \r\nllvmlite                           0.31.0             \r\nlocket                             0.2.0              \r\nlockfile                           0.12.2             \r\nlxml                               4.5.0              \r\nMarkdown                           3.2.1              \r\nMarkupSafe                         1.1.1              \r\nmatplotlib                         3.1.3              \r\nmccabe                             0.6.1              \r\nmenuinst                           1.4.16             \r\nmistune                            0.8.4              \r\nmkl-fft                            1.0.15             \r\nmkl-random                         1.1.0              \r\nmkl-service                        2.3.0              \r\nmock                               4.0.1              \r\nmore-itertools                     8.2.0              \r\nmpmath                             1.1.0              \r\nmsgpack                            1.0.0              \r\nmultipledispatch                   0.6.0              \r\nnavigator-updater                  0.2.1              \r\nnbconvert                          5.6.1              \r\nnbformat                           5.0.4              \r\nnetworkx                           2.4                \r\nnltk                               3.4.5              \r\nnose                               1.3.7              \r\nnotebook                           6.0.3              \r\nnumba                              0.48.0             \r\nnumexpr                            2.7.1              \r\nnumpy                              1.18.1             \r\nnumpydoc                           0.9.2              \r\noauthlib                           3.1.0              \r\nolefile                            0.46               \r\nopencv-python                      4.2.0.34           \r\nopenpyxl                           3.0.3              \r\nopt-einsum                         3.2.0              \r\npackaging                          20.3               \r\npandas                             1.0.3              \r\npandocfilters                      1.4.2              \r\nparamiko                           2.7.1              \r\nparso                              0.5.2              \r\npartd                              1.1.0              \r\npath                               13.1.0             \r\npathlib2                           2.3.5              \r\npathtools                          0.1.2              \r\npatsy                              0.5.1              \r\npep8                               1.7.1              \r\npexpect                            4.8.0              \r\npickleshare                        0.7.5              \r\nPillow                             7.0.0              \r\npip                                20.0.2             \r\npkginfo                            1.5.0.1            \r\npluggy                             0.13.1             \r\nply                                3.11               \r\nprometheus-client                  0.7.1              \r\nprompt-toolkit                     3.0.3              \r\nprotobuf                           3.11.4             \r\npsutil                             5.7.0              \r\npy                                 1.8.1              \r\npyasn1                             0.4.8              \r\npyasn1-modules                     0.2.8              \r\npycodestyle                        2.5.0              \r\npycosat                            0.6.3              \r\npycparser                          2.20               \r\npycrypto                           2.6.1              \r\npycurl                             7.43.0.5           \r\npydocstyle                         4.0.1              \r\npyflakes                           2.1.1              \r\npyglet                             1.5.0              \r\nPygments                           2.6.1              \r\nPyJWT                              1.7.1              \r\npylint                             2.4.4              \r\nPyNaCl                             1.3.0              \r\npyodbc                             4.0.0-unsupported  \r\npyOpenSSL                          19.1.0             \r\npyparsing                          2.4.6              \r\npyreadline                         2.1                \r\npyrsistent                         0.15.7             \r\nPySocks                            1.7.1              \r\npytest                             5.4.1              \r\npytest-arraydiff                   0.3                \r\npytest-astropy                     0.8.0              \r\npytest-astropy-header              0.1.2              \r\npytest-doctestplus                 0.5.0              \r\npytest-openfiles                   0.4.0              \r\npytest-remotedata                  0.3.2              \r\npython-dateutil                    2.8.1              \r\npython-jsonrpc-server              0.3.4              \r\npython-language-server             0.31.9             \r\npytz                               2019.3             \r\nPyWavelets                         1.1.1              \r\npywin32                            227                \r\npywin32-ctypes                     0.2.0              \r\npywinpty                           0.5.7              \r\nPyYAML                             5.3.1              \r\npyzmq                              18.1.1             \r\nQDarkStyle                         2.8                \r\nQtAwesome                          0.7.0              \r\nqtconsole                          4.7.2              \r\nQtPy                               1.9.0              \r\nrequests                           2.23.0             \r\nrequests-oauthlib                  1.3.0              \r\nrope                               0.16.0             \r\nrsa                                4.0                \r\nRtree                              0.9.3              \r\nruamel-yaml                        0.15.87            \r\nscikit-image                       0.16.2             \r\nscikit-learn                       0.22.1             \r\nscipy                              1.1.0              \r\nseaborn                            0.10.0             \r\nSend2Trash                         1.5.0              \r\nsetuptools                         46.1.1.post20200323\r\nsimplegeneric                      0.8.1              \r\nsingledispatch                     3.4.0.3            \r\nsix                                1.14.0             \r\nsnowballstemmer                    2.0.0              \r\nsortedcollections                  1.1.2              \r\nsortedcontainers                   2.1.0              \r\nsoupsieve                          2.0                \r\nSphinx                             2.4.4              \r\nsphinxcontrib-applehelp            1.0.2              \r\nsphinxcontrib-devhelp              1.0.2              \r\nsphinxcontrib-htmlhelp             1.0.3              \r\nsphinxcontrib-jsmath               1.0.1              \r\nsphinxcontrib-qthelp               1.0.3              \r\nsphinxcontrib-serializinghtml      1.1.4              \r\nsphinxcontrib-websupport           1.2.1              \r\nspyder                             4.1.1              \r\nspyder-kernels                     1.9.0              \r\nSQLAlchemy                         1.3.15             \r\nstable-baselines                   2.10.0             \r\nstatsmodels                        0.11.0             \r\nsympy                              1.5.1              \r\ntables                             3.6.1              \r\ntblib                              1.6.0              \r\ntensorboard                        1.15.0             \r\ntensorflow                         1.15.0             \r\ntensorflow-estimator               1.15.1             \r\ntensorflow-gpu                     1.15.0             \r\ntermcolor                          1.1.0              \r\nterminado                          0.8.3              \r\ntestpath                           0.4.4              \r\ntoolz                              0.10.0             \r\ntorch                              1.4.0              \r\ntorchvision                        0.5.0              \r\ntornado                            6.0.4              \r\ntqdm                               4.43.0             \r\ntraitlets                          4.3.3              \r\nujson                              1.35               \r\nunicodecsv                         0.14.1             \r\nurllib3                            1.25.8             \r\nwatchdog                           0.10.2             \r\nwcwidth                            0.1.8              \r\nwebencodings                       0.5.1              \r\nWerkzeug                           0.16.0             \r\nwheel                              0.34.2             \r\nwidgetsnbextension                 3.5.1              \r\nwin-inet-pton                      1.1.0              \r\nwin-unicode-console                0.5                \r\nwincertstore                       0.2                \r\nwrapt                              1.12.1             \r\nxlrd                               1.2.0              \r\nXlsxWriter                         1.2.8              \r\nxlwings                            0.18.0             \r\nxlwt                               1.3.0              \r\nxmltodict                          0.12.0             \r\nyapf                               0.28.0             \r\nzict                               2.0.0              \r\nzipp                               2.2.0   `\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1116", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1116/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1116/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1116/events", "html_url": "https://github.com/openai/baselines/issues/1116", "id": 646797137, "node_id": "MDU6SXNzdWU2NDY3OTcxMzc=", "number": 1116, "title": "ImportError: cannot import name FlattenObservation", "user": {"login": "ryanmaxwell96", "id": 19628119, "node_id": "MDQ6VXNlcjE5NjI4MTE5", "avatar_url": "https://avatars2.githubusercontent.com/u/19628119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ryanmaxwell96", "html_url": "https://github.com/ryanmaxwell96", "followers_url": "https://api.github.com/users/ryanmaxwell96/followers", "following_url": "https://api.github.com/users/ryanmaxwell96/following{/other_user}", "gists_url": "https://api.github.com/users/ryanmaxwell96/gists{/gist_id}", "starred_url": "https://api.github.com/users/ryanmaxwell96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ryanmaxwell96/subscriptions", "organizations_url": "https://api.github.com/users/ryanmaxwell96/orgs", "repos_url": "https://api.github.com/users/ryanmaxwell96/repos", "events_url": "https://api.github.com/users/ryanmaxwell96/events{/privacy}", "received_events_url": "https://api.github.com/users/ryanmaxwell96/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-28T00:14:25Z", "updated_at": "2020-06-29T18:58:36Z", "closed_at": "2020-06-29T18:57:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey,\r\n\r\nI know someone else created an issue with this error, but I have not seen any resolve so creating my own to bring it back up again. I'm getting this error \"ImportError: cannot import name FlattenObservation\" with gym 0.15.4. Any help would be greatly appreciated!\r\n\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1113", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1113/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1113/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1113/events", "html_url": "https://github.com/openai/baselines/issues/1113", "id": 638220713, "node_id": "MDU6SXNzdWU2MzgyMjA3MTM=", "number": 1113, "title": "AttributeError: 'MultiDiscrete' object has no attribute 'n'", "user": {"login": "hridoylego", "id": 59928531, "node_id": "MDQ6VXNlcjU5OTI4NTMx", "avatar_url": "https://avatars1.githubusercontent.com/u/59928531?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hridoylego", "html_url": "https://github.com/hridoylego", "followers_url": "https://api.github.com/users/hridoylego/followers", "following_url": "https://api.github.com/users/hridoylego/following{/other_user}", "gists_url": "https://api.github.com/users/hridoylego/gists{/gist_id}", "starred_url": "https://api.github.com/users/hridoylego/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hridoylego/subscriptions", "organizations_url": "https://api.github.com/users/hridoylego/orgs", "repos_url": "https://api.github.com/users/hridoylego/repos", "events_url": "https://api.github.com/users/hridoylego/events{/privacy}", "received_events_url": "https://api.github.com/users/hridoylego/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-13T19:51:06Z", "updated_at": "2020-06-19T20:06:52Z", "closed_at": "2020-06-19T20:06:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "I follow the instruction here:\r\nhttps://github.com/Unity-Technologies/ml-agents/tree/master/gym-unity\r\n\r\nTo train the GridWorld agent of ml-agents using the deepq algorithm using the train_unity.py code and ran into the following error:\r\n\r\n```\r\n2020-06-13 15:39:04 INFO [environment.py:111] Connected to Unity environment with package version 1.0.2-preview and communication version 1.0.0\r\n2020-06-13 15:39:05 INFO [environment.py:342] Connected new brain:\r\nGridWorld?team=0\r\n2020-06-13 15:39:05 WARNING [__init__.py:83] `uint8_visual was set to true, but visual observations are not in use. This setting will not have any effect.\r\nLogging to ./logs\r\nWARNING:tensorflow:From c:\\users\\hridoy\\documents\\baselines\\baselines\\common\\tf_util.py:53: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\r\n\r\n2020-06-13 15:39:05 WARNING [deprecation_wrapper.py:119] From c:\\users\\hridoy\\documents\\baselines\\baselines\\common\\tf_util.py:53: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\r\n\r\nWARNING:tensorflow:From c:\\users\\hridoy\\documents\\baselines\\baselines\\common\\tf_util.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\r\n\r\n2020-06-13 15:39:05 WARNING [deprecation_wrapper.py:119] From c:\\users\\hridoy\\documents\\baselines\\baselines\\common\\tf_util.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\r\n\r\nWARNING:tensorflow:From c:\\users\\hridoy\\documents\\baselines\\baselines\\common\\tf_util.py:70: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\r\n\r\n2020-06-13 15:39:05 WARNING [deprecation_wrapper.py:119] From c:\\users\\hridoy\\documents\\baselines\\baselines\\common\\tf_util.py:70: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\r\n\r\nWARNING:tensorflow:From c:\\users\\hridoy\\documents\\baselines\\baselines\\common\\misc_util.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\r\n\r\n2020-06-13 15:39:05 WARNING [deprecation_wrapper.py:119] From c:\\users\\hridoy\\documents\\baselines\\baselines\\common\\misc_util.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\hridoy\\Anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\hridoy\\Anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\hridoy\\ml-agents\\Project\\env\\train_unity.py\", line 35, in <module>\r\n    main()\r\n  File \"C:\\Users\\hridoy\\ml-agents\\Project\\env\\train_unity.py\", line 29, in main\r\n    dueling=True\r\n  File \"c:\\users\\hridoy\\documents\\baselines\\baselines\\deepq\\deepq.py\", line 204, in learn\r\n    num_actions=env.action_space.n,\r\nAttributeError: 'MultiDiscrete' object has no attribute 'n'\r\n2020-06-13 15:39:06 INFO [environment.py:498] Environment shut down with return code 0 (CTRL_C_EVENT).\r\n\r\n```\r\n\r\nHere is the unity setup from which I built the environment:\r\n\r\n![image](https://user-images.githubusercontent.com/59928531/84073795-78cfcd00-a99f-11ea-9397-9af4205bf208.png)\r\n\r\nI had to delete the agent view area or I get the error there is more than 1 agent in the scene.\r\n\r\n\r\nHere are the files in my env directory:\r\n\r\n![image](https://user-images.githubusercontent.com/59928531/84073920-b2a0d380-a99f-11ea-9016-ee7e0d1965bc.png)\r\n\r\n\r\n- Unity Version: [Unity 2019.3.5f1]\r\n- OS + version: [Windows 10]\r\n-_Baselines version_:0.1.6\r\n- _ML-Agents version_: ML-Agents v0.16.1\r\n- _TensorFlow version_: 1.14.0\r\n- _Environment_: Gridworld", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1111", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1111/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1111/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1111/events", "html_url": "https://github.com/openai/baselines/issues/1111", "id": 626643400, "node_id": "MDU6SXNzdWU2MjY2NDM0MDA=", "number": 1111, "title": "baseline tf2 doesn't work", "user": {"login": "sleeplessai", "id": 2018063, "node_id": "MDQ6VXNlcjIwMTgwNjM=", "avatar_url": "https://avatars1.githubusercontent.com/u/2018063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sleeplessai", "html_url": "https://github.com/sleeplessai", "followers_url": "https://api.github.com/users/sleeplessai/followers", "following_url": "https://api.github.com/users/sleeplessai/following{/other_user}", "gists_url": "https://api.github.com/users/sleeplessai/gists{/gist_id}", "starred_url": "https://api.github.com/users/sleeplessai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sleeplessai/subscriptions", "organizations_url": "https://api.github.com/users/sleeplessai/orgs", "repos_url": "https://api.github.com/users/sleeplessai/repos", "events_url": "https://api.github.com/users/sleeplessai/events{/privacy}", "received_events_url": "https://api.github.com/users/sleeplessai/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-28T16:24:35Z", "updated_at": "2020-05-30T12:38:57Z", "closed_at": "2020-05-30T12:38:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "As the title tells.\r\nTF2 branch doesn't work anyway.\r\nSince OpenAI adopted PyTorch, will it have a PyTorch implementation for baselines?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1107", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1107/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1107/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1107/events", "html_url": "https://github.com/openai/baselines/issues/1107", "id": 618636498, "node_id": "MDU6SXNzdWU2MTg2MzY0OTg=", "number": 1107, "title": "Why baselines GAIL uses reward log(1-D) rather than log(D)?", "user": {"login": "zhihaocheng", "id": 37742226, "node_id": "MDQ6VXNlcjM3NzQyMjI2", "avatar_url": "https://avatars1.githubusercontent.com/u/37742226?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhihaocheng", "html_url": "https://github.com/zhihaocheng", "followers_url": "https://api.github.com/users/zhihaocheng/followers", "following_url": "https://api.github.com/users/zhihaocheng/following{/other_user}", "gists_url": "https://api.github.com/users/zhihaocheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhihaocheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhihaocheng/subscriptions", "organizations_url": "https://api.github.com/users/zhihaocheng/orgs", "repos_url": "https://api.github.com/users/zhihaocheng/repos", "events_url": "https://api.github.com/users/zhihaocheng/events{/privacy}", "received_events_url": "https://api.github.com/users/zhihaocheng/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-15T01:37:39Z", "updated_at": "2020-06-08T07:47:03Z", "closed_at": "2020-06-08T07:47:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "I checked the implementation of baselines GAIL. I found that you are using reward log(1-D). But in the original paper, this should be log(D). I am a little confused, could anyone help me?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1103", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1103/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1103/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1103/events", "html_url": "https://github.com/openai/baselines/issues/1103", "id": 612472751, "node_id": "MDU6SXNzdWU2MTI0NzI3NTE=", "number": 1103, "title": "[Classic Control Promble] Training baselines branch TF2-PPO2 to solve Pendulum-v0 extremely slow and unstable", "user": {"login": "MrForExample", "id": 62230687, "node_id": "MDQ6VXNlcjYyMjMwNjg3", "avatar_url": "https://avatars2.githubusercontent.com/u/62230687?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MrForExample", "html_url": "https://github.com/MrForExample", "followers_url": "https://api.github.com/users/MrForExample/followers", "following_url": "https://api.github.com/users/MrForExample/following{/other_user}", "gists_url": "https://api.github.com/users/MrForExample/gists{/gist_id}", "starred_url": "https://api.github.com/users/MrForExample/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MrForExample/subscriptions", "organizations_url": "https://api.github.com/users/MrForExample/orgs", "repos_url": "https://api.github.com/users/MrForExample/repos", "events_url": "https://api.github.com/users/MrForExample/events{/privacy}", "received_events_url": "https://api.github.com/users/MrForExample/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-05T09:42:55Z", "updated_at": "2020-05-10T05:46:44Z", "closed_at": "2020-05-10T05:46:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "Command: \r\n`python -m baselines.run --alg=ppo2 --env=Pendulum-v0 --num_timesteps=1e6 --reward_scale=0.001 --save_path=./models/Pendulm_ppo2`\r\n\r\nThe hyperparameter use in baselines/ppo2/defaults.py:\r\n```\r\ndef classic_control():\r\n    return dict(\r\n        nsteps=128,\r\n        nminibatches=4,\r\n        lam=0.95,\r\n        gamma=0.99,\r\n        noptepochs=4,\r\n        log_interval=1,\r\n        ent_coef=.01,\r\n        lr=lambda f: f * 2e-4,\r\n        cliprange=0.1,\r\n        num_layers=2, \r\n        num_hidden=64, \r\n        activation='relu'\r\n    ) \r\n```\r\n\r\nExample result:\r\n```\r\nBeginning of training\r\n-------------------------------------------\r\n| eplenmean               | 200           |\r\n| eprewmean               | -1.43e+03     |\r\n| fps                     | 836           |\r\n| loss/approxkl           | 1.0275808e-13 |\r\n| loss/clipfrac           | 0.0           |\r\n| loss/policy_entropy     | 1.4534587     |\r\n| loss/policy_loss        | 1.0652002e-07 |\r\n| loss/value_loss         | 0.006119203   |\r\n| misc/explained_variance | -1.88         |\r\n| misc/nupdates           | 11            |\r\n| misc/serial_timesteps   | 1408          |\r\n| misc/time_elapsed       | 2.96          |\r\n| misc/total_timesteps    | 1408          |\r\n-------------------------------------------\r\nAfter 1M step:\r\n-------------------------------------------\r\n| eplenmean               | 200           |\r\n| eprewmean               | -1.43e+03     |\r\n| fps                     | 799           |\r\n| loss/approxkl           | 0.0           |\r\n| loss/clipfrac           | 0.0           |\r\n| loss/policy_entropy     | 13.628587     |\r\n| loss/policy_loss        | -5.378388e-08 |\r\n| loss/value_loss         | 0.0008752448  |\r\n| misc/explained_variance | 0.266         |\r\n| misc/nupdates           | 7812          |\r\n| misc/serial_timesteps   | 999936        |\r\n| misc/time_elapsed       | 1.24e+03      |\r\n| misc/total_timesteps    | 999936        |\r\n-------------------------------------------\r\n```\r\nThe source code of baselines and PPO is download use git and left untouched, I spend quite some time adjust the hyperparameter and it doesn't seem have much effect on result if there any, \r\nDoes any one have any idea what's could go wrong?\r\n    ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1102", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1102/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1102/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1102/events", "html_url": "https://github.com/openai/baselines/issues/1102", "id": 610947108, "node_id": "MDU6SXNzdWU2MTA5NDcxMDg=", "number": 1102, "title": "Blackjack-v0 throws NotImplementedError error", "user": {"login": "Stephanehk", "id": 17076091, "node_id": "MDQ6VXNlcjE3MDc2MDkx", "avatar_url": "https://avatars2.githubusercontent.com/u/17076091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Stephanehk", "html_url": "https://github.com/Stephanehk", "followers_url": "https://api.github.com/users/Stephanehk/followers", "following_url": "https://api.github.com/users/Stephanehk/following{/other_user}", "gists_url": "https://api.github.com/users/Stephanehk/gists{/gist_id}", "starred_url": "https://api.github.com/users/Stephanehk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Stephanehk/subscriptions", "organizations_url": "https://api.github.com/users/Stephanehk/orgs", "repos_url": "https://api.github.com/users/Stephanehk/repos", "events_url": "https://api.github.com/users/Stephanehk/events{/privacy}", "received_events_url": "https://api.github.com/users/Stephanehk/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-05-01T20:16:40Z", "updated_at": "2020-05-01T20:25:20Z", "closed_at": "2020-05-01T20:25:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have gym 0.17.1 installed with python 3 on Mac OS Mojave 10.14.6. Rendering other gym environments such as CartPole-v0 works fine, however, when I render Blackjack-v0  I get the following error:\r\n```\r\n  File \"gym_demo_test.py\", line 10, in <module>\r\n    env.render()\r\n  File \"//anaconda3/envs/cvdevenv/lib/python3.6/site-packages/gym/core.py\", line 105, in render\r\n    raise NotImplementedError\r\nNotImplementedError\r\n```\r\nThe code I am using is OpenAI's demo code, shown below:\r\n```\r\nimport gym\r\nenv = gym.make('Blackjack-v0')\r\nobservation = env.reset()\r\ndone = False\r\n\r\nwhile not done:\r\n    env.render()\r\n    #print(observation)\r\n    #1 moves to the right, 0 moves to the left\r\n    action = env.action_space.sample()\r\n    observation, reward, done, info = env.step(action)\r\n    print (reward)\r\n    if done:\r\n        print(\"Episode finished after {} timesteps\".format(t+1))\r\n        break\r\nenv.close()\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1099", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1099/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1099/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1099/events", "html_url": "https://github.com/openai/baselines/issues/1099", "id": 603363357, "node_id": "MDU6SXNzdWU2MDMzNjMzNTc=", "number": 1099, "title": "Why is the MaxAndSkip not used in wrap_deepmind? ", "user": {"login": "neevparikh", "id": 41182432, "node_id": "MDQ6VXNlcjQxMTgyNDMy", "avatar_url": "https://avatars1.githubusercontent.com/u/41182432?v=4", "gravatar_id": "", "url": "https://api.github.com/users/neevparikh", "html_url": "https://github.com/neevparikh", "followers_url": "https://api.github.com/users/neevparikh/followers", "following_url": "https://api.github.com/users/neevparikh/following{/other_user}", "gists_url": "https://api.github.com/users/neevparikh/gists{/gist_id}", "starred_url": "https://api.github.com/users/neevparikh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/neevparikh/subscriptions", "organizations_url": "https://api.github.com/users/neevparikh/orgs", "repos_url": "https://api.github.com/users/neevparikh/repos", "events_url": "https://api.github.com/users/neevparikh/events{/privacy}", "received_events_url": "https://api.github.com/users/neevparikh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-20T16:20:39Z", "updated_at": "2020-04-20T16:24:14Z", "closed_at": "2020-04-20T16:24:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "The original nature DQN paper maxes over two frames doesn't it? So why does the wrap_deepmind version not use that. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1096", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1096/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1096/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1096/events", "html_url": "https://github.com/openai/baselines/issues/1096", "id": 592535236, "node_id": "MDU6SXNzdWU1OTI1MzUyMzY=", "number": 1096, "title": "Not A2C but REINFORCE with baseline", "user": {"login": "YacineBenameur", "id": 41924979, "node_id": "MDQ6VXNlcjQxOTI0OTc5", "avatar_url": "https://avatars3.githubusercontent.com/u/41924979?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YacineBenameur", "html_url": "https://github.com/YacineBenameur", "followers_url": "https://api.github.com/users/YacineBenameur/followers", "following_url": "https://api.github.com/users/YacineBenameur/following{/other_user}", "gists_url": "https://api.github.com/users/YacineBenameur/gists{/gist_id}", "starred_url": "https://api.github.com/users/YacineBenameur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YacineBenameur/subscriptions", "organizations_url": "https://api.github.com/users/YacineBenameur/orgs", "repos_url": "https://api.github.com/users/YacineBenameur/repos", "events_url": "https://api.github.com/users/YacineBenameur/events{/privacy}", "received_events_url": "https://api.github.com/users/YacineBenameur/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-04-02T10:46:53Z", "updated_at": "2020-04-02T11:35:28Z", "closed_at": "2020-04-02T11:35:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "According to Sutton's book, your implementation of A2C corresponds to a variant of REINFORCE with baseline rather than actual actor-critic method as there's any bootstrapping performed.\r\n**A2C :** Advantage = reward + gamma * V(s') - V(s)\r\n**REINFORCE with baseline** Advantage = Expected_return - V(s)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1090", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1090/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1090/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1090/events", "html_url": "https://github.com/openai/baselines/issues/1090", "id": 580140680, "node_id": "MDU6SXNzdWU1ODAxNDA2ODA=", "number": 1090, "title": "SubprocVecEnv not treated as VecEnv by PPO2", "user": {"login": "windweller", "id": 4699797, "node_id": "MDQ6VXNlcjQ2OTk3OTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/4699797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/windweller", "html_url": "https://github.com/windweller", "followers_url": "https://api.github.com/users/windweller/followers", "following_url": "https://api.github.com/users/windweller/following{/other_user}", "gists_url": "https://api.github.com/users/windweller/gists{/gist_id}", "starred_url": "https://api.github.com/users/windweller/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/windweller/subscriptions", "organizations_url": "https://api.github.com/users/windweller/orgs", "repos_url": "https://api.github.com/users/windweller/repos", "events_url": "https://api.github.com/users/windweller/events{/privacy}", "received_events_url": "https://api.github.com/users/windweller/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-12T18:30:53Z", "updated_at": "2020-03-13T01:51:25Z", "closed_at": "2020-03-12T20:04:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to train a CNN-LSTM policy using PPO2 on a custom game environment.\r\n\r\n```python\r\nfrom baselines.common.vec_env.subproc_vec_env import SubprocVecEnv\r\n\r\nclass BounceVecEnv(SubprocVecEnv):\r\n    def __init__(self, env_maker, num_envs):\r\n        self.metadata = {'render.modes': []}\r\n        self.reward_range = (-5, 5)\r\n\r\n        env_fns = [env_maker.make for _ in range(num_envs)]\r\n\r\n        super().__init__(env_fns)\r\n        self.dummy_info = [{} for _ in range(num_envs)]\r\n```\r\n\r\nThen in the main code:\r\n\r\n```python\r\nenv = BounceVecEnv(env_maker, num_envs=2)\r\nprint(isinstance(env, VecEnv))\r\n# True\r\nmodel = PPO2('CnnLstmPolicy', env, nminibatches=args.nminibatches, verbose=1)\r\nmodel.learn(5)\r\n# Wrapping the env in a DummyVecEnv\r\n```\r\n\r\nPPO2 will always wrap my environment in a `DummyVecEnv` even though my environment was already wrapped in `SubprocVecEnv`. This leads to a shape mismatch issue.\r\n\r\nCan anyone maybe let me know how to debug this issue and why it's happening? \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1084", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1084/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1084/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1084/events", "html_url": "https://github.com/openai/baselines/issues/1084", "id": 565947977, "node_id": "MDU6SXNzdWU1NjU5NDc5Nzc=", "number": 1084, "title": "How are my Hindsight Experience Replay (HER) results obtained 50 times faster than original paper?", "user": {"login": "RyanRizzo96", "id": 31866965, "node_id": "MDQ6VXNlcjMxODY2OTY1", "avatar_url": "https://avatars3.githubusercontent.com/u/31866965?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RyanRizzo96", "html_url": "https://github.com/RyanRizzo96", "followers_url": "https://api.github.com/users/RyanRizzo96/followers", "following_url": "https://api.github.com/users/RyanRizzo96/following{/other_user}", "gists_url": "https://api.github.com/users/RyanRizzo96/gists{/gist_id}", "starred_url": "https://api.github.com/users/RyanRizzo96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RyanRizzo96/subscriptions", "organizations_url": "https://api.github.com/users/RyanRizzo96/orgs", "repos_url": "https://api.github.com/users/RyanRizzo96/repos", "events_url": "https://api.github.com/users/RyanRizzo96/events{/privacy}", "received_events_url": "https://api.github.com/users/RyanRizzo96/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-02-16T18:32:57Z", "updated_at": "2020-02-23T12:50:26Z", "closed_at": "2020-02-23T12:50:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am reproducing the results from Hindsight Experience Replay by Andrychowicz et. al. In the original paper they present the results below, where the agent is trained for 200 epochs.\r\n\r\n200 epochs * 800 episodes * 50 time steps = 8,000,000 total time steps.\r\n\r\n[![enter image description here][1]][1]\r\n\r\nI try to reproduce the results but instead of using 8 cpu cores, I am using 16 CPU cores.\r\n\r\n\r\n----------\r\n## Fetch Push ##\r\n\r\nI train the `FetchPush` for 80 epochs, but with only 50 episodes per epoch. Therefore 80 * 50 * 50 = 200,000 iterations. I present the curve below, generated using **two random seeds**:\r\n\r\nAfter 20 epochs = 50,000 iterations we solve this environment. In the paper above, it took the original authors 100 episodes = 4,000,000 iterations to do so.\r\n\r\nHow is my algorithm converging **50 times faster**?\r\n\r\n[![enter image description here][2]][2]\r\n\r\n----------\r\n## Pick and Place ##\r\n\r\nI train the `FetchPickAndPlace` for 80 epochs, but with only 50 episodes per epoch. Therefore 80 * 50 * 50 = 200,000 iterations. I present the curve below, generated using **three random seeds**:\r\n\r\n[![enter image description here][3]][3]\r\n\r\n\r\nand logger output for the first two epochs, showing that indeed I have 50 episodes per epoch:\r\n\r\n\r\n[![enter image description here][4]][4]\r\n\r\nNow, as can be seen from my tensorboard plot, after 40 epochs we get a steady success rate, close to 1. 40 epochs * 50 episodes * 50 time steps = 100,000 iterations. Therefore it took the algorithm approximately 100,000 time steps to learn this environment.\r\n\r\nThe original paper took approximately 50 * 800 * 50 = 2,000,000 time steps to achieve the same goal.\r\n\r\n\r\nHow is it that in my case the environment was solved nearly **20 times faster**? Are there any flaws in my workings above? Surely I am doing something wrong, right?\r\n\r\nResults are also faster than another paper which also uses 19 MPI workers:\r\n\r\n[![enter image description here][5]][5]\r\n\r\nAs stated in this paper: \"We train for  50 epochs (one epoch consists of 19  2  50 = 1 900 full episodes), which amounts to a total of 4.75 x10^6 timesteps.\" It took around 2,000,000 timesteps to reach a median success rate of 0.9.\r\n\r\n----------\r\n**Summary**\r\n\r\n![image](https://user-images.githubusercontent.com/31866965/74610841-1a809500-50f7-11ea-8bdf-5ccb840d2e40.png)\r\n\r\n\r\nAny suggestions on what I may be doing wrong would be appreciated.\r\n\r\n  [1]: https://i.stack.imgur.com/Bw6Sj.png\r\n  [2]: https://i.stack.imgur.com/vpOCd.png\r\n  [3]: https://i.stack.imgur.com/3BMhE.png\r\n  [4]: https://i.stack.imgur.com/aGESH.png\r\n  [5]: https://i.stack.imgur.com/QiTSg.png", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1083", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1083/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1083/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1083/events", "html_url": "https://github.com/openai/baselines/issues/1083", "id": 562748819, "node_id": "MDU6SXNzdWU1NjI3NDg4MTk=", "number": 1083, "title": "Her.RolloutWorker not finding env.reset method", "user": {"login": "rickstaa", "id": 17570430, "node_id": "MDQ6VXNlcjE3NTcwNDMw", "avatar_url": "https://avatars0.githubusercontent.com/u/17570430?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rickstaa", "html_url": "https://github.com/rickstaa", "followers_url": "https://api.github.com/users/rickstaa/followers", "following_url": "https://api.github.com/users/rickstaa/following{/other_user}", "gists_url": "https://api.github.com/users/rickstaa/gists{/gist_id}", "starred_url": "https://api.github.com/users/rickstaa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rickstaa/subscriptions", "organizations_url": "https://api.github.com/users/rickstaa/orgs", "repos_url": "https://api.github.com/users/rickstaa/repos", "events_url": "https://api.github.com/users/rickstaa/events{/privacy}", "received_events_url": "https://api.github.com/users/rickstaa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-02-10T18:33:48Z", "updated_at": "2020-02-27T15:29:46Z", "closed_at": "2020-02-27T15:29:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am currently trying to use the HER algorithm for training a `fetch` robot. I do this using the `train.py` script below (see [this repository for the full code](https://github.com/rickstaa/my_fetch_training)).\r\n\r\n```\r\n#! /usr/bin/env python\r\n\"\"\"\r\nUses HER algorithm which stands for H*indsight *Experience Replay. This algorithm\r\nuses the experience replay from the DQL but chooses the goal after the episode is over\r\n(hindsignt).\r\n\"\"\"\r\nimport os\r\nimport sys\r\n\r\nimport click\r\nimport numpy as np\r\nimport json\r\nfrom mpi4py import MPI\r\n\r\nfrom baselines import logger\r\nfrom baselines.common import set_global_seeds\r\nfrom baselines.common.mpi_moments import mpi_moments\r\nimport baselines.her.experiment.config as config\r\nfrom baselines.her.rollout import RolloutWorker\r\nfrom baselines.her.util import mpi_fork\r\nfrom baselines.common.cmd_util import make_vec_env\r\nfrom baselines.common.cmd_util import make_robotics_env\r\nimport gym\r\n\r\nfrom subprocess import CalledProcessError\r\n\r\n# from gym.envs.robotics.fetch import reach\r\nimport my_fetch_task_env\r\nimport rospy\r\n\r\n\r\ndef mpi_average(value):\r\n    if value == []:\r\n        value = [0.0]\r\n    if not isinstance(value, list):\r\n        value = [value]\r\n    return mpi_moments(np.array(value))[0]\r\n\r\n\r\ndef train(\r\n    policy,\r\n    rollout_worker,\r\n    evaluator,\r\n    n_epochs,\r\n    n_test_rollouts,\r\n    n_cycles,\r\n    n_batches,\r\n    policy_save_interval,\r\n    save_policies,\r\n    **kwargs\r\n):\r\n    rank = MPI.COMM_WORLD.Get_rank()\r\n\r\n    latest_policy_path = os.path.join(logger.get_dir(), \"policy_latest.pkl\")\r\n    best_policy_path = os.path.join(logger.get_dir(), \"policy_best.pkl\")\r\n    periodic_policy_path = os.path.join(logger.get_dir(), \"policy_{}.pkl\")\r\n\r\n    logger.info(\"Training...\")\r\n    best_success_rate = -1\r\n    for epoch in range(n_epochs):\r\n        # train\r\n        rollout_worker.clear_history()\r\n        for _ in range(n_cycles):\r\n            episode = rollout_worker.generate_rollouts()\r\n            policy.store_episode(episode)\r\n            for _ in range(n_batches):\r\n                policy.train()\r\n            policy.update_target_net()\r\n\r\n        # test\r\n        evaluator.clear_history()\r\n        for _ in range(n_test_rollouts):\r\n            evaluator.generate_rollouts()\r\n\r\n        # record logs\r\n        logger.record_tabular(\"epoch\", epoch)\r\n        for key, val in evaluator.logs(\"test\"):\r\n            logger.record_tabular(key, mpi_average(val))\r\n        for key, val in rollout_worker.logs(\"train\"):\r\n            logger.record_tabular(key, mpi_average(val))\r\n        for key, val in policy.logs():\r\n            logger.record_tabular(key, mpi_average(val))\r\n\r\n        if rank == 0:\r\n            logger.dump_tabular()\r\n\r\n        # save the policy if it's better than the previous ones\r\n        success_rate = mpi_average(evaluator.current_success_rate())\r\n        if rank == 0 and success_rate >= best_success_rate and save_policies:\r\n            best_success_rate = success_rate\r\n            logger.info(\r\n                \"New best success rate: {}. Saving policy to {} ...\".format(\r\n                    best_success_rate, best_policy_path\r\n                )\r\n            )\r\n            evaluator.save_policy(best_policy_path)\r\n            evaluator.save_policy(latest_policy_path)\r\n        if (\r\n            rank == 0\r\n            and policy_save_interval > 0\r\n            and epoch % policy_save_interval == 0\r\n            and save_policies\r\n        ):\r\n            policy_path = periodic_policy_path.format(epoch)\r\n            logger.info(\"Saving periodic policy to {} ...\".format(policy_path))\r\n            evaluator.save_policy(policy_path)\r\n\r\n        # make sure that different threads have different seeds\r\n        local_uniform = np.random.uniform(size=(1,))\r\n        root_uniform = local_uniform.copy()\r\n        MPI.COMM_WORLD.Bcast(root_uniform, root=0)\r\n        if rank != 0:\r\n            assert local_uniform[0] != root_uniform[0]\r\n\r\n\r\ndef launch(\r\n    env,\r\n    logdir,\r\n    n_epochs,\r\n    num_cpu,\r\n    seed,\r\n    replay_strategy,\r\n    policy_save_interval,\r\n    clip_return,\r\n    override_params={},\r\n    save_policies=True,\r\n):\r\n    # Fork for multi-CPU MPI implementation.\r\n    if num_cpu > 1:\r\n        try:\r\n            whoami = mpi_fork(num_cpu, [\"--bind-to\", \"core\"])\r\n        except CalledProcessError:\r\n            # fancy version of mpi call failed, try simple version\r\n            whoami = mpi_fork(num_cpu)\r\n\r\n        if whoami == \"parent\":\r\n            sys.exit(0)\r\n        import baselines.common.tf_util as U\r\n\r\n        U.single_threaded_session().__enter__()\r\n    rank = MPI.COMM_WORLD.Get_rank()\r\n\r\n    # Configure logging\r\n    if rank == 0:\r\n        if logdir or logger.get_dir() is None:\r\n            logger.configure(dir=logdir)\r\n    else:\r\n        logger.configure()\r\n    logdir = logger.get_dir()\r\n    assert logdir is not None\r\n    os.makedirs(logdir, exist_ok=True)\r\n\r\n    # Seed everything.\r\n    rank_seed = seed + 1000000 * rank\r\n    set_global_seeds(rank_seed)\r\n\r\n    # Prepare params.\r\n    params = config.DEFAULT_PARAMS\r\n    params[\"env_name\"] = env\r\n    params[\"replay_strategy\"] = replay_strategy\r\n    if env in config.DEFAULT_ENV_PARAMS:\r\n        params.update(\r\n            config.DEFAULT_ENV_PARAMS[env]\r\n        )  # merge env-specific parameters in\r\n    params.update(**override_params)  # makes it possible to override any parameter\r\n    with open(os.path.join(logger.get_dir(), \"params.json\"), \"w\") as f:\r\n        json.dump(params, f)\r\n    params = config.prepare_params(params)\r\n    config.log_params(params, logger=logger)\r\n\r\n    if num_cpu == 1:\r\n        logger.warn()\r\n        logger.warn(\"*** Warning ***\")\r\n        logger.warn(\r\n            \"You are running HER with just a single MPI worker. This will work, but the \"\r\n            + \"experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) \"\r\n            + \"were obtained with --num_cpu 19. This makes a significant difference and if you \"\r\n            + \"are looking to reproduce those results, be aware of this. Please also refer to \"\r\n            + \"https://github.com/openai/baselines/issues/314 for further details.\"\r\n        )\r\n        logger.warn(\"****************\")\r\n        logger.warn()\r\n\r\n    dims = config.configure_dims(params)\r\n    policy = config.configure_ddpg(dims=dims, params=params, clip_return=clip_return)\r\n\r\n    rollout_params = {\r\n        \"exploit\": False,\r\n        \"use_target_net\": False,\r\n        \"use_demo_states\": True,\r\n        \"compute_Q\": False,\r\n        \"T\": params[\"T\"],\r\n    }\r\n\r\n    eval_params = {\r\n        \"exploit\": True,\r\n        \"use_target_net\": params[\"test_with_polyak\"],\r\n        \"use_demo_states\": False,\r\n        \"compute_Q\": True,\r\n        \"T\": params[\"T\"],\r\n    }\r\n\r\n    for name in [\"T\", \"rollout_batch_size\", \"gamma\", \"noise_eps\", \"random_eps\"]:\r\n        rollout_params[name] = params[name]\r\n        eval_params[name] = params[name]\r\n\r\n    # FIXME: VERSION 1: Use params[\"make_env\"] variable to create environment\r\n    env_vec = params[\"make_env\"]\r\n\r\n    # FIXME: VERSION 2: Initialize vector environment using make_vect_env class\r\n    # env_vec = make_vec_env(env, 'robotics', num_env=1, seed=None)\r\n    # env_vec = make_vec_env(env, 'robotics', num_env=1, seed=rank_seed)\r\n\r\n    # FIXME: try2: Initialize vector environment using the make_robotics_env class\r\n    # env_vec = make_robotics_env(env, seed=rank_seed, rank=rank)\r\n\r\n    # FIXME: try3: Initialize vector environment using the original gym.make method\r\n    env_vec = gym.make(env)\r\n    env_vec.seed(rank_seed)\r\n\r\n    # Create Rollout worker\r\n    rollout_worker = RolloutWorker(\r\n        env_vec, policy, dims, logger, **rollout_params\r\n    )\r\n    rollout_worker.seed(rank_seed)\r\n\r\n    evaluator = RolloutWorker(env_vec, policy, dims, logger, **eval_params)\r\n    evaluator.seed(rank_seed)\r\n\r\n    train(\r\n        logdir=logdir,\r\n        policy=policy,\r\n        rollout_worker=rollout_worker,\r\n        evaluator=evaluator,\r\n        n_epochs=n_epochs,\r\n        n_test_rollouts=params[\"n_test_rollouts\"],\r\n        n_cycles=params[\"n_cycles\"],\r\n        n_batches=params[\"n_batches\"],\r\n        policy_save_interval=policy_save_interval,\r\n        save_policies=save_policies,\r\n    )\r\n\r\n\r\n@click.command()\r\n@click.option(\r\n    \"--env\",\r\n    type=str,\r\n    default=\"FetchReach-v0\",\r\n    help=\"the name of the OpenAI Gym environment that you want to train on\",\r\n)\r\n@click.option(\r\n    \"--logdir\",\r\n    type=str,\r\n    default=None,\r\n    help=\"the path to where logs and policy pickles should go. If not specified, creates a folder in /tmp/\",\r\n)\r\n@click.option(\r\n    \"--n_epochs\", type=int, default=50, help=\"the number of training epochs to run\"\r\n)\r\n@click.option(\r\n    \"--num_cpu\", type=int, default=1, help=\"the number of CPU cores to use (using MPI)\"\r\n)\r\n@click.option(\r\n    \"--seed\",\r\n    type=int,\r\n    default=0,\r\n    help=\"the random seed used to seed both the environment and the training code\",\r\n)\r\n@click.option(\r\n    \"--policy_save_interval\",\r\n    type=int,\r\n    default=5,\r\n    help=\"the interval with which policy pickles are saved. If set to 0, only the best and latest policy will be pickled.\",\r\n)\r\n@click.option(\r\n    \"--replay_strategy\",\r\n    type=click.Choice([\"future\", \"none\"]),\r\n    default=\"future\",\r\n    help='the HER replay strategy to be used. \"future\" uses HER, \"none\" disables HER.',\r\n)\r\n@click.option(\r\n    \"--clip_return\",\r\n    type=int,\r\n    default=1,\r\n    help=\"whether or not returns should be clipped\",\r\n)\r\ndef main(**kwargs):\r\n    rospy.init_node(\"train_fetch_her\")\r\n    launch(**kwargs)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n```\r\n\r\nUnfortunately, I when running the `train.py` file I get the following error message:\r\n\r\n```\r\nAttributeError: 'function' object has no attribute 'reset' inf rollout.py\r\n```\r\n\r\nThe following two solutions, that can be used to get rid of this error, were given in #798 by \r\n@pzhokhov:\r\n\r\n- Revert back to the old version 146bbf886ba533fe08b07e01d1c0356aaf7fcc80.\r\n- Add two lines of code before initiating the RolloutWorker.\r\n\r\nThese solutions, however, did not solve the problem for me (see the report of each solution below).\r\n\r\n**Option 1: Revert back to the old version 146bbf886ba533fe08b07e01d1c0356aaf7fcc80:**\r\n\r\nI now run into the following error, when running the `train.py` file:\r\n\r\n```\r\nModuleNotFoundError: No module named 'mujoco_py'\r\n```\r\n\r\nAs I would rather add modifications to my train.py script than buying an additional mujoco license, I tried the second solution.\r\n\r\n**Option 2: Initiate environment before  initializing RolloutWorker**\r\n\r\nI therefore tried adding the following code before the RolloutWorker initiation:\r\n\r\n```\r\nfrom baselines.common.cmd_util import make_vec_env\r\nenv = make_vec_env(env, 'robotics', num_env=1, seed=None)\r\n```\r\n\r\nbut when running the `train_modified.py` script I now receive the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"./src/my_fetch_train/scripts/train_modified.py\", line 280, in <module>\r\n    main()\r\n  File \"/home/ricks/.catkin_ws_python3/openai_venv/lib/python3.6/site-packages/click/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/ricks/.catkin_ws_python3/openai_venv/lib/python3.6/site-packages/click/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/ricks/.catkin_ws_python3/openai_venv/lib/python3.6/site-packages/click/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/ricks/.catkin_ws_python3/openai_venv/lib/python3.6/site-packages/click/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"./src/my_fetch_train/scripts/train_modified.py\", line 276, in main\r\n    launch(**kwargs)\r\n  File \"./src/my_fetch_train/scripts/train_modified.py\", line 210, in launch\r\n    env_vec, policy, dims, logger, **rollout_params\r\n  File \"/home/ricks/Development/robot_academy_ws/src/baselines/baselines/her/util.py\", line 36, in wrapper\r\n    return method(*positional_args, **keyword_args)\r\n  File \"/home/ricks/Development/robot_academy_ws/src/baselines/baselines/her/rollout.py\", line 41, in __init__\r\n    self.reset_all_rollouts()\r\n  File \"/home/ricks/Development/robot_academy_ws/src/baselines/baselines/her/rollout.py\", line 46, in reset_all_rollouts\r\n    self.initial_o = self.obs_dict['observation']\r\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\r\n```\r\n\r\nI presume this is caused since the [DummyEnv](https://github.com/openai/baselines/blob/master/baselines/common/vec_env/dummy_vec_env.py) class is used instead of my own environment. As a result, I tried the following code:\r\n\r\n```\r\nfrom baselines.common.cmd_util import make_robotics_env\r\nenv_vec= make_robotics_env(env, seed=rank_seed, rank=rank)\r\n```\r\n\r\nBut this also gave me the error above. Finally, I tried inputting a normal `gym.env` instead of a vectorized env by using the following code:\r\n\r\n```\r\n    rollout_worker = RolloutWorker(\r\n        env_vec, policy, dims, logger, **rollout_params\r\n    )\r\n    rollout_worker.seed(rank_seed)\r\n```\r\n\r\nBut when doing this, I receive the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"./src/my_fetch_train/scripts/train_modified.py\", line 289, in <module>\r\n    main()\r\n  File \"/home/ricks/.catkin_ws_python3/openai_venv/lib/python3.6/site-packages/click/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/ricks/.catkin_ws_python3/openai_venv/lib/python3.6/site-packages/click/core.py\", line 717, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/home/ricks/.catkin_ws_python3/openai_venv/lib/python3.6/site-packages/click/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/ricks/.catkin_ws_python3/openai_venv/lib/python3.6/site-packages/click/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"./src/my_fetch_train/scripts/train_modified.py\", line 285, in main\r\n    launch(**kwargs)\r\n  File \"./src/my_fetch_train/scripts/train_modified.py\", line 221, in launch\r\n    rollout_worker.seed(rank_seed)\r\nAttributeError: 'RolloutWorker' object has no attribute 'seed'\r\n```\r\n\r\nI was, therefore, wondering if somebody has an example on how to use the HER algorithm with the master branch of the [openai/baselines](https://github.com/openai/baselines/blob/master/baselines) repository?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1065", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1065/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1065/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1065/events", "html_url": "https://github.com/openai/baselines/issues/1065", "id": 547123992, "node_id": "MDU6SXNzdWU1NDcxMjM5OTI=", "number": 1065, "title": "Majority errors when running pytest after install (tf2)", "user": {"login": "rsekelsky", "id": 17655959, "node_id": "MDQ6VXNlcjE3NjU1OTU5", "avatar_url": "https://avatars1.githubusercontent.com/u/17655959?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsekelsky", "html_url": "https://github.com/rsekelsky", "followers_url": "https://api.github.com/users/rsekelsky/followers", "following_url": "https://api.github.com/users/rsekelsky/following{/other_user}", "gists_url": "https://api.github.com/users/rsekelsky/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsekelsky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsekelsky/subscriptions", "organizations_url": "https://api.github.com/users/rsekelsky/orgs", "repos_url": "https://api.github.com/users/rsekelsky/repos", "events_url": "https://api.github.com/users/rsekelsky/events{/privacy}", "received_events_url": "https://api.github.com/users/rsekelsky/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-01-08T21:53:55Z", "updated_at": "2020-01-09T17:03:24Z", "closed_at": "2020-01-09T17:03:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have an Anaconda environment with tensorflow 2.0 installed in it currently, running on Ubuntu 18.04. I went through all the installation steps in the readme and made sure I installed from the tf2 branch, but when I run pytest I get 24 errors and 4 successes, the final error being a broken pipe. I could post specific things from the pytest if I can find them, but the output is so large I didn't bother posting it here. Current python version is 3.7.\r\n\r\nI ran into this issue back when I was trying to install this on Windows 10, but not sure which errors I was getting. I vaguely remember having to install some other gym packages, and then a wheel failing, but I figure it's better to start from scratch here. Anyone have advice?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1046", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1046/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1046/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1046/events", "html_url": "https://github.com/openai/baselines/issues/1046", "id": 530076006, "node_id": "MDU6SXNzdWU1MzAwNzYwMDY=", "number": 1046, "title": "Help with meaning of stats/ log", "user": {"login": "lpsantao", "id": 36695370, "node_id": "MDQ6VXNlcjM2Njk1Mzcw", "avatar_url": "https://avatars2.githubusercontent.com/u/36695370?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lpsantao", "html_url": "https://github.com/lpsantao", "followers_url": "https://api.github.com/users/lpsantao/followers", "following_url": "https://api.github.com/users/lpsantao/following{/other_user}", "gists_url": "https://api.github.com/users/lpsantao/gists{/gist_id}", "starred_url": "https://api.github.com/users/lpsantao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lpsantao/subscriptions", "organizations_url": "https://api.github.com/users/lpsantao/orgs", "repos_url": "https://api.github.com/users/lpsantao/repos", "events_url": "https://api.github.com/users/lpsantao/events{/privacy}", "received_events_url": "https://api.github.com/users/lpsantao/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-28T21:08:12Z", "updated_at": "2019-12-30T18:33:47Z", "closed_at": "2019-12-30T18:33:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\nI'm kind of new to RL and openai gym so I was wondering if anyone could help me with the following questions:\r\n- what is the meaning of stats_g and stats_o given every epoc of training in the HER algorithm?\r\n- how is the test/training split done? \r\nhere's a log sample:\r\nTraining...\r\n| epoch              | 0        |\r\n| stats_g/mean       | 0.893    |\r\n| stats_g/std        | 0.122    |\r\n| stats_o/mean       | 0.269    |\r\n| stats_o/std        | 0.0392   |\r\n| test/episode       | 10       |\r\n| test/mean_Q        | -0.602   |\r\n| test/success_rate  | 0.5      |\r\n| train/episode      | 50       |  \r\n| train/success_rate | 0.4        |\r\n\r\nthank you!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1041", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1041/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1041/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1041/events", "html_url": "https://github.com/openai/baselines/issues/1041", "id": 526371246, "node_id": "MDU6SXNzdWU1MjYzNzEyNDY=", "number": 1041, "title": "About transfer to tf2 ,no module from tensorflow.contrib.staging ", "user": {"login": "YunchuZhang", "id": 33641269, "node_id": "MDQ6VXNlcjMzNjQxMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/33641269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YunchuZhang", "html_url": "https://github.com/YunchuZhang", "followers_url": "https://api.github.com/users/YunchuZhang/followers", "following_url": "https://api.github.com/users/YunchuZhang/following{/other_user}", "gists_url": "https://api.github.com/users/YunchuZhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/YunchuZhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YunchuZhang/subscriptions", "organizations_url": "https://api.github.com/users/YunchuZhang/orgs", "repos_url": "https://api.github.com/users/YunchuZhang/repos", "events_url": "https://api.github.com/users/YunchuZhang/events{/privacy}", "received_events_url": "https://api.github.com/users/YunchuZhang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-21T05:20:44Z", "updated_at": "2019-11-25T04:09:51Z", "closed_at": "2019-11-25T04:09:51Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there,\r\nI just want to transfer all the code to tf2 and see that tf.contrib is deleted , i want to ask that do you know which function or package could replace the  StagingArea? \r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1035", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1035/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1035/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1035/events", "html_url": "https://github.com/openai/baselines/issues/1035", "id": 521860189, "node_id": "MDU6SXNzdWU1MjE4NjAxODk=", "number": 1035, "title": "GAIL: Humanoid data environment id", "user": {"login": "Jendker", "id": 14967831, "node_id": "MDQ6VXNlcjE0OTY3ODMx", "avatar_url": "https://avatars1.githubusercontent.com/u/14967831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jendker", "html_url": "https://github.com/Jendker", "followers_url": "https://api.github.com/users/Jendker/followers", "following_url": "https://api.github.com/users/Jendker/following{/other_user}", "gists_url": "https://api.github.com/users/Jendker/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jendker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jendker/subscriptions", "organizations_url": "https://api.github.com/users/Jendker/orgs", "repos_url": "https://api.github.com/users/Jendker/repos", "events_url": "https://api.github.com/users/Jendker/events{/privacy}", "received_events_url": "https://api.github.com/users/Jendker/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-11-12T23:21:02Z", "updated_at": "2020-07-02T13:20:47Z", "closed_at": "2020-07-02T13:20:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "What is the proper value of the `env_id` parameter which would match the data Humanoid or HumanoidStandup? When trying `Humanoid-v2,v3` or `HumanoidStandup-v2,v3` I get:\r\n\r\n```\r\nValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 376 and the array at index 1 has size 11\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1031", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1031/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1031/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1031/events", "html_url": "https://github.com/openai/baselines/issues/1031", "id": 519077964, "node_id": "MDU6SXNzdWU1MTkwNzc5NjQ=", "number": 1031, "title": "module 'stable_baselines.deepq' has no attribute 'models'", "user": {"login": "weixiang-95", "id": 56947639, "node_id": "MDQ6VXNlcjU2OTQ3NjM5", "avatar_url": "https://avatars1.githubusercontent.com/u/56947639?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weixiang-95", "html_url": "https://github.com/weixiang-95", "followers_url": "https://api.github.com/users/weixiang-95/followers", "following_url": "https://api.github.com/users/weixiang-95/following{/other_user}", "gists_url": "https://api.github.com/users/weixiang-95/gists{/gist_id}", "starred_url": "https://api.github.com/users/weixiang-95/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weixiang-95/subscriptions", "organizations_url": "https://api.github.com/users/weixiang-95/orgs", "repos_url": "https://api.github.com/users/weixiang-95/repos", "events_url": "https://api.github.com/users/weixiang-95/events{/privacy}", "received_events_url": "https://api.github.com/users/weixiang-95/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-11-07T06:54:15Z", "updated_at": "2019-11-08T22:42:58Z", "closed_at": "2019-11-08T22:42:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1023", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1023/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1023/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1023/events", "html_url": "https://github.com/openai/baselines/issues/1023", "id": 513890367, "node_id": "MDU6SXNzdWU1MTM4OTAzNjc=", "number": 1023, "title": "Python crashes when starting baselines or pytest", "user": {"login": "Phantomb", "id": 5164642, "node_id": "MDQ6VXNlcjUxNjQ2NDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/5164642?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Phantomb", "html_url": "https://github.com/Phantomb", "followers_url": "https://api.github.com/users/Phantomb/followers", "following_url": "https://api.github.com/users/Phantomb/following{/other_user}", "gists_url": "https://api.github.com/users/Phantomb/gists{/gist_id}", "starred_url": "https://api.github.com/users/Phantomb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Phantomb/subscriptions", "organizations_url": "https://api.github.com/users/Phantomb/orgs", "repos_url": "https://api.github.com/users/Phantomb/repos", "events_url": "https://api.github.com/users/Phantomb/events{/privacy}", "received_events_url": "https://api.github.com/users/Phantomb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-10-29T12:43:17Z", "updated_at": "2019-11-08T22:51:32Z", "closed_at": "2019-11-08T22:51:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "See the image. \r\n![image](https://user-images.githubusercontent.com/5164642/67768102-19493080-fa52-11e9-804d-4bdbeccfd21f.png)\r\n\r\nWhat exactly causes this, and what can I do about it?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1020", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1020/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1020/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1020/events", "html_url": "https://github.com/openai/baselines/issues/1020", "id": 507956241, "node_id": "MDU6SXNzdWU1MDc5NTYyNDE=", "number": 1020, "title": "Mismatch between plotted iterations and actual iterations", "user": {"login": "RyanRizzo96", "id": 31866965, "node_id": "MDQ6VXNlcjMxODY2OTY1", "avatar_url": "https://avatars3.githubusercontent.com/u/31866965?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RyanRizzo96", "html_url": "https://github.com/RyanRizzo96", "followers_url": "https://api.github.com/users/RyanRizzo96/followers", "following_url": "https://api.github.com/users/RyanRizzo96/following{/other_user}", "gists_url": "https://api.github.com/users/RyanRizzo96/gists{/gist_id}", "starred_url": "https://api.github.com/users/RyanRizzo96/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RyanRizzo96/subscriptions", "organizations_url": "https://api.github.com/users/RyanRizzo96/orgs", "repos_url": "https://api.github.com/users/RyanRizzo96/repos", "events_url": "https://api.github.com/users/RyanRizzo96/events{/privacy}", "received_events_url": "https://api.github.com/users/RyanRizzo96/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-10-16T16:19:24Z", "updated_at": "2019-11-08T23:14:55Z", "closed_at": "2019-11-08T23:14:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am training HER on FetchReach for 10k iterations:\r\n\r\n`\r\npython3 -m baselines.run --alg=her --env=FetchReach-v1 --num_timesteps=10000 --save_path=~/models/testRum_HER_reach_10k --log_path=~/logs/HER/test_10k\r\n`\r\n\r\nI then use the information [here](https://github.com/openai/baselines/blob/master/docs/viz/viz.ipynb) to visualize the results. I present my code below. AS can be seen the plotted result shows 20k iterations whereas the actual number of iterations is 10k. Any idea why this happens?\r\n\r\n```\r\n\r\nfrom baselines.common import plot_util as plot\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\nresults = plot.load_results('~/logs/HER')\r\nprint(results)\r\nr = results[0]\r\nplt.plot(np.cumsum(r.monitor.l), plot.smooth(r.monitor.r, radius=10))  # radius to smoother\r\nplt.xlabel('Iterations')\r\nplt.ylabel('Reward')\r\nplt.show()\r\n\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/31866965/66938360-56202b00-f041-11e9-9aed-b62835f15d5a.png)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1018", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1018/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1018/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1018/events", "html_url": "https://github.com/openai/baselines/issues/1018", "id": 505636367, "node_id": "MDU6SXNzdWU1MDU2MzYzNjc=", "number": 1018, "title": "About mpi running for HER DDPG", "user": {"login": "YunchuZhang", "id": 33641269, "node_id": "MDQ6VXNlcjMzNjQxMjY5", "avatar_url": "https://avatars1.githubusercontent.com/u/33641269?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YunchuZhang", "html_url": "https://github.com/YunchuZhang", "followers_url": "https://api.github.com/users/YunchuZhang/followers", "following_url": "https://api.github.com/users/YunchuZhang/following{/other_user}", "gists_url": "https://api.github.com/users/YunchuZhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/YunchuZhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YunchuZhang/subscriptions", "organizations_url": "https://api.github.com/users/YunchuZhang/orgs", "repos_url": "https://api.github.com/users/YunchuZhang/repos", "events_url": "https://api.github.com/users/YunchuZhang/events{/privacy}", "received_events_url": "https://api.github.com/users/YunchuZhang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-10-11T04:51:22Z", "updated_at": "2019-11-08T23:01:07Z", "closed_at": "2019-11-08T23:01:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi there, \r\ndo you know how that mpirun error about? \r\nWhen i use :mpirun -np 8 python -m baselines.run --alg=her --env= FetchReach-v1   --num_timesteps=2e7\r\nError: node list format not recognized. Try using '-hosts=<hostnames>'.\r\nAnd when i add '-hosts':mpirun -np 8 -hosts python -m baselines.run --alg=her --env= FetchReach-v1   --num_timesteps=2e7\r\nit shows:\r\n[mpiexec@compute-0-38.local] match_arg (utils/args/args.c:163): unrecognized argument m\r\n[mpiexec@compute-0-38.local] HYDU_parse_array (utils/args/args.c:178): argument matching returned error\r\n[mpiexec@compute-0-38.local] parse_args (ui/mpich/utils.c:1642): error parsing input array\r\n[mpiexec@compute-0-38.local] HYD_uii_mpx_get_parameters (ui/mpich/utils.c:1694): unable to parse user arguments\r\n[mpiexec@compute-0-38.local] main (ui/mpich/mpiexec.c:148): error parsing parameters\r\n\r\nDo you know what's the problem for this?\r\n\r\nThanks\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1017", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1017/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1017/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1017/events", "html_url": "https://github.com/openai/baselines/issues/1017", "id": 505618670, "node_id": "MDU6SXNzdWU1MDU2MTg2NzA=", "number": 1017, "title": "does this toolbox support PyTorch?", "user": {"login": "lihuiknight", "id": 1125468, "node_id": "MDQ6VXNlcjExMjU0Njg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1125468?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lihuiknight", "html_url": "https://github.com/lihuiknight", "followers_url": "https://api.github.com/users/lihuiknight/followers", "following_url": "https://api.github.com/users/lihuiknight/following{/other_user}", "gists_url": "https://api.github.com/users/lihuiknight/gists{/gist_id}", "starred_url": "https://api.github.com/users/lihuiknight/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lihuiknight/subscriptions", "organizations_url": "https://api.github.com/users/lihuiknight/orgs", "repos_url": "https://api.github.com/users/lihuiknight/repos", "events_url": "https://api.github.com/users/lihuiknight/events{/privacy}", "received_events_url": "https://api.github.com/users/lihuiknight/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-10-11T03:38:11Z", "updated_at": "2019-10-25T22:33:36Z", "closed_at": "2019-10-25T22:33:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "FYI", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1007", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1007/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1007/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1007/events", "html_url": "https://github.com/openai/baselines/issues/1007", "id": 497459444, "node_id": "MDU6SXNzdWU0OTc0NTk0NDQ=", "number": 1007, "title": "using the OpenAI baselines to train the robotic arm", "user": {"login": "addy1997", "id": 29406906, "node_id": "MDQ6VXNlcjI5NDA2OTA2", "avatar_url": "https://avatars0.githubusercontent.com/u/29406906?v=4", "gravatar_id": "", "url": "https://api.github.com/users/addy1997", "html_url": "https://github.com/addy1997", "followers_url": "https://api.github.com/users/addy1997/followers", "following_url": "https://api.github.com/users/addy1997/following{/other_user}", "gists_url": "https://api.github.com/users/addy1997/gists{/gist_id}", "starred_url": "https://api.github.com/users/addy1997/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/addy1997/subscriptions", "organizations_url": "https://api.github.com/users/addy1997/orgs", "repos_url": "https://api.github.com/users/addy1997/repos", "events_url": "https://api.github.com/users/addy1997/events{/privacy}", "received_events_url": "https://api.github.com/users/addy1997/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-24T05:11:51Z", "updated_at": "2019-09-24T11:55:23Z", "closed_at": "2019-09-24T11:55:22Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is it possible to integrate openAI baselines with ROS(Robotic Operating system) to train any serial robot to perform tasks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1006", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1006/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1006/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1006/events", "html_url": "https://github.com/openai/baselines/issues/1006", "id": 496445623, "node_id": "MDU6SXNzdWU0OTY0NDU2MjM=", "number": 1006, "title": "Not train with vectorized environment for APIs you don't have control over?", "user": {"login": "zergy", "id": 3721823, "node_id": "MDQ6VXNlcjM3MjE4MjM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3721823?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zergy", "html_url": "https://github.com/zergy", "followers_url": "https://api.github.com/users/zergy/followers", "following_url": "https://api.github.com/users/zergy/following{/other_user}", "gists_url": "https://api.github.com/users/zergy/gists{/gist_id}", "starred_url": "https://api.github.com/users/zergy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zergy/subscriptions", "organizations_url": "https://api.github.com/users/zergy/orgs", "repos_url": "https://api.github.com/users/zergy/repos", "events_url": "https://api.github.com/users/zergy/events{/privacy}", "received_events_url": "https://api.github.com/users/zergy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-09-20T16:35:46Z", "updated_at": "2019-11-08T23:02:49Z", "closed_at": "2019-11-08T23:02:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is there a way to not use vectorized environment to train PPO and A2C for APIs that you can't really wrap with a DummyVecEnv? and not have to use either \"Box\" or \"Discrete\" for action/obs space?\r\n\r\nfor environments that don't really have control over the code? such as starcraft2 or other non-self-created games? (don't believe pysc2 provides vec envs, nor are action/obs in box/discrete format)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/1001", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/1001/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/1001/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/1001/events", "html_url": "https://github.com/openai/baselines/issues/1001", "id": 490796035, "node_id": "MDU6SXNzdWU0OTA3OTYwMzU=", "number": 1001, "title": "Gradient with respect to input is `None`", "user": {"login": "akanksha-atrey", "id": 12663320, "node_id": "MDQ6VXNlcjEyNjYzMzIw", "avatar_url": "https://avatars2.githubusercontent.com/u/12663320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akanksha-atrey", "html_url": "https://github.com/akanksha-atrey", "followers_url": "https://api.github.com/users/akanksha-atrey/followers", "following_url": "https://api.github.com/users/akanksha-atrey/following{/other_user}", "gists_url": "https://api.github.com/users/akanksha-atrey/gists{/gist_id}", "starred_url": "https://api.github.com/users/akanksha-atrey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akanksha-atrey/subscriptions", "organizations_url": "https://api.github.com/users/akanksha-atrey/orgs", "repos_url": "https://api.github.com/users/akanksha-atrey/repos", "events_url": "https://api.github.com/users/akanksha-atrey/events{/privacy}", "received_events_url": "https://api.github.com/users/akanksha-atrey/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-09-08T19:32:44Z", "updated_at": "2019-11-05T15:38:33Z", "closed_at": "2019-11-05T15:38:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to calculate the gradient of the outputs with respect to the input but I am getting None consistently. I am attempting this in `baselines/baselines/common/policies.py` in the following function (note `tf.gradients(a_logits, [observation]))`).\r\n\r\n```\r\ndef step(self, observation, **extra_feed):\r\n    a, a_logits, v, state, neglogp = self._evaluate([self.action, self.pi, self.vf, self.state, self.neglogp], observation, **extra_feed)\r\n    if state.size == 0:\r\n        state = None\r\n\r\n    print(tf.gradients(a_logits, [observation]))\r\n    return a, v, state, neglogp, a_logits.flatten()\r\n```\r\n\r\nHas anyone faced this before? Note, I am getting [None] output even for gradient w.r.t to the negative log probability (neglogp). I would really appreciate any help!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/998", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/998/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/998/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/998/events", "html_url": "https://github.com/openai/baselines/issues/998", "id": 487762067, "node_id": "MDU6SXNzdWU0ODc3NjIwNjc=", "number": 998, "title": "When I run multiple thread experiment, it showed up this error. Could anyone help to solve it?", "user": {"login": "YijiongLin", "id": 26537492, "node_id": "MDQ6VXNlcjI2NTM3NDky", "avatar_url": "https://avatars3.githubusercontent.com/u/26537492?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YijiongLin", "html_url": "https://github.com/YijiongLin", "followers_url": "https://api.github.com/users/YijiongLin/followers", "following_url": "https://api.github.com/users/YijiongLin/following{/other_user}", "gists_url": "https://api.github.com/users/YijiongLin/gists{/gist_id}", "starred_url": "https://api.github.com/users/YijiongLin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YijiongLin/subscriptions", "organizations_url": "https://api.github.com/users/YijiongLin/orgs", "repos_url": "https://api.github.com/users/YijiongLin/repos", "events_url": "https://api.github.com/users/YijiongLin/events{/privacy}", "received_events_url": "https://api.github.com/users/YijiongLin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "pzhokhov", "id": 25395937, "node_id": "MDQ6VXNlcjI1Mzk1OTM3", "avatar_url": "https://avatars0.githubusercontent.com/u/25395937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pzhokhov", "html_url": "https://github.com/pzhokhov", "followers_url": "https://api.github.com/users/pzhokhov/followers", "following_url": "https://api.github.com/users/pzhokhov/following{/other_user}", "gists_url": "https://api.github.com/users/pzhokhov/gists{/gist_id}", "starred_url": "https://api.github.com/users/pzhokhov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pzhokhov/subscriptions", "organizations_url": "https://api.github.com/users/pzhokhov/orgs", "repos_url": "https://api.github.com/users/pzhokhov/repos", "events_url": "https://api.github.com/users/pzhokhov/events{/privacy}", "received_events_url": "https://api.github.com/users/pzhokhov/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pzhokhov", "id": 25395937, "node_id": "MDQ6VXNlcjI1Mzk1OTM3", "avatar_url": "https://avatars0.githubusercontent.com/u/25395937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pzhokhov", "html_url": "https://github.com/pzhokhov", "followers_url": "https://api.github.com/users/pzhokhov/followers", "following_url": "https://api.github.com/users/pzhokhov/following{/other_user}", "gists_url": "https://api.github.com/users/pzhokhov/gists{/gist_id}", "starred_url": "https://api.github.com/users/pzhokhov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pzhokhov/subscriptions", "organizations_url": "https://api.github.com/users/pzhokhov/orgs", "repos_url": "https://api.github.com/users/pzhokhov/repos", "events_url": "https://api.github.com/users/pzhokhov/events{/privacy}", "received_events_url": "https://api.github.com/users/pzhokhov/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2019-08-31T11:48:15Z", "updated_at": "2019-09-27T21:45:42Z", "closed_at": "2019-09-27T21:45:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello!\r\nWhen I run this command: **mpirun -np 2 python -m baselines.run --num_env=1 --alg=her --enFetchPickAndPlace-v1 --num_timesteps=2.5e6 --n_cycles=1**\r\n, it showed up all the traceback as above. Could anyone help me to solve this problem?  \r\n\r\nThe most wired thing is that I can run it in the first time, but when I terminate the experiment with \"ctrl+c\" in the terminal, it cannot be run anymore and always showed up this problem. \r\n \r\n **I ran it in commit number:  2bca7901f51c88cdef3ca0666c6a87c454a4dbe8**\r\n\r\n\r\n\r\n```\r\nTraining...\r\nTraceback (most recent call last):\r\n  File \"/home/bourne/anaconda3/envs/mirror/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/bourne/anaconda3/envs/mirror/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/bourne/baselines/baselines/run.py\", line 250, in <module>\r\n    main(sys.argv)\r\n  File \"/home/bourne/baselines/baselines/run.py\", line 216, in main\r\n    model, env = train(args, extra_args)\r\n  File \"/home/bourne/baselines/baselines/run.py\", line 80, in train\r\n    **alg_kwargs\r\n  File \"/home/bourne/baselines/baselines/her/her.py\", line 177, in learn\r\n    policy_save_interval=policy_save_interval, demo_file=demo_file)\r\n  File \"/home/bourne/baselines/baselines/her/her.py\", line 56, in train\r\n    logger.record_tabular(key, mpi_average(val))\r\n  File \"/home/bourne/baselines/baselines/her/her.py\", line 19, in mpi_average\r\n    return mpi_moments(np.array(value))[0]\r\n  File \"/home/bourne/baselines/baselines/common/mpi_moments.py\", line 22, in mpi_moments\r\n    mean, count = mpi_mean(x, axis=axis, comm=comm, keepdims=True)\r\n  File \"/home/bourne/baselines/baselines/common/mpi_moments.py\", line 16, in mpi_mean\r\n    comm.Allreduce(localsum, globalsum, op=MPI.SUM)\r\n  File \"mpi4py/MPI/Comm.pyx\", line 714, in mpi4py.MPI.Comm.Allreduce\r\n**mpi4py.MPI.Exception: MPI_ERR_IN_STATUS: error code in status**\r\n\r\nIf you suspect this is an IPython bug, please report it at:\r\n    https://github.com/ipython/ipython/issues\r\nor send an email to the mailing list at ipython-dev@python.org\r\n\r\nYou can print a more detailed traceback right now with \"%tb\", or use \"%debug\"\r\nto interactively debug it.\r\n\r\nExtra-detailed tracebacks for bug-reporting purposes can be enabled via:\r\n    %config Application.verbose_crash=True\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/994", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/994/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/994/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/994/events", "html_url": "https://github.com/openai/baselines/issues/994", "id": 485182293, "node_id": "MDU6SXNzdWU0ODUxODIyOTM=", "number": 994, "title": "why `step_model` and `train_model` instead of one?", "user": {"login": "breezedeus", "id": 6712673, "node_id": "MDQ6VXNlcjY3MTI2NzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6712673?v=4", "gravatar_id": "", "url": "https://api.github.com/users/breezedeus", "html_url": "https://github.com/breezedeus", "followers_url": "https://api.github.com/users/breezedeus/followers", "following_url": "https://api.github.com/users/breezedeus/following{/other_user}", "gists_url": "https://api.github.com/users/breezedeus/gists{/gist_id}", "starred_url": "https://api.github.com/users/breezedeus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/breezedeus/subscriptions", "organizations_url": "https://api.github.com/users/breezedeus/orgs", "repos_url": "https://api.github.com/users/breezedeus/repos", "events_url": "https://api.github.com/users/breezedeus/events{/privacy}", "received_events_url": "https://api.github.com/users/breezedeus/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-26T11:14:52Z", "updated_at": "2019-10-25T22:44:46Z", "closed_at": "2019-10-25T22:44:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I am reading the code of `a2c.py`, but confused about the design of `step_model` and `train_model`. As I read, both of them share parameters. So, why are two models used instead of one? Thanks.\r\n\r\n\r\n```python\r\n            # step_model is used for sampling\r\n            step_model = policy(nenvs, 1, sess)\r\n\r\n            # train_model is used to train our network\r\n            train_model = policy(nbatch, nsteps, sess)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/993", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/993/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/993/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/993/events", "html_url": "https://github.com/openai/baselines/issues/993", "id": 484688031, "node_id": "MDU6SXNzdWU0ODQ2ODgwMzE=", "number": 993, "title": "Is the PPO2 optimization synchronous or asynchronous between the different agents ?", "user": {"login": "Deathn0t", "id": 5201978, "node_id": "MDQ6VXNlcjUyMDE5Nzg=", "avatar_url": "https://avatars0.githubusercontent.com/u/5201978?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Deathn0t", "html_url": "https://github.com/Deathn0t", "followers_url": "https://api.github.com/users/Deathn0t/followers", "following_url": "https://api.github.com/users/Deathn0t/following{/other_user}", "gists_url": "https://api.github.com/users/Deathn0t/gists{/gist_id}", "starred_url": "https://api.github.com/users/Deathn0t/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Deathn0t/subscriptions", "organizations_url": "https://api.github.com/users/Deathn0t/orgs", "repos_url": "https://api.github.com/users/Deathn0t/repos", "events_url": "https://api.github.com/users/Deathn0t/events{/privacy}", "received_events_url": "https://api.github.com/users/Deathn0t/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-23T19:56:50Z", "updated_at": "2019-10-25T22:45:55Z", "closed_at": "2019-10-25T22:45:55Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nabout the optimization strategy for PPO2, do you know if Is the optimization process is synchronous or asynchronous between the different agents?\r\n\r\nThank you for your help.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/991", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/991/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/991/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/991/events", "html_url": "https://github.com/openai/baselines/issues/991", "id": 484286294, "node_id": "MDU6SXNzdWU0ODQyODYyOTQ=", "number": 991, "title": "I found out in Fetch Env, the action space is the linear velocity of grip, instead of grip position described in the paper", "user": {"login": "YijiongLin", "id": 26537492, "node_id": "MDQ6VXNlcjI2NTM3NDky", "avatar_url": "https://avatars3.githubusercontent.com/u/26537492?v=4", "gravatar_id": "", "url": "https://api.github.com/users/YijiongLin", "html_url": "https://github.com/YijiongLin", "followers_url": "https://api.github.com/users/YijiongLin/followers", "following_url": "https://api.github.com/users/YijiongLin/following{/other_user}", "gists_url": "https://api.github.com/users/YijiongLin/gists{/gist_id}", "starred_url": "https://api.github.com/users/YijiongLin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/YijiongLin/subscriptions", "organizations_url": "https://api.github.com/users/YijiongLin/orgs", "repos_url": "https://api.github.com/users/YijiongLin/repos", "events_url": "https://api.github.com/users/YijiongLin/events{/privacy}", "received_events_url": "https://api.github.com/users/YijiongLin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-08-23T01:28:40Z", "updated_at": "2019-08-31T12:27:12Z", "closed_at": "2019-08-23T06:42:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "Today I found out in Fetch Env, the action space is the linear velocity of grip, instead of grip position described in the paper.\r\n\r\nBecause when I whether set the action always to [1,0,0,0] or [0.001,0,0,0], the grip always go to the same furthest place in the X axis positive direction. But with different velocity to get to there.\r\n\r\nSo I have a confusion about this, what exactly is the action space in the code, does it correspond to the paper Plappert et al. (2018) and Hindsight Experience Replay?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/989", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/989/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/989/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/989/events", "html_url": "https://github.com/openai/baselines/issues/989", "id": 480559862, "node_id": "MDU6SXNzdWU0ODA1NTk4NjI=", "number": 989, "title": "PPO1 time steps and relationship with episodes", "user": {"login": "kosmylo", "id": 13433764, "node_id": "MDQ6VXNlcjEzNDMzNzY0", "avatar_url": "https://avatars1.githubusercontent.com/u/13433764?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kosmylo", "html_url": "https://github.com/kosmylo", "followers_url": "https://api.github.com/users/kosmylo/followers", "following_url": "https://api.github.com/users/kosmylo/following{/other_user}", "gists_url": "https://api.github.com/users/kosmylo/gists{/gist_id}", "starred_url": "https://api.github.com/users/kosmylo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kosmylo/subscriptions", "organizations_url": "https://api.github.com/users/kosmylo/orgs", "repos_url": "https://api.github.com/users/kosmylo/repos", "events_url": "https://api.github.com/users/kosmylo/events{/privacy}", "received_events_url": "https://api.github.com/users/kosmylo/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-08-14T08:54:46Z", "updated_at": "2019-08-20T11:07:16Z", "closed_at": "2019-08-20T11:07:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "I would like to ask what is the relationship between time steps given as argument in PPO and the episodes.\r\n\r\nFor example if my episode is consisted of 1000 time steps, then if I want to train for 100 episodes I have to give as argument 1000*100 = 100000 time steps?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/987", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/987/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/987/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/987/events", "html_url": "https://github.com/openai/baselines/issues/987", "id": 479934552, "node_id": "MDU6SXNzdWU0Nzk5MzQ1NTI=", "number": 987, "title": "deleted", "user": {"login": "guikarist", "id": 19543014, "node_id": "MDQ6VXNlcjE5NTQzMDE0", "avatar_url": "https://avatars0.githubusercontent.com/u/19543014?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guikarist", "html_url": "https://github.com/guikarist", "followers_url": "https://api.github.com/users/guikarist/followers", "following_url": "https://api.github.com/users/guikarist/following{/other_user}", "gists_url": "https://api.github.com/users/guikarist/gists{/gist_id}", "starred_url": "https://api.github.com/users/guikarist/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guikarist/subscriptions", "organizations_url": "https://api.github.com/users/guikarist/orgs", "repos_url": "https://api.github.com/users/guikarist/repos", "events_url": "https://api.github.com/users/guikarist/events{/privacy}", "received_events_url": "https://api.github.com/users/guikarist/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-08-13T02:51:49Z", "updated_at": "2019-08-26T01:32:08Z", "closed_at": "2019-08-26T01:31:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "deleted", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/985", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/985/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/985/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/985/events", "html_url": "https://github.com/openai/baselines/issues/985", "id": 479485981, "node_id": "MDU6SXNzdWU0Nzk0ODU5ODE=", "number": 985, "title": "GAIL gpu runs slower than cpu", "user": {"login": "tangypnuaa", "id": 40466308, "node_id": "MDQ6VXNlcjQwNDY2MzA4", "avatar_url": "https://avatars0.githubusercontent.com/u/40466308?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tangypnuaa", "html_url": "https://github.com/tangypnuaa", "followers_url": "https://api.github.com/users/tangypnuaa/followers", "following_url": "https://api.github.com/users/tangypnuaa/following{/other_user}", "gists_url": "https://api.github.com/users/tangypnuaa/gists{/gist_id}", "starred_url": "https://api.github.com/users/tangypnuaa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tangypnuaa/subscriptions", "organizations_url": "https://api.github.com/users/tangypnuaa/orgs", "repos_url": "https://api.github.com/users/tangypnuaa/repos", "events_url": "https://api.github.com/users/tangypnuaa/events{/privacy}", "received_events_url": "https://api.github.com/users/tangypnuaa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-08-12T06:29:39Z", "updated_at": "2019-12-08T04:21:23Z", "closed_at": "2019-12-08T04:21:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/982", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/982/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/982/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/982/events", "html_url": "https://github.com/openai/baselines/issues/982", "id": 478855076, "node_id": "MDU6SXNzdWU0Nzg4NTUwNzY=", "number": 982, "title": "Not able to run any baseline example due to missing entry point", "user": {"login": "Ujwal2910", "id": 19718533, "node_id": "MDQ6VXNlcjE5NzE4NTMz", "avatar_url": "https://avatars0.githubusercontent.com/u/19718533?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ujwal2910", "html_url": "https://github.com/Ujwal2910", "followers_url": "https://api.github.com/users/Ujwal2910/followers", "following_url": "https://api.github.com/users/Ujwal2910/following{/other_user}", "gists_url": "https://api.github.com/users/Ujwal2910/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ujwal2910/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ujwal2910/subscriptions", "organizations_url": "https://api.github.com/users/Ujwal2910/orgs", "repos_url": "https://api.github.com/users/Ujwal2910/repos", "events_url": "https://api.github.com/users/Ujwal2910/events{/privacy}", "received_events_url": "https://api.github.com/users/Ujwal2910/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-08-09T08:07:25Z", "updated_at": "2019-11-08T23:16:34Z", "closed_at": "2019-11-08T23:16:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "while running this-\r\n\r\ncommand - python3 -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=2e7\r\nTraceback (most recent call last):\r\n  File \"/home/ujwal/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/ujwal/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n\r\nin run.py, line 35, in <module>\r\n    env_type = env.entry_point.split(':')[0].split('.')[-1]\r\nAttributeError: 'EnvSpec' object has no attribute 'entry_point'", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/981", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/981/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/981/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/981/events", "html_url": "https://github.com/openai/baselines/issues/981", "id": 478456374, "node_id": "MDU6SXNzdWU0Nzg0NTYzNzQ=", "number": 981, "title": "DDPG doesn't work in mujoco", "user": {"login": "Kchu", "id": 39457661, "node_id": "MDQ6VXNlcjM5NDU3NjYx", "avatar_url": "https://avatars2.githubusercontent.com/u/39457661?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kchu", "html_url": "https://github.com/Kchu", "followers_url": "https://api.github.com/users/Kchu/followers", "following_url": "https://api.github.com/users/Kchu/following{/other_user}", "gists_url": "https://api.github.com/users/Kchu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kchu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kchu/subscriptions", "organizations_url": "https://api.github.com/users/Kchu/orgs", "repos_url": "https://api.github.com/users/Kchu/repos", "events_url": "https://api.github.com/users/Kchu/events{/privacy}", "received_events_url": "https://api.github.com/users/Kchu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-08-08T12:59:32Z", "updated_at": "2019-10-25T22:54:42Z", "closed_at": "2019-10-25T22:54:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "I recently tested the baselines' DDPG algorithm, but unexpectedly, DDPG failed to get great scroes and to converge.  I can't get the ideal results in many mujoco environments.\r\nI use the download source installation, the command line runned is below: \r\npython -m baselines.run --alg=ddpg --env=HalfCheetah-v2 --num_timesteps=1e6", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/973", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/973/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/973/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/973/events", "html_url": "https://github.com/openai/baselines/issues/973", "id": 475251612, "node_id": "MDU6SXNzdWU0NzUyNTE2MTI=", "number": 973, "title": "Saving a Model", "user": {"login": "ThomasZav", "id": 48513935, "node_id": "MDQ6VXNlcjQ4NTEzOTM1", "avatar_url": "https://avatars3.githubusercontent.com/u/48513935?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ThomasZav", "html_url": "https://github.com/ThomasZav", "followers_url": "https://api.github.com/users/ThomasZav/followers", "following_url": "https://api.github.com/users/ThomasZav/following{/other_user}", "gists_url": "https://api.github.com/users/ThomasZav/gists{/gist_id}", "starred_url": "https://api.github.com/users/ThomasZav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ThomasZav/subscriptions", "organizations_url": "https://api.github.com/users/ThomasZav/orgs", "repos_url": "https://api.github.com/users/ThomasZav/repos", "events_url": "https://api.github.com/users/ThomasZav/events{/privacy}", "received_events_url": "https://api.github.com/users/ThomasZav/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-31T16:49:03Z", "updated_at": "2019-11-08T23:21:06Z", "closed_at": "2019-11-08T23:21:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "When we run this command,\r\n\r\npython -m baselines.run --alg=....\r\n\r\nIt saves the model as one file. How can we save the model in the following format?\r\n.ckpt.meta\r\nckpt.index\r\n.ckpt.data\r\ncheckpoint\r\n\r\nOr can we decompose that one file into checkpoint files?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/972", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/972/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/972/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/972/events", "html_url": "https://github.com/openai/baselines/issues/972", "id": 475104115, "node_id": "MDU6SXNzdWU0NzUxMDQxMTU=", "number": 972, "title": "VecNormalize \"return\" calculation", "user": {"login": "humorbeing", "id": 26265059, "node_id": "MDQ6VXNlcjI2MjY1MDU5", "avatar_url": "https://avatars1.githubusercontent.com/u/26265059?v=4", "gravatar_id": "", "url": "https://api.github.com/users/humorbeing", "html_url": "https://github.com/humorbeing", "followers_url": "https://api.github.com/users/humorbeing/followers", "following_url": "https://api.github.com/users/humorbeing/following{/other_user}", "gists_url": "https://api.github.com/users/humorbeing/gists{/gist_id}", "starred_url": "https://api.github.com/users/humorbeing/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/humorbeing/subscriptions", "organizations_url": "https://api.github.com/users/humorbeing/orgs", "repos_url": "https://api.github.com/users/humorbeing/repos", "events_url": "https://api.github.com/users/humorbeing/events{/privacy}", "received_events_url": "https://api.github.com/users/humorbeing/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-31T12:05:43Z", "updated_at": "2019-08-12T19:44:54Z", "closed_at": "2019-08-12T19:44:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "Can someone confirm this: \r\nthe \"return\" calculation in this code is actually NOT a real RL return.\r\nIt's the 3rd line in the code.\r\ncode:\r\n```\r\ndef step_wait(self):\r\n        obs, rews, news, infos = self.venv.step_wait()\r\n        self.ret = self.ret * self.gamma + rews  # <--- this line\r\n        ...\r\n        self.ret[news] = 0.\r\n        return obs, rews, news, infos\r\n```\r\nSo, If follow this equation, we will end up with early rewards are discounted most and later rewards are spared. **vs.** where in RL return, It should be, early rewards are spared and later rewards are discounted most. Isn't it?\r\n\r\nI am so confused when everyone in #538 post talks about \"**returns**\" here and there.\r\nIn the post, @andytwigg points out the same concern as mine.\r\n\r\n> the RL algorithm discounts 'backwards' and this method discounts in the opposite direction.\r\n\r\nI am so confused about this. Is this equation the correct way of calculating RL returns?\r\n\r\nBig thanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/966", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/966/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/966/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/966/events", "html_url": "https://github.com/openai/baselines/issues/966", "id": 473049817, "node_id": "MDU6SXNzdWU0NzMwNDk4MTc=", "number": 966, "title": "AttributeError: entry_point variable broken in run.py", "user": {"login": "NicoBach", "id": 43953203, "node_id": "MDQ6VXNlcjQzOTUzMjAz", "avatar_url": "https://avatars1.githubusercontent.com/u/43953203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NicoBach", "html_url": "https://github.com/NicoBach", "followers_url": "https://api.github.com/users/NicoBach/followers", "following_url": "https://api.github.com/users/NicoBach/following{/other_user}", "gists_url": "https://api.github.com/users/NicoBach/gists{/gist_id}", "starred_url": "https://api.github.com/users/NicoBach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NicoBach/subscriptions", "organizations_url": "https://api.github.com/users/NicoBach/orgs", "repos_url": "https://api.github.com/users/NicoBach/repos", "events_url": "https://api.github.com/users/NicoBach/events{/privacy}", "received_events_url": "https://api.github.com/users/NicoBach/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-07-25T20:13:41Z", "updated_at": "2019-08-31T13:39:22Z", "closed_at": "2019-08-10T14:00:18Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hello!\r\nWith a recent commit in openai gym (https://github.com/openai/gym/commit/dc91f434f83f3ad612ff353cbf2c1afc4788896b) the entry_point variable was changed from private to public, thus breaking baselines/baselines/run.py script.\r\nUpdating baselines/run.py in lines 35 and 129 from\r\n`env_type = env._entry_point.split(':')[0].split('.')[-1]`\r\nto \r\n`env_type = env.entry_point.split(':')[0].split('.')[-1]`\r\nfixes this problem. I hope, this can be useful.\r\n\r\nBest regards,\r\nNico Bach", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/965", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/965/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/965/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/965/events", "html_url": "https://github.com/openai/baselines/issues/965", "id": 472189065, "node_id": "MDU6SXNzdWU0NzIxODkwNjU=", "number": 965, "title": "'Box' object has no attribute 'n'", "user": {"login": "Usmaniatech", "id": 14370981, "node_id": "MDQ6VXNlcjE0MzcwOTgx", "avatar_url": "https://avatars1.githubusercontent.com/u/14370981?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Usmaniatech", "html_url": "https://github.com/Usmaniatech", "followers_url": "https://api.github.com/users/Usmaniatech/followers", "following_url": "https://api.github.com/users/Usmaniatech/following{/other_user}", "gists_url": "https://api.github.com/users/Usmaniatech/gists{/gist_id}", "starred_url": "https://api.github.com/users/Usmaniatech/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Usmaniatech/subscriptions", "organizations_url": "https://api.github.com/users/Usmaniatech/orgs", "repos_url": "https://api.github.com/users/Usmaniatech/repos", "events_url": "https://api.github.com/users/Usmaniatech/events{/privacy}", "received_events_url": "https://api.github.com/users/Usmaniatech/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-24T09:54:53Z", "updated_at": "2019-11-08T23:34:43Z", "closed_at": "2019-11-08T23:34:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "Does deepq support multi agent. I am trying to train Tennis example without the parallel training, but it's generating error.\r\n\r\n![error](https://user-images.githubusercontent.com/14370981/61784283-e1af6480-ae22-11e9-92df-527e8e1b7db0.PNG)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/959", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/959/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/959/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/959/events", "html_url": "https://github.com/openai/baselines/issues/959", "id": 466353703, "node_id": "MDU6SXNzdWU0NjYzNTM3MDM=", "number": 959, "title": "Definition of custom environments when using PPO2", "user": {"login": "RogerFrigola", "id": 3978462, "node_id": "MDQ6VXNlcjM5Nzg0NjI=", "avatar_url": "https://avatars2.githubusercontent.com/u/3978462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RogerFrigola", "html_url": "https://github.com/RogerFrigola", "followers_url": "https://api.github.com/users/RogerFrigola/followers", "following_url": "https://api.github.com/users/RogerFrigola/following{/other_user}", "gists_url": "https://api.github.com/users/RogerFrigola/gists{/gist_id}", "starred_url": "https://api.github.com/users/RogerFrigola/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RogerFrigola/subscriptions", "organizations_url": "https://api.github.com/users/RogerFrigola/orgs", "repos_url": "https://api.github.com/users/RogerFrigola/repos", "events_url": "https://api.github.com/users/RogerFrigola/events{/privacy}", "received_events_url": "https://api.github.com/users/RogerFrigola/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-07-10T14:47:43Z", "updated_at": "2019-08-26T19:34:34Z", "closed_at": "2019-08-23T10:44:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm using a custom environment which attempts to adhere to the `gym` specification in:\r\n\r\n[https://gym.openai.com/docs/](https://gym.openai.com/docs/)\r\n\r\nHowever, PPO2 fails because it requires that the `info` dictionary returned by `env.step(...)` has the key `'episode'`. \r\n\r\nAs far as I can see, there is no documentation specifying what keys should the `info` dictionary have for the learning algorithms to work.\r\n\r\nDoes `baselines` require `gym` environments with extra features? Any clarification would be most welcome.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/949", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/949/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/949/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/949/events", "html_url": "https://github.com/openai/baselines/issues/949", "id": 463103912, "node_id": "MDU6SXNzdWU0NjMxMDM5MTI=", "number": 949, "title": "Typo in GAIL dataset log", "user": {"login": "seungjaeryanlee", "id": 6107926, "node_id": "MDQ6VXNlcjYxMDc5MjY=", "avatar_url": "https://avatars3.githubusercontent.com/u/6107926?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seungjaeryanlee", "html_url": "https://github.com/seungjaeryanlee", "followers_url": "https://api.github.com/users/seungjaeryanlee/followers", "following_url": "https://api.github.com/users/seungjaeryanlee/following{/other_user}", "gists_url": "https://api.github.com/users/seungjaeryanlee/gists{/gist_id}", "starred_url": "https://api.github.com/users/seungjaeryanlee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seungjaeryanlee/subscriptions", "organizations_url": "https://api.github.com/users/seungjaeryanlee/orgs", "repos_url": "https://api.github.com/users/seungjaeryanlee/repos", "events_url": "https://api.github.com/users/seungjaeryanlee/events{/privacy}", "received_events_url": "https://api.github.com/users/seungjaeryanlee/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-07-02T08:53:49Z", "updated_at": "2019-08-05T23:55:34Z", "closed_at": "2019-08-05T23:55:34Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "https://github.com/openai/baselines/blob/c57528573ea695b19cd03e98dae48f0082fb2b5e/baselines/gail/dataset/mujoco_dset.py#L80\r\n\r\nI believe it should be \"Total trajectories\" ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/948", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/948/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/948/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/948/events", "html_url": "https://github.com/openai/baselines/issues/948", "id": 462421652, "node_id": "MDU6SXNzdWU0NjI0MjE2NTI=", "number": 948, "title": "HER model don't learn again after load", "user": {"login": "kjacek", "id": 5958720, "node_id": "MDQ6VXNlcjU5NTg3MjA=", "avatar_url": "https://avatars0.githubusercontent.com/u/5958720?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kjacek", "html_url": "https://github.com/kjacek", "followers_url": "https://api.github.com/users/kjacek/followers", "following_url": "https://api.github.com/users/kjacek/following{/other_user}", "gists_url": "https://api.github.com/users/kjacek/gists{/gist_id}", "starred_url": "https://api.github.com/users/kjacek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kjacek/subscriptions", "organizations_url": "https://api.github.com/users/kjacek/orgs", "repos_url": "https://api.github.com/users/kjacek/repos", "events_url": "https://api.github.com/users/kjacek/events{/privacy}", "received_events_url": "https://api.github.com/users/kjacek/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-06-30T16:17:18Z", "updated_at": "2019-06-30T16:25:31Z", "closed_at": "2019-06-30T16:25:31Z", "author_association": "NONE", "active_lock_reason": null, "body": "It seems HER model don't learn again after load previously learned model.\r\n\r\n```\r\nmodel = HER.load('her_bit_env', env=env)\r\nmodel.learn(1000)\r\nmodel.save(\"her_bit_env\")\r\n\r\n```\r\nI got exactly the same effect after test.\r\nStable baselines v.2.6 ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/945", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/945/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/945/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/945/events", "html_url": "https://github.com/openai/baselines/issues/945", "id": 461577816, "node_id": "MDU6SXNzdWU0NjE1Nzc4MTY=", "number": 945, "title": "DQN documentation", "user": {"login": "gaperez64", "id": 2659561, "node_id": "MDQ6VXNlcjI2NTk1NjE=", "avatar_url": "https://avatars3.githubusercontent.com/u/2659561?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gaperez64", "html_url": "https://github.com/gaperez64", "followers_url": "https://api.github.com/users/gaperez64/followers", "following_url": "https://api.github.com/users/gaperez64/following{/other_user}", "gists_url": "https://api.github.com/users/gaperez64/gists{/gist_id}", "starred_url": "https://api.github.com/users/gaperez64/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gaperez64/subscriptions", "organizations_url": "https://api.github.com/users/gaperez64/orgs", "repos_url": "https://api.github.com/users/gaperez64/repos", "events_url": "https://api.github.com/users/gaperez64/events{/privacy}", "received_events_url": "https://api.github.com/users/gaperez64/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-06-27T14:53:54Z", "updated_at": "2020-03-17T16:50:23Z", "closed_at": "2020-03-17T16:50:23Z", "author_association": "NONE", "active_lock_reason": null, "body": "I do not understand the details of many of the parameters used to call DQN (like buffer_size, exploration_fraction, exploration_final_eps, train_freq, print_freq, prioritized_replay parameters, callback, param_noise etc.) and how they affect the learning process. \r\n\r\nCould you point me to a paper / link that explains these parameters and the learning algorithm?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/926", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/926/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/926/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/926/events", "html_url": "https://github.com/openai/baselines/issues/926", "id": 452186092, "node_id": "MDU6SXNzdWU0NTIxODYwOTI=", "number": 926, "title": "Deepq Favoring Action 0 in Discrete Action Space", "user": {"login": "Jyosua", "id": 11085230, "node_id": "MDQ6VXNlcjExMDg1MjMw", "avatar_url": "https://avatars0.githubusercontent.com/u/11085230?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jyosua", "html_url": "https://github.com/Jyosua", "followers_url": "https://api.github.com/users/Jyosua/followers", "following_url": "https://api.github.com/users/Jyosua/following{/other_user}", "gists_url": "https://api.github.com/users/Jyosua/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jyosua/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jyosua/subscriptions", "organizations_url": "https://api.github.com/users/Jyosua/orgs", "repos_url": "https://api.github.com/users/Jyosua/repos", "events_url": "https://api.github.com/users/Jyosua/events{/privacy}", "received_events_url": "https://api.github.com/users/Jyosua/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-06-04T20:13:57Z", "updated_at": "2019-06-13T23:14:47Z", "closed_at": "2019-06-13T23:14:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "We've written our own environment and are trying to run the deepq algorithm with a discrete action space of 7 actions. However, regardless of how we construct our rewards, we're noticing that when we run using\r\n\r\n`python3 -m baselines.run --alg=deepq --env=custom_env-v0 --num_timesteps=1e5 --save_path=~/simplemodel`\r\n\r\nthe agent seems to heavily favor action 0 of the 7 actions available. It initially seems to have a fairly even distribution for the first 6 episodes, but then you can see a much large number of action 0 being picked after that point and this disparity continues to grow as more episodes are completed; in later episodes, it rarely seems to pick the other actions at all.\r\n\r\nWhen we noticed this behavior, we decided to remove everything in our environment that provides a reward and just return a reward of 0, but still saw the same result. Is this a bug or is there something we should be doing to avoid this?\r\n\r\nHere's some generic environment code that produces the issue:\r\n```python\r\nimport gym\r\nimport random\r\nimport numpy as np\r\nfrom gym import spaces\r\nimport os\r\n\r\nMAX_TIMESTEP = 365\r\n\r\n# Mapping of value change to action states\r\nACTION_MEANING = {\r\n    0: 50,\r\n    1: 25,\r\n    2: 5,\r\n    3: 0,\r\n    4: -5,\r\n    5: -25,\r\n    6: -50,\r\n}\r\n\r\nclass ExampleEnv(gym.Env):\r\n  metadata = {'render.modes': ['human']}\r\n  def __init__(self):\r\n    # rows and columns for the observation space \r\n    self.cols = 8\r\n    self.rows = 30\r\n    self.episodeNumber = 0\r\n\r\n    self.actionCounts = {\r\n        0: 0,\r\n        1: 0,\r\n        2: 0,\r\n        3: 0,\r\n        4: 0,\r\n        5: 0,\r\n        6: 0,\r\n    }\r\n\r\n    # gym environment declarations\r\n    self.action_space = spaces.Discrete(7)\r\n    high_array = [4000]\r\n    high_array = high_array + ([1]*((self.cols*self.rows)))\r\n    self.observation_space = spaces.Box(low=np.array([0] * ((self.cols * self.rows) + 1)), high=np.array(high_array))\r\n\r\n  def step(self, action):\r\n    self.actionCounts[action] += 1\r\n    reward = 0\r\n    self.currentValue = max(self.currentValue + ACTION_MEANING[action], 0)\r\n    self.currentValue = min(self.currentValue + ACTION_MEANING[action], 4000)\r\n    self.t += 1\r\n\r\n    if self.t == MAX_TIMESTEP:\r\n      print(f\"Episode {self.episodeNumber} completed\")\r\n      self.episodeNumber += 1\r\n      print(f\"Action Count{self.actionCounts}\")\r\n\r\n    return self.getObservation(), reward, False, {}\r\n  \r\n  def reset(self):\r\n    self.t = 0\r\n    self.currentValue = 2000\r\n  \r\n  def render(self, mode='human', close=False):\r\n    pass\r\n\r\n  def getObservation(self):\r\n    observation_array = [self.currentValue]\r\n    observation_array = observation_array + ([0]*((self.cols*self.rows)))\r\n    \r\n    return np.array(observation_array)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/904", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/904/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/904/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/904/events", "html_url": "https://github.com/openai/baselines/issues/904", "id": 444036832, "node_id": "MDU6SXNzdWU0NDQwMzY4MzI=", "number": 904, "title": "baseline codes are written by python2.7 but the end of support for python 2.X is just 2020", "user": {"login": "wooramkang", "id": 31590573, "node_id": "MDQ6VXNlcjMxNTkwNTcz", "avatar_url": "https://avatars0.githubusercontent.com/u/31590573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wooramkang", "html_url": "https://github.com/wooramkang", "followers_url": "https://api.github.com/users/wooramkang/followers", "following_url": "https://api.github.com/users/wooramkang/following{/other_user}", "gists_url": "https://api.github.com/users/wooramkang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wooramkang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wooramkang/subscriptions", "organizations_url": "https://api.github.com/users/wooramkang/orgs", "repos_url": "https://api.github.com/users/wooramkang/repos", "events_url": "https://api.github.com/users/wooramkang/events{/privacy}", "received_events_url": "https://api.github.com/users/wooramkang/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-05-14T17:28:17Z", "updated_at": "2019-05-16T09:39:59Z", "closed_at": "2019-05-16T09:39:59Z", "author_association": "NONE", "active_lock_reason": null, "body": "baseline codes are written by python2.7 but the end of support for python 2.X is just 2020\r\ni guess that's big problem\r\nthe codes need to be rewritten by Python 3.X", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/900", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/900/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/900/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/900/events", "html_url": "https://github.com/openai/baselines/issues/900", "id": 442134515, "node_id": "MDU6SXNzdWU0NDIxMzQ1MTU=", "number": 900, "title": "f-strings breaks Python < 3.6", "user": {"login": "fiorenza2", "id": 15997485, "node_id": "MDQ6VXNlcjE1OTk3NDg1", "avatar_url": "https://avatars3.githubusercontent.com/u/15997485?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fiorenza2", "html_url": "https://github.com/fiorenza2", "followers_url": "https://api.github.com/users/fiorenza2/followers", "following_url": "https://api.github.com/users/fiorenza2/following{/other_user}", "gists_url": "https://api.github.com/users/fiorenza2/gists{/gist_id}", "starred_url": "https://api.github.com/users/fiorenza2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fiorenza2/subscriptions", "organizations_url": "https://api.github.com/users/fiorenza2/orgs", "repos_url": "https://api.github.com/users/fiorenza2/repos", "events_url": "https://api.github.com/users/fiorenza2/events{/privacy}", "received_events_url": "https://api.github.com/users/fiorenza2/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-05-09T09:18:07Z", "updated_at": "2019-05-31T21:27:12Z", "closed_at": "2019-05-31T21:27:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey minor point, but the latest PR means in `mpi_adam_optimizer.py` the f-string in the assert (line 68) breaks Python versions below 3.6; perhaps update the `README.md` dependencies to 3.6 instead of 3.5? Or just remove the f-string (my work-around for now).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/896", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/896/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/896/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/896/events", "html_url": "https://github.com/openai/baselines/issues/896", "id": 440426250, "node_id": "MDU6SXNzdWU0NDA0MjYyNTA=", "number": 896, "title": "Memory problem in using LazyFrames", "user": {"login": "NaiveRed", "id": 11832387, "node_id": "MDQ6VXNlcjExODMyMzg3", "avatar_url": "https://avatars3.githubusercontent.com/u/11832387?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NaiveRed", "html_url": "https://github.com/NaiveRed", "followers_url": "https://api.github.com/users/NaiveRed/followers", "following_url": "https://api.github.com/users/NaiveRed/following{/other_user}", "gists_url": "https://api.github.com/users/NaiveRed/gists{/gist_id}", "starred_url": "https://api.github.com/users/NaiveRed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NaiveRed/subscriptions", "organizations_url": "https://api.github.com/users/NaiveRed/orgs", "repos_url": "https://api.github.com/users/NaiveRed/repos", "events_url": "https://api.github.com/users/NaiveRed/events{/privacy}", "received_events_url": "https://api.github.com/users/NaiveRed/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2019-05-05T10:00:30Z", "updated_at": "2019-08-30T06:32:47Z", "closed_at": "2019-08-30T06:32:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi~\r\nI am trying **atari_wrappers.py** in other place and I checked the usage in **deepq.py** and **replay_buffer.py**.\r\n\r\nhttps://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/deepq/deepq.py#L279-L284\r\n\r\nhttps://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/deepq/replay_buffer.py#L36-L41\r\n\r\nIt seems the memory(RAM) will still increase fast when I use **LazyFrames**.\r\nDoes it need to make a deep copy on the Lazyframes object before convert it to the numpy array? Or the replay buffer will store the **LazyFrames** whose **`self._out`** has been concatenating several numpy arrays. (more RAM)\r\n\r\nhttps://github.com/openai/baselines/blob/3301089b48c42b87b396e246ea3f56fa4bfc9678/baselines/common/atari_wrappers.py#L208-L212\r\n\r\nLike this:\r\n```python\r\naction = act(np.array(copy.deepcopy(obs))[None], update_eps=update_eps, **kwargs)[0]\r\n```\r\nand\r\n```python\r\nobses_t.append(np.array(copy.deepcopy(obs_t), copy=False))\r\nobses_tp1.append(np.array(copy.deepcopy(obs_tp1), copy=False))\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/893", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/893/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/893/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/893/events", "html_url": "https://github.com/openai/baselines/issues/893", "id": 439956479, "node_id": "MDU6SXNzdWU0Mzk5NTY0Nzk=", "number": 893, "title": "The Agent's performance is poor after achieving good training results (DQN on Pong) ", "user": {"login": "odats", "id": 944379, "node_id": "MDQ6VXNlcjk0NDM3OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/944379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/odats", "html_url": "https://github.com/odats", "followers_url": "https://api.github.com/users/odats/followers", "following_url": "https://api.github.com/users/odats/following{/other_user}", "gists_url": "https://api.github.com/users/odats/gists{/gist_id}", "starred_url": "https://api.github.com/users/odats/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/odats/subscriptions", "organizations_url": "https://api.github.com/users/odats/orgs", "repos_url": "https://api.github.com/users/odats/repos", "events_url": "https://api.github.com/users/odats/events{/privacy}", "received_events_url": "https://api.github.com/users/odats/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-05-03T09:13:01Z", "updated_at": "2019-05-04T14:23:17Z", "closed_at": "2019-05-04T14:23:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have trained the agent on Pong env and achieving mean: 16\r\nWhen I run this model the agent's performance is poor: -20\r\nWhy do I get this behavior?\r\nDQN on Pong\r\n\r\n```\r\ndef train():\r\n    logger.configure()\r\n    env = make_atari('PongNoFrameskip-v4')\r\n    env = bench.Monitor(env, logger.get_dir())\r\n    env = deepq.wrap_atari_dqn(env)\r\n\r\n    model = deepq.learn(\r\n        env,\r\n        \"conv_only\",\r\n        convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)],\r\n        hiddens=[256],\r\n        dueling=True,\r\n        lr=1e-4,\r\n        checkpoint_path=\"pong_checkpoint\",\r\n        total_timesteps=int(1e6),\r\n        print_freq=10,\r\n        buffer_size=10000,\r\n        exploration_fraction=0.1,\r\n        exploration_final_eps=0.01,\r\n        train_freq=4,\r\n        learning_starts=10000,\r\n        target_network_update_freq=1000,\r\n        gamma=0.99,\r\n    )\r\n\r\n    model.save('pong_model.pkl')\r\n    env.close()\r\n```\r\n\r\n```\r\ndef play_pong():\r\n    env = gym.make(\"PongNoFrameskip-v4\")\r\n    env = deepq.wrap_atari_dqn(env)\r\n    model = deepq.learn(\r\n        env,\r\n        \"conv_only\",\r\n        convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)],\r\n        hiddens=[256],\r\n        dueling=True,\r\n        total_timesteps=0,\r\n        load_path=\"pong_model.pkl\"  \r\n    )\r\n\r\n    while True:\r\n        obs, done = env.reset(), False\r\n        episode_rew = 0\r\n        while not done:\r\n            env.render()\r\n            obs, rew, done, _ = env.step(model(obs[None])[0])\r\n            episode_rew += rew\r\n        print(\"Episode reward\", episode_rew)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/884", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/884/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/884/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/884/events", "html_url": "https://github.com/openai/baselines/issues/884", "id": 437645100, "node_id": "MDU6SXNzdWU0Mzc2NDUxMDA=", "number": 884, "title": "TfRunningMeanStd error with mujoco", "user": {"login": "inkyusa", "id": 5215050, "node_id": "MDQ6VXNlcjUyMTUwNTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/5215050?v=4", "gravatar_id": "", "url": "https://api.github.com/users/inkyusa", "html_url": "https://github.com/inkyusa", "followers_url": "https://api.github.com/users/inkyusa/followers", "following_url": "https://api.github.com/users/inkyusa/following{/other_user}", "gists_url": "https://api.github.com/users/inkyusa/gists{/gist_id}", "starred_url": "https://api.github.com/users/inkyusa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/inkyusa/subscriptions", "organizations_url": "https://api.github.com/users/inkyusa/orgs", "repos_url": "https://api.github.com/users/inkyusa/repos", "events_url": "https://api.github.com/users/inkyusa/events{/privacy}", "received_events_url": "https://api.github.com/users/inkyusa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-04-26T12:16:30Z", "updated_at": "2019-04-29T10:36:17Z", "closed_at": "2019-04-29T10:36:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nAccording to comment on https://github.com/openai/baselines regarding Mujoco vecnormalization, I changed RunningMeanStd by TfRunningMeanStd as instructed but faced the following error while running \"python -m baselines.run --alg=ppo2 --env=Humanoid-v2 --network=mlp --num_timesteps=2e7\"\r\n\r\n> File \"/home/testmony/workspace/venv_p3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1659, in _create_c_op\r\n>     c_op = c_api.TF_FinishOperation(op_desc)\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 1 and 0 for 'Assign_3' (op: 'Assign') with input shapes: [376], [].\r\n\r\nDid anyone experience similar issue?\r\n\r\nBTW \"python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=1e6\" seems to work properly with TfRunningMeanStd.\r\n\r\nI am using Mujoco200, Ubuntu 16.04, TF 1.13.1 (CPU-only) and baseline master branch.\r\n\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/878", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/878/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/878/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/878/events", "html_url": "https://github.com/openai/baselines/issues/878", "id": 433736859, "node_id": "MDU6SXNzdWU0MzM3MzY4NTk=", "number": 878, "title": "PPO2: Non-deterministic behavior when setting --num_timesteps", "user": {"login": "brett-daley", "id": 20010659, "node_id": "MDQ6VXNlcjIwMDEwNjU5", "avatar_url": "https://avatars0.githubusercontent.com/u/20010659?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brett-daley", "html_url": "https://github.com/brett-daley", "followers_url": "https://api.github.com/users/brett-daley/followers", "following_url": "https://api.github.com/users/brett-daley/following{/other_user}", "gists_url": "https://api.github.com/users/brett-daley/gists{/gist_id}", "starred_url": "https://api.github.com/users/brett-daley/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brett-daley/subscriptions", "organizations_url": "https://api.github.com/users/brett-daley/orgs", "repos_url": "https://api.github.com/users/brett-daley/repos", "events_url": "https://api.github.com/users/brett-daley/events{/privacy}", "received_events_url": "https://api.github.com/users/brett-daley/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-04-16T11:50:02Z", "updated_at": "2019-06-01T13:31:44Z", "closed_at": "2019-06-01T13:31:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "When I change the `--num_timesteps` argument for PPO2, even after setting the random seed and with all other hyperparameters the same, I get different performances after a few updates. **Although each individual run is entirely deterministic, for some reason changing the length of training affects the reproducibility of the results.** I'm on commit fa37beb.\r\n\r\nFor example, running PPO2 for 4 updates:\r\n`python -m baselines.run --env=Hopper-v2 --seed=0 --num_env=1 --nsteps=2048 --num_timesteps=8192`\r\n\r\nI get these episode rewards:\r\n```\r\n| eprewmean          | 16.5         |\r\n| eprewmean          | 21.1         |\r\n| eprewmean          | 23.1         |\r\n| eprewmean          | 31.4         |\r\n```\r\n\r\nAnd then running it for 5 updates:\r\n`python -m baselines.run --env=Hopper-v2 --seed=0 --num_env=1 --nsteps=2048 --num_timesteps=10240`\r\n\r\nI get these:\r\n```\r\n| eprewmean          | 16.5         |\r\n| eprewmean          | 21.1         |\r\n| eprewmean          | 24.1         |\r\n| eprewmean          | 32.9         |\r\n| eprewmean          | 54.6         |\r\n```\r\n\r\nNotice that the performances have diverged at the 3rd update, despite the identical hyperparameters and seed. I believe this is a bug, but I cannot figure out where it is coming from.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/876", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/876/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/876/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/876/events", "html_url": "https://github.com/openai/baselines/issues/876", "id": 433618262, "node_id": "MDU6SXNzdWU0MzM2MTgyNjI=", "number": 876, "title": "PPO2 Atari cannot reproduce paper results", "user": {"login": "llach", "id": 18076234, "node_id": "MDQ6VXNlcjE4MDc2MjM0", "avatar_url": "https://avatars3.githubusercontent.com/u/18076234?v=4", "gravatar_id": "", "url": "https://api.github.com/users/llach", "html_url": "https://github.com/llach", "followers_url": "https://api.github.com/users/llach/followers", "following_url": "https://api.github.com/users/llach/following{/other_user}", "gists_url": "https://api.github.com/users/llach/gists{/gist_id}", "starred_url": "https://api.github.com/users/llach/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/llach/subscriptions", "organizations_url": "https://api.github.com/users/llach/orgs", "repos_url": "https://api.github.com/users/llach/repos", "events_url": "https://api.github.com/users/llach/events{/privacy}", "received_events_url": "https://api.github.com/users/llach/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2019-04-16T07:10:42Z", "updated_at": "2019-04-27T12:21:00Z", "closed_at": "2019-04-27T12:21:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to reproduce the reported PPO2 results on the Atari environments.\r\nMy script looks like this:\r\n\r\n```python\r\nfrom baselines.run import main\r\n\r\nargs = [\r\n    '--env', 'BreakoutNoFrameskip-v4',\r\n    '--alg', 'ppo2',\r\n    '--num_env', '16',\r\n    '--log_interval', '1',\r\n    '--seed', '0',\r\n]\r\n\r\nmain(args)\r\n```\r\n\r\nIt basically uses the default Atari parameters for PPO which match those from the paper (in `ppo2/defaults.py`), but after 10M steps, my final reward was ~20 with a peak at 30. This doesn't come close to reported performance which was ~300. \r\nWhat am I missing here?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/869", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/869/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/869/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/869/events", "html_url": "https://github.com/openai/baselines/issues/869", "id": 429170189, "node_id": "MDU6SXNzdWU0MjkxNzAxODk=", "number": 869, "title": "Cannot find commit cbd21ef mentioned by benchmark page", "user": {"login": "ktlichkid", "id": 11657533, "node_id": "MDQ6VXNlcjExNjU3NTMz", "avatar_url": "https://avatars3.githubusercontent.com/u/11657533?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktlichkid", "html_url": "https://github.com/ktlichkid", "followers_url": "https://api.github.com/users/ktlichkid/followers", "following_url": "https://api.github.com/users/ktlichkid/following{/other_user}", "gists_url": "https://api.github.com/users/ktlichkid/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktlichkid/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktlichkid/subscriptions", "organizations_url": "https://api.github.com/users/ktlichkid/orgs", "repos_url": "https://api.github.com/users/ktlichkid/repos", "events_url": "https://api.github.com/users/ktlichkid/events{/privacy}", "received_events_url": "https://api.github.com/users/ktlichkid/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-04-04T09:20:37Z", "updated_at": "2019-04-09T11:50:12Z", "closed_at": "2019-04-07T03:04:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI am trying to reproduce the benchmark curve in this page (noted as Benchmarks in Readme): http://htmlpreview.github.io/?https://github.com/openai/baselines/blob/master/benchmarks_atari10M.htm\r\n\r\nAccording to the link above, it seems the benchmark curves were produced with commit `cbd21ef`. However I failed to find a commit with that revision number in this project. \r\n\r\nHow could I find the correct version to reproduce the benchmark curves? Any hint will be appreciated!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/857", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/857/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/857/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/857/events", "html_url": "https://github.com/openai/baselines/issues/857", "id": 422512187, "node_id": "MDU6SXNzdWU0MjI1MTIxODc=", "number": 857, "title": "why alpha=0.99, epsilon=1e-5 in RMSprop?", "user": {"login": "chang-guofeng", "id": 3156581, "node_id": "MDQ6VXNlcjMxNTY1ODE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3156581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chang-guofeng", "html_url": "https://github.com/chang-guofeng", "followers_url": "https://api.github.com/users/chang-guofeng/followers", "following_url": "https://api.github.com/users/chang-guofeng/following{/other_user}", "gists_url": "https://api.github.com/users/chang-guofeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/chang-guofeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chang-guofeng/subscriptions", "organizations_url": "https://api.github.com/users/chang-guofeng/orgs", "repos_url": "https://api.github.com/users/chang-guofeng/repos", "events_url": "https://api.github.com/users/chang-guofeng/events{/privacy}", "received_events_url": "https://api.github.com/users/chang-guofeng/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-19T02:16:22Z", "updated_at": "2019-04-04T01:23:21Z", "closed_at": "2019-04-04T01:23:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello, \r\nI found the default params for  RMSprop in A2C is alpha(decay)=0.99, epsilon=1e-5, and that in tf.train.RMSPropOptimizer(\uff09the default is decay=0.9, epsilon=1e-10;\r\nCan anyone tell me how to make choice, any information helps\r\nthanks.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/852", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/852/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/852/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/852/events", "html_url": "https://github.com/openai/baselines/issues/852", "id": 420782231, "node_id": "MDU6SXNzdWU0MjA3ODIyMzE=", "number": 852, "title": "deepq is not working in the latest master branch", "user": {"login": "haochihlin", "id": 8316182, "node_id": "MDQ6VXNlcjgzMTYxODI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8316182?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haochihlin", "html_url": "https://github.com/haochihlin", "followers_url": "https://api.github.com/users/haochihlin/followers", "following_url": "https://api.github.com/users/haochihlin/following{/other_user}", "gists_url": "https://api.github.com/users/haochihlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/haochihlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haochihlin/subscriptions", "organizations_url": "https://api.github.com/users/haochihlin/orgs", "repos_url": "https://api.github.com/users/haochihlin/repos", "events_url": "https://api.github.com/users/haochihlin/events{/privacy}", "received_events_url": "https://api.github.com/users/haochihlin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-14T00:44:28Z", "updated_at": "2019-04-05T23:43:36Z", "closed_at": "2019-04-05T23:43:36Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi,\r\nI cloned the latest master branch of baselines and tested deepq today,\r\nbut it shows errors with \"print(f'episode_rew={episode_rew}')\"\r\n\r\nCommand I used: `$ python -m baselines.run --alg=deepq --env=CartPole-v0`\r\n\r\nWhole terminal output:\r\n`$ python -m baselines.run --alg=deepq --env=CartPole-v0`\r\n\r\n`Traceback (most recent call last):\r\n  File \"/usr/lib/python3.5/runpy.py\", line 174, in _run_module_as_main\r\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 144, in _get_module_details\r\n    code = loader.get_code(mod_name)\r\n  File \"<frozen importlib._bootstrap_external>\", line 767, in get_code\r\n  File \"<frozen importlib._bootstrap_external>\", line 727, in source_to_code\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n  File \"/home/hlin/.virtualenvs/benchmarks/lib/python3.5/site-packages/baselines/run.py\", line 235\r\n    print(f'episode_rew={episode_rew}')\r\n                                     ^\r\nSyntaxError: invalid syntax\r\n`\r\n\r\nSince I don't meet this issue last week as I cloned the previous version of master branch,\r\nSo, I removed the line `print(f'episode_rew={episode_rew}')` in `run.py`, it works well now.\r\n\r\nMaybe you can check and test it again.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/851", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/851/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/851/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/851/events", "html_url": "https://github.com/openai/baselines/issues/851", "id": 420082341, "node_id": "MDU6SXNzdWU0MjAwODIzNDE=", "number": 851, "title": "Logging reward for plotting", "user": {"login": "slerman12", "id": 9126603, "node_id": "MDQ6VXNlcjkxMjY2MDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/9126603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/slerman12", "html_url": "https://github.com/slerman12", "followers_url": "https://api.github.com/users/slerman12/followers", "following_url": "https://api.github.com/users/slerman12/following{/other_user}", "gists_url": "https://api.github.com/users/slerman12/gists{/gist_id}", "starred_url": "https://api.github.com/users/slerman12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/slerman12/subscriptions", "organizations_url": "https://api.github.com/users/slerman12/orgs", "repos_url": "https://api.github.com/users/slerman12/repos", "events_url": "https://api.github.com/users/slerman12/events{/privacy}", "received_events_url": "https://api.github.com/users/slerman12/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-03-12T16:25:31Z", "updated_at": "2019-03-28T16:21:49Z", "closed_at": "2019-03-28T16:21:49Z", "author_association": "NONE", "active_lock_reason": null, "body": "The A2C code logs metrics like explained variance, but doesn't log simply average reward over time. It's a little complicated with A2C since rewards come from multiple environments at a time, but I would like to plot some kind of average over time. Is there a way to modify the A2C logger code to output these tabular values to CSV and include reward as a metric? How do I change the output directory?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/850", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/850/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/850/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/850/events", "html_url": "https://github.com/openai/baselines/issues/850", "id": 419776110, "node_id": "MDU6SXNzdWU0MTk3NzYxMTA=", "number": 850, "title": "PPO2 does not work on mujoco env ", "user": {"login": "Jerryxiaoyu", "id": 22829052, "node_id": "MDQ6VXNlcjIyODI5MDUy", "avatar_url": "https://avatars0.githubusercontent.com/u/22829052?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jerryxiaoyu", "html_url": "https://github.com/Jerryxiaoyu", "followers_url": "https://api.github.com/users/Jerryxiaoyu/followers", "following_url": "https://api.github.com/users/Jerryxiaoyu/following{/other_user}", "gists_url": "https://api.github.com/users/Jerryxiaoyu/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jerryxiaoyu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jerryxiaoyu/subscriptions", "organizations_url": "https://api.github.com/users/Jerryxiaoyu/orgs", "repos_url": "https://api.github.com/users/Jerryxiaoyu/repos", "events_url": "https://api.github.com/users/Jerryxiaoyu/events{/privacy}", "received_events_url": "https://api.github.com/users/Jerryxiaoyu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-03-12T02:50:20Z", "updated_at": "2019-04-05T23:49:02Z", "closed_at": "2019-04-05T23:49:02Z", "author_association": "NONE", "active_lock_reason": null, "body": " Hi, everyone. I ran ppo2 on mujoco env with default parameters as follows:\r\n`python -m baselines.run --alg=ppo2 --env=Ant-v2 --num_timesteps=1e6`\r\nbut the code is stuck on the following line:\r\nhttps://github.com/openai/baselines/blob/1259f6ab25c6f7261e33c4c3b92df869188f9260/baselines/ppo2/ppo2.py#L157\r\nand I didn't get any error or warning.\r\nActually, both Atari envs using `ppo2`  and any env using `trpo-mpi` work successfully.\r\nI use python 3.5.2 virtual env on anaconda. And mujoco and tensorflow-gpu work well.\r\n\r\n So if anyone could help me out here, I would be very happy. Thanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/844", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/844/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/844/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/844/events", "html_url": "https://github.com/openai/baselines/issues/844", "id": 418532473, "node_id": "MDU6SXNzdWU0MTg1MzI0NzM=", "number": 844, "title": "Mean final scores of PPO paper", "user": {"login": "rasoolfa", "id": 11698385, "node_id": "MDQ6VXNlcjExNjk4Mzg1", "avatar_url": "https://avatars2.githubusercontent.com/u/11698385?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rasoolfa", "html_url": "https://github.com/rasoolfa", "followers_url": "https://api.github.com/users/rasoolfa/followers", "following_url": "https://api.github.com/users/rasoolfa/following{/other_user}", "gists_url": "https://api.github.com/users/rasoolfa/gists{/gist_id}", "starred_url": "https://api.github.com/users/rasoolfa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rasoolfa/subscriptions", "organizations_url": "https://api.github.com/users/rasoolfa/orgs", "repos_url": "https://api.github.com/users/rasoolfa/repos", "events_url": "https://api.github.com/users/rasoolfa/events{/privacy}", "received_events_url": "https://api.github.com/users/rasoolfa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-03-07T21:58:27Z", "updated_at": "2019-03-11T22:28:47Z", "closed_at": "2019-03-11T22:28:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi @joschu \r\n\r\nHow were numbers in Table 6, page 12 (i.e. Mean final scores (last 100 episodes) of [PPO](https://arxiv.org/abs/1707.06347) calculated? I mean were those numbers are calculated from *.monitor.csv files or sth else?\r\n\r\nThanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/839", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/839/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/839/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/839/events", "html_url": "https://github.com/openai/baselines/issues/839", "id": 415813060, "node_id": "MDU6SXNzdWU0MTU4MTMwNjA=", "number": 839, "title": "IndexError: invalid index to scalar variable.", "user": {"login": "bmwant", "id": 3602533, "node_id": "MDQ6VXNlcjM2MDI1MzM=", "avatar_url": "https://avatars1.githubusercontent.com/u/3602533?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bmwant", "html_url": "https://github.com/bmwant", "followers_url": "https://api.github.com/users/bmwant/followers", "following_url": "https://api.github.com/users/bmwant/following{/other_user}", "gists_url": "https://api.github.com/users/bmwant/gists{/gist_id}", "starred_url": "https://api.github.com/users/bmwant/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bmwant/subscriptions", "organizations_url": "https://api.github.com/users/bmwant/orgs", "repos_url": "https://api.github.com/users/bmwant/repos", "events_url": "https://api.github.com/users/bmwant/events{/privacy}", "received_events_url": "https://api.github.com/users/bmwant/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-02-28T20:39:35Z", "updated_at": "2019-03-12T00:44:19Z", "closed_at": "2019-03-12T00:44:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hey, I'm trying to visualize model trained with \r\n```\r\npython -m baselines.run --alg=deepq --env=PongNoFrameskip-v4 --num_timesteps=1e4 --save_path=~/models/pong_10K_deepq\r\n```\r\nby loading saved model like this\r\n```\r\npython -m baselines.run --alg=deepq --env=PongNoFrameskip-v4 --num_timesteps=0 --load_path=~/models/pong_10K_deepq --play\r\n```\r\n\r\nBut instead of visualizing it throws an error\r\n```\r\nLogging to /var/folders/vy/mgpxtlld3q3cltdt357grl2c0000gn/T/openai-2019-02-28-22-25-59-032839\r\nenv_type: atari\r\nTraining deepq on atari:PongNoFrameskip-v4 with arguments\r\n{'network': 'conv_only', 'lr': 0.0001, 'buffer_size': 10000, 'exploration_fraction': 0.1, 'exploration_final_eps': 0.01, 'train_freq': 4, 'learning_starts': 10000, 'target_network_update_freq': 1000, 'gamma': 0.99, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'checkpoint_freq': 10000, 'checkpoint_path': None, 'dueling': True, 'load_path': '~/models/pong_1K_deepq'}\r\n2019-02-28 22:25:59.679533: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nWARNING:tensorflow:From /Users/bmwant/pr/baselines/baselines/common/input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nWARNING:tensorflow:From /Users/bmwant/.pyenv/versions/baselines/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /Users/bmwant/.pyenv/versions/baselines/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.flatten instead.\r\nWARNING:tensorflow:From /Users/bmwant/.pyenv/versions/baselines/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nLoaded model from ~/models/pong_1K_deepq\r\nRunning trained model\r\nTraceback (most recent call last):\r\n  File \"/Users/bmwant/.pyenv/versions/3.7.2/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/Users/bmwant/.pyenv/versions/3.7.2/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/Users/bmwant/pr/baselines/baselines/run.py\", line 244, in <module>\r\n    main(sys.argv)\r\n  File \"/Users/bmwant/pr/baselines/baselines/run.py\", line 231, in main\r\n    episode_rew += rew[0]\r\nIndexError: invalid index to scalar variable.\r\n```\r\n- `Python 3.7.2`\r\n- `tensorflow==1.13.1`\r\n- `-e git+git@github.com:openai/baselines.git@b875fb7b5e4feb85b9f1f1bf4e78f64c75595664#egg=baselines`\r\n- `gym==0.12.0`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/829", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/829/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/829/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/829/events", "html_url": "https://github.com/openai/baselines/issues/829", "id": 412085082, "node_id": "MDU6SXNzdWU0MTIwODUwODI=", "number": 829, "title": "Where does the ppo2 reset the env?", "user": {"login": "HitLyn", "id": 25073978, "node_id": "MDQ6VXNlcjI1MDczOTc4", "avatar_url": "https://avatars1.githubusercontent.com/u/25073978?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HitLyn", "html_url": "https://github.com/HitLyn", "followers_url": "https://api.github.com/users/HitLyn/followers", "following_url": "https://api.github.com/users/HitLyn/following{/other_user}", "gists_url": "https://api.github.com/users/HitLyn/gists{/gist_id}", "starred_url": "https://api.github.com/users/HitLyn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HitLyn/subscriptions", "organizations_url": "https://api.github.com/users/HitLyn/orgs", "repos_url": "https://api.github.com/users/HitLyn/repos", "events_url": "https://api.github.com/users/HitLyn/events{/privacy}", "received_events_url": "https://api.github.com/users/HitLyn/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2019-02-19T19:24:14Z", "updated_at": "2019-04-09T21:58:58Z", "closed_at": "2019-02-20T07:53:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "In ppo1, when the env.step() gets done which means the mission has been achieved, the env will be reset by env.set(),then the training continue:\r\nhttps://github.com/openai/baselines/blob/5b41c926c7a852df3f0928afdf2429f96a3965cb/baselines/ppo1/pposgd_simple.py#L61\r\nBut I can't find where ppo2 reset the env, or do I misunderstand something?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/825", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/825/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/825/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/825/events", "html_url": "https://github.com/openai/baselines/issues/825", "id": 410978239, "node_id": "MDU6SXNzdWU0MTA5NzgyMzk=", "number": 825, "title": "Failed to download resource", "user": {"login": "ramyragab1", "id": 22369453, "node_id": "MDQ6VXNlcjIyMzY5NDUz", "avatar_url": "https://avatars0.githubusercontent.com/u/22369453?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ramyragab1", "html_url": "https://github.com/ramyragab1", "followers_url": "https://api.github.com/users/ramyragab1/followers", "following_url": "https://api.github.com/users/ramyragab1/following{/other_user}", "gists_url": "https://api.github.com/users/ramyragab1/gists{/gist_id}", "starred_url": "https://api.github.com/users/ramyragab1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ramyragab1/subscriptions", "organizations_url": "https://api.github.com/users/ramyragab1/orgs", "repos_url": "https://api.github.com/users/ramyragab1/repos", "events_url": "https://api.github.com/users/ramyragab1/events{/privacy}", "received_events_url": "https://api.github.com/users/ramyragab1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-02-15T22:47:59Z", "updated_at": "2020-07-29T12:26:09Z", "closed_at": "2020-07-29T12:26:09Z", "author_association": "NONE", "active_lock_reason": null, "body": "when i tray install with homebrew \r\nError: Failed to download resource \"cmake\"\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/822", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/822/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/822/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/822/events", "html_url": "https://github.com/openai/baselines/issues/822", "id": 409268949, "node_id": "MDU6SXNzdWU0MDkyNjg5NDk=", "number": 822, "title": "PPO2 globalseeds", "user": {"login": "ecada", "id": 18642218, "node_id": "MDQ6VXNlcjE4NjQyMjE4", "avatar_url": "https://avatars1.githubusercontent.com/u/18642218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ecada", "html_url": "https://github.com/ecada", "followers_url": "https://api.github.com/users/ecada/followers", "following_url": "https://api.github.com/users/ecada/following{/other_user}", "gists_url": "https://api.github.com/users/ecada/gists{/gist_id}", "starred_url": "https://api.github.com/users/ecada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ecada/subscriptions", "organizations_url": "https://api.github.com/users/ecada/orgs", "repos_url": "https://api.github.com/users/ecada/repos", "events_url": "https://api.github.com/users/ecada/events{/privacy}", "received_events_url": "https://api.github.com/users/ecada/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-02-12T12:14:58Z", "updated_at": "2019-02-21T17:43:34Z", "closed_at": "2019-02-21T14:23:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nI've been experimenting with the PPO2 algorithm using DummyVecEnv where the number of environments is set to 16. I've realized that in the learn method set_global_seeds use a single seed for every 16 environments.\r\n\r\nhttps://github.com/openai/baselines/blob/5b41c926c7a852df3f0928afdf2429f96a3965cb/baselines/ppo2/ppo2.py#L80\r\n\r\nDoesn't that lead to sampling the same actions for each environment when using 1 process and hinder the exploration in parallel sampling? \r\n\r\nThank you so much for this wonderful library as always, it is the most essential repository for deep reinforcement learning research.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/818", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/818/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/818/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/818/events", "html_url": "https://github.com/openai/baselines/issues/818", "id": 407612752, "node_id": "MDU6SXNzdWU0MDc2MTI3NTI=", "number": 818, "title": "Feature request: Plug in arbitrary model for policy", "user": {"login": "EliasHasle", "id": 17208315, "node_id": "MDQ6VXNlcjE3MjA4MzE1", "avatar_url": "https://avatars0.githubusercontent.com/u/17208315?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EliasHasle", "html_url": "https://github.com/EliasHasle", "followers_url": "https://api.github.com/users/EliasHasle/followers", "following_url": "https://api.github.com/users/EliasHasle/following{/other_user}", "gists_url": "https://api.github.com/users/EliasHasle/gists{/gist_id}", "starred_url": "https://api.github.com/users/EliasHasle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EliasHasle/subscriptions", "organizations_url": "https://api.github.com/users/EliasHasle/orgs", "repos_url": "https://api.github.com/users/EliasHasle/repos", "events_url": "https://api.github.com/users/EliasHasle/events{/privacy}", "received_events_url": "https://api.github.com/users/EliasHasle/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-07T09:43:48Z", "updated_at": "2019-02-07T18:02:02Z", "closed_at": "2019-02-07T18:02:02Z", "author_association": "NONE", "active_lock_reason": null, "body": "I would like to test my own non-standard policy architectures with stable baselines.\r\n\r\nI realize this is probably not an easy feature to add, if anything because you need to coordinate multiple instances with SubProcEnv.\r\n\r\nWhat is the least restrictive solution you can come up with? For instance, would a TensorFlow SavedModel that satisfies certain IO requirements be within reach?\r\n\r\nEdit: To elaborate a bit, I am very happy that environments are (almost) black boxes, and in an ideal world the policy would be a sort of black box too. I understand that the tight connection between optimization procedure and policy makes this difficult, but I would appreciate any steps in this direction, whether it be an object-oriented approach or another one. I have not inspected the relevant parts of the source of stable-baselines, but I am sure you have made some thoughts on generalization during your work on the policy classes.\r\n\r\nI intented to post this on stable-baselines, actually. But it looks like I simply did not investigate their docs thoroughly enough. https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html#custom-policy mentions at the bottom how to use a custom tensorflow policy network. Closing here anyway.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/816", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/816/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/816/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/816/events", "html_url": "https://github.com/openai/baselines/issues/816", "id": 406540045, "node_id": "MDU6SXNzdWU0MDY1NDAwNDU=", "number": 816, "title": "flatten_dict_observations issue", "user": {"login": "xuxiyang1993", "id": 29387830, "node_id": "MDQ6VXNlcjI5Mzg3ODMw", "avatar_url": "https://avatars1.githubusercontent.com/u/29387830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xuxiyang1993", "html_url": "https://github.com/xuxiyang1993", "followers_url": "https://api.github.com/users/xuxiyang1993/followers", "following_url": "https://api.github.com/users/xuxiyang1993/following{/other_user}", "gists_url": "https://api.github.com/users/xuxiyang1993/gists{/gist_id}", "starred_url": "https://api.github.com/users/xuxiyang1993/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xuxiyang1993/subscriptions", "organizations_url": "https://api.github.com/users/xuxiyang1993/orgs", "repos_url": "https://api.github.com/users/xuxiyang1993/repos", "events_url": "https://api.github.com/users/xuxiyang1993/events{/privacy}", "received_events_url": "https://api.github.com/users/xuxiyang1993/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-04T22:03:45Z", "updated_at": "2019-12-08T21:53:32Z", "closed_at": "2019-12-08T21:53:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/openai/baselines/blob/5b41c926c7a852df3f0928afdf2429f96a3965cb/baselines/run.py#L113", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/811", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/811/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/811/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/811/events", "html_url": "https://github.com/openai/baselines/issues/811", "id": 405819581, "node_id": "MDU6SXNzdWU0MDU4MTk1ODE=", "number": 811, "title": "custom_cartpole example make_session parameter problem", "user": {"login": "jbrusey", "id": 641425, "node_id": "MDQ6VXNlcjY0MTQyNQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/641425?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbrusey", "html_url": "https://github.com/jbrusey", "followers_url": "https://api.github.com/users/jbrusey/followers", "following_url": "https://api.github.com/users/jbrusey/following{/other_user}", "gists_url": "https://api.github.com/users/jbrusey/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbrusey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbrusey/subscriptions", "organizations_url": "https://api.github.com/users/jbrusey/orgs", "repos_url": "https://api.github.com/users/jbrusey/repos", "events_url": "https://api.github.com/users/jbrusey/events{/privacy}", "received_events_url": "https://api.github.com/users/jbrusey/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-02-01T18:25:47Z", "updated_at": "2019-04-01T23:24:03Z", "closed_at": "2019-04-01T23:24:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "On running:\r\n$ python custom_cartpole.py\r\nI get\r\n...\r\nTypeError: config must be a tf.ConfigProto, but got <class 'int'>\r\n\r\nThis seems to be caused by a change to the parameter order for tf_util.make_session. I'd like to suggest the attached patch. \r\n[cartpole.patch.txt](https://github.com/openai/baselines/files/2822829/cartpole.patch.txt)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/804", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/804/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/804/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/804/events", "html_url": "https://github.com/openai/baselines/issues/804", "id": 404207334, "node_id": "MDU6SXNzdWU0MDQyMDczMzQ=", "number": 804, "title": "Memory Leak when --num_env > 1", "user": {"login": "MatPoliquin", "id": 7024551, "node_id": "MDQ6VXNlcjcwMjQ1NTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/7024551?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MatPoliquin", "html_url": "https://github.com/MatPoliquin", "followers_url": "https://api.github.com/users/MatPoliquin/followers", "following_url": "https://api.github.com/users/MatPoliquin/following{/other_user}", "gists_url": "https://api.github.com/users/MatPoliquin/gists{/gist_id}", "starred_url": "https://api.github.com/users/MatPoliquin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MatPoliquin/subscriptions", "organizations_url": "https://api.github.com/users/MatPoliquin/orgs", "repos_url": "https://api.github.com/users/MatPoliquin/repos", "events_url": "https://api.github.com/users/MatPoliquin/events{/privacy}", "received_events_url": "https://api.github.com/users/MatPoliquin/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-29T09:55:14Z", "updated_at": "2019-02-11T18:38:52Z", "closed_at": "2019-02-11T18:38:52Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "repro:\r\npython3 -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=2e7 --num_env=2\r\n\r\nObservations:\r\n\r\n- The memory usage of the two python env processes increases at about 30MB per minute until it OOM.\r\n- If I run with --num_env=1 there is no leak\r\n- cifar10 runs with no leaks\r\n- If I use other algos such as --alg=acer, it also leaks\r\n- If I use retro env (as opposed to atari env in the command above) it also leaks\r\n\r\nI tried to track down the memory leak with **pympler**.\r\n\r\nIn:\r\ndef worker(remote, parent_remote, env_fn_wrapper),  **subproc_vec_env.py**\r\nI used:\r\n```\r\nfrom pympler import tracker\r\ntr = tracker.SummaryTracker()\r\n\r\n[...]\r\nif cmd == 'step':\r\n     ob, reward, done, info = env.step(data)\r\n      if done:\r\n          **tr.print_diff()**\r\n          ob = env.reset()\r\n```\r\n\r\nThis is the output I got:\r\n\r\n                            types |                       # objects |         total size\r\n==================================== | =========== | ============\r\n  <class 'numpy.ndarray |                               911 |    113.88 KB\r\n  <class 'builtin_function_or_method |           911 |     64.05 KB\r\n  <class 'float |                                                  53 |     1.24 KB\r\n   <class 'list |                                                     0 |    928     B\r\n   <class 'int |                                                      1 |     28     B\r\n\r\n\r\n**Seems the ob, reward, done and info variable are leaking.**\r\nI tried to use del on these variables but the garbage collector doesn't get rid of them, even if I manually call it  with \"gc.collect(2)\"\r\n\r\n\r\nSoftware:\r\nUbuntu 18.04\r\nTensorflow 1.12\r\nPython 3.6.7\r\nlatest baselines (no modifications)\r\n\r\nHardware:\r\n2x 2680v2\r\n64MB ddr3\r\ngtx 1060", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/803", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/803/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/803/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/803/events", "html_url": "https://github.com/openai/baselines/issues/803", "id": 403703787, "node_id": "MDU6SXNzdWU0MDM3MDM3ODc=", "number": 803, "title": "run behavior_clone.py \uff0cget error   X11/Xlib.h: No such file or directory #include <X11/Xlib.h> and  \u2018gnu-cc\u2019  failed with exit status 1", "user": {"login": "sxwgit", "id": 21139332, "node_id": "MDQ6VXNlcjIxMTM5MzMy", "avatar_url": "https://avatars0.githubusercontent.com/u/21139332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sxwgit", "html_url": "https://github.com/sxwgit", "followers_url": "https://api.github.com/users/sxwgit/followers", "following_url": "https://api.github.com/users/sxwgit/following{/other_user}", "gists_url": "https://api.github.com/users/sxwgit/gists{/gist_id}", "starred_url": "https://api.github.com/users/sxwgit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sxwgit/subscriptions", "organizations_url": "https://api.github.com/users/sxwgit/orgs", "repos_url": "https://api.github.com/users/sxwgit/repos", "events_url": "https://api.github.com/users/sxwgit/events{/privacy}", "received_events_url": "https://api.github.com/users/sxwgit/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2019-01-28T08:45:39Z", "updated_at": "2019-01-31T18:21:47Z", "closed_at": "2019-01-31T18:21:47Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\n\r\nWhen running the behavior_clone.py on the conda environment\uff0ci get the following error\r\n\r\n> running build_ext\r\nbuilding 'mujoco_py.cymj' extension\r\n/home/songxw/anaconda3/envs/mujoco-py/bin/x86_64-conda_cos6-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -fPIC -I/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py -I/home/songxw/.mujoco/mjpro150/include -I/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/numpy/core/include -I/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/vendor/egl -I/home/songxw/anaconda3/envs/mujoco-py/include/python3.5m -c /home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/cymj.c -o /home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/generated/_pyxbld_1.50.1.68_35_linuxgpuextensionbuilder/temp.linux-x86_64-3.5/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/cymj.o -fopenmp -w\r\n/home/songxw/anaconda3/envs/mujoco-py/bin/x86_64-conda_cos6-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -fPIC -I/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py -I/home/songxw/.mujoco/mjpro150/include -I/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/numpy/core/include -I/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/vendor/egl -I/home/songxw/anaconda3/envs/mujoco-py/include/python3.5m -c /home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/gl/eglshim.c -o /home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/generated/_pyxbld_1.50.1.68_35_linuxgpuextensionbuilder/temp.linux-x86_64-3.5/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/gl/eglshim.o -fopenmp -w\r\nIn file included from /home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/gl/egl.h:39:0,\r\nfrom /home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/gl/eglshim.c:2:\r\n/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/site-packages/mujoco_py/gl/eglplatform.h:99:10: fatal error: X11/Xlib.h: No such file or directory\r\n#include <X11/Xlib.h>\r\n^~~~~~~~~~~~\r\ncompilation terminated.\r\nTraceback (most recent call last):\r\nFile \"/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/distutils/unixccompiler.py\", line 118, in _compile\r\nextra_postargs)\r\nFile \"/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/distutils/ccompiler.py\", line 909, in spawn\r\nspawn(cmd, dry_run=self.dry_run)\r\nFile \"/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/distutils/spawn.py\", line 36, in spawn\r\n_spawn_posix(cmd, search_path, dry_run=dry_run)\r\nFile \"/home/songxw/anaconda3/envs/mujoco-py/lib/python3.5/distutils/spawn.py\", line 159, in _spawn_posix\r\n% (cmd, exit_status))\r\ndistutils.errors.DistutilsExecError: command '/home/songxw/anaconda3/envs/mujoco-py/bin/x86_64-conda_cos6-linux-gnu-cc' failed with exit status 1\r\n\r\nmy conda environment \r\n\r\n> active env location : /home/songxw/anaconda3/envs/mujoco-py\r\nshell level : 2\r\nuser config file : /home/songxw/.condarc\r\npopulated config files :\r\nconda version : 4.5.12\r\nconda-build version : 3.17.6\r\npython version : 3.7.1.final.0\r\nbase environment : /home/songxw/anaconda3 (writable)\r\nchannel URLs : https://repo.anaconda.com/pkgs/main/linux-64\r\nhttps://repo.anaconda.com/pkgs/main/noarch\r\nhttps://repo.anaconda.com/pkgs/free/linux-64\r\nhttps://repo.anaconda.com/pkgs/free/noarch\r\nhttps://repo.anaconda.com/pkgs/r/linux-64\r\nhttps://repo.anaconda.com/pkgs/r/noarch\r\nhttps://repo.anaconda.com/pkgs/pro/linux-64\r\nhttps://repo.anaconda.com/pkgs/pro/noarch\r\npackage cache : /home/songxw/anaconda3/pkgs\r\n/home/songxw/.conda/pkgs\r\nenvs directories : /home/songxw/anaconda3/envs\r\n/home/songxw/.conda/envs\r\nplatform : linux-64\r\nuser-agent : conda/4.5.12 requests/2.21.0 CPython/3.7.1 Linux/4.15.0-29-generic ubuntu/16.04 glibc/2.23\r\nUID:GID : 1000:1000\r\nnetrc file : None\r\noffline mode : False\r\n\r\n\r\n\r\n\r\nI have tried many methods, including conda install gcc, (but i get another issue like [this ](https://github.com/ContinuumIO/anaconda-issues/issues/1392) \uff0cand that answer doesnt  work,)sad.\r\nwhat should i do to solve this problem ( \u2018gnu-cc\u2019 failed with exit status 1)\r\nBest regards,", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/802", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/802/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/802/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/802/events", "html_url": "https://github.com/openai/baselines/issues/802", "id": 403052547, "node_id": "MDU6SXNzdWU0MDMwNTI1NDc=", "number": 802, "title": "observation normalization?", "user": {"login": "hankly", "id": 4230272, "node_id": "MDQ6VXNlcjQyMzAyNzI=", "avatar_url": "https://avatars0.githubusercontent.com/u/4230272?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hankly", "html_url": "https://github.com/hankly", "followers_url": "https://api.github.com/users/hankly/followers", "following_url": "https://api.github.com/users/hankly/following{/other_user}", "gists_url": "https://api.github.com/users/hankly/gists{/gist_id}", "starred_url": "https://api.github.com/users/hankly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hankly/subscriptions", "organizations_url": "https://api.github.com/users/hankly/orgs", "repos_url": "https://api.github.com/users/hankly/repos", "events_url": "https://api.github.com/users/hankly/events{/privacy}", "received_events_url": "https://api.github.com/users/hankly/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824580, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODA=", "url": "https://api.github.com/repos/openai/baselines/labels/bug", "name": "bug", "color": "ee0701", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-25T08:28:41Z", "updated_at": "2019-04-01T22:44:42Z", "closed_at": "2019-04-01T22:44:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "https://github.com/openai/baselines/blob/b55eda1dde7292a56ad63d8a849198100bd26a17/baselines/gail/adversary.py#L69\r\n\r\nIn gail/adeversay.py Line 69.\r\nI suppose it normalize obs.but ,is it something wrong?\r\n \r\nit should be `obs = (obs_ph - self.obs_rms.mean) / self.obs_rms.std` instead?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/798", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/798/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/798/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/798/events", "html_url": "https://github.com/openai/baselines/issues/798", "id": 402505767, "node_id": "MDU6SXNzdWU0MDI1MDU3Njc=", "number": 798, "title": "AttributeError: 'function' object has no attribute 'reset' inf rollout.py ", "user": {"login": "dovanhuong", "id": 33709616, "node_id": "MDQ6VXNlcjMzNzA5NjE2", "avatar_url": "https://avatars0.githubusercontent.com/u/33709616?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dovanhuong", "html_url": "https://github.com/dovanhuong", "followers_url": "https://api.github.com/users/dovanhuong/followers", "following_url": "https://api.github.com/users/dovanhuong/following{/other_user}", "gists_url": "https://api.github.com/users/dovanhuong/gists{/gist_id}", "starred_url": "https://api.github.com/users/dovanhuong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dovanhuong/subscriptions", "organizations_url": "https://api.github.com/users/dovanhuong/orgs", "repos_url": "https://api.github.com/users/dovanhuong/repos", "events_url": "https://api.github.com/users/dovanhuong/events{/privacy}", "received_events_url": "https://api.github.com/users/dovanhuong/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-01-24T01:43:58Z", "updated_at": "2020-02-12T10:55:48Z", "closed_at": "2019-01-31T05:49:16Z", "author_association": "NONE", "active_lock_reason": null, "body": "Dear all,\r\n I'm working with implement HER algorithm in UR5 environment. After I launch with the 1 epoches and reset my environment. It always tell to me 'function' object has no attribute 'reset'. The detail of my issue as below: \r\n2019-01-24 10:21:38.551305: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nCreating a DDPG agent with action space 4 x [0.15       0.05       0.26179939 0.26179939]...\r\nTraceback (most recent call last):\r\n  File \"/home/huong/catkin_ws/src/ur_gazebo_test2/experiment/train.py\", line 224, in <module>\r\n    main()\r\n  File \"/home/huong/env_tensorflow/lib/python3.5/site-packages/click/core.py\", line 764, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/home/huong/env_tensorflow/lib/python3.5/site-packages/click/core.py\", line 717, in main\r\n[INFO] [1548292899.141068, 877.931000]: DONE CONFIGURE DDPG\r\n    rv = self.invoke(ctx)\r\n  File \"/home/huong/env_tensorflow/lib/python3.5/site-packages/click/core.py\", line 956, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/home/huong/env_tensorflow/lib/python3.5/site-packages/click/core.py\", line 555, in invoke\r\n    return callback(*args, **kwargs)\r\n  File \"/home/huong/catkin_ws/src/ur_gazebo_test2/experiment/train.py\", line 220, in main\r\n    launch(**kwargs)\r\n  File \"/home/huong/catkin_ws/src/ur_gazebo_test2/experiment/train.py\", line 194, in launch\r\n    rollout_worker = RolloutWorker(params['make_env'], policy, dims, logger, **rollout_params)\r\n  File \"/home/huong/baselines/baselines/her/util.py\", line 36, in wrapper\r\n    return method(*positional_args, **keyword_args)\r\n  File \"/home/huong/baselines/baselines/her/rollout.py\", line 42, in __init__\r\n    self.reset_all_rollouts()\r\n  File \"/home/huong/baselines/baselines/her/rollout.py\", line 46, in reset_all_rollouts\r\n    self.obs_dict = self.venv.reset()\r\nAttributeError: 'function' object has no attribute 'reset'\r\n\r\nProcess finished with exit code 1\r\n\r\nMy config.py and train.py as in  the link: https://github.com/dovanhuong/Baselines_UR5_issue\r\nHas anyone can solve this issue or have suggestions, please tell to me know! I'm looking forward to hear your advices~", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/795", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/795/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/795/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/795/events", "html_url": "https://github.com/openai/baselines/issues/795", "id": 401112133, "node_id": "MDU6SXNzdWU0MDExMTIxMzM=", "number": 795, "title": "[common] Inconsistent usage and implementation of tf_util.function", "user": {"login": "Rishav1", "id": 9868364, "node_id": "MDQ6VXNlcjk4NjgzNjQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/9868364?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Rishav1", "html_url": "https://github.com/Rishav1", "followers_url": "https://api.github.com/users/Rishav1/followers", "following_url": "https://api.github.com/users/Rishav1/following{/other_user}", "gists_url": "https://api.github.com/users/Rishav1/gists{/gist_id}", "starred_url": "https://api.github.com/users/Rishav1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Rishav1/subscriptions", "organizations_url": "https://api.github.com/users/Rishav1/orgs", "repos_url": "https://api.github.com/users/Rishav1/repos", "events_url": "https://api.github.com/users/Rishav1/events{/privacy}", "received_events_url": "https://api.github.com/users/Rishav1/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-20T16:07:49Z", "updated_at": "2019-01-31T18:23:48Z", "closed_at": "2019-01-31T18:23:48Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "According to the [docstring example](https://github.com/openai/baselines/blob/master/baselines/common/tf_util.py#L147-L160) of tf_util.function(), it should support *args as well as **kwargs, but the way tf_util._Function class has been implemented, the [__call__](https://github.com/openai/baselines/blob/master/baselines/common/tf_util.py#L200) accepts only *args, and that too in the exact order in which the input placeholders were passed. \r\n\r\nPlus, in the implementation of _Function class, the [givens are updated post the inputs](https://github.com/openai/baselines/blob/master/baselines/common/tf_util.py#L203-L208), which has the behavior of overwriting the passed arguments instead of acting as default values. \r\n\r\nThis has several impact on the RL algorithm implementations, such as:\r\n\r\n1. In deepq, the [act function](https://github.com/openai/baselines/blob/master/baselines/deepq/build_graph.py#L193-L196) never does any exploration as the update_eps_ph = -1 is set in the givens.\r\n\r\n2. In deepq, the [act with param noise](https://github.com/openai/baselines/blob/18b6390be606e6eac559489bb34e5dfc47a14168/baselines/deepq/build_graph.py#L310) never updates the noise threshold or scale or gets the reset=True flag.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/791", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/791/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/791/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/791/events", "html_url": "https://github.com/openai/baselines/issues/791", "id": 399448517, "node_id": "MDU6SXNzdWUzOTk0NDg1MTc=", "number": 791, "title": "Jessica Lockwood& Johnnyhelm", "user": {"login": "cindyloutom", "id": 45528312, "node_id": "MDQ6VXNlcjQ1NTI4MzEy", "avatar_url": "https://avatars2.githubusercontent.com/u/45528312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cindyloutom", "html_url": "https://github.com/cindyloutom", "followers_url": "https://api.github.com/users/cindyloutom/followers", "following_url": "https://api.github.com/users/cindyloutom/following{/other_user}", "gists_url": "https://api.github.com/users/cindyloutom/gists{/gist_id}", "starred_url": "https://api.github.com/users/cindyloutom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cindyloutom/subscriptions", "organizations_url": "https://api.github.com/users/cindyloutom/orgs", "repos_url": "https://api.github.com/users/cindyloutom/repos", "events_url": "https://api.github.com/users/cindyloutom/events{/privacy}", "received_events_url": "https://api.github.com/users/cindyloutom/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2019-01-15T17:15:15Z", "updated_at": "2019-01-23T01:27:15Z", "closed_at": "2019-01-23T01:27:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/790", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/790/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/790/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/790/events", "html_url": "https://github.com/openai/baselines/issues/790", "id": 399446237, "node_id": "MDU6SXNzdWUzOTk0NDYyMzc=", "number": 790, "title": "error when i run python -m baselines.run --alg=ppo2 .... HELP please", "user": {"login": "sosinfo212", "id": 9013866, "node_id": "MDQ6VXNlcjkwMTM4NjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/9013866?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sosinfo212", "html_url": "https://github.com/sosinfo212", "followers_url": "https://api.github.com/users/sosinfo212/followers", "following_url": "https://api.github.com/users/sosinfo212/following{/other_user}", "gists_url": "https://api.github.com/users/sosinfo212/gists{/gist_id}", "starred_url": "https://api.github.com/users/sosinfo212/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sosinfo212/subscriptions", "organizations_url": "https://api.github.com/users/sosinfo212/orgs", "repos_url": "https://api.github.com/users/sosinfo212/repos", "events_url": "https://api.github.com/users/sosinfo212/events{/privacy}", "received_events_url": "https://api.github.com/users/sosinfo212/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-01-15T17:09:28Z", "updated_at": "2019-01-24T23:05:35Z", "closed_at": "2019-01-24T23:05:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "hello  i have a problem i think in my python setup when i run \r\npython -m baselines.run --alg=ppo2 --env=Humanoid-v2 --network=mlp --num_timesteps=2e7\r\n**i got this error** \r\n`Traceback (most recent call last):\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/Users/macos/mjpro150/baselines/baselines/run.py\", line 9, in <module>\r\n    from baselines.common.vec_env.vec_video_recorder import VecVideoRecorder\r\n  File \"baselines/common/__init__.py\", line 3, in <module>\r\n    from baselines.common.dataset import Dataset\r\n  File \"baselines/common/dataset.py\", line 50\r\n    def iterbatches(arrays, *, num_batches=None, batch_size=None, shuffle=True, include_final_partial_batch=True):\r\n                             ^\r\nSyntaxError: invalid syntax\r\n`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/783", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/783/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/783/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/783/events", "html_url": "https://github.com/openai/baselines/issues/783", "id": 397897333, "node_id": "MDU6SXNzdWUzOTc4OTczMzM=", "number": 783, "title": "Missing arguments in call to build policy when using ACER with LSTM. ", "user": {"login": "ethanwaldie", "id": 5624918, "node_id": "MDQ6VXNlcjU2MjQ5MTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5624918?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ethanwaldie", "html_url": "https://github.com/ethanwaldie", "followers_url": "https://api.github.com/users/ethanwaldie/followers", "following_url": "https://api.github.com/users/ethanwaldie/following{/other_user}", "gists_url": "https://api.github.com/users/ethanwaldie/gists{/gist_id}", "starred_url": "https://api.github.com/users/ethanwaldie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ethanwaldie/subscriptions", "organizations_url": "https://api.github.com/users/ethanwaldie/orgs", "repos_url": "https://api.github.com/users/ethanwaldie/repos", "events_url": "https://api.github.com/users/ethanwaldie/events{/privacy}", "received_events_url": "https://api.github.com/users/ethanwaldie/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2019-01-10T16:00:02Z", "updated_at": "2019-01-24T02:32:00Z", "closed_at": "2019-01-24T02:32:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Hi there, \r\n\r\nI have been trying to use the ACER model with an LSTM policy or:\r\n\r\n`python -m baselines.run --alg=acer --env=CartPole-v0 --network=lstm`\r\n\r\nHowever I am consistently getting the following error: \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/ethanwaldie/anaconda3/envs/malmo_env/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/Users/ethanwaldie/anaconda3/envs/malmo_env/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/Users/ethanwaldie/thesis/baselines/baselines/run.py\", line 240, in <module>\r\n    main(sys.argv)\r\n  File \"/Users/ethanwaldie/thesis/baselines/baselines/run.py\", line 207, in main\r\n    model, env = train(args, extra_args)\r\n  File \"/Users/ethanwaldie/thesis/baselines/baselines/run.py\", line 81, in train\r\n    **alg_kwargs\r\n  File \"/Users/ethanwaldie/thesis/baselines/baselines/acer/acer.py\", line 359, in learn\r\n    trust_region=trust_region, alpha=alpha, delta=delta)\r\n  File \"/Users/ethanwaldie/thesis/baselines/baselines/acer/acer.py\", line 78, in __init__\r\n    step_model = policy(observ_placeholder=step_ob_placeholder, sess=sess)\r\n  File \"/Users/ethanwaldie/thesis/baselines/baselines/common/policies.py\", line 148, in policy_fn\r\n    nenv = nbatch // nsteps\r\nTypeError: unsupported operand type(s) for //: 'NoneType' and 'NoneType'\r\n```\r\n\r\nWhen following the stacktrace I have found the following lines to be of issue, Inside the model object in acer.py the policy builder is called with insufficient arguments for a recurrent policy. \r\n\r\nlines 78 and 79 in acer.py:\r\n\r\n``` \r\nwith tf.variable_scope('acer_model', reuse=tf.AUTO_REUSE):\r\n            step_model = policy(observ_placeholder=step_ob_placeholder, sess=sess)\r\n            train_model = policy(observ_placeholder=train_ob_placeholder, sess=sess)\r\n```\r\n\r\nThis causes the code to break in the common/policies.py file lines 146-151:\r\n\r\n```\r\nif recurrent_tensors is not None:\r\n                    # recurrent architecture, need a few more steps\r\n                    nenv = nbatch // nsteps\r\n                    assert nenv > 0, 'Bad input for recurrent policy: batch size {} smaller than nsteps {}'.format(nbatch, nsteps)\r\n                    policy_latent, recurrent_tensors = policy_network(encoded_x, nenv)\r\n                    extra_tensors.update(recurrent_tensors)\r\n```\r\n\r\nAnd this only occurs for recurrent policies. If  these policies are not supported, perhaps the documentation should be updated, as in neither the readme or the learn function of the acer.py module is this mentioned. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/771", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/771/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/771/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/771/events", "html_url": "https://github.com/openai/baselines/issues/771", "id": 393504219, "node_id": "MDU6SXNzdWUzOTM1MDQyMTk=", "number": 771, "title": "PPO2: Epsilon exploration?", "user": {"login": "Ploppz", "id": 4773287, "node_id": "MDQ6VXNlcjQ3NzMyODc=", "avatar_url": "https://avatars2.githubusercontent.com/u/4773287?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ploppz", "html_url": "https://github.com/Ploppz", "followers_url": "https://api.github.com/users/Ploppz/followers", "following_url": "https://api.github.com/users/Ploppz/following{/other_user}", "gists_url": "https://api.github.com/users/Ploppz/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ploppz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ploppz/subscriptions", "organizations_url": "https://api.github.com/users/Ploppz/orgs", "repos_url": "https://api.github.com/users/Ploppz/repos", "events_url": "https://api.github.com/users/Ploppz/events{/privacy}", "received_events_url": "https://api.github.com/users/Ploppz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824585, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODU=", "url": "https://api.github.com/repos/openai/baselines/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-21T15:48:48Z", "updated_at": "2018-12-21T21:20:00Z", "closed_at": "2018-12-21T20:49:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "I tried to train `Acrobot-v1` using your PPO implementation (`ppo2`). But it performs really bad - virtually never reaches the goal. I ran it for 200 episodes (100000 time steps) but it only reached the goal once after 495 timesteps (environment resets at 500 timestep, so this is rather useless).\r\n\r\nI wonder if epsilon exploration would make this better (note that Acrobot has very sparse rewards). However I could not find any way to add epsilon exploration. If I could somehow just **wrap or modify the action-taking function or class**, that would help.\r\n\r\nHere is my code:\r\n\r\n```\r\nfrom baselines.common.vec_env.dummy_vec_env import DummyVecEnv\r\nfrom baselines.ppo2.ppo2 import learn\r\nimport baselines.common.models as models\r\n\r\nimport gym\r\nfrom matplotlib import pyplot as plt\r\n\r\n\r\nclass Env:\r\n    def __init__(self, inner_env):\r\n        self.rewards = []\r\n        self.reward = 0\r\n        self.env = inner_env\r\n        self.observation_space = inner_env.observation_space\r\n        self.action_space = inner_env.action_space\r\n\r\n        self.ob_dim = inner_env.observation_space.shape[0]\r\n\r\n    def step(self, action):\r\n        state_next, r, terminal, info = self.env.step(action)\r\n        self.reward += r\r\n        if terminal:\r\n            self.rewards.append(self.reward)\r\n            self.reward = 0\r\n        return state_next, r, terminal, info\r\n\r\n    def reset(self):\r\n        state = self.env.reset()\r\n        return state\r\n\r\n    def render(self):\r\n        return self.env.render()\r\n\r\nif __name__ == '__main__':\r\n    from baselines import logger\r\n    logger.set_level(logger.DISABLED)\r\n\r\n    ENV_NAME = \"Acrobot-v1\"\r\n    env = DummyVecEnv([lambda: Env(gym.make(ENV_NAME))] * 4)\r\n\r\n    network = models.mlp(2, 15)\r\n    learn(network=network, env=env, total_timesteps=100000, nsteps=12)\r\n    rewards = [val for tup in zip(*[e.rewards for e in env.envs]) for val in tup]\r\n    plt.plot(rewards)\r\n    plt.savefig(\"result.png\")\r\n```\r\n\r\nThe reason I added an `Env` class (just a wrapper around OpenAI env) was to be able to accumulate reward so that I could plot it and inspect it. (any advice how to do that without this 'hack' would also be welcome).", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/766", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/766/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/766/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/766/events", "html_url": "https://github.com/openai/baselines/issues/766", "id": 392363529, "node_id": "MDU6SXNzdWUzOTIzNjM1Mjk=", "number": 766, "title": "PPO2 Why combine loss function when parameters not shared between policy and value?", "user": {"login": "rallen10", "id": 7907092, "node_id": "MDQ6VXNlcjc5MDcwOTI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7907092?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rallen10", "html_url": "https://github.com/rallen10", "followers_url": "https://api.github.com/users/rallen10/followers", "following_url": "https://api.github.com/users/rallen10/following{/other_user}", "gists_url": "https://api.github.com/users/rallen10/gists{/gist_id}", "starred_url": "https://api.github.com/users/rallen10/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rallen10/subscriptions", "organizations_url": "https://api.github.com/users/rallen10/orgs", "repos_url": "https://api.github.com/users/rallen10/repos", "events_url": "https://api.github.com/users/rallen10/events{/privacy}", "received_events_url": "https://api.github.com/users/rallen10/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-18T22:31:16Z", "updated_at": "2018-12-20T06:49:25Z", "closed_at": "2018-12-19T22:16:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "In ppo2, the loss function used for training is the combined `loss = policy_loss + value_loss - entropy` (see: https://github.com/openai/baselines/blob/master/baselines/ppo2/model.py#L88). As it is described in Eqn 9 of the original PPO paper, this is the loss function to be used if your model shares parameters between the policy and the value. However, if you set `value_network=\"copy\"`, my understanding is that the parameters are no longer shared between the policy and value network; they just have the same structure but they are two separate networks. Under this condition, shouldn't the training operation be broken up into an policy training operation (i.e. actor training) and a value training operation (i.e. critic training)? As far as I can tell, that is not implemented anywhere in the ppo2 baselines code.\r\n\r\nThis question arose from trying to debug a learning process where my value loss was orders of magnitude larger than my policy loss thus it totally dominates the combined loss function and thus the learning behaviour.  This further raised the question if the value loss is even correctly calculated (see related question https://github.com/openai/baselines/issues/765), but even if it is calculated correctly, it seems that you may want to split the training of the two networks.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/764", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/764/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/764/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/764/events", "html_url": "https://github.com/openai/baselines/issues/764", "id": 391432486, "node_id": "MDU6SXNzdWUzOTE0MzI0ODY=", "number": 764, "title": "DDPG never converge", "user": {"login": "iswaverly", "id": 29541748, "node_id": "MDQ6VXNlcjI5NTQxNzQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/29541748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iswaverly", "html_url": "https://github.com/iswaverly", "followers_url": "https://api.github.com/users/iswaverly/followers", "following_url": "https://api.github.com/users/iswaverly/following{/other_user}", "gists_url": "https://api.github.com/users/iswaverly/gists{/gist_id}", "starred_url": "https://api.github.com/users/iswaverly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iswaverly/subscriptions", "organizations_url": "https://api.github.com/users/iswaverly/orgs", "repos_url": "https://api.github.com/users/iswaverly/repos", "events_url": "https://api.github.com/users/iswaverly/events{/privacy}", "received_events_url": "https://api.github.com/users/iswaverly/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-12-16T03:46:03Z", "updated_at": "2019-03-20T03:44:14Z", "closed_at": "2018-12-17T09:00:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "I trained DDPG with command refered in README, which is \"python -m baselines.run --alg=ddpg --env=HalfCheetah-v2 --num_timesteps=1e6\".\r\nAfter 1000000 steps, the reward is still negative.\r\nI tried other games, such as \"popper\", none of this can I get the correct result.\r\n\r\nI use the master branch with latest code, and my tensorflow-gpu version is 1.8.0.\r\n\r\nHave anyone train DDPG success?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/762", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/762/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/762/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/762/events", "html_url": "https://github.com/openai/baselines/issues/762", "id": 391394380, "node_id": "MDU6SXNzdWUzOTEzOTQzODA=", "number": 762, "title": "eplenmean and eprewmean always nan", "user": {"login": "mitar", "id": 585279, "node_id": "MDQ6VXNlcjU4NTI3OQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/585279?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mitar", "html_url": "https://github.com/mitar", "followers_url": "https://api.github.com/users/mitar/followers", "following_url": "https://api.github.com/users/mitar/following{/other_user}", "gists_url": "https://api.github.com/users/mitar/gists{/gist_id}", "starred_url": "https://api.github.com/users/mitar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mitar/subscriptions", "organizations_url": "https://api.github.com/users/mitar/orgs", "repos_url": "https://api.github.com/users/mitar/repos", "events_url": "https://api.github.com/users/mitar/events{/privacy}", "received_events_url": "https://api.github.com/users/mitar/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-12-15T17:00:43Z", "updated_at": "2018-12-21T19:10:45Z", "closed_at": "2018-12-21T19:06:08Z", "author_association": "NONE", "active_lock_reason": null, "body": "For my own environment, when I run ppo2, I am always getting `nan` for `eplenmean` and `eprewmean`. I see from the code that it uses `'l'` and `'r'` keys from debug info returned from step calls. But what are those values? Where it is documented?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/761", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/761/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/761/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/761/events", "html_url": "https://github.com/openai/baselines/issues/761", "id": 390117967, "node_id": "MDU6SXNzdWUzOTAxMTc5Njc=", "number": 761, "title": "why minus maximum in function entropy in a2c ?", "user": {"login": "chang-guofeng", "id": 3156581, "node_id": "MDQ6VXNlcjMxNTY1ODE=", "avatar_url": "https://avatars2.githubusercontent.com/u/3156581?v=4", "gravatar_id": "", "url": "https://api.github.com/users/chang-guofeng", "html_url": "https://github.com/chang-guofeng", "followers_url": "https://api.github.com/users/chang-guofeng/followers", "following_url": "https://api.github.com/users/chang-guofeng/following{/other_user}", "gists_url": "https://api.github.com/users/chang-guofeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/chang-guofeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/chang-guofeng/subscriptions", "organizations_url": "https://api.github.com/users/chang-guofeng/orgs", "repos_url": "https://api.github.com/users/chang-guofeng/repos", "events_url": "https://api.github.com/users/chang-guofeng/events{/privacy}", "received_events_url": "https://api.github.com/users/chang-guofeng/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-12T08:39:07Z", "updated_at": "2018-12-13T05:36:22Z", "closed_at": "2018-12-13T05:36:22Z", "author_association": "NONE", "active_lock_reason": null, "body": " a_0 = self.logits - tf.reduce_max(self.logits, axis=-1, keepdims=True)\r\nI got confused for a very long time, any information is welcome, thanks a lot!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/759", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/759/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/759/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/759/events", "html_url": "https://github.com/openai/baselines/issues/759", "id": 389442740, "node_id": "MDU6SXNzdWUzODk0NDI3NDA=", "number": 759, "title": "Action space in custom gym env is ignored", "user": {"login": "miguelrass", "id": 11755779, "node_id": "MDQ6VXNlcjExNzU1Nzc5", "avatar_url": "https://avatars2.githubusercontent.com/u/11755779?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miguelrass", "html_url": "https://github.com/miguelrass", "followers_url": "https://api.github.com/users/miguelrass/followers", "following_url": "https://api.github.com/users/miguelrass/following{/other_user}", "gists_url": "https://api.github.com/users/miguelrass/gists{/gist_id}", "starred_url": "https://api.github.com/users/miguelrass/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miguelrass/subscriptions", "organizations_url": "https://api.github.com/users/miguelrass/orgs", "repos_url": "https://api.github.com/users/miguelrass/repos", "events_url": "https://api.github.com/users/miguelrass/events{/privacy}", "received_events_url": "https://api.github.com/users/miguelrass/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824585, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODU=", "url": "https://api.github.com/repos/openai/baselines/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-10T19:05:31Z", "updated_at": "2018-12-20T17:26:28Z", "closed_at": "2018-12-20T17:26:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "I've defined my custom gym env with the following action space:\r\nself.action_space = spaces.Box(low=np.array([-1.0] * (3)), high=np.array([1.0] * (3)), dtype=np.float32)\r\n\r\nThen, when using the PPO1 algorithm, I get actions that look like this:\r\n[-0.57349634 -2.55674    -0.10379485]\r\n[ 0.8132414  -0.9062461   0.03924657]\r\n[-1.4108657  -0.44285738  1.135338  ]\r\n...\r\n\r\nSome of the values are out of the specified range, e.g., -2.55, -1.41, 1.13\r\nIs this considered intended behavior?\r\n\r\nThanks in advance\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/757", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/757/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/757/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/757/events", "html_url": "https://github.com/openai/baselines/issues/757", "id": 388950929, "node_id": "MDU6SXNzdWUzODg5NTA5Mjk=", "number": 757, "title": "Failed testing with \"RuntimeError: Graph is finalized and cannot be modified.\"", "user": {"login": "Krasaa", "id": 25505807, "node_id": "MDQ6VXNlcjI1NTA1ODA3", "avatar_url": "https://avatars2.githubusercontent.com/u/25505807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Krasaa", "html_url": "https://github.com/Krasaa", "followers_url": "https://api.github.com/users/Krasaa/followers", "following_url": "https://api.github.com/users/Krasaa/following{/other_user}", "gists_url": "https://api.github.com/users/Krasaa/gists{/gist_id}", "starred_url": "https://api.github.com/users/Krasaa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Krasaa/subscriptions", "organizations_url": "https://api.github.com/users/Krasaa/orgs", "repos_url": "https://api.github.com/users/Krasaa/repos", "events_url": "https://api.github.com/users/Krasaa/events{/privacy}", "received_events_url": "https://api.github.com/users/Krasaa/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-08T19:18:44Z", "updated_at": "2018-12-09T13:58:53Z", "closed_at": "2018-12-09T12:29:27Z", "author_association": "NONE", "active_lock_reason": null, "body": "I tried to install baselines into my working environment but the testing failed.\r\nWorking environment: Tensorflow  1.12.0, python 3.6, gym 0.10.9\r\n\r\nError information:\r\n    def test_noise_normal():\r\n>       _run('--noise_type=normal_0.1')\r\n\r\nbaselines/ddpg/test_smoke.py:10: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nbaselines/ddpg/test_smoke.py:4: in _run\r\n    M(('--alg=ddpg --env=Pendulum-v0 --num_timesteps=0 ' + argstr).split(' '))\r\nbaselines/run.py:198: in main\r\n    model, env = train(args, extra_args)\r\nbaselines/run.py:81: in train\r\n    **alg_kwargs\r\nbaselines/ddpg/ddpg.py:92: in learn\r\n    reward_scale=reward_scale)\r\nbaselines/ddpg/ddpg_learner.py:72: in __init__\r\n    self.obs0 = tf.placeholder(tf.float32, shape=(None,) + observation_shape, name='obs0')\r\n../../anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1747: in placeholder\r\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\r\n../../anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py:5206: in placeholder\r\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\r\n../../anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:787: in _apply_op_helper\r\n    op_def=op_def)\r\n../../anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:488: in new_func\r\n    return func(*args, **kwargs)\r\n../../anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:3246: in create_op\r\n    self._check_not_finalized()\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <tensorflow.python.framework.ops.Graph object at 0x7f4fa4893dd8>\r\n\r\n    def _check_not_finalized(self):\r\n      \"\"\"Check if the graph is finalized.\r\n    \r\n        Raises:\r\n          RuntimeError: If the graph finalized.\r\n        \"\"\"\r\n      if self._finalized:\r\n       raise RuntimeError(\"Graph is finalized and cannot be modified.\")\r\nE       RuntimeError: Graph is finalized and cannot be modified.\r\n\r\n../../anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:2919: RuntimeError\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/756", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/756/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/756/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/756/events", "html_url": "https://github.com/openai/baselines/issues/756", "id": 388769565, "node_id": "MDU6SXNzdWUzODg3Njk1NjU=", "number": 756, "title": "SubprocVecEnv sometimes hangs if tensorflow is being used", "user": {"login": "christopherhesse", "id": 440336, "node_id": "MDQ6VXNlcjQ0MDMzNg==", "avatar_url": "https://avatars2.githubusercontent.com/u/440336?v=4", "gravatar_id": "", "url": "https://api.github.com/users/christopherhesse", "html_url": "https://github.com/christopherhesse", "followers_url": "https://api.github.com/users/christopherhesse/followers", "following_url": "https://api.github.com/users/christopherhesse/following{/other_user}", "gists_url": "https://api.github.com/users/christopherhesse/gists{/gist_id}", "starred_url": "https://api.github.com/users/christopherhesse/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/christopherhesse/subscriptions", "organizations_url": "https://api.github.com/users/christopherhesse/orgs", "repos_url": "https://api.github.com/users/christopherhesse/repos", "events_url": "https://api.github.com/users/christopherhesse/events{/privacy}", "received_events_url": "https://api.github.com/users/christopherhesse/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-12-07T18:42:33Z", "updated_at": "2019-01-07T21:33:49Z", "closed_at": "2019-01-07T21:33:49Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "This script seems to reproduce the hang pretty reliably on linux:\r\n\r\n```\r\nimport multiprocessing\r\nfrom baselines.common.vec_env.subproc_vec_env import SubprocVecEnv\r\nimport gym\r\nimport tensorflow as tf\r\nimport datetime\r\n\r\n\r\ndef loop():\r\n    print(datetime.datetime.now().isoformat())\r\n    # https://github.com/tensorflow/tensorflow/issues/20600\r\n    graph = tf.Graph()  # not creating this graph avoids the hang\r\n    sess = tf.Session(graph=graph)  \r\n    with sess.graph.as_default():\r\n        some_var = tf.Variable(0, dtype=tf.int64)\r\n        SubprocVecEnv([lambda: gym.make('CartPole-v1') for i in range(1)])  # replacing with DummyVecEnv avoids the hang\r\n\r\n\r\ndef main():\r\n    while True:\r\n        loop()\r\n\r\n\r\nif __name__ == '__main__':\r\n    # this fixes the hang but is slower than the default fork method\r\n    # https://github.com/tensorflow/tensorflow/issues/5448#issuecomment-314953888\r\n    # multiprocessing.set_start_method('spawn')\r\n    main()\r\n```\r\n\r\nIt looks like tensorflow + fork() is not really supported, one possible fix is to use the `spawn` method instead.  There may be other possible fixes though.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/755", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/755/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/755/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/755/events", "html_url": "https://github.com/openai/baselines/issues/755", "id": 388571898, "node_id": "MDU6SXNzdWUzODg1NzE4OTg=", "number": 755, "title": "Intuition behind batch sizes", "user": {"login": "Olimoyo", "id": 14180933, "node_id": "MDQ6VXNlcjE0MTgwOTMz", "avatar_url": "https://avatars2.githubusercontent.com/u/14180933?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Olimoyo", "html_url": "https://github.com/Olimoyo", "followers_url": "https://api.github.com/users/Olimoyo/followers", "following_url": "https://api.github.com/users/Olimoyo/following{/other_user}", "gists_url": "https://api.github.com/users/Olimoyo/gists{/gist_id}", "starred_url": "https://api.github.com/users/Olimoyo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Olimoyo/subscriptions", "organizations_url": "https://api.github.com/users/Olimoyo/orgs", "repos_url": "https://api.github.com/users/Olimoyo/repos", "events_url": "https://api.github.com/users/Olimoyo/events{/privacy}", "received_events_url": "https://api.github.com/users/Olimoyo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824585, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODU=", "url": "https://api.github.com/repos/openai/baselines/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-12-07T09:31:15Z", "updated_at": "2018-12-20T21:17:00Z", "closed_at": "2018-12-20T21:17:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "Does anyone have a good intuition or explanation behind the choice of batch size for different algorithms? \r\n\r\nI noticed that for TRPO/PPO the batch size is usually set as ~2048 by default, but on the other hand for A2C the default batch size tends to be closer to ~80. \r\n\r\nDoes it have to do with discrete control vs continuous control? In this paper (https://arxiv.org/pdf/1708.05144.pdf), they use the following batch sizes:\r\nDiscrete\r\nACKTR: 640\r\nA2C: 80\r\nTRPO: 512\r\n\r\nContinuous\r\nACKTR: 2500\r\nA2C: 2500\r\nTRPO: 25000", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/753", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/753/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/753/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/753/events", "html_url": "https://github.com/openai/baselines/issues/753", "id": 388103371, "node_id": "MDU6SXNzdWUzODgxMDMzNzE=", "number": 753, "title": "run baseline with mpi -np 1, performance decrease dramatically", "user": {"login": "scotthuang1989", "id": 5325686, "node_id": "MDQ6VXNlcjUzMjU2ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/5325686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scotthuang1989", "html_url": "https://github.com/scotthuang1989", "followers_url": "https://api.github.com/users/scotthuang1989/followers", "following_url": "https://api.github.com/users/scotthuang1989/following{/other_user}", "gists_url": "https://api.github.com/users/scotthuang1989/gists{/gist_id}", "starred_url": "https://api.github.com/users/scotthuang1989/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scotthuang1989/subscriptions", "organizations_url": "https://api.github.com/users/scotthuang1989/orgs", "repos_url": "https://api.github.com/users/scotthuang1989/repos", "events_url": "https://api.github.com/users/scotthuang1989/events{/privacy}", "received_events_url": "https://api.github.com/users/scotthuang1989/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "pzhokhov", "id": 25395937, "node_id": "MDQ6VXNlcjI1Mzk1OTM3", "avatar_url": "https://avatars0.githubusercontent.com/u/25395937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pzhokhov", "html_url": "https://github.com/pzhokhov", "followers_url": "https://api.github.com/users/pzhokhov/followers", "following_url": "https://api.github.com/users/pzhokhov/following{/other_user}", "gists_url": "https://api.github.com/users/pzhokhov/gists{/gist_id}", "starred_url": "https://api.github.com/users/pzhokhov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pzhokhov/subscriptions", "organizations_url": "https://api.github.com/users/pzhokhov/orgs", "repos_url": "https://api.github.com/users/pzhokhov/repos", "events_url": "https://api.github.com/users/pzhokhov/events{/privacy}", "received_events_url": "https://api.github.com/users/pzhokhov/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pzhokhov", "id": 25395937, "node_id": "MDQ6VXNlcjI1Mzk1OTM3", "avatar_url": "https://avatars0.githubusercontent.com/u/25395937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pzhokhov", "html_url": "https://github.com/pzhokhov", "followers_url": "https://api.github.com/users/pzhokhov/followers", "following_url": "https://api.github.com/users/pzhokhov/following{/other_user}", "gists_url": "https://api.github.com/users/pzhokhov/gists{/gist_id}", "starred_url": "https://api.github.com/users/pzhokhov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pzhokhov/subscriptions", "organizations_url": "https://api.github.com/users/pzhokhov/orgs", "repos_url": "https://api.github.com/users/pzhokhov/repos", "events_url": "https://api.github.com/users/pzhokhov/events{/privacy}", "received_events_url": "https://api.github.com/users/pzhokhov/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-12-06T08:22:36Z", "updated_at": "2019-03-04T08:03:33Z", "closed_at": "2019-03-04T08:03:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "This is how I measure the time spend on interacting with environment:\r\n\r\nin ppo.py , function: learn\r\n\r\n **data_collecting_time = deque(maxlen=1000)\r\n       t_start = time.time()**\r\n        obs, returns, masks, actions, values, neglogpacs, states, epinfos = runner.run()\r\n        **data_collecting_time.append(time.time() - t_start)**\r\n\r\n**print(\"mean data collecting time: \", sum(data_collecting_time)/len(data_collecting_time))**\r\n\r\n**code marked with bold is my code.**\r\n\r\nif I run with following command:\r\n\r\n`python -m baselines.run_stock  xxxx`\r\n\r\nit will take 10 seconds.\r\n\r\nif I run with this command:\r\n`mpirun -np 1 python -m baselines.run_stock  xxxx`\r\n\r\nit will take 30 seconds.\r\n\r\nI don't understand this. because I think these 2 command should have same effect. Can someone help me?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/748", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/748/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/748/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/748/events", "html_url": "https://github.com/openai/baselines/issues/748", "id": 387099353, "node_id": "MDU6SXNzdWUzODcwOTkzNTM=", "number": 748, "title": "Error using cnn-deepq to train CartPole-v0", "user": {"login": "HaozhengLi", "id": 19581955, "node_id": "MDQ6VXNlcjE5NTgxOTU1", "avatar_url": "https://avatars0.githubusercontent.com/u/19581955?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HaozhengLi", "html_url": "https://github.com/HaozhengLi", "followers_url": "https://api.github.com/users/HaozhengLi/followers", "following_url": "https://api.github.com/users/HaozhengLi/following{/other_user}", "gists_url": "https://api.github.com/users/HaozhengLi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HaozhengLi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HaozhengLi/subscriptions", "organizations_url": "https://api.github.com/users/HaozhengLi/orgs", "repos_url": "https://api.github.com/users/HaozhengLi/repos", "events_url": "https://api.github.com/users/HaozhengLi/events{/privacy}", "received_events_url": "https://api.github.com/users/HaozhengLi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-12-04T03:05:42Z", "updated_at": "2018-12-04T08:22:12Z", "closed_at": "2018-12-04T08:22:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\n\r\nI wrote an DIY < classic_control > gym environment but need the < cnn > to train it, instead of < mlp >.\r\n\r\nBut baselines seems not support < cnn > in < classic_control > gym environment.\r\n\r\nFor example, while using cnn-deepq to train CartPole-v0, error occurs:\r\n \r\n`Traceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35\\lib\\runpy.py\", line 170, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\run.py\", line 265, in <module>\r\n    main()\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\run.py\", line 214, in main\r\n    model, env = train(args, extra_args)\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\run.py\", line 80, in train\r\n    **alg_kwargs\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\deepq\\deepq.py\", line 212, in learn\r\n    param_noise=param_noise\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\deepq\\build_graph.py\", line 376, in build_train\r\n    act_f = build_act(make_obs_ph, q_func, num_actions, scope=scope, reuse=reuse)\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\deepq\\build_graph.py\", line 183, in build_act\r\n    q_values = q_func(observations_ph.get(), num_actions, scope=\"q_func\")\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\deepq\\models.py\", line 101, in q_func_builder\r\n    latent = network(input_placeholder)\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\common\\models.py\", line 65, in network_fn\r\n    return nature_cnn(X, **conv_kwargs)\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\common\\models.py\", line 23, in nature_cnn\r\n    **conv_kwargs))\r\n  File \"E:\\Output\\Python_output\\KOG\\baselines-kog\\baselines\\a2c\\utils.py\", line 49, in conv\r\n    nin = x.get_shape()[channel_ax].value\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 521, in __getitem__\r\n    return self._dims[key]\r\nIndexError: list index out of range`\r\n \r\nI think it's a problem about the shape of input observation, but I have no idea how to change the code.\r\n\r\nCan anyone help? Thanks a lot.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/743", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/743/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/743/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/743/events", "html_url": "https://github.com/openai/baselines/issues/743", "id": 385751324, "node_id": "MDU6SXNzdWUzODU3NTEzMjQ=", "number": 743, "title": "Reward and Length Buffer", "user": {"login": "ecada", "id": 18642218, "node_id": "MDQ6VXNlcjE4NjQyMjE4", "avatar_url": "https://avatars1.githubusercontent.com/u/18642218?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ecada", "html_url": "https://github.com/ecada", "followers_url": "https://api.github.com/users/ecada/followers", "following_url": "https://api.github.com/users/ecada/following{/other_user}", "gists_url": "https://api.github.com/users/ecada/gists{/gist_id}", "starred_url": "https://api.github.com/users/ecada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ecada/subscriptions", "organizations_url": "https://api.github.com/users/ecada/orgs", "repos_url": "https://api.github.com/users/ecada/repos", "events_url": "https://api.github.com/users/ecada/events{/privacy}", "received_events_url": "https://api.github.com/users/ecada/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824585, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODU=", "url": "https://api.github.com/repos/openai/baselines/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-29T14:04:07Z", "updated_at": "2018-12-19T23:16:51Z", "closed_at": "2018-12-19T23:16:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "Regarding the lines in ppo1/pposgd_simple.py:\r\nlenbuffer = deque(maxlen=100) # rolling buffer for episode lengths\r\nrewbuffer = deque(maxlen=100) # rolling buffer for episode rewards\r\n\r\nWhen graphing the learning curves on tensorboard, I guess the episode rewards are calculated for the last 100 timesteps of the 2048 timesteps horizon. Is this a valid evaluation when compared to 2048 timesteps case with plot.py and why is it the default? Thank you so much for this wonderful repository by the way!  \ud83d\ude04 ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/742", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/742/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/742/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/742/events", "html_url": "https://github.com/openai/baselines/issues/742", "id": 385682367, "node_id": "MDU6SXNzdWUzODU2ODIzNjc=", "number": 742, "title": "undefined symbol", "user": {"login": "GbengaOdesanmi", "id": 29349982, "node_id": "MDQ6VXNlcjI5MzQ5OTgy", "avatar_url": "https://avatars0.githubusercontent.com/u/29349982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GbengaOdesanmi", "html_url": "https://github.com/GbengaOdesanmi", "followers_url": "https://api.github.com/users/GbengaOdesanmi/followers", "following_url": "https://api.github.com/users/GbengaOdesanmi/following{/other_user}", "gists_url": "https://api.github.com/users/GbengaOdesanmi/gists{/gist_id}", "starred_url": "https://api.github.com/users/GbengaOdesanmi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GbengaOdesanmi/subscriptions", "organizations_url": "https://api.github.com/users/GbengaOdesanmi/orgs", "repos_url": "https://api.github.com/users/GbengaOdesanmi/repos", "events_url": "https://api.github.com/users/GbengaOdesanmi/events{/privacy}", "received_events_url": "https://api.github.com/users/GbengaOdesanmi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-11-29T11:06:12Z", "updated_at": "2018-12-20T02:11:35Z", "closed_at": "2018-12-20T02:11:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "Please, I am having this error, kindly help me out on how to solve it, I tried this but not repeating itself.\r\nconda install -y --verbose -c conda-forge opencv==3.4.1 tensorflow==1.8.0\r\n\r\n(tensorflow) gbenga@gbenga-Lenovo:~/baselines$ python -m baselines.her.experiment.train --num_cpu 1\r\nLogging to /tmp/openai-2018-11-29-18-55-47-521866\r\nTraceback (most recent call last):\r\n  File \"/home/gbenga/Downloads/abiona1008/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/gbenga/Downloads/abiona1008/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/gbenga/baselines/baselines/her/experiment/train.py\", line 12, in <module>\r\n    import baselines.her.experiment.config as config\r\n  File \"/home/gbenga/baselines/baselines/her/experiment/config.py\", line 5, in <module>\r\n    from baselines.her.ddpg import DDPG\r\n  File \"/home/gbenga/baselines/baselines/her/ddpg.py\", line 4, in <module>\r\n    import tensorflow as tf\r\n  File \"/home/gbenga/Downloads/abiona1008/envs/tensorflow/lib/python3.6/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/home/gbenga/Downloads/abiona1008/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 59, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/home/gbenga/Downloads/abiona1008/envs/tensorflow/lib/python3.6/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"/home/gbenga/Downloads/abiona1008/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/descriptor.py\", line 47, in <module>\r\n    from google.protobuf.pyext import _message\r\nImportError: /home/gbenga/Downloads/abiona1008/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/pyext/_message.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZNK6google8protobuf10TextFormat17FieldValuePrinter9PrintBoolEb\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/741", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/741/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/741/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/741/events", "html_url": "https://github.com/openai/baselines/issues/741", "id": 385656094, "node_id": "MDU6SXNzdWUzODU2NTYwOTQ=", "number": 741, "title": "confirm if my understanding of mpi usage is right", "user": {"login": "scotthuang1989", "id": 5325686, "node_id": "MDQ6VXNlcjUzMjU2ODY=", "avatar_url": "https://avatars3.githubusercontent.com/u/5325686?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scotthuang1989", "html_url": "https://github.com/scotthuang1989", "followers_url": "https://api.github.com/users/scotthuang1989/followers", "following_url": "https://api.github.com/users/scotthuang1989/following{/other_user}", "gists_url": "https://api.github.com/users/scotthuang1989/gists{/gist_id}", "starred_url": "https://api.github.com/users/scotthuang1989/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scotthuang1989/subscriptions", "organizations_url": "https://api.github.com/users/scotthuang1989/orgs", "repos_url": "https://api.github.com/users/scotthuang1989/repos", "events_url": "https://api.github.com/users/scotthuang1989/events{/privacy}", "received_events_url": "https://api.github.com/users/scotthuang1989/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824585, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODU=", "url": "https://api.github.com/repos/openai/baselines/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-29T10:01:50Z", "updated_at": "2018-12-13T01:15:35Z", "closed_at": "2018-12-13T01:15:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have read the code and did some experiment about running basline with openmpi. I want to confirm if I am right before I run large scale experiments.\r\n\r\nThere are 2 parallel machenism:\r\n\r\n**1. environment parallel:**  \r\n\r\n   this is specified by the` --num_env` , it is done by create multiple process and run 1 environment in each process.\r\n\r\n**2. mpi parallel:** \r\n\r\nI can run baseline with following command:\r\n\r\n`mpirun -np 2 python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4  --num_env  3`\r\n\r\nthis will create 2 mpi processes and\r\neach mpi process will crate 4 child processes(1 main process  and 3 subprocess for environment) independently. \r\n\r\nthis command will crate  8 processes in total. \r\n\r\nduring training \r\neach mpi process will calculate gradient independently and \r\n`MpiAdamOptimizer `will  calculate average gradient from these 2 mpi process and then apply to variables in all 2 mpi process.\r\n\r\nplease correct me if I am wrong. it will save tons of my time. thanks.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/739", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/739/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/739/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/739/events", "html_url": "https://github.com/openai/baselines/issues/739", "id": 385554150, "node_id": "MDU6SXNzdWUzODU1NTQxNTA=", "number": 739, "title": "Unable to debug the PPO2 algorithm with VSCode", "user": {"login": "davidhopper2003", "id": 31435476, "node_id": "MDQ6VXNlcjMxNDM1NDc2", "avatar_url": "https://avatars0.githubusercontent.com/u/31435476?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidhopper2003", "html_url": "https://github.com/davidhopper2003", "followers_url": "https://api.github.com/users/davidhopper2003/followers", "following_url": "https://api.github.com/users/davidhopper2003/following{/other_user}", "gists_url": "https://api.github.com/users/davidhopper2003/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidhopper2003/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidhopper2003/subscriptions", "organizations_url": "https://api.github.com/users/davidhopper2003/orgs", "repos_url": "https://api.github.com/users/davidhopper2003/repos", "events_url": "https://api.github.com/users/davidhopper2003/events{/privacy}", "received_events_url": "https://api.github.com/users/davidhopper2003/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-29T03:28:38Z", "updated_at": "2018-12-13T00:57:26Z", "closed_at": "2018-12-13T00:57:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "I used VSCode to debug the PPO2 algorithm. When debugging to line 58 of the file `baselines/common/vec_env/subproc_vec_env.py`:\r\n\r\n```python\r\nobservation_space, action_space = self.remotes[0].recv()\r\n```\r\n\r\nthe program has no response and the debugging process cannot continue (As shown below). \r\n![ppo2_debug_1](https://user-images.githubusercontent.com/31435476/49197695-c8a4ff80-f3ca-11e8-87f0-468bb47250c2.png)\r\n![ppo2_debug_2](https://user-images.githubusercontent.com/31435476/49197696-c8a4ff80-f3ca-11e8-84a0-6297ab5f8868.png)\r\n![ppo2_debug_3](https://user-images.githubusercontent.com/31435476/49197697-c8a4ff80-f3ca-11e8-989e-2ecbba52c6b1.png)\r\n\r\nMy configuration file `.vscode/launch.json` is shown as follows:\r\n\r\n```\r\n{\r\n\r\n    // Use IntelliSense to learn about possible attributes.\r\n\r\n    // Hover to view descriptions of existing attributes.\r\n\r\n    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387\r\n\r\n    \"version\": \"0.2.0\",\r\n\r\n    \"configurations\": [\r\n\r\n        {\r\n\r\n            \"name\": \"Python: Module\",\r\n\r\n            \"type\": \"python\",\r\n\r\n            \"request\": \"launch\",\r\n\r\n            \"module\": \"baselines.run\",\r\n\r\n            \"console\": \"integratedTerminal\",\r\n\r\n            \"args\": [\r\n\r\n                \"--alg\",\r\n\r\n                \"ppo2\",\r\n\r\n                \"--env\",\r\n\r\n                \"PongNoFrameskip-v4\",\r\n\r\n                \"--num_timesteps\",\r\n\r\n                \"2e7\",\r\n\r\n                \"--save_path\",\r\n\r\n                \"~/models/pong_20M_ppo2\"\r\n\r\n            ],\r\n\r\n        },\r\n\r\n        {\r\n\r\n            \"name\": \"Python: Current File (Integrated Terminal)\",\r\n\r\n            \"type\": \"python\",\r\n\r\n            \"request\": \"launch\",\r\n\r\n            \"program\": \"${workspaceFolder}/baselines/run.py\",\r\n\r\n            \"console\": \"integratedTerminal\", \r\n\r\n            \"args\": [\r\n\r\n                \"--alg\",\r\n\r\n                \"ppo2\",\r\n\r\n                \"--env\",\r\n\r\n                \"PongNoFrameskip-v4\",\r\n\r\n                \"--num_timesteps\",\r\n\r\n                \"2e7\",\r\n\r\n                \"--save_path\",\r\n\r\n                \"~/models/pong_20M_ppo2\"\r\n\r\n            ],\r\n\r\n        }\r\n\r\n    ]\r\n\r\n}\r\n```\r\n\r\nWhen I used the command line \r\n\r\n`python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=2e7 --save_path=~/models/pong_20M_ppo2` \r\n\r\nto run the program in a terminal, there is no problem. \r\n\r\nAny helpful suggestions will be highly appreciated. Thank you.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/738", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/738/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/738/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/738/events", "html_url": "https://github.com/openai/baselines/issues/738", "id": 385383540, "node_id": "MDU6SXNzdWUzODUzODM1NDA=", "number": 738, "title": "`FetchPickAndPlace-v1`: AssertionError: Can only deal with Discrete and Box observation spaces for now", "user": {"login": "gtatiya", "id": 22827159, "node_id": "MDQ6VXNlcjIyODI3MTU5", "avatar_url": "https://avatars3.githubusercontent.com/u/22827159?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gtatiya", "html_url": "https://github.com/gtatiya", "followers_url": "https://api.github.com/users/gtatiya/followers", "following_url": "https://api.github.com/users/gtatiya/following{/other_user}", "gists_url": "https://api.github.com/users/gtatiya/gists{/gist_id}", "starred_url": "https://api.github.com/users/gtatiya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gtatiya/subscriptions", "organizations_url": "https://api.github.com/users/gtatiya/orgs", "repos_url": "https://api.github.com/users/gtatiya/repos", "events_url": "https://api.github.com/users/gtatiya/events{/privacy}", "received_events_url": "https://api.github.com/users/gtatiya/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-28T17:40:57Z", "updated_at": "2018-12-19T22:44:51Z", "closed_at": "2018-12-19T22:44:50Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am trying to learn how to run the baseline for the Fetch robot environment. But, when I run the code: \r\n`python -m baselines.run --alg=ppo2 --env=FetchPickAndPlace-v1 --num_timesteps=30000 --nsteps=128`\r\n\r\nI got following error:\r\n```\r\n/home/gyan/Downloads/gym-master/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\r\n  result = entry_point.load(False)\r\nTraining ppo2 on robotics:FetchPickAndPlace-v1 with arguments \r\n{'nsteps': 128, 'network': 'mlp'}\r\nTraceback (most recent call last):\r\n  File \"/home/gyan/anaconda2/envs/py3_6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/gyan/anaconda2/envs/py3_6/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/gyan/Downloads/baselines-master/baselines/run.py\", line 226, in <module>\r\n    main(sys.argv)\r\n  File \"/home/gyan/Downloads/baselines-master/baselines/run.py\", line 198, in main\r\n    model, env = train(args, extra_args)\r\n  File \"/home/gyan/Downloads/baselines-master/baselines/run.py\", line 81, in train\r\n    **alg_kwargs\r\n  File \"/home/gyan/Downloads/baselines-master/baselines/ppo2/ppo2.py\", line 108, in learn\r\n    max_grad_norm=max_grad_norm)\r\n  File \"/home/gyan/Downloads/baselines-master/baselines/ppo2/model.py\", line 34, in __init__\r\n    act_model = policy(nbatch_act, 1, sess)\r\n  File \"/home/gyan/Downloads/baselines-master/baselines/common/policies.py\", line 129, in policy_fn\r\n    X = observ_placeholder if observ_placeholder is not None else observation_placeholder(ob_space, batch_size=nbatch)\r\n  File \"/home/gyan/Downloads/baselines-master/baselines/common/input.py\", line 25, in observation_placeholder\r\n    'Can only deal with Discrete and Box observation spaces for now'\r\nAssertionError: Can only deal with Discrete and Box observation spaces for now\r\n\r\n```\r\n\r\nOS: Ubuntu 16.04\r\nPython Python 3.6.7\r\n\r\nPlease Help !!!\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/730", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/730/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/730/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/730/events", "html_url": "https://github.com/openai/baselines/issues/730", "id": 384172621, "node_id": "MDU6SXNzdWUzODQxNzI2MjE=", "number": 730, "title": "Sticky Frame Skip ", "user": {"login": "wilkinsmicawber", "id": 44240798, "node_id": "MDQ6VXNlcjQ0MjQwNzk4", "avatar_url": "https://avatars3.githubusercontent.com/u/44240798?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wilkinsmicawber", "html_url": "https://github.com/wilkinsmicawber", "followers_url": "https://api.github.com/users/wilkinsmicawber/followers", "following_url": "https://api.github.com/users/wilkinsmicawber/following{/other_user}", "gists_url": "https://api.github.com/users/wilkinsmicawber/gists{/gist_id}", "starred_url": "https://api.github.com/users/wilkinsmicawber/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wilkinsmicawber/subscriptions", "organizations_url": "https://api.github.com/users/wilkinsmicawber/orgs", "repos_url": "https://api.github.com/users/wilkinsmicawber/repos", "events_url": "https://api.github.com/users/wilkinsmicawber/events{/privacy}", "received_events_url": "https://api.github.com/users/wilkinsmicawber/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-26T04:45:08Z", "updated_at": "2018-11-26T04:51:56Z", "closed_at": "2018-11-26T04:51:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "The Gotta Learn Fast Article implemented sticky frameskip. It appears that it would have also been integrated into baselines. I can't seem to find it in the code for the rainbow implementation. Is sticky frame skip implemented in the base code?\r\n\r\nThe article also used regular frameskip, but I can't find it, either. Is frameskip in the baseline implementations?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/729", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/729/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/729/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/729/events", "html_url": "https://github.com/openai/baselines/issues/729", "id": 383472244, "node_id": "MDU6SXNzdWUzODM0NzIyNDQ=", "number": 729, "title": "Is it possible to run the baseline algorithm on self-made gym environments?", "user": {"login": "azinoma", "id": 23343830, "node_id": "MDQ6VXNlcjIzMzQzODMw", "avatar_url": "https://avatars3.githubusercontent.com/u/23343830?v=4", "gravatar_id": "", "url": "https://api.github.com/users/azinoma", "html_url": "https://github.com/azinoma", "followers_url": "https://api.github.com/users/azinoma/followers", "following_url": "https://api.github.com/users/azinoma/following{/other_user}", "gists_url": "https://api.github.com/users/azinoma/gists{/gist_id}", "starred_url": "https://api.github.com/users/azinoma/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/azinoma/subscriptions", "organizations_url": "https://api.github.com/users/azinoma/orgs", "repos_url": "https://api.github.com/users/azinoma/repos", "events_url": "https://api.github.com/users/azinoma/events{/privacy}", "received_events_url": "https://api.github.com/users/azinoma/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-22T10:30:36Z", "updated_at": "2018-11-22T14:01:45Z", "closed_at": "2018-11-22T14:01:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "I have a very basic question:\r\nwhat's the best way if I want to run the algorithms implemented in baselines on some environment I made myself?\r\nBest greetings,\r\nMarlon", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/727", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/727/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/727/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/727/events", "html_url": "https://github.com/openai/baselines/issues/727", "id": 383225744, "node_id": "MDU6SXNzdWUzODMyMjU3NDQ=", "number": 727, "title": "MPI with PPO2 broken", "user": {"login": "brendenpetersen", "id": 15270620, "node_id": "MDQ6VXNlcjE1MjcwNjIw", "avatar_url": "https://avatars0.githubusercontent.com/u/15270620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendenpetersen", "html_url": "https://github.com/brendenpetersen", "followers_url": "https://api.github.com/users/brendenpetersen/followers", "following_url": "https://api.github.com/users/brendenpetersen/following{/other_user}", "gists_url": "https://api.github.com/users/brendenpetersen/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendenpetersen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendenpetersen/subscriptions", "organizations_url": "https://api.github.com/users/brendenpetersen/orgs", "repos_url": "https://api.github.com/users/brendenpetersen/repos", "events_url": "https://api.github.com/users/brendenpetersen/events{/privacy}", "received_events_url": "https://api.github.com/users/brendenpetersen/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-21T17:33:23Z", "updated_at": "2018-11-27T01:56:57Z", "closed_at": "2018-11-27T01:56:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "A recent commit seems to have broken MPI for PPO2. Minimal example with fresh clone:\r\n\r\n```\r\n$ python baselines/run.py --env=CartPole-v1 --alg=ppo2 # Works\r\n$ mpirun -n 2 python baselines/run.py --env=CartPole-v1 --alg=ppo2 # Hangs on sync_from_root\r\n```\r\n\r\nThe cause is that `sync_from_root` (which is only called by rank > 0) is waiting for a Bcast of `global_variables`, which doesn't exist in rank 0.\r\n\r\nBug (ppo2/model: L125):\r\n\r\n```\r\nif MPI is None or MPI.COMM_WORLD.Get_rank() == 0:\r\n    initialize()\r\nelse:\r\n    global_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"\")\r\n    sync_from_root(sess, global_variables) #pylint: disable=E1101\r\n```\r\n\r\nFix:\r\n\r\n```\r\nif MPI is None or MPI.COMM_WORLD.Get_rank() == 0:\r\n    initialize()\r\nglobal_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"\")\r\nif MPI is not None:            \r\n    sync_from_root(sess, global_variables) #pylint: disable=E1101\r\n```\r\n\r\nI will submit a PR to fix this issue.\r\n\r\n(Future question: Should I submit both issue+PR when I both identify+fix a bug, or just submit a PR?)", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/726", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/726/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/726/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/726/events", "html_url": "https://github.com/openai/baselines/issues/726", "id": 383159700, "node_id": "MDU6SXNzdWUzODMxNTk3MDA=", "number": 726, "title": "best hardware combination for deep-RL", "user": {"login": "akhilsanand", "id": 38490368, "node_id": "MDQ6VXNlcjM4NDkwMzY4", "avatar_url": "https://avatars1.githubusercontent.com/u/38490368?v=4", "gravatar_id": "", "url": "https://api.github.com/users/akhilsanand", "html_url": "https://github.com/akhilsanand", "followers_url": "https://api.github.com/users/akhilsanand/followers", "following_url": "https://api.github.com/users/akhilsanand/following{/other_user}", "gists_url": "https://api.github.com/users/akhilsanand/gists{/gist_id}", "starred_url": "https://api.github.com/users/akhilsanand/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/akhilsanand/subscriptions", "organizations_url": "https://api.github.com/users/akhilsanand/orgs", "repos_url": "https://api.github.com/users/akhilsanand/repos", "events_url": "https://api.github.com/users/akhilsanand/events{/privacy}", "received_events_url": "https://api.github.com/users/akhilsanand/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824585, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODU=", "url": "https://api.github.com/repos/openai/baselines/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-21T15:05:08Z", "updated_at": "2018-11-27T00:57:24Z", "closed_at": "2018-11-27T00:57:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI am looking for the best possible hardware combination for performing deep reinforcement learning on highly complex MuJoCo environments. Please suggest the best CPU-GPU combination possible.\r\n\r\nThanks,\r\nAkhil ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/721", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/721/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/721/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/721/events", "html_url": "https://github.com/openai/baselines/issues/721", "id": 381910472, "node_id": "MDU6SXNzdWUzODE5MTA0NzI=", "number": 721, "title": "DDPG popart bug fixed, code needs to be modified", "user": {"login": "ZheYang-sjtu", "id": 22572646, "node_id": "MDQ6VXNlcjIyNTcyNjQ2", "avatar_url": "https://avatars2.githubusercontent.com/u/22572646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZheYang-sjtu", "html_url": "https://github.com/ZheYang-sjtu", "followers_url": "https://api.github.com/users/ZheYang-sjtu/followers", "following_url": "https://api.github.com/users/ZheYang-sjtu/following{/other_user}", "gists_url": "https://api.github.com/users/ZheYang-sjtu/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZheYang-sjtu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZheYang-sjtu/subscriptions", "organizations_url": "https://api.github.com/users/ZheYang-sjtu/orgs", "repos_url": "https://api.github.com/users/ZheYang-sjtu/repos", "events_url": "https://api.github.com/users/ZheYang-sjtu/events{/privacy}", "received_events_url": "https://api.github.com/users/ZheYang-sjtu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-11-17T23:13:09Z", "updated_at": "2018-11-27T00:27:33Z", "closed_at": "2018-11-27T00:27:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi guys. I've been using OpenAI's implementation of DDPG and PPO for a couple of months. It's a great tool.\r\n\r\nI recently read Deepmind's paper about Popart and I think that their method can improve my system performance. I tried to use the popart module within DDPG but it doesn't work. It seems popart module has not been fully implemented.\r\n\r\nI would like to ask if it is on your schedule? If you guys already have a version of popart, could you please send me the code so that I could try it on my system?\r\n\r\nThank you so much!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/719", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/719/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/719/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/719/events", "html_url": "https://github.com/openai/baselines/issues/719", "id": 381610394, "node_id": "MDU6SXNzdWUzODE2MTAzOTQ=", "number": 719, "title": "ModuleNotFoundError when running PPO1", "user": {"login": "zhangchuheng123", "id": 9392899, "node_id": "MDQ6VXNlcjkzOTI4OTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/9392899?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangchuheng123", "html_url": "https://github.com/zhangchuheng123", "followers_url": "https://api.github.com/users/zhangchuheng123/followers", "following_url": "https://api.github.com/users/zhangchuheng123/following{/other_user}", "gists_url": "https://api.github.com/users/zhangchuheng123/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangchuheng123/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangchuheng123/subscriptions", "organizations_url": "https://api.github.com/users/zhangchuheng123/orgs", "repos_url": "https://api.github.com/users/zhangchuheng123/repos", "events_url": "https://api.github.com/users/zhangchuheng123/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangchuheng123/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-16T13:58:40Z", "updated_at": "2018-11-16T14:07:34Z", "closed_at": "2018-11-16T14:07:33Z", "author_association": "NONE", "active_lock_reason": null, "body": "Problem:\r\n\r\nI followed the instructions to install baselines from github repo, and simply replaced ppo2 by ppo1. \r\n\r\n```\r\npython -m baselines.run --alg=ppo1 --env=Hopper-v2 --network=mlp --num_timesteps=2e7\r\n```\r\n\r\nI got following error.\r\n\r\n```\r\n$ python -m baselines.run --alg=ppo1 --env=Hopper-v2 --network=mlp --num_timesteps=2e7\r\n\r\n/home1/zhangchuheng/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nLogging to /tmp/openai-2018-11-16-21-38-25-152557\r\nLogging to /tmp/openai-2018-11-16-21-38-25-254664\r\nenv_type: mujoco\r\nTraceback (most recent call last):\r\n  File \"/home1/zhangchuheng/projects/baseline/baselines/baselines/run.py\", line 146, in get_alg_module\r\n    alg_module = import_module('.'.join(['baselines', alg, submodule]))\r\n  File \"/home1/zhangchuheng/miniconda3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\nModuleNotFoundError: No module named 'baselines.ppo1.ppo1'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home1/zhangchuheng/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home1/zhangchuheng/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home1/zhangchuheng/projects/baseline/baselines/baselines/run.py\", line 224, in <module>\r\n    main()\r\n  File \"/home1/zhangchuheng/projects/baseline/baselines/baselines/run.py\", line 198, in main\r\n    model, env = train(args, extra_args)\r\n  File \"/home1/zhangchuheng/projects/baseline/baselines/baselines/run.py\", line 61, in train\r\n    learn = get_learn_function(args.alg)\r\n  File \"/home1/zhangchuheng/projects/baseline/baselines/baselines/run.py\", line 155, in get_learn_function\r\n    return get_alg_module(alg).learn\r\n  File \"/home1/zhangchuheng/projects/baseline/baselines/baselines/run.py\", line 149, in get_alg_module\r\n    alg_module = import_module('.'.join(['rl_' + 'algs', alg, submodule]))\r\n  File \"/home1/zhangchuheng/miniconda3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\nModuleNotFoundError: No module named 'rl_algs'\r\n```\r\n\r\nI found that it looks for the submodule ``baselines.ppo1.ppo1`` in ``run.py``. However, there is not a ``ppo1.py`` under the path like other algorithms do.\r\n\r\n```\r\ndef get_alg_module(alg, submodule=None):\r\n    submodule = submodule or alg\r\n    try:\r\n        # first try to import the alg module from baselines\r\n        alg_module = import_module('.'.join(['baselines', alg, submodule]))\r\n    except ImportError:\r\n        # then from rl_algs\r\n        alg_module = import_module('.'.join(['rl_' + 'algs', alg, submodule]))\r\n\r\n    return alg_module\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/718", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/718/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/718/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/718/events", "html_url": "https://github.com/openai/baselines/issues/718", "id": 381606133, "node_id": "MDU6SXNzdWUzODE2MDYxMzM=", "number": 718, "title": "[Question] Default hyperparameter choice for Prioritized Experience Replay", "user": {"login": "cli0", "id": 25091717, "node_id": "MDQ6VXNlcjI1MDkxNzE3", "avatar_url": "https://avatars3.githubusercontent.com/u/25091717?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cli0", "html_url": "https://github.com/cli0", "followers_url": "https://api.github.com/users/cli0/followers", "following_url": "https://api.github.com/users/cli0/following{/other_user}", "gists_url": "https://api.github.com/users/cli0/gists{/gist_id}", "starred_url": "https://api.github.com/users/cli0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cli0/subscriptions", "organizations_url": "https://api.github.com/users/cli0/orgs", "repos_url": "https://api.github.com/users/cli0/repos", "events_url": "https://api.github.com/users/cli0/events{/privacy}", "received_events_url": "https://api.github.com/users/cli0/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824585, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODU=", "url": "https://api.github.com/repos/openai/baselines/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2018-11-16T13:46:46Z", "updated_at": "2018-11-20T16:12:01Z", "closed_at": "2018-11-19T18:42:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "Your PER implementation is rank-based and the default hyperparameter values (alpha=0.6, beta=0.4) that you have written down are actually the \"ideal\" combination for proportional PER and not rank-based. At least according to the original paper for PER https://arxiv.org/pdf/1511.05952.pdf , if I'm not mistaken. Is this an oversight or is your PER proportional somehow?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/717", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/717/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/717/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/717/events", "html_url": "https://github.com/openai/baselines/issues/717", "id": 381583621, "node_id": "MDU6SXNzdWUzODE1ODM2MjE=", "number": 717, "title": "DDPG cannot work on the robotics environment.", "user": {"login": "WuXinyang2012", "id": 33317242, "node_id": "MDQ6VXNlcjMzMzE3MjQy", "avatar_url": "https://avatars3.githubusercontent.com/u/33317242?v=4", "gravatar_id": "", "url": "https://api.github.com/users/WuXinyang2012", "html_url": "https://github.com/WuXinyang2012", "followers_url": "https://api.github.com/users/WuXinyang2012/followers", "following_url": "https://api.github.com/users/WuXinyang2012/following{/other_user}", "gists_url": "https://api.github.com/users/WuXinyang2012/gists{/gist_id}", "starred_url": "https://api.github.com/users/WuXinyang2012/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/WuXinyang2012/subscriptions", "organizations_url": "https://api.github.com/users/WuXinyang2012/orgs", "repos_url": "https://api.github.com/users/WuXinyang2012/repos", "events_url": "https://api.github.com/users/WuXinyang2012/events{/privacy}", "received_events_url": "https://api.github.com/users/WuXinyang2012/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "pzhokhov", "id": 25395937, "node_id": "MDQ6VXNlcjI1Mzk1OTM3", "avatar_url": "https://avatars0.githubusercontent.com/u/25395937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pzhokhov", "html_url": "https://github.com/pzhokhov", "followers_url": "https://api.github.com/users/pzhokhov/followers", "following_url": "https://api.github.com/users/pzhokhov/following{/other_user}", "gists_url": "https://api.github.com/users/pzhokhov/gists{/gist_id}", "starred_url": "https://api.github.com/users/pzhokhov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pzhokhov/subscriptions", "organizations_url": "https://api.github.com/users/pzhokhov/orgs", "repos_url": "https://api.github.com/users/pzhokhov/repos", "events_url": "https://api.github.com/users/pzhokhov/events{/privacy}", "received_events_url": "https://api.github.com/users/pzhokhov/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pzhokhov", "id": 25395937, "node_id": "MDQ6VXNlcjI1Mzk1OTM3", "avatar_url": "https://avatars0.githubusercontent.com/u/25395937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pzhokhov", "html_url": "https://github.com/pzhokhov", "followers_url": "https://api.github.com/users/pzhokhov/followers", "following_url": "https://api.github.com/users/pzhokhov/following{/other_user}", "gists_url": "https://api.github.com/users/pzhokhov/gists{/gist_id}", "starred_url": "https://api.github.com/users/pzhokhov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pzhokhov/subscriptions", "organizations_url": "https://api.github.com/users/pzhokhov/orgs", "repos_url": "https://api.github.com/users/pzhokhov/repos", "events_url": "https://api.github.com/users/pzhokhov/events{/privacy}", "received_events_url": "https://api.github.com/users/pzhokhov/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-11-16T12:41:04Z", "updated_at": "2019-05-14T20:37:44Z", "closed_at": "2018-12-20T17:01:21Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi, I am doing a project on the robotics environment, which is in continuous space, so I am trying to use DDPG in the FetchReach-v1 environment:\r\n\r\n```bash\r\npython -m baselines.run --alg=ddpg --env=FetchReach-v1 --num_timesteps=1e6\r\n```\r\nit tells me:\r\n```bash\r\nTypeError: can only concatenate tuple (not \"NoneType\") to tuple\r\n```\r\n\r\nIt seems that this problem is because the robotics environments have a dictionary-based observation space.\r\n\r\nIt would be much better if someone can fix this bug and make the baselines.run a really general method for all the gym environments.\r\n\r\nThanks in advance!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/714", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/714/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/714/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/714/events", "html_url": "https://github.com/openai/baselines/issues/714", "id": 381025024, "node_id": "MDU6SXNzdWUzODEwMjUwMjQ=", "number": 714, "title": "I truly do not know how to plot my work with HER", "user": {"login": "nohboogy", "id": 45060180, "node_id": "MDQ6VXNlcjQ1MDYwMTgw", "avatar_url": "https://avatars2.githubusercontent.com/u/45060180?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nohboogy", "html_url": "https://github.com/nohboogy", "followers_url": "https://api.github.com/users/nohboogy/followers", "following_url": "https://api.github.com/users/nohboogy/following{/other_user}", "gists_url": "https://api.github.com/users/nohboogy/gists{/gist_id}", "starred_url": "https://api.github.com/users/nohboogy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nohboogy/subscriptions", "organizations_url": "https://api.github.com/users/nohboogy/orgs", "repos_url": "https://api.github.com/users/nohboogy/repos", "events_url": "https://api.github.com/users/nohboogy/events{/privacy}", "received_events_url": "https://api.github.com/users/nohboogy/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2018-11-15T06:56:25Z", "updated_at": "2018-11-17T11:25:04Z", "closed_at": "2018-11-17T09:14:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "I'm trying to use her algorithm with train.py and I just found that only params.json and ~pkl files are saved in directory.\r\n\r\n\r\nI tried to use logger.py and result_plotter.py but couldn't save any .csv file. \r\n\r\nIs there any way to save my works and make a plot?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/openai/baselines/issues/713", "repository_url": "https://api.github.com/repos/openai/baselines", "labels_url": "https://api.github.com/repos/openai/baselines/issues/713/labels{/name}", "comments_url": "https://api.github.com/repos/openai/baselines/issues/713/comments", "events_url": "https://api.github.com/repos/openai/baselines/issues/713/events", "html_url": "https://github.com/openai/baselines/issues/713", "id": 380965158, "node_id": "MDU6SXNzdWUzODA5NjUxNTg=", "number": 713, "title": "PPO on Atari Specifics", "user": {"login": "Ashboy64", "id": 22405246, "node_id": "MDQ6VXNlcjIyNDA1MjQ2", "avatar_url": "https://avatars3.githubusercontent.com/u/22405246?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ashboy64", "html_url": "https://github.com/Ashboy64", "followers_url": "https://api.github.com/users/Ashboy64/followers", "following_url": "https://api.github.com/users/Ashboy64/following{/other_user}", "gists_url": "https://api.github.com/users/Ashboy64/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ashboy64/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ashboy64/subscriptions", "organizations_url": "https://api.github.com/users/Ashboy64/orgs", "repos_url": "https://api.github.com/users/Ashboy64/repos", "events_url": "https://api.github.com/users/Ashboy64/events{/privacy}", "received_events_url": "https://api.github.com/users/Ashboy64/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 611824585, "node_id": "MDU6TGFiZWw2MTE4MjQ1ODU=", "url": "https://api.github.com/repos/openai/baselines/labels/question", "name": "question", "color": "cc317c", "default": true, "description": null}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2018-11-15T01:53:10Z", "updated_at": "2018-11-19T21:47:39Z", "closed_at": "2018-11-19T21:44:40Z", "author_association": "NONE", "active_lock_reason": null, "body": "Thanks for the great resource. I had a question regarding the implementation of PPO for Atari environments. In order for the model to learn the optimal policy, it seems to me that it must be able to detect motion in the game. Thus, feeding one frame to the model each time when an action needs to be taken is inadequate, a collection of frames or a difference frame will need to be fed in to allow the algorithm to 'see' the motion that is occurring. Is this being done in this implementation? Where can I see the specifics of this process?\r\n\r\nThanks in advance.", "performed_via_github_app": null, "score": 1.0}]}