{"total_count": 408, "incomplete_results": false, "items": [{"url": "https://api.github.com/repos/tensorflow/datasets/issues/2316", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2316/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2316/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2316/events", "html_url": "https://github.com/tensorflow/datasets/issues/2316", "id": 681063226, "node_id": "MDU6SXNzdWU2ODEwNjMyMjY=", "number": 2316, "title": "Turn off intermediate pre-fetching", "user": {"login": "swghosh", "id": 10649800, "node_id": "MDQ6VXNlcjEwNjQ5ODAw", "avatar_url": "https://avatars0.githubusercontent.com/u/10649800?v=4", "gravatar_id": "", "url": "https://api.github.com/users/swghosh", "html_url": "https://github.com/swghosh", "followers_url": "https://api.github.com/users/swghosh/followers", "following_url": "https://api.github.com/users/swghosh/following{/other_user}", "gists_url": "https://api.github.com/users/swghosh/gists{/gist_id}", "starred_url": "https://api.github.com/users/swghosh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/swghosh/subscriptions", "organizations_url": "https://api.github.com/users/swghosh/orgs", "repos_url": "https://api.github.com/users/swghosh/repos", "events_url": "https://api.github.com/users/swghosh/events{/privacy}", "received_events_url": "https://api.github.com/users/swghosh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}, {"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-08-18T13:55:59Z", "updated_at": "2020-08-22T08:35:44Z", "closed_at": "2020-08-22T08:35:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "https://github.com/tensorflow/datasets/blob/bdf30a10adbedac843374052d81e9bae607fd9b3/tensorflow_datasets/core/dataset_builder.py#L572\r\n\r\nIs it possible to turn off prefetching while using `tfds.load(ds_name)`?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2300", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2300/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2300/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2300/events", "html_url": "https://github.com/tensorflow/datasets/issues/2300", "id": 678393233, "node_id": "MDU6SXNzdWU2NzgzOTMyMzM=", "number": 2300, "title": "Functionality of dataset.repeat(-1) in tensorflow 1", "user": {"login": "engrmz", "id": 28756526, "node_id": "MDQ6VXNlcjI4NzU2NTI2", "avatar_url": "https://avatars3.githubusercontent.com/u/28756526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/engrmz", "html_url": "https://github.com/engrmz", "followers_url": "https://api.github.com/users/engrmz/followers", "following_url": "https://api.github.com/users/engrmz/following{/other_user}", "gists_url": "https://api.github.com/users/engrmz/gists{/gist_id}", "starred_url": "https://api.github.com/users/engrmz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/engrmz/subscriptions", "organizations_url": "https://api.github.com/users/engrmz/orgs", "repos_url": "https://api.github.com/users/engrmz/repos", "events_url": "https://api.github.com/users/engrmz/events{/privacy}", "received_events_url": "https://api.github.com/users/engrmz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-08-13T12:20:02Z", "updated_at": "2020-08-14T12:44:38Z", "closed_at": "2020-08-14T12:44:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello everyone, \r\nCan you please help in understanding the functionality of `dataset = dataset.repeat(-1)` in tensorflow 1? In my case, when I am using it, it iterates the dataset infinitely. However, when I set it any other number than -1, it fetches only a single sample. ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2294", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2294/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2294/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2294/events", "html_url": "https://github.com/tensorflow/datasets/issues/2294", "id": 676296458, "node_id": "MDU6SXNzdWU2NzYyOTY0NTg=", "number": 2294, "title": "[data request] <Cats VS Dogs>", "user": {"login": "LittlePirate007", "id": 48082461, "node_id": "MDQ6VXNlcjQ4MDgyNDYx", "avatar_url": "https://avatars1.githubusercontent.com/u/48082461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LittlePirate007", "html_url": "https://github.com/LittlePirate007", "followers_url": "https://api.github.com/users/LittlePirate007/followers", "following_url": "https://api.github.com/users/LittlePirate007/following{/other_user}", "gists_url": "https://api.github.com/users/LittlePirate007/gists{/gist_id}", "starred_url": "https://api.github.com/users/LittlePirate007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LittlePirate007/subscriptions", "organizations_url": "https://api.github.com/users/LittlePirate007/orgs", "repos_url": "https://api.github.com/users/LittlePirate007/repos", "events_url": "https://api.github.com/users/LittlePirate007/events{/privacy}", "received_events_url": "https://api.github.com/users/LittlePirate007/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168524723, "node_id": "MDU6TGFiZWwxMTY4NTI0NzIz", "url": "https://api.github.com/repos/tensorflow/datasets/labels/dataset%20request", "name": "dataset request", "color": "beb7ff", "default": false, "description": "Request for a new dataset to be added"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-08-10T17:26:17Z", "updated_at": "2020-08-10T17:34:57Z", "closed_at": "2020-08-10T17:34:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "* Name of dataset: <name>\r\n* URL of dataset: <url>\r\n* License of dataset: <license type>\r\n* Short description of dataset and use case(s): <description>\r\n\r\nFolks who would also like to see this dataset in `tensorflow/datasets`, please thumbs-up so the developers can know which requests to prioritize.\r\n\r\nAnd if you'd like to contribute the dataset (thank you!), see our [guide to adding a dataset](https://github.com/tensorflow/datasets/blob/master/docs/add_dataset.md).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2272", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2272/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2272/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2272/events", "html_url": "https://github.com/tensorflow/datasets/issues/2272", "id": 672942551, "node_id": "MDU6SXNzdWU2NzI5NDI1NTE=", "number": 2272, "title": "NonMatchingChecksumError(resource.url, tmp_path) when downloading Caltech Birds 2011", "user": {"login": "shekkizh", "id": 4872889, "node_id": "MDQ6VXNlcjQ4NzI4ODk=", "avatar_url": "https://avatars2.githubusercontent.com/u/4872889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shekkizh", "html_url": "https://github.com/shekkizh", "followers_url": "https://api.github.com/users/shekkizh/followers", "following_url": "https://api.github.com/users/shekkizh/following{/other_user}", "gists_url": "https://api.github.com/users/shekkizh/gists{/gist_id}", "starred_url": "https://api.github.com/users/shekkizh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shekkizh/subscriptions", "organizations_url": "https://api.github.com/users/shekkizh/orgs", "repos_url": "https://api.github.com/users/shekkizh/repos", "events_url": "https://api.github.com/users/shekkizh/events{/privacy}", "received_events_url": "https://api.github.com/users/shekkizh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-04T17:03:19Z", "updated_at": "2020-08-12T18:52:32Z", "closed_at": "2020-08-12T18:52:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nTensorflow datasets - Caltech Birds 2011 download fails with a resulting checksum error.\r\n\r\n**Environment information**\r\n* Operating System: Linux (Mint)\r\n* Python version: 3.6\r\n* `tfds-nightly` version: 3.2.1.dev202008040105\r\n* `tensorflow-gpu` version: 2.3.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\ntfds.load(name='caltech_birds2011', split=['train','test'], with_info=True, as_supervised=False)\r\n```\r\n**Log**\r\n```\r\n File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py\", line 382, in load\r\n    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 379, in download_and_prepare\r\n    download_config=download_config)\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 1033, in _download_and_prepare\r\n    max_examples_per_split=download_config.max_examples_per_split,\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 943, in _download_and_prepare\r\n    dl_manager, **split_generators_kwargs):\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/image_classification/caltech_birds.py\", line 237, in _split_generators\r\n    self._caltech_birds_info.images_url,\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 547, in download\r\n    return _map_promise(self._download, url_or_urls)\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 638, in _map_promise\r\n    res = tf.nest.map_structure(lambda p: p.get(), all_promises)  # Wait promises\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 635, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 635, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 638, in <lambda>\r\n    res = tf.nest.map_structure(lambda p: p.get(), all_promises)  # Wait promises\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/promise/promise.py\", line 512, in get\r\n    return self._target_settled_value(_raise=True)\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/promise/promise.py\", line 516, in _target_settled_value\r\n    return self._target()._settled_value(_raise)\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/promise/promise.py\", line 226, in _settled_value\r\n    reraise(type(raise_val), raise_val, self._traceback)\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/promise/promise.py\", line 87, in try_catch\r\n    return (handler(*args, **kwargs), None)\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 484, in callback\r\n    url_info=url_info,\r\n  File \"/home/charlie/.virtualenvs/tensorflow2/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 344, in _handle_download_result\r\n    raise NonMatchingChecksumError(resource.url, tmp_path)\r\ntensorflow_datasets.core.download.download_manager.NonMatchingChecksumError: Artifact http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz, downloaded to /media/charlie/hd_1/Datasets/downloads/visi.calt.edu_visi-data_CUB-200-2011_CUB_28D73zFxAmvlUWt5COvgFRW1-TL_ki16ulFRBqlHuuRc.tgz.tmp.3d7c4df8876242c3a4f0abf35ab88f06/view, has wrong checksum. This might indicate:\r\n * The website may be down (e.g. returned a 503 status code). Please check the url.\r\n * For Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See https://github.com/tensorflow/datasets/issues/1482\r\n * The original datasets files may have been updated. In this case the TFDS dataset builder should be updated to use the new files and checksums. Sorry about that. Please open an issue or send us a PR with a fix.\r\n * If you're adding a new dataset, don't forget to register the checksums as explained in: https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally\r\n```\r\n\r\n**Expected behavior**\r\nDataset to be downloaded\r\n\r\n**Additional context**\r\nUsing tf.compat.v1 and tf.disable_v2_behavior()\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2270", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2270/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2270/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2270/events", "html_url": "https://github.com/tensorflow/datasets/issues/2270", "id": 672469220, "node_id": "MDU6SXNzdWU2NzI0NjkyMjA=", "number": 2270, "title": "Allow tfds.as_numpy() to return a reusable Iterable when converting a tf.data.Dataset", "user": {"login": "dthkao", "id": 11166458, "node_id": "MDQ6VXNlcjExMTY2NDU4", "avatar_url": "https://avatars1.githubusercontent.com/u/11166458?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dthkao", "html_url": "https://github.com/dthkao", "followers_url": "https://api.github.com/users/dthkao/followers", "following_url": "https://api.github.com/users/dthkao/following{/other_user}", "gists_url": "https://api.github.com/users/dthkao/gists{/gist_id}", "starred_url": "https://api.github.com/users/dthkao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dthkao/subscriptions", "organizations_url": "https://api.github.com/users/dthkao/orgs", "repos_url": "https://api.github.com/users/dthkao/repos", "events_url": "https://api.github.com/users/dthkao/events{/privacy}", "received_events_url": "https://api.github.com/users/dthkao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-08-04T03:02:54Z", "updated_at": "2020-08-04T18:44:12Z", "closed_at": "2020-08-04T18:44:12Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently `tfds.as_numpy(dataset)` returns an Iterator which (if the datset is finite) can only be consumed once. This (I believe) is different than the tf.data.Datset semantics. For example this results in the second for loop below iterating through zero elements (i.e., do_more_stuff is not called):\r\n\r\n```\r\nnumpy_items = tfds.as_numpy(dataset)  # dataset is finite\r\nfor item in numpy_items:\r\n  do_stuff(item)\r\nfor item in numpy_items:\r\n  do_more_stuff(item)\r\n```\r\n\r\n**Describe the solution you'd like**\r\nI'd like if `numpy_items` can be used multiple times -- for example computing metrics over the entire dataset without re-instantiation.\r\n\r\n**Describe alternatives you've considered**\r\nRe-initializing an iterator for each use. This becomes complicated when the dataset is passed around to multiple places.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2212", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2212/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2212/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2212/events", "html_url": "https://github.com/tensorflow/datasets/issues/2212", "id": 662706106, "node_id": "MDU6SXNzdWU2NjI3MDYxMDY=", "number": 2212, "title": "Dataset error with uc_merced dataset", "user": {"login": "gallorob", "id": 32876132, "node_id": "MDQ6VXNlcjMyODc2MTMy", "avatar_url": "https://avatars1.githubusercontent.com/u/32876132?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gallorob", "html_url": "https://github.com/gallorob", "followers_url": "https://api.github.com/users/gallorob/followers", "following_url": "https://api.github.com/users/gallorob/following{/other_user}", "gists_url": "https://api.github.com/users/gallorob/gists{/gist_id}", "starred_url": "https://api.github.com/users/gallorob/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gallorob/subscriptions", "organizations_url": "https://api.github.com/users/gallorob/orgs", "repos_url": "https://api.github.com/users/gallorob/repos", "events_url": "https://api.github.com/users/gallorob/events{/privacy}", "received_events_url": "https://api.github.com/users/gallorob/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1257633672, "node_id": "MDU6TGFiZWwxMjU3NjMzNjcy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/documentation", "name": "documentation", "color": "fbca04", "default": true, "description": "Pull Request or Issue related with comments or documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-21T07:46:07Z", "updated_at": "2020-07-23T01:32:03Z", "closed_at": "2020-07-23T01:32:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "_Note_: Bug was originally wrongly opened on the tensorflow repository, see [here](https://github.com/tensorflow/tensorflow/issues/41078)\r\n\r\n**System information**\r\n- Using Google Colab's default TF installation\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\nDataset's samples are not all of the expected 256x256x3 shape, I found 44 out of 2100 samples with different shape. Currently, during preprocessing, I have to rescale the image if necessary.\r\n\r\n**Describe the expected behavior**\r\nAll samples should have 256x256x3 shape.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow.compat.v2 as tf\r\nimport tensorflow_datasets as tfds\r\n\r\ndataset, info = tfds.load('uc_merced',\r\n                            split='train',\r\n                            as_supervised=True,\r\n                            with_info=True,\r\n                            shuffle_files=True)\r\n\r\nexp_shape = (256, 256, 3)\r\nn = 0\r\nfor sample in dataset.take(-1):\r\n    if sample[0].shape != exp_shape:\r\n        n += 1\r\n\r\nprint('Found {} samples with wrong shape'.format(n))\r\n```\r\n\r\n**Other info / logs**\r\n`Found 44 samples with wrong shape`\r\n\r\n**Additional notes**\r\nThis may seem to be a problem with the original dataset (http://weegee.vision.ucmerced.edu/datasets/landuse.html). If a fix is not possible, it may be a good idea to add a note in the documentation page https://www.tensorflow.org/datasets/catalog/uc_merced to let new users know about the issue.\r\nAlternatively, a possible solution that the user would have to implement is something like:\r\n```\r\ndef correct_dims(x, y):\r\n    some_resizing_function(x, (256, 256, 3))\r\n```\r\nand after loading the dataset:\r\n```\r\ndataset = dataset.map(correct_dims)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2199", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2199/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2199/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2199/events", "html_url": "https://github.com/tensorflow/datasets/issues/2199", "id": 657068618, "node_id": "MDU6SXNzdWU2NTcwNjg2MTg=", "number": 2199, "title": "ImportError: cannot import name 'ContextManager'", "user": {"login": "SinaChavoshi", "id": 20114005, "node_id": "MDQ6VXNlcjIwMTE0MDA1", "avatar_url": "https://avatars0.githubusercontent.com/u/20114005?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SinaChavoshi", "html_url": "https://github.com/SinaChavoshi", "followers_url": "https://api.github.com/users/SinaChavoshi/followers", "following_url": "https://api.github.com/users/SinaChavoshi/following{/other_user}", "gists_url": "https://api.github.com/users/SinaChavoshi/gists{/gist_id}", "starred_url": "https://api.github.com/users/SinaChavoshi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SinaChavoshi/subscriptions", "organizations_url": "https://api.github.com/users/SinaChavoshi/orgs", "repos_url": "https://api.github.com/users/SinaChavoshi/repos", "events_url": "https://api.github.com/users/SinaChavoshi/events{/privacy}", "received_events_url": "https://api.github.com/users/SinaChavoshi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1257633672, "node_id": "MDU6TGFiZWwxMjU3NjMzNjcy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/documentation", "name": "documentation", "color": "fbca04", "default": true, "description": "Pull Request or Issue related with comments or documentation"}, {"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-15T05:20:56Z", "updated_at": "2020-07-23T15:42:39Z", "closed_at": "2020-07-23T15:42:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\ntfds 3.2.0 requires later version of typing 3.6.0>= which includes support for \"ContextManager\" (ref https://docs.python.org/3/library/typing.html#typing.ContextManager). However this is not specified in requirements file resulting in failure python 3.5.2 environment. \r\n\r\n**Environment information**\r\n* Operating System: ubuntu 18.0\r\n* Python version: 3.5.2 \r\n* `tensorflow-datasets` version: 3.2.0\r\n* `tensorflow` version: 2.2\r\n\r\n**Reproduction instructions**\r\n\r\nsetup an environment with python 3.5.2. \r\n\r\n```shell\r\npip3 install tensorflow \r\npython -c \"import tensroflow_datasets as tfds\" \r\n```\r\n\r\n**Link to logs**\r\nIf applicable, <link to gist with logs, stack trace>\r\n\r\n**Expected behavior**\r\nWhat you expected to happen.\r\ntfds should pull required dependancies\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2196", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2196/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2196/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2196/events", "html_url": "https://github.com/tensorflow/datasets/issues/2196", "id": 656805197, "node_id": "MDU6SXNzdWU2NTY4MDUxOTc=", "number": 2196, "title": "[load-data-error]: additional-pos-args-requested", "user": {"login": "saranshbh", "id": 11285999, "node_id": "MDQ6VXNlcjExMjg1OTk5", "avatar_url": "https://avatars0.githubusercontent.com/u/11285999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saranshbh", "html_url": "https://github.com/saranshbh", "followers_url": "https://api.github.com/users/saranshbh/followers", "following_url": "https://api.github.com/users/saranshbh/following{/other_user}", "gists_url": "https://api.github.com/users/saranshbh/gists{/gist_id}", "starred_url": "https://api.github.com/users/saranshbh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saranshbh/subscriptions", "organizations_url": "https://api.github.com/users/saranshbh/orgs", "repos_url": "https://api.github.com/users/saranshbh/repos", "events_url": "https://api.github.com/users/saranshbh/events{/privacy}", "received_events_url": "https://api.github.com/users/saranshbh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-07-14T18:17:15Z", "updated_at": "2020-07-14T20:27:55Z", "closed_at": "2020-07-14T20:27:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Error imported data from tfds**\r\n\r\n\r\n**Environment information**\r\n* Operating System: Windows 10\r\n* Python version: 3.8\r\n* `tensorflow-datasets`/`tfds-nightly` version: tensorflow-datasets: 3.2.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: tensorflow: 2.2.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\n(raw_train, raw_valid, raw_test), metadata = tfds.load(\r\n    'cats_vs_dogs',\r\n    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\r\n    with_info=True,\r\n    as_supervised=True\r\n)\r\n\r\n```\r\n\r\n**Error**\r\nhttps://gist.github.com/saranshbh/7c5f9744d2ca3c9e9b88475e1b0c3d55\r\n\r\n**Expected behavior**\r\nLoad the dataset. \r\n\r\n**Additional context**\r\nError is a TypeError expecting two positional arguments.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2191", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2191/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2191/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2191/events", "html_url": "https://github.com/tensorflow/datasets/issues/2191", "id": 656039569, "node_id": "MDU6SXNzdWU2NTYwMzk1Njk=", "number": 2191, "title": "Missing 2 required positional arguments.", "user": {"login": "Lothedr", "id": 16463845, "node_id": "MDQ6VXNlcjE2NDYzODQ1", "avatar_url": "https://avatars2.githubusercontent.com/u/16463845?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lothedr", "html_url": "https://github.com/Lothedr", "followers_url": "https://api.github.com/users/Lothedr/followers", "following_url": "https://api.github.com/users/Lothedr/following{/other_user}", "gists_url": "https://api.github.com/users/Lothedr/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lothedr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lothedr/subscriptions", "organizations_url": "https://api.github.com/users/Lothedr/orgs", "repos_url": "https://api.github.com/users/Lothedr/repos", "events_url": "https://api.github.com/users/Lothedr/events{/privacy}", "received_events_url": "https://api.github.com/users/Lothedr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-13T18:05:18Z", "updated_at": "2020-07-13T22:08:24Z", "closed_at": "2020-07-13T22:08:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nCalling `tfds.builder('mnist')` causes exception:\r\n\r\n> TypeError: \\_\\_init__() missing 2 required positional arguments: 'op' and 'message'\r\n\r\n**Environment information**\r\n* Operating System: Windows 10 Pro\r\n* Python version: 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]\r\n* `tensorflow-datasets` version: 3.2.0\r\n* `tensorflow` version: 2.2.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\nbuilder = tfds.builder('mnist')\r\n```\r\n\r\n**Link to logs**\r\n[Traceback](https://gist.github.com/Lothedr/5e7d835cb471d001c8f4b29f86085a8d)\r\n\r\n**Expected behavior**\r\nI expected that tfds will not throw an exception.\r\n\r\n**Additional context**\r\nThere seems to be an implementation error [here](https://github.com/tensorflow/datasets/blob/a25626d3fd20c98a3ac99589cf68079022f2b232/tensorflow_datasets/core/utils/py_utils.py#L392). In my case, `exc_type` is `UnimplmentedError` and its constructor needs more arguments according to the [implementation](https://github.com/tensorflow/tensorflow/blob/909c073034e9b185149717c22b83d52dbd7396c3/tensorflow/python/framework/errors_impl.py#L436). \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2190", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2190/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2190/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2190/events", "html_url": "https://github.com/tensorflow/datasets/issues/2190", "id": 656031277, "node_id": "MDU6SXNzdWU2NTYwMzEyNzc=", "number": 2190, "title": "Error loading imdb_reviews on Julyter Lab and Windows 10 machine", "user": {"login": "wbadry", "id": 5664750, "node_id": "MDQ6VXNlcjU2NjQ3NTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/5664750?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wbadry", "html_url": "https://github.com/wbadry", "followers_url": "https://api.github.com/users/wbadry/followers", "following_url": "https://api.github.com/users/wbadry/following{/other_user}", "gists_url": "https://api.github.com/users/wbadry/gists{/gist_id}", "starred_url": "https://api.github.com/users/wbadry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wbadry/subscriptions", "organizations_url": "https://api.github.com/users/wbadry/orgs", "repos_url": "https://api.github.com/users/wbadry/repos", "events_url": "https://api.github.com/users/wbadry/events{/privacy}", "received_events_url": "https://api.github.com/users/wbadry/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-13T17:50:47Z", "updated_at": "2020-07-15T01:11:37Z", "closed_at": "2020-07-15T01:06:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\nimport tensorflow_datasets as tfds\r\n\r\nprint(\"Version: \", tf.__version__)\r\nprint(\"Eager mode: \", tf.executing_eagerly())\r\nprint(\"Hub version: \", hub.__version__)\r\nprint(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\r\n\r\n```\r\n\r\n```\r\nVersion:  2.2.0\r\nEager mode:  True\r\nHub version:  0.8.0\r\nGPU is available\r\n```\r\n\r\n**The datasets** list can be loaded with no issues. When trying to **load imdb_reviews** or any other dataset, I encounter this error\r\n\r\n```python\r\n#tfds.list_builders()\r\nimdb, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\r\n```\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nUnimplementedError                        Traceback (most recent call last)\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py in try_reraise(*args, **kwargs)\r\n    398   try:\r\n--> 399     yield\r\n    400   except Exception:   # pylint: disable=broad-except\r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py in builder(name, **builder_init_kwargs)\r\n    243       prefix=\"Failed to construct dataset {}\".format(name)):\r\n--> 244     return builder_cls(name)(**builder_kwargs)\r\n    245 \r\n\r\nc:\\python37\\lib\\site-packages\\wrapt\\wrappers.py in __call__(self, *args, **kwargs)\r\n    602             return self._self_wrapper(self.__wrapped__, self._self_instance,\r\n--> 603                     args, kwargs)\r\n    604 \r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     68     _check_required(fn, kwargs)\r\n---> 69     return fn(*args, **kwargs)\r\n     70 \r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in __init__(self, data_dir, config, version)\r\n    205     else:  # Use the code version (do not restore data)\r\n--> 206       self.info.initialize_from_bucket()\r\n    207 \r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py in initialize_from_bucket(self)\r\n    422     tmp_dir = tempfile.mkdtemp(\"tfds\")\r\n--> 423     data_files = gcs_utils.gcs_dataset_info_files(self.full_name)\r\n    424     if not data_files:\r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\gcs_utils.py in gcs_dataset_info_files(dataset_dir)\r\n     69   \"\"\"Return paths to GCS files in the given dataset directory.\"\"\"\r\n---> 70   return gcs_listdir(posixpath.join(GCS_DATASET_INFO_DIR, dataset_dir))\r\n     71 \r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\gcs_utils.py in gcs_listdir(dir_name)\r\n     62   root_dir = gcs_path(dir_name)\r\n---> 63   if _is_gcs_disabled or not tf.io.gfile.exists(root_dir):\r\n     64     return None\r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in file_exists_v2(path)\r\n    266   try:\r\n--> 267     _pywrap_file_io.FileExists(compat.as_bytes(path))\r\n    268   except errors.NotFoundError:\r\n\r\nUnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/dataset_info/imdb_reviews/plain_text/1.0.0')\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-33-06930b64f980> in <module>\r\n      1 #tfds.list_builders()\r\n----> 2 imdb, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\r\n\r\nc:\\python37\\lib\\site-packages\\wrapt\\wrappers.py in __call__(self, *args, **kwargs)\r\n    562 \r\n    563         return self._self_wrapper(self.__wrapped__, self._self_instance,\r\n--> 564                 args, kwargs)\r\n    565 \r\n    566 class BoundFunctionWrapper(_FunctionWrapperBase):\r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     67     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     68     _check_required(fn, kwargs)\r\n---> 69     return fn(*args, **kwargs)\r\n     70 \r\n     71   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py in load(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\r\n    366     data_dir = constants.DATA_DIR\r\n    367 \r\n--> 368   dbuilder = builder(name, data_dir=data_dir, **builder_kwargs)\r\n    369   if download:\r\n    370     download_and_prepare_kwargs = download_and_prepare_kwargs or {}\r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py in builder(name, **builder_init_kwargs)\r\n    242   with py_utils.try_reraise(\r\n    243       prefix=\"Failed to construct dataset {}\".format(name)):\r\n--> 244     return builder_cls(name)(**builder_kwargs)\r\n    245 \r\n    246 \r\n\r\nc:\\python37\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n    128                 value = type()\r\n    129             try:\r\n--> 130                 self.gen.throw(type, value, traceback)\r\n    131             except StopIteration as exc:\r\n    132                 # Suppress StopIteration *unless* it's the same exception that\r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py in try_reraise(*args, **kwargs)\r\n    399     yield\r\n    400   except Exception:   # pylint: disable=broad-except\r\n--> 401     reraise(*args, **kwargs)\r\n    402 \r\n    403 \r\n\r\nc:\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py in reraise(prefix, suffix)\r\n    390   suffix = '\\n' + suffix if suffix else ''\r\n    391   msg = prefix + str(exc_value) + suffix\r\n--> 392   six.reraise(exc_type, exc_type(msg), exc_traceback)\r\n    393 \r\n    394 \r\n\r\nTypeError: __init__() missing 2 required positional arguments: 'op' and 'message'\r\n```\r\n\r\nMay I know the problem? Thanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2182", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2182/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2182/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2182/events", "html_url": "https://github.com/tensorflow/datasets/issues/2182", "id": 655183862, "node_id": "MDU6SXNzdWU2NTUxODM4NjI=", "number": 2182, "title": "Can't download example datasets from google", "user": {"login": "LaBaum", "id": 67793135, "node_id": "MDQ6VXNlcjY3NzkzMTM1", "avatar_url": "https://avatars0.githubusercontent.com/u/67793135?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LaBaum", "html_url": "https://github.com/LaBaum", "followers_url": "https://api.github.com/users/LaBaum/followers", "following_url": "https://api.github.com/users/LaBaum/following{/other_user}", "gists_url": "https://api.github.com/users/LaBaum/gists{/gist_id}", "starred_url": "https://api.github.com/users/LaBaum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LaBaum/subscriptions", "organizations_url": "https://api.github.com/users/LaBaum/orgs", "repos_url": "https://api.github.com/users/LaBaum/repos", "events_url": "https://api.github.com/users/LaBaum/events{/privacy}", "received_events_url": "https://api.github.com/users/LaBaum/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-11T10:36:37Z", "updated_at": "2020-07-13T22:12:26Z", "closed_at": "2020-07-11T14:23:46Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hello,\r\nIm trying to get into AI Development with tensorflow, but I can't download the example datasets. Every time I try it, Ill get a error from the debug console and from vsc.\r\n\r\nHere my code:\r\n\r\n`import numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\nimport tensorflow_datasets as tfds\r\nprint(tfds.list_builders())\r\nds = tfds.load('mnist', split='train', shuffle_files=True)\r\nassert isinstance(ds, tf.data.Dataset)\r\n`\r\n\r\n\r\nand the errors I recieve:\r\n`W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Failed precondition: Error executing an HTTP request: libcurl code 77 meaning 'Problem with the SSL CA cert (path? access rights?)', error details: error setting certificate verify locations: CAfile: /etc/ssl/certs/ca-certificates.crt`\r\n\r\n`Exception has occurred: TypeError\r\n__init__() missing 2 required positional arguments: 'op' and 'message'\r\n  File \"/home/Dokumente/Python Workspace/TF Einstieg/TfTextClassificication.py\", line 7, in <module>\r\n    ds = tfds.load('mnist', split='train', shuffle_files=True)`\r\n\r\n\r\nIt would be nice if theire is somebody who can help me, because I can't figure out by myself :/\r\n**Environment information**\r\n* Operating System: Fedora32\r\n* Python version: 3.8.3\r\n* `tensorflow-datasets: 3.2.0\r\n* `tensorflow: 2.2.0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2176", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2176/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2176/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2176/events", "html_url": "https://github.com/tensorflow/datasets/issues/2176", "id": 654666324, "node_id": "MDU6SXNzdWU2NTQ2NjYzMjQ=", "number": 2176, "title": "Slow Speed", "user": {"login": "jsl303", "id": 11588295, "node_id": "MDQ6VXNlcjExNTg4Mjk1", "avatar_url": "https://avatars3.githubusercontent.com/u/11588295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsl303", "html_url": "https://github.com/jsl303", "followers_url": "https://api.github.com/users/jsl303/followers", "following_url": "https://api.github.com/users/jsl303/following{/other_user}", "gists_url": "https://api.github.com/users/jsl303/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsl303/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsl303/subscriptions", "organizations_url": "https://api.github.com/users/jsl303/orgs", "repos_url": "https://api.github.com/users/jsl303/repos", "events_url": "https://api.github.com/users/jsl303/events{/privacy}", "received_events_url": "https://api.github.com/users/jsl303/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-10T09:59:12Z", "updated_at": "2020-07-22T16:16:10Z", "closed_at": "2020-07-22T16:16:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "Is this normal to be this slow?\r\nAccording to speedtest-cli, I have 254.38 Mbit/s downstream and 232.71 Mbit/s upstream.\r\n```\r\ntest_data, info = tfds.load(name=\"voc/2007\", with_info=True, split=\"validation\")\r\n\u2190[1mDownloading and preparing dataset voc/2007/4.0.0 (download: 868.85 MiB, generated: Unknown size, total: 868.85 MiB) to\r\nDl Size...:  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                          | 83/868 [06:16<1:04:41,  4.94s/ MiB]\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2172", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2172/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2172/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2172/events", "html_url": "https://github.com/tensorflow/datasets/issues/2172", "id": 654306327, "node_id": "MDU6SXNzdWU2NTQzMDYzMjc=", "number": 2172, "title": "Can't convert ImageNet to TFDS", "user": {"login": "wilderfield", "id": 15713959, "node_id": "MDQ6VXNlcjE1NzEzOTU5", "avatar_url": "https://avatars1.githubusercontent.com/u/15713959?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wilderfield", "html_url": "https://github.com/wilderfield", "followers_url": "https://api.github.com/users/wilderfield/followers", "following_url": "https://api.github.com/users/wilderfield/following{/other_user}", "gists_url": "https://api.github.com/users/wilderfield/gists{/gist_id}", "starred_url": "https://api.github.com/users/wilderfield/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wilderfield/subscriptions", "organizations_url": "https://api.github.com/users/wilderfield/orgs", "repos_url": "https://api.github.com/users/wilderfield/repos", "events_url": "https://api.github.com/users/wilderfield/events{/privacy}", "received_events_url": "https://api.github.com/users/wilderfield/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-07-09T19:47:18Z", "updated_at": "2020-07-10T00:50:11Z", "closed_at": "2020-07-10T00:50:11Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I need help with / What I was wondering**\r\nI need to run `python -m tensorflow_datasets.scripts.download_and_prepare --datasets=imagenet2012` to convert imagenet dataset to \"tfds\" format.\r\n\r\nI have:\r\n```\r\n~/tensorflow_datasets/downloads/manual/ILSVRC2012_img_train.tar\r\n~/tensorflow_datasets/downloads/manual/ILSVRC2012_img_val.tar\r\n```\r\n\r\nI get a crash:\r\n```\r\n$ python -m tensorflow_datasets.scripts.download_and_prepare --datasets=imagenet2012\r\n2020-07-09 12:42:44.810165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1                      \r\nI0709 12:42:46.014064 139951095191360 download_and_prepare.py:201] Running download_and_prepare for dataset(s):                                                        \r\nimagenet2012                                                                                                                                                           \r\n2020-07-09 12:42:46.039449: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'\".                                                                                                  \r\nI0709 12:42:46.465344 139951095191360 dataset_info.py:427] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: imagenet2012/5.0.0                                         \r\nI0709 12:42:46.734692 139951095191360 dataset_info.py:358] Load dataset info from /tmp/tmpq9l_v2v7tfds                                                                                       \r\nI0709 12:42:46.738695 139951095191360 dataset_info.py:398] Field info.description from disk and from code do not match. Keeping the one from code.                                           \r\nI0709 12:42:46.738808 139951095191360 dataset_info.py:398] Field info.citation from disk and from code do not match. Keeping the one from code.                                              \r\nI0709 12:42:46.739076 139951095191360 download_and_prepare.py:139] download_and_prepare for dataset imagenet2012/5.0.0...                                                                    \r\nI0709 12:42:46.739398 139951095191360 dataset_builder.py:346] Generating dataset imagenet2012 (/home/bryanloz/tensorflow_datasets/imagenet2012/5.0.0)                                        \r\nDownloading and preparing dataset imagenet2012/5.0.0 (download: 144.02 GiB, generated: Unknown size, total: 144.02 GiB) to /home/bryanloz/tensorflow_datasets/imagenet2012/5.0.0...          \r\nI0709 12:42:49.851376 139951095191360 dataset_builder.py:947] Generating split train                                                                                                         \r\n76809 examples [01:11, 1230.11 examples/s]2020-07-09 12:44:01.563442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1       \r\n2020-07-09 12:44:01.758785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:                                                                         \r\npciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0                                                                                                                     \r\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                               \r\n2020-07-09 12:44:01.760404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:                                                                         \r\npciBusID: 0000:af:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0                                                                                                                     \r\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                               \r\n2020-07-09 12:44:01.761609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:                                                                         \r\npciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0                                                                                                                     \r\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                               \r\n2020-07-09 12:44:01.761638: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1                                            \r\n2020-07-09 12:44:01.763099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10                                              \r\n2020-07-09 12:44:01.764466: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10                                               \r\n2020-07-09 12:44:01.768670: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10                                              \r\n2020-07-09 12:44:01.807622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10                                            \r\n2020-07-09 12:44:01.809431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10                                            \r\n2020-07-09 12:44:01.815753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7                                                \r\n2020-07-09 12:44:01.827543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2                                                                     \r\n2020-07-09 12:44:01.828474: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA                                                                                                                          \r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.                                                                                                  \r\n2020-07-09 12:44:01.868361: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz                                                                          \r\n2020-07-09 12:44:01.878461: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557610c82a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:                                                                                                                                                                                          \r\n2020-07-09 12:44:01.878515: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version                                                             \r\n2020-07-09 12:44:01.900848: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.069513: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:2: failed initializing StreamExecutor for CUDA device ordinal 2: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.069596: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.069938: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 0, reason: Internal: no supported devices found for platform CUDA                                                                                                                                                                                      \r\n2020-07-09 12:44:02.074957: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.214344: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:2: failed initializing StreamExecutor for CUDA device ordinal 2: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.214487: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.214891: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 1, reason: Internal: no supported devices found for platform CUDA                                                                                                                                                                                      \r\n2020-07-09 12:44:02.220597: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.376580: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.376694: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:2: failed initializing StreamExecutor for CUDA device ordinal 2: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS                                                        \r\n2020-07-09 12:44:02.377093: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 2, reason: Internal: no supported devices found for platform CUDA\r\n2020-07-09 12:44:02.518009: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS\r\nFatal Python error: Aborted\r\n\r\nThread 0x00007f4786554700 (most recent call first):\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/threading.py\", line 300 in wait\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/threading.py\", line 552 in wait\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tqdm/_monitor.py\", line 69 in run\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/threading.py\", line 917 in _bootstrap_inner\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/threading.py\", line 885 in _bootstrap\r\n\r\nCurrent thread 0x00007f48e7509740 (most recent call first):\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 539 in ensure_initialized\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 97 in convert_to_eager_tensor\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 300 in _constant_eager_impl\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 275 in _constant_impl\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 264 in constant\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 338 in _constant_tensor_conversion_function\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1525 in convert_to_tensor\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py\", line 1241 in decode_jpeg_eager_fallback\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py\", line 1177 in decode_jpeg\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/core/utils/tf_utils.py\", line 77 in run\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/core/utils/image_utils.py\", line 54 in jpeg_cmyk_to_rgb\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/image_classification/imagenet.py\", line 176 in _fix_image\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/image_classification/imagenet.py\", line 197 in _generate_examples\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tqdm/std.py\", line 1129 in __iter__\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 1034 in _prepare_split\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 951 in _download_and_prepare\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 1019 in _download_and_prepare\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 376 in download_and_prepare\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 69 in disallow_positional_args_dec\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/scripts/download_and_prepare.py\", line 156 in download_and_prepare\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/scripts/download_and_prepare.py\", line 236 in main\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/site-packages/tensorflow_datasets/scripts/download_and_prepare.py\", line 241 in <module>\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/runpy.py\", line 85 in _run_code\r\n  File \"/scratch/bryanloz/anaconda3/envs/tf22/lib/python3.7/runpy.py\", line 193 in _run_module_as_main\r\nAborted (core dumped)\r\n```\r\n\r\n**What I've tried so far**\r\nI've tried moving the tar balls from network storage to local storage with no improvement\r\n\r\n**It would be nice if...**\r\nIt might be helpful if documentation for tfds was a bit more verbose, what is tfds even doing to my tar balls?\r\n\r\n**Environment information**\r\n(if applicable)\r\n* Ubuntu 18.04\r\n* Python version: 3.7.0\r\n* `tensorflow-datasets`/`tfds-nightly` version: (tfds-nightly) 3.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: (tf-nightly) 2.4.0-dev20200709\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2160", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2160/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2160/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2160/events", "html_url": "https://github.com/tensorflow/datasets/issues/2160", "id": 653250302, "node_id": "MDU6SXNzdWU2NTMyNTAzMDI=", "number": 2160, "title": "Script to add a new dataset generates files in ~/.local/lib/python3.6", "user": {"login": "enigmaeth", "id": 14938154, "node_id": "MDQ6VXNlcjE0OTM4MTU0", "avatar_url": "https://avatars0.githubusercontent.com/u/14938154?v=4", "gravatar_id": "", "url": "https://api.github.com/users/enigmaeth", "html_url": "https://github.com/enigmaeth", "followers_url": "https://api.github.com/users/enigmaeth/followers", "following_url": "https://api.github.com/users/enigmaeth/following{/other_user}", "gists_url": "https://api.github.com/users/enigmaeth/gists{/gist_id}", "starred_url": "https://api.github.com/users/enigmaeth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/enigmaeth/subscriptions", "organizations_url": "https://api.github.com/users/enigmaeth/orgs", "repos_url": "https://api.github.com/users/enigmaeth/repos", "events_url": "https://api.github.com/users/enigmaeth/events{/privacy}", "received_events_url": "https://api.github.com/users/enigmaeth/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-07-08T12:17:31Z", "updated_at": "2020-07-11T18:40:04Z", "closed_at": "2020-07-11T18:40:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "Script to add a new dataset generates files in `~/.local/lib/python3.6/site-packages/tensorflow_datasets`.\r\nhttps://www.tensorflow.org/datasets/add_dataset#writing_my_datasetpy\r\n\r\n**Environment information**\r\n* Operating System: elementary OS, 5.1.4 Hera\r\n* Linux kernel: 4.15.0-101-generic\r\n* Python version: 3.6.9\r\n* `tensorflow-datasets`/`tfds-nightly` version: tensorflow-datasets==3.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: tensorflow-gpu==1.13.1\r\n```\r\n$ pip freeze | grep \"tensorflow\"\r\ntensorflow==2.2.0\r\ntensorflow-datasets==3.1.0\r\ntensorflow-estimator==2.2.0\r\ntensorflow-gpu==1.13.1\r\ntensorflow-metadata==0.22.1\r\ntensorflow-probability==0.10.0\r\n```\r\n\r\n**Reproduction instructions**     \r\n```\r\npython3 tensorflow_datasets/scripts/create_new_dataset.py \\  \r\n  --dataset test_dataset_audio \\  \r\n  --type audio\r\n```\r\n\r\n**Expected behavior**\r\nThese files should be generated in the repository clone, but it gets generated inside `~/.local/lib/python3.6` which is a hard place to find.\r\n\r\n**Additional context**\r\n[`flags.DEFINE_string('tfds_dir', None, 'Root directory of tfds (auto-computed)')`](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/scripts/create_new_dataset.py#L54) might be computing the root dir incorrectly?\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2159", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2159/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2159/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2159/events", "html_url": "https://github.com/tensorflow/datasets/issues/2159", "id": 653214521, "node_id": "MDU6SXNzdWU2NTMyMTQ1MjE=", "number": 2159, "title": "Error downloading UCF101", "user": {"login": "OrrAvrech", "id": 30447591, "node_id": "MDQ6VXNlcjMwNDQ3NTkx", "avatar_url": "https://avatars0.githubusercontent.com/u/30447591?v=4", "gravatar_id": "", "url": "https://api.github.com/users/OrrAvrech", "html_url": "https://github.com/OrrAvrech", "followers_url": "https://api.github.com/users/OrrAvrech/followers", "following_url": "https://api.github.com/users/OrrAvrech/following{/other_user}", "gists_url": "https://api.github.com/users/OrrAvrech/gists{/gist_id}", "starred_url": "https://api.github.com/users/OrrAvrech/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/OrrAvrech/subscriptions", "organizations_url": "https://api.github.com/users/OrrAvrech/orgs", "repos_url": "https://api.github.com/users/OrrAvrech/repos", "events_url": "https://api.github.com/users/OrrAvrech/events{/privacy}", "received_events_url": "https://api.github.com/users/OrrAvrech/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-07-08T11:25:42Z", "updated_at": "2020-07-11T18:22:08Z", "closed_at": "2020-07-11T18:22:07Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nHi,\r\nI couldn't load UCF101 dataset in tensorflow-datasets. \r\nGot this error: \r\n`DownloadError: Failed to get url https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip. HTTP code: 404.`\r\nThen I saw that the homepage PHP file doesn't exist anymore.\r\nAny chance of solving it?\r\n\r\n**Environment information**\r\n* `tensorflow-datasets` version: 2.1.0", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2158", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2158/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2158/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2158/events", "html_url": "https://github.com/tensorflow/datasets/issues/2158", "id": 652587313, "node_id": "MDU6SXNzdWU2NTI1ODczMTM=", "number": 2158, "title": "Incorrect manual download instructions for imagenet2012", "user": {"login": "mattdutson", "id": 14988371, "node_id": "MDQ6VXNlcjE0OTg4Mzcx", "avatar_url": "https://avatars3.githubusercontent.com/u/14988371?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mattdutson", "html_url": "https://github.com/mattdutson", "followers_url": "https://api.github.com/users/mattdutson/followers", "following_url": "https://api.github.com/users/mattdutson/following{/other_user}", "gists_url": "https://api.github.com/users/mattdutson/gists{/gist_id}", "starred_url": "https://api.github.com/users/mattdutson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mattdutson/subscriptions", "organizations_url": "https://api.github.com/users/mattdutson/orgs", "repos_url": "https://api.github.com/users/mattdutson/repos", "events_url": "https://api.github.com/users/mattdutson/events{/privacy}", "received_events_url": "https://api.github.com/users/mattdutson/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1257633672, "node_id": "MDU6TGFiZWwxMjU3NjMzNjcy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/documentation", "name": "documentation", "color": "fbca04", "default": true, "description": "Pull Request or Issue related with comments or documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-07-07T19:49:02Z", "updated_at": "2020-07-11T18:35:57Z", "closed_at": "2020-07-11T18:35:57Z", "author_association": "NONE", "active_lock_reason": null, "body": "I am using TensorFlow 2.2 and TensorFlow Datasets 1.2.\r\n\r\nThe [imagenet2012 dataset documentation](https://www.tensorflow.org/datasets/catalog/imagenet2012) instructs the user to manually download `ILSVRC2012_img_train.tar` and `ILSVRC2012_img_val.tar` to `~/tensorflow_datasets/manual`. Even after doing this, a call to `tfds.load(\"imagenet2012\")` attempts to download the dataset from the web, which results in an error due to the need for a login.\r\n\r\nI have also tried moving the `.tar` files to `~/tensorflow_datasets/downloads/manual` and `~/tensorflow_datasets/downloads/manual/imagenet2012`, none of which have worked.\r\n\r\nNot sure if this is a documentation issue or a bug.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2155", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2155/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2155/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2155/events", "html_url": "https://github.com/tensorflow/datasets/issues/2155", "id": 652254349, "node_id": "MDU6SXNzdWU2NTIyNTQzNDk=", "number": 2155, "title": "citrus_leaves raises 404 Error", "user": {"login": "sebastian-sz", "id": 58402418, "node_id": "MDQ6VXNlcjU4NDAyNDE4", "avatar_url": "https://avatars1.githubusercontent.com/u/58402418?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sebastian-sz", "html_url": "https://github.com/sebastian-sz", "followers_url": "https://api.github.com/users/sebastian-sz/followers", "following_url": "https://api.github.com/users/sebastian-sz/following{/other_user}", "gists_url": "https://api.github.com/users/sebastian-sz/gists{/gist_id}", "starred_url": "https://api.github.com/users/sebastian-sz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sebastian-sz/subscriptions", "organizations_url": "https://api.github.com/users/sebastian-sz/orgs", "repos_url": "https://api.github.com/users/sebastian-sz/repos", "events_url": "https://api.github.com/users/sebastian-sz/events{/privacy}", "received_events_url": "https://api.github.com/users/sebastian-sz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-07-07T11:43:00Z", "updated_at": "2020-07-23T16:51:56Z", "closed_at": "2020-07-23T16:51:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nRunning `ds = tfds.load(\"citrus_leaves)` raises:\r\n```python\r\nDownloadError                             Traceback (most recent call last)\r\n<ipython-input-2-af6ac9dbcf8c> in <module>()\r\n----> 1 ds = tfds.load('citrus_leaves')\r\n\r\n19 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/download/downloader.py in _sync_download(self, url, destination_path)\r\n    233       if response.status_code != 200:\r\n    234         raise DownloadError('Failed to get url %s. HTTP code: %d.' %\r\n--> 235                             (url, response.status_code))\r\n    236     fname = _get_filename(response)\r\n    237     path = os.path.join(destination_path, fname)\r\n\r\nDownloadError: Failed to get url https://data.mendeley.com/datasets/3f83gxmv57/2/files/6f809085-8c29-49f7-afbc-f90854fd45dc/Citrus.zip. HTTP code: 404.\r\n```\r\n\r\n**Environment information**\r\n* Operating System: Ubuntu 18.04.3 LTS (Google Colab) \r\n* Python version: 3.6.9\r\n* `tensorflow-datasets`/`tfds-nightly` version: `tensorflow-datasets 3.1.0`\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: `tensorflow 2.2.0`\r\n\r\n**Reproduction instructions**\r\n```python\r\n!pip install --upgrade tensorflow-datasets\r\nimport tensorflow_datasets as tfds\r\nds = tfds.load('citrus_leaves')\r\n```\r\n\r\n**Link to logs**\r\n-\r\n\r\n**Expected behavior**\r\nExpected the `tfds` not to raise an 404 error and return `tf.data.Dataset` instance instead.\r\n\r\n**Additional context**\r\ntfds docs: https://www.tensorflow.org/datasets/catalog/citrus_leaves \r\n\r\nIt looks like the function is trying to call a dead url (this will 404):\r\nhttps://data.mendeley.com/datasets/3f83gxmv57/2/files/6f809085-8c29-49f7-afbc-f90854fd45dc/Citrus.zip \r\n\r\nAccording to the official dataset webpage (taken from tfds docs), the new location for the zipped dataset is:\r\nhttps://data.mendeley.com/datasets/3f83gxmv57/2/files/53398b67-6f0e-4a67-8384-e2b574b2ebf4/Citrus.zip\r\nSource: https://data.mendeley.com/datasets/3f83gxmv57/2 \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2135", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2135/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2135/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2135/events", "html_url": "https://github.com/tensorflow/datasets/issues/2135", "id": 647646980, "node_id": "MDU6SXNzdWU2NDc2NDY5ODA=", "number": 2135, "title": "TFDS just download the tfrecord", "user": {"login": "tommywei110", "id": 12221646, "node_id": "MDQ6VXNlcjEyMjIxNjQ2", "avatar_url": "https://avatars3.githubusercontent.com/u/12221646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tommywei110", "html_url": "https://github.com/tommywei110", "followers_url": "https://api.github.com/users/tommywei110/followers", "following_url": "https://api.github.com/users/tommywei110/following{/other_user}", "gists_url": "https://api.github.com/users/tommywei110/gists{/gist_id}", "starred_url": "https://api.github.com/users/tommywei110/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tommywei110/subscriptions", "organizations_url": "https://api.github.com/users/tommywei110/orgs", "repos_url": "https://api.github.com/users/tommywei110/repos", "events_url": "https://api.github.com/users/tommywei110/events{/privacy}", "received_events_url": "https://api.github.com/users/tommywei110/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-29T20:31:57Z", "updated_at": "2020-07-01T17:41:18Z", "closed_at": "2020-07-01T17:41:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I need help with / What I was wondering**\r\nI'm trying to create an API on top of tfds that requires the downloadable to just be the tfrecord.\r\nI wonder if there's way to configure the builder such that it only downloads the tfrecords.\r\n\r\n**What I've tried so far**\r\nLooking at the documentations and searching for solution\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2133", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2133/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2133/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2133/events", "html_url": "https://github.com/tensorflow/datasets/issues/2133", "id": 647567685, "node_id": "MDU6SXNzdWU2NDc1Njc2ODU=", "number": 2133, "title": "[GSoC] Better auto-sharding in multi-worker pipelines", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}, {"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-29T18:08:49Z", "updated_at": "2020-08-18T13:35:23Z", "closed_at": "2020-08-18T13:35:23Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently, when the dataset only has a single shard with many workers (`info.splits['train'].num_shards < read_config.input_context.num_input_pipelines`).\r\nWe're raising an error in: `tensorflow_datasets/core/tfrecords_reader.py`\r\n\r\n```\r\nValueError: Cannot shard the pipeline with given `input_context`.`num_shards=1` but `num_input_pipelines=2`. \r\nThis means that some workers won't read any data. To shard the data, you may want to use the subsplit API\r\ninstead: https://www.tensorflow.org/datasets/splits\r\n```\r\n\r\n```py\r\noptions = tf.data.Options()\r\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\r\n\r\nread_config = tfds.ReadConfig(\r\n   input_context=input_context,\r\n   options=options,\r\n)\r\nds = tfds.builder(..., split='train', read_config=read_config)\r\n```\r\nCurrently, the user should manually use the subsplit API instead: `tfds.load(..., split=f'train[{from_}%:{to}%]')`\r\nWhere `from_` and `to` are different values per workers.\r\n\r\nThis isn't a very user-friendly workflow. We likely should:\r\n\r\n* Provide an util to auto-generate subsplits: `tfds.subsplit('train', num_subsplits=2, subsplit_id=0) == 'train[:50%]')`.\r\n* Auto-apply the subsplit API if `num_shards < num_pipelines` and `input_context` is provided.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2132", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2132/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2132/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2132/events", "html_url": "https://github.com/tensorflow/datasets/issues/2132", "id": 646970388, "node_id": "MDU6SXNzdWU2NDY5NzAzODg=", "number": 2132, "title": "TensorFlow Datasets IMDB reviews dataset page - HTML in the description", "user": {"login": "8bitmp3", "id": 19637339, "node_id": "MDQ6VXNlcjE5NjM3MzM5", "avatar_url": "https://avatars3.githubusercontent.com/u/19637339?v=4", "gravatar_id": "", "url": "https://api.github.com/users/8bitmp3", "html_url": "https://github.com/8bitmp3", "followers_url": "https://api.github.com/users/8bitmp3/followers", "following_url": "https://api.github.com/users/8bitmp3/following{/other_user}", "gists_url": "https://api.github.com/users/8bitmp3/gists{/gist_id}", "starred_url": "https://api.github.com/users/8bitmp3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/8bitmp3/subscriptions", "organizations_url": "https://api.github.com/users/8bitmp3/orgs", "repos_url": "https://api.github.com/users/8bitmp3/repos", "events_url": "https://api.github.com/users/8bitmp3/events{/privacy}", "received_events_url": "https://api.github.com/users/8bitmp3/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 1257633672, "node_id": "MDU6TGFiZWwxMjU3NjMzNjcy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/documentation", "name": "documentation", "color": "fbca04", "default": true, "description": "Pull Request or Issue related with comments or documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-28T17:30:35Z", "updated_at": "2020-06-29T21:34:53Z", "closed_at": "2020-06-29T21:34:44Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "See the rendering at the beginning of the IMDB reviews dataset page: https://www.tensorflow.org/datasets/catalog/imdb_reviews. The source code should be here https://github.com/tensorflow/datasets/blob/master/docs/catalog/imdb_reviews.md\r\n\r\nScreenshot:\r\n\r\n<img width=\"400\" alt=\"image\" src=\"https://user-images.githubusercontent.com/19637339/85954091-f23e5800-b96c-11ea-85b9-c67a3671c782.png\">\r\n\r\n\r\nHTML line affected: \r\n```html\r\n<meta itemprop=\"description\" content=\"Large Movie Review Dataset.&#10;This is a dataset ... ;See [the guide](https://www.tensorflow.org/datasets/overview) for more&#10;informations on [tensorflow_datasets](https://www.tensorflow.org/datasets).&#10;&#10;\" />\r\n```\r\n\r\nI couldn't find a bug by comparing `imdb_reviews.md` to the other raw Markdown files of other datasets at https://github.com/tensorflow/datasets/tree/master/docs/catalog. Can you check on your side?\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2131", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2131/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2131/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2131/events", "html_url": "https://github.com/tensorflow/datasets/issues/2131", "id": 646969629, "node_id": "MDU6SXNzdWU2NDY5Njk2Mjk=", "number": 2131, "title": "Checksum of dataset", "user": {"login": "liubaoryol", "id": 33065573, "node_id": "MDQ6VXNlcjMzMDY1NTcz", "avatar_url": "https://avatars0.githubusercontent.com/u/33065573?v=4", "gravatar_id": "", "url": "https://api.github.com/users/liubaoryol", "html_url": "https://github.com/liubaoryol", "followers_url": "https://api.github.com/users/liubaoryol/followers", "following_url": "https://api.github.com/users/liubaoryol/following{/other_user}", "gists_url": "https://api.github.com/users/liubaoryol/gists{/gist_id}", "starred_url": "https://api.github.com/users/liubaoryol/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/liubaoryol/subscriptions", "organizations_url": "https://api.github.com/users/liubaoryol/orgs", "repos_url": "https://api.github.com/users/liubaoryol/repos", "events_url": "https://api.github.com/users/liubaoryol/events{/privacy}", "received_events_url": "https://api.github.com/users/liubaoryol/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 1052290131, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMx", "url": "https://api.github.com/repos/tensorflow/datasets/labels/duplicate", "name": "duplicate", "color": "cfd3d7", "default": true, "description": "This issue or pull request already exists"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-28T17:26:20Z", "updated_at": "2020-06-29T18:53:08Z", "closed_at": "2020-06-29T03:43:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nChecksum of dataset `cifar10_1` does not match, hindering the download of data. The URL for downloading `cifar10_1` is up and running, so I believe that the data has been updated", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2130", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2130/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2130/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2130/events", "html_url": "https://github.com/tensorflow/datasets/issues/2130", "id": 646642648, "node_id": "MDU6SXNzdWU2NDY2NDI2NDg=", "number": 2130, "title": "Generating split train 3255 examples [1:25:25,  5.69s/ examples]Killed", "user": {"login": "SamuelMarks", "id": 807580, "node_id": "MDQ6VXNlcjgwNzU4MA==", "avatar_url": "https://avatars0.githubusercontent.com/u/807580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SamuelMarks", "html_url": "https://github.com/SamuelMarks", "followers_url": "https://api.github.com/users/SamuelMarks/followers", "following_url": "https://api.github.com/users/SamuelMarks/following{/other_user}", "gists_url": "https://api.github.com/users/SamuelMarks/gists{/gist_id}", "starred_url": "https://api.github.com/users/SamuelMarks/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SamuelMarks/subscriptions", "organizations_url": "https://api.github.com/users/SamuelMarks/orgs", "repos_url": "https://api.github.com/users/SamuelMarks/repos", "events_url": "https://api.github.com/users/SamuelMarks/events{/privacy}", "received_events_url": "https://api.github.com/users/SamuelMarks/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-27T09:03:55Z", "updated_at": "2020-06-29T18:49:21Z", "closed_at": "2020-06-29T18:49:21Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Short description**\r\nI'm using tfds on a private dataset. It works fine on all my other datasets, including ones using all the same code.\r\n\r\nI believe it worked on one of the TensorFlow 2.0 alphas also. Now I'm running into an issue, I've tried on two servers with different CPUs.\r\n\r\n**Environment information**\r\n* Operating System: Debian 4.19.118-2+deb10u1 (2020-06-07) x86_64\r\n* Python version: 3.7.3\r\n* `tensorflow-datasets`/`tfds-nightly` version: 3.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: 2.2.0\r\n\r\n**Reproduction instructions**\r\nI'm using this configuration, which you can use for the `refuge` dataset or any other dataset (think of this like a AOT version of [`tf.keras.preprocessing.image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory)):\r\nhttps://github.com/SamuelMarks/ml_prepare/blob/master/ml_prepare/_tfds/base.py\r\n\r\n**Link to logs**\r\n```\r\n2020-06-27 05:37:12 - absl - INFO - Generating dataset bmes (/mnt/tensorflow_datasets/downloads/tensorflow_datasets/bmes/2.0.0)\r\nDownloading and preparing dataset bmes/2.0.0 (download: Unknown size, generated: Unknown size, total: Unknown size) to /mnt/tensorflow_datasets/downloads/tensorflow_datasets/bmes/2.0.0...\r\n2020-06-27 05:37:12 - absl - INFO - Generating split valid\r\n0 examples [00:00, ? examples/s]2020-06-27 05:37:13.013174: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-06-27 05:37:13.013227: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-06-27 05:37:13.013251: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ml-params-vm0): /proc/driver/nvidia/version does not exist\r\n2020-06-27 05:37:13.013785: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-06-27 05:37:13.307794: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\r\n2020-06-27 05:37:13.308321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe740000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-27 05:37:13.308368: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n1408 examples [09:17,  1.37 examples/s]resolved all files, now you should delete: '/tmp/dr_spocsk5j239s'\r\nShuffling and writing examples to /mnt/tensorflow_datasets/downloads/tensorflow_datasets/bmes/2.0.0.incomplete584CRG/bmes-valid.tfrecord\r\n  0%|                                                                                                                 | 0/1408 [00:00<?, ? examples/s]2020-06-27 05:46:29 - absl - INFO - Done writing /mnt/tensorflow_datasets/downloads/tensorflow_datasets/bmes/2.0.0.incomplete584CRG/bmes-valid.tfrecord. Shard lengths: [1408]\r\n2020-06-27 05:46:29 - absl - INFO - Generating split train                                                                                            \r\n3255 examples [1:25:25,  5.69s/ examples]Killed\r\n```\r\n\r\nEDIT: Ran it again, it could be an out of memory error, this time it go a tiny bit further (yes, I removed `/mnt/tensorflow_datasets` first:\r\n```\r\n1408 examples [10:15,  1.19 examples/s]resolved all files, now you should delete: '/tmp/bmesy1tq2ha5'\r\nShuffling and writing examples to /mnt/tensorflow_datasets/bmes/2.0.0.incompleteUXSE9J/bmes-valid.tfrecord\r\n  0%|                                                                                                                 | 0/1408 [00:00<?, ? examples/s]2020-06-27 11:07:16 - absl - INFO - Done writing /mnt/tensorflow_datasets/bmes/2.0.0.incompleteUXSE9J/bmes-valid.tfrecord. Shard lengths: [1408]\r\n2020-06-27 11:07:16 - absl - INFO - Generating split train                                                                                            \r\n3183 examples [1:38:31,  7.64s/ examples]Killed\r\n```\r\n\r\n**Expected behavior**\r\nNo error, and it all to succeed, or an error and it to fail.\r\n\r\n**Additional context**\r\nMaybe there is a debug environment variable or configuration I can set, to give me more information than the `Killed` message I receive after ~90 minutes? - FYI: There's 14072 images\r\n\r\n```\r\n$ /mnt/tensorflow_datasets/symlinked_datasets/bmes$ for d in *; do\r\n    printf '%s\\t' \"$d\"; find \"$d\" -type l -iname '*.jpg' | wc -l; done\r\ntest\t1407\r\ntrain\t11257\r\nvalid\t1408\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2121", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2121/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2121/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2121/events", "html_url": "https://github.com/tensorflow/datasets/issues/2121", "id": 645761238, "node_id": "MDU6SXNzdWU2NDU3NjEyMzg=", "number": 2121, "title": "kitti tfds checksum error", "user": {"login": "joelbudu", "id": 888508, "node_id": "MDQ6VXNlcjg4ODUwOA==", "avatar_url": "https://avatars0.githubusercontent.com/u/888508?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joelbudu", "html_url": "https://github.com/joelbudu", "followers_url": "https://api.github.com/users/joelbudu/followers", "following_url": "https://api.github.com/users/joelbudu/following{/other_user}", "gists_url": "https://api.github.com/users/joelbudu/gists{/gist_id}", "starred_url": "https://api.github.com/users/joelbudu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joelbudu/subscriptions", "organizations_url": "https://api.github.com/users/joelbudu/orgs", "repos_url": "https://api.github.com/users/joelbudu/repos", "events_url": "https://api.github.com/users/joelbudu/events{/privacy}", "received_events_url": "https://api.github.com/users/joelbudu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-06-25T18:19:16Z", "updated_at": "2020-06-25T18:43:48Z", "closed_at": "2020-06-25T18:43:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nI'm getting an error when trying to download the kitti dataset from tfdf using the following command:\r\n```ds = tfds.load('kitti', split='train')```\r\n\r\n**Environment information**\r\n* Operating System: <os>\r\n* Python version: Python 3\r\n* `tensorflow-datasets` version: 2.1.0\r\n* `tensorflow` version: 2.1\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\npip install tensorflow-datasets\r\nimport tensorflow_datasets as tfds\r\n\r\nds = tfds.load('kitti', split='train')\r\n```\r\n\r\n\r\n**Expected behavior**\r\nExpected the files to download successfully \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2115", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2115/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2115/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2115/events", "html_url": "https://github.com/tensorflow/datasets/issues/2115", "id": 644042980, "node_id": "MDU6SXNzdWU2NDQwNDI5ODA=", "number": 2115, "title": "tfds not returning tf.data.Dataset object?", "user": {"login": "abhinavsp0730", "id": 43638955, "node_id": "MDQ6VXNlcjQzNjM4OTU1", "avatar_url": "https://avatars1.githubusercontent.com/u/43638955?v=4", "gravatar_id": "", "url": "https://api.github.com/users/abhinavsp0730", "html_url": "https://github.com/abhinavsp0730", "followers_url": "https://api.github.com/users/abhinavsp0730/followers", "following_url": "https://api.github.com/users/abhinavsp0730/following{/other_user}", "gists_url": "https://api.github.com/users/abhinavsp0730/gists{/gist_id}", "starred_url": "https://api.github.com/users/abhinavsp0730/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/abhinavsp0730/subscriptions", "organizations_url": "https://api.github.com/users/abhinavsp0730/orgs", "repos_url": "https://api.github.com/users/abhinavsp0730/repos", "events_url": "https://api.github.com/users/abhinavsp0730/events{/privacy}", "received_events_url": "https://api.github.com/users/abhinavsp0730/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-06-23T18:08:07Z", "updated_at": "2020-07-03T08:42:47Z", "closed_at": "2020-07-03T08:42:47Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "\r\nwhy tfds is not returning tf.data.Dataset object.\r\n\r\nI'm not able to use map function, that I can easily used in  tf.data.Dataset.\r\n```\r\ndef res_img(img, lbl):\r\n  return tf.cast(img, tf.float32)/255., lbl\r\ntrain.map(res_img)\r\n\r\n```\r\n\r\nGetting the following error:\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-10-bd20e19a7769> in <module>()\r\n----> 1 train.map(res_img)\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    263       except Exception as e:  # pylint:disable=broad-except\r\n    264         if hasattr(e, 'ag_error_metadata'):\r\n--> 265           raise e.ag_error_metadata.to_exception(e)\r\n    266         else:\r\n    267           raise\r\n\r\nTypeError: in user code:\r\n\r\n\r\n    TypeError: tf__res_img() missing 1 required positional argument: 'lbl'", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2113", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2113/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2113/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2113/events", "html_url": "https://github.com/tensorflow/datasets/issues/2113", "id": 643597987, "node_id": "MDU6SXNzdWU2NDM1OTc5ODc=", "number": 2113, "title": "download_kaggle_data() fails", "user": {"login": "sharanramjee", "id": 26339982, "node_id": "MDQ6VXNlcjI2MzM5OTgy", "avatar_url": "https://avatars3.githubusercontent.com/u/26339982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sharanramjee", "html_url": "https://github.com/sharanramjee", "followers_url": "https://api.github.com/users/sharanramjee/followers", "following_url": "https://api.github.com/users/sharanramjee/following{/other_user}", "gists_url": "https://api.github.com/users/sharanramjee/gists{/gist_id}", "starred_url": "https://api.github.com/users/sharanramjee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sharanramjee/subscriptions", "organizations_url": "https://api.github.com/users/sharanramjee/orgs", "repos_url": "https://api.github.com/users/sharanramjee/repos", "events_url": "https://api.github.com/users/sharanramjee/events{/privacy}", "received_events_url": "https://api.github.com/users/sharanramjee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 1052290133, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMz", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help%20wanted", "name": "help wanted", "color": "008672", "default": true, "description": "Extra attention is needed"}], "state": "closed", "locked": false, "assignee": {"login": "sharanramjee", "id": 26339982, "node_id": "MDQ6VXNlcjI2MzM5OTgy", "avatar_url": "https://avatars3.githubusercontent.com/u/26339982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sharanramjee", "html_url": "https://github.com/sharanramjee", "followers_url": "https://api.github.com/users/sharanramjee/followers", "following_url": "https://api.github.com/users/sharanramjee/following{/other_user}", "gists_url": "https://api.github.com/users/sharanramjee/gists{/gist_id}", "starred_url": "https://api.github.com/users/sharanramjee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sharanramjee/subscriptions", "organizations_url": "https://api.github.com/users/sharanramjee/orgs", "repos_url": "https://api.github.com/users/sharanramjee/repos", "events_url": "https://api.github.com/users/sharanramjee/events{/privacy}", "received_events_url": "https://api.github.com/users/sharanramjee/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sharanramjee", "id": 26339982, "node_id": "MDQ6VXNlcjI2MzM5OTgy", "avatar_url": "https://avatars3.githubusercontent.com/u/26339982?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sharanramjee", "html_url": "https://github.com/sharanramjee", "followers_url": "https://api.github.com/users/sharanramjee/followers", "following_url": "https://api.github.com/users/sharanramjee/following{/other_user}", "gists_url": "https://api.github.com/users/sharanramjee/gists{/gist_id}", "starred_url": "https://api.github.com/users/sharanramjee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sharanramjee/subscriptions", "organizations_url": "https://api.github.com/users/sharanramjee/orgs", "repos_url": "https://api.github.com/users/sharanramjee/repos", "events_url": "https://api.github.com/users/sharanramjee/events{/privacy}", "received_events_url": "https://api.github.com/users/sharanramjee/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2020-06-23T07:23:30Z", "updated_at": "2020-07-01T00:22:08Z", "closed_at": "2020-07-01T00:22:08Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Short description**\r\ndownload_kaggle_data() fails if there are a lot of files to be downloaded.\r\nEx: Attempting to download the [money species dataset](https://www.kaggle.com/slothkong/10-monkey-species) results in an error with the following error message: \"429 - Too Many Requests\" despite it being a reasonably small dataset with not a lot of files\r\n\r\n**Environment information**\r\n* Operating System: Windows 10\r\n* Python version: 3.7.2\r\n* `tensorflow-datasets`/`tfds-nightly` version: tensorflow-datasets 3.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: tensorflow 2.2.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\npath = dl_manager.download_kaggle_data('slothkong/10-monkey-species')\r\n```\r\n\r\n**Link to logs**\r\nhttps://gist.github.com/sharanramjee/6a7eb94f806c2e39d114a660af81dfee\r\n\r\n**Expected behavior**\r\nExpected to download the dataset from kaggle and proceed with TFDS dataset preparation\r\n\r\n**Additional context**\r\nNeed to install kaggle API and set up CLI authentication as described [here](https://www.kaggle.com/docs/api) in order to use download_kaggle_data()\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2109", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2109/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2109/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2109/events", "html_url": "https://github.com/tensorflow/datasets/issues/2109", "id": 643107826, "node_id": "MDU6SXNzdWU2NDMxMDc4MjY=", "number": 2109, "title": "NonMatchingChecksumError with tfds.load on GCP ", "user": {"login": "yashjakhotiya", "id": 26331636, "node_id": "MDQ6VXNlcjI2MzMxNjM2", "avatar_url": "https://avatars0.githubusercontent.com/u/26331636?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yashjakhotiya", "html_url": "https://github.com/yashjakhotiya", "followers_url": "https://api.github.com/users/yashjakhotiya/followers", "following_url": "https://api.github.com/users/yashjakhotiya/following{/other_user}", "gists_url": "https://api.github.com/users/yashjakhotiya/gists{/gist_id}", "starred_url": "https://api.github.com/users/yashjakhotiya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yashjakhotiya/subscriptions", "organizations_url": "https://api.github.com/users/yashjakhotiya/orgs", "repos_url": "https://api.github.com/users/yashjakhotiya/repos", "events_url": "https://api.github.com/users/yashjakhotiya/events{/privacy}", "received_events_url": "https://api.github.com/users/yashjakhotiya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-06-22T14:14:53Z", "updated_at": "2020-06-23T08:35:36Z", "closed_at": "2020-06-23T08:35:36Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\ntfds.load returns NonMatchingChecksumError when used on a GCP hosted Jupyter Server. There is no issue with the same dataset if I run tfds.load on my local machine.\r\n\r\n**Environment information**\r\n* Operating System: Ubuntu 18.04\r\n* Python version: 3.6.9\r\n* `tensorflow-datasets`/`tfds-nightly` version: `tensorflow datasets 3.1.0`\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: `tensorflow 2.1.0`\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\ndataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\r\n                          as_supervised=True)\r\n\r\n```\r\n**Link to logs**\r\nhttps://gist.github.com/yashjakhotiya/d5b7bc7657e7a78eed2b8b492482e8cd\r\n\r\n**Expected behavior**\r\ntfds.load should work on GCP without NonMatchingChecksumError or should point out to actual error.\r\n\r\n**Additional context**\r\nThe Jupyter Notebook is managed by Kubeflow\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2105", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2105/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2105/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2105/events", "html_url": "https://github.com/tensorflow/datasets/issues/2105", "id": 642479858, "node_id": "MDU6SXNzdWU2NDI0Nzk4NTg=", "number": 2105, "title": "GCS utils returns only 1000 files", "user": {"login": "acharles7", "id": 17268094, "node_id": "MDQ6VXNlcjE3MjY4MDk0", "avatar_url": "https://avatars2.githubusercontent.com/u/17268094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acharles7", "html_url": "https://github.com/acharles7", "followers_url": "https://api.github.com/users/acharles7/followers", "following_url": "https://api.github.com/users/acharles7/following{/other_user}", "gists_url": "https://api.github.com/users/acharles7/gists{/gist_id}", "starred_url": "https://api.github.com/users/acharles7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acharles7/subscriptions", "organizations_url": "https://api.github.com/users/acharles7/orgs", "repos_url": "https://api.github.com/users/acharles7/repos", "events_url": "https://api.github.com/users/acharles7/events{/privacy}", "received_events_url": "https://api.github.com/users/acharles7/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-21T02:12:42Z", "updated_at": "2020-07-06T22:02:43Z", "closed_at": "2020-07-06T22:02:43Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, [tensorflow_datasets/core/utils/gcs_utils.py](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/core/utils/gcs_utils.py#L77) uses `requests` to return files from GCP Bucket \r\n\r\n```python\r\ndef gcs_files(prefix_filter=None):\r\n  \"\"\"List all files in GCS bucket.\"\"\"\r\n  top_level_xml_str = download_gcs_file('', prefix_filter=prefix_filter)\r\n  xml_root = ElementTree.fromstring(top_level_xml_str)\r\n  filenames = [el[0].text for el in xml_root if el.tag.endswith('Contents')]\r\n  return filenames\r\n```\r\nThe above function `gcs_files` returns only 1000 objects per request as describe in google [XML_API](https://cloud.google.com/storage/docs/xml-api/get-bucket-list). But there are more than 1000 files in the bucket that we need to complete the whole dataset.\r\n\r\n**Describe the solution you'd like**\r\nWe can iterate (requests) until we get all files using the value of `NextMarker` provided in the `XML Response` for continue listing the Bucket after the set of results\r\n\r\n**Describe alternatives you've considered**\r\nWe can also use `tf.io.gfile`\r\n\r\n**Additional context**\r\n#1938", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2092", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2092/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2092/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2092/events", "html_url": "https://github.com/tensorflow/datasets/issues/2092", "id": 639621404, "node_id": "MDU6SXNzdWU2Mzk2MjE0MDQ=", "number": 2092, "title": "Data set problem", "user": {"login": "ahmadnazeeh", "id": 64912872, "node_id": "MDQ6VXNlcjY0OTEyODcy", "avatar_url": "https://avatars1.githubusercontent.com/u/64912872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahmadnazeeh", "html_url": "https://github.com/ahmadnazeeh", "followers_url": "https://api.github.com/users/ahmadnazeeh/followers", "following_url": "https://api.github.com/users/ahmadnazeeh/following{/other_user}", "gists_url": "https://api.github.com/users/ahmadnazeeh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahmadnazeeh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahmadnazeeh/subscriptions", "organizations_url": "https://api.github.com/users/ahmadnazeeh/orgs", "repos_url": "https://api.github.com/users/ahmadnazeeh/repos", "events_url": "https://api.github.com/users/ahmadnazeeh/events{/privacy}", "received_events_url": "https://api.github.com/users/ahmadnazeeh/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-16T12:22:57Z", "updated_at": "2020-06-25T17:15:05Z", "closed_at": "2020-06-25T17:15:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I need help with / What I was wondering**\r\nI have my own data set in \".csv\" format with 2-columns, I need to use my own data set instead of \"ted_hrlr_translate/pt_to_en\", that is loaded as an example for data set from TED Talks. The code is:\r\n\r\nexamples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\r\n                               as_supervised=True)\r\ntrain_examples, val_examples = examples['train'], examples['validation']\r\n\r\nmy own data set is \" ATB3-all.csv \"\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2087", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2087/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2087/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2087/events", "html_url": "https://github.com/tensorflow/datasets/issues/2087", "id": 638500138, "node_id": "MDU6SXNzdWU2Mzg1MDAxMzg=", "number": 2087, "title": "tarfile.ReadError: bad checksum ImageNet tensorflow dataset", "user": {"login": "martinmamql", "id": 29204081, "node_id": "MDQ6VXNlcjI5MjA0MDgx", "avatar_url": "https://avatars0.githubusercontent.com/u/29204081?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinmamql", "html_url": "https://github.com/martinmamql", "followers_url": "https://api.github.com/users/martinmamql/followers", "following_url": "https://api.github.com/users/martinmamql/following{/other_user}", "gists_url": "https://api.github.com/users/martinmamql/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinmamql/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinmamql/subscriptions", "organizations_url": "https://api.github.com/users/martinmamql/orgs", "repos_url": "https://api.github.com/users/martinmamql/repos", "events_url": "https://api.github.com/users/martinmamql/events{/privacy}", "received_events_url": "https://api.github.com/users/martinmamql/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-15T02:50:14Z", "updated_at": "2020-06-17T20:57:12Z", "closed_at": "2020-06-17T20:57:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I need help with / What I was wondering**\r\nInitialize checksum file when I have ILSVRC2012_img_train.tar and ILSVRC2012_img_val.tar\r\n\r\n**What I've tried so far**\r\nI have followed https://www.tensorflow.org/datasets/catalog/imagenet2012 and put the two archive files ILSVRC2012_img_train.tar and ILSVRC2012_img_val.tar to the corresponding directory. Then the error\r\n`tarfile.ReadError: bad checksum`\r\noccurs.\r\nAfter adding the following lines to try to initialize the checksum file:\r\n```\r\nchecksum_dir = os.path.join(os.path.dirname(__file__), '/home/martin_ma_mql/tensorflow_datasets/downloads/manual/checksu$\r\n  checksum_dir = os.path.normpath(checksum_dir)\r\n  # Add the checksum dir (will be executed when the user import your dataset)\r\n  tfds.download.add_checksums_dir(checksum_dir)\r\n  builder = tfds.builder(FLAGS.dataset, data_dir=FLAGS.data_dir)\r\n  dl_config = tfds.download.DownloadConfig(register_checksums=True)\r\n  builder.download_and_prepare(download_config=dl_config)\r\n```\r\n\r\nThe error persists.\r\n\r\nFull error message:\r\n```\r\nWARNING:tensorflow:From /home/martin_ma_mql/simclr/resnet.py:38: The name tf.layers.BatchNormalization is deprecated. Pleas\r\ne use tf.compat.v1.layers.BatchNormalization instead.\r\nI0615 02:39:01.717853 139708827453184 dataset_info.py:430] Load pre-computed DatasetInfo (eg: splits, num examples,...) fro\r\nm GCS: imagenet2012/5.0.0\r\nI0615 02:39:01.762809 139708827453184 dataset_info.py:361] Load dataset info from /tmp/tmpjzvgtj2_tfds\r\nI0615 02:39:01.768465 139708827453184 dataset_info.py:401] Field info.description from disk and from code do not match. Kee\r\nping the one from code.\r\nI0615 02:39:01.768634 139708827453184 dataset_info.py:401] Field info.citation from disk and from code do not match. Keepin\r\ng the one from code.\r\nI0615 02:39:01.769159 139708827453184 dataset_builder.py:333] Generating dataset imagenet2012 (/home/martin_ma_mql/tensorfl\r\now_datasets/imagenet2012/5.0.0)\r\nDownloading and preparing dataset imagenet2012/5.0.0 (download: 144.02 GiB, generated: Unknown size, total: 144.02 GiB) to \r\n/home/martin_ma_mql/tensorflow_datasets/imagenet2012/5.0.0...\r\nI0615 02:39:08.569597 139708827453184 dataset_builder.py:924] Generating split train\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/tarfile.py\", line 2281, in next\r\n    tarinfo = self.tarinfo.fromtarfile(self)\r\n  File \"/usr/lib/python3.5/tarfile.py\", line 1083, in fromtarfile\r\n    obj = cls.frombuf(buf, tarfile.encoding, tarfile.errors)\r\n  File \"/usr/lib/python3.5/tarfile.py\", line 1027, in frombuf\r\n    raise InvalidHeaderError(\"bad checksum\")\r\ntarfile.InvalidHeaderError: bad checksum\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"run.py\", line 427, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/lib/python3.5/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"run.py\", line 347, in main\r\n    builder.download_and_prepare(download_config=dl_config)\r\n  File \"/home/martin_ma_mql/.local/lib/python3.5/site-packages/tensorflow_datasets/core/api_utils.py\", line 69, in disallow\r\n_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/home/martin_ma_mql/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 363, in d\r\nownload_and_prepare\r\n    download_config=download_config)\r\n  File \"/home/martin_ma_mql/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 996, in _\r\ndownload_and_prepare\r\n    max_examples_per_split=download_config.max_examples_per_split,\r\n  File \"/home/martin_ma_mql/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 928, in _\r\ndownload_and_prepare\r\n    self._prepare_split(split_generator, **prepare_split_kwargs)\r\n  File \"/home/martin_ma_mql/.local/lib/python3.5/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 1011, in \r\n_prepare_split\r\n    total=split_info.num_examples, leave=False):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tqdm/std.py\", line 1129, in __iter__\r\n    for obj in iterable:\r\n  File \"/home/martin_ma_mql/.local/lib/python3.5/site-packages/tensorflow_datasets/image_classification/imagenet.py\", line \r\n195, in _generate_examples\r\n    fobj_mem, tfds.download.ExtractMethod.TAR_STREAM):\r\n  File \"/home/martin_ma_mql/.local/lib/python3.5/site-packages/tensorflow_datasets/core/download/extractor.py\", line 163, i\r\nn iter_tar\r\n    tar = tarfile.open(mode=read_type, fileobj=fobj)\r\n  File \"/usr/lib/python3.5/tarfile.py\", line 1589, in open\r\n    t = cls(name, filemode, stream, **kwargs)\r\n  File \"/usr/lib/python3.5/tarfile.py\", line 1470, in __init__\r\n    self.firstmember = self.next()\r\n  File \"/usr/lib/python3.5/tarfile.py\", line 2293, in next\r\n    raise ReadError(str(e))\r\ntarfile.ReadError: bad checksum\r\n```\r\n\r\n**It would be nice if...**\r\nSince the official documentation says that we need to pre-download, after downloading step how may we proceed to initialize the checksum to avoid the error?\r\n\r\n**Environment information**\r\n(if applicable)\r\n* Operating System: Debian GNU/Linux 9 on Google Cloud n1-standard-2\r\n* Python version: 3.5.3\r\n* `tensorflow-datasets`/`tfds-nightly` version: 3.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: 1.15.2\r\n\r\nThank you so much for your great patience and help!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2086", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2086/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2086/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2086/events", "html_url": "https://github.com/tensorflow/datasets/issues/2086", "id": 637371968, "node_id": "MDU6SXNzdWU2MzczNzE5Njg=", "number": 2086, "title": "[data request] <ImageNet>", "user": {"login": "garychanchan", "id": 53088844, "node_id": "MDQ6VXNlcjUzMDg4ODQ0", "avatar_url": "https://avatars1.githubusercontent.com/u/53088844?v=4", "gravatar_id": "", "url": "https://api.github.com/users/garychanchan", "html_url": "https://github.com/garychanchan", "followers_url": "https://api.github.com/users/garychanchan/followers", "following_url": "https://api.github.com/users/garychanchan/following{/other_user}", "gists_url": "https://api.github.com/users/garychanchan/gists{/gist_id}", "starred_url": "https://api.github.com/users/garychanchan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/garychanchan/subscriptions", "organizations_url": "https://api.github.com/users/garychanchan/orgs", "repos_url": "https://api.github.com/users/garychanchan/repos", "events_url": "https://api.github.com/users/garychanchan/events{/privacy}", "received_events_url": "https://api.github.com/users/garychanchan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168524723, "node_id": "MDU6TGFiZWwxMTY4NTI0NzIz", "url": "https://api.github.com/repos/tensorflow/datasets/labels/dataset%20request", "name": "dataset request", "color": "beb7ff", "default": false, "description": "Request for a new dataset to be added"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-11T23:03:39Z", "updated_at": "2020-06-12T17:13:12Z", "closed_at": "2020-06-12T17:11:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "* Name of dataset: <name>\r\n* URL of dataset: <url>\r\n* License of dataset: <license type>\r\n* Short description of dataset and use case(s): <description>\r\n\r\nFolks who would also like to see this dataset in `tensorflow/datasets`, please thumbs-up so the developers can know which requests to prioritize.\r\n\r\nAnd if you'd like to contribute the dataset (thank you!), see our [guide to adding a dataset](https://github.com/tensorflow/datasets/blob/master/docs/add_dataset.md).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2081", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2081/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2081/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2081/events", "html_url": "https://github.com/tensorflow/datasets/issues/2081", "id": 635921386, "node_id": "MDU6SXNzdWU2MzU5MjEzODY=", "number": 2081, "title": "UnicodeDecodeError: 'utf-8' codec can't decode byte ~", "user": {"login": "NohHaklim", "id": 62823216, "node_id": "MDQ6VXNlcjYyODIzMjE2", "avatar_url": "https://avatars0.githubusercontent.com/u/62823216?v=4", "gravatar_id": "", "url": "https://api.github.com/users/NohHaklim", "html_url": "https://github.com/NohHaklim", "followers_url": "https://api.github.com/users/NohHaklim/followers", "following_url": "https://api.github.com/users/NohHaklim/following{/other_user}", "gists_url": "https://api.github.com/users/NohHaklim/gists{/gist_id}", "starred_url": "https://api.github.com/users/NohHaklim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/NohHaklim/subscriptions", "organizations_url": "https://api.github.com/users/NohHaklim/orgs", "repos_url": "https://api.github.com/users/NohHaklim/repos", "events_url": "https://api.github.com/users/NohHaklim/events{/privacy}", "received_events_url": "https://api.github.com/users/NohHaklim/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-10T04:39:08Z", "updated_at": "2020-06-11T11:11:19Z", "closed_at": "2020-06-11T11:11:18Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I need help with / What I was wondering**\r\nwhen i study this tutorial: https://www.tensorflow.org/tutorials/generative/cyclegan, error occured.\r\nif load 'cycle_gan/horse2zebra' no problem occur, but use 'monet2photo', 'cezanne2photo',... same problem occured. \r\n```\r\ndataset, metadata = tfds.load('cycle_gan/monet2photo',\r\n                              with_info=True, as_supervised=True)\r\n```\r\ni had swiched tensorflow 2.0.0 but not solved.\r\nHow to solve this problem??\r\n\r\ntraceback:\r\n```\r\nUnicodeDecodeErrorTraceback (most recent call last)\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\download\\extractor.py in _sync_extract(self, from_path, method, to_path)\r\n     95         dst_path = path and os.path.join(to_path_tmp, path) or to_path_tmp\r\n---> 96         _copy(handle, dst_path)\r\n     97     except BaseException as err:\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\download\\extractor.py in _copy(src_file, dest_path)\r\n    125         break\r\n--> 126       dest_file.write(data)\r\n    127 \r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in write(self, file_content)\r\n    100     \"\"\"Writes file_content to the file. Appends to the end of the file.\"\"\"\r\n--> 101     self._prewrite_check()\r\n    102     self._writable_file.append(compat.as_bytes(file_content))\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in _prewrite_check(self)\r\n     86       self._writable_file = _pywrap_file_io.WritableFile(\r\n---> 87           compat.as_bytes(self.__name), compat.as_bytes(self.__mode))\r\n     88 \r\n\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc6 in position 275: invalid continuation byte\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nExtractErrorTraceback (most recent call last)\r\n<ipython-input-7-9a8969b34ad3> in <module>\r\n----> 1 dataset = tfds.load('cycle_gan/monet2photo')\r\n      2 \r\n      3 train_horses, train_zebras = dataset['trainA'], dataset['trainB']\r\n      4 test_horses, test_zebras = dataset['testA'], dataset['testB']\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     67     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     68     _check_required(fn, kwargs)\r\n---> 69     return fn(*args, **kwargs)\r\n     70 \r\n     71   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py in load(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\r\n    367   if download:\r\n    368     download_and_prepare_kwargs = download_and_prepare_kwargs or {}\r\n--> 369     dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n    370 \r\n    371   if as_dataset_kwargs is None:\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     67     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     68     _check_required(fn, kwargs)\r\n---> 69     return fn(*args, **kwargs)\r\n     70 \r\n     71   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in download_and_prepare(self, download_dir, download_config)\r\n    361           self._download_and_prepare(\r\n    362               dl_manager=dl_manager,\r\n--> 363               download_config=download_config)\r\n    364 \r\n    365           # NOTE: If modifying the lines below to put additional information in\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in _download_and_prepare(self, dl_manager, download_config)\r\n    994     super(GeneratorBasedBuilder, self)._download_and_prepare(\r\n    995         dl_manager=dl_manager,\r\n--> 996         max_examples_per_split=download_config.max_examples_per_split,\r\n    997     )\r\n    998 \r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in _download_and_prepare(self, dl_manager, **prepare_split_kwargs)\r\n    914         prepare_split_kwargs)\r\n    915     for split_generator in self._split_generators(\r\n--> 916         dl_manager, **split_generators_kwargs):\r\n    917       if str(split_generator.split_info.name).lower() == \"all\":\r\n    918         raise ValueError(\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\image_classification\\cycle_gan.py in _split_generators(self, dl_manager)\r\n    110     \"\"\"Returns SplitGenerators.\"\"\"\r\n    111     url = _DL_URLS[self.builder_config.name]\r\n--> 112     data_dirs = dl_manager.download_and_extract(url)\r\n    113 \r\n    114     path_to_dataset = os.path.join(data_dirs, tf.io.gfile.listdir(data_dirs)[0])\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py in download_and_extract(self, url_or_urls)\r\n    417     with self._downloader.tqdm():\r\n    418       with self._extractor.tqdm():\r\n--> 419         return _map_promise(self._download_extract, url_or_urls)\r\n    420 \r\n    421   @property\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py in _map_promise(map_fn, all_inputs)\r\n    460   \"\"\"Map the function into each element and resolve the promise.\"\"\"\r\n    461   all_promises = utils.map_nested(map_fn, all_inputs)  # Apply the function\r\n--> 462   res = utils.map_nested(_wait_on_promise, all_promises)\r\n    463   return res\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py in map_nested(function, data_struct, dict_only, map_tuple)\r\n    165         return tuple(mapped)\r\n    166   # Singleton\r\n--> 167   return function(data_struct)\r\n    168 \r\n    169 \r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py in _wait_on_promise(p)\r\n    444 \r\n    445   def _wait_on_promise(p):\r\n--> 446     return p.get()\r\n    447 \r\n    448 else:\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\promise\\promise.py in get(self, timeout)\r\n    510         target = self._target()\r\n    511         self._wait(timeout or DEFAULT_TIMEOUT)\r\n--> 512         return self._target_settled_value(_raise=True)\r\n    513 \r\n    514     def _target_settled_value(self, _raise=False):\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\promise\\promise.py in _target_settled_value(self, _raise)\r\n    514     def _target_settled_value(self, _raise=False):\r\n    515         # type: (bool) -> Any\r\n--> 516         return self._target()._settled_value(_raise)\r\n    517 \r\n    518     _value = _reason = _target_settled_value\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\promise\\promise.py in _settled_value(self, _raise)\r\n    224             if _raise:\r\n    225                 raise_val = self._fulfillment_handler0\r\n--> 226                 reraise(type(raise_val), raise_val, self._traceback)\r\n    227             return self._fulfillment_handler0\r\n    228 \r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\six.py in reraise(tp, value, tb)\r\n    701             if value.__traceback__ is not tb:\r\n    702                 raise value.with_traceback(tb)\r\n--> 703             raise value\r\n    704         finally:\r\n    705             value = None\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\promise\\promise.py in handle_future_result(future)\r\n    842         # type: (Any) -> None\r\n    843         try:\r\n--> 844             resolve(future.result())\r\n    845         except Exception as e:\r\n    846             tb = exc_info()[2]\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\concurrent\\futures\\_base.py in result(self, timeout)\r\n    426                 raise CancelledError()\r\n    427             elif self._state == FINISHED:\r\n--> 428                 return self.__get_result()\r\n    429 \r\n    430             self._condition.wait(timeout)\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\concurrent\\futures\\_base.py in __get_result(self)\r\n    382     def __get_result(self):\r\n    383         if self._exception:\r\n--> 384             raise self._exception\r\n    385         else:\r\n    386             return self._result\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\concurrent\\futures\\thread.py in run(self)\r\n     55 \r\n     56         try:\r\n---> 57             result = self.fn(*self.args, **self.kwargs)\r\n     58         except BaseException as exc:\r\n     59             self.future.set_exception(exc)\r\n\r\nc:\\users\\lenovo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_datasets\\core\\download\\extractor.py in _sync_extract(self, from_path, method, to_path)\r\n    106             'https://docs.python.org/3/using/windows.html#removing-the-max-path-limitation'\r\n    107         )\r\n--> 108       raise ExtractError(msg)\r\n    109     # `tf.io.gfile.Rename(overwrite=True)` doesn't work for non empty\r\n    110     # directories, so delete destination first, if it already exists.\r\n\r\nExtractError: Error while extracting C:\\Users\\Lenovo\\tensorflow_datasets\\downloads\\peop.eecs.berk.edu_taes_park_Cycl_data_moniPkbAPwij5fJQR-_GIDsHRGcmPFyLkz8-qL7NfrAWwQ.zip to C:\\Users\\Lenovo\\tensorflow_datasets\\downloads\\extracted\\ZIP.peop.eecs.berk.edu_taes_park_Cycl_data_moniPkbAPwij5fJQR-_GIDsHRGcmPFyLkz8-qL7NfrAWwQ.zip (file: monet2photo\\testB\\2014-12-10 12:08:40.jpg) : 'utf-8' codec can't decode byte 0xc6 in position 275: invalid continuation byte\r\n```\r\n**Environment information**\r\n(if applicable)\r\n* Operating System:  windows10\r\n* Python version: <3.7>\r\n* `tensorflow-datasets`/`tfds-nightly` version: <3.1.0, / 3.1.0.dev202006090106>\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: <2.2 / 1.15.2 / . / .>\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2078", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2078/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2078/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2078/events", "html_url": "https://github.com/tensorflow/datasets/issues/2078", "id": 634239536, "node_id": "MDU6SXNzdWU2MzQyMzk1MzY=", "number": 2078, "title": "ValueError while using ReadInstruction API", "user": {"login": "bosecodes", "id": 39362431, "node_id": "MDQ6VXNlcjM5MzYyNDMx", "avatar_url": "https://avatars0.githubusercontent.com/u/39362431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bosecodes", "html_url": "https://github.com/bosecodes", "followers_url": "https://api.github.com/users/bosecodes/followers", "following_url": "https://api.github.com/users/bosecodes/following{/other_user}", "gists_url": "https://api.github.com/users/bosecodes/gists{/gist_id}", "starred_url": "https://api.github.com/users/bosecodes/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bosecodes/subscriptions", "organizations_url": "https://api.github.com/users/bosecodes/orgs", "repos_url": "https://api.github.com/users/bosecodes/repos", "events_url": "https://api.github.com/users/bosecodes/events{/privacy}", "received_events_url": "https://api.github.com/users/bosecodes/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-06-08T06:40:35Z", "updated_at": "2020-06-08T18:02:42Z", "closed_at": "2020-06-08T18:01:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nValueError while using ReadInstruction API\r\n**Environment information**\r\n* Operating System: Pop OS (Ubuntu : Linux)\r\n* Python version: 3.7\r\n* Tensorflow-datasets version 3.1.0 \r\n* Tensorflow-GPU version 2.0.0\r\n\r\n**Reproduction instructions**\r\n\r\n```py\r\ntrain_ds = tfds.load('mnist', split=tfds.core.ReadInstruction('train'))\r\n\r\ntrain_ds, test_ds = tfds.load('mnist', split=[\r\n    tfds.core.ReadInstruction('train'),\r\n    tfds.core.ReadInstruction('test'),\r\n])\r\n\r\nri = tfds.core.ReadInstruction('train') + tfds.core.ReadInstruction('test')\r\ntrain_test_ds = tfds.load('mnist', split=ri)\r\n\r\ntrain_10_20_ds = tfds.load('mnist', split=tfds.core.ReadInstruction(\r\n    'train', from_=10, to=20, unit='abs'))\r\n\r\ntrain_10_20_ds = tfds.load('mnist', split=tfds.core.ReadInstruction(\r\n    'train', to=10, unit='%'))\r\n\r\nri = (tfds.core.ReadInstruction('train', to=10, unit='%') +\r\n      tfds.core.ReadInstruction('train', from_=-80, unit='%'))\r\ntrain_10_80pct_ds = tfds.load('mnist', split=ri)\r\n\r\nvals_ds = tfds.load('mnist', [\r\n    tfds.core.ReadInstruction('train', from_=k, to=k+10, unit='%')\r\n    for k in range(0, 100, 10)])\r\ntrains_ds = tfds.load('mnist', [\r\n    (tfds.core.ReadInstruction('train', to=k, unit='%') +\r\n     tfds.core.ReadInstruction('train', from_=k+10, unit='%'))\r\n    for k in range(0, 100, 10)])\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-8-6dc8b00bbebf> in <module>\r\n     34 vals_ds = tfds.load('mnist', [\r\n     35     tfds.core.ReadInstruction('train', from_=k, to=k+10, unit='%')\r\n---> 36     for k in range(0, 100, 10)])\r\n     37 trains_ds = tfds.load('mnist', [\r\n     38     (tfds.core.ReadInstruction('train', to=k, unit='%') +\r\n\r\n~/anaconda3/envs/gputest/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     65   def disallow_positional_args_dec(fn, instance, args, kwargs):\r\n     66     ismethod = instance is not None\r\n---> 67     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     68     _check_required(fn, kwargs)\r\n     69     return fn(*args, **kwargs)\r\n\r\n~/anaconda3/envs/gputest/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py in _check_no_positional(fn, args, is_method, allowed)\r\n     79     if all([name in allowed for name in arg_names]):\r\n     80       return\r\n---> 81     raise ValueError(_POSITIONAL_ARG_ERR_MSG % (fn.__name__, str(arg_names)))\r\n     82 \r\n     83 \r\n\r\nValueError: Please use keyword arguments and not positional arguments. This enables more flexible API development. Thank you!\r\nPositional arguments passed to fn load: ['name', 'split'].\r\n---------------------------------------------------------------------------\r\n```\r\n**Expected behavior**\r\nThe Slicing should have worked as simple as using the Simple String API approach.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2077", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2077/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2077/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2077/events", "html_url": "https://github.com/tensorflow/datasets/issues/2077", "id": 633894270, "node_id": "MDU6SXNzdWU2MzM4OTQyNzA=", "number": 2077, "title": "ImportError: cannot import name 'extract_zipped_paths' from 'requests.utils'", "user": {"login": "louis925", "id": 18520676, "node_id": "MDQ6VXNlcjE4NTIwNjc2", "avatar_url": "https://avatars2.githubusercontent.com/u/18520676?v=4", "gravatar_id": "", "url": "https://api.github.com/users/louis925", "html_url": "https://github.com/louis925", "followers_url": "https://api.github.com/users/louis925/followers", "following_url": "https://api.github.com/users/louis925/following{/other_user}", "gists_url": "https://api.github.com/users/louis925/gists{/gist_id}", "starred_url": "https://api.github.com/users/louis925/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/louis925/subscriptions", "organizations_url": "https://api.github.com/users/louis925/orgs", "repos_url": "https://api.github.com/users/louis925/repos", "events_url": "https://api.github.com/users/louis925/events{/privacy}", "received_events_url": "https://api.github.com/users/louis925/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-06-08T00:05:01Z", "updated_at": "2020-06-18T19:41:19Z", "closed_at": "2020-06-18T19:41:19Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nImportError: cannot import name 'extract_zipped_paths' from 'requests.utils'\r\n\r\n**Environment information**\r\n* Operating System: Windows 10 Pro 64bits\r\n* Python version: 3.7.5\r\n* `tensorflow-datasets`/`tfds-nightly` version: tensorflow-datasets 3.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: tensorflow 2.1.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\npip install tensorflow-datasets\r\n```\r\nThis will also install the latest `requests==2.23.0`.\r\n\r\nHowever, it is not compatible with 2.23.0.\r\n```\r\nimport tensorflow_datasets as tfds\r\n```\r\nThis give you\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-30-46a8a2031c9c> in <module>()\r\n----> 1 import tensorflow_datasets as tfds\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_datasets\\__init__.py in <module>()\r\n     44 # needs to happen before anything else, since the imports below will try to\r\n     45 # import tensorflow, too.\r\n---> 46 from tensorflow_datasets.core import tf_compat\r\n     47 tf_compat.ensure_tf_install()\r\n     48 \r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py in <module>()\r\n     21 tf_compat.ensure_tf_install()\r\n     22 \r\n---> 23 from tensorflow_datasets.core.dataset_builder import BeamBasedBuilder  # pylint:disable=g-import-not-at-top\r\n     24 from tensorflow_datasets.core.dataset_builder import BuilderConfig\r\n     25 from tensorflow_datasets.core.dataset_builder import DatasetBuilder\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in <module>()\r\n     33 from tensorflow_datasets.core import constants\r\n     34 from tensorflow_datasets.core import dataset_utils\r\n---> 35 from tensorflow_datasets.core import download\r\n     36 from tensorflow_datasets.core import file_format_adapter\r\n     37 from tensorflow_datasets.core import lazy_imports_lib\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\__init__.py in <module>()\r\n     17 \r\n     18 from tensorflow_datasets.core.download.checksums import add_checksums_dir\r\n---> 19 from tensorflow_datasets.core.download.download_manager import DownloadConfig\r\n     20 from tensorflow_datasets.core.download.download_manager import DownloadManager\r\n     21 from tensorflow_datasets.core.download.extractor import iter_archive\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py in <module>()\r\n     32 from tensorflow_datasets.core import utils\r\n     33 from tensorflow_datasets.core.download import checksums\r\n---> 34 from tensorflow_datasets.core.download import downloader\r\n     35 from tensorflow_datasets.core.download import extractor\r\n     36 from tensorflow_datasets.core.download import resource as resource_lib\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py in <module>()\r\n     31 import promise\r\n     32 import requests\r\n---> 33 from requests.utils import extract_zipped_paths\r\n     34 from six.moves import urllib\r\n     35 import tensorflow as tf\r\n\r\nImportError: cannot import name 'extract_zipped_paths'\r\n```\r\n**Link to logs**\r\nIf applicable, <link to gist with logs, stack trace>\r\n\r\n**Expected behavior**\r\nLimit the `request==2.21.0` in the `setup.py` of tensorflow-datasets pip installation script so it can be properly import.\r\n\r\n**Additional context**\r\nThe current `tensorflow-datasets` package is not compatible with the latest `requests==2.23.0` package but only compatible with `2.21.0`. However, the `tensorflow-datasets` didn't specify the upper compatible version, which cause new user not able to import the package properly.\r\n\r\nSee also: https://stackoverflow.com/questions/57890219/importerror-cannot-import-name-extract-zipped-paths", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2067", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2067/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2067/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2067/events", "html_url": "https://github.com/tensorflow/datasets/issues/2067", "id": 628765159, "node_id": "MDU6SXNzdWU2Mjg3NjUxNTk=", "number": 2067, "title": "New Image Folder dataset", "user": {"login": "vijayphoenix", "id": 41972768, "node_id": "MDQ6VXNlcjQxOTcyNzY4", "avatar_url": "https://avatars3.githubusercontent.com/u/41972768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vijayphoenix", "html_url": "https://github.com/vijayphoenix", "followers_url": "https://api.github.com/users/vijayphoenix/followers", "following_url": "https://api.github.com/users/vijayphoenix/following{/other_user}", "gists_url": "https://api.github.com/users/vijayphoenix/gists{/gist_id}", "starred_url": "https://api.github.com/users/vijayphoenix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vijayphoenix/subscriptions", "organizations_url": "https://api.github.com/users/vijayphoenix/orgs", "repos_url": "https://api.github.com/users/vijayphoenix/repos", "events_url": "https://api.github.com/users/vijayphoenix/events{/privacy}", "received_events_url": "https://api.github.com/users/vijayphoenix/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": {"login": "vijayphoenix", "id": 41972768, "node_id": "MDQ6VXNlcjQxOTcyNzY4", "avatar_url": "https://avatars3.githubusercontent.com/u/41972768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vijayphoenix", "html_url": "https://github.com/vijayphoenix", "followers_url": "https://api.github.com/users/vijayphoenix/followers", "following_url": "https://api.github.com/users/vijayphoenix/following{/other_user}", "gists_url": "https://api.github.com/users/vijayphoenix/gists{/gist_id}", "starred_url": "https://api.github.com/users/vijayphoenix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vijayphoenix/subscriptions", "organizations_url": "https://api.github.com/users/vijayphoenix/orgs", "repos_url": "https://api.github.com/users/vijayphoenix/repos", "events_url": "https://api.github.com/users/vijayphoenix/events{/privacy}", "received_events_url": "https://api.github.com/users/vijayphoenix/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "vijayphoenix", "id": 41972768, "node_id": "MDQ6VXNlcjQxOTcyNzY4", "avatar_url": "https://avatars3.githubusercontent.com/u/41972768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vijayphoenix", "html_url": "https://github.com/vijayphoenix", "followers_url": "https://api.github.com/users/vijayphoenix/followers", "following_url": "https://api.github.com/users/vijayphoenix/following{/other_user}", "gists_url": "https://api.github.com/users/vijayphoenix/gists{/gist_id}", "starred_url": "https://api.github.com/users/vijayphoenix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vijayphoenix/subscriptions", "organizations_url": "https://api.github.com/users/vijayphoenix/orgs", "repos_url": "https://api.github.com/users/vijayphoenix/repos", "events_url": "https://api.github.com/users/vijayphoenix/events{/privacy}", "received_events_url": "https://api.github.com/users/vijayphoenix/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2020-06-01T22:20:37Z", "updated_at": "2020-06-20T22:51:00Z", "closed_at": "2020-06-20T22:51:00Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently, TFDS has a [tfds.image.ImageLabelFolder](https://www.tensorflow.org/datasets/catalog/image_label_folder) class which creates a dataset from a folder of images. However, the current API feels confusing and boilerplate.\r\n\r\n**Describe the solution you'd like**\r\n\r\nWe should create a new `ImageFolder` class that should not pre-process the data to TF-Record.\r\nIt would be small util which dynamically loads their images from a folder (No preprocessing, no tf-record, no splits, no versioning, and all other stuff).\r\n\r\nA probable new API could be\r\n```\r\nbuilder = tfds.ImageFolder('/path/to/images')  # Extract the labels,...\r\nds = builder.as_dataset()\r\n```\r\n\r\nImageFolder would not inherit from `tfds.core.GeneratorBasedBuilder`, but directly from `tfds.core.DatasetBuilder.` `FeatureConnectors`, `ClassLabel` could still dynamically be loaded at start time, but not used for decoding.\r\n\r\n**Additional Context**\r\n\r\nSome point to consider:\r\n- Support for split API? \r\nWe should at least allow the user to define Train, Val, Test splits (which will be automatically deduced by the directory structure of ImageFolder).\r\n- What output ? `{'image', 'label', 'image/filename'}` ? \r\nCurrently, ImageLabelFolder is a part of image_classification datasets. So, `label` must be one of the outputs. We can also add a more generic ImageFolder class. Here the output could be `{'image', 'image/filename'}`\r\n- Support for `as_supervised`?\r\n- Support for decode API?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2059", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2059/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2059/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2059/events", "html_url": "https://github.com/tensorflow/datasets/issues/2059", "id": 626570278, "node_id": "MDU6SXNzdWU2MjY1NzAyNzg=", "number": 2059, "title": "Seeing 403 when trying to get \"imdb_reviews\" dataset", "user": {"login": "sunseaandpalms", "id": 58729464, "node_id": "MDQ6VXNlcjU4NzI5NDY0", "avatar_url": "https://avatars3.githubusercontent.com/u/58729464?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sunseaandpalms", "html_url": "https://github.com/sunseaandpalms", "followers_url": "https://api.github.com/users/sunseaandpalms/followers", "following_url": "https://api.github.com/users/sunseaandpalms/following{/other_user}", "gists_url": "https://api.github.com/users/sunseaandpalms/gists{/gist_id}", "starred_url": "https://api.github.com/users/sunseaandpalms/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sunseaandpalms/subscriptions", "organizations_url": "https://api.github.com/users/sunseaandpalms/orgs", "repos_url": "https://api.github.com/users/sunseaandpalms/repos", "events_url": "https://api.github.com/users/sunseaandpalms/events{/privacy}", "received_events_url": "https://api.github.com/users/sunseaandpalms/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-28T14:43:37Z", "updated_at": "2020-05-30T08:06:39Z", "closed_at": "2020-05-30T08:06:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nSeeing 403 when trying to get `\"imdb_reviews\"` dataset.\r\n\r\n**Environment information**\r\n* Operating System: `Win7`\r\n* Python version: `3.7.7`\r\n* `tensorflow-datasets`/`tfds-nightly` version:  `tfds-nightly==3.1.0.dev202005280105`\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: <package and version>\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\ntfds.load(name=\"imdb_reviews\")\r\n```\r\n\r\n**Link to logs**\r\n```\r\n/lib/python3.7/site-packages/tensorflow_datasets/core/download/downloader.py in _sync_download(self, url, destination_path)\r\n    233         iter(functools.partial(response.read, io.DEFAULT_BUFFER_SIZE), b''),\r\n    234     )\r\n--> 235 \r\n    236 \r\n    237 def _get_drive_url(url: str, session: requests.Session) -> str:\r\n\r\nDownloadError: Failed to get url http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz. HTTP code: 403.\r\n```\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2054", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2054/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2054/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2054/events", "html_url": "https://github.com/tensorflow/datasets/issues/2054", "id": 624042333, "node_id": "MDU6SXNzdWU2MjQwNDIzMzM=", "number": 2054, "title": "Disable check sum checkings", "user": {"login": "aaronhma", "id": 25288451, "node_id": "MDQ6VXNlcjI1Mjg4NDUx", "avatar_url": "https://avatars1.githubusercontent.com/u/25288451?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaronhma", "html_url": "https://github.com/aaronhma", "followers_url": "https://api.github.com/users/aaronhma/followers", "following_url": "https://api.github.com/users/aaronhma/following{/other_user}", "gists_url": "https://api.github.com/users/aaronhma/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaronhma/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaronhma/subscriptions", "organizations_url": "https://api.github.com/users/aaronhma/orgs", "repos_url": "https://api.github.com/users/aaronhma/repos", "events_url": "https://api.github.com/users/aaronhma/events{/privacy}", "received_events_url": "https://api.github.com/users/aaronhma/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-25T04:49:39Z", "updated_at": "2020-06-01T04:39:20Z", "closed_at": "2020-06-01T04:39:20Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Is your feature request related to a problem? Please describe.**\r\nThis feature request relates to my issue: #2053 and many other people's issues.\r\n\r\n**Describe the solution you'd like**\r\nI think that there should be an option to disable the checking the checksum of a dataset. \r\n\r\nThanks!\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2053", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2053/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2053/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2053/events", "html_url": "https://github.com/tensorflow/datasets/issues/2053", "id": 624041847, "node_id": "MDU6SXNzdWU2MjQwNDE4NDc=", "number": 2053, "title": "NonMatchingChecksumError for oxford_flowers102", "user": {"login": "aaronhma", "id": 25288451, "node_id": "MDQ6VXNlcjI1Mjg4NDUx", "avatar_url": "https://avatars1.githubusercontent.com/u/25288451?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaronhma", "html_url": "https://github.com/aaronhma", "followers_url": "https://api.github.com/users/aaronhma/followers", "following_url": "https://api.github.com/users/aaronhma/following{/other_user}", "gists_url": "https://api.github.com/users/aaronhma/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaronhma/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaronhma/subscriptions", "organizations_url": "https://api.github.com/users/aaronhma/orgs", "repos_url": "https://api.github.com/users/aaronhma/repos", "events_url": "https://api.github.com/users/aaronhma/events{/privacy}", "received_events_url": "https://api.github.com/users/aaronhma/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-05-25T04:47:53Z", "updated_at": "2020-06-01T04:39:01Z", "closed_at": "2020-06-01T04:39:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nWhen\r\n\r\n**Environment information**\r\n* Operating System: macOS\r\n* Python version: Conda Python 3.7.7\r\n* `tfds-nightly\r\n* `tensorflow 2.2.0\r\n\r\n**Reproduction instructions**\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\nimport json\r\n# ======\r\n# Load the dataset with TensorFlow Datasets.\r\ndataset, dataset_info = tfds.load('oxford_flowers102', with_info = True, as_supervised = True)\r\n\r\n# Create a training set, a validation set and a test set.\r\ntraining, testing, validation = dataset['train'], dataset['test'], dataset['validation']\r\n```\r\n\r\n**Link to logs**\r\n```\r\nNonMatchingChecksumError: Artifact https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz, downloaded to /Users/aaronma/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_102flowersoWedSp98maBn1wypsDib6T-q2NVbO40fwvTflmPmQpY.tgz.tmp.3a12a0ebc88c4d528dc1f1a15f3b4648/102flowers.tgz, has wrong checksum. This might indicate:\r\n * The website may be down (e.g. returned a 503 status code). Please check the url.\r\n * For Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See https://github.com/tensorflow/datasets/issues/1482\r\n * The original datasets files may have been updated. In this case the TFDS dataset builder should be updated to use the new files and checksums. Sorry about that. Please open an issue or send us a PR with a fix.\r\n * If you're adding a new dataset, don't forget to register the checksums as explained in: https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally\r\n```\r\n\r\n**Expected behavior**\r\nI expect the dataset to be downloaded without any checksum errors.\r\n\r\nAny help with this would be appreciated! Thanks!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2048", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2048/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2048/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2048/events", "html_url": "https://github.com/tensorflow/datasets/issues/2048", "id": 622693331, "node_id": "MDU6SXNzdWU2MjI2OTMzMzE=", "number": 2048, "title": "[data request] Deepmind's PG-19", "user": {"login": "afrozenator", "id": 1131030, "node_id": "MDQ6VXNlcjExMzEwMzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1131030?v=4", "gravatar_id": "", "url": "https://api.github.com/users/afrozenator", "html_url": "https://github.com/afrozenator", "followers_url": "https://api.github.com/users/afrozenator/followers", "following_url": "https://api.github.com/users/afrozenator/following{/other_user}", "gists_url": "https://api.github.com/users/afrozenator/gists{/gist_id}", "starred_url": "https://api.github.com/users/afrozenator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/afrozenator/subscriptions", "organizations_url": "https://api.github.com/users/afrozenator/orgs", "repos_url": "https://api.github.com/users/afrozenator/repos", "events_url": "https://api.github.com/users/afrozenator/events{/privacy}", "received_events_url": "https://api.github.com/users/afrozenator/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168524723, "node_id": "MDU6TGFiZWwxMTY4NTI0NzIz", "url": "https://api.github.com/repos/tensorflow/datasets/labels/dataset%20request", "name": "dataset request", "color": "beb7ff", "default": false, "description": "Request for a new dataset to be added"}, {"id": 1052290134, "node_id": "MDU6TGFiZWwxMDUyMjkwMTM0", "url": "https://api.github.com/repos/tensorflow/datasets/labels/good%20first%20issue", "name": "good first issue", "color": "7057ff", "default": true, "description": "Good for newcomers"}], "state": "closed", "locked": false, "assignee": {"login": "afrozenator", "id": 1131030, "node_id": "MDQ6VXNlcjExMzEwMzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1131030?v=4", "gravatar_id": "", "url": "https://api.github.com/users/afrozenator", "html_url": "https://github.com/afrozenator", "followers_url": "https://api.github.com/users/afrozenator/followers", "following_url": "https://api.github.com/users/afrozenator/following{/other_user}", "gists_url": "https://api.github.com/users/afrozenator/gists{/gist_id}", "starred_url": "https://api.github.com/users/afrozenator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/afrozenator/subscriptions", "organizations_url": "https://api.github.com/users/afrozenator/orgs", "repos_url": "https://api.github.com/users/afrozenator/repos", "events_url": "https://api.github.com/users/afrozenator/events{/privacy}", "received_events_url": "https://api.github.com/users/afrozenator/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "afrozenator", "id": 1131030, "node_id": "MDQ6VXNlcjExMzEwMzA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1131030?v=4", "gravatar_id": "", "url": "https://api.github.com/users/afrozenator", "html_url": "https://github.com/afrozenator", "followers_url": "https://api.github.com/users/afrozenator/followers", "following_url": "https://api.github.com/users/afrozenator/following{/other_user}", "gists_url": "https://api.github.com/users/afrozenator/gists{/gist_id}", "starred_url": "https://api.github.com/users/afrozenator/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/afrozenator/subscriptions", "organizations_url": "https://api.github.com/users/afrozenator/orgs", "repos_url": "https://api.github.com/users/afrozenator/repos", "events_url": "https://api.github.com/users/afrozenator/events{/privacy}", "received_events_url": "https://api.github.com/users/afrozenator/received_events", "type": "User", "site_admin": false}, {"login": "acharles7", "id": 17268094, "node_id": "MDQ6VXNlcjE3MjY4MDk0", "avatar_url": "https://avatars2.githubusercontent.com/u/17268094?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acharles7", "html_url": "https://github.com/acharles7", "followers_url": "https://api.github.com/users/acharles7/followers", "following_url": "https://api.github.com/users/acharles7/following{/other_user}", "gists_url": "https://api.github.com/users/acharles7/gists{/gist_id}", "starred_url": "https://api.github.com/users/acharles7/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acharles7/subscriptions", "organizations_url": "https://api.github.com/users/acharles7/orgs", "repos_url": "https://api.github.com/users/acharles7/repos", "events_url": "https://api.github.com/users/acharles7/events{/privacy}", "received_events_url": "https://api.github.com/users/acharles7/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 25, "created_at": "2020-05-21T18:29:35Z", "updated_at": "2020-06-01T20:17:55Z", "closed_at": "2020-06-01T20:17:55Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "* Name of dataset: PG-19\r\n* URL of dataset: https://github.com/deepmind/pg19\r\n* License of dataset: Apache License 2.0\r\n* Short description of dataset and use case(s): This repository contains the PG-19 language modeling benchmark. It includes a set of books extracted from the Project Gutenberg books library, that were published before 1919. It also contains metadata of book titles and publication dates. PG-19 is over double the size of the Billion Word benchmark and contains documents that are 20X longer, on average, than the WikiText long-range language modelling benchmark.\r\n\r\nhttps://github.com/deepmind/pg19\r\n\r\nFolks who would also like to see this dataset in `tensorflow/datasets`, please thumbs-up so the developers can know which requests to prioritize.\r\n\r\nAnd if you'd like to contribute the dataset (thank you!), see our [guide to adding a dataset](https://github.com/tensorflow/datasets/blob/master/docs/add_dataset.md).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2046", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2046/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2046/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2046/events", "html_url": "https://github.com/tensorflow/datasets/issues/2046", "id": 622269678, "node_id": "MDU6SXNzdWU2MjIyNjk2Nzg=", "number": 2046, "title": "Setting interleave_parallel_reads always results in KeyError", "user": {"login": "nobutoba", "id": 44864310, "node_id": "MDQ6VXNlcjQ0ODY0MzEw", "avatar_url": "https://avatars1.githubusercontent.com/u/44864310?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nobutoba", "html_url": "https://github.com/nobutoba", "followers_url": "https://api.github.com/users/nobutoba/followers", "following_url": "https://api.github.com/users/nobutoba/following{/other_user}", "gists_url": "https://api.github.com/users/nobutoba/gists{/gist_id}", "starred_url": "https://api.github.com/users/nobutoba/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nobutoba/subscriptions", "organizations_url": "https://api.github.com/users/nobutoba/orgs", "repos_url": "https://api.github.com/users/nobutoba/repos", "events_url": "https://api.github.com/users/nobutoba/events{/privacy}", "received_events_url": "https://api.github.com/users/nobutoba/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-21T06:01:57Z", "updated_at": "2020-05-21T20:22:29Z", "closed_at": "2020-05-21T20:22:29Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nThe commits https://github.com/tensorflow/datasets/commit/e23fb248a575990cad34e260e564a37f8b181c6d, https://github.com/tensorflow/datasets/commit/c7027413b339d3a48fd309ec78ff8b2b3c93b1f4 deprecated `interleave_parallel_reads` and introduced `interleave_cycle_length` instead. However, instantiating the `ReadConfig` class with the `interleave_parallel_reads` argument always results in `KeyError`, in addition to logging the deprecation warning. An outcome of this KeyError is incompatibility of TensorFlow Dataset 3.1.0 with TensorFlow Model Garden 2.2.0.\r\n\r\n**Environment information**\r\n* Operating System: CentOS Linux 7\r\n* Python version: 3.7.6\r\n* `tensorflow-datasets`/`tfds-nightly` version: TensorFlow Datasets 3.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: TensorFlow 2.2.0\r\n\r\n**Reproduction instructions**\r\nAs shown in a [README](https://github.com/tensorflow/models/blob/v2.2.0/official/vision/image_classification/README.md) of TensorFlow Model Garden 2.2.0, run the following command\r\n\r\n```shell\r\npython3 classifier_trainer.py \\\r\n  --mode=train_and_eval \\\r\n  --model_type=resnet \\\r\n  --dataset=imagenet \\\r\n  --data_dir=$DATA_DIR \\\r\n  --config_file=configs/examples/resnet/imagenet/gpu.yaml \\\r\n  --params_override='runtime.num_gpus=1'\r\n```\r\n\r\nwhere `DATA_DIR` is the path to the ImageNet dataset. The command throws the following `KeyError`:\r\n\r\n```\r\n/some/path/.venv/lib/python3.7/site-packages/tensorflow_datasets/core/utils/read_config.py in __init__(self, **kwargs)\r\n     97         raise ValueError('Cannot set both {} and {}'.format(_OLD, _NEW))\r\n     98       logging.warning(_WARNING_MSG)\r\n---> 99       kwargs[_OLD] = kwargs.pop(_NEW)\r\n    100     super(ReadConfig, self).__init__(**kwargs)\r\n\r\nKeyError: 'interleave_cycle_length'\r\n```\r\n\r\n**Expected behavior**\r\nSince the `interleave_parallel_reads` argument is still valid, it should only log a deprecation warning but must not raise an Exception as above.\r\n\r\n**Additional context**\r\nIn a nutshell, the correct code would be\r\n\r\n```\r\nkwargs[_NEW] = kwargs.pop(_OLD)\r\n```\r\n\r\ninstead of the current\r\n\r\n```\r\nkwargs[_OLD] = kwargs.pop(_NEW)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2045", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2045/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2045/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2045/events", "html_url": "https://github.com/tensorflow/datasets/issues/2045", "id": 622256644, "node_id": "MDU6SXNzdWU2MjIyNTY2NDQ=", "number": 2045, "title": "duplicate logging message after calling tfds.load", "user": {"login": "SinaChavoshi", "id": 20114005, "node_id": "MDQ6VXNlcjIwMTE0MDA1", "avatar_url": "https://avatars0.githubusercontent.com/u/20114005?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SinaChavoshi", "html_url": "https://github.com/SinaChavoshi", "followers_url": "https://api.github.com/users/SinaChavoshi/followers", "following_url": "https://api.github.com/users/SinaChavoshi/following{/other_user}", "gists_url": "https://api.github.com/users/SinaChavoshi/gists{/gist_id}", "starred_url": "https://api.github.com/users/SinaChavoshi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SinaChavoshi/subscriptions", "organizations_url": "https://api.github.com/users/SinaChavoshi/orgs", "repos_url": "https://api.github.com/users/SinaChavoshi/repos", "events_url": "https://api.github.com/users/SinaChavoshi/events{/privacy}", "received_events_url": "https://api.github.com/users/SinaChavoshi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-21T05:25:49Z", "updated_at": "2020-06-18T20:23:09Z", "closed_at": "2020-06-18T19:33:37Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nDescription of the bug.\r\nA call to tensorflow_datasets.load  adds an additional logging handler, tf registers a separate logging handler, this results in duplicate logging messages. \r\n\r\nexample : \r\n\r\n**Environment information**\r\n* Operating System: ubuntu 16\r\n* Python version: 3.7\r\n* `tensorflow-datasets` version: '2.0.0'\r\n* `tensorflow` version:'2.1.0-dlenv_tfe'\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\n(ds_train, ds_test), ds_info = tfds.load(\r\n    'mnist',\r\n    split=['train', 'test'],\r\n    shuffle_files=True,\r\n    as_supervised=True,\r\n    with_info=True,\r\n)\r\n\r\ntf.get_logger().info('This info log will show up twice')\r\n```\r\n\r\n**Link to logs**\r\nNA\r\n\r\n**Expected behavior**\r\nOnly one log message should show up. \r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\nThis behavior is described in details at https://stackoverflow.com/questions/6729268/log-messages-appearing-twice-with-python-logging\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2039", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2039/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2039/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2039/events", "html_url": "https://github.com/tensorflow/datasets/issues/2039", "id": 620831375, "node_id": "MDU6SXNzdWU2MjA4MzEzNzU=", "number": 2039, "title": "ValueError: Shapes (28, 28) and (28, 28, 1) must have the same rank", "user": {"login": "muhammadfahid51", "id": 57350797, "node_id": "MDQ6VXNlcjU3MzUwNzk3", "avatar_url": "https://avatars1.githubusercontent.com/u/57350797?v=4", "gravatar_id": "", "url": "https://api.github.com/users/muhammadfahid51", "html_url": "https://github.com/muhammadfahid51", "followers_url": "https://api.github.com/users/muhammadfahid51/followers", "following_url": "https://api.github.com/users/muhammadfahid51/following{/other_user}", "gists_url": "https://api.github.com/users/muhammadfahid51/gists{/gist_id}", "starred_url": "https://api.github.com/users/muhammadfahid51/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/muhammadfahid51/subscriptions", "organizations_url": "https://api.github.com/users/muhammadfahid51/orgs", "repos_url": "https://api.github.com/users/muhammadfahid51/repos", "events_url": "https://api.github.com/users/muhammadfahid51/events{/privacy}", "received_events_url": "https://api.github.com/users/muhammadfahid51/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-19T09:39:44Z", "updated_at": "2020-05-21T05:17:44Z", "closed_at": "2020-05-21T05:17:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "My dataset is in MNIST format.\r\nWhen I load the data in tensorflow-datasets, it gives me the titled error. I don't know what and where the problem actually lies. \r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2036", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2036/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2036/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2036/events", "html_url": "https://github.com/tensorflow/datasets/issues/2036", "id": 619549541, "node_id": "MDU6SXNzdWU2MTk1NDk1NDE=", "number": 2036, "title": "Can i resume download of C4 dataset", "user": {"login": "nikregrado", "id": 49633535, "node_id": "MDQ6VXNlcjQ5NjMzNTM1", "avatar_url": "https://avatars2.githubusercontent.com/u/49633535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikregrado", "html_url": "https://github.com/nikregrado", "followers_url": "https://api.github.com/users/nikregrado/followers", "following_url": "https://api.github.com/users/nikregrado/following{/other_user}", "gists_url": "https://api.github.com/users/nikregrado/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikregrado/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikregrado/subscriptions", "organizations_url": "https://api.github.com/users/nikregrado/orgs", "repos_url": "https://api.github.com/users/nikregrado/repos", "events_url": "https://api.github.com/users/nikregrado/events{/privacy}", "received_events_url": "https://api.github.com/users/nikregrado/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-16T20:26:37Z", "updated_at": "2020-05-19T08:53:30Z", "closed_at": "2020-05-19T08:53:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "When i download this dataset in one of link i got 503 error and script was stopped. When i trying to run script again i got OsError: Not enough disk space...  Can I resume download, or i need to delete all downloaded files and try it again? ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2035", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2035/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2035/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2035/events", "html_url": "https://github.com/tensorflow/datasets/issues/2035", "id": 619384337, "node_id": "MDU6SXNzdWU2MTkzODQzMzc=", "number": 2035, "title": "Accessing a newly created tfds dataset", "user": {"login": "tonyboston-au", "id": 21052400, "node_id": "MDQ6VXNlcjIxMDUyNDAw", "avatar_url": "https://avatars2.githubusercontent.com/u/21052400?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tonyboston-au", "html_url": "https://github.com/tonyboston-au", "followers_url": "https://api.github.com/users/tonyboston-au/followers", "following_url": "https://api.github.com/users/tonyboston-au/following{/other_user}", "gists_url": "https://api.github.com/users/tonyboston-au/gists{/gist_id}", "starred_url": "https://api.github.com/users/tonyboston-au/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tonyboston-au/subscriptions", "organizations_url": "https://api.github.com/users/tonyboston-au/orgs", "repos_url": "https://api.github.com/users/tonyboston-au/repos", "events_url": "https://api.github.com/users/tonyboston-au/events{/privacy}", "received_events_url": "https://api.github.com/users/tonyboston-au/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-05-16T05:33:04Z", "updated_at": "2020-05-27T01:16:14Z", "closed_at": "2020-05-27T01:16:14Z", "author_association": "NONE", "active_lock_reason": null, "body": "A dataset was created and the guidance for adding the dataset to tfds from: https://www.tensorflow.org/datasets/add_dataset \r\n\r\nAfter creating the dataset.py file, ran the command:\r\n$ python -m tensorflow_datasets.scripts.download_and_prepare   --register_checksums=True   --datasets=auslssm2018\r\n\r\nThis downloaded my dataset and generated output: \r\n\r\nDataset auslssm2018 downloaded and prepared to /Users/tboston/tensorflow_datasets/auslssm2018/0.1.0. Subsequent calls will reuse this data.\r\nname: \"auslssm2018\"\r\ndescription: \"The Australian Landsat LCC 2018 dataset was created from a 100km square Landsat geomedian RGB images of southern NSW with a resoliution of 25 metres. The 3968x3968 pixel image has been broken up into 961 128x128 pixel chips. Label (segmentation mask) data is was created based on \\'Catchment scale land use of Australia - Update December 2018\\' and \\'Forests of Australia (2018)\\' available from ABARES. Label data represents a simplified 10 member LCC: 0:nodata, 1:forest, 2:grassland, 3:horticulture, 4:crop, 5:plantation, 6:bare, 7:water, 8:builtup, 9:unknown.\"\r\ncitation: \"@misc{AusLandsat2018,\\n    title={AusLandsat2108: A Dataset to test deep learning models for Land Use and Land Cover Classification},\\n    author={Tony Boston},\\n    year={2020},\\n    eprint={},\\n    archivePrefix={},\\n    primaryClass={}\\n}\"\r\nsplits {\r\n  name: \"test\"\r\n  shard_lengths: 130\r\n  num_bytes: 638115\r\n}\r\nsplits {\r\n  name: \"train\"\r\n  shard_lengths: 700\r\n  num_bytes: 3430588\r\n}\r\nsplits {\r\n  name: \"validation\"\r\n  shard_lengths: 131\r\n  num_bytes: 642160\r\n}\r\nversion: \"0.1.0\"\r\ndownload_size: 4373797\r\n\r\n\r\nAttempts to access the dataset now seem to fail. A command like this:\r\ndataset = tfds.load('auslssm2018', download=False)\r\n\r\nalways generates a DatasetNotFoundError error.\r\n\r\nSorry this is obviously a basic issue. Thanks in advance for any pointers.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2024", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2024/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2024/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2024/events", "html_url": "https://github.com/tensorflow/datasets/issues/2024", "id": 617540386, "node_id": "MDU6SXNzdWU2MTc1NDAzODY=", "number": 2024, "title": "TypeError 'UrlInfo' object is not iterable error when loading oxford_iiit_pet dataset.", "user": {"login": "alvarobasi", "id": 36459941, "node_id": "MDQ6VXNlcjM2NDU5OTQx", "avatar_url": "https://avatars0.githubusercontent.com/u/36459941?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alvarobasi", "html_url": "https://github.com/alvarobasi", "followers_url": "https://api.github.com/users/alvarobasi/followers", "following_url": "https://api.github.com/users/alvarobasi/following{/other_user}", "gists_url": "https://api.github.com/users/alvarobasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/alvarobasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alvarobasi/subscriptions", "organizations_url": "https://api.github.com/users/alvarobasi/orgs", "repos_url": "https://api.github.com/users/alvarobasi/repos", "events_url": "https://api.github.com/users/alvarobasi/events{/privacy}", "received_events_url": "https://api.github.com/users/alvarobasi/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-13T15:21:56Z", "updated_at": "2020-06-03T23:30:54Z", "closed_at": "2020-06-03T23:30:54Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nException has occurred: TypeError\r\n'UrlInfo' object is not iterable error is triggered when trying to load a TF dataset.\r\n\r\nI've tried with other datasets such as dogs_vs_cats with the same result.\r\n**Environment information**\r\n* Operating System: Ubuntu 18.04 LTS\r\n* Python version: 3.6.9\r\n* `tfds-nightly` version: 3.1.0.dev202005130105\r\n* `tf-nightly-gpu` version: 2.2.0.dev20200508\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\n(train_dataset, test_dataset), info = tfds.load(name=\"oxford_iiit_pet:3.*.*\",\r\n                                                split=[\"train\", \"test\"],\r\n                                                shuffle_files=True,\r\n                                                as_supervised=True,\r\n                                                with_info=True)\r\n```\r\n\r\n**Link to logs**\r\nIf applicable, <link to gist with logs, stack trace>\r\n\r\n**Expected behavior**\r\nWhat you expected to happen.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2021", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2021/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2021/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2021/events", "html_url": "https://github.com/tensorflow/datasets/issues/2021", "id": 617325157, "node_id": "MDU6SXNzdWU2MTczMjUxNTc=", "number": 2021, "title": "Error when loading imdb_reviews dataset", "user": {"login": "keosu", "id": 1130816, "node_id": "MDQ6VXNlcjExMzA4MTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/1130816?v=4", "gravatar_id": "", "url": "https://api.github.com/users/keosu", "html_url": "https://github.com/keosu", "followers_url": "https://api.github.com/users/keosu/followers", "following_url": "https://api.github.com/users/keosu/following{/other_user}", "gists_url": "https://api.github.com/users/keosu/gists{/gist_id}", "starred_url": "https://api.github.com/users/keosu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/keosu/subscriptions", "organizations_url": "https://api.github.com/users/keosu/orgs", "repos_url": "https://api.github.com/users/keosu/repos", "events_url": "https://api.github.com/users/keosu/events{/privacy}", "received_events_url": "https://api.github.com/users/keosu/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-05-13T10:16:44Z", "updated_at": "2020-06-03T23:30:24Z", "closed_at": "2020-06-03T23:30:24Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nthe following code report an error when running on colab\r\n```\r\ntrain_data, validation_data, test_data = tfds.load(\r\n    name=\"imdb_reviews\", \r\n    split=('train[:60%]', 'train[60%:]', 'test'),\r\n    as_supervised=True)\r\n```\r\n\r\n**Environment information**\r\ncolab\r\n\r\n**Reproduction instructions**\r\n\r\n\r\n1. open this link https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\r\n2. run in colab \r\n\r\n**Link to logs**\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-2-4b45eebfd65c> in <module>()\r\n      4     name=\"imdb_reviews\",\r\n      5     split=('train[:60%]', 'train[60%:]', 'test'),\r\n----> 6     as_supervised=True)\r\n\r\n5 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/download/download_manager.py in <genexpr>(.0)\r\n    255   def downloaded_size(self):\r\n    256     \"\"\"Returns the total size of downloaded files.\"\"\"\r\n--> 257     return sum(size for size, sha256 in self._recorded_url_infos.values())\r\n    258 \r\n    259   def _get_final_dl_path(self, url, sha256):\r\n\r\nTypeError: 'UrlInfo' object is not iterable\r\n ", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2016", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2016/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2016/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2016/events", "html_url": "https://github.com/tensorflow/datasets/issues/2016", "id": 616419812, "node_id": "MDU6SXNzdWU2MTY0MTk4MTI=", "number": 2016, "title": " cifar10_1 error: wrong checksum ", "user": {"login": "Vinnitsky", "id": 4279372, "node_id": "MDQ6VXNlcjQyNzkzNzI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4279372?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Vinnitsky", "html_url": "https://github.com/Vinnitsky", "followers_url": "https://api.github.com/users/Vinnitsky/followers", "following_url": "https://api.github.com/users/Vinnitsky/following{/other_user}", "gists_url": "https://api.github.com/users/Vinnitsky/gists{/gist_id}", "starred_url": "https://api.github.com/users/Vinnitsky/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Vinnitsky/subscriptions", "organizations_url": "https://api.github.com/users/Vinnitsky/orgs", "repos_url": "https://api.github.com/users/Vinnitsky/repos", "events_url": "https://api.github.com/users/Vinnitsky/events{/privacy}", "received_events_url": "https://api.github.com/users/Vinnitsky/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-12T07:15:07Z", "updated_at": "2020-06-30T17:28:05Z", "closed_at": "2020-06-30T17:28:05Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nWhen I load cifar10_1 dataset I got an error - the wrong checksum \r\n\r\n**Environment information**\r\n* Operating System: ubuntu 18.4\r\n* Python version: 3.6.10               hcf32534_1    anaconda\r\n* `tensorflow-datasets` version: 3.1.0                    pypi_0    pypi\r\n* `tensorflow-gpu` version: 2.1.0                h0d30ee6_0\r\n**Reproduction instructions**\r\n\r\n```\r\nraw_ds, info = tfds.load('cifar10_1', split='train', shuffle_files=True, with_info=True)\r\n```\r\nor \r\n```\r\nbuilder = tfds.builder('cifar10_1')\r\ninfo = builder.info\r\nbuilder.download_and_prepare()\r\n```\r\n\r\n**Link to logs**\r\nDownloading and preparing dataset cifar10_1/v4/1.0.0 (download: 5.93 MiB, generated: Unknown size, total: 5.93 MiB) to /home/ip/tensorflow_datasets/cifar10_1/v4/1.0.0...\r\n\r\n\r\n---------------------------------------------------------------------------\r\nNonMatchingChecksumError                  Traceback (most recent call last)\r\n in \r\n      1 # Construct a tf.data.Dataset\r\n----> 2 raw_ds, info = tfds.load('cifar10_1', split='train', shuffle_files=True, with_info=True)\r\n      3 \r\n      4 # Dispaly info\r\n      5 print(info)\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     67     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     68     _check_required(fn, kwargs)\r\n---> 69     return fn(*args, **kwargs)\r\n     70 \r\n     71   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py in load(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\r\n    367   if download:\r\n    368     download_and_prepare_kwargs = download_and_prepare_kwargs or {}\r\n--> 369     dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n    370 \r\n    371   if as_dataset_kwargs is None:\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     67     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n     68     _check_required(fn, kwargs)\r\n---> 69     return fn(*args, **kwargs)\r\n     70 \r\n     71   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py in download_and_prepare(self, download_dir, download_config)\r\n    361           self._download_and_prepare(\r\n    362               dl_manager=dl_manager,\r\n--> 363               download_config=download_config)\r\n    364 \r\n    365           # NOTE: If modifying the lines below to put additional information in\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py in _download_and_prepare(self, dl_manager, download_config)\r\n    994     super(GeneratorBasedBuilder, self)._download_and_prepare(\r\n    995         dl_manager=dl_manager,\r\n--> 996         max_examples_per_split=download_config.max_examples_per_split,\r\n    997     )\r\n    998 \r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py in _download_and_prepare(self, dl_manager, **prepare_split_kwargs)\r\n    914         prepare_split_kwargs)\r\n    915     for split_generator in self._split_generators(\r\n--> 916         dl_manager, **split_generators_kwargs):\r\n    917       if str(split_generator.split_info.name).lower() == \"all\":\r\n    918         raise ValueError(\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/image_classification/cifar10_1.py in _split_generators(self, dl_manager)\r\n    125     image_path, label_path = dl_manager.download([\r\n    126         image_url,\r\n--> 127         label_url,\r\n    128     ])\r\n    129 \r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py in download(self, url_or_urls)\r\n    359     # Add progress bar to follow the download state\r\n    360     with self._downloader.tqdm():\r\n--> 361       return _map_promise(self._download, url_or_urls)\r\n    362 \r\n    363   def iter_archive(self, resource):\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py in _map_promise(map_fn, all_inputs)\r\n    460   \"\"\"Map the function into each element and resolve the promise.\"\"\"\r\n    461   all_promises = utils.map_nested(map_fn, all_inputs)  # Apply the function\r\n--> 462   res = utils.map_nested(_wait_on_promise, all_promises)\r\n    463   return res\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/utils/py_utils.py in map_nested(function, data_struct, dict_only, map_tuple)\r\n    159     if isinstance(data_struct, tuple(types)):\r\n    160       mapped = [map_nested(function, v, dict_only, map_tuple)\r\n--> 161                 for v in data_struct]\r\n    162       if isinstance(data_struct, list):\r\n    163         return mapped\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/utils/py_utils.py in (.0)\r\n    159     if isinstance(data_struct, tuple(types)):\r\n    160       mapped = [map_nested(function, v, dict_only, map_tuple)\r\n--> 161                 for v in data_struct]\r\n    162       if isinstance(data_struct, list):\r\n    163         return mapped\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/utils/py_utils.py in map_nested(function, data_struct, dict_only, map_tuple)\r\n    165         return tuple(mapped)\r\n    166   # Singleton\r\n--> 167   return function(data_struct)\r\n    168 \r\n    169 \r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py in _wait_on_promise(p)\r\n    444 \r\n    445   def _wait_on_promise(p):\r\n--> 446     return p.get()\r\n    447 \r\n    448 else:\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/promise/promise.py in get(self, timeout)\r\n    508         target = self._target()\r\n    509         self._wait(timeout or DEFAULT_TIMEOUT)\r\n--> 510         return self._target_settled_value(_raise=True)\r\n    511 \r\n    512     def _target_settled_value(self, _raise=False):\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/promise/promise.py in _target_settled_value(self, _raise)\r\n    512     def _target_settled_value(self, _raise=False):\r\n    513         # type: (bool) -> Any\r\n--> 514         return self._target()._settled_value(_raise)\r\n    515 \r\n    516     _value = _reason = _target_settled_value\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/promise/promise.py in _settled_value(self, _raise)\r\n    222             if _raise:\r\n    223                 raise_val = self._fulfillment_handler0\r\n--> 224                 reraise(type(raise_val), raise_val, self._traceback)\r\n    225             return self._fulfillment_handler0\r\n    226 \r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/six.py in reraise(tp, value, tb)\r\n    701             if value.__traceback__ is not tb:\r\n    702                 raise value.with_traceback(tb)\r\n--> 703             raise value\r\n    704         finally:\r\n    705             value = None\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/promise/promise.py in try_catch(handler, *args, **kwargs)\r\n     83     # type: (Callable, Any, Any) -> Union[Tuple[Any, None], Tuple[None, Tuple[Exception, Optional[TracebackType]]]]\r\n     84     try:\r\n---> 85         return (handler(*args, **kwargs), None)\r\n     86     except Exception as e:\r\n     87         tb = exc_info()[2]\r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py in callback(val)\r\n    304       checksum, dl_size = val\r\n    305       return self._handle_download_result(\r\n--> 306           resource, download_dir_path, checksum, dl_size)\r\n    307     return self._downloader.download(url, download_dir_path).then(callback)\r\n    308 \r\n\r\n~/anaconda3/envs/fv/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py in _handle_download_result(self, resource, tmp_dir_path, sha256, dl_size)\r\n    259       self._record_sizes_checksums()\r\n    260     elif (dl_size, sha256) != self._sizes_checksums.get(resource.url, None):\r\n--> 261       raise NonMatchingChecksumError(resource.url, tmp_path)\r\n    262     download_path = self._get_final_dl_path(resource.url, sha256)\r\n    263     resource_lib.write_info_file(resource, download_path, self._dataset_name,\r\n\r\nNonMatchingChecksumError: Artifact https://github.com/modestyachts/CIFAR-10.1/blob/master/datasets/cifar10.1_v4_data.npy?raw=true, downloaded to /home/ip/tensorflow_datasets/downloads/mode_CIFA-10.1_blob_mast_data_cifaNq0Cwy9MOL7TDNeozV80r6_1TggOEPcU1qi0prAIGnc.npyraw=true.tmp.e6e20b6b04a04146b10698deb40a2cdf/cifar10.1_v4_data.npy, has wrong checksum. This might indicate:\r\n * The website may be down (e.g. returned a 503 status code). Please check the url.\r\n * For Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See https://github.com/tensorflow/datasets/issues/1482\r\n * The original datasets files may have been updated. In this case the TFDS dataset builder should be updated to use the new files and checksums. Sorry about that. Please open an issue or send us a PR with a fix.\r\n * If you're adding a new dataset, don't forget to register the checksums as explained in: https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally\r\n\r\n**Expected behavior**\r\nloaded dataset\r\n\r\n**Additional context**\r\nNo\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2011", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2011/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2011/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2011/events", "html_url": "https://github.com/tensorflow/datasets/issues/2011", "id": 615656265, "node_id": "MDU6SXNzdWU2MTU2NTYyNjU=", "number": 2011, "title": "oxford_iiit_pet has wrong Checksum", "user": {"login": "djdongjin", "id": 28295179, "node_id": "MDQ6VXNlcjI4Mjk1MTc5", "avatar_url": "https://avatars1.githubusercontent.com/u/28295179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/djdongjin", "html_url": "https://github.com/djdongjin", "followers_url": "https://api.github.com/users/djdongjin/followers", "following_url": "https://api.github.com/users/djdongjin/following{/other_user}", "gists_url": "https://api.github.com/users/djdongjin/gists{/gist_id}", "starred_url": "https://api.github.com/users/djdongjin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/djdongjin/subscriptions", "organizations_url": "https://api.github.com/users/djdongjin/orgs", "repos_url": "https://api.github.com/users/djdongjin/repos", "events_url": "https://api.github.com/users/djdongjin/events{/privacy}", "received_events_url": "https://api.github.com/users/djdongjin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-11T07:29:55Z", "updated_at": "2020-05-11T08:31:31Z", "closed_at": "2020-05-11T08:31:30Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nDescription of the bug.\r\n\r\nThe `oxford_iiit_pet` dataset has a wrong checksum value.\r\n\r\n**Environment information**\r\n* Operating System: colab\r\n* Python version: 3.6.9\r\n* `tensorflow-datasets`/`tfds-nightly` version: tensorflow-datasets 2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: tensorflow 2.2.0-rc4\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\ndataset, info = tfds.load('oxford_iiit_pet', with_info=True)\r\n```\r\n\r\n**Link to logs**\r\nIf applicable, <link to gist with logs, stack trace>\r\n\r\n**Expected behavior**\r\nWhat you expected to happen.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2010", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2010/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2010/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2010/events", "html_url": "https://github.com/tensorflow/datasets/issues/2010", "id": 615532275, "node_id": "MDU6SXNzdWU2MTU1MzIyNzU=", "number": 2010, "title": "Catalog Dataset Example Throws Error", "user": {"login": "TaylorBradshaw", "id": 39289583, "node_id": "MDQ6VXNlcjM5Mjg5NTgz", "avatar_url": "https://avatars1.githubusercontent.com/u/39289583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TaylorBradshaw", "html_url": "https://github.com/TaylorBradshaw", "followers_url": "https://api.github.com/users/TaylorBradshaw/followers", "following_url": "https://api.github.com/users/TaylorBradshaw/following{/other_user}", "gists_url": "https://api.github.com/users/TaylorBradshaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/TaylorBradshaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TaylorBradshaw/subscriptions", "organizations_url": "https://api.github.com/users/TaylorBradshaw/orgs", "repos_url": "https://api.github.com/users/TaylorBradshaw/repos", "events_url": "https://api.github.com/users/TaylorBradshaw/events{/privacy}", "received_events_url": "https://api.github.com/users/TaylorBradshaw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1257633672, "node_id": "MDU6TGFiZWwxMjU3NjMzNjcy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/documentation", "name": "documentation", "color": "fbca04", "default": true, "description": "Pull Request or Issue related with comments or documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-05-11T01:45:41Z", "updated_at": "2020-06-04T00:16:17Z", "closed_at": "2020-06-04T00:16:17Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Description of issue**\r\n\r\nThe example on https://www.tensorflow.org/datasets/catalog/overview is not usable.  The int2str function inside of the print function throws a ValueError because it's trying to print the label of 32 images at once.  Removing the line 'ds = ds.batch(32)' fixed the value error for me, and caused the program to print out all of the labels of each image, though I'm not sure that's the intended result as there's a lot of images in some of these datasets.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2004", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2004/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2004/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2004/events", "html_url": "https://github.com/tensorflow/datasets/issues/2004", "id": 614387024, "node_id": "MDU6SXNzdWU2MTQzODcwMjQ=", "number": 2004, "title": "URL changing for XNLI and MNLI/MultiNLI", "user": {"login": "sleepinyourhat", "id": 1284441, "node_id": "MDQ6VXNlcjEyODQ0NDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1284441?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sleepinyourhat", "html_url": "https://github.com/sleepinyourhat", "followers_url": "https://api.github.com/users/sleepinyourhat/followers", "following_url": "https://api.github.com/users/sleepinyourhat/following{/other_user}", "gists_url": "https://api.github.com/users/sleepinyourhat/gists{/gist_id}", "starred_url": "https://api.github.com/users/sleepinyourhat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sleepinyourhat/subscriptions", "organizations_url": "https://api.github.com/users/sleepinyourhat/orgs", "repos_url": "https://api.github.com/users/sleepinyourhat/repos", "events_url": "https://api.github.com/users/sleepinyourhat/events{/privacy}", "received_events_url": "https://api.github.com/users/sleepinyourhat/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-05-07T22:36:59Z", "updated_at": "2020-05-09T00:50:43Z", "closed_at": "2020-05-09T00:50:43Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nNYU is turning down the server/site that hosts the reference copies of XNLI and MNLI shortly, so the URLs will have to change.\r\n\r\nNew URLs:\r\nhttps://cims.nyu.edu/~sbowman/multinli\r\nhttps://cims.nyu.edu/~sbowman/xnli\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/2000", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/2000/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/2000/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/2000/events", "html_url": "https://github.com/tensorflow/datasets/issues/2000", "id": 614073480, "node_id": "MDU6SXNzdWU2MTQwNzM0ODA=", "number": 2000, "title": "ImageAugmentation using tf.keras.preprocessing.image.ImageDataGenerator and tf.datasets: model.fit() is running infinitely", "user": {"login": "Thomasaws1", "id": 63084597, "node_id": "MDQ6VXNlcjYzMDg0NTk3", "avatar_url": "https://avatars0.githubusercontent.com/u/63084597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Thomasaws1", "html_url": "https://github.com/Thomasaws1", "followers_url": "https://api.github.com/users/Thomasaws1/followers", "following_url": "https://api.github.com/users/Thomasaws1/following{/other_user}", "gists_url": "https://api.github.com/users/Thomasaws1/gists{/gist_id}", "starred_url": "https://api.github.com/users/Thomasaws1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Thomasaws1/subscriptions", "organizations_url": "https://api.github.com/users/Thomasaws1/orgs", "repos_url": "https://api.github.com/users/Thomasaws1/repos", "events_url": "https://api.github.com/users/Thomasaws1/events{/privacy}", "received_events_url": "https://api.github.com/users/Thomasaws1/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-05-07T13:49:34Z", "updated_at": "2020-05-07T14:29:38Z", "closed_at": "2020-05-07T14:29:38Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I need help with / What I was wondering**\r\nI am facing issue while running the fit() function in TensorFlow(v 2.2.0-rc4) with augmented images(using ImageDataGenerator) passed as a dataset. The fit() function is running infinitely without stopping.\r\n\r\n**What I've tried so far**\r\nI tried it with the default code which was shared in Tensorflow documentation. \r\n\r\nPlease find the code snippet below:\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nfrom tensorflow.keras.models import Sequential, Model \r\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D \r\nfrom tensorflow.keras.layers import Input, Dense\r\n\r\nflowers = tf.keras.utils.get_file(\r\n    'flower_photos',\r\n    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\r\n    untar=True)\r\n\r\nimg_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)\r\n\r\nimages, labels = next(img_gen.flow_from_directory(flowers))\r\n\r\nprint(images.dtype, images.shape)\r\nprint(labels.dtype, labels.shape)\r\n\r\ntrain_data_gen = img_gen.flow_from_directory(\r\n                    batch_size=32, \r\n                    directory=flowers,\r\n                    shuffle=True,\r\n                    target_size=(256, 256),\r\n                    class_mode='categorical')\r\n\r\nds = tf.data.Dataset.from_generator(lambda: train_data_gen,\r\n                     output_types=(tf.float32, tf.float32),\r\n                     output_shapes=([32, 256, 256, 3],\r\n                                    [32, 5])\r\n                     )\r\n\r\nds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\nit = iter(ds)\r\nbatch = next(it)\r\nprint(batch)\r\n\r\ndef create_model():\r\n  model = Sequential()\r\n  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=images[0].shape))\r\n  model.add(Conv2D(32, (3, 3), activation='relu'))\r\n  model.add(MaxPooling2D(pool_size=(2, 2)))\r\n  model.add(Dropout(0.5))\r\n  model.add(Conv2D(64, (3, 3), activation='relu'))\r\n  model.add(Conv2D(64, (3, 3), activation='relu'))\r\n  model.add(MaxPooling2D(pool_size=(2, 2)))\r\n  model.add(Dropout(0.5))\r\n  model.add(Flatten())\r\n  model.add(Dense(64, activation='relu'))\r\n  model.add(Dropout(0.5))\r\n  model.add(Dense(5, activation='softmax'))\r\n  return model\r\n\r\nmodel = create_model()\r\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])\r\nmodel.fit(ds, verbose=1,  batch_size= 32, epochs =1)\r\n\r\nThis last line of code - fit() is running infinitly without stopping. I had also tried passing steps_per_epoch = total_no_of_train_records/batch_size.\r\n\r\n**It would be nice if...**\r\nI would like you to confirm whethere this is a bug in the tensorflow datasets package and in which release will this be fixed.\r\n\r\n\r\n**Environment information**\r\n* System: Google colaborator\r\n* Python version: v3.6.9\r\n* `tensorflow-datasets`/`tfds-nightly` version: v2.2.0-rc4\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1998", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1998/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1998/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1998/events", "html_url": "https://github.com/tensorflow/datasets/issues/1998", "id": 614040021, "node_id": "MDU6SXNzdWU2MTQwNDAwMjE=", "number": 1998, "title": "AttributeError: 'Split' object has no attribute 'subsplit'", "user": {"login": "DeqianBai", "id": 39949193, "node_id": "MDQ6VXNlcjM5OTQ5MTkz", "avatar_url": "https://avatars0.githubusercontent.com/u/39949193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DeqianBai", "html_url": "https://github.com/DeqianBai", "followers_url": "https://api.github.com/users/DeqianBai/followers", "following_url": "https://api.github.com/users/DeqianBai/following{/other_user}", "gists_url": "https://api.github.com/users/DeqianBai/gists{/gist_id}", "starred_url": "https://api.github.com/users/DeqianBai/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DeqianBai/subscriptions", "organizations_url": "https://api.github.com/users/DeqianBai/orgs", "repos_url": "https://api.github.com/users/DeqianBai/repos", "events_url": "https://api.github.com/users/DeqianBai/events{/privacy}", "received_events_url": "https://api.github.com/users/DeqianBai/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-05-07T13:01:44Z", "updated_at": "2020-07-08T02:55:29Z", "closed_at": "2020-05-07T14:35:00Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I need help with / What I was wondering**\r\nTraceback (most recent call last):\r\n  File \"F:/ML/Deep Learning/NLP/Paper/07-Transformer/NMT-Transformer/Data_process/01.py\", line 17, in <module>\r\n    train_half_1, train_half_2 = tfds.Split.TRAIN.subsplit(2)\r\nAttributeError: 'Split' object has no attribute 'subsplit'\r\n\r\n\r\n**What I've tried so far**\r\nI search this error in google , but there is no such issue like this. I first encounter when I try to download the dataset \"newscommentary_v14\" in \"wmt19_translate/zh-en\" :\r\n```\r\nconfig = tfds.translate.wmt.WmtConfig(\r\n            version=tfds.core.Version(\"1.0.0\"),\r\n            language_pair=(\"zh\", \"en\"),\r\n            subsets={\r\n                tfds.Split.TRAIN: [\"newscommentary_v14\"]\r\n            }\r\n        )\r\nbuilder = tfds.builder(\"wmt_translate\", config=config)\r\nbuilder.download_and_prepare(download_dir=self.download_dir)\r\n\r\n# 3. \u5207\u5272\u6570\u636e\u96c6\uff0c\u4f7f\u7528 tfds.Split \u5b9a\u4e49\u4e00\u4e2a\u5c06\u6b64\u6570\u636e\u96c6\u5207\u6210\u591a\u4e2a\u90e8\u5206\u7684 split\uff1a\r\ntrain_perc = 20\r\nval_prec = 1\r\ndrop_prec = 100 - train_perc - val_prec\r\n\r\nsplit = tfds.Split.TRAIN.subsplit([train_perc, val_prec, drop_prec])\r\n\r\n# \u5c06\u524d\u4e24\u4e2a splits \u62ff\u6765\u5f53\u4f5c\u8bad\u7ec3\u4ee5\u53ca\u9a8c\u8bc1\u96c6\uff0c\u5269\u4f59\u7684\u90e8\u5206\uff08\u7b2c 3 \u4e2a split\uff09\u820d\u5f03\u4e0d\u7528\uff1a\r\nexamples = builder.as_dataset(split=split, as_supervised=True)\r\ntrain_examples, val_examples, _ = examples\r\n```\r\n**It would be nice if...**\r\nThe question was happened when I run the code in Pycharm with .py file.\r\nbut it is OK when I run the code in Colab of google with .ipynb  file.\r\n\r\n**Environment information**\r\n(if applicable)\r\n* Operating System: windows 10\r\n* Python version: 3.6\r\n* `tensorflow-datasets: 3.1.0\r\n* `tensorflow` version:  2.0.0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1978", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1978/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1978/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1978/events", "html_url": "https://github.com/tensorflow/datasets/issues/1978", "id": 610740880, "node_id": "MDU6SXNzdWU2MTA3NDA4ODA=", "number": 1978, "title": "Checksums for oxford_iiit_pet changed, and the dataset cannot be loaded.", "user": {"login": "greentec", "id": 6878615, "node_id": "MDQ6VXNlcjY4Nzg2MTU=", "avatar_url": "https://avatars3.githubusercontent.com/u/6878615?v=4", "gravatar_id": "", "url": "https://api.github.com/users/greentec", "html_url": "https://github.com/greentec", "followers_url": "https://api.github.com/users/greentec/followers", "following_url": "https://api.github.com/users/greentec/following{/other_user}", "gists_url": "https://api.github.com/users/greentec/gists{/gist_id}", "starred_url": "https://api.github.com/users/greentec/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/greentec/subscriptions", "organizations_url": "https://api.github.com/users/greentec/orgs", "repos_url": "https://api.github.com/users/greentec/repos", "events_url": "https://api.github.com/users/greentec/events{/privacy}", "received_events_url": "https://api.github.com/users/greentec/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2020-05-01T13:05:08Z", "updated_at": "2020-05-05T20:05:48Z", "closed_at": "2020-05-05T19:28:56Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nChecksums for oxford_iiit_pet dataset is changed.\r\n\r\n**Environment information**\r\n* Operating System: Google Colab\r\n* Python version: 3.6.9 (default, Nov  7 2019, 10:44:02) \\n[GCC 8.3.0]\r\n* `tensorflow-datasets`/`tfds-nightly` version: 2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: 2.2.0-rc3\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\n# dataset, info = tfds.load('oxford_iiit_pet:3.0.0', with_info=True)\r\ndataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\r\n```\r\n\r\n**Link to logs**\r\nhttps://gist.github.com/greentec/f36b550c9b8c51b559ae3bb80588ae53\r\n\r\n**Expected behavior**\r\nLoad the Oxford Pet Dataset normally.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1977", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1977/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1977/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1977/events", "html_url": "https://github.com/tensorflow/datasets/issues/1977", "id": 609839413, "node_id": "MDU6SXNzdWU2MDk4Mzk0MTM=", "number": 1977, "title": "Checksums for oxford_flowers102 changed", "user": {"login": "lgeiger", "id": 13285808, "node_id": "MDQ6VXNlcjEzMjg1ODA4", "avatar_url": "https://avatars1.githubusercontent.com/u/13285808?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lgeiger", "html_url": "https://github.com/lgeiger", "followers_url": "https://api.github.com/users/lgeiger/followers", "following_url": "https://api.github.com/users/lgeiger/following{/other_user}", "gists_url": "https://api.github.com/users/lgeiger/gists{/gist_id}", "starred_url": "https://api.github.com/users/lgeiger/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lgeiger/subscriptions", "organizations_url": "https://api.github.com/users/lgeiger/orgs", "repos_url": "https://api.github.com/users/lgeiger/repos", "events_url": "https://api.github.com/users/lgeiger/events{/privacy}", "received_events_url": "https://api.github.com/users/lgeiger/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-04-30T11:17:20Z", "updated_at": "2020-05-21T14:04:58Z", "closed_at": "2020-05-01T18:12:38Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Short description**\r\nThe checksum for `oxford_flowers102` changed recently which breaks downloading of the dataset.\r\n\r\n**Environment information**\r\n* Operating System: macOS\r\n* Python version: 3.7\r\n* `tensorflow-datasets`/`tfds-nightly` version: 3.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: 2.2.0rc3\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nrm -r ~/tensorflow_datasets/oxford_flowers102/\r\nrm -r ~/tensorflow_datasets/downloads\r\n```\r\n```python\r\ntfds.load(\"oxford_flowers102\", split=\"train\")\r\n```\r\n\r\n**Link to logs**\r\n```\r\nArtifact https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz, downloaded to ~/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_102flowersoWedSp98maBn1wypsDib6T-q2NVbO40fwvTflmPmQpY.tgz.tmp.9496e46fb0ed404fa5b339ba8c39a725/102flowers.tgz, has wrong checksum. This might indicate:\r\n * The website may be down (e.g. returned a 503 status code). Please check the url.\r\n * For Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See https://github.com/tensorflow/datasets/issues/1482\r\n * The original datasets files may have been updated. In this case the TFDS dataset builder should be updated to use the new files and checksums. Sorry about that. Please open an issue or send us a PR with a fix.\r\n * If you're adding a new dataset, don't forget to register the checksums as explained in: https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally\r\n```\r\n\r\n**Expected behavior**\r\nChecksums should match and extraction would succeed.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1975", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1975/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1975/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1975/events", "html_url": "https://github.com/tensorflow/datasets/issues/1975", "id": 609496797, "node_id": "MDU6SXNzdWU2MDk0OTY3OTc=", "number": 1975, "title": "Strange CUDA_ERROR_OPERATING_SYSTEM error", "user": {"login": "mbaharan", "id": 33820892, "node_id": "MDQ6VXNlcjMzODIwODky", "avatar_url": "https://avatars0.githubusercontent.com/u/33820892?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mbaharan", "html_url": "https://github.com/mbaharan", "followers_url": "https://api.github.com/users/mbaharan/followers", "following_url": "https://api.github.com/users/mbaharan/following{/other_user}", "gists_url": "https://api.github.com/users/mbaharan/gists{/gist_id}", "starred_url": "https://api.github.com/users/mbaharan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mbaharan/subscriptions", "organizations_url": "https://api.github.com/users/mbaharan/orgs", "repos_url": "https://api.github.com/users/mbaharan/repos", "events_url": "https://api.github.com/users/mbaharan/events{/privacy}", "received_events_url": "https://api.github.com/users/mbaharan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-30T01:45:51Z", "updated_at": "2020-06-11T17:45:15Z", "closed_at": "2020-06-11T17:45:15Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nWhen I run the attached code in Visual Studio Code, it perfectly runs, however, it gives me the following error in terminal:\r\n```\r\nUsing TensorFlow backend.\r\n2020-04-29 20:38:19.353406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-04-29 20:38:19.355244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n2.1.0\r\nI0429 20:38:21.922154 140355061643072 dataset_info.py:430] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: imagenet2012/5.0.0\r\nI0429 20:38:22.127279 140355061643072 dataset_info.py:361] Load dataset info from /tmp/tmpazbl_w1stfds\r\nI0429 20:38:22.133743 140355061643072 dataset_info.py:401] Field info.description from disk and from code do not match. Keeping the one from code.\r\nI0429 20:38:22.133888 140355061643072 dataset_info.py:401] Field info.citation from disk and from code do not match. Keeping the one from code.\r\nI0429 20:38:22.134435 140355061643072 dataset_builder.py:333] Generating dataset imagenet2012 (/mnt/2TB/tf_imagenet/raw_data/imagenet2012/5.0.0)\r\nDownloading and preparing dataset imagenet2012/5.0.0 (download: 144.02 GiB, generated: Unknown size, total: 144.02 GiB) to /mnt/2TB/tf_imagenet/raw_data/imagenet2012/5.0.0...\r\nI0429 20:38:25.899271 140355061643072 dataset_builder.py:924] Generating split train\r\n76738 examples [01:01, 1077.61 examples/s]2020-04-29 20:39:27.416213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-04-29 20:39:27.507741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: TITAN V computeCapability: 7.0\r\ncoreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\r\n2020-04-29 20:39:27.511579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:82:00.0 name: TITAN V computeCapability: 7.0\r\ncoreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\r\n2020-04-29 20:39:27.511672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-04-29 20:39:27.511736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-04-29 20:39:27.888134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-04-29 20:39:27.977509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-04-29 20:39:28.687471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-04-29 20:39:28.741244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-04-29 20:39:28.741321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-04-29 20:39:28.744550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2020-04-29 20:39:28.745108: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-04-29 20:39:28.773996: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400170000 Hz\r\n2020-04-29 20:39:28.776362: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x495dfb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-29 20:39:28.776389: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-04-29 20:39:29.020400: W tensorflow/compiler/xla/service/platform_util.cc:276] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS\r\n2020-04-29 20:39:29.020784: W tensorflow/compiler/xla/service/platform_util.cc:276] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS\r\n2020-04-29 20:39:29.021112: I tensorflow/compiler/jit/xla_gpu_device.cc:136] Ignoring visible XLA_GPU_JIT device. Device number is 0, reason: Internal: no supported devices found for platform CUDA\r\n2020-04-29 20:39:29.227347: W tensorflow/compiler/xla/service/platform_util.cc:276] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS\r\n2020-04-29 20:39:29.227517: W tensorflow/compiler/xla/service/platform_util.cc:276] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS\r\n2020-04-29 20:39:29.227869: I tensorflow/compiler/jit/xla_gpu_device.cc:136] Ignoring visible XLA_GPU_JIT device. Device number is 1, reason: Internal: no supported devices found for platform CUDA\r\n2020-04-29 20:39:29.349563: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OPERATING_SYSTEM: OS call failed or operation not supported on this OS\r\nFatal Python error: Aborted\r\nThread 0x00007fa6a0c64700 (most recent call first):\r\n  File \"/usr/lib/python3.6/threading.py\", line 299 in wait\r\n  File \"/usr/lib/python3.6/threading.py\", line 551 in wait\r\n  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_monitor.py\", line 69 in run\r\n  File \"/usr/lib/python3.6/threading.py\", line 916 in _bootstrap_inner\r\n  File \"/usr/lib/python3.6/threading.py\", line 884 in _bootstrap\r\n\r\nCurrent thread 0x00007fa6f5977740 (most recent call first):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/context.py\", line 509 in ensure_initialized\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 95 in convert_to_eager_tensor\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 266 in _constant_impl\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 258 in constant\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 317 in _constant_tensor_conversion_function\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1314 in convert_to_tensor\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_image_ops.py\", line 1129 in decode_jpeg_eager_fallback\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_image_ops.py\", line 1063 in decode_jpeg\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/utils/tf_utils.py\", line 75 in run\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/utils/image_utils.py\", line 54 in jpeg_cmyk_to_rgb\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/image_classification/imagenet.py\", line 175 in _fix_image\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/image_classification/imagenet.py\", line 196 in _generate_examples\r\n  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 1032 in __iter__\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 1011 in _prepare_split\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 928 in _download_and_prepare\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 996 in _download_and_prepare\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 363 in download_and_prepare\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/api_utils.py\", line 69 in disallow_positional_args_dec\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/registered.py\", line 369 in load\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/api_utils.py\", line 69 in disallow_positional_args_dec\r\n  File \"./train.py\", line 39 in get_imagenet_dataset\r\n  File \"./train.py\", line 59 in main\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299 in run\r\n  File \"./train.py\", line 132 in <module>\r\nAborted (core dumped)\r\n\r\n```\r\n**Environment information**\r\n* Operating System: Ubuntu 18.04.4 LTS\r\n* Python version: 3.6.9\r\n* `tensorflow-datasets` version: 3.1.0\r\n* `tensorflow-gpu` version: 2.1.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport os\r\nimport math\r\nimport numpy as np\r\nimport cv2 as cv\r\nimport keras\r\nimport tensorflow as tf\r\n\r\nfrom keras.applications import mobilenet\r\nfrom keras.applications.mobilenet import MobileNet\r\nfrom keras.applications.mobilenet import preprocess_input, decode_predictions\r\nfrom keras import optimizers\r\nfrom keras.preprocessing import image\r\nfrom keras.utils import to_categorical\r\n\r\nimport tensorflow_datasets as tfds\r\nfrom utils.utils import build_optimizer\r\n\r\nfrom absl import app\r\nfrom absl import flags\r\n\r\nflags.DEFINE_string(\"data_dir\", None,\r\n                    \"ImageNet dataset directory.\")\r\n\r\nFLAGS = flags.FLAGS\r\n\r\ndef main(_):\r\n  ds = tfds.load(name=\"imagenet2012\", data_dir=FLAGS.data_dir)\r\n\r\nif __name__ == \"__main__\":\r\n  flags.mark_flag_as_required(\"data_dir\")\r\n  #flags.mark_flag_as_required(\"model_name\")\r\n  #flags.mark_flag_as_required(\"ckpt_dir\")\r\n  #flags.mark_flag_as_required(\"output_tflite\")\r\n  app.run(main)\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1963", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1963/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1963/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1963/events", "html_url": "https://github.com/tensorflow/datasets/issues/1963", "id": 608477411, "node_id": "MDU6SXNzdWU2MDg0Nzc0MTE=", "number": 1963, "title": "AssertionError: No examples were yielded for Rock_Paper_Scissors", "user": {"login": "balajivenky06", "id": 12076782, "node_id": "MDQ6VXNlcjEyMDc2Nzgy", "avatar_url": "https://avatars3.githubusercontent.com/u/12076782?v=4", "gravatar_id": "", "url": "https://api.github.com/users/balajivenky06", "html_url": "https://github.com/balajivenky06", "followers_url": "https://api.github.com/users/balajivenky06/followers", "following_url": "https://api.github.com/users/balajivenky06/following{/other_user}", "gists_url": "https://api.github.com/users/balajivenky06/gists{/gist_id}", "starred_url": "https://api.github.com/users/balajivenky06/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/balajivenky06/subscriptions", "organizations_url": "https://api.github.com/users/balajivenky06/orgs", "repos_url": "https://api.github.com/users/balajivenky06/repos", "events_url": "https://api.github.com/users/balajivenky06/events{/privacy}", "received_events_url": "https://api.github.com/users/balajivenky06/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-28T17:09:19Z", "updated_at": "2020-04-29T03:29:12Z", "closed_at": "2020-04-29T03:29:12Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nDescription of the bug.\r\nAssertionError: No examples were yielded.\r\nShuffling and writing examples to C:\\Users\\hp\\tensorflow_datasets\\rock_paper_scissors\\3.0.0.incomplete6IRJSB\\rock_paper_scissors-train.tfrecord\r\n**Environment information**\r\n* Operating System: windows 10\r\n* Python version: <3.7>\r\n_NAME_RE = re.compile(r\"^(rps|rps-test-set)/(rock|paper|scissors)/[\\w-]*\\.png$\") re.compile is wrong... please check", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1960", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1960/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1960/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1960/events", "html_url": "https://github.com/tensorflow/datasets/issues/1960", "id": 607896017, "node_id": "MDU6SXNzdWU2MDc4OTYwMTc=", "number": 1960, "title": "[GSoC] Investigate current kokoro failure.", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-04-27T22:28:45Z", "updated_at": "2020-04-29T00:01:30Z", "closed_at": "2020-04-29T00:01:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Our builds are failing at head: https://source.cloud.google.com/results/invocations/08727437-e079-4920-bd0d-4929781edcef/targets/tensorflow_datasets%2Fgh_testing%2Fcontinuous/log\r\n\r\n```\r\n____________________ DocumentDatasetsTest.test_with_config _____________________\r\n...\r\n>     if builder_cls.BUILDER_CONFIGS:\r\nE     AttributeError: type object 'EmptyDatasetBuilder' has no attribute 'BUILDER_CONFIGS'\r\n\r\ntensorflow_datasets/core/registered.py:456: AttributeError\r\n```\r\n\r\nAs far as understand:\r\n* (1) Executing `document_datasets_test.py` execute `core/registered_test.py`, probably during imports.\r\n* (2) When `registered_test` is executed, the `EmptyDatasetBuilder` is registered\r\n* (3) `document_datasets_test` crash because `EmptyDatasetBuilder` is not a `registered dataset`.\r\n\r\nThe issue is (1). It's not clear why executing `import tensorflow_datasets as tfds` execute the `core/registered_test.py` even though the file isn't imported anywhere. This seems like a bug. Is this an issue with pytype used to run the tests ?", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1949", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1949/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1949/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1949/events", "html_url": "https://github.com/tensorflow/datasets/issues/1949", "id": 606630915, "node_id": "MDU6SXNzdWU2MDY2MzA5MTU=", "number": 1949, "title": "[GSoC] Fix documentation images", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-24T23:11:57Z", "updated_at": "2020-04-29T18:52:13Z", "closed_at": "2020-04-29T18:52:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "https://github.com/tensorflow/datasets/pull/1948 is adding visualisation to the documentation, however it seems that images have visual artefacts (missing images, bad labels,...).\r\nIt is likely due to the fact that matplotlib do not support multi-threading. We should investigate if the `scripts/generate_visualization.py`  can use multi-processing instead of multi-processing.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1928", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1928/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1928/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1928/events", "html_url": "https://github.com/tensorflow/datasets/issues/1928", "id": 604413335, "node_id": "MDU6SXNzdWU2MDQ0MTMzMzU=", "number": 1928, "title": "Typo in description of duke_ultrasound \"avalible\"", "user": {"login": "MaxGhenis", "id": 6076111, "node_id": "MDQ6VXNlcjYwNzYxMTE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6076111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MaxGhenis", "html_url": "https://github.com/MaxGhenis", "followers_url": "https://api.github.com/users/MaxGhenis/followers", "following_url": "https://api.github.com/users/MaxGhenis/following{/other_user}", "gists_url": "https://api.github.com/users/MaxGhenis/gists{/gist_id}", "starred_url": "https://api.github.com/users/MaxGhenis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MaxGhenis/subscriptions", "organizations_url": "https://api.github.com/users/MaxGhenis/orgs", "repos_url": "https://api.github.com/users/MaxGhenis/repos", "events_url": "https://api.github.com/users/MaxGhenis/events{/privacy}", "received_events_url": "https://api.github.com/users/MaxGhenis/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1257633672, "node_id": "MDU6TGFiZWwxMjU3NjMzNjcy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/documentation", "name": "documentation", "color": "fbca04", "default": true, "description": "Pull Request or Issue related with comments or documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-22T02:51:56Z", "updated_at": "2020-07-23T17:41:26Z", "closed_at": "2020-07-23T17:41:26Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nhttps://www.tensorflow.org/datasets/catalog/duke_ultrasound says:\r\n>A usage example is avalible here.\r\n\r\nShould be \"available\"\r\n\r\nhttps://github.com/tensorflow/datasets/blob/d4e0e83a2c7b5ee8b807d036493ef0329e8f446e/tensorflow_datasets/testing/metadata/duke_ultrasound/1.0.0/dataset_info.json#L3", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1923", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1923/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1923/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1923/events", "html_url": "https://github.com/tensorflow/datasets/issues/1923", "id": 604245463, "node_id": "MDU6SXNzdWU2MDQyNDU0NjM=", "number": 1923, "title": "How to filter the dataset to get images from a specific class?", "user": {"login": "rao208", "id": 44291384, "node_id": "MDQ6VXNlcjQ0MjkxMzg0", "avatar_url": "https://avatars1.githubusercontent.com/u/44291384?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rao208", "html_url": "https://github.com/rao208", "followers_url": "https://api.github.com/users/rao208/followers", "following_url": "https://api.github.com/users/rao208/following{/other_user}", "gists_url": "https://api.github.com/users/rao208/gists{/gist_id}", "starred_url": "https://api.github.com/users/rao208/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rao208/subscriptions", "organizations_url": "https://api.github.com/users/rao208/orgs", "repos_url": "https://api.github.com/users/rao208/repos", "events_url": "https://api.github.com/users/rao208/events{/privacy}", "received_events_url": "https://api.github.com/users/rao208/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-21T19:55:48Z", "updated_at": "2020-04-23T16:30:44Z", "closed_at": "2020-04-23T16:30:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I need help with / What I was wondering**\r\n\r\nI want to use pre-trained networks to train my dataset. I am a novice at this and right now just exploring and playing with the basic dataset cats_vs_dogs as given in the link:\r\n\r\n[https://www.tensorflow.org/tutorials/images/transfer_learning ](URL)\r\n\r\nI am using the exact same code with some modifications like one-hot encoding and the architecture of my own.\r\n\r\nI was wondering how to plot the images of only one class in cat_vs_dog dataset i.e. either cat or dog. In other words, I want to separate the dataset belonging to class 'cat' from that belonging to class 'dog'. I would like to do this not for training purpose, but to achieve some different goals\r\n\r\n**What I've tried so far**\r\n\r\nThere is an answer on StackOverflow ([https://stackoverflow.com/questions/55731774/filter-dataset-to-get-just-images-from-specific-class](URL))\r\n\r\nUnfortunately, this didn't give the desired output because of the following issues:\r\n\r\n* **Issue 1:** label = x['label'] in predicate function gave me error\r\n\r\n> TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'label'\r\n\r\nSo, I replaced x['label'] with x[0] i.e. class 'cat'. The predicate function looks something like this:\r\n\r\n```\r\ndef predicate(x, allowed_labels=tf.constant([0.])):\r\n    label = x[0]\r\n    isallowed = tf.equal( tf.cast(allowed_labels, tf.float32), tf.cast(label, tf.float32))\r\n    reduced = tf.reduce_sum(tf.cast(isallowed, tf.float32))\r\n    return tf.greater(reduced, tf.constant(0.))\r\n\r\ntrain = raw_train.map(format_example)\r\nvalidation = raw_validation.map(format_example)\r\ntest = raw_test.map(format_example)\r\n\r\ntrain = train.filter(predicate)\r\nvalidation = validation.filter(predicate)\r\ntest = test.filter(predicate)\r\n\r\nfor image, label in train.take(10):\r\n    print(\"label---\", label)\r\n    plt.figure()\r\n    plt.imshow(image)\r\n    plt.title(get_label_name(label))\r\n\r\nplt.show()\r\n```\r\n\r\nThe output is:\r\n\r\n```\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\nlabel--- tf.Tensor(1, shape=(), dtype=int64)\r\n```\r\nSo, it is basically giving me only class 'dog', even when I input class 'cat'. Maybe this is because predicate function returns **tf.greater(reduced, tf.constant(0.))**.\r\n\r\n* **Issue 2:**\r\n\r\nIn a naive attempt, to overcome Issue 1, I changed return to \r\n`return tf.greater_equal(reduced, tf.constant(0.))` and `return tf.greater(reduced, tf.constant(-1.))`\r\n\r\nand due to obvious reasons, it didn't work. \r\n\r\n* **Issue 3:**\r\n\r\nAlso, let's say I have more than two classes like cifar10 dataset and I would like to keep class 4 and 7 and filter out the rest of the classes. Then, how should I modify the code? As mentioned before x['label'] is giving me an error.\r\n\r\nIs it possible to make predicate function more generic, so that I can keep N number of classes and filter out the rest of the classes? or is there any other way to filter the dataset to get images from a specific class?\r\n\r\n**Environment information**\r\n* Operating System: <windows>\r\n* Distribution: Anaconda\r\n* Python version: <3.7.7>\r\n* Tensorflow 2.1\r\n* tensorflow_datasets 1.2.0\r\n\r\nPlease let me know if any more information is required. Thank you for your help in advance.\r\n\r\nBest Regards", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1917", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1917/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1917/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1917/events", "html_url": "https://github.com/tensorflow/datasets/issues/1917", "id": 603102689, "node_id": "MDU6SXNzdWU2MDMxMDI2ODk=", "number": 1917, "title": "tensorflow_datasets.image.MNIST overriding to add extra functionality", "user": {"login": "SouBanerjee", "id": 35866182, "node_id": "MDQ6VXNlcjM1ODY2MTgy", "avatar_url": "https://avatars2.githubusercontent.com/u/35866182?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SouBanerjee", "html_url": "https://github.com/SouBanerjee", "followers_url": "https://api.github.com/users/SouBanerjee/followers", "following_url": "https://api.github.com/users/SouBanerjee/following{/other_user}", "gists_url": "https://api.github.com/users/SouBanerjee/gists{/gist_id}", "starred_url": "https://api.github.com/users/SouBanerjee/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SouBanerjee/subscriptions", "organizations_url": "https://api.github.com/users/SouBanerjee/orgs", "repos_url": "https://api.github.com/users/SouBanerjee/repos", "events_url": "https://api.github.com/users/SouBanerjee/events{/privacy}", "received_events_url": "https://api.github.com/users/SouBanerjee/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-20T09:52:39Z", "updated_at": "2020-06-11T17:27:04Z", "closed_at": "2020-06-11T17:27:04Z", "author_association": "NONE", "active_lock_reason": null, "body": "Hi,\r\nI am new to tensorflow\r\nI was wondering how to override predefined tensorflow_datasets.image.MNIST for my own work.\r\nFor example:\r\n    I want to create a split-mnist dataset in which I will be accessing images from only two classes at a single time, how to modify MNIST class or how to inherit MNIST class to add that feature.\r\n\r\nIn pytorch, I could inherit torchvision.datasets.MNIST into another class and then I could get a mask for the classes for which I need to access the images and then I could get the images of those classes by calling the dataloader and for that I just needed to pass the class_labels for which classes I need images as an argument to the inherited class\r\n\r\n**Environment information**\r\n(if applicable)\r\n* Operating System: Ubuntu 18.04\r\n* Python version: 3.7\r\n* `tensorflow-datasets version: 1.2.0\r\n* `tensorflow-gpu version: 2.1.0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1901", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1901/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1901/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1901/events", "html_url": "https://github.com/tensorflow/datasets/issues/1901", "id": 602199572, "node_id": "MDU6SXNzdWU2MDIxOTk1NzI=", "number": 1901, "title": "caltech_birds yields no examples on windows", "user": {"login": "Eshan-Agarwal", "id": 47007275, "node_id": "MDQ6VXNlcjQ3MDA3Mjc1", "avatar_url": "https://avatars0.githubusercontent.com/u/47007275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Eshan-Agarwal", "html_url": "https://github.com/Eshan-Agarwal", "followers_url": "https://api.github.com/users/Eshan-Agarwal/followers", "following_url": "https://api.github.com/users/Eshan-Agarwal/following{/other_user}", "gists_url": "https://api.github.com/users/Eshan-Agarwal/gists{/gist_id}", "starred_url": "https://api.github.com/users/Eshan-Agarwal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Eshan-Agarwal/subscriptions", "organizations_url": "https://api.github.com/users/Eshan-Agarwal/orgs", "repos_url": "https://api.github.com/users/Eshan-Agarwal/repos", "events_url": "https://api.github.com/users/Eshan-Agarwal/events{/privacy}", "received_events_url": "https://api.github.com/users/Eshan-Agarwal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-17T19:54:26Z", "updated_at": "2020-06-08T18:39:32Z", "closed_at": "2020-04-30T03:34:37Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment information**\r\n* Operating System: <os>Windows 10\r\n* Issue is specific to windows.\r\n\r\n**Short description**\r\n`caltech_birds.py` yields no example on windows this is due to windows take `\\` in path and other platform takes `/`. Error is in [line#49](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image_classification/caltech_birds.py#L49) & [line#173](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image_classification/caltech_birds.py#L173)\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\nds, ds_info = tfds.load(\"caltech_birds\", with_info = True)\r\nprint(ds_info)\r\n```\r\n\r\n**Link to logs**\r\nFor full stacktrace is [here](https://gist.github.com/Eshan-Agarwal/c2b54f8fa60e5863fdeeda96261977e6)\r\n\r\n**Expected behavior**\r\n`caltech_birds` dataset able to loaded and yield examples on windows also\r\n\r\n**Additional context**\r\n1. This works fine on Linux/Mac as error is due to windows path using backslash while other using forward slash.\r\n2. [line#49](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image_classification/caltech_birds.py#L49) can be replaced as `_NAME_RE = re.compile(r\"((\\w*)[/\\\\])*(\\d*).(\\w*)[/\\\\](\\w*.jpg)$\")`, but paths in archive is like `CUB_200_2011\\images\\035.Purple_Finch\\Purple_Finch_0091_27425.jpg` and windows takes `\\035` as hexadecimal `\\x035` and gives path string as `CUB_200_2011\\images\\x035.Purple_Finch\\Purple_Finch_0091_27425.jpg` so suggested regx pattern wont help much.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1888", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1888/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1888/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1888/events", "html_url": "https://github.com/tensorflow/datasets/issues/1888", "id": 601454355, "node_id": "MDU6SXNzdWU2MDE0NTQzNTU=", "number": 1888, "title": "Horses_or_Humans - No Examples Yielded", "user": {"login": "lmoroney", "id": 1134591, "node_id": "MDQ6VXNlcjExMzQ1OTE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1134591?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lmoroney", "html_url": "https://github.com/lmoroney", "followers_url": "https://api.github.com/users/lmoroney/followers", "following_url": "https://api.github.com/users/lmoroney/following{/other_user}", "gists_url": "https://api.github.com/users/lmoroney/gists{/gist_id}", "starred_url": "https://api.github.com/users/lmoroney/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lmoroney/subscriptions", "organizations_url": "https://api.github.com/users/lmoroney/orgs", "repos_url": "https://api.github.com/users/lmoroney/repos", "events_url": "https://api.github.com/users/lmoroney/events{/privacy}", "received_events_url": "https://api.github.com/users/lmoroney/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-04-16T20:46:19Z", "updated_at": "2020-04-16T23:20:00Z", "closed_at": "2020-04-16T23:20:00Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Short description**\r\nUsing Windows 10\r\n\r\nRun:\r\ndataset_name = \"horses_or_humans\"\r\ndataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True)\r\n\r\nDataset will download, but when extracting will give error:\r\n\r\nShuffling and writing examples to C:\\Users\\lmoro\\tensorflow_datasets\\horses_or_humans\\3.0.0.incomplete185N4P\\horses_or_humans-train.tfrecord\r\nTraceback (most recent call last):\r\n  File \"D:/bookwork/testwindows/venv/test.py\", line 5, in <module>\r\n    dataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\wrapt\\wrappers.py\", line 567, in __call__\r\n    args, kwargs)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\", line 305, in load\r\n    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\wrapt\\wrappers.py\", line 606, in __call__\r\n    args, kwargs)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 334, in download_and_prepare\r\n    download_config=download_config)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 1030, in _download_and_prepare\r\n    max_examples_per_split=download_config.max_examples_per_split,\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 883, in _download_and_prepare\r\n    self._prepare_split(split_generator, **prepare_split_kwargs)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 1058, in _prepare_split\r\n    shard_lengths = writer.finalize()\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_writer.py\", line 211, in finalize\r\n    self._shuffler.bucket_lengths, self._path)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_writer.py\", line 88, in _get_shard_specs\r\n    shard_boundaries = _get_shard_boundaries(num_examples, num_shards)\r\n  File \"D:\\bookwork\\testwindows\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_writer.py\", line 107, in _get_shard_boundaries\r\n    raise AssertionError(\"No examples were yielded.\")\r\nAssertionError: No examples were yielded.\r\n\r\n\r\n**Environment information**\r\n* Operating System: Windows 10\r\n* Python version: 3.7.3\r\n* `tensorflow-datasets`/`tfds-nightly` version: 2.0.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: 2.0.0\r\n\r\n**Reproduction instructions**\r\n\r\nRun on Windows. The issue I believe is in the path separators. It's fine on Mac, Linux and Colab, but fails on Windows.\r\n\r\n```\r\ndataset_name = \"horses_or_humans\"\r\ndataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True)\r\n```\r\n\r\n**Expected behavior**\r\nTF Records to be extracted.\r\n\r\n**Additional context**\r\nWhen using 1.3.2, the .tfrecord files are extracted but empty. Upgrade to 2.0.0 gives this error, further upgrades (to 3.0.0) and the error stays.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1867", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1867/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1867/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1867/events", "html_url": "https://github.com/tensorflow/datasets/issues/1867", "id": 599060598, "node_id": "MDU6SXNzdWU1OTkwNjA1OTg=", "number": 1867, "title": "Adding duke_ultrasound dataset to gs://tfds-data/datasets", "user": {"login": "Ouwen", "id": 5455421, "node_id": "MDQ6VXNlcjU0NTU0MjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5455421?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Ouwen", "html_url": "https://github.com/Ouwen", "followers_url": "https://api.github.com/users/Ouwen/followers", "following_url": "https://api.github.com/users/Ouwen/following{/other_user}", "gists_url": "https://api.github.com/users/Ouwen/gists{/gist_id}", "starred_url": "https://api.github.com/users/Ouwen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Ouwen/subscriptions", "organizations_url": "https://api.github.com/users/Ouwen/orgs", "repos_url": "https://api.github.com/users/Ouwen/repos", "events_url": "https://api.github.com/users/Ouwen/events{/privacy}", "received_events_url": "https://api.github.com/users/Ouwen/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2020-04-13T18:41:07Z", "updated_at": "2020-06-08T22:05:24Z", "closed_at": "2020-06-08T22:04:57Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "* Name of dataset: duke_ultrasound\r\n* URL of dataset: `https://www.tensorflow.org/datasets/catalog/duke_ultrasound`\r\n* License of dataset: Creative Commons BY-NC Attribution-NonCommercial 4.0 International\r\n\r\nI am the creator of the `duke_ultrasound` dataset and was interested in hosting the dataset through `gs://tfds-data/datasets`. I believe this will make it easier for researchers to use/access and is better than hosting it in our own bucket. Please let me know if the license for the data would need to change, or if there are other steps for the data transfer. Much appreciated!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1866", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1866/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1866/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1866/events", "html_url": "https://github.com/tensorflow/datasets/issues/1866", "id": 598839525, "node_id": "MDU6SXNzdWU1OTg4Mzk1MjU=", "number": 1866, "title": "[data request] <COCO>", "user": {"login": "renzhiwei1997", "id": 62872263, "node_id": "MDQ6VXNlcjYyODcyMjYz", "avatar_url": "https://avatars1.githubusercontent.com/u/62872263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/renzhiwei1997", "html_url": "https://github.com/renzhiwei1997", "followers_url": "https://api.github.com/users/renzhiwei1997/followers", "following_url": "https://api.github.com/users/renzhiwei1997/following{/other_user}", "gists_url": "https://api.github.com/users/renzhiwei1997/gists{/gist_id}", "starred_url": "https://api.github.com/users/renzhiwei1997/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/renzhiwei1997/subscriptions", "organizations_url": "https://api.github.com/users/renzhiwei1997/orgs", "repos_url": "https://api.github.com/users/renzhiwei1997/repos", "events_url": "https://api.github.com/users/renzhiwei1997/events{/privacy}", "received_events_url": "https://api.github.com/users/renzhiwei1997/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168524723, "node_id": "MDU6TGFiZWwxMTY4NTI0NzIz", "url": "https://api.github.com/repos/tensorflow/datasets/labels/dataset%20request", "name": "dataset request", "color": "beb7ff", "default": false, "description": "Request for a new dataset to be added"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-13T11:33:25Z", "updated_at": "2020-08-03T07:12:01Z", "closed_at": "2020-08-03T07:12:01Z", "author_association": "NONE", "active_lock_reason": null, "body": "* Name of dataset: <name>\r\n* URL of dataset: <url>\r\n* License of dataset: <license type>\r\n* Short description of dataset and use case(s): <description>\r\n\r\nFolks who would also like to see this dataset in `tensorflow/datasets`, please thumbs-up so the developers can know which requests to prioritize.\r\n\r\nAnd if you'd like to contribute the dataset (thank you!), see our [guide to adding a dataset](https://github.com/tensorflow/datasets/blob/master/docs/add_dataset.md).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1865", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1865/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1865/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1865/events", "html_url": "https://github.com/tensorflow/datasets/issues/1865", "id": 598839262, "node_id": "MDU6SXNzdWU1OTg4MzkyNjI=", "number": 1865, "title": "coco", "user": {"login": "renzhiwei1997", "id": 62872263, "node_id": "MDQ6VXNlcjYyODcyMjYz", "avatar_url": "https://avatars1.githubusercontent.com/u/62872263?v=4", "gravatar_id": "", "url": "https://api.github.com/users/renzhiwei1997", "html_url": "https://github.com/renzhiwei1997", "followers_url": "https://api.github.com/users/renzhiwei1997/followers", "following_url": "https://api.github.com/users/renzhiwei1997/following{/other_user}", "gists_url": "https://api.github.com/users/renzhiwei1997/gists{/gist_id}", "starred_url": "https://api.github.com/users/renzhiwei1997/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/renzhiwei1997/subscriptions", "organizations_url": "https://api.github.com/users/renzhiwei1997/orgs", "repos_url": "https://api.github.com/users/renzhiwei1997/repos", "events_url": "https://api.github.com/users/renzhiwei1997/events{/privacy}", "received_events_url": "https://api.github.com/users/renzhiwei1997/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168524723, "node_id": "MDU6TGFiZWwxMTY4NTI0NzIz", "url": "https://api.github.com/repos/tensorflow/datasets/labels/dataset%20request", "name": "dataset request", "color": "beb7ff", "default": false, "description": "Request for a new dataset to be added"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-13T11:32:46Z", "updated_at": "2020-04-13T16:27:03Z", "closed_at": "2020-04-13T16:27:03Z", "author_association": "NONE", "active_lock_reason": null, "body": "* Name of dataset: <name>\r\n* URL of dataset: <url>\r\n* License of dataset: <license type>\r\n* Short description of dataset and use case(s): <description>\r\n\r\nFolks who would also like to see this dataset in `tensorflow/datasets`, please thumbs-up so the developers can know which requests to prioritize.\r\n\r\nAnd if you'd like to contribute the dataset (thank you!), see our [guide to adding a dataset](https://github.com/tensorflow/datasets/blob/master/docs/add_dataset.md).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1862", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1862/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1862/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1862/events", "html_url": "https://github.com/tensorflow/datasets/issues/1862", "id": 598448330, "node_id": "MDU6SXNzdWU1OTg0NDgzMzA=", "number": 1862, "title": "Dataset wikipedia cannot be loaded at version 1.0.0, only: 0.0.3", "user": {"login": "dvirginz", "id": 31047807, "node_id": "MDQ6VXNlcjMxMDQ3ODA3", "avatar_url": "https://avatars2.githubusercontent.com/u/31047807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dvirginz", "html_url": "https://github.com/dvirginz", "followers_url": "https://api.github.com/users/dvirginz/followers", "following_url": "https://api.github.com/users/dvirginz/following{/other_user}", "gists_url": "https://api.github.com/users/dvirginz/gists{/gist_id}", "starred_url": "https://api.github.com/users/dvirginz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dvirginz/subscriptions", "organizations_url": "https://api.github.com/users/dvirginz/orgs", "repos_url": "https://api.github.com/users/dvirginz/repos", "events_url": "https://api.github.com/users/dvirginz/events{/privacy}", "received_events_url": "https://api.github.com/users/dvirginz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-12T09:43:13Z", "updated_at": "2020-04-13T07:44:28Z", "closed_at": "2020-04-13T07:44:28Z", "author_association": "NONE", "active_lock_reason": null, "body": "tfds nightly, downloaded the wikipedia dataset using:\r\n`python -m tensorflow_datasets.scripts.download_and_prepare --datasets=wikipedia/20190301.en`\r\nNow trying to access it using \r\n`ds, info = tfds.load('wikipedia/20190301.en:1.0.0', download=False, shuffle_files=True, with_info=True)`\r\n\r\nBut receiving the error\r\n```\r\nERROR:absl:Failed to construct dataset wikipedia\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n in \r\n      1 # Construct a tf.data.Dataset\r\n----> 2 ds, info = tfds.load('wikipedia/20190301.en:1.0.0', download=False, shuffle_files=True, with_info=True)\r\n\r\n~\\Anaconda3\\envs\\docBert\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     ismethod = instance is not None\r\n     51     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n---> 52     _check_required(fn, kwargs)\r\n     53     return fn(*args, **kwargs)\r\n     54 \r\n\r\n~\\Anaconda3\\envs\\docBert\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py in load(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\r\n    295       [the guide](https://github.com/tensorflow/datasets/tree/master/docs/decode.md)\r\n    296       for more info.\r\n--> 297     read_config: `tfds.ReadConfig`, Additional options to configure the\r\n    298       input pipeline (e.g. seed, num parallel reads,...).\r\n    299     with_info: `bool`, if True, tfds.load will return the tuple\r\n\r\n~\\Anaconda3\\envs\\docBert\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py in builder(name, **builder_init_kwargs)\r\n    167     elif class_dict.get(\"IN_DEVELOPMENT\"):\r\n    168       _IN_DEVELOPMENT_REGISTRY[name] = builder_cls\r\n--> 169     else:\r\n    170       _DATASET_REGISTRY[name] = builder_cls\r\n    171     return builder_cls\r\n\r\n~\\Anaconda3\\envs\\docBert\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)\r\n     50     ismethod = instance is not None\r\n     51     _check_no_positional(fn, args, ismethod, allowed=allowed)\r\n---> 52     _check_required(fn, kwargs)\r\n     53     return fn(*args, **kwargs)\r\n     54 \r\n\r\n~\\Anaconda3\\envs\\docBert\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in __init__(self, data_dir, config, version)\r\n    178         `builder_config`s will have their own subdirectories and versions.\r\n    179       version: `str`. Optional version at which to load the dataset. An error is\r\n--> 180         raised if specified version cannot be satisfied. Eg: '1.2.3', '1.2.*'.\r\n    181         The special value \"experimental_latest\" will use the highest version,\r\n    182         even if not default. This is not recommended unless you know what you\r\n\r\n~\\Anaconda3\\envs\\docBert\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in _pick_version(self, requested_version)\r\n    209   def __setstate__(self, state):\r\n    210     self.__init__(**state)\r\n--> 211 \r\n    212   @utils.memoized_property\r\n    213   def canonical_version(self):\r\n\r\nAssertionError: Dataset wikipedia cannot be loaded at version 1.0.0, only: 0.0.3.\r\n```", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1859", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1859/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1859/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1859/events", "html_url": "https://github.com/tensorflow/datasets/issues/1859", "id": 598102541, "node_id": "MDU6SXNzdWU1OTgxMDI1NDE=", "number": 1859, "title": "curated_breast_imaging_ddsm dataset creates unequal patch shapes.", "user": {"login": "haakontk", "id": 38468400, "node_id": "MDQ6VXNlcjM4NDY4NDAw", "avatar_url": "https://avatars3.githubusercontent.com/u/38468400?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haakontk", "html_url": "https://github.com/haakontk", "followers_url": "https://api.github.com/users/haakontk/followers", "following_url": "https://api.github.com/users/haakontk/following{/other_user}", "gists_url": "https://api.github.com/users/haakontk/gists{/gist_id}", "starred_url": "https://api.github.com/users/haakontk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haakontk/subscriptions", "organizations_url": "https://api.github.com/users/haakontk/orgs", "repos_url": "https://api.github.com/users/haakontk/repos", "events_url": "https://api.github.com/users/haakontk/events{/privacy}", "received_events_url": "https://api.github.com/users/haakontk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-10T21:27:46Z", "updated_at": "2020-04-10T22:23:39Z", "closed_at": "2020-04-10T22:23:39Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\n[cbis_ddsm.py](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image_classification/cbis_ddsm.py) creates unequal patch shapes. \r\n\r\n**Environment information**\r\n* Operating System: Ubuntu 18.04.3 LTS\r\n* Python version: Python 3.7.7. [GCC 7.3.0] :: Anaconda, Inc. on linux\r\n* `tensorflow-datasets`/ version: 1.2.0\r\n* `tensorflow` version: 2.1.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport os\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\n\r\n\r\n\r\n# Getting data directory from environment varialbe\r\ndata_directory = os.environ['CBIS_DDSM']\r\n\r\n# Changing manual_dir from default (~/tensorflow_datasets/manual/) to environment path.\r\ntfds.download.DownloadManager.manual_dir = data_directory\r\n\r\nds, ds_info = tfds.load('curated_breast_imaging_ddsm',\r\n                data_dir = data_directory,\r\n                with_info = True)\r\nds_test    = ds['test']\r\n\r\nfor element in ds_test.take(10):\r\n    image = element['image']\r\n    print(image.shape)\r\n```\r\n\r\n**Output**\r\n2020-04-10 23:16:23.055173: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-04-10 23:16:23.064116: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2020-04-10 23:16:23.064148: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hakon-PC): /proc/driver/nvidia/version does not exist\r\n2020-04-10 23:16:23.064512: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2020-04-10 23:16:23.089820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3593415000 Hz\r\n2020-04-10 23:16:23.092120: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d0adba9c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-10 23:16:23.092169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nWARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\r\n(224, 224, 1)\r\n(224, 82, 1)\r\n(224, 224, 1)\r\n(224, 224, 1)\r\n(224, 189, 1)\r\n(224, 224, 1)\r\n(224, 224, 1)\r\n(224, 224, 1)\r\n(224, 178, 1)\r\n(224, 224, 1)\r\n\r\n\r\n**Expected behavior**\r\nI expected all shapes to be (224, 224, 1)\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1853", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1853/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1853/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1853/events", "html_url": "https://github.com/tensorflow/datasets/issues/1853", "id": 597958201, "node_id": "MDU6SXNzdWU1OTc5NTgyMDE=", "number": 1853, "title": "`stable_versions.txt` should not have `VERSION` equal to `None`", "user": {"login": "vijayphoenix", "id": 41972768, "node_id": "MDQ6VXNlcjQxOTcyNzY4", "avatar_url": "https://avatars3.githubusercontent.com/u/41972768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vijayphoenix", "html_url": "https://github.com/vijayphoenix", "followers_url": "https://api.github.com/users/vijayphoenix/followers", "following_url": "https://api.github.com/users/vijayphoenix/following{/other_user}", "gists_url": "https://api.github.com/users/vijayphoenix/gists{/gist_id}", "starred_url": "https://api.github.com/users/vijayphoenix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vijayphoenix/subscriptions", "organizations_url": "https://api.github.com/users/vijayphoenix/orgs", "repos_url": "https://api.github.com/users/vijayphoenix/repos", "events_url": "https://api.github.com/users/vijayphoenix/events{/privacy}", "received_events_url": "https://api.github.com/users/vijayphoenix/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-10T15:50:20Z", "updated_at": "2020-04-11T00:19:35Z", "closed_at": "2020-04-11T00:19:35Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Short description**\r\nThe list of stable versions of the datasets includes `wmt_translate/None`\r\nhttps://github.com/tensorflow/datasets/blob/d87ac2c0ecc0655400841a3a502c7c6775f1b6bf/tensorflow_datasets/stable_versions.txt#L1525\r\n\r\nSo, this can be interpreted as a stable dataset `wmt_translate` with `VERSION = None`\r\n\r\n**Enviroment-info**\r\n* `tensorflow-datasets`/`tfds-nightly` version: tfds:2.1.0 and tfds-nightly\r\n\r\n**Expected behavior**\r\nInclude a default version field in `wmt_translate` or exclude `wmt_translate` from the `tfds.core.registered.list_full_names()`.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1849", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1849/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1849/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1849/events", "html_url": "https://github.com/tensorflow/datasets/issues/1849", "id": 597147078, "node_id": "MDU6SXNzdWU1OTcxNDcwNzg=", "number": 1849, "title": "Typo.", "user": {"login": "haakontk", "id": 38468400, "node_id": "MDQ6VXNlcjM4NDY4NDAw", "avatar_url": "https://avatars3.githubusercontent.com/u/38468400?v=4", "gravatar_id": "", "url": "https://api.github.com/users/haakontk", "html_url": "https://github.com/haakontk", "followers_url": "https://api.github.com/users/haakontk/followers", "following_url": "https://api.github.com/users/haakontk/following{/other_user}", "gists_url": "https://api.github.com/users/haakontk/gists{/gist_id}", "starred_url": "https://api.github.com/users/haakontk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/haakontk/subscriptions", "organizations_url": "https://api.github.com/users/haakontk/orgs", "repos_url": "https://api.github.com/users/haakontk/repos", "events_url": "https://api.github.com/users/haakontk/events{/privacy}", "received_events_url": "https://api.github.com/users/haakontk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1257633672, "node_id": "MDU6TGFiZWwxMjU3NjMzNjcy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/documentation", "name": "documentation", "color": "fbca04", "default": true, "description": "Pull Request or Issue related with comments or documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-09T09:25:15Z", "updated_at": "2020-07-23T17:41:25Z", "closed_at": "2020-07-23T17:41:25Z", "author_association": "NONE", "active_lock_reason": null, "body": "Typo in [cbis_ddsm.py](https://github.com/tensorflow/datasets/blob/f2f1267a25f7b25eb8fefd2960e7570b72b1ba28/tensorflow_datasets/image_classification/cbis_ddsm.py#L416) line 416.\r\n`benign_or_malignant = 'BENING'` -> `benign_or_malignant = 'BENIGN'`", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1846", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1846/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1846/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1846/events", "html_url": "https://github.com/tensorflow/datasets/issues/1846", "id": 596704401, "node_id": "MDU6SXNzdWU1OTY3MDQ0MDE=", "number": 1846, "title": "DatasetBuilder is failing to load a certain datasets", "user": {"login": "shikhar2707", "id": 36820528, "node_id": "MDQ6VXNlcjM2ODIwNTI4", "avatar_url": "https://avatars0.githubusercontent.com/u/36820528?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shikhar2707", "html_url": "https://github.com/shikhar2707", "followers_url": "https://api.github.com/users/shikhar2707/followers", "following_url": "https://api.github.com/users/shikhar2707/following{/other_user}", "gists_url": "https://api.github.com/users/shikhar2707/gists{/gist_id}", "starred_url": "https://api.github.com/users/shikhar2707/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shikhar2707/subscriptions", "organizations_url": "https://api.github.com/users/shikhar2707/orgs", "repos_url": "https://api.github.com/users/shikhar2707/repos", "events_url": "https://api.github.com/users/shikhar2707/events{/privacy}", "received_events_url": "https://api.github.com/users/shikhar2707/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-04-08T16:26:06Z", "updated_at": "2020-04-08T16:46:24Z", "closed_at": "2020-04-08T16:41:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nThe tfds DatasetBuilder is failing to load a certain dataset.\r\nI wrote a basic piece of code to check if it can load all the registered datasets or not.\r\nThe code - \r\n`Dataset_List = tfds.list_builders()`\r\n`Count = 0`\r\n`for i in range(len(Dataset_List)):`\r\n    `try:`\r\n        `tfds.builder(Dataset_List[i]).info`\r\n    `except:`\r\n        `Count += 1`\r\nwhich in turns returns the error\r\n`ERROR:absl:Failed to construct dataset my_dataset`\r\n`ERROR:absl:Failed to construct dataset open_images_v4`\r\n`ERROR:absl:Failed to construct dataset wmt_translate`\r\n\r\n**Environment information**\r\n* Operating System:  Windows 10 x64 4GB RAM\r\n* Python version: 3.7\r\n* `tensorflow-datasets`/`tfds-nightly` version: Tensorflow 2.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: <package and version>\r\n\r\n**Expected behavior**\r\nThe Datasets should load comfortably.\r\non", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1834", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1834/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1834/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1834/events", "html_url": "https://github.com/tensorflow/datasets/issues/1834", "id": 595925363, "node_id": "MDU6SXNzdWU1OTU5MjUzNjM=", "number": 1834, "title": "[GSoC] Clevr dataset generation is failing", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-07T14:46:54Z", "updated_at": "2020-04-07T21:03:33Z", "closed_at": "2020-04-07T21:03:33Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Clevr was updated recently in https://github.com/tensorflow/datasets/commit/af54aaf4b525fd6624319a0e38d6b3fc50870e23. \r\n\r\nHowever generation seems to be failing for the `test` set with:\r\n\r\n```\r\ntensorflow_datasets/image/clevr.py\", line 107, in _generate_examples\r\n    \"answer\": q[\"answer\"],\r\nKeyError: 'answer'\r\n```\r\n\r\nWe should investigate and fix Clevr generation.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1830", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1830/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1830/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1830/events", "html_url": "https://github.com/tensorflow/datasets/issues/1830", "id": 595545712, "node_id": "MDU6SXNzdWU1OTU1NDU3MTI=", "number": 1830, "title": "[GSoC] Avoid registering tests datasets", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}, {"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-04-07T02:29:12Z", "updated_at": "2020-04-07T21:04:11Z", "closed_at": "2020-04-07T21:04:10Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently `tfds.list_builder` list [`dummy_mnist`](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/testing/test_utils.py#L393) and other test-only datasets. We should make sure to avoid registering those datasets.\r\n\r\n* Add `with tfds.core.registered.skip_registeration():` context manager which when applied skip dataset registration. Changes should go in `registered.py`. Add tests in `registered_test.py`.\r\n* Apply this to the public API: https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/public_api.py#L24\r\n\r\n```\r\nwith core.registered.skip_registeration():\r\n  from tensorflow_datasets import testing\r\n```\r\n\r\n* Add a `test_dataset_registered.py` which check that `tfds.list_builder` do not contains `dummy_mnist` or other test datasets.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1825", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1825/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1825/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1825/events", "html_url": "https://github.com/tensorflow/datasets/issues/1825", "id": 595495094, "node_id": "MDU6SXNzdWU1OTU0OTUwOTQ=", "number": 1825, "title": "[GSoC] Update document_datasets to indicate which datasets are tfds-nightly only", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}, {"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-06T23:44:10Z", "updated_at": "2020-04-29T21:38:12Z", "closed_at": "2020-04-29T21:38:12Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Currently, some datasets are present in `tfds-nightly` but not yet on the stable version. This confuse users which think the dataset do not exists (like in https://github.com/tensorflow/datasets/issues/1692).\r\n\r\nWe should add a `Note:` in the dataset documentation `.md` to explain the dataset is only available in https://www.tensorflow.org/api_docs/python/tf/raw_ops/Abort.\r\n\r\nTo do this:\r\n\r\n1. Add a new script `freeze_dataset_versions.py` which call [`list_full_names`](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/core/registered.py#L407) to save all datasets full names (e.g. `mnist/3.0.2`, `c4/en/2.0.0`) to some `stable_versions.txt` file.\r\n2. Update the [document_datasets.py](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/scripts/document_datasets.py) script to update the dataset documentation when dataset name/config/version isn't found in the `stable_version.txt` list.\r\n\r\nIn addition of the `Note:`, we should add the [nights_stay](https://material.io/resources/icons/?icon=nights_stay&style=baseline) icon with a tooltip saying \"Only available in tfds-nigthly\": \r\n   * When the dataset name is new, the icon should be added on the dataset name header.\r\n   * When the config is new, the icon should appear on the config name header (e.g. https://www.tensorflow.org/datasets/catalog/wikipedia#wikipedia20200301cho)\r\n   * When the version is new, the icon should be added next to the version number. Note that the previous stable version should still be displayed on the list.\r\n\r\nNote: The solution should not reload the `stable_version.txt` for each dataset but instead load it once and re-use it across all datasets.\r\n\r\nTo test the documentation generation, you can use the following code snippet:\r\n\r\n```python\r\nimport os\r\n\r\nfrom tensorflow_datasets.scripts import generate_visualization  # Your new script\r\nfrom tensorflow_datasets.scripts import document_datasets\r\n\r\nDATASET_TO_TESTS = ['mnist', 'cifar10',...]  # Datasets you want to test the script on.\r\ndst_dir = ...  # Destination directory\r\n\r\ndef main(_):\r\n  for ds_name in DATASET_TO_TESTS:\r\n    # 1) Generate the datasets (as script assume the datasets are already generated)\r\n    tfds.load(ds_name)  \r\n\r\n    # 2) Generate and save the documentation page\r\n    doc_content = document_datasets.dataset_docs_str([ds_name])\r\n    with open(os.path.join(dst_dir, f'{ds_name}.md')) as f:\r\n      f.write(doc_content)\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1824", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1824/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1824/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1824/events", "html_url": "https://github.com/tensorflow/datasets/issues/1824", "id": 595453430, "node_id": "MDU6SXNzdWU1OTU0NTM0MzA=", "number": 1824, "title": "Kaggle downloader fails to download datasets", "user": {"login": "vijayphoenix", "id": 41972768, "node_id": "MDQ6VXNlcjQxOTcyNzY4", "avatar_url": "https://avatars3.githubusercontent.com/u/41972768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vijayphoenix", "html_url": "https://github.com/vijayphoenix", "followers_url": "https://api.github.com/users/vijayphoenix/followers", "following_url": "https://api.github.com/users/vijayphoenix/following{/other_user}", "gists_url": "https://api.github.com/users/vijayphoenix/gists{/gist_id}", "starred_url": "https://api.github.com/users/vijayphoenix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vijayphoenix/subscriptions", "organizations_url": "https://api.github.com/users/vijayphoenix/orgs", "repos_url": "https://api.github.com/users/vijayphoenix/repos", "events_url": "https://api.github.com/users/vijayphoenix/events{/privacy}", "received_events_url": "https://api.github.com/users/vijayphoenix/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-06T21:55:09Z", "updated_at": "2020-04-17T19:47:34Z", "closed_at": "2020-04-17T19:47:34Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "**Short description**\r\nWhen downloading datasets from Kaggle using `dl_manager.download_kaggle_data()` function, it throws the following errors.\r\n```\r\nNonMatchingChecksumError: Artifact kaggle://competition/digit-recognizer/sample_submission.csv, downloaded to /root/tensorflow_datasets/competiti_digit-recognize_sample_submissioIUxxdxSEdFK1_W-trEIDwYRuks7CiRMFvbzIvDrAFcA.csv.tmp.6ee33ceae48442718ab6db436f6115fe/sample_submission.csv, has wrong checksum.\r\n```\r\nand in some other datasets\r\n```\r\nNotFoundError: /root/tensorflow_datasets/data_fire_us-coun-covi-19-data_us-counMuhrcRpwHSpUuZrqFnl9FdmeJs90GcVIwO9g0KC7BiU.csv.tmp.9e67f4fae786466fa5303ff6cf7a030d/us-counties.csv; No such file or directory\r\n```\r\n**Environment information and Reproduction instructions**\r\nColab Link : [link](https://colab.research.google.com/drive/1kdqmjjp-Omg3GfKO4FthubegCnJUrNqf)\r\n\r\n**Expected behavior**\r\nIt should download the dataset without any problem.\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1821", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1821/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1821/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1821/events", "html_url": "https://github.com/tensorflow/datasets/issues/1821", "id": 595291263, "node_id": "MDU6SXNzdWU1OTUyOTEyNjM=", "number": 1821, "title": "Got Unrecognized instruction format while spiting using subsplit ", "user": {"login": "Eshan-Agarwal", "id": 47007275, "node_id": "MDQ6VXNlcjQ3MDA3Mjc1", "avatar_url": "https://avatars0.githubusercontent.com/u/47007275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Eshan-Agarwal", "html_url": "https://github.com/Eshan-Agarwal", "followers_url": "https://api.github.com/users/Eshan-Agarwal/followers", "following_url": "https://api.github.com/users/Eshan-Agarwal/following{/other_user}", "gists_url": "https://api.github.com/users/Eshan-Agarwal/gists{/gist_id}", "starred_url": "https://api.github.com/users/Eshan-Agarwal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Eshan-Agarwal/subscriptions", "organizations_url": "https://api.github.com/users/Eshan-Agarwal/orgs", "repos_url": "https://api.github.com/users/Eshan-Agarwal/repos", "events_url": "https://api.github.com/users/Eshan-Agarwal/events{/privacy}", "received_events_url": "https://api.github.com/users/Eshan-Agarwal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-06T17:25:12Z", "updated_at": "2020-04-06T17:48:12Z", "closed_at": "2020-04-06T17:40:19Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Short description**\r\nI am loading `mnist` dataset using weighted subsplit ( `tfds.Split.TRAIN.subsplit(weighted = [2, 1, 1])` ) as per instruction [here](https://www.tensorflow.org/datasets/api_docs/python/tfds/core/NamedSplit#top_of_page) and got \r\n\r\n> AssertionError: Unrecognized instruction format: NamedSplit('train')(tfds.percent[0:50])\r\n\r\n**Environment information**\r\n* Operating System: <os> Colab\r\n* Python version: <version>\r\n* `tensorflow-datasets`/`tfds-nightly` version: <package and version> 2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: <package and version>\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\n\r\ns1, s2, s3 = tfds.Split.TRAIN.subsplit(weighted = [2, 1, 1])\r\n\r\ndataset,info= tfds.load('mnist',with_info=True, split=s1)\r\n```\r\n\r\n**Link to logs**\r\nlogs [link](https://gist.github.com/Eshan-Agarwal/20d0694760b971ef3281400455f30f33)\r\n\r\n**Expected behavior**\r\nSpliting works fine\r\n\r\n**Additional context**\r\nSee this [colab ](https://colab.research.google.com/drive/1Aai-803eDuifSHGaPwLBUhQu7LTMf0_r)\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1816", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1816/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1816/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1816/events", "html_url": "https://github.com/tensorflow/datasets/issues/1816", "id": 594428816, "node_id": "MDU6SXNzdWU1OTQ0Mjg4MTY=", "number": 1816, "title": "download_and_prepare for c4 dataset fails on DownloadManager error", "user": {"login": "shepsels", "id": 19605241, "node_id": "MDQ6VXNlcjE5NjA1MjQx", "avatar_url": "https://avatars2.githubusercontent.com/u/19605241?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shepsels", "html_url": "https://github.com/shepsels", "followers_url": "https://api.github.com/users/shepsels/followers", "following_url": "https://api.github.com/users/shepsels/following{/other_user}", "gists_url": "https://api.github.com/users/shepsels/gists{/gist_id}", "starred_url": "https://api.github.com/users/shepsels/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shepsels/subscriptions", "organizations_url": "https://api.github.com/users/shepsels/orgs", "repos_url": "https://api.github.com/users/shepsels/repos", "events_url": "https://api.github.com/users/shepsels/events{/privacy}", "received_events_url": "https://api.github.com/users/shepsels/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-04-05T12:13:27Z", "updated_at": "2020-04-06T18:12:23Z", "closed_at": "2020-04-06T17:44:35Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nWhen trying to generate c4 dataset on google cloud dataflow, download manager fails on ''DownloadManager' object has no attribute '_downloader' [while running 'Map(download_url)']'\r\n\r\n**Environment information**\r\n* Python version: 3.7.4\r\n* tensorflow-datasets v2.1.0\r\n* tensorflow v2.1.0\r\n\r\n**Reproduction instructions**\r\n* Following the instructions provided here: https://www.tensorflow.org/datasets/beam_datasets#on_google_cloud_dataflow (including running successfully the quickstart document). The dataflow job was created successfully and started uploading binaries and incomplete data to gs bucket, and failed in the step 'create_wet_files'.\r\n```\r\nFile \"../.pyenv/versions/3.7.4/envs/datasets-temp/lib/python3.7/site-packages/tensorflow_datasets/text/c4.py\", line 258, in download_url\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 315, in download\r\n    with self._downloader.tqdm():\r\nAttributeError: 'DownloadManager' object has no attribute '_downloader'\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1812", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1812/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1812/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1812/events", "html_url": "https://github.com/tensorflow/datasets/issues/1812", "id": 593949229, "node_id": "MDU6SXNzdWU1OTM5NDkyMjk=", "number": 1812, "title": "data.map fails when as_supervised=True in tfds.load", "user": {"login": "dandawg", "id": 12484302, "node_id": "MDQ6VXNlcjEyNDg0MzAy", "avatar_url": "https://avatars3.githubusercontent.com/u/12484302?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dandawg", "html_url": "https://github.com/dandawg", "followers_url": "https://api.github.com/users/dandawg/followers", "following_url": "https://api.github.com/users/dandawg/following{/other_user}", "gists_url": "https://api.github.com/users/dandawg/gists{/gist_id}", "starred_url": "https://api.github.com/users/dandawg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dandawg/subscriptions", "organizations_url": "https://api.github.com/users/dandawg/orgs", "repos_url": "https://api.github.com/users/dandawg/repos", "events_url": "https://api.github.com/users/dandawg/events{/privacy}", "received_events_url": "https://api.github.com/users/dandawg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-04-04T16:55:30Z", "updated_at": "2020-04-04T20:53:10Z", "closed_at": "2020-04-04T20:53:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nAfter loading data using `as_supervised=True`, I get the following error when using a lambda function inside of `map`:\r\n```\r\nTypeError: in converted code:\r\n    TypeError: <lambda>() takes 1 positional argument but 2 were given\r\n```\r\nThe error vanishes if `as_supervised=False`\r\n\r\n\r\n**Environment information**\r\n* Operating System: Linux Mint 18.1 Cinnamon 64-bit\r\n* Python version: 2.1.0\r\n* `tensorflow-datasets`/`tfds-nightly` version: 2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: NA\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\ndata = tfds.load('iris', as_supervised=True, split='train')\r\ndata = data.map(lambda ds: ds)\r\n\r\n# Returned error\r\nTraceback (most recent call last):\r\n...\r\nTypeError: in converted code:\r\n    TypeError: <lambda>() takes 1 positional argument but 2 were given\r\n\r\n```\r\nAs I mentioned, if I take out `as_supervised=True`, the map function runs just fine. I believe this is a bug because the `as_supervised` flag should just change the format of the Tensor elements, but not whether the `map` function works or not.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1811", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1811/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1811/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1811/events", "html_url": "https://github.com/tensorflow/datasets/issues/1811", "id": 593794814, "node_id": "MDU6SXNzdWU1OTM3OTQ4MTQ=", "number": 1811, "title": "tfds.show_examples rows parameter does work properly", "user": {"login": "nirajkale", "id": 40765055, "node_id": "MDQ6VXNlcjQwNzY1MDU1", "avatar_url": "https://avatars3.githubusercontent.com/u/40765055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nirajkale", "html_url": "https://github.com/nirajkale", "followers_url": "https://api.github.com/users/nirajkale/followers", "following_url": "https://api.github.com/users/nirajkale/following{/other_user}", "gists_url": "https://api.github.com/users/nirajkale/gists{/gist_id}", "starred_url": "https://api.github.com/users/nirajkale/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nirajkale/subscriptions", "organizations_url": "https://api.github.com/users/nirajkale/orgs", "repos_url": "https://api.github.com/users/nirajkale/repos", "events_url": "https://api.github.com/users/nirajkale/events{/privacy}", "received_events_url": "https://api.github.com/users/nirajkale/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-04-04T10:43:04Z", "updated_at": "2020-04-05T13:45:41Z", "closed_at": "2020-04-05T13:45:41Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nSay I have loaded a dataset using tfds & if I use tfds.show_exmaples to plot examples. the argument for number of rows does not work properly. It seems to plot rows = argument value +1 (seems like its following 0 based index or something). I know its nitpicking at this moment but thought I'll report it anyway.\r\nThanks\r\n\r\n**Environment information**\r\nI'm using google colab\r\n* Operating System: google colab\r\n* Python version: 3.6.8\r\n* `tensorflow-datasets`/`tfds-nightly` version: tensorflow-datasets 2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: tensorflow 2.1\r\n\r\n**Reproduction instructions**\r\n```\r\nimport tensorflow_datasets as tfds\r\nds_train, info_train = tfds.load('cats_vs_dogs', split= 'train[:80%]', with_info= True)\r\ntfds.show_examples(info_train, ds_train, rows= 1, cols = 3)\r\n```\r\nThis seems to show 2 rows instead of 1\r\n\r\n**Expected behavior**\r\nThis should have printed only 1 row", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1804", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1804/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1804/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1804/events", "html_url": "https://github.com/tensorflow/datasets/issues/1804", "id": 593677212, "node_id": "MDU6SXNzdWU1OTM2NzcyMTI=", "number": 1804, "title": "No files found for wiki-40B datasets", "user": {"login": "geoffbacon", "id": 11916848, "node_id": "MDQ6VXNlcjExOTE2ODQ4", "avatar_url": "https://avatars1.githubusercontent.com/u/11916848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/geoffbacon", "html_url": "https://github.com/geoffbacon", "followers_url": "https://api.github.com/users/geoffbacon/followers", "following_url": "https://api.github.com/users/geoffbacon/following{/other_user}", "gists_url": "https://api.github.com/users/geoffbacon/gists{/gist_id}", "starred_url": "https://api.github.com/users/geoffbacon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/geoffbacon/subscriptions", "organizations_url": "https://api.github.com/users/geoffbacon/orgs", "repos_url": "https://api.github.com/users/geoffbacon/repos", "events_url": "https://api.github.com/users/geoffbacon/events{/privacy}", "received_events_url": "https://api.github.com/users/geoffbacon/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2020-04-03T22:40:52Z", "updated_at": "2020-04-06T16:30:58Z", "closed_at": "2020-04-06T16:30:58Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nI can't download the Wiki-40B datasets.\r\n\r\n**Environment information**\r\n* Operating System: OSX\r\n* Python version: 3.7.5\r\n* `tensorflow-datasets`/`tfds-nightly` version: tfds-nightly 2.1.0.dev202004030105\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: tensorflow 2.1.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\npython -m tensorflow_datasets.scripts.download_and_prepare \\\r\n--datasets=wiki40b/Wiki40B.it\r\n```\r\nHere, I've illustrated with the Italian dataset, but none of the other languages seem to download either.\r\n\r\n**Link to logs**\r\n```\r\nI0403 15:30:20.204281 4533941696 download_and_prepare.py:197] Running download_and_prepare for dataset(s):\r\nwiki40b/Wiki40B.it\r\nI0403 15:30:20.204676 4533941696 dataset_builder.py:203] Load pre-computed datasetinfo (eg: splits) from bucket.\r\nI0403 15:30:20.392930 4533941696 dataset_info.py:428] Loading info from GCS for wiki40b/Wiki40B.it/1.1.0\r\nI0403 15:30:20.534743 4533941696 dataset_info.py:400] Field info.description from disk and from code do not match. Keeping the one from code.\r\nI0403 15:30:20.534955 4533941696 dataset_info.py:400] Field info.redistribution_info from disk and from code do not match. Keeping the one from code.\r\nI0403 15:30:20.535104 4533941696 download_and_prepare.py:136] download_and_prepare for dataset wiki40b/Wiki40B.it/1.1.0...\r\nI0403 15:30:20.854214 4533941696 dataset_builder.py:337] Generating dataset wiki40b (/Users/bacon/tensorflow_datasets/wiki40b/Wiki40B.it/1.1.0)\r\nDownloading and preparing dataset wiki40b/Wiki40B.it/1.1.0 (download: Unknown size, generated: 2.00 GiB, total: 2.00 GiB) to /Users/bacon/tensorflow_datasets/wiki40b/Wiki40B.it/1.1.0\r\n...\r\nI0403 15:30:21.059412 4533941696 pipeline.py:175] Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\r\nI0403 15:30:21.064759 4533941696 dataset_builder.py:915] Generating split train\r\nI0403 15:30:21.065811 4533941696 wiki40b.py:134] generating examples from = /bigstore/tfds-data/downloads/wiki40b/tfrecord_prod/train/it_examples-*\r\nTraceback (most recent call last):\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/scripts/download_and_prepare.py\", line 237, in <module>\r\n    app.run(main)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/scripts/download_and_prepare.py\", line 232, in main\r\n    download_and_prepare(builder)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/scripts/download_and_prepare.py\", line 153, in download_and_prepare\r\n    download_config=dl_config,\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 53, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 367, in download_and_prepare\r\n    download_config=download_config)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 1181, in _download_and_prepare\r\n    pipeline=pipeline,\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 919, in _download_and_prepare\r\n    self._prepare_split(split_generator, **prepare_split_kwargs)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 1229, in _prepare_split\r\n    _ = pipeline | split_name >> _build_pcollection()   # pylint: disable=no-value-for-parameter\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 989, in __ror__\r\n    return self.transform.__ror__(pvalueish, self.label)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 549, in __ror__\r\n    result = p.apply(self, pvalueish, label)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 536, in apply\r\n    return self.apply(transform, pvalueish)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/pipeline.py\", line 577, in apply\r\n    pvalueish_result = self.runner.apply(transform, pvalueish, self._options)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 195, in apply\r\n    return m(transform, input, options)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/runners/runner.py\", line 225, in apply_PTransform\r\n    return transform.expand(input)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/transforms/ptransform.py\", line 913, in expand\r\n    return self._fn(pcoll, *args, **kwargs)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 1223, in _build_pcollection\r\n    pipeline, **split_generator.gen_kwargs)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/tensorflow_datasets/text/wiki40b.py\", line 154, in _build_pcollection\r\n    | beam.FlatMap(_extract_content))\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/io/tfrecordio.py\", line 261, in __init__\r\n    validate)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/io/tfrecordio.py\", line 178, in __init__\r\n    validate=validate)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/io/filebasedsource.py\", line 125, in __init__\r\n    self._validate()\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/options/value_provider.py\", line 140, in _f\r\n    return fnc(self, *args, **kwargs)\r\n  File \"/Users/bacon/miniconda/envs/model/lib/python3.7/site-packages/apache_beam/io/filebasedsource.py\", line 186, in _validate\r\n    'No files found based on the file pattern %s' % pattern)\r\nOSError: No files found based on the file pattern /bigstore/tfds-data/downloads/wiki40b/tfrecord_prod/train/it_examples-*\r\n```\r\n\r\n**Expected behavior**\r\nI'd expect the datasets to download.\r\n\r\n**Additional context**\r\nThe [Wikipedia](https://www.tensorflow.org/datasets/catalog/wikipedia) datasets download fine.\r\n\r\n```\r\npython -m tensorflow_datasets.scripts.download_and_prepare \\\r\n--datasets=wikipedia/20190301.aa\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1792", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1792/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1792/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1792/events", "html_url": "https://github.com/tensorflow/datasets/issues/1792", "id": 593052248, "node_id": "MDU6SXNzdWU1OTMwNTIyNDg=", "number": 1792, "title": "[GSoC] Update fake data for caltech_birds2011 & other datasets", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-03T03:32:08Z", "updated_at": "2020-06-10T18:13:34Z", "closed_at": "2020-06-10T18:13:34Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "The fake data for `caltech_birds2011` is way to big (> 100MB). We should investigate where does this huge size comes from and try to reduce it.\r\n\r\nFake data is at https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/testing/test_data/fake_examples/caltech_birds2011\r\nThe test is at: https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image_classification/caltech_birds_test.py\r\n\r\nAmong the other datasets which have huge fake data size are:\r\n* abstract_reasoning\r\n* waymo\r\n* duke_ultra_sound\r\n* starcraft\r\n\r\nThose datasets take more than 70% of all fake data size. caltech_birds2011 is almost half of it.\r\nReducing the size of those fake data would have a huge impact on our github repository size.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1783", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1783/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1783/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1783/events", "html_url": "https://github.com/tensorflow/datasets/issues/1783", "id": 591956129, "node_id": "MDU6SXNzdWU1OTE5NTYxMjk=", "number": 1783, "title": "Error while extracting long named datasets.", "user": {"login": "Eshan-Agarwal", "id": 47007275, "node_id": "MDQ6VXNlcjQ3MDA3Mjc1", "avatar_url": "https://avatars0.githubusercontent.com/u/47007275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Eshan-Agarwal", "html_url": "https://github.com/Eshan-Agarwal", "followers_url": "https://api.github.com/users/Eshan-Agarwal/followers", "following_url": "https://api.github.com/users/Eshan-Agarwal/following{/other_user}", "gists_url": "https://api.github.com/users/Eshan-Agarwal/gists{/gist_id}", "starred_url": "https://api.github.com/users/Eshan-Agarwal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Eshan-Agarwal/subscriptions", "organizations_url": "https://api.github.com/users/Eshan-Agarwal/orgs", "repos_url": "https://api.github.com/users/Eshan-Agarwal/repos", "events_url": "https://api.github.com/users/Eshan-Agarwal/events{/privacy}", "received_events_url": "https://api.github.com/users/Eshan-Agarwal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-04-01T14:22:48Z", "updated_at": "2020-04-16T23:36:59Z", "closed_at": "2020-04-16T23:36:59Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Environment information**\r\n* Operating System: <os> Windows 10\r\n* Python version: <version>\r\n* `tensorflow-datasets`/`tfds-nightly` version: <package and version> 2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: <package and version> 2.1.0\r\n\r\n**Short description**\r\nGot extract error when try to extract `plant_village` dataset using `tfds.load()`. This error occurs because path name of extraction file is very long for `plant_village `dataset. `ZIP.data.mend.com_data_tywb_1_file_127d-7c63-4rDQyRTmE0CqGGXmH53WlQp0NWefMfDW89aj1A0m5D_A.zip.incomplete_ee6bd33c39f64df4a87a438bdda8bc29/Plant_leave_diseases_dataset_without_augmentation`. due to which it fails to make new directory inside this directory, I tried manually to make folder but it fails and give error `file name too long` .\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\nds,ds_info = tfds.load(\"plant_village\", with_info = True)\r\nprint(ds_info)\r\n```\r\n\r\n**logs**\r\nExtractError: Error while extracting C:\\Users\\eshan\\tensorflow_datasets\\downloads\\data.mend.com_data_tywb_1_file_127d-7c63-4rDQyRTmE0CqGGXmH53WlQp0NWefMfDW89aj1A0m5D_A.zip to C:\\Users\\eshan\\tensorflow_datasets\\downloads\\extracted\\ZIP.data.mend.com_data_tywb_1_file_127d-7c63-4rDQyRTmE0CqGGXmH53WlQp0NWefMfDW89aj1A0m5D_A.zip (file: Plant_leave_diseases_dataset_without_augmentation\\Apple___Apple_scab\\image (1).JPG) : Failed to create a directory: C:\\Users\\eshan\\tensorflow_datasets\\downloads\\extracted\\ZIP.data.mend.com_data_tywb_1_file_127d-7c63-4rDQyRTmE0CqGGXmH53WlQp0NWefMfDW89aj1A0m5D_A.zip.incomplete_ee6bd33c39f64df4a87a438bdda8bc29\\Plant_leave_diseases_dataset_without_augmentation/Apple___Apple_scab; No such file or directory\r\n\r\n\r\n**Expected behavior**\r\nThere is no problem in extraction of dataset.\r\n\r\n**Additional context**\r\nThis works fine in colab as error occur only when user forgot to disable path length limit in python.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1781", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1781/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1781/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1781/events", "html_url": "https://github.com/tensorflow/datasets/issues/1781", "id": 591833285, "node_id": "MDU6SXNzdWU1OTE4MzMyODU=", "number": 1781, "title": "[Stanford_dogs] No examples yielded", "user": {"login": "Flowhill", "id": 8323119, "node_id": "MDQ6VXNlcjgzMjMxMTk=", "avatar_url": "https://avatars0.githubusercontent.com/u/8323119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Flowhill", "html_url": "https://github.com/Flowhill", "followers_url": "https://api.github.com/users/Flowhill/followers", "following_url": "https://api.github.com/users/Flowhill/following{/other_user}", "gists_url": "https://api.github.com/users/Flowhill/gists{/gist_id}", "starred_url": "https://api.github.com/users/Flowhill/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Flowhill/subscriptions", "organizations_url": "https://api.github.com/users/Flowhill/orgs", "repos_url": "https://api.github.com/users/Flowhill/repos", "events_url": "https://api.github.com/users/Flowhill/events{/privacy}", "received_events_url": "https://api.github.com/users/Flowhill/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 16, "created_at": "2020-04-01T11:12:53Z", "updated_at": "2020-04-03T10:55:09Z", "closed_at": "2020-04-02T21:28:53Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nWhen performing the following snippet of code:\r\n`tfds.load(\"stanford_dogs\")`\r\n\r\nthe error: _AssertionError(\"No examples were yielded.\")_ is thrown\r\n\r\n**Environment information**\r\n* Operating System: Windows 10\r\n* Python version: 3.6.10 |Anaconda, Inc.| (default, Mar 23 2020, 17:58:33) [MSC v.1916 64 bit (AMD64)]\r\n* `tensorflow-datasets`/`tfds-nightly` version: tensorflow-datasets=2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version:\r\nVia _'pip freeze | findstr tensorflow'_\r\ntensorflow==2.1.0\r\ntensorflow-datasets==2.1.0\r\ntensorflow-estimator==2.1.0\r\ntensorflow-metadata==0.21.1\r\n\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\ntfds.load(\"stanford_dogs\")\r\n```\r\n\r\n**Link to logs**\r\n_[1mDownloading and preparing dataset stanford_dogs/0.2.0 (download: 778.12 MiB, generated: Unknown size, total: 778.12 MiB) to C:\\Users\\Flowhill\\tensorflow_datasets\\stanford_dogs\\0.2.0...\u001b[0m\r\nDl Completed...: 0 url [00:00, ? url/s]\r\nDl Size...: 0 MiB [00:00, ? MiB/s]\r\nDl Size...: 0 MiB [00:00, ? MiB/s]\r\n\r\nDl Completed...: 0 url [00:00, ? url/s]\r\nDl Completed...: 0 url [00:00, ? url/s]\r\nDl Size...: 0 MiB [00:00, ? MiB/s]\r\n\r\nExtraction completed...: 0 file [00:00, ? file/s]\r\nExtraction completed...: 0 file [00:00, ? file/s]\r\n\r\nDl Size...: 0 MiB [00:00, ? MiB/s]\r\n\r\nDl Completed...: 0 url [00:00, ? url/s]\r\nShuffling and writing examples to C:\\Users\\Flowhill\\tensorflow_datasets\\stanford_dogs\\0.2.0.incomplete37A45O\\stanford_dogs-train.tfrecord\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\", line 305, in load\r\n    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 340, in download_and_prepare\r\n    download_config=download_config)\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 1078, in _download_and_prepare\r\n    max_examples_per_split=download_config.max_examples_per_split,\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 931, in _download_and_prepare\r\n    self._prepare_split(split_generator, **prepare_split_kwargs)\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 1106, in _prepare_split\r\n    shard_lengths, total_size = writer.finalize()\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_writer.py\", line 211, in finalize\r\n    self._shuffler.bucket_lengths, self._path)\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_writer.py\", line 88, in _get_shard_specs\r\n    shard_boundaries = _get_shard_boundaries(num_examples, num_shards)\r\n  File \"C:\\Users\\Flowhill\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_writer.py\", line 107, in _get_shard_boundaries\r\n    raise AssertionError(\"No examples were yielded.\")\r\nAssertionError: No examples were yielded._\r\n\r\n**Expected behavior**\r\nStanford dogs was already downloaded so no download bars there as expected.\r\nRunning this with tfds.load(\"mnist\") produces no errors.\r\n\r\n**Additional context**\r\nA similar problem happened to a user using the PlantVillage and The300wLpTest datasets [here](https://github.com/tensorflow/datasets/issues/1670).\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1765", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1765/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1765/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1765/events", "html_url": "https://github.com/tensorflow/datasets/issues/1765", "id": 590224119, "node_id": "MDU6SXNzdWU1OTAyMjQxMTk=", "number": 1765, "title": "Wrong sentence formation in colab notebook", "user": {"login": "shikhar2707", "id": 36820528, "node_id": "MDQ6VXNlcjM2ODIwNTI4", "avatar_url": "https://avatars0.githubusercontent.com/u/36820528?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shikhar2707", "html_url": "https://github.com/shikhar2707", "followers_url": "https://api.github.com/users/shikhar2707/followers", "following_url": "https://api.github.com/users/shikhar2707/following{/other_user}", "gists_url": "https://api.github.com/users/shikhar2707/gists{/gist_id}", "starred_url": "https://api.github.com/users/shikhar2707/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shikhar2707/subscriptions", "organizations_url": "https://api.github.com/users/shikhar2707/orgs", "repos_url": "https://api.github.com/users/shikhar2707/repos", "events_url": "https://api.github.com/users/shikhar2707/events{/privacy}", "received_events_url": "https://api.github.com/users/shikhar2707/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-03-30T11:44:48Z", "updated_at": "2020-04-02T00:25:11Z", "closed_at": "2020-04-02T00:25:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "The line underneath tfds.load() says\r\ntfds.load() is a convenient method that is, the simplest way to build and load a `tf.data.Dataset.`\r\nDoesnt seem a correctly formed sentence.\r\nI have sent a PR regarding this. @Conchylicultor please check if it is okay.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1762", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1762/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1762/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1762/events", "html_url": "https://github.com/tensorflow/datasets/issues/1762", "id": 590007301, "node_id": "MDU6SXNzdWU1OTAwMDczMDE=", "number": 1762, "title": "Improve the TFDS Getting Started Documentation", "user": {"login": "ashutosh1919", "id": 20843596, "node_id": "MDQ6VXNlcjIwODQzNTk2", "avatar_url": "https://avatars3.githubusercontent.com/u/20843596?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashutosh1919", "html_url": "https://github.com/ashutosh1919", "followers_url": "https://api.github.com/users/ashutosh1919/followers", "following_url": "https://api.github.com/users/ashutosh1919/following{/other_user}", "gists_url": "https://api.github.com/users/ashutosh1919/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashutosh1919/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashutosh1919/subscriptions", "organizations_url": "https://api.github.com/users/ashutosh1919/orgs", "repos_url": "https://api.github.com/users/ashutosh1919/repos", "events_url": "https://api.github.com/users/ashutosh1919/events{/privacy}", "received_events_url": "https://api.github.com/users/ashutosh1919/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1257633672, "node_id": "MDU6TGFiZWwxMjU3NjMzNjcy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/documentation", "name": "documentation", "color": "fbca04", "default": true, "description": "Pull Request or Issue related with comments or documentation"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2020-03-30T05:37:01Z", "updated_at": "2020-06-04T00:32:42Z", "closed_at": "2020-06-04T00:32:42Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Duplicate of issue [#37330](https://github.com/tensorflow/tensorflow/issues/37330) from tf repo.\r\nAs per @lamberta's [#37330 comment](https://github.com/tensorflow/tensorflow/issues/37330#issuecomment-597806716), this issue is opened so that  issue on tf repo can be closed and this will be monitored. \r\nPR #1633  will fix this issue.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1757", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1757/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1757/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1757/events", "html_url": "https://github.com/tensorflow/datasets/issues/1757", "id": 589818668, "node_id": "MDU6SXNzdWU1ODk4MTg2Njg=", "number": 1757, "title": "Error in implementing some datasets", "user": {"login": "shikhar2707", "id": 36820528, "node_id": "MDQ6VXNlcjM2ODIwNTI4", "avatar_url": "https://avatars0.githubusercontent.com/u/36820528?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shikhar2707", "html_url": "https://github.com/shikhar2707", "followers_url": "https://api.github.com/users/shikhar2707/followers", "following_url": "https://api.github.com/users/shikhar2707/following{/other_user}", "gists_url": "https://api.github.com/users/shikhar2707/gists{/gist_id}", "starred_url": "https://api.github.com/users/shikhar2707/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shikhar2707/subscriptions", "organizations_url": "https://api.github.com/users/shikhar2707/orgs", "repos_url": "https://api.github.com/users/shikhar2707/repos", "events_url": "https://api.github.com/users/shikhar2707/events{/privacy}", "received_events_url": "https://api.github.com/users/shikhar2707/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-29T15:35:30Z", "updated_at": "2020-06-03T23:31:48Z", "closed_at": "2020-06-03T23:31:48Z", "author_association": "NONE", "active_lock_reason": null, "body": "Upon implementing some datasets such as Pix3D for the first time, one ends up with an error showing-\r\n`NonMatchingChecksumError: Artifact http://pix3d.csail.mit.edu/data/pix3d.zip, downloaded to ./pix3d.csail.mit.edu_pix3d4gh-bf6GMM2oHrBcmQyos_K1PupfuBITgTic9qdZ2Xc.zip.tmp.3b8459f449b34fc68ed246e8c371495f/pix3d.zip, has wrong checksum.`\r\n\r\nHence, I'll be sending a PR correcting the issue. Check if its fine.\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1754", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1754/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1754/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1754/events", "html_url": "https://github.com/tensorflow/datasets/issues/1754", "id": 589790171, "node_id": "MDU6SXNzdWU1ODk3OTAxNzE=", "number": 1754, "title": "Minor error in sentence in `add_dataset.md`", "user": {"login": "ManishAradwad", "id": 29497701, "node_id": "MDQ6VXNlcjI5NDk3NzAx", "avatar_url": "https://avatars0.githubusercontent.com/u/29497701?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ManishAradwad", "html_url": "https://github.com/ManishAradwad", "followers_url": "https://api.github.com/users/ManishAradwad/followers", "following_url": "https://api.github.com/users/ManishAradwad/following{/other_user}", "gists_url": "https://api.github.com/users/ManishAradwad/gists{/gist_id}", "starred_url": "https://api.github.com/users/ManishAradwad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ManishAradwad/subscriptions", "organizations_url": "https://api.github.com/users/ManishAradwad/orgs", "repos_url": "https://api.github.com/users/ManishAradwad/repos", "events_url": "https://api.github.com/users/ManishAradwad/events{/privacy}", "received_events_url": "https://api.github.com/users/ManishAradwad/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2020-03-29T13:19:17Z", "updated_at": "2020-04-04T02:22:26Z", "closed_at": "2020-04-04T02:22:26Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Under [`DatasetBuilder`](https://github.com/tensorflow/datasets/blob/master/docs/add_dataset.md#datasetbuilder), there is a sentence:\r\n\r\n```Most datasets subclass tfds.core.GeneratorBasedBuilder, which is a subclass of tfds.core.DatasetBuilder that simplifies defining a dataset. It works well for datasets that can be generated on a single machine. ```\r\n\r\nI think it should be ```Most datasets are defined as a subclass...```\r\n\r\nIf it's fine I'll be sending a PR soon. Thanks", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1753", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1753/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1753/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1753/events", "html_url": "https://github.com/tensorflow/datasets/issues/1753", "id": 589602871, "node_id": "MDU6SXNzdWU1ODk2MDI4NzE=", "number": 1753, "title": "[GSOC] Checksum mismatch for Pix3D", "user": {"login": "aradhyamathur", "id": 6674956, "node_id": "MDQ6VXNlcjY2NzQ5NTY=", "avatar_url": "https://avatars0.githubusercontent.com/u/6674956?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aradhyamathur", "html_url": "https://github.com/aradhyamathur", "followers_url": "https://api.github.com/users/aradhyamathur/followers", "following_url": "https://api.github.com/users/aradhyamathur/following{/other_user}", "gists_url": "https://api.github.com/users/aradhyamathur/gists{/gist_id}", "starred_url": "https://api.github.com/users/aradhyamathur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aradhyamathur/subscriptions", "organizations_url": "https://api.github.com/users/aradhyamathur/orgs", "repos_url": "https://api.github.com/users/aradhyamathur/repos", "events_url": "https://api.github.com/users/aradhyamathur/events{/privacy}", "received_events_url": "https://api.github.com/users/aradhyamathur/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2020-03-28T15:53:12Z", "updated_at": "2020-03-29T13:05:32Z", "closed_at": "2020-03-29T13:05:32Z", "author_association": "NONE", "active_lock_reason": null, "body": "While implementing the dataset for Pix3D I run into error due to a checksum mismatch from the DownloadManager. The error is as follows -\r\n\r\n`~/anaconda3/envs/gsoc/lib/python3.7/site-packages/tensorflow_datasets-2.1.0-py3.7.egg/tensorflow_datasets/core/download/download_manager.py in callback(val)\r\n    260       checksum, dl_size = val\r\n    261       return self._handle_download_result(\r\n--> 262           resource, download_dir_path, checksum, dl_size)\r\n    263     return self._downloader.download(url, download_dir_path).then(callback)\r\n    264 \r\n\r\n~/anaconda3/envs/gsoc/lib/python3.7/site-packages/tensorflow_datasets-2.1.0-py3.7.egg/tensorflow_datasets/core/download/download_manager.py in _handle_download_result(self, resource, tmp_dir_path, sha256, dl_size)\r\n    215       self._record_sizes_checksums()\r\n    216     elif (dl_size, sha256) != self._sizes_checksums.get(resource.url, None):\r\n--> 217       raise NonMatchingChecksumError(resource.url, tmp_path)\r\n    218     download_path = self._get_final_dl_path(resource.url, sha256)\r\n    219     resource_lib.write_info_file(resource, download_path, self._dataset_name,\r\n\r\nNonMatchingChecksumError: Artifact http://pix3d.csail.mit.edu/data/pix3d.zip, downloaded to ./pix3d.csail.mit.edu_pix3d4gh-bf6GMM2oHrBcmQyos_K1PupfuBITgTic9qdZ2Xc.zip.tmp.3b8459f449b34fc68ed246e8c371495f/pix3d.zip, has wrong checksum.`\r\n\r\n\r\n* Operating System: Ubuntu 18.04\r\n* Python version: 3.7.6\r\n* `tensorflow-datasets`/`tfds-nightly` version: 2.1.0\r\n\r\n\r\nCould you please guide how this error could be resolved ?\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1741", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1741/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1741/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1741/events", "html_url": "https://github.com/tensorflow/datasets/issues/1741", "id": 589294905, "node_id": "MDU6SXNzdWU1ODkyOTQ5MDU=", "number": 1741, "title": "[GSoC] Update Groove and Nsynth to use tfds.features.Audio", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}, {"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-27T17:37:21Z", "updated_at": "2020-04-01T21:40:07Z", "closed_at": "2020-04-01T21:39:49Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "It seems that groove dataset is currently using `tfds.features.Tensor` to store the audio. For consistency with other datasets, we should use `tfds.features.Audio` instead.\r\n\r\nhttps://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/audio/groove.py#L135\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1739", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1739/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1739/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1739/events", "html_url": "https://github.com/tensorflow/datasets/issues/1739", "id": 589242091, "node_id": "MDU6SXNzdWU1ODkyNDIwOTE=", "number": 1739, "title": "Load ImageNet from processed tfrecord files via tfds.load.", "user": {"login": "Gsunshine", "id": 18630903, "node_id": "MDQ6VXNlcjE4NjMwOTAz", "avatar_url": "https://avatars3.githubusercontent.com/u/18630903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gsunshine", "html_url": "https://github.com/Gsunshine", "followers_url": "https://api.github.com/users/Gsunshine/followers", "following_url": "https://api.github.com/users/Gsunshine/following{/other_user}", "gists_url": "https://api.github.com/users/Gsunshine/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gsunshine/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gsunshine/subscriptions", "organizations_url": "https://api.github.com/users/Gsunshine/orgs", "repos_url": "https://api.github.com/users/Gsunshine/repos", "events_url": "https://api.github.com/users/Gsunshine/events{/privacy}", "received_events_url": "https://api.github.com/users/Gsunshine/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-03-27T16:11:54Z", "updated_at": "2020-04-12T05:38:50Z", "closed_at": "2020-03-28T04:05:52Z", "author_association": "NONE", "active_lock_reason": null, "body": "**What I've tried so far**\r\nSince ImageNet changed its rule of downloading the dataset, I could not directly access the dataset via tfds.load. I followed [URL](https://cloud.google.com/tpu/docs/imagenet-setup) to transform local ImageNet 2012 dataset to tfrecord files. However I find it seems to be incompatible with current tfds API, especially tfds.load.\r\n\r\nI cannot load those tfrecord files through tfds.load. And it failed to continue even I resorted to tf.data.TFRecordDataset because I use the framework of tfgan [data_provider.py](https://github.com/tensorflow/gan/blob/master/tensorflow_gan/examples/self_attention_estimator/data_provider.py) and it presumed some features from the return type of tfds.load.\r\n\r\nI also tried to apply manual_dir through\r\n` download_and_prepare_kwargs={'download_config':tfds.download.DownloadConfig(manual_dir=flags.FLAGS.manual_dir)}`\r\nfor tfds.load but failed again since we had no original tar files except extrated images only.\r\n\r\n**What I need help with / What I was wondering**\r\nI am not sure how to meet the demand. It is more prefered to load the dataset from extracted images or processed tfrecord files via tfds.load since tfgan is well tested thus a re-implementation of data provider may change the training behavior.\r\n\r\nThx for help!", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1724", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1724/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1724/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1724/events", "html_url": "https://github.com/tensorflow/datasets/issues/1724", "id": 587558211, "node_id": "MDU6SXNzdWU1ODc1NTgyMTE=", "number": 1724, "title": "dataset_builder_test fails", "user": {"login": "Eshan-Agarwal", "id": 47007275, "node_id": "MDQ6VXNlcjQ3MDA3Mjc1", "avatar_url": "https://avatars0.githubusercontent.com/u/47007275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Eshan-Agarwal", "html_url": "https://github.com/Eshan-Agarwal", "followers_url": "https://api.github.com/users/Eshan-Agarwal/followers", "following_url": "https://api.github.com/users/Eshan-Agarwal/following{/other_user}", "gists_url": "https://api.github.com/users/Eshan-Agarwal/gists{/gist_id}", "starred_url": "https://api.github.com/users/Eshan-Agarwal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Eshan-Agarwal/subscriptions", "organizations_url": "https://api.github.com/users/Eshan-Agarwal/orgs", "repos_url": "https://api.github.com/users/Eshan-Agarwal/repos", "events_url": "https://api.github.com/users/Eshan-Agarwal/events{/privacy}", "received_events_url": "https://api.github.com/users/Eshan-Agarwal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2020-03-25T09:26:56Z", "updated_at": "2020-03-25T16:32:33Z", "closed_at": "2020-03-25T16:32:33Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Short description**\r\nRunning `!python ./tensorflow_datasets/core/dataset_builder_test.py` fails (After uninstalling pip package of tfds). otherwise tests fails\r\n\r\n**Environment information**\r\n* Operating System: <os> Colab\r\n* Python version: <version>\r\n* `tensorflow-datasets`/`tfds-nightly` version: <package and version>\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: <package and version> 2.0.0\r\n\r\n**Reproduction instructions**\r\nSee this [colab ](https://colab.research.google.com/drive/1y31DXfhGZbWE0_EXIJLpoDNfFgMd173Z)notebook\r\n\r\n**Link to logs**\r\nShows \r\n\r\n> Traceback (most recent call last):\r\n  File \"./tensorflow_datasets/core/dataset_builder_test.py\", line 29, in <module>\r\n    from tensorflow_datasets import testing\r\nModuleNotFoundError: No module named 'tensorflow_datasets'\r\n\r\n**Expected behavior**\r\nIt should run fine and all tests are passed sucessfully.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1716", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1716/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1716/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1716/events", "html_url": "https://github.com/tensorflow/datasets/issues/1716", "id": 587281627, "node_id": "MDU6SXNzdWU1ODcyODE2Mjc=", "number": 1716, "title": "[GSoC] Update checksums for missing urls", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}, {"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 19, "created_at": "2020-03-24T21:10:40Z", "updated_at": "2020-04-04T21:05:29Z", "closed_at": "2020-04-04T21:05:29Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Thanks to https://github.com/tensorflow/datasets/commit/5a8ee376c39a885c9132cdd22a8b2669febe6366 (https://github.com/tensorflow/datasets/issues/1397), we now check that all urls from `dl_manager.download()` are correctly registered.\r\n\r\nHowever, some of the urls are not registered for some of our datasets. We should generate the checksums for the missing urls by running `download_and_prepare` script with `--register_checksums` as per https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally.\r\n\r\nNote: The dataset don't need to be fully generated, so you can modify the dataset implementation to only download the files.\r\n\r\nThe datasets to updates are the ones with `SKIP_CHECKSUMS = True`.\r\nTo know which urls are missing, just run the tests and the error message should show the missing urls.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1709", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1709/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1709/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1709/events", "html_url": "https://github.com/tensorflow/datasets/issues/1709", "id": 587211207, "node_id": "MDU6SXNzdWU1ODcyMTEyMDc=", "number": 1709, "title": "[GSoC] Split `tfds.image` in smaller sections", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}, {"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-24T19:00:36Z", "updated_at": "2020-04-04T16:48:30Z", "closed_at": "2020-04-04T16:48:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "As the number of dataset is growing, it becomes harder to find images dataset: https://www.tensorflow.org/datasets/catalog/overview#all_datasets\r\n\r\nWe should try to split the image section into multiple ones. I think we should move all images datasets which have a `ClassLabel` into a new `image_classification` section.\r\n\r\nAs example, this was already done once for the object_detection section in https://github.com/tensorflow/datasets/commit/bc2d5c71351a51fb330d5d933dfbe12838610a65 and https://github.com/tensorflow/datasets/commit/9b948c44bccb9184c81ac4395a0aaab2257344a1\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1708", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1708/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1708/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1708/events", "html_url": "https://github.com/tensorflow/datasets/issues/1708", "id": 587174825, "node_id": "MDU6SXNzdWU1ODcxNzQ4MjU=", "number": 1708, "title": "[GSoC] TFDS should fail when user try to generate an old version", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2020-03-24T18:06:30Z", "updated_at": "2020-04-08T16:51:53Z", "closed_at": "2020-04-08T16:51:53Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "TFDS only support generation of dataset for the last versions.\r\n\r\nWe should make sure to raise an error here if the user try to generate an older version. The `download_and_prepare()` function should be updated here to raise an error: https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/core/dataset_builder.py#L290\r\n\r\nA version can only be installed if the version is the `self.canonical_version` or the `max(self.versions)`\r\n\r\nFor example:\r\n```\r\nVERSION = tfds.core.Version('1.0.0')  # Can be generated\r\nSUPPORTED_VERSION = [\r\n    tfds.core.Version('2.1.0'),  # Can be generated\r\n    tfds.core.Version('2.0.0'),  # Cannot be generated\r\n    tfds.core.Version('0.1.0'),  # Cannot be generated\r\n]\r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1699", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1699/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1699/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1699/events", "html_url": "https://github.com/tensorflow/datasets/issues/1699", "id": 586346369, "node_id": "MDU6SXNzdWU1ODYzNDYzNjk=", "number": 1699, "title": "[GSoC] Fix scientific_paper dataset", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}, {"id": 1686186902, "node_id": "MDU6TGFiZWwxNjg2MTg2OTAy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/contributions%20welcome", "name": "contributions welcome", "color": "f98e9e", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-03-23T16:37:31Z", "updated_at": "2020-03-30T20:11:31Z", "closed_at": "2020-03-30T20:11:31Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "**Short description**\r\n\r\nCurrent dataset generation is broken for `scientific_paper`:\r\n\r\n```\r\ntensorflow_datasets/core/dataset_builder.py\", line 955, in _download_and_prepare\r\n 0323 08:31:16.738257     self._prepare_split(split_generator, **prepare_split_kwargs)\r\n 0323 08:31:16.738258   File \"/py/tensorflow_datasets/core/dataset_builder.py\", line 1127, in _prepare_split\r\n 0323 08:31:16.738259     total=split_info.num_examples, leave=False):\r\n 0323 08:31:16.738260   File \"/py/tqdm/_tqdm.py\", line 979, in __iter__\r\n 0323 08:31:16.738261     for obj in iterable:\r\n 0323 08:31:16.738262   File \"/py/tensorflow_datasets/summarization/scientific_papers.py\", line 115, in _generate_examples\r\n 0323 08:31:16.738265     for line in f:\r\n 0323 08:31:16.738266   File \"tensorflow/python/lib/io/file_io.py\", line 211, in __next__\r\n 0323 08:31:16.738267     return self.next()\r\n 0323 08:31:16.738268   File \"/tensorflow/python/lib/io/file_io.py\", line 205, in next\r\n 0323 08:31:16.738269     retval = self.readline()\r\n 0323 08:31:16.738270   File \"/tensorflow/python/lib/io/file_io.py\", line 169, in readline\r\n 0323 08:31:16.738271     self._preread_check()\r\n 0323 08:31:16.738272   File \"/tensorflow/python/lib/io/file_io.py\", line 79, in _preread_check\r\n 0323 08:31:16.738273     self.__name, 1024 * 512)\r\n 0323 08:31:16.738275 google3.third_party.tensorflow.python.framework.errors_impl.NotFoundError: no parent directory '/home/tensorflow-datasets/extracts/ZIP.ucid_1lvsqvsFi3W-pE1SqNZI0s8NR_export_download1CQHRyal4p4gv4NAVf5-_pD4o3vOCitRLkq35IcBPAQ/pubmed-release'; /home/tensorflow-datasets/extracts/ZIP.ucid_1lvsqvsFi3W-pE1SqNZI0s8NR_export_download1CQHRyal4p4gv4NAVf5-_pD4o3vOCitRLkq35IcBPAQ/pubmed-release/train.txt; Open on /home/tensorflow-datasets/extracts/ZIP.ucid_1lvsqvsFi3W-pE1SqNZI0s8NR_export_download1CQHRyal4p4gv4NAVf5-_pD4o3vOCitRLkq35IcBPAQ/pubmed-release/train.txt\r\n 0323 08:31:16.738313 \u001b[1mDownloading and preparing dataset scientific_papers/pubmed/1.1.1 (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/tensorflow-datasets/datasets/2020-03-23_082941586704.scientific_papers/scientific_papers/pubmed/1.1.1...\u001b[0m\r\n 0323 08:31:16.738319 \r\n```\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1696", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1696/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1696/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1696/events", "html_url": "https://github.com/tensorflow/datasets/issues/1696", "id": 586208101, "node_id": "MDU6SXNzdWU1ODYyMDgxMDE=", "number": 1696, "title": "show_examples fails to import matplotlib.pyplot", "user": {"login": "Flamefire", "id": 309017, "node_id": "MDQ6VXNlcjMwOTAxNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/309017?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Flamefire", "html_url": "https://github.com/Flamefire", "followers_url": "https://api.github.com/users/Flamefire/followers", "following_url": "https://api.github.com/users/Flamefire/following{/other_user}", "gists_url": "https://api.github.com/users/Flamefire/gists{/gist_id}", "starred_url": "https://api.github.com/users/Flamefire/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Flamefire/subscriptions", "organizations_url": "https://api.github.com/users/Flamefire/orgs", "repos_url": "https://api.github.com/users/Flamefire/repos", "events_url": "https://api.github.com/users/Flamefire/events{/privacy}", "received_events_url": "https://api.github.com/users/Flamefire/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2020-03-23T13:27:38Z", "updated_at": "2020-03-23T23:46:45Z", "closed_at": "2020-03-23T23:46:45Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\n`show_examples` leads to an error: \"AttributeError: module 'matplotlib' has no attribute 'pyplot'\"\r\n\r\n**Environment information**\r\n* Operating System: Linux\r\n* Python version: 3.7.4\r\n* `tensorflow-datasets` version: 2.0.0\r\n\r\n**Reproduction instructions**\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\ndatasets, info = tfds.load(name='stanford_dogs',\r\n                               with_info=True, split='train')\r\ntfds.show_examples(\r\n    info, datasets, rows=3, cols=3, plot_scale=3.0, image_key=None\r\n)\r\n```\r\n\r\n**Additional context**\r\nhttps://github.com/tensorflow/datasets/blob/dcaa4c76905bb9eb14b4e0947d1fce15c48aea0f/tensorflow_datasets/core/visualization.py#L66 is not enough, you need to explicitly `import matplotlib.pyplot`, see https://stackoverflow.com/questions/14812342/matplotlib-has-no-attribute-pyplot\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1695", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1695/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1695/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1695/events", "html_url": "https://github.com/tensorflow/datasets/issues/1695", "id": 586175430, "node_id": "MDU6SXNzdWU1ODYxNzU0MzA=", "number": 1695, "title": "tfds doesn't work", "user": {"login": "colinbebrave", "id": 13401748, "node_id": "MDQ6VXNlcjEzNDAxNzQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/13401748?v=4", "gravatar_id": "", "url": "https://api.github.com/users/colinbebrave", "html_url": "https://github.com/colinbebrave", "followers_url": "https://api.github.com/users/colinbebrave/followers", "following_url": "https://api.github.com/users/colinbebrave/following{/other_user}", "gists_url": "https://api.github.com/users/colinbebrave/gists{/gist_id}", "starred_url": "https://api.github.com/users/colinbebrave/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/colinbebrave/subscriptions", "organizations_url": "https://api.github.com/users/colinbebrave/orgs", "repos_url": "https://api.github.com/users/colinbebrave/repos", "events_url": "https://api.github.com/users/colinbebrave/events{/privacy}", "received_events_url": "https://api.github.com/users/colinbebrave/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-03-23T12:33:58Z", "updated_at": "2020-03-24T03:05:11Z", "closed_at": "2020-03-24T03:05:10Z", "author_association": "NONE", "active_lock_reason": null, "body": "tfds just doesn't work..\r\nevery time I run code like \r\n`tfds.load('ted_hrlr_translate/pt_to_en', with_info=True)`, it would return \r\n\r\n```\r\nERROR:absl:Failed to construct dataset ted_hrlr_translate\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/adapters.py\", line 412, in send\r\n    conn = self.get_connection(request.url, proxies)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/adapters.py\", line 305, in get_connection\r\n    proxy_url = parse_url(proxy)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/util/url.py\", line 398, in parse_url\r\n    return six.raise_from(LocationParseError(source_url), None)\r\n  File \"<string>\", line 3, in raise_from\r\nexport\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 2, in <module>\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/registered.py\", line 302, in load\r\n    dbuilder = builder(name, data_dir=data_dir, **builder_kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/registered.py\", line 172, in builder\r\n    return _DATASET_REGISTRY[name](**builder_kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 203, in __init__\r\n    self.info.initialize_from_bucket()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_info.py\", line 428, in initialize_from_bucket\r\n    data_files = gcs_utils.gcs_dataset_info_files(self.full_name)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/utils/gcs_utils.py\", line 65, in gcs_dataset_info_files\r\n    filenames = [el for el in gcs_files(prefix_filter=prefix)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/utils/gcs_utils.py\", line 55, in gcs_files\r\n    top_level_xml_str = download_gcs_file(\"\", prefix_filter=prefix_filter)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_datasets/core/utils/gcs_utils.py\", line 41, in download_gcs_file\r\n    resp = requests.get(url, stream=stream)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\", line 76, in get\r\n    return request('get', url, params=params, **kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\", line 61, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\", line 530, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\", line 643, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/adapters.py\", line 414, in send\r\n    raise InvalidURL(e, request=request)\r\nexport\r\n```\r\n\r\n**What I've tried so far**\r\nI upgraded tfds, six, requests, but still no gains.\r\n\r\n\r\n**Environment information**\r\n* Operating System: macos 10.15.3\r\n* Python version: 3.7.3\r\n* `tensorflow-datasets`/`tfds-nightly` version: 2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: 2.1.0\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1692", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1692/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1692/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1692/events", "html_url": "https://github.com/tensorflow/datasets/issues/1692", "id": 585945393, "node_id": "MDU6SXNzdWU1ODU5NDUzOTM=", "number": 1692, "title": "waymo_open_dataset does not work", "user": {"login": "karolmajek", "id": 11379772, "node_id": "MDQ6VXNlcjExMzc5Nzcy", "avatar_url": "https://avatars0.githubusercontent.com/u/11379772?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karolmajek", "html_url": "https://github.com/karolmajek", "followers_url": "https://api.github.com/users/karolmajek/followers", "following_url": "https://api.github.com/users/karolmajek/following{/other_user}", "gists_url": "https://api.github.com/users/karolmajek/gists{/gist_id}", "starred_url": "https://api.github.com/users/karolmajek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karolmajek/subscriptions", "organizations_url": "https://api.github.com/users/karolmajek/orgs", "repos_url": "https://api.github.com/users/karolmajek/repos", "events_url": "https://api.github.com/users/karolmajek/events{/privacy}", "received_events_url": "https://api.github.com/users/karolmajek/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-03-23T05:38:00Z", "updated_at": "2020-03-23T16:19:06Z", "closed_at": "2020-03-23T16:19:06Z", "author_association": "NONE", "active_lock_reason": null, "body": "**Short description**\r\nI wanted to use this one: https://www.tensorflow.org/datasets/catalog/waymo_open_dataset\r\nand get:\r\n\r\n```\r\nDatasetNotFoundError: Dataset waymo_open_dataset not found. Available datasets:\r\n\r\n```\r\n\r\n**Environment information**\r\n- Colab\r\n- TF2\r\n\r\n**Reproduction instructions**\r\nhttps://colab.research.google.com/drive/1BLw3KWI6NkE19ZnOnO3As6WGUbpTiJ2r\r\n\r\n```\r\ntry:\r\n  # Use the %tensorflow_version magic if in colab.\r\n  %tensorflow_version 2.x\r\nexcept Exception:\r\n  pass\r\n\r\n!pip uninstall tensorflow_datasets -y\r\n!pip install git+https://github.com/tensorflow/datasets.git\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\ntfds.object_detection.__dir__()\r\nds = tfds.load('waymo_open_dataset')\r\n```\r\nResult:\r\n```\r\n['__name__',\r\n '__doc__',\r\n '__package__',\r\n '__loader__',\r\n '__spec__',\r\n '__path__',\r\n '__file__',\r\n '__cached__',\r\n '__builtins__',\r\n 'coco',\r\n 'Coco',\r\n 'kitti',\r\n 'Kitti',\r\n 'open_images',\r\n 'OpenImagesV4',\r\n 'voc',\r\n 'Voc',\r\n 'wider_face',\r\n 'WiderFace']\r\nDatasetNotFoundError: Dataset waymo_open_dataset not found. Available datasets:\r\n[...]\r\n```\r\n\r\n**Expected behavior**\r\nload Waymo Open Datset\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1691", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1691/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1691/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1691/events", "html_url": "https://github.com/tensorflow/datasets/issues/1691", "id": 585695630, "node_id": "MDU6SXNzdWU1ODU2OTU2MzA=", "number": 1691, "title": "A feature to show relationship between datasets", "user": {"login": "vijayphoenix", "id": 41972768, "node_id": "MDQ6VXNlcjQxOTcyNzY4", "avatar_url": "https://avatars3.githubusercontent.com/u/41972768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vijayphoenix", "html_url": "https://github.com/vijayphoenix", "followers_url": "https://api.github.com/users/vijayphoenix/followers", "following_url": "https://api.github.com/users/vijayphoenix/following{/other_user}", "gists_url": "https://api.github.com/users/vijayphoenix/gists{/gist_id}", "starred_url": "https://api.github.com/users/vijayphoenix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vijayphoenix/subscriptions", "organizations_url": "https://api.github.com/users/vijayphoenix/orgs", "repos_url": "https://api.github.com/users/vijayphoenix/repos", "events_url": "https://api.github.com/users/vijayphoenix/events{/privacy}", "received_events_url": "https://api.github.com/users/vijayphoenix/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290132, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMy", "url": "https://api.github.com/repos/tensorflow/datasets/labels/enhancement", "name": "enhancement", "color": "a2eeef", "default": true, "description": "New feature or request"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2020-03-22T11:18:57Z", "updated_at": "2020-06-03T23:32:12Z", "closed_at": "2020-06-03T23:32:11Z", "author_association": "COLLABORATOR", "active_lock_reason": null, "body": "As the no. of datasets (~ 200) in tfds is growing, soon it will become harder to iterate over the list of datasets.\r\nSo, it would be great if we could add some feature to \r\n* show the relationship between datasets or \r\n* give a hint of what are other similar datasets.\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1690", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1690/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1690/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1690/events", "html_url": "https://github.com/tensorflow/datasets/issues/1690", "id": 585635766, "node_id": "MDU6SXNzdWU1ODU2MzU3NjY=", "number": 1690, "title": "How to find the download link for specific datasets?", "user": {"login": "tinyxuyan", "id": 44150841, "node_id": "MDQ6VXNlcjQ0MTUwODQx", "avatar_url": "https://avatars1.githubusercontent.com/u/44150841?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tinyxuyan", "html_url": "https://github.com/tinyxuyan", "followers_url": "https://api.github.com/users/tinyxuyan/followers", "following_url": "https://api.github.com/users/tinyxuyan/following{/other_user}", "gists_url": "https://api.github.com/users/tinyxuyan/gists{/gist_id}", "starred_url": "https://api.github.com/users/tinyxuyan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tinyxuyan/subscriptions", "organizations_url": "https://api.github.com/users/tinyxuyan/orgs", "repos_url": "https://api.github.com/users/tinyxuyan/repos", "events_url": "https://api.github.com/users/tinyxuyan/events{/privacy}", "received_events_url": "https://api.github.com/users/tinyxuyan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1168536139, "node_id": "MDU6TGFiZWwxMTY4NTM2MTM5", "url": "https://api.github.com/repos/tensorflow/datasets/labels/help", "name": "help", "color": "e29e6c", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-22T03:20:47Z", "updated_at": "2020-03-22T05:40:42Z", "closed_at": "2020-03-22T05:40:42Z", "author_association": "NONE", "active_lock_reason": null, "body": "The net is quite slow here, therefore, I can not download the datasets through tfds.load command. I want to manually add the datasets to the desired path. However, I can not find the download link for the specific datasets, such as the MNIST. \r\nHoping someone can teach me how to find the links.\r\nThanks in advance.", "performed_via_github_app": null, "score": 1.0}, {"url": "https://api.github.com/repos/tensorflow/datasets/issues/1682", "repository_url": "https://api.github.com/repos/tensorflow/datasets", "labels_url": "https://api.github.com/repos/tensorflow/datasets/issues/1682/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/datasets/issues/1682/comments", "events_url": "https://api.github.com/repos/tensorflow/datasets/issues/1682/events", "html_url": "https://github.com/tensorflow/datasets/issues/1682", "id": 584812305, "node_id": "MDU6SXNzdWU1ODQ4MTIzMDU=", "number": 1682, "title": "robonet.py was not downloaded after pip install", "user": {"login": "Eshan-Agarwal", "id": 47007275, "node_id": "MDQ6VXNlcjQ3MDA3Mjc1", "avatar_url": "https://avatars0.githubusercontent.com/u/47007275?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Eshan-Agarwal", "html_url": "https://github.com/Eshan-Agarwal", "followers_url": "https://api.github.com/users/Eshan-Agarwal/followers", "following_url": "https://api.github.com/users/Eshan-Agarwal/following{/other_user}", "gists_url": "https://api.github.com/users/Eshan-Agarwal/gists{/gist_id}", "starred_url": "https://api.github.com/users/Eshan-Agarwal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Eshan-Agarwal/subscriptions", "organizations_url": "https://api.github.com/users/Eshan-Agarwal/orgs", "repos_url": "https://api.github.com/users/Eshan-Agarwal/repos", "events_url": "https://api.github.com/users/Eshan-Agarwal/events{/privacy}", "received_events_url": "https://api.github.com/users/Eshan-Agarwal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1052290130, "node_id": "MDU6TGFiZWwxMDUyMjkwMTMw", "url": "https://api.github.com/repos/tensorflow/datasets/labels/bug", "name": "bug", "color": "d73a4a", "default": true, "description": "Something isn't working"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2020-03-20T02:59:25Z", "updated_at": "2020-03-20T18:01:17Z", "closed_at": "2020-03-20T11:34:16Z", "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "**Short description**\r\nI am trying to load `robonet ` dataset after `pip install tensorflow_datasets` (without importing it from cloning repo) but it says no dataset name robonet exist.\r\n\r\n**Environment information**\r\n* Operating System: <os> Windows 10\r\n* Python version: <version> 3.7\r\n* `tensorflow-datasets`/`tfds-nightly` version: <package and version>2.1.0\r\n* `tensorflow`/`tensorflow-gpu`/`tf-nightly`/`tf-nightly-gpu` version: <package and version>2.0\r\n\r\n**Reproduction instructions**\r\n\r\nPlease make sure you run below script after  `pip install tensorflow_datasets` (Not with cloned one)\r\n```\r\nimport tensorflow_datasets as tfds\r\ndata, data_info = tfds.load(\"robonet\", with_info= True)\r\nprint(data_info)\r\n```\r\n\r\n**Expected behavior**\r\nLike other datasets `robonet `also loaded successfully using `tfds.load`\r\n\r\n\r\n", "performed_via_github_app": null, "score": 1.0}]}